[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R 数据科学 2e （双语）",
    "section": "",
    "text": "Welcome\nThis is the website for the 2nd edition of “R for Data Science”. This book will teach you how to do data science with R: You’ll learn how to get your data into R, get it into the most useful structure, transform it and visualize.\n这里是第二版 《R 数据科学》 的网站。 本书将教你如何用 R 来做数据科学：你将学习如何将数据导入 R，如何将其整理为最有用结构，以及如何转换和可视化数据。\nIn this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualizing, and exploring data.\n在本书中，你会发现一套数据科学的实践技能。 就像化学家学习如何清洗试管和储备实验室一样，你将学习如何清理数据和绘制图表——以及许多其他事情。 这些是让数据科学得以实现的技能，在这里你会找到用 R 来完成这些事情的最佳实践。 你将学习如何使用图形语法 (grammar of graphics)、文学编程 (literate programming) 和可重复研究 (reproducible research) 来节省时间。 你还将学习如何管理认知资源，以便在整理、可视化和探索数据时促进新发现。\nThis website is and will always be free, licensed under the CC BY-NC-ND 3.0 License. If you’d like a physical copy of the book, you can order it on Amazon. If you appreciate reading the book for free and would like to give back, please make a donation to Kākāpō Recovery: the kākāpō (which appears on the cover of R4DS) is a critically endangered parrot native to New Zealand; there are only 244 left.\n本网站是并且将永远是免费的，基于 CC BY-NC-ND 3.0 许可协议。 如果你想要实体书，可以在 亚马逊 上订购。 如果你很感激能够免费阅读本书并希望回馈，请向 Kākāpō Recovery 捐款：kākāpō (R4DS 封面上的鸟) 是新西兰本土的一种极度濒危的鹦鹉；目前仅存 244 只。\nIf you speak another language, you might be interested in the freely available translations of the 1st edition:\n如果你使用其他语言，你可能会对第一版的免费译本感兴趣：\n\nSpanish\nItalian\nTurkish\nPortuguese\n\nYou can find suggested answers to exercises in the book at https://mine-cetinkaya-rundel.github.io/r4ds-solutions.\n你可以在 https://mine-cetinkaya-rundel.github.io/r4ds-solutions 找到书中练习的建议答案。\nPlease note that R4DS uses a Contributor Code of Conduct. By contributing to this book, you agree to abide by its terms.\n请注意，R4DS 使用 贡献者行为准则。 为本书做贡献，即表示你同意遵守其条款。 http://googleusercontent.com/youtube_content/0",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface-2e.html",
    "href": "preface-2e.html",
    "title": "Preface to the second edition",
    "section": "",
    "text": "Welcome to the second edition of “R for Data Science”! This is a major reworking of the first edition, removing material we no longer think is useful, adding material we wish we included in the first edition, and generally updating the text and code to reflect changes in best practices. We’re also very excited to welcome a new co-author: Mine Çetinkaya-Rundel, a noted data science educator and one of our colleagues at Posit (the company formerly known as RStudio).\n欢迎阅读《R 数据科学》第二版！ 这是对第一版的一次重大修订，我们删除了一些我们认为不再有用的材料，添加了我们希望在第一版中就包含的内容，并全面更新了文本和代码，以反映最佳实践的变化。 我们也非常高兴地迎来了一位新的合著者：Mine Çetinkaya-Rundel，她是一位著名的数据科学教育家，也是我们在 Posit (前身为 RStudio 的公司) 的同事之一。\nA brief summary of the biggest changes follows:\n以下是主要变化的简要总结：\n\nThe first part of the book has been renamed to “Whole game”. The goal of this section is to give you the rough details of the “whole game” of data science before we dive into the details.\n本书的第一部分已更名为 “全局认知” (Whole game)。 本部分的目标是在我们深入探讨细节之前，让你对数据科学的 “全局” 有一个大致的了解。\nThe second part of the book is “Visualize”. This part gives data visualization tools and best practices a more thorough coverage compared to the first edition. The best place to get all the details is still the ggplot2 book, but now R4DS covers more of the most important techniques.\n本书的第二部分是 “可视化” (Visualize)。 与第一版相比，这部分对数据可视化工具和最佳实践进行了更全面的介绍。 获取所有细节的最佳去处仍然是 《ggplot2 book》，但现在 R4DS 涵盖了更多最重要的技术。\nThe third part of the book is now called “Transform” and gains new chapters on numbers, logical vectors, and missing values. These were previously parts of the data transformation chapter, but needed much more room to cover all the details.\n本书的第三部分现在称为 “转换” (Transform)，并增加了关于数字、逻辑向量和缺失值的新章节。 这些内容以前是数据转换章节的一部分，但需要更多的空间来涵盖所有细节。\nThe fourth part of the book is called “Import”. It’s a new set of chapters that goes beyond reading flat text files to working with spreadsheets, getting data out of databases, working with big data, rectangling hierarchical data, and scraping data from web sites.\n本书的第四部分称为 “导入” (Import)。 这是一组新的章节，内容超出了读取纯文本文件的范围，还包括处理电子表格、从数据库中获取数据、处理大数据、整理层次化数据以及从网站上抓取数据。\nThe “Program” part remains, but has been rewritten from top-to-bottom to focus on the most important parts of function writing and iteration. Function writing now includes details on how to wrap tidyverse functions (dealing with the challenges of tidy evaluation), since this has become much easier and more important over the last few years. We’ve added a new chapter on important base R functions that you’re likely to see in wild-caught R code.\n“编程” (Program) 部分仍然保留，但已经从头到尾进行了重写，以专注于函数编写和迭代的最重要部分。 函数编写现在包含了如何包装 tidyverse 函数的细节 (处理整洁评估 (tidy evaluation) 的挑战)，因为在过去几年中，这变得更加容易和重要。 我们增加了一个新章节，介绍了一些重要的基础 R 函数，你很可能会在实际的 R 代码中看到它们。\nThe modeling part has been removed. We never had enough room to fully do modelling justice, and there are now much better resources available. We generally recommend using the tidymodels packages and reading Tidy Modeling with R by Max Kuhn and Julia Silge.\n建模 (modeling) 部分已被移除。 我们一直没有足够的篇幅来充分地讲解建模，而且现在有更好的资源可供使用。 我们通常推荐使用 tidymodels 宏包并阅读 Max Kuhn 和 Julia Silge 合著的 《Tidy Modeling with R》。\nThe “Communicate” part remains, but has been thoroughly updated to feature Quarto instead of R Markdown. This edition of the book has been written in Quarto, and it’s clearly the tool of the future.\n“沟通” (Communicate) 部分仍然保留，但已经全面更新，以 Quarto 代替 R Markdown。 本书的这一版是用 Quarto 编写的，它显然是未来的工具。",
    "crumbs": [
      "Preface to the second edition"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "What you will learn\nData science is an exciting discipline that allows you to transform raw data into understanding, insight, and knowledge.\n数据科学是一门激动人心的学科，它能让你将原始数据转化为理解、洞察和知识。\nThe goal of “R for Data Science” is to help you learn the most important tools in R that will allow you to do data science efficiently and reproducibly, and to have some fun along the way 😃.\n《R 数据科学》的目标是帮助你学习 R 中最重要的工具，这些工具将使你能够高效、可重复地进行数据科学工作，并在此过程中获得一些乐趣 😃。\nAfter reading this book, you’ll have the tools to tackle a wide variety of data science challenges using the best parts of R.\n读完本书后，你将拥有使用 R 的精华部分来应对各种数据科学挑战的工具。\nData science is a vast field, and there’s no way you can master it all by reading a single book.\n数据科学是一个广阔的领域，不可能通过阅读一本书就掌握所有内容。\nThis book aims to give you a solid foundation in the most important tools and enough knowledge to find the resources to learn more when necessary.\n本书旨在为你打下最重要的工具的坚实基础，并提供足够的知识，以便在必要时找到更多学习资源。\nOur model of the steps of a typical data science project looks something like Figure 1.\n我们对典型数据科学项目步骤的模型如 Figure 1 所示。\nFigure 1: In our model of the data science process, you start with data import and tidying. Next, you understand your data with an iterative cycle of transforming, visualizing, and modeling. You finish the process by communicating your results to other humans.\nFirst, you must import your data into R.\n首先，你必须将数据 导入 (import) 到 R 中。\nThis typically means that you take data stored in a file, database, or web application programming interface (API) and load it into a data frame in R.\n这通常意味着你将存储在文件、数据库或 Web 应用程序编程接口 (API) 中的数据加载到 R 的数据框 (data frame) 中。\nIf you can’t get your data into R, you can’t do data science on it!\n如果无法将数据导入 R，你就无法对其进行数据科学分析！\nOnce you’ve imported your data, it is a good idea to tidy it.\n导入数据后，最好对其进行 整理 (tidy)。\nTidying your data means storing it in a consistent form that matches the semantics of the dataset with how it is stored.\n整理数据意味着将其以一种一致的形式存储，该形式将数据集的语义与其存储方式相匹配。\nIn brief, when your data is tidy, each column is a variable and each row is an observation.\n简而言之，当你的数据是整洁 (tidy) 的时，每一列都是一个变量，每一行都是一个观测。\nTidy data is important because the consistent structure lets you focus your efforts on answering questions about the data, not fighting to get the data into the right form for different functions.\n整洁的数据很重要，因为其一致的结构可以让你专注于回答关于数据的问题，而不是费力地将数据转换为适合不同函数的形式。\nOnce you have tidy data, a common next step is to transform it.\n拥有整洁的数据后，通常的下一步是进行 转换 (transform)。\nTransformation includes narrowing in on observations of interest (like all people in one city or all data from the last year), creating new variables that are functions of existing variables (like computing speed from distance and time), and calculating a set of summary statistics (like counts or means).\n转换包括筛选出感兴趣的观测（例如，某个城市的所有人或去年的所有数据），根据现有变量创建新变量（例如，根据距离和时间计算速度），以及计算一组摘要统计量（例如，计数或均值）。\nTogether, tidying and transforming are called wrangling because getting your data in a form that’s natural to work with often feels like a fight!\n整理和转换合在一起被称为 数据整理 (wrangling)，因为将数据处理成易于使用的形式通常感觉像一场战斗！\nOnce you have tidy data with the variables you need, there are two main engines of knowledge generation: visualization and modeling.\n当你拥有了包含所需变量的整洁数据后，知识生成的两大引擎便是：可视化和建模。\nThese have complementary strengths and weaknesses, so any real data analysis will iterate between them many times.\n这两者各有优缺点，相辅相成，因此任何实际的数据分析都会在它们之间多次迭代。\nVisualization is a fundamentally human activity.\n可视化 (Visualization) 本质上是一项人类活动。\nA good visualization will show you things you did not expect or raise new questions about the data.\n好的可视化会向你展示意想不到的情况，或引发关于数据的新问题。\nA good visualization might also hint that you’re asking the wrong question or that you need to collect different data.\n好的可视化也可能暗示你问错了问题，或者你需要收集不同的数据。\nVisualizations can surprise you, but they don’t scale particularly well because they require a human to interpret them.\n可视化可以给你带来惊喜，但它们的可扩展性不是很好，因为它们需要人来解释。\nModels are complementary tools to visualization.\n模型 (Models) 是可视化的补充工具。\nOnce you have made your questions sufficiently precise, you can use a model to answer them.\n一旦你将问题定义得足够精确，就可以使用模型来回答它们。\nModels are fundamentally mathematical or computational tools, so they generally scale well.\n模型本质上是数学或计算工具，因此它们通常具有良好的可扩展性。\nEven when they don’t, it’s usually cheaper to buy more computers than it is to buy more brains!\n即使它们不具备扩展性，通常购买更多的计算机也比雇佣更多的人脑便宜！\nBut every model makes assumptions, and by its very nature, a model cannot question its own assumptions.\n但是，每个模型都有其假设，而模型本身无法质疑自身的假设。\nThat means a model cannot fundamentally surprise you.\n这意味着模型本质上不会给你带来惊喜。\nThe last step of data science is communication, an absolutely critical part of any data analysis project.\n数据科学的最后一步是 沟通 (communication)，这是任何数据分析项目中都至关重要的部分。\nIt doesn’t matter how well your models and visualization have led you to understand the data unless you can also communicate your results to others.\n除非你能够将结果传达给他人，否则无论你的模型和可视化让你对数据有多深的理解，都毫无意义。\nSurrounding all these tools is programming.\n围绕所有这些工具的是 编程 (programming)。\nProgramming is a cross-cutting tool that you use in nearly every part of a data science project.\n编程是一个贯穿始终的工具，你在数据科学项目的几乎每个部分都会用到它。\nYou don’t need to be an expert programmer to be a successful data scientist, but learning more about programming pays off because becoming a better programmer allows you to automate common tasks and solve new problems with greater ease.\n你不需要成为编程专家才能成为一名成功的数据科学家，但学习更多编程知识是值得的，因为成为一名更好的程序员可以让你自动化常规任务，并更轻松地解决新问题。\nYou’ll use these tools in every data science project, but they’re not enough for most projects.\n你会在每个数据科学项目中使用这些工具，但对于大多数项目来说，这些工具是不够的。\nThere’s a rough 80/20 rule at play: you can tackle about 80% of every project using the tools you’ll learn in this book, but you’ll need other tools to tackle the remaining 20%.\n这里有一个粗略的 80/20 法则：你可以使用本书中学到的工具解决每个项目中大约 80% 的问题，但你需要其他工具来解决剩下的 20%。\nThroughout this book, we’ll point you to resources where you can learn more.\n在本书中，我们将为你指出可以学习更多内容的资源。",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#how-this-book-is-organized",
    "href": "intro.html#how-this-book-is-organized",
    "title": "Introduction",
    "section": "How this book is organized",
    "text": "How this book is organized\nThe previous description of the tools of data science is organized roughly according to the order in which you use them in an analysis (although, of course, you’ll iterate through them multiple times).\n前面关于数据科学工具的描述大致是按照你在分析中使用的顺序来组织的（当然，你会多次迭代使用它们）。\nIn our experience, however, learning data importing and tidying first is suboptimal because, 80% of the time, it’s routine and boring, and the other 20% of the time, it’s weird and frustrating.\n然而，根据我们的经验，首先学习数据导入和整理并非最佳选择，因为 80% 的情况下，这个过程是常规且乏味的，而另外 20% 的情况下，它又奇怪又令人沮丧。\nThat’s a bad place to start learning a new subject!\n这对于开始学习一个新主题来说不是一个好的起点！\nInstead, we’ll start with visualization and transformation of data that’s already been imported and tidied.\n因此，我们将从已导入和整理好的数据的可视化和转换开始。\nThat way, when you ingest and tidy your own data, your motivation will stay high because you know the pain is worth the effort.\n这样，当你处理和整理自己的数据时，你会保持高昂的积极性，因为你知道这些辛苦是值得的。\nWithin each chapter, we try to adhere to a consistent pattern: start with some motivating examples so you can see the bigger picture, and then dive into the details.\n在每一章中，我们都尽量遵循一个一致的模式：从一些激励人心的例子开始，让你看到全局，然后再深入细节。\nEach section of the book is paired with exercises to help you practice what you’ve learned.\n本书的每个部分都配有练习，以帮助你实践所学内容。\nAlthough it can be tempting to skip the exercises, there’s no better way to learn than by practicing on real problems.\n尽管跳过练习很诱人，但没有比通过解决实际问题进行练习更好的学习方法了。",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#what-you-wont-learn",
    "href": "intro.html#what-you-wont-learn",
    "title": "Introduction",
    "section": "What you won’t learn",
    "text": "What you won’t learn\nThere are several important topics that this book doesn’t cover.\n本书没有涵盖几个重要主题。\nWe believe it’s important to stay ruthlessly focused on the essentials so you can get up and running as quickly as possible.\n我们认为，严格专注于基础知识非常重要，这样你才能尽快上手。\nThat means this book can’t cover every important topic.\n这意味着本书无法涵盖所有重要主题。\nModeling\nModeling is super important for data science, but it’s a big topic, and unfortunately, we just don’t have the space to give it the coverage it deserves here.\n建模对于数据科学非常重要，但它是一个很大的主题，不幸的是，我们在这里没有足够的篇幅来给予它应有的介绍。\nTo learn more about modeling, we highly recommend Tidy Modeling with R by our colleagues Max Kuhn and Julia Silge.\n要了解更多关于建模的知识，我们强烈推荐我们的同事 Max Kuhn 和 Julia Silge 编写的 《Tidy Modeling with R》。\nThis book will teach you the tidymodels family of packages, which, as you might guess from the name, share many conventions with the tidyverse packages we use in this book.\n这本书将教你 tidymodels 系列包，正如你可能从名字中猜到的那样，它与我们在本书中使用的 tidyverse 包有许多共同的约定。\nBig data\nThis book proudly and primarily focuses on small, in-memory datasets.\n本书主要且自豪地专注于内存中的小型数据集。\nThis is the right place to start because you can’t tackle big data unless you have experience with small data.\n这是一个正确的起点，因为如果你没有处理小数据的经验，你就无法处理大数据。\nThe tools you’ll learn throughout the majority of this book will easily handle hundreds of megabytes of data, and with a bit of care, you can typically use them to work with a few gigabytes of data.\n你在本书大部分内容中学到的工具可以轻松处理数百兆字节的数据，如果稍加注意，你通常可以使用它们来处理几千兆字节的数据。\nWe’ll also show you how to get data out of databases and parquet files, both of which are often used to store big data.\n我们还将向你展示如何从数据库和 parquet 文件中获取数据，这两种文件都常用于存储大数据。\nYou won’t necessarily be able to work with the entire dataset, but that’s not a problem because you only need a subset or subsample to answer the question that you’re interested in.\n你不一定能处理整个数据集，但这不成问题，因为你只需要一个子集或子样本来回答你感兴趣的问题。\nIf you’re routinely working with larger data (10–100 GB, say), we recommend learning more about data.table.\n如果你经常处理更大的数据（比如 10-100 GB），我们建议你学习更多关于 data.table 的知识。\nWe don’t teach it here because it uses a different interface than the tidyverse and requires you to learn some different conventions.\n我们在这里不教它，因为它使用了与 tidyverse 不同的接口，并且需要你学习一些不同的约定。\nHowever, it is incredibly faster, and the performance payoff is worth investing some time in learning it if you’re working with large data.\n然而，它的速度非常快，如果你处理大数据，那么花时间学习它所带来的性能提升是值得的。\nPython, Julia, and friends\nIn this book, you won’t learn anything about Python, Julia, or any other programming language useful for data science.\n在本书中，你不会学到任何关于 Python、Julia 或任何其他可用于数据科学的编程语言的知识。\nThis isn’t because we think these tools are bad.\n这并不是因为我们认为这些工具不好。\nThey’re not!\n它们不是！\nAnd in practice, most data science teams use a mix of languages, often at least R and Python.\n在实践中，大多数数据科学团队会混合使用多种语言，通常至少包括 R 和 Python。\nBut we strongly believe that it’s best to master one tool at a time, and R is a great place to start.\n但我们坚信，一次掌握一个工具是最好的，而 R 是一个很好的起点。",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "Introduction",
    "section": "Prerequisites",
    "text": "Prerequisites\nWe’ve made a few assumptions about what you already know to get the most out of this book.\n为了让你能从本书中获得最大收益，我们对你已有的知识做了一些假设。\nYou should be generally numerically literate, and it’s helpful if you have some basic programming experience already.\n你应该具备基本的数字素养，如果已经有一些基础的编程经验会更有帮助。\nIf you’ve never programmed before, you might find Hands on Programming with R by Garrett to be a valuable adjunct to this book.\n如果你以前从未编程过，你可能会发现 Garrett 编写的 《Hands on Programming with R》 是本书的一个有价值的补充。\nYou need four things to run the code in this book: R, RStudio, a collection of R packages called the tidyverse, and a handful of other packages.\n你需要四样东西来运行本书中的代码：R、RStudio、一个名为 tidyverse 的 R 包集合，以及一些其他包。\nPackages are the fundamental units of reproducible R code.\n包 (Packages) 是可重现 R 代码的基本单位。\nThey include reusable functions, documentation that describes how to use them, and sample data.\n它们包括可重用的函数、描述如何使用它们的文档以及示例数据。\nR\nTo download R, go to CRAN, the comprehensive R archive network, https://cloud.r-project.org.\n要下载 R，请访问 CRAN (the comprehensive R archive network)，网址为 https://cloud.r-project.org。\nA new major version of R comes out once a year, and there are 2-3 minor releases each year.\nR 每年发布一个新的主版本，并且每年有 2-3 个次要版本发布。\nIt’s a good idea to update regularly.\n定期更新是个好主意。\nUpgrading can be a bit of a hassle, especially for major versions that require you to re-install all your packages, but putting it off only makes it worse.\n升级可能有点麻烦，特别是对于需要重新安装所有包的主版本，但拖延只会让情况变得更糟。\nWe recommend R 4.2.0 or later for this book.\n本书推荐使用 R 4.2.0 或更高版本。\nRStudio\nRStudio is an integrated development environment, or IDE, for R programming, which you can download from https://posit.co/download/rstudio-desktop/.\nRStudio 是一个用于 R 编程的集成开发环境 (IDE)，你可以从 https://posit.co/download/rstudio-desktop/ 下载。\nRStudio is updated a couple of times a year, and it will automatically let you know when a new version is out, so there’s no need to check back.\nRStudio 每年更新几次，当新版本发布时它会自动通知你，所以无需反复检查。\nIt’s a good idea to upgrade regularly to take advantage of the latest and greatest features.\n定期升级以利用最新最好的功能是个好主意。\nFor this book, make sure you have at least RStudio 2022.02.0.\n对于本书，请确保你至少拥有 RStudio 2022.02.0 版本。\nWhen you start RStudio, Figure 2, you’ll see two key regions in the interface: the console pane and the output pane.\n当你启动 RStudio 时，如 Figure 2 所示，你会在界面中看到两个关键区域：控制台窗格 (console pane) 和输出窗格 (output pane)。\nFor now, all you need to know is that you type the R code in the console pane and press enter to run it.\n目前，你只需要知道在控制台窗格中输入 R 代码并按 Enter 键来运行它。\nYou’ll learn more as we go along!1\n随着学习的深入，你会学到更多！2\n\n\n\n\n\n\n\nFigure 2: The RStudio IDE has two key regions: type R code in the console pane on the left, and look for plots in the output pane on the right.\n\n\n\n\nThe tidyverse\nYou’ll also need to install some R packages.\n你还需要安装一些 R 包。\nAn R package is a collection of functions, data, and documentation that extends the capabilities of base R.\nR 包 (package) 是一个函数、数据和文档的集合，它扩展了基础 R 的功能。\nUsing packages is key to the successful use of R.\n使用包是成功使用 R 的关键。\nThe majority of the packages that you will learn in this book are part of the so-called tidyverse.\n你在本书中将学到的大部分包都属于所谓的 tidyverse。\nAll packages in the tidyverse share a common philosophy of data and R programming and are designed to work together.\ntidyverse 中的所有包都共享一种通用的数据和 R 编程理念，并且被设计为可以协同工作。\nYou can install the complete tidyverse with a single line of code:\n你可以用一行代码安装完整的 tidyverse：\n\ninstall.packages(\"tidyverse\")\n\nOn your computer, type that line of code in the console, and then press enter to run it.\n在你的计算机上，在控制台中输入那行代码，然后按 Enter 键运行它。\nR will download the packages from CRAN and install them on your computer.\nR 将从 CRAN 下载这些包并安装到你的计算机上。\nYou will not be able to use the functions, objects, or help files in a package until you load it with library().\n在使用 library() 加载包之前，你将无法使用其中的函数、对象或帮助文件。\nOnce you have installed a package, you can load it using the library() function:\n安装包后，你可以使用 library() 函数加载它：\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n#&gt; ✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.0.4     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nThis tells you that tidyverse loads nine packages: dplyr, forcats, ggplot2, lubridate, purrr, readr, stringr, tibble, tidyr.\n这会告诉你 tidyverse 加载了九个包：dplyr、forcats、ggplot2、lubridate、purrr、readr、stringr、tibble、tidyr。\nThese are considered the core of the tidyverse because you’ll use them in almost every analysis.\n这些被认为是 tidyverse 的 核心，因为你几乎在每次分析中都会使用它们。\nPackages in the tidyverse change fairly frequently.\ntidyverse 中的包变化相当频繁。\nYou can see if updates are available by running tidyverse_update().\n你可以运行 tidyverse_update() 来查看是否有可用的更新。\nOther packages\nThere are many other excellent packages that are not part of the tidyverse because they solve problems in a different domain or are designed with a different set of underlying principles.\n还有许多其他优秀的包不属于 tidyverse，因为它们解决的是不同领域的问题，或者遵循一套不同的基本原则进行设计。\nThis doesn’t make them better or worse; it just makes them different.\n这并不是说它们更好或更差，只是它们不同。\nIn other words, the complement to the tidyverse is not the messyverse but many other universes of interrelated packages.\n换句话说，与 tidyverse 互补的不是 messyverse（混乱宇宙），而是许多其他相互关联的包的宇宙。\nAs you tackle more data science projects with R, you’ll learn new packages and new ways of thinking about data.\n随着你用 R 解决更多的数据科学项目，你将学习新的包和新的数据思维方式。\nWe’ll use many packages from outside the tidyverse in this book. 本书中我们将使用许多来自 tidyverse 之外的包。\nFor example, we’ll use the following packages because they provide interesting datasets for us to work with in the process of learning R:\n例如，我们将使用以下包，因为它们在我们学习 R 的过程中提供了有趣的数据集供我们使用：\n\ninstall.packages(\n  c(\"arrow\", \"babynames\", \"curl\", \"duckdb\", \"gapminder\", \n    \"ggrepel\", \"ggridges\", \"ggthemes\", \"hexbin\", \"janitor\", \"Lahman\", \n    \"leaflet\", \"maps\", \"nycflights13\", \"openxlsx\", \"palmerpenguins\", \n    \"repurrrsive\", \"tidymodels\", \"writexl\")\n  )\n\nWe’ll also use a selection of other packages for one off examples.\n我们还将为一些一次性的例子使用一些其他的包。\nYou don’t need to install them now, just remember that whenever you see an error like this:\n你现在不需要安装它们，只需记住，当你看到如下错误时：\n\nlibrary(ggrepel)\n#&gt; Error in library(ggrepel) : there is no package called ‘ggrepel’\n\nYou need to run install.packages(\"ggrepel\") to install the package.\n你需要运行 install.packages(\"ggrepel\") 来安装该包。",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#running-r-code",
    "href": "intro.html#running-r-code",
    "title": "Introduction",
    "section": "Running R code",
    "text": "Running R code\nThe previous section showed you several examples of running R code.\n上一节向你展示了几个运行 R 代码的例子。\nThe code in the book looks like this:\n书中的代码看起来是这样的：\n\n1 + 2\n#&gt; [1] 3\n\nIf you run the same code in your local console, it will look like this:\n如果你在本地控制台中运行相同的代码，它会看起来像这样：\n          &gt; 1 + 2 [1] 3\nThere are two main differences.\n这里有两个主要区别。\nIn your console, you type after the &gt;, called the prompt; we don’t show the prompt in the book.\n在你的控制台中，你在 &gt;（称为 提示符 (prompt)）后面输入；我们在书中不显示提示符。\nIn the book, the output is commented out with #&gt;; in your console, it appears directly after your code.\n在书中，输出用 #&gt; 注释掉；在你的控制台中，它直接出现在你的代码之后。\nThese two differences mean that if you’re working with an electronic version of the book, you can easily copy code out of the book and paste it into the console.\n这两个区别意味着，如果你使用的是本书的电子版，你可以轻松地从书中复制代码并粘贴到控制台中。\nThroughout the book, we use a consistent set of conventions to refer to code:\n在整本书中，我们使用一套一致的约定来引用代码：\n-   Functions are displayed in a code font and followed by parentheses, like sum() or mean().\n-   函数以代码字体显示，并后跟括号，如 sum() 或 mean()。\n-   Other R objects (such as data or function arguments) are in a code font, without parentheses, like flights or x.\n-   其他 R 对象（例如数据或函数参数）使用代码字体，不带括号，如 flights 或 x。\n-   Sometimes, to make it clear which package an object comes from, we’ll use the package name followed by two colons, like dplyr::mutate() or nycflights13::flights.     This is also valid R code.\n-   有时，为了明确一个对象来自哪个包，我们会使用包名后跟两个冒号的形式，如 dplyr::mutate() 或 nycflights13::flights。这也是有效的 R 代码。",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#acknowledgments",
    "href": "intro.html#acknowledgments",
    "title": "Introduction",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis book isn’t just the product of Hadley, Mine, and Garrett but is the result of many conversations (in person and online) that we’ve had with many people in the R community.\n本书不仅仅是 Hadley、Mine 和 Garrett 的成果，也是我们与 R 社区中许多人进行多次（面对面和在线）对话的结果。\nWe’re incredibly grateful for all the conversations we’ve had with y’all; thank you so much!\n我们非常感谢与大家进行的所有对话；非常感谢你们！\nThis book was written in the open, and many people contributed via pull requests. A special thanks to all 259 of you who contributed improvements via GitHub pull requests (in alphabetical order by username): 本书是公开写成的，许多人通过拉取请求 (pull requests) 做出了贡献。特别感谢所有通过 GitHub 拉取请求（按用户名首字母排序）为本书做出改进的 259 位贡献者：@a-rosenberg, Tim Becker (@a2800276), Abinash Satapathy (@Abinashbunty), Adam Gruer (@adam-gruer), adi pradhan (@adidoit), A. s. (@Adrianzo), Aep Hidyatuloh (@aephidayatuloh), Andrea Gilardi (@agila5), Ajay Deonarine (@ajay-d), @AlanFeder, Daihe Sui (@alansuidaihe), @alberto-agudo, @AlbertRapp, @aleloi, pete (@alonzi), Alex (@ALShum), Andrew M. (@amacfarland), Andrew Landgraf (@andland), @andyhuynh92, Angela Li (@angela-li), Antti Rask (@AnttiRask), LOU Xun (@aquarhead), @ariespirgel, @august-18, Michael Henry (@aviast), Azza Ahmed (@azzaea), Steven Moran (@bambooforest), Brian G. Barkley (@BarkleyBG), Mara Averick (@batpigandme), Oluwafemi OYEDELE (@BB1464), Brent Brewington (@bbrewington), Bill Behrman (@behrman), Ben Herbertson (@benherbertson), Ben Marwick (@benmarwick), Ben Steinberg (@bensteinberg), Benjamin Yeh (@bentyeh), Betul Turkoglu (@betulturkoglu), Brandon Greenwell (@bgreenwell), Bianca Peterson (@BinxiePeterson), Birger Niklas (@BirgerNi), Brett Klamer (@bklamer), @boardtc, Christian (@c-hoh), Caddy (@caddycarine), Camille V Leonard (@camillevleonard), @canovasjm, Cedric Batailler (@cedricbatailler), Christina Wei (@christina-wei), Christian Mongeau (@chrMongeau), Cooper Morris (@coopermor), Colin Gillespie (@csgillespie), Rademeyer Vermaak (@csrvermaak), Chloe Thierstein (@cthierst), Chris Saunders (@ctsa), Abhinav Singh (@curious-abhinav), Curtis Alexander (@curtisalexander), Christian G. Warden (@cwarden), Charlotte Wickham (@cwickham), Kenny Darrell (@darrkj), David Kane (@davidkane9), David (@davidrsch), David Rubinger (@davidrubinger), David Clark (@DDClark), Derwin McGeary (@derwinmcgeary), Daniel Gromer (@dgromer), @Divider85, @djbirke, Danielle Navarro (@djnavarro), Russell Shean (@DOH-RPS1303), Zhuoer Dong (@dongzhuoer), Devin Pastoor (@dpastoor), @DSGeoff, Devarshi Thakkar (@dthakkar09), Julian During (@duju211), Dylan Cashman (@dylancashman), Dirk Eddelbuettel (@eddelbuettel), Edwin Thoen (@EdwinTh), Ahmed El-Gabbas (@elgabbas), Henry Webel (@enryH), Ercan Karadas (@ercan7), Eric Kitaif (@EricKit), Eric Watt (@ericwatt), Erik Erhardt (@erikerhardt), Etienne B. Racine (@etiennebr), Everett Robinson (@evjrob), @fellennert, Flemming Miguel (@flemmingmiguel), Floris Vanderhaeghe (@florisvdh), @funkybluehen, @gabrivera, Garrick Aden-Buie (@gadenbuie), Peter Ganong (@ganong123), Gerome Meyer (@GeroVanMi), Gleb Ebert (@gl-eb), Josh Goldberg (@GoldbergData), bahadir cankardes (@gridgrad), Gustav W Delius (@gustavdelius), Hao Chen (@hao-trivago), Harris McGehee (@harrismcgehee), @hendrikweisser, Hengni Cai (@hengnicai), Iain (@Iain-S), Ian Sealy (@iansealy), Ian Lyttle (@ijlyttle), Ivan Krukov (@ivan-krukov), Jacob Kaplan (@jacobkap), Jazz Weisman (@jazzlw), John Blischak (@jdblischak), John D. Storey (@jdstorey), Gregory Jefferis (@jefferis), Jeffrey Stevens (@JeffreyRStevens), 蒋雨蒙 (@JeldorPKU), Jennifer (Jenny) Bryan (@jennybc), Jen Ren (@jenren), Jeroen Janssens (@jeroenjanssens), @jeromecholewa, Janet Wesner (@jilmun), Jim Hester (@jimhester), JJ Chen (@jjchern), Jacek Kolacz (@jkolacz), Joanne Jang (@joannejang), @johannes4998, John Sears (@johnsears), @jonathanflint, Jon Calder (@jonmcalder), Jonathan Page (@jonpage), Jon Harmon (@jonthegeek), JooYoung Seo (@jooyoungseo), Justinas Petuchovas (@jpetuchovas), Jordan (@jrdnbradford), Jeffrey Arnold (@jrnold), Jose Roberto Ayala Solares (@jroberayalas), Joyce Robbins (@jtr13), @juandering, Julia Stewart Lowndes (@jules32), Sonja (@kaetschap), Kara Woo (@karawoo), Katrin Leinweber (@katrinleinweber), Karandeep Singh (@kdpsingh), Kevin Perese (@kevinxperese), Kevin Ferris (@kferris10), Kirill Sevastyanenko (@kirillseva), Jonathan Kitt (@KittJonathan), @koalabearski, Kirill Müller (@krlmlr), Rafał Kucharski (@kucharsky), Kevin Wright (@kwstat), Noah Landesberg (@landesbergn), Lawrence Wu (@lawwu), @lindbrook, Luke W Johnston (@lwjohnst86), Kara de la Marck (@MarckK), Kunal Marwaha (@marwahaha), Matan Hakim (@matanhakim), Matthias Liew (@MatthiasLiew), Matt Wittbrodt (@MattWittbrodt), Mauro Lepore (@maurolepore), Mark Beveridge (@mbeveridge), @mcewenkhundi, mcsnowface, PhD (@mcsnowface), Matt Herman (@mfherman), Michael Boerman (@michaelboerman), Mitsuo Shiota (@mitsuoxv), Matthew Hendrickson (@mjhendrickson), @MJMarshall, Misty Knight-Finley (@mkfin7), Mohammed Hamdy (@mmhamdy), Maxim Nazarov (@mnazarov), Maria Paula Caldas (@mpaulacaldas), Mustafa Ascha (@mustafaascha), Nelson Areal (@nareal), Nate Olson (@nate-d-olson), Nathanael (@nateaff), @nattalides, Ned Western (@NedJWestern), Nick Clark (@nickclark1000), @nickelas, Nirmal Patel (@nirmalpatel), Nischal Shrestha (@nischalshrestha), Nicholas Tierney (@njtierney), Jakub Nowosad (@Nowosad), Nick Pullen (@nstjhp), @olivier6088, Olivier Cailloux (@oliviercailloux), Robin Penfold (@p0bs), Pablo E. Garcia (@pabloedug), Paul Adamson (@padamson), Penelope Y (@penelopeysm), Peter Hurford (@peterhurford), Peter Baumgartner (@petzi53), Patrick Kennedy (@pkq), Pooya Taherkhani (@pooyataher), Y. Yu (@PursuitOfDataScience), Radu Grosu (@radugrosu), Ranae Dietzel (@Ranae), Ralph Straumann (@rastrau), Rayna M Harris (@raynamharris), @ReeceGoding, Robin Gertenbach (@rgertenbach), Jajo (@RIngyao), Riva Quiroga (@rivaquiroga), Richard Knight (@RJHKnight), Richard Zijdeman (@rlzijdeman), @robertchu03, Robin Kohrs (@RobinKohrs), Robin (@Robinlovelace), Emily Robinson (@robinsones), Rob Tenorio (@robtenorio), Rod Mazloomi (@RodAli), Rohan Alexander (@RohanAlexander), Romero Morais (@RomeroBarata), Albert Y. Kim (@rudeboybert), Saghir (@saghirb), Hojjat Salmasian (@salmasian), Jonas (@sauercrowd), Vebash Naidoo (@sciencificity), Seamus McKinsey (@seamus-mckinsey), @seanpwilliams, Luke Smith (@seasmith), Matthew Sedaghatfar (@sedaghatfar), Sebastian Kraus (@sekR4), Sam Firke (@sfirke), Shannon Ellis (@ShanEllis), @shoili, Christian Heinrich (@Shurakai), S’busiso Mkhondwane (@sibusiso16), SM Raiyyan (@sm-raiyyan), Jakob Krigovsky (@sonicdoe), Stephan Koenig (@stephan-koenig), Stephen Balogun (@stephenbalogun), Steven M. Mortimer (@StevenMMortimer), Stéphane Guillou (@stragu), Sulgi Kim (@sulgik), Sergiusz Bleja (@svenski), Tal Galili (@talgalili), Alec Fisher (@Taurenamo), Todd Gerarden (@tgerarden), Tom Godfrey (@thomasggodfrey), Tim Broderick (@timbroderick), Tim Waterhouse (@timwaterhouse), TJ Mahr (@tjmahr), Thomas Klebel (@tklebel), Tom Prior (@tomjamesprior), Terence Teo (@tteo), @twgardner2, Ulrik Lyngs (@ulyngs), Shinya Uryu (@uribo), Martin Van der Linden (@vanderlindenma), Walter Somerville (@waltersom), @werkstattcodes, Will Beasley (@wibeasley), Yihui Xie (@yihui), Yiming (Paul) Li (@yimingli), @yingxingwu, Hiroaki Yutani (@yutannihilation), Yu Yu Aung (@yuyu-aung), Zach Bogart (@zachbogart), @zeal626, Zeki Akyol (@zekiakyol).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#colophon",
    "href": "intro.html#colophon",
    "title": "Introduction",
    "section": "Colophon",
    "text": "Colophon\nAn online version of this book is available at https://r4ds.hadley.nz.\n本书的在线版本可在 https://r4ds.hadley.nz 查看。\nIt will continue to evolve in between reprints of the physical book.\n在实体书再版之间，它将继续发展。\nThe source of the book is available at https://github.com/hadley/r4ds.\n本书的源代码可在 https://github.com/hadley/r4ds 找到。\nThe book is powered by Quarto, which makes it easy to write books that combine text and executable code.\n本书由 Quarto 提供支持，它使得编写结合文本和可执行代码的书籍变得容易。",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "Introduction",
    "section": "",
    "text": "If you’d like a comprehensive overview of all of RStudio’s features, see the RStudio User Guide at https://docs.posit.co/ide/user.↩︎\nIf you’d like a comprehensive overview of all of RStudio’s features, see the RStudio User Guide at https://docs.posit.co/ide/user.↩︎",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "whole-game.html",
    "href": "whole-game.html",
    "title": "Whole game",
    "section": "",
    "text": "Our goal in this part of the book is to give you a rapid overview of the main tools of data science: importing, tidying, transforming, and visualizing data, as shown in Figure 1. We want to show you the “whole game” of data science giving you just enough of all the major pieces so that you can tackle real, if simple, datasets. The later parts of the book will hit each of these topics in more depth, increasing the range of data science challenges that you can tackle.\n本书这部分的目标是快速概述数据科学的主要工具：导入 (importing)、整理 (tidying)、转换 (transforming) 和可视化数据 (visualizing data)，如 Figure 1 所示。我们希望向你展示数据科学的“全貌” (whole game)，为你提供所有主要部分的足够知识，以便你可以处理真实的（尽管是简单的）数据集。本书的后续部分将更深入地探讨这些主题，增加你可以应对的数据科学挑战的范围。\n\n\n\n\n\n\n\nFigure 1: In this section of the book, you’ll learn how to import, tidy, transform, and visualize data.\n\n\n\n\nFour chapters focus on the tools of data science:\n有四章内容重点介绍数据科学的工具：\n-   Visualization is a great place to start with R programming, because the payoff is so clear: you get to make elegant and informative plots that help you understand data.     In 1  Data visualization you’ll dive into visualization, learning the basic structure of a ggplot2 plot, and powerful techniques for turning data into plots.\n\n可视化是开始 R 编程的绝佳起点，因为回报非常明确：你可以制作出优雅且信息丰富的图表，帮助你理解数据。在 1  Data visualization 中，你将深入学习可视化，了解 ggplot2 图的基本结构以及将数据转化为图表的强大技术。\n\n-   Visualization alone is typically not enough, so in 3  数据转换, you’ll learn the key verbs that allow you to select important variables, filter out key observations, create new variables, and compute summaries.\n\n通常仅有可视化是不够的，因此在 3  数据转换 中，你将学习一些关键的“动词” (verbs)，它们能让你选择重要的变量、筛选出关键的观测值、创建新变量以及计算摘要。\n\n-   In 5  数据整理, you’ll learn about tidy data, a consistent way of storing your data that makes transformation, visualization, and modelling easier.     You’ll learn the underlying principles, and how to get your data into a tidy form.\n\n在 5  数据整理 中，你将学习整洁数据 (tidy data)，这是一种一致的数据存储方式，可以使转换、可视化和建模变得更加容易。你将学习其基本原则，以及如何将你的数据整理成整洁的形式。\n\n-   Before you can transform and visualize your data, you need to first get your data into R.     In 7  数据导入 you’ll learn the basics of getting .csv files into R.\n\n在转换和可视化数据之前，你首先需要将数据导入 R。在 7  数据导入 中，你将学习将 .csv 文件导入 R 的基础知识。\n\nNestled among these chapters are four other chapters that focus on your R workflow. In 2  Workflow: basics, 4  工作流：代码风格, and 6  工作流：脚本和项目 you’ll learn good workflow practices for writing and organizing your R code. These will set you up for success in the long run, as they’ll give you the tools to stay organized when you tackle real projects. Finally, 8  工作流：获取帮助 will teach you how to get help and keep learning.\n在这些章节之间，还有另外四章专注于你的 R 工作流程 (workflow)。在 2  Workflow: basics、4  工作流：代码风格 和 6  工作流：脚本和项目 中，你将学习编写和组织 R 代码的良好工作流程实践。从长远来看，这些将为你奠定成功的基础，因为它们为你提供了在处理实际项目时保持条理的工具。最后，8  工作流：获取帮助 将教你如何获取帮助并持续学习。",
    "crumbs": [
      "Whole game"
    ]
  },
  {
    "objectID": "data-visualize.html",
    "href": "data-visualize.html",
    "title": "1  Data visualization",
    "section": "",
    "text": "1.1 Introduction\nR has several systems for making graphs, but ggplot2 is one of the most elegant and most versatile. ggplot2 implements the grammar of graphics, a coherent system for describing and building graphs. With ggplot2, you can do more and faster by learning one system and applying it in many places.\nR 有多种制图系统，但 ggplot2 是其中最优雅、功能最丰富的系统之一。ggplot2 实现了图形语法 (grammar of graphics)，这是一个用于描述和构建图形的连贯系统。借助 ggplot2，你可以通过学习一个系统并将其应用于许多地方，从而更快地完成更多工作。\nThis chapter will teach you how to visualize your data using ggplot2. We will start by creating a simple scatterplot and use that to introduce aesthetic mappings and geometric objects – the fundamental building blocks of ggplot2. We will then walk you through visualizing distributions of single variables as well as visualizing relationships between two or more variables. We’ll finish off with saving your plots and troubleshooting tips.\n本章将教你如何使用 ggplot2 可视化数据。我们将从创建一个简单的散点图开始，并用它来介绍美学映射 (aesthetic mappings) 和几何对象 (geometric objects)——ggplot2 的基本构建模块。然后，我们将引导你学习如何可视化单个变量的分布以及两个或多个变量之间的关系。最后，我们将介绍如何保存你的图表以及一些故障排除技巧。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#introduction",
    "href": "data-visualize.html#introduction",
    "title": "1  Data visualization",
    "section": "",
    "text": "“The simple graph has brought more information to the data analyst’s mind than any other device.” — John Tukey\n\n\n“简单的图形为数据分析师带来的信息比任何其他设备都多。” — John Tukey\n\n\n\n\n\n\n1.1.1 Prerequisites\nThis chapter focuses on ggplot2, one of the core packages in the tidyverse. To access the datasets, help pages, and functions used in this chapter, load the tidyverse by running:\n本章重点介绍 ggplot2，它是 tidyverse 中的核心包之一。要访问本章中使用的数据集、帮助页面和函数，请通过运行以下代码加载 tidyverse：\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n#&gt; ✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.0.4     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nThat one line of code loads the core tidyverse; the packages that you will use in almost every data analysis. It also tells you which functions from the tidyverse conflict with functions in base R (or from other packages you might have loaded)1.\n这一行代码会加载核心的 tidyverse；这些包几乎在每个数据分析中都会用到。它还会告诉你 tidyverse 中的哪些函数与 R 基础包（或你可能已加载的其他包）中的函数存在冲突2。\nIf you run this code and get the error message there is no package called 'tidyverse', you’ll need to first install it, then run library() once again.\n如果你运行此代码并收到错误消息 there is no package called 'tidyverse'，你需要先安装它，然后再运行一次 library()。\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nYou only need to install a package once, but you need to load it every time you start a new session.\n你只需要安装一个包一次，但每次开始新会话时都需要加载它。\nIn addition to tidyverse, we will also use the palmerpenguins package, which includes the penguins dataset containing body measurements for penguins on three islands in the Palmer Archipelago, and the ggthemes package, which offers a colorblind safe color palette.\n除了 tidyverse，我们还将使用 palmerpenguins 包，其中包含了 penguins 数据集，该数据集包含了帕默群岛 (Palmer Archipelago) 上三个岛屿的企鹅身体测量数据，以及 ggthemes 包，它提供了一个色盲安全的调色板。\n\nlibrary(palmerpenguins)\n#&gt; \n#&gt; Attaching package: 'palmerpenguins'\n#&gt; The following objects are masked from 'package:datasets':\n#&gt; \n#&gt;     penguins, penguins_raw\nlibrary(ggthemes)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#first-steps",
    "href": "data-visualize.html#first-steps",
    "title": "1  Data visualization",
    "section": "\n1.2 First steps",
    "text": "1.2 First steps\nDo penguins with longer flippers weigh more or less than penguins with shorter flippers? You probably already have an answer, but try to make your answer precise. What does the relationship between flipper length and body mass look like? Is it positive? Negative? Linear? Nonlinear? Does the relationship vary by the species of the penguin? How about by the island where the penguin lives? Let’s create visualizations that we can use to answer these questions.\n鳍状肢较长的企鹅比鳍状肢较短的企鹅重还是轻？你可能已经有了答案，但请尝试让你的答案更精确。鳍状肢长度和体重之间的关系是怎样的？是正相关？负相关？线性？还是非线性？这种关系是否因企鹅的种类而异？又是否因企鹅居住的岛屿而异？让我们创建一些可视化图表来回答这些问题。\n\n1.2.1 The penguins data frame\nYou can test your answers to those questions with the penguins data frame found in palmerpenguins (a.k.a. palmerpenguins::penguins). A data frame is a rectangular collection of variables (in the columns) and observations (in the rows). penguins contains 344 observations collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER3.\n你可以使用 palmerpenguins 包中的 penguins 数据框 (data frame)（也称为 palmerpenguins::penguins）来检验你对这些问题的答案。数据框是变量（在列中）和观测（在行中）的矩形集合。penguins 包含了 344 条观测数据，由 Kristen Gorman 博士和帕默站，南极 LTER 收集并提供4。\nTo make the discussion easier, let’s define some terms:\n为了让讨论更容易，我们先定义一些术语：\n\nA variable is a quantity, quality, or property that you can measure.\n变量 (variable) 是你可以测量的数量、质量或属性。\nA value is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.\n值 (value) 是你测量时变量的状态。一个变量的值可能在每次测量中都会改变。\nAn observation is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. We’ll sometimes refer to an observation as a data point.\n观测 (observation) 是在相似条件下进行的一组测量（通常你在同一时间对同一对象进行一次观测中的所有测量）。一个观测会包含多个值，每个值都与一个不同的变量相关联。我们有时也将一个观测称为一个数据点。\nTabular data is a set of values, each associated with a variable and an observation. Tabular data is tidy if each value is placed in its own “cell”, each variable in its own column, and each observation in its own row.\n表格数据 (tabular data) 是一组值，每个值都与一个变量和一个观测相关联。如果每个值都放在自己的“单元格”中，每个变量都在自己的列中，每个观测都在自己的行中，那么表格数据就是整洁 (tidy) 的。\n\nIn this context, a variable refers to an attribute of all the penguins, and an observation refers to all the attributes of a single penguin.\n在此背景下，一个变量指的是所有企鹅的一个属性，而一个观测指的是一只企鹅的所有属性。\nType the name of the data frame in the console and R will print a preview of its contents. Note that it says tibble on top of this preview. In the tidyverse, we use special data frames called tibbles that you will learn more about soon.\n在控制台中输入数据框的名称，R 将打印其内容的预览。注意，在这个预览的顶部显示着 tibble。在 tidyverse 中，我们使用一种特殊的数据框，称为 tibbles，你很快就会学到更多关于它的知识。\n\npenguins\n#&gt; # A tibble: 344 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 338 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt;\n\nThis data frame contains 8 columns. For an alternative view, where you can see all variables and the first few observations of each variable, use glimpse(). Or, if you’re in RStudio, run View(penguins) to open an interactive data viewer.\n该数据框包含 8 列。若要查看另一种视图，其中可以看到所有变量以及每个变量的前几个观测值，请使用 glimpse()。或者，如果你在 RStudio 中，运行 View(penguins) 来打开一个交互式数据查看器。\n\nglimpse(penguins)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, A…\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torge…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.…\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.…\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, …\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 347…\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, m…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2…\n\nAmong the variables in penguins are:\n在 penguins 的变量中，有：\n\nspecies: a penguin’s species (Adelie, Chinstrap, or Gentoo).\nspecies：企鹅的种类（阿德利、帽带或巴布亚）。\nflipper_length_mm: length of a penguin’s flipper, in millimeters.\nflipper_length_mm：企鹅鳍状肢的长度，单位为毫米。\nbody_mass_g: body mass of a penguin, in grams.\nbody_mass_g：企鹅的体重，单位为克。\n\nTo learn more about penguins, open its help page by running ?penguins.\n要了解更多关于 penguins 的信息，请运行 ?penguins 打开其帮助页面。\n\n1.2.2 Ultimate goal\nOur ultimate goal in this chapter is to recreate the following visualization displaying the relationship between flipper lengths and body masses of these penguins, taking into consideration the species of the penguin.\n我们在本章的最终目标是重现以下可视化图表，该图表展示了这些企鹅的鳍状肢长度和体重之间的关系，同时考虑了企鹅的种类。\n\n\n\n\n\n\n\n\n\n1.2.3 Creating a ggplot\nLet’s recreate this plot step-by-step.\n让我们一步一步地重现这个图表。\nWith ggplot2, you begin a plot with the function ggplot(), defining a plot object that you then add layers to. The first argument of ggplot() is the dataset to use in the graph and so ggplot(data = penguins) creates an empty graph that is primed to display the penguins data, but since we haven’t told it how to visualize it yet, for now it’s empty. This is not a very exciting plot, but you can think of it like an empty canvas you’ll paint the remaining layers of your plot onto.\n使用 ggplot2 时，你用 ggplot() 函数开始一个绘图，定义一个绘图对象，然后向其添加图层 (layers)。ggplot() 的第一个参数是要在图中使用的数据集，所以 ggplot(data = penguins) 创建了一个空的图表，准备好显示 penguins 数据，但由于我们还没有告诉它如何可视化，所以目前它是空的。这不是一个非常激动人心的图表，但你可以把它想象成一块空的画布，你将在上面绘制图表的其余图层。\n\nggplot(data = penguins)\n\n\n\n\n\n\n\nNext, we need to tell ggplot() how the information from our data will be visually represented. The mapping argument of the ggplot() function defines how variables in your dataset are mapped to visual properties (aesthetics) of your plot. The mapping argument is always defined in the aes() function, and the x and y arguments of aes() specify which variables to map to the x and y axes. For now, we will only map flipper length to the x aesthetic and body mass to the y aesthetic. ggplot2 looks for the mapped variables in the data argument, in this case, penguins.\n接下来，我们需要告诉 ggplot() 如何将我们数据中的信息进行可视化表示。ggplot() 函数的 mapping 参数定义了数据集中的变量如何映射到图表的视觉属性（美学 (aesthetics)）。mapping 参数总是在 aes() 函数中定义，aes() 的 x 和 y 参数指定了将哪些变量映射到 x 轴和 y 轴。现在，我们只将鳍状肢长度映射到 x 美学，将体重映射到 y 美学。ggplot2 会在 data 参数中查找映射的变量，在这里是 penguins。\nThe following plot shows the result of adding these mappings.\n下面的图表显示了添加这些映射的结果。\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n)\n\n\n\n\n\n\n\nOur empty canvas now has more structure – it’s clear where flipper lengths will be displayed (on the x-axis) and where body masses will be displayed (on the y-axis). But the penguins themselves are not yet on the plot. This is because we have not yet articulated, in our code, how to represent the observations from our data frame on our plot.\n我们空荡荡的画布现在有了更多的结构——很清楚鳍状肢长度将显示在哪里（x 轴上），体重将显示在哪里（y 轴上）。但是企鹅本身还没有在图上。这是因为我们还没有在代码中明确说明如何在图上表示我们数据框中的观测值。\nTo do so, we need to define a geom: the geometrical object that a plot uses to represent data. These geometric objects are made available in ggplot2 with functions that start with geom_. People often describe plots by the type of geom that the plot uses. For example, bar charts use bar geoms (geom_bar()), line charts use line geoms (geom_line()), boxplots use boxplot geoms (geom_boxplot()), scatterplots use point geoms (geom_point()), and so on.\n为此，我们需要定义一个 geom：图表用来表示数据的几何对象。这些几何对象在 ggplot2 中通过以 geom_ 开头的函数提供。人们通常用图表使用的 geom 类型来描述图表。例如，条形图使用条形 geom (geom_bar())，折线图使用折线 geom (geom_line())，箱线图使用箱线图 geom (geom_boxplot())，散点图使用点 geom (geom_point()) 等等。\nThe function geom_point() adds a layer of points to your plot, which creates a scatterplot. ggplot2 comes with many geom functions that each adds a different type of layer to a plot. You’ll learn a whole bunch of geoms throughout the book, particularly in Chapter 9.\ngeom_point() 函数会为你的图表添加一个点图层，从而创建一个散点图。ggplot2 提供了许多 geom 函数，每个函数都为图表添加不同类型的图层。你将在本书中，特别是在 Chapter 9 中学到很多 geom。\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\nNow we have something that looks like what we might think of as a “scatterplot”. It doesn’t yet match our “ultimate goal” plot, but using this plot we can start answering the question that motivated our exploration: “What does the relationship between flipper length and body mass look like?” The relationship appears to be positive (as flipper length increases, so does body mass), fairly linear (the points are clustered around a line instead of a curve), and moderately strong (there isn’t too much scatter around such a line). Penguins with longer flippers are generally larger in terms of their body mass.\n现在我们有了一个可以称之为“散点图”的东西。它还不完全符合我们的“最终目标”图，但通过这个图，我们可以开始回答我们探索的动机问题：“鳍状肢长度和体重之间的关系是怎样的？” 这种关系看起来是正相关的（随着鳍状肢长度的增加，体重也增加），相当线性的（数据点聚集在一条直线周围而不是一条曲线上），并且强度适中（围绕这条线的散布不是很大）。鳍状肢较长的企鹅通常体重也较重。\nBefore we add more layers to this plot, let’s pause for a moment and review the warning message we got:\n在我们为这张图添加更多图层之前，让我们暂停一下，回顾一下我们收到的警告信息：\n\nRemoved 2 rows containing missing values (geom_point()).\n\n\n删除了 2 行包含缺失值的行 (geom_point()).\n\nWe’re seeing this message because there are two penguins in our dataset with missing body mass and/or flipper length values and ggplot2 has no way of representing them on the plot without both of these values. Like R, ggplot2 subscribes to the philosophy that missing values should never silently go missing. This type of warning is probably one of the most common types of warnings you will see when working with real data – missing values are a very common issue and you’ll learn more about them throughout the book, particularly in Chapter 18. For the remaining plots in this chapter we will suppress this warning so it’s not printed alongside every single plot we make.\n我们看到这个消息是因为我们的数据集中有两只企鹅缺少体重和/或鳍状肢长度的值，而 ggplot2 在没有这两个值的情况下无法在图上表示它们。和 R 一样，ggplot2 遵循的哲学是缺失值不应该被悄悄地忽略。这种类型的警告可能是你在处理真实数据时会看到的最常见的警告之一——缺失值是一个非常普遍的问题，你将在本书中，特别是在 Chapter 18 中学到更多关于它们的内容。在本章余下的图表中，我们将抑制这个警告，这样它就不会在我们制作的每一张图表旁边都打印出来。\n\n1.2.4 Adding aesthetics and layers\nScatterplots are useful for displaying the relationship between two numerical variables, but it’s always a good idea to be skeptical of any apparent relationship between two variables and ask if there may be other variables that explain or change the nature of this apparent relationship. For example, does the relationship between flipper length and body mass differ by species? Let’s incorporate species into our plot and see if this reveals any additional insights into the apparent relationship between these variables. We will do this by representing species with different colored points.\n散点图对于显示两个数值变量之间的关系非常有用，但对两个变量之间的任何明显关系持怀疑态度总是一个好主意，并询问是否可能有其他变量解释或改变了这种明显关系的性质。例如，鳍状肢长度和体重之间的关系是否因物种而异？让我们将物种纳入我们的图表中，看看这是否会揭示出这些变量之间明显关系的任何其他见解。我们将通过用不同颜色的点来代表物种来做到这一点。\nTo achieve this, will we need to modify the aesthetic or the geom? If you guessed “in the aesthetic mapping, inside of aes()”, you’re already getting the hang of creating data visualizations with ggplot2! And if not, don’t worry. Throughout the book you will make many more ggplots and have many more opportunities to check your intuition as you make them.\n要实现这一点，我们需要修改美学还是几何对象？如果你猜到“在 aes() 内部的美学映射中”，那么你已经开始掌握用 ggplot2 创建数据可视化的窍门了！如果没猜对，也别担心。在本书中，你将制作更多的 ggplot 图，并有更多机会在制作过程中检验你的直觉。\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point()\n\n\n\n\n\n\n\nWhen a categorical variable is mapped to an aesthetic, ggplot2 will automatically assign a unique value of the aesthetic (here a unique color) to each unique level of the variable (each of the three species), a process known as scaling. ggplot2 will also add a legend that explains which values correspond to which levels.\n当一个分类变量被映射到一个美学上时，ggplot2 会自动为该变量的每个唯一级别（这里是三个物种中的每一个）分配一个唯一的美学值（这里是唯一的颜色），这个过程被称为标度变换 (scaling)。ggplot2 还会添加一个图例，解释哪些值对应哪些级别。\nNow let’s add one more layer: a smooth curve displaying the relationship between body mass and flipper length. Before you proceed, refer back to the code above, and think about how we can add this to our existing plot.\n现在让我们再添加一个图层：一条平滑曲线，显示体重和鳍状肢长度之间的关系。在继续之前，请回顾上面的代码，并思考如何将其添加到我们现有的图表中。\nSince this is a new geometric object representing our data, we will add a new geom as a layer on top of our point geom: geom_smooth(). And we will specify that we want to draw the line of best fit based on a linear model with method = \"lm\".\n由于这是一个代表我们数据的新几何对象，我们将在点几何对象之上添加一个新的几何对象作为图层：geom_smooth()。并且我们将指定我们想要基于 linear model（线性模型）绘制最佳拟合线，通过 method = \"lm\"。\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nWe have successfully added lines, but this plot doesn’t look like the plot from Section 1.2.2, which only has one line for the entire dataset as opposed to separate lines for each of the penguin species.\n我们成功地添加了线，但这张图看起来不像 Section 1.2.2 中的图，那张图只有一条线代表整个数据集，而不是为每种企鹅分别画线。\nWhen aesthetic mappings are defined in ggplot(), at the global level, they’re passed down to each of the subsequent geom layers of the plot. However, each geom function in ggplot2 can also take a mapping argument, which allows for aesthetic mappings at the local level that are added to those inherited from the global level. Since we want points to be colored based on species but don’t want the lines to be separated out for them, we should specify color = species for geom_point() only.\n当美学映射在 ggplot() 中定义时，即在全局级别，它们会被传递给图的每个后续几何图层。然而，ggplot2 中的每个几何函数也可以接受一个 mapping 参数，这允许在局部级别进行美学映射，这些映射会添加到从全局级别继承的映射中。由于我们希望点根据物种着色，但又不希望线条也因此分开，我们应该只为 geom_point() 指定 color = species。\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nVoila! We have something that looks very much like our ultimate goal, though it’s not yet perfect. We still need to use different shapes for each species of penguins and improve labels.\n瞧！我们得到了一个与我们的最终目标非常相似的东西，虽然还不是完美的。我们仍然需要为每种企鹅使用不同的形状，并改进标签。\nIt’s generally not a good idea to represent information using only colors on a plot, as people perceive colors differently due to color blindness or other color vision differences. Therefore, in addition to color, we can also map species to the shape aesthetic.\n通常，在图表上仅使用颜色来表示信息并不是一个好主意，因为人们因色盲或其他色觉差异而对颜色的感知不同。因此，除了颜色，我们还可以将 species 映射到 shape 美学上。\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nNote that the legend is automatically updated to reflect the different shapes of the points as well.\n注意，图例也会自动更新，以反映点的不同形状。\nAnd finally, we can improve the labels of our plot using the labs() function in a new layer. Some of the arguments to labs() might be self explanatory: title adds a title and subtitle adds a subtitle to the plot. Other arguments match the aesthetic mappings, x is the x-axis label, y is the y-axis label, and color and shape define the label for the legend. In addition, we can improve the color palette to be colorblind safe with the scale_color_colorblind() function from the ggthemes package.\n最后，我们可以使用 labs() 函数在一个新的图层中改进我们图表的标签。labs() 的一些参数可能是不言自明的：title 为图表添加标题，subtitle 添加副标题。其他参数与美学映射相匹配，x 是 x 轴标签，y 是 y 轴标签，而 color 和 shape 定义了图例的标签。此外，我们可以使用 ggthemes 包中的 scale_color_colorblind() 函数来改进调色板，使其对色盲友好。\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Body mass and flipper length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Flipper length (mm)\", y = \"Body mass (g)\",\n    color = \"Species\", shape = \"Species\"\n  ) +\n  scale_color_colorblind()\n\n\n\n\n\n\n\nWe finally have a plot that perfectly matches our “ultimate goal”!\n我们终于有了一个与我们的“最终目标”完全匹配的图表！\n\n1.2.5 Exercises\n\nHow many rows are in penguins? How many columns?\npenguins 中有多少行？多少列？\nWhat does the bill_depth_mm variable in the penguins data frame describe? Read the help for ?penguins to find out.\npenguins 数据框中的 bill_depth_mm 变量描述了什么？阅读 ?penguins 的帮助文档来找出答案。\nMake a scatterplot of bill_depth_mm vs. bill_length_mm. That is, make a scatterplot with bill_depth_mm on the y-axis and bill_length_mm on the x-axis. Describe the relationship between these two variables.\n制作一个 bill_depth_mm 对 bill_length_mm 的散点图。也就是说，制作一个以 bill_depth_mm 为 y 轴，bill_length_mm 为 x 轴的散点图。描述这两个变量之间的关系。\nWhat happens if you make a scatterplot of species vs. bill_depth_mm? What might be a better choice of geom?\n如果你制作一个 species 对 bill_depth_mm 的散点图会发生什么？什么可能是更好的几何对象选择？\nWhy does the following give an error and how would you fix it?\n\n为什么下面的代码会报错，你将如何修复它？\n{r}     #| eval: false     ggplot(data = penguins) +        geom_point()\n\nWhat does the na.rm argument do in geom_point()? What is the default value of the argument? Create a scatterplot where you successfully use this argument set to TRUE.\ngeom_point() 中的 na.rm 参数有什么作用？该参数的默认值是什么？创建一个散点图，在其中成功地将此参数设置为 TRUE。\nAdd the following caption to the plot you made in the previous exercise: “Data come from the palmerpenguins package.” Hint: Take a look at the documentation for labs().\n在你上一个练习中制作的图表中添加以下标题：“数据来自 palmerpenguins 包。” 提示：查看 labs() 的文档。\nRecreate the following visualization. What aesthetic should bill_depth_mm be mapped to? And should it be mapped at the global level or at the geom level?\n\n重新创建以下可视化图表。bill_depth_mm 应该映射到哪个美学上？它应该在全局级别还是在几何对象级别进行映射？\n{r}     #| echo: false     #| warning: false     #| fig-alt: |     #|   A scatterplot of body mass vs. flipper length of penguins, colored      #|   by bill depth. A smooth curve of the relationship between body mass      #|   and flipper length is overlaid. The relationship is positive,      #|   fairly linear, and moderately strong.     ggplot(       data = penguins,       mapping = aes(x = flipper_length_mm, y = body_mass_g)     ) +       geom_point(aes(color = bill_depth_mm)) +       geom_smooth()\n\nRun this code in your head and predict what the output will look like. Then, run the code in R and check your predictions.\n\n在脑海中运行这段代码，并预测输出会是什么样子。然后，在 R 中运行代码并检查你的预测。\n{r}     #| eval: false     ggplot(       data = penguins,       mapping = aes(x = flipper_length_mm, y = body_mass_g, color = island)     ) +       geom_point() +       geom_smooth(se = FALSE)\n\nWill these two graphs look different? Why/why not?\n\n这两张图看起来会有所不同吗？为什么/为什么不？\n```{r} #| eval: false ggplot( data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g) ) + geom_point() + geom_smooth()\nggplot() + geom_point( data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g) ) + geom_smooth( data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g) ) ```",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggplot2-calls",
    "href": "data-visualize.html#sec-ggplot2-calls",
    "title": "1  Data visualization",
    "section": "\n1.3 ggplot2 calls",
    "text": "1.3 ggplot2 calls\nAs we move on from these introductory sections, we’ll transition to a more concise expression of ggplot2 code. So far we’ve been very explicit, which is helpful when you are learning:\n随着我们从这些介绍性部分过渡，我们将转向更简洁的 ggplot2 代码表达方式。到目前为止，我们一直非常明确，这在学习时很有帮助：\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n\nTypically, the first one or two arguments to a function are so important that you should know them by heart. The first two arguments to ggplot() are data and mapping, in the remainder of the book, we won’t supply those names. That saves typing, and, by reducing the amount of extra text, makes it easier to see what’s different between plots. That’s a really important programming concern that we’ll come back to in Chapter 25.\n通常，函数的前一两个参数非常重要，你应该牢记在心。ggplot() 的前两个参数是 data 和 mapping，在本书的其余部分，我们将不再提供这些名称。这样可以节省打字时间，并且通过减少额外的文本量，更容易看出图表之间的差异。这是一个非常重要的编程问题，我们将在 Chapter 25 中再次讨论。\nRewriting the previous plot more concisely yields:\n更简洁地重写之前的图表，得到：\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()\n\nIn the future, you’ll also learn about the pipe, |&gt;, which will allow you to create that plot with:\n将来，你还会学到管道符 |&gt;，它将允许你用以下方式创建该图表：\n\npenguins |&gt; \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#visualizing-distributions",
    "href": "data-visualize.html#visualizing-distributions",
    "title": "1  Data visualization",
    "section": "\n1.4 Visualizing distributions",
    "text": "1.4 Visualizing distributions\nHow you visualize the distribution of a variable depends on the type of variable: categorical or numerical.\n如何可视化一个变量的分布取决于该变量的类型：分类变量或数值变量。\n\n1.4.1 A categorical variable\nA variable is categorical if it can only take one of a small set of values. To examine the distribution of a categorical variable, you can use a bar chart. The height of the bars displays how many observations occurred with each x value.\n如果一个变量只能取一小组值中的一个，那么它就是分类 (categorical) 变量。要检查分类变量的分布，你可以使用条形图。条形的高度显示了每个 x 值出现了多少次观测。\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\n\n\n\nIn bar plots of categorical variables with non-ordered levels, like the penguin species above, it’s often preferable to reorder the bars based on their frequencies. Doing so requires transforming the variable to a factor (how R handles categorical data) and then reordering the levels of that factor.\n在具有无序级别的分类变量的条形图中，比如上面的企鹅 species，通常最好根据它们的频率重新排序条形。这样做需要将变量转换为因子（R 处理分类数据的方式），然后重新排序该因子的级别。\n\nggplot(penguins, aes(x = fct_infreq(species))) +\n  geom_bar()\n\n\n\n\n\n\n\nYou will learn more about factors and functions for dealing with factors (like fct_infreq() shown above) in Chapter 16.\n你将在 Chapter 16 中学习更多关于因子以及处理因子的函数（如上面展示的 fct_infreq()）的知识。\n\n1.4.2 A numerical variable\nA variable is numerical (or quantitative) if it can take on a wide range of numerical values, and it is sensible to add, subtract, or take averages with those values. Numerical variables can be continuous or discrete.\n如果一个变量可以取广泛的数值，并且对这些值进行加、减或求平均是有意义的，那么它就是数值 (numerical)（或定量）变量。数值变量可以是连续的或离散的。\nOne commonly used visualization for distributions of continuous variables is a histogram.\n对于连续变量的分布，一种常用的可视化方法是直方图。\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 200)\n\n\n\n\n\n\n\nA histogram divides the x-axis into equally spaced bins and then uses the height of a bar to display the number of observations that fall in each bin. In the graph above, the tallest bar shows that 39 observations have a body_mass_g value between 3,500 and 3,700 grams, which are the left and right edges of the bar.\n直方图将 x 轴划分为等距的区间（bin），然后用条形的高度来显示落入每个区间内的观测数量。在上图中，最高的条形显示有 39 个观测的 body_mass_g 值在 3500 到 3700 克之间，这是该条形的左右边缘。\nYou can set the width of the intervals in a histogram with the binwidth argument, which is measured in the units of the x variable. You should always explore a variety of binwidths when working with histograms, as different binwidths can reveal different patterns. In the plots below a binwidth of 20 is too narrow, resulting in too many bars, making it difficult to determine the shape of the distribution. Similarly, a binwidth of 2,000 is too high, resulting in all data being binned into only three bars, and also making it difficult to determine the shape of the distribution. A binwidth of 200 provides a sensible balance.\n你可以使用 binwidth 参数设置直方图中区间的宽度，该参数以 x 变量的单位来度量。在使用直方图时，你应该总是尝试不同的 binwidth，因为不同的宽度可以揭示不同的模式。在下面的图表中，20 的 binwidth 太窄，导致条形过多，难以确定分布的形状。同样，2000 的 binwidth 太高，导致所有数据只被分到三个条形中，也难以确定分布的形状。200 的 binwidth 提供了一个合理的平衡。\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 20)\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 2000)\n\n\n\n\n\n\n\n\n\n\nAn alternative visualization for distributions of numerical variables is a density plot. A density plot is a smoothed-out version of a histogram and a practical alternative, particularly for continuous data that comes from an underlying smooth distribution. We won’t go into how geom_density() estimates the density (you can read more about that in the function documentation), but let’s explain how the density curve is drawn with an analogy. Imagine a histogram made out of wooden blocks. Then, imagine that you drop a cooked spaghetti string over it. The shape the spaghetti will take draped over blocks can be thought of as the shape of the density curve. It shows fewer details than a histogram but can make it easier to quickly glean the shape of the distribution, particularly with respect to modes and skewness.\n数值变量分布的另一种可视化方法是密度图。密度图是直方图的平滑版本，是一种实用的替代方案，特别是对于来自底层平滑分布的连续数据。我们不会深入探讨 geom_density() 如何估计密度（你可以在函数文档中阅读更多相关内容），但让我们用一个类比来解释密度曲线是如何绘制的。想象一个由木块制成的直方图。然后，想象你把一根煮熟的意大利面条扔在上面。意大利面条披在木块上的形状可以被认为是密度曲线的形状。它比直方图显示的细节少，但可以更容易地快速了解分布的形状，特别是在众数和偏度方面。\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_density()\n#&gt; Warning: Removed 2 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\n\n1.4.3 Exercises\n\nMake a bar plot of species of penguins, where you assign species to the y aesthetic. How is this plot different?\n制作一个 penguins 的 species 条形图，其中你将 species 分配给 y 美学。这个图有什么不同？\nHow are the following two plots different? Which aesthetic, color or fill, is more useful for changing the color of bars?\n\n下面两张图有什么不同？哪个美学，color 还是 fill，对于改变条形的颜色更有用？\n```{r} #| eval: false ggplot(penguins, aes(x = species)) + geom_bar(color = “red”)\nggplot(penguins, aes(x = species)) + geom_bar(fill = “red”) ```\n\nWhat does the bins argument in geom_histogram() do?\ngeom_histogram() 中的 bins 参数有什么作用？\nMake a histogram of the carat variable in the diamonds dataset that is available when you load the tidyverse package. Experiment with different binwidths. What binwidth reveals the most interesting patterns?\n制作一个 diamonds 数据集中 carat 变量的直方图，该数据集在加载 tidyverse 包时可用。尝试不同的 binwidth。哪个 binwidth 揭示了最有趣的模式？",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#visualizing-relationships",
    "href": "data-visualize.html#visualizing-relationships",
    "title": "1  Data visualization",
    "section": "\n1.5 Visualizing relationships",
    "text": "1.5 Visualizing relationships\nTo visualize a relationship we need to have at least two variables mapped to aesthetics of a plot. In the following sections you will learn about commonly used plots for visualizing relationships between two or more variables and the geoms used for creating them.\n要可视化一个关系，我们需要将至少两个变量映射到图表的美学上。在接下来的部分中，你将学习用于可视化两个或多个变量之间关系的常用图表，以及用于创建它们的几何对象。\n\n1.5.1 A numerical and a categorical variable\nTo visualize the relationship between a numerical and a categorical variable we can use side-by-side box plots. A boxplot is a type of visual shorthand for measures of position (percentiles) that describe a distribution. It is also useful for identifying potential outliers. As shown in Figure 1.1, each boxplot consists of:\n要可视化数值变量和分类变量之间的关系，我们可以使用并排的箱线图。箱线图 (boxplot) 是一种描述分布位置度量（百分位数）的视觉简写。它对于识别潜在的异常值也很有用。如 Figure 1.1 所示，每个箱线图都包含：\n\nA box that indicates the range of the middle half of the data, a distance known as the interquartile range (IQR), stretching from the 25th percentile of the distribution to the 75th percentile. In the middle of the box is a line that displays the median, i.e. 50th percentile, of the distribution. These three lines give you a sense of the spread of the distribution and whether or not the distribution is symmetric about the median or skewed to one side.\n一个箱体，表示数据中间一半的范围，这个距离被称为四分位距 (interquartile range, IQR)，从分布的第 25 百分位数延伸到第 75 百分位数。箱体中间有一条线，显示分布的中位数，即第 50 百分位数。这三条线让你了解分布的离散程度以及分布是否关于中位数对称或偏向一侧。\nVisual points that display observations that fall more than 1.5 times the IQR from either edge of the box. These outlying points are unusual so are plotted individually.\n一些视觉点，显示那些距离箱体任一边缘超过 1.5 倍 IQR 的观测值。这些离群点是不寻常的，因此会单独绘制。\nA line (or whisker) that extends from each end of the box and goes to the farthest non-outlier point in the distribution.\n一条从箱体两端延伸出来的线（或称为胡须），一直延伸到分布中最远的非离群点。\n\n\n\n\n\n\n\n\nFigure 1.1: Diagram depicting how a boxplot is created.\n\n\n\n\nLet’s take a look at the distribution of body mass by species using geom_boxplot():\n让我们使用 geom_boxplot() 来查看按物种划分的体重分布：\n\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nAlternatively, we can make density plots with geom_density().\n或者，我们可以用 geom_density() 制作密度图。\n\nggplot(penguins, aes(x = body_mass_g, color = species)) +\n  geom_density(linewidth = 0.75)\n\n\n\n\n\n\n\nWe’ve also customized the thickness of the lines using the linewidth argument in order to make them stand out a bit more against the background.\n我们还使用了 linewidth 参数自定义了线条的粗细，以使它们在背景中更突出一些。\nAdditionally, we can map species to both color and fill aesthetics and use the alpha aesthetic to add transparency to the filled density curves. This aesthetic takes values between 0 (completely transparent) and 1 (completely opaque). In the following plot it’s set to 0.5.\n此外，我们可以将 species 映射到 color 和 fill 两个美学上，并使用 alpha 美学为填充的密度曲线添加透明度。这个美学的值介于 0（完全透明）和 1（完全不透明）之间。在下面的图表中，它被设置为 0.5。\n\nggplot(penguins, aes(x = body_mass_g, color = species, fill = species)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nNote the terminology we have used here:\n注意我们在这里使用的术语：\n\nWe map variables to aesthetics if we want the visual attribute represented by that aesthetic to vary based on the values of that variable.\nOtherwise, we set the value of an aesthetic.\n如果希望由某个美学表示的视觉属性根据某个变量的值而变化，我们就将变量映射 (map) 到该美学。\n否则，我们就设置 (set) 该美学的值。\n\n1.5.2 Two categorical variables\nWe can use stacked bar plots to visualize the relationship between two categorical variables. For example, the following two stacked bar plots both display the relationship between island and species, or specifically, visualizing the distribution of species within each island.\n我们可以使用堆叠条形图来可视化两个分类变量之间的关系。例如，以下两个堆叠条形图都显示了 island 和 species 之间的关系，或者具体来说，可视化了每个岛屿内 species 的分布。\nThe first plot shows the frequencies of each species of penguins on each island. The plot of frequencies shows that there are equal numbers of Adelies on each island. But we don’t have a good sense of the percentage balance within each island.\n第一张图显示了每个岛屿上每种企鹅的频率。频率图显示，每个岛屿上的阿德利企鹅数量相等。但我们无法很好地了解每个岛屿内部的百分比平衡。\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar()\n\n\n\n\n\n\n\nThe second plot, a relative frequency plot created by setting position = \"fill\" in the geom, is more useful for comparing species distributions across islands since it’s not affected by the unequal numbers of penguins across the islands. Using this plot we can see that Gentoo penguins all live on Biscoe island and make up roughly 75% of the penguins on that island, Chinstrap all live on Dream island and make up roughly 50% of the penguins on that island, and Adelie live on all three islands and make up all of the penguins on Torgersen.\n第二张图，一个通过在几何对象中设置 position = \"fill\" 创建的相对频率图，在比较各岛屿间物种分布时更有用，因为它不受各岛屿企鹅数量不等的影响。使用这张图我们可以看到，所有巴布亚企鹅都生活在比斯科岛上，约占该岛企鹅的 75%；所有帽带企鹅都生活在梦幻岛上，约占该岛企鹅的 50%；而阿德利企鹅生活在所有三个岛屿上，并构成了特格尔森岛上的全部企鹅。\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nIn creating these bar charts, we map the variable that will be separated into bars to the x aesthetic, and the variable that will change the colors inside the bars to the fill aesthetic.\n在创建这些条形图时，我们将要被分成条形的变量映射到 x 美学，将要改变条形内部颜色的变量映射到 fill 美学。\n\n1.5.3 Two numerical variables\nSo far you’ve learned about scatterplots (created with geom_point()) and smooth curves (created with geom_smooth()) for visualizing the relationship between two numerical variables. A scatterplot is probably the most commonly used plot for visualizing the relationship between two numerical variables.\n到目前为止，你已经学习了用于可视化两个数值变量之间关系的散点图（用 geom_point() 创建）和平滑曲线（用 geom_smooth() 创建）。散点图可能是可视化两个数值变量之间关系最常用的图表。\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\n\n\n\n\n\n\n1.5.4 Three or more variables\nAs we saw in Section 1.2.4, we can incorporate more variables into a plot by mapping them to additional aesthetics. For example, in the following scatterplot the colors of points represent species and the shapes of points represent islands.\n正如我们在 Section 1.2.4 中看到的，我们可以通过将更多变量映射到额外的美学上，将它们整合到图表中。例如，在下面的散点图中，点的颜色代表物种，点的形状代表岛屿。\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = island))\n\n\n\n\n\n\n\nHowever adding too many aesthetic mappings to a plot makes it cluttered and difficult to make sense of. Another way, which is particularly useful for categorical variables, is to split your plot into facets, subplots that each display one subset of the data.\n然而，向图表中添加过多的美学映射会使其变得杂乱无章，难以理解。另一种方法，特别是对于分类变量很有用，就是将你的图表分割成分面 (facets)，即每个子图显示数据的一个子集。\nTo facet your plot by a single variable, use facet_wrap(). The first argument of facet_wrap() is a formula5, which you create with ~ followed by a variable name. The variable that you pass to facet_wrap() should be categorical.\n要按单个变量对图表进行分面，请使用 facet_wrap()。facet_wrap() 的第一个参数是一个公式6，你通过 ~ 后跟一个变量名来创建它。传递给 facet_wrap() 的变量应该是分类变量。\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species)) +\n  facet_wrap(~island)\n\n\n\n\n\n\n\nYou will learn about many other geoms for visualizing distributions of variables and relationships between them in Chapter 9.\n你将在 Chapter 9 中学习许多其他用于可视化变量分布和它们之间关系的几何对象。\n\n1.5.5 Exercises\n\nThe mpg data frame that is bundled with the ggplot2 package contains 234 observations collected by the US Environmental Protection Agency on 38 car models. Which variables in mpg are categorical? Which variables are numerical? (Hint: Type ?mpg to read the documentation for the dataset.) How can you see this information when you run mpg?\n与 ggplot2 包捆绑的 mpg 数据框包含由美国环境保护署收集的 38 种汽车模型的 234 条观测数据。mpg 中的哪些变量是分类变量？哪些变量是数值变量？（提示：输入 ?mpg 阅读数据集的文档。）当你运行 mpg 时，如何看到这些信息？\nMake a scatterplot of hwy vs. displ using the mpg data frame. Next, map a third, numerical variable to color, then size, then both color and size, then shape. How do these aesthetics behave differently for categorical vs. numerical variables?\n使用 mpg 数据框制作一个 hwy 对 displ 的散点图。接下来，将第三个数值变量映射到 color，然后是 size，然后是 color 和 size，最后是 shape。这些美学对于分类变量和数值变量的行为有何不同？\nIn the scatterplot of hwy vs. displ, what happens if you map a third variable to linewidth?\n在 hwy 对 displ 的散点图中，如果将第三个变量映射到 linewidth 会发生什么？\nWhat happens if you map the same variable to multiple aesthetics?\n如果将同一个变量映射到多个美学上会发生什么？\nMake a scatterplot of bill_depth_mm vs. bill_length_mm and color the points by species. What does adding coloring by species reveal about the relationship between these two variables? What about faceting by species?\n制作一个 bill_depth_mm 对 bill_length_mm 的散点图，并按 species 为点着色。按物种着色揭示了这两个变量之间关系的什么信息？按 species 分面又如何呢？\nWhy does the following yield two separate legends? How would you fix it to combine the two legends?\n\n为什么下面的代码会产生两个独立的图例？你将如何修复它以合并这两个图例？\n{r}     #| warning: false     #| fig-show: hide     ggplot(       data = penguins,       mapping = aes(         x = bill_length_mm, y = bill_depth_mm,          color = species, shape = species       )     ) +       geom_point() +       labs(color = \"Species\")\n\nCreate the two following stacked bar plots. Which question can you answer with the first one? Which question can you answer with the second one?\n\n创建以下两个堆叠条形图。你可以用第一个回答什么问题？你可以用第二个回答什么问题？\n{r}     #| fig-show: hide     ggplot(penguins, aes(x = island, fill = species)) +       geom_bar(position = \"fill\")     ggplot(penguins, aes(x = species, fill = island)) +       geom_bar(position = \"fill\")",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggsave",
    "href": "data-visualize.html#sec-ggsave",
    "title": "1  Data visualization",
    "section": "\n1.6 Saving your plots",
    "text": "1.6 Saving your plots\nOnce you’ve made a plot, you might want to get it out of R by saving it as an image that you can use elsewhere. That’s the job of ggsave(), which will save the plot most recently created to disk:\n一旦你制作了一个图表，你可能想把它从 R 中导出来，保存为一张图片以便在其他地方使用。这是 ggsave() 的工作，它会将最近创建的图表保存到磁盘上：\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\nggsave(filename = \"penguin-plot.png\")\n\nThis will save your plot to your working directory, a concept you’ll learn more about in Chapter 6.\n这会将你的图表保存到你的工作目录中，关于这个概念你将在 Chapter 6 中学到更多。\nIf you don’t specify the width and height they will be taken from the dimensions of the current plotting device. For reproducible code, you’ll want to specify them. You can learn more about ggsave() in the documentation.\n如果你不指定 width 和 height，它们将取自当前绘图设备的尺寸。为了代码的可重现性，你会想要指定它们。你可以在文档中了解更多关于 ggsave() 的信息。\nGenerally, however, we recommend that you assemble your final reports using Quarto, a reproducible authoring system that allows you to interleave your code and your prose and automatically include your plots in your write-ups. You will learn more about Quarto in Chapter 28.\n然而，通常我们建议你使用 Quarto 来组织你的最终报告，这是一个可重现的创作系统，它允许你将代码和散文交织在一起，并自动将你的图表包含在你的报告中。你将在 Chapter 28 中学习更多关于 Quarto 的知识。\n\n1.6.1 Exercises\n\nRun the following lines of code. Which of the two plots is saved as mpg-plot.png? Why?\n\n运行以下代码行。哪一张图被保存为 mpg-plot.png？为什么？\n{r}     #| eval: false     ggplot(mpg, aes(x = class)) +       geom_bar()     ggplot(mpg, aes(x = cty, y = hwy)) +       geom_point()     ggsave(\"mpg-plot.png\")\n\nWhat do you need to change in the code above to save the plot as a PDF instead of a PNG? How could you find out what types of image files would work in ggsave()?\n在上面的代码中，你需要改变什么才能将图表保存为 PDF 而不是 PNG？你如何找出 ggsave() 可以使用哪些类型的图像文件？",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#common-problems",
    "href": "data-visualize.html#common-problems",
    "title": "1  Data visualization",
    "section": "\n1.7 Common problems",
    "text": "1.7 Common problems\nAs you start to run R code, you’re likely to run into problems. Don’t worry — it happens to everyone. We have all been writing R code for years, but every day we still write code that doesn’t work on the first try!\n当你开始运行 R 代码时，你很可能会遇到问题。别担心——这发生在每个人身上。我们都写了很多年的 R 代码，但每天我们仍然会写出第一次尝试就不工作的代码！\nStart by carefully comparing the code that you’re running to the code in the book. R is extremely picky, and a misplaced character can make all the difference. Make sure that every ( is matched with a ) and every \" is paired with another \". Sometimes you’ll run the code and nothing happens. Check the left-hand of your console: if it’s a +, it means that R doesn’t think you’ve typed a complete expression and it’s waiting for you to finish it. In this case, it’s usually easy to start from scratch again by pressing ESCAPE to abort processing the current command.\n首先仔细比较你正在运行的代码和书中的代码。R 非常挑剔，一个放错位置的字符都可能造成天壤之别。确保每个 ( 都与一个 ) 匹配，每个 \" 都与另一个 \" 配对。有时你运行代码后什么也没发生。检查你的控制台左侧：如果是一个 +，这意味着 R 认为你还没有输入一个完整的表达式，它正在等你完成。在这种情况下，通常很容易通过按 ESCAPE 键中止处理当前命令来重新开始。\nOne common problem when creating ggplot2 graphics is to put the + in the wrong place: it has to come at the end of the line, not the start. In other words, make sure you haven’t accidentally written code like this:\n在创建 ggplot2 图形时，一个常见的问题是把 + 放在了错误的位置：它必须放在行的末尾，而不是开头。换句话说，确保你没有意外地写出这样的代码：\n\nggplot(data = mpg) \n+ geom_point(mapping = aes(x = displ, y = hwy))\n\nIf you’re still stuck, try the help. You can get help about any R function by running ?function_name in the console, or highlighting the function name and pressing F1 in RStudio. Don’t worry if the help doesn’t seem that helpful - instead skip down to the examples and look for code that matches what you’re trying to do.\n如果你仍然卡住了，试试帮助。你可以通过在控制台中运行 ?function_name 来获取任何 R 函数的帮助，或者在 RStudio 中高亮函数名并按 F1。如果帮助看起来不那么有用，也不要担心——直接跳到示例部分，寻找与你正在尝试做的事情相匹配的代码。\nIf that doesn’t help, carefully read the error message. Sometimes the answer will be buried there! But when you’re new to R, even if the answer is in the error message, you might not yet know how to understand it. Another great tool is Google: try googling the error message, as it’s likely someone else has had the same problem, and has gotten help online.\n如果那没有帮助，仔细阅读错误信息。有时答案就埋藏在那里！但是当你刚接触 R 时，即使答案在错误信息中，你可能还不知道如何理解它。另一个很棒的工具是谷歌：尝试用谷歌搜索错误信息，因为很可能其他人也遇到过同样的问题，并且在网上得到了帮助。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#summary",
    "href": "data-visualize.html#summary",
    "title": "1  Data visualization",
    "section": "\n1.8 Summary",
    "text": "1.8 Summary\nIn this chapter, you’ve learned the basics of data visualization with ggplot2. We started with the basic idea that underpins ggplot2: a visualization is a mapping from variables in your data to aesthetic properties like position, color, size and shape. You then learned about increasing the complexity and improving the presentation of your plots layer-by-layer. You also learned about commonly used plots for visualizing the distribution of a single variable as well as for visualizing relationships between two or more variables, by leveraging additional aesthetic mappings and/or splitting your plot into small multiples using faceting.\n在本章中，你学习了用 ggplot2 进行数据可视化的基础知识。我们从支撑 ggplot2 的基本思想开始：可视化是将数据中的变量映射到诸如位置、颜色、大小和形状等美学属性。然后你学习了如何逐层增加图表的复杂性和改善其呈现方式。你还学习了用于可视化单个变量分布以及可视化两个或多个变量之间关系的常用图表，方法是利用额外的美学映射和/或使用分面将图表分割成小倍数图。\nWe’ll use visualizations again and again throughout this book, introducing new techniques as we need them as well as do a deeper dive into creating visualizations with ggplot2 in Chapter 9 through Chapter 11.\n在本书中，我们将反复使用可视化，在需要时介绍新技术，并在 Chapter 9 到 Chapter 11 中更深入地探讨用 ggplot2 创建可视化。\nWith the basics of visualization under your belt, in the next chapter we’re going to switch gears a little and give you some practical workflow advice. We intersperse workflow advice with data science tools throughout this part of the book because it’ll help you stay organized as you write increasing amounts of R code.\n掌握了可视化的基础知识后，在下一章中，我们将稍微转换一下思路，给你一些实用的工作流程建议。我们在本书的这一部分将工作流程建议与数据科学工具穿插在一起，因为当你编写越来越多的 R 代码时，这将帮助你保持条理。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#footnotes",
    "href": "data-visualize.html#footnotes",
    "title": "1  Data visualization",
    "section": "",
    "text": "You can eliminate that message and force conflict resolution to happen on demand by using the conflicted package, which becomes more important as you load more packages. You can learn more about conflicted at https://conflicted.r-lib.org.↩︎\nYou can eliminate that message and force conflict resolution to happen on demand by using the conflicted package, which becomes more important as you load more packages. You can learn more about conflicted at https://conflicted.r-lib.org.↩︎\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.↩︎\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.↩︎\nHere “formula” is the name of the thing created by ~, not a synonym for “equation”.↩︎\nHere “formula” is the name of the thing created by ~, not a synonym for “equation”.↩︎",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html",
    "href": "workflow-basics.html",
    "title": "2  Workflow: basics",
    "section": "",
    "text": "2.1 Coding basics\nYou now have some experience running R code. We didn’t give you many details, but you’ve obviously figured out the basics, or you would’ve thrown this book away in frustration! Frustration is natural when you start programming in R because it is such a stickler for punctuation, and even one character out of place can cause it to complain. But while you should expect to be a little frustrated, take comfort in that this experience is typical and temporary: it happens to everyone, and the only way to get over it is to keep trying.\n你现在已经有了一些运行 R 代码的经验。我们没有提供太多细节，但你显然已经掌握了基础知识，否则你早就沮丧地把这本书扔掉了！当你开始用 R 编程时，感到沮丧是很自然的，因为它对标点符号要求非常严格，即使一个字符放错了位置，也可能导致它报错。但是，尽管你应该预料到会有些沮丧，但请放心，这种经历是典型且暂时的：每个人都会遇到，而克服它的唯一方法就是不断尝试。\nBefore we go any further, let’s ensure you’ve got a solid foundation in running R code and that you know some of the most helpful RStudio features.\n在继续之前，让我们确保你在运行 R 代码方面有坚实的基础，并且了解一些最有用的 RStudio 功能。\nLet’s review some basics we’ve omitted so far in the interest of getting you plotting as quickly as possible. You can use R to do basic math calculations:\n让我们回顾一些我们之前为了让你尽快开始绘图而省略的基础知识。你可以使用 R 进行基本的数学计算：\n1 / 200 * 30\n#&gt; [1] 0.15\n(59 + 73 + 2) / 3\n#&gt; [1] 44.66667\nsin(pi / 2)\n#&gt; [1] 1\nYou can create new objects with the assignment operator &lt;-:\n你可以使用赋值运算符 &lt;- 创建新对象：\nx &lt;- 3 * 4\nNote that the value of x is not printed, it’s just stored. If you want to view the value, type x in the console.\n注意，x 的值没有被打印出来，它只是被存储了。如果你想查看它的值，可以在控制台 (console) 中输入 x。\nYou can combine multiple elements into a vector with c():\n你可以用 c() 将多个元素合并 (combine) 成一个向量 (vector)：\nprimes &lt;- c(2, 3, 5, 7, 11, 13)\nAnd basic arithmetic on vectors is applied to every element of the vector:\n对向量进行的基本算术运算会应用于向量的每个元素：\nprimes * 2\n#&gt; [1]  4  6 10 14 22 26\nprimes - 1\n#&gt; [1]  1  2  4  6 10 12\nAll R statements where you create objects, assignment statements, have the same form:\n所有创建对象的 R 语句，即赋值 (assignment) 语句，都具有相同的形式：\nobject_name &lt;- value\nWhen reading that code, say “object name gets value” in your head.\n读这段代码时，可以在脑海里默念“对象名得到值”。\nYou will make lots of assignments, and &lt;- is a pain to type. You can save time with RStudio’s keyboard shortcut: Alt + - (the minus sign). Notice that RStudio automatically surrounds &lt;- with spaces, which is a good code formatting practice. Code can be miserable to read on a good day, so giveyoureyesabreak and use spaces.\n你会进行大量赋值操作，而输入 &lt;- 很麻烦。你可以使用 RStudio 的键盘快捷键来节省时间：Alt + - (减号)。注意，RStudio 会自动在 &lt;- 两侧加上空格，这是一个很好的代码格式化习惯。代码在好的情况下也可能难以阅读，所以请使用空格，让你的眼睛休息一下。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#comments",
    "href": "workflow-basics.html#comments",
    "title": "2  Workflow: basics",
    "section": "\n2.2 Comments",
    "text": "2.2 Comments\nR will ignore any text after # for that line. This allows you to write comments, text that is ignored by R but read by other humans. We’ll sometimes include comments in examples explaining what’s happening with the code.\nR 会忽略某行中 # 之后的所有文本。这允许你编写注释 (comments)，这些文本会被 R 忽略，但可供其他人阅读。我们有时会在示例中加入注释来解释代码的功能。\nComments can be helpful for briefly describing what the following code does.\n注释对于简要描述后续代码的功能很有帮助。\n\n# create vector of primes\nprimes &lt;- c(2, 3, 5, 7, 11, 13)\n\n# multiply primes by 2\nprimes * 2\n#&gt; [1]  4  6 10 14 22 26\n\nWith short pieces of code like this, leaving a comment for every single line of code might not be necessary. But as the code you’re writing gets more complex, comments can save you (and your collaborators) a lot of time figuring out what was done in the code.\n对于像这样简短的代码片段，可能没有必要为每一行代码都留下注释。但随着你编写的代码越来越复杂，注释可以为你（和你的合作者）节省大量时间来理解代码的功能。\nUse comments to explain the why of your code, not the how or the what. The what and how of your code are always possible to figure out, even if it might be tedious, by carefully reading it. If you describe every step in the comments, and then change the code, you will have to remember to update the comments as well or it will be confusing when you return to your code in the future.\n使用注释来解释你代码的原因 (why)，而不是方式 (how) 或内容 (what)。你代码的内容和方式总是可以通过仔细阅读代码来弄清楚，即使这可能很乏味。如果你在注释中描述了每一步，然后又更改了代码，你就必须记得同时更新注释，否则将来你回到代码时会感到困惑。\nFiguring out why something was done is much more difficult, if not impossible. For example, geom_smooth() has an argument called span, which controls the smoothness of the curve, with larger values yielding a smoother curve. Suppose you decide to change the value of span from its default of 0.75 to 0.9: it’s easy for a future reader to understand what is happening, but unless you note your thinking in a comment, no one will understand why you changed the default.\n弄清楚为什么这么做要困难得多，甚至是不可能的。例如，geom_smooth() 有一个名为 span 的参数，它控制曲线的平滑度，值越大，曲线越平滑。假设你决定将 span 的值从默认的 0.75 更改为 0.9：未来的读者很容易理解发生了什么，但除非你在注释中记下你的想法，否则没人会明白你为什么要更改默认值。\nFor data analysis code, use comments to explain your overall plan of attack and record important insights as you encounter them. There’s no way to re-capture this knowledge from the code itself.\n对于数据分析代码，使用注释来解释你的整体分析计划，并记录你遇到的重要见解。这些知识是无法从代码本身重新获取的。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#sec-whats-in-a-name",
    "href": "workflow-basics.html#sec-whats-in-a-name",
    "title": "2  Workflow: basics",
    "section": "\n2.3 What’s in a name?",
    "text": "2.3 What’s in a name?\nObject names must start with a letter and can only contain letters, numbers, _, and .. You want your object names to be descriptive, so you’ll need to adopt a convention for multiple words. We recommend snake_case, where you separate lowercase words with _.\n对象名称必须以字母开头，并且只能包含字母、数字、_ 和 .。你希望你的对象名称具有描述性，所以你需要为多个单词的命名采用一种约定。我们推荐使用蛇形命名法 (snake_case)，即用 _ 分隔小写单词。\n\ni_use_snake_case\notherPeopleUseCamelCase\nsome.people.use.periods\nAnd_aFew.People_RENOUNCEconvention\n\nWe’ll return to names again when we discuss code style in Chapter 4.\n我们将在 Chapter 4 中讨论代码风格时再次回到命名问题。\nYou can inspect an object by typing its name:\n你可以通过输入对象名称来查看它：\n\nx\n#&gt; [1] 12\n\nMake another assignment:\n进行另一个赋值操作：\n\nthis_is_a_really_long_name &lt;- 2.5\n\nTo inspect this object, try out RStudio’s completion facility: type “this”, press TAB, add characters until you have a unique prefix, then press return.\n要查看这个对象，可以试试 RStudio 的自动补全功能：输入 “this”，按 TAB 键，继续添加字符直到前缀唯一，然后按回车键。\nLet’s assume you made a mistake, and that the value of this_is_a_really_long_name should be 3.5, not 2.5. You can use another keyboard shortcut to help you fix it. For example, you can press ↑ to bring the last command you typed and edit it. Or, type “this” then press Cmd/Ctrl + ↑ to list all the commands you’ve typed that start with those letters. Use the arrow keys to navigate, then press enter to retype the command. Change 2.5 to 3.5 and rerun.\n假设你犯了一个错误，this_is_a_really_long_name 的值应该是 3.5，而不是 2.5。你可以使用另一个键盘快捷键来帮助你修正。例如，你可以按 ↑ 键调出你输入的上一条命令并进行编辑。或者，输入 “this” 然后按 Cmd/Ctrl + ↑ 键，列出所有以这些字母开头的你输入过的命令。使用方向键导航，然后按回车键重新输入该命令。将 2.5 改为 3.5 并重新运行。\nMake yet another assignment:\n再进行一个赋值操作：\n\nr_rocks &lt;- 2^3\n\nLet’s try to inspect it:\n让我们试着查看它：\n\nr_rock\n#&gt; Error: object 'r_rock' not found\nR_rocks\n#&gt; Error: object 'R_rocks' not found\n\nThis illustrates the implied contract between you and R: R will do the tedious computations for you, but in exchange, you must be completely precise in your instructions. If not, you’re likely to get an error that says the object you’re looking for was not found. Typos matter; R can’t read your mind and say, “oh, they probably meant r_rocks when they typed r_rock”. Case matters; similarly, R can’t read your mind and say, “oh, they probably meant r_rocks when they typed R_rocks”.\n这说明了你和 R 之间的一个隐含约定：R 会为你完成繁琐的计算，但作为交换，你的指令必须完全精确。否则，你很可能会收到一个错误，提示找不到你想要的对象。拼写错误很重要；R 无法读懂你的心思，说：“哦，他们输入 r_rock 时可能指的是 r_rocks”。大小写也很重要；同样，R 也无法读懂你的心思，说：“哦，他们输入 R_rocks 时可能指的是 r_rocks”。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#calling-functions",
    "href": "workflow-basics.html#calling-functions",
    "title": "2  Workflow: basics",
    "section": "\n2.4 Calling functions",
    "text": "2.4 Calling functions\nR has a large collection of built-in functions that are called like this:\nR 有大量内置函数，调用方式如下：\n\nfunction_name(argument1 = value1, argument2 = value2, ...)\n\nLet’s try using seq(), which makes regular sequences of numbers, and while we’re at it, learn more helpful features of RStudio. Type se and hit TAB. A popup shows you possible completions. Specify seq() by typing more (a q) to disambiguate or by using ↑/↓ arrows to select. Notice the floating tooltip that pops up, reminding you of the function’s arguments and purpose. If you want more help, press F1 to get all the details in the help tab in the lower right pane.\n让我们尝试使用 seq() 函数，它可以生成规则的数字序列 (sequence)，同时我们也可以学习更多 RStudio 的实用功能。输入 se 然后按 TAB 键。一个弹出窗口会显示可能的补全选项。通过输入更多字符（一个 q）来明确指定 seq()，或者使用 ↑/↓ 箭头来选择。注意弹出的浮动提示框，它会提醒你函数的参数和用途。如果你需要更多帮助，可以按 F1 键，在右下角窗格的帮助 (Help) 选项卡中获取所有详细信息。\nWhen you’ve selected the function you want, press TAB again. RStudio will add matching opening (() and closing ()) parentheses for you. Type the name of the first argument, from, and set it equal to 1. Then, type the name of the second argument, to, and set it equal to 10. Finally, hit return.\n当你选定想要的函数后，再次按 TAB 键。RStudio 会为你添加匹配的开括号 ( 和闭括号 )。输入第一个参数的名称 from，并将其设置为 1。然后，输入第二个参数的名称 to，并将其设置为 10。最后，按回车键。\n\nseq(from = 1, to = 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nWe often omit the names of the first several arguments in function calls, so we can rewrite this as follows:\n在函数调用中，我们通常会省略前几个参数的名称，所以我们可以像下面这样重写：\n\nseq(1, 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nType the following code and notice that RStudio provides similar assistance with the paired quotation marks:\n输入以下代码，注意 RStudio 对成对的引号也提供了类似的辅助功能：\n\nx &lt;- \"hello world\"\n\nQuotation marks and parentheses must always come in a pair. RStudio does its best to help you, but it’s still possible to mess up and end up with a mismatch. If this happens, R will show you the continuation character “+”:\n引号和括号必须总是成对出现。RStudio 会尽力帮助你，但仍然有可能出错并导致不匹配。如果发生这种情况，R 会显示一个连续字符 +：\n&gt; x &lt;- \"hello\n+\nThe + tells you that R is waiting for more input; it doesn’t think you’re done yet. Usually, this means you’ve forgotten either a \" or a ). Either add the missing pair, or press ESCAPE to abort the expression and try again.\n+ 告诉你 R 正在等待更多输入；它认为你还没有完成。这通常意味着你忘记了输入一个 \" 或 )。你可以补上缺失的符号，或者按 ESCAPE 键中止表达式并重试。\nNote that the environment tab in the upper right pane displays all of the objects that you’ve created:\n注意，右上角窗格中的环境 (Environment) 选项卡会显示你创建的所有对象：",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#exercises",
    "href": "workflow-basics.html#exercises",
    "title": "2  Workflow: basics",
    "section": "\n2.5 Exercises",
    "text": "2.5 Exercises\n\n\nWhy does this code not work?\n为什么这段代码无法工作？\n\nmy_variable &lt;- 10\nmy_varıable\n#&gt; Error: object 'my_varıable' not found\n\nLook carefully! (This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.)\n仔细看！(这可能看起来像一个无意义的练习，但训练你的大脑注意最微小的差异，在编程时会大有裨益。)\n\n\nTweak each of the following R commands so that they run correctly:\n调整以下每个 R 命令，使它们能够正确运行：\n\nlibary(todyverse)\n\nggplot(dTA = mpg) + \n  geom_point(maping = aes(x = displ y = hwy)) +\n  geom_smooth(method = \"lm)\n\n\n\nPress Option + Shift + K / Alt + Shift + K. What happens? How can you get to the same place using the menus?\n按 Option + Shift + K / Alt + Shift + K。会发生什么？你如何通过菜单到达同一个地方？\n\n\nLet’s revisit an exercise from the Section 1.6. Run the following lines of code. Which of the two plots is saved as mpg-plot.png? Why?\n让我们重温 Section 1.6 中的一个练习。运行以下代码行。哪张图被保存为 mpg-plot.png？为什么？\n\nmy_bar_plot &lt;- ggplot(mpg, aes(x = class)) +\n  geom_bar()\nmy_scatter_plot &lt;- ggplot(mpg, aes(x = cty, y = hwy)) +\n  geom_point()\nggsave(filename = \"mpg-plot.png\", plot = my_bar_plot)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#summary",
    "href": "workflow-basics.html#summary",
    "title": "2  Workflow: basics",
    "section": "\n2.6 Summary",
    "text": "2.6 Summary\nNow that you’ve learned a little more about how R code works, and some tips to help you understand your code when you come back to it in the future. In the next chapter, we’ll continue your data science journey by teaching you about dplyr, the tidyverse package that helps you transform data, whether it’s selecting important variables, filtering down to rows of interest, or computing summary statistics.\n现在你对 R 代码的工作原理有了更多了解，也学到了一些技巧，可以帮助你在未来回顾代码时更好地理解它。在下一章中，我们将继续你的数据科学之旅，教你关于 dplyr 的知识，这是一个 tidyverse 包，可以帮助你转换数据，无论是选择重要变量、筛选感兴趣的行，还是计算汇总统计数据。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "data-transform.html",
    "href": "data-transform.html",
    "title": "3  数据转换",
    "section": "",
    "text": "3.1 引言\n可视化是产生洞见的重要工具，但你很少能得到完全符合你需求的、可以直接用来制作你想要的图表的数据形式。通常，你需要创建一些新的变量或摘要来用数据回答你的问题，或者你可能只是想重命名变量或重新排序观测值，以便让数据更容易处理。在本章中，你将学习如何做到所有这些（以及更多！），本章将向你介绍如何使用 dplyr 包和一个关于 2013 年从纽约市起飞的航班的新数据集来进行数据转换。\n本章的目标是让你对所有用于转换数据框的关键工具有一个全面的了解。我们将从操作数据框的行和列的函数开始，然后回过头来更多地讨论管道 (pipe)，这是一个用于组合动词的重要工具。接着，我们将介绍处理分组的能力。本章最后会有一个案例研究，展示这些函数的实际应用。在后面的章节中，当我们开始深入研究特定类型的数据（例如，数字、字符串、日期）时，我们将更详细地回顾这些函数。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#引言",
    "href": "data-transform.html#引言",
    "title": "3  数据转换",
    "section": "",
    "text": "3.1.1 先决条件\n在本章中，我们将重点关注 dplyr 包，它是 tidyverse 的另一个核心成员。我们将使用 nycflights13 包中的数据来说明关键思想，并使用 ggplot2 来帮助我们理解数据。\n\nlibrary(nycflights13)\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n#&gt; ✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.0.4     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n请仔细注意加载 tidyverse 时打印出的冲突信息。它告诉你 dplyr 覆盖了 R 基础包中的一些函数。如果你在加载 dplyr 后想使用这些函数的基础版本，你需要使用它们的全名：stats::filter() 和 stats::lag()。到目前为止，我们大多忽略了函数来自哪个包，因为这通常不重要。然而，知道包可以帮助你找到帮助和相关函数，所以当我们需​​要精确说明一个函数来自哪个包时，我们将使用与 R 相同的语法：packagename::functionname()。\n\n3.1.2 nycflights13\n为了探索基本的 dplyr 动词，我们将使用 nycflights13::flights。这个数据集包含了 2013 年从纽约市起飞的所有 336,776 个航班。数据来自美国交通统计局，并在 ?flights 中有文档说明。\n\nflights\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nflights 是一个 tibble，这是 tidyverse 使用的一种特殊类型的数据框，以避免一些常见的陷阱。tibble 和数据框之间最重要的区别是 tibble 的打印方式；它们专为大型数据集设计，因此只显示前几行和能在一个屏幕上容纳的列。有几种方法可以查看所有内容。如果你正在使用 RStudio，最方便的可能是 View(flights)，它会打开一个可交互、可滚动和可筛选的视图。否则你可以使用 print(flights, width = Inf) 来显示所有列，或者使用 glimpse()：\n\nglimpse(flights)\n#&gt; Rows: 336,776\n#&gt; Columns: 19\n#&gt; $ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n#&gt; $ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 55…\n#&gt; $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 60…\n#&gt; $ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2,…\n#&gt; $ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 8…\n#&gt; $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 8…\n#&gt; $ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7,…\n#&gt; $ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\"…\n#&gt; $ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301…\n#&gt; $ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N…\n#&gt; $ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LG…\n#&gt; $ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IA…\n#&gt; $ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149…\n#&gt; $ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 73…\n#&gt; $ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6…\n#&gt; $ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59…\n#&gt; $ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-0…\n\n在这两种视图中，变量名后面都跟着缩写，告诉你每个变量的类型：&lt;int&gt; 是整数 (integer) 的缩写，&lt;dbl&gt; 是双精度浮点数 (double)（也就是实数）的缩写，&lt;chr&gt; 是字符 (character)（也就是字符串）的缩写，&lt;dttm&gt; 是日期时间 (date-time) 的缩写。这些都很重要，因为你可以对一列执行的操作在很大程度上取决于它的“类型”。\n\n3.1.3 dplyr 基础\n你即将学习主要的 dplyr 动词（函数），它们将使你能够解决绝大多数数据操作挑战。但在我们讨论它们各自的差异之前，值得说明一下它们的共同点：\n\n第一个参数总是一个数据框。\n后续的参数通常使用变量名（不带引号）来描述要操作的列。\n输出总是一个新的数据框。\n\n因为每个动词都只做好一件事，所以解决复杂问题通常需要组合多个动词，我们将使用管道 |&gt; 来实现这一点。我们将在 Section 3.4 中更多地讨论管道，但简而言之，管道将其左侧的内容传递给右侧的函数，因此 x |&gt; f(y) 等同于 f(x, y)，而 x |&gt; f(y) |&gt; g(z) 等同于 g(f(x, y), z)。管道最简单的发音方式是“然后 (then)”。这使得即使你还没有学习细节，也能对以下代码有一个大致的了解：\n\nflights |&gt;\n    filter(dest == \"IAH\") |&gt;\n    group_by(year, month, day) |&gt;\n    summarize(\n        arr_delay = mean(arr_delay, na.rm = TRUE)\n    )\n\ndplyr 的动词根据它们操作的对象分为四组：行 (rows)、列 (columns)、组 (groups) 或表 (tables)。在接下来的部分中，你将学习针对行、列和组的最重要的动词。然后，我们将在 Chapter 19 中回到处理表的连接动词。让我们开始吧！",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#行",
    "href": "data-transform.html#行",
    "title": "3  数据转换",
    "section": "\n3.2 行",
    "text": "3.2 行\n操作数据集行的最重要的动词是 filter() 和 arrange()。filter() 可以在不改变行顺序的情况下改变哪些行存在，而 arrange() 可以在不改变哪些行存在的情况下改变行的顺序。这两个函数都只影响行，列保持不变。我们还将讨论 distinct()，它能找到具有唯一值的行。与 arrange() 和 filter() 不同，它也可以选择性地修改列。\n\n3.2.1 filter()\n\nfilter() 允许你根据列的值保留行1。第一个参数是数据框。第二个及后续参数是保留行必须满足的条件。例如，我们可以找到所有晚点超过 120 分钟（两小时）起飞的航班：\n\nflights |&gt;\n    filter(dep_delay &gt; 120)\n#&gt; # A tibble: 9,723 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      848           1835       853     1001           1950\n#&gt; 2  2013     1     1      957            733       144     1056            853\n#&gt; 3  2013     1     1     1114            900       134     1447           1222\n#&gt; 4  2013     1     1     1540           1338       122     2020           1825\n#&gt; 5  2013     1     1     1815           1325       290     2120           1542\n#&gt; 6  2013     1     1     1842           1422       260     1958           1535\n#&gt; # ℹ 9,717 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n除了 &gt;（大于），你还可以使用 &gt;=（大于或等于）、&lt;（小于）、&lt;=（小于或等于）、==（等于）和 !=（不等于）。你还可以用 & 或 , 组合条件来表示“与”（检查两个条件），或用 | 来表示“或”（检查任一条件）：\n\n# 1 月 1 日起飞的航班\nflights |&gt;\n    filter(month == 1 & day == 1)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# 1 月或 2 月起飞的航班\nflights |&gt;\n    filter(month == 1 | month == 2)\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n当你组合 | 和 == 时，有一个很有用的快捷方式：%in%。它会保留变量等于右侧值之一的行：\n\n# 一种更短的方式来选择 1 月或 2 月起飞的航班\nflights |&gt;\n    filter(month %in% c(1, 2))\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n我们将在 Chapter 12 中更详细地回到这些比较和逻辑运算符。\n当你运行 filter() 时，dplyr 会执行筛选操作，创建一个新的数据框，然后打印它。它不会修改现有的 flights 数据集，因为 dplyr 函数从不修改它们的输入。要保存结果，你需要使用赋值运算符 &lt;-：\n\njan1 &lt;- flights |&gt;\n    filter(month == 1 & day == 1)\n\n\n3.2.2 常见错误\n当你刚开始使用 R 时，最容易犯的错误是在测试相等性时使用 = 而不是 ==。filter() 会在这种情况下提醒你：\n\nflights |&gt;\n    filter(month = 1)\n#&gt; Error in `filter()`:\n#&gt; ! We detected a named input.\n#&gt; ℹ This usually means that you've used `=` instead of `==`.\n#&gt; ℹ Did you mean `month == 1`?\n\n另一个错误是你像在英语中那样写“或”语句：\n\nflights |&gt;\n    filter(month == 1 | 2)\n\n这在某种意义上是“有效”的，因为它不会抛出错误，但它没有做你想要的事情，因为 | 首先检查条件 month == 1，然后检查条件 2，这不是一个合理的检查条件。我们将在 Section 12.3.2 中学习更多关于这里发生了什么以及为什么会这样。\n\n3.2.3 arrange()\n\narrange() 根据列的值改变行的顺序。它接受一个数据框和一组列名（或更复杂的表达式）作为排序依据。如果你提供多个列名，每个额外的列将用于打破前一列值中的平局。例如，以下代码按出发时间排序，该时间分布在四列中。我们首先得到最早的年份，然后在一年内，最早的月份，依此类推。\n\nflights |&gt;\n    arrange(year, month, day, dep_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n你可以在 arrange() 内部对一列使用 desc()，以按该列的降序（从大到小）重新排序数据框。例如，这段代码按延误时间从多到少对航班进行排序：\n\nflights |&gt;\n    arrange(desc(dep_delay))\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     9      641            900      1301     1242           1530\n#&gt; 2  2013     6    15     1432           1935      1137     1607           2120\n#&gt; 3  2013     1    10     1121           1635      1126     1239           1810\n#&gt; 4  2013     9    20     1139           1845      1014     1457           2210\n#&gt; 5  2013     7    22      845           1600      1005     1044           1815\n#&gt; 6  2013     4    10     1100           1900       960     1342           2211\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n注意行数没有改变——我们只是在排列数据，而不是筛选数据。\n\n3.2.4 distinct()\n\ndistinct() 找到数据集中的所有唯一行，所以从技术上讲，它主要操作行。然而，大多数时候，你会想要一些变量的独特组合，所以你也可以选择性地提供列名：\n\n# 如果有的话，移除重复的行\nflights |&gt;\n    distinct()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# 找到所有唯一的出发地和目的地对\nflights |&gt;\n    distinct(origin, dest)\n#&gt; # A tibble: 224 × 2\n#&gt;   origin dest \n#&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 EWR    IAH  \n#&gt; 2 LGA    IAH  \n#&gt; 3 JFK    MIA  \n#&gt; 4 JFK    BQN  \n#&gt; 5 LGA    ATL  \n#&gt; 6 EWR    ORD  \n#&gt; # ℹ 218 more rows\n\n另外，如果你想在筛选唯一行时保留其他列，你可以使用 .keep_all = TRUE 选项。\n\nflights |&gt;\n    distinct(origin, dest, .keep_all = TRUE)\n#&gt; # A tibble: 224 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 218 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n所有这些不同的航班都在 1 月 1 日并非巧合：distinct() 会找到数据集中唯一行的第一次出现，并丢弃其余的。\n如果你想找到出现的次数，最好将 distinct() 换成 count()。通过 sort = TRUE 参数，你可以按出现次数的降序排列它们。你将在 Section 13.3 中学到更多关于 count 的知识。\n\nflights |&gt;\n    count(origin, dest, sort = TRUE)\n#&gt; # A tibble: 224 × 3\n#&gt;   origin dest      n\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 JFK    LAX   11262\n#&gt; 2 LGA    ATL   10263\n#&gt; 3 LGA    ORD    8857\n#&gt; 4 JFK    SFO    8204\n#&gt; 5 LGA    CLT    6168\n#&gt; 6 EWR    ORD    6100\n#&gt; # ℹ 218 more rows\n\n\n3.2.5 练习\n\n\n在单个管道中，找到满足以下每个条件的所有航班：\n\n到达延误两小时或以上\n飞往休斯顿（IAH 或 HOU）\n由联合航空、美国航空或达美航空运营\n在夏季（七月、八月和九月）出发\n到达延误超过两小时，但起飞没有晚点\n延误至少一小时，但在飞行中弥补了超过 30 分钟的时间\n\n\n对 flights 进行排序，找出起飞延误最长的航班。找出清晨最早离开的航班。\n对 flights 进行排序，找出最快的航班。（提示：尝试在函数内部包含数学计算。）\n2013 年的每一天都有航班吗？\n哪些航班飞行的距离最远？哪些飞行的距离最短？\n如果你同时使用 filter() 和 arrange()，它们的顺序重要吗？为什么/为什么不？思考一下结果以及函数需要做多少工作。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#列",
    "href": "data-transform.html#列",
    "title": "3  数据转换",
    "section": "\n3.3 列",
    "text": "3.3 列\n有四个重要的动词会影响列而不改变行：mutate() 从现有列派生出新列，select() 改变哪些列存在，rename() 改变列的名称，relocate() 改变列的位置。\n\n3.3.1 mutate()\n\nmutate() 的工作是添加从现有列计算出的新列。在数据转换的章节中，你将学习一大堆可以用来操作不同类型变量的函数。现在，我们只使用基本代数，这使我们能够计算 gain（延误航班在空中弥补了多少时间）和 speed（以英里/小时为单位）：\n\nflights |&gt;\n    mutate(\n        gain = dep_delay - arr_delay,\n        speed = distance / air_time * 60\n    )\n#&gt; # A tibble: 336,776 × 21\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n默认情况下，mutate() 会在你数据集的右侧添加新列，这使得很难看到这里发生了什么。我们可以使用 .before 参数将变量添加到左侧2：\n\nflights |&gt;\n    mutate(\n        gain = dep_delay - arr_delay,\n        speed = distance / air_time * 60,\n        .before = 1\n    )\n#&gt; # A tibble: 336,776 × 21\n#&gt;    gain speed  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    -9  370.  2013     1     1      517            515         2      830\n#&gt; 2   -16  374.  2013     1     1      533            529         4      850\n#&gt; 3   -31  408.  2013     1     1      542            540         2      923\n#&gt; 4    17  517.  2013     1     1      544            545        -1     1004\n#&gt; 5    19  394.  2013     1     1      554            600        -6      812\n#&gt; 6   -16  288.  2013     1     1      554            558        -4      740\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\n. 表示 .before 是函数的参数，而不是我们正在创建的第三个新变量的名称。你也可以使用 .after 在某个变量之后添加，并且在 .before 和 .after 中你都可以使用变量名而不是位置。例如，我们可以在 day 之后添加新变量：\n\nflights |&gt;\n    mutate(\n        gain = dep_delay - arr_delay,\n        speed = distance / air_time * 60,\n        .after = day\n    )\n\n另外，你可以用 .keep 参数来控制保留哪些变量。一个特别有用的参数是 \"used\"，它指定我们只保留在 mutate() 步骤中涉及或创建的列。例如，以下输出将只包含 dep_delay、arr_delay、air_time、gain、hours 和 gain_per_hour 这些变量。\n\nflights |&gt;\n    mutate(\n        gain = dep_delay - arr_delay,\n        hours = air_time / 60,\n        gain_per_hour = gain / hours,\n        .keep = \"used\"\n    )\n\n注意，由于我们没有将上述计算的结果赋值回 flights，新变量 gain、hours 和 gain_per_hour 只会被打印出来，而不会存储在数据框中。如果我们希望它们在数据框中可用于将来的使用，我们应该仔细考虑是否希望将结果赋值回 flights，从而覆盖原始的具有更多变量的数据框，还是赋值给一个新对象。通常，正确的答案是一个新对象，其名称应具有信息性以表明其内容，例如 delay_gain，但你也可能有充分的理由覆盖 flights。\n\n3.3.2 select()\n\n得到包含成百上千个变量的数据集并不少见。在这种情况下，第一个挑战通常就是专注于你感兴趣的变量。select() 允许你使用基于变量名称的操作快速地聚焦于一个有用的子集：\n\n\n按名称选择列：\n\nflights |&gt;\nselect(year, month, day)\n\n\n\n选择从 year 到 day 之间的所有列（包括 year 和 day）：\n\nflights |&gt;\nselect(year:day)\n\n\n\n选择除了从 year 到 day 之外的所有列（包括 year 和 day）：\n\nflights |&gt;\nselect(!year:day)\n\n历史上，这个操作是用 - 而不是 ! 来完成的，所以你很可能会在实际应用中看到它。这两个运算符作用相同，但行为上有一些细微的差异。我们推荐使用 !，因为它读作“非 (not)”，并且能很好地与 & 和 | 结合。\n\n\n选择所有字符类型的列：\n\nflights |&gt;\nselect(where(is.character))\n\n\n\n在 select() 中可以使用许多辅助函数：\n\n\nstarts_with(\"abc\")：匹配以 “abc” 开头的名称。\n\nends_with(\"xyz\")：匹配以 “xyz” 结尾的名称。\n\ncontains(\"ijk\")：匹配包含 “ijk” 的名称。\n\nnum_range(\"x\", 1:3)：匹配 x1、x2 和 x3。\n\n更多详情请参见 ?select。一旦你了解了正则表达式（Chapter 15 的主题），你也将能够使用 matches() 来选择匹配模式的变量。\n你可以在 select() 时使用 = 来重命名变量。新名称出现在 = 的左侧，旧变量出现在右侧：\n\nflights |&gt;\n    select(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 1\n#&gt;   tail_num\n#&gt;   &lt;chr&gt;   \n#&gt; 1 N14228  \n#&gt; 2 N24211  \n#&gt; 3 N619AA  \n#&gt; 4 N804JB  \n#&gt; 5 N668DN  \n#&gt; 6 N39463  \n#&gt; # ℹ 336,770 more rows\n\n\n3.3.3 rename()\n\n如果你想保留所有现有的变量，只想重命名少数几个，你可以使用 rename() 而不是 select()：\n\nflights |&gt;\n    rename(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n如果你有一堆命名不一致的列，并且手动修复它们会很痛苦，可以看看 janitor::clean_names()，它提供了一些有用的自动清理功能。\n\n3.3.4 relocate()\n\n使用 relocate() 来移动变量的位置。你可能想把相关的变量收集在一起，或者把重要的变量移到前面。默认情况下，relocate() 会把变量移到最前面：\n\nflights |&gt;\n    relocate(time_hour, air_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;   time_hour           air_time  year month   day dep_time sched_dep_time\n#&gt;   &lt;dttm&gt;                 &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n#&gt; 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n#&gt; 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n#&gt; 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n#&gt; 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n#&gt; 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, …\n\n你也可以使用 .before 和 .after 参数指定将它们放在哪里，就像在 mutate() 中一样：\n\nflights |&gt;\n    relocate(year:dep_time, .after = time_hour)\nflights |&gt;\n    relocate(starts_with(\"arr\"), .before = dep_time)\n\n\n3.3.5 练习\n\n比较 dep_time、sched_dep_time 和 dep_delay。你期望这三个数字之间有什么关系？\n尽可能多地想出从 flights 中选择 dep_time、dep_delay、arr_time 和 arr_delay 的方法。\n如果在 select() 调用中多次指定同一个变量的名称会发生什么？\n\nany_of() 函数是做什么的？为什么它与下面这个向量一起使用可能会有帮助？\n\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\n\n\n运行以下代码的结果是否让你感到惊讶？select 辅助函数默认如何处理大小写？你如何更改该默认设置？\n\nflights |&gt; select(contains(\"TIME\"))\n\n\n将 air_time 重命名为 air_time_min 以表明度量单位，并将其移动到数据框的开头。\n\n为什么以下代码不起作用，这个错误是什么意思？\n\nflights |&gt;\nselect(tailnum) |&gt;\narrange(arr_delay)\n#&gt; Error in `arrange()`:\n#&gt; ℹ In argument: `..1 = arr_delay`.\n#&gt; Caused by error:\n#&gt; ! object 'arr_delay' not found",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-the-pipe",
    "href": "data-transform.html#sec-the-pipe",
    "title": "3  数据转换",
    "section": "\n3.4 管道",
    "text": "3.4 管道\n我们上面已经向你展示了管道的简单示例，但它真正的威力在于你开始组合多个动词时。例如，假设你想找到飞往休斯顿 IAH 机场的最快航班：你需要组合 filter()、mutate()、select() 和 arrange()：\n\nflights |&gt;\n    filter(dest == \"IAH\") |&gt;\n    mutate(speed = distance / air_time * 60) |&gt;\n    select(year:day, dep_time, carrier, flight, speed) |&gt;\n    arrange(desc(speed))\n#&gt; # A tibble: 7,198 × 7\n#&gt;    year month   day dep_time carrier flight speed\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n#&gt; 1  2013     7     9      707 UA         226  522.\n#&gt; 2  2013     8    27     1850 UA        1128  521.\n#&gt; 3  2013     8    28      902 UA        1711  519.\n#&gt; 4  2013     8    28     2122 UA        1022  519.\n#&gt; 5  2013     6    11     1628 UA        1178  515.\n#&gt; 6  2013     8    27     1017 UA         333  515.\n#&gt; # ℹ 7,192 more rows\n\n尽管这个管道有四个步骤，但它很容易浏览，因为动词都出现在每行的开头：从 flights 数据开始，然后筛选，然后派生，然后选择，然后排序。\n如果我们没有管道会怎么样？我们可以将每个函数调用嵌套在前一个调用中：\n\narrange(\n    select(\n        mutate(\n            filter(\n                flights,\n                dest == \"IAH\"\n            ),\n            speed = distance / air_time * 60\n        ),\n        year:day, dep_time, carrier, flight, speed\n    ),\n    desc(speed)\n)\n\n或者我们可以使用一堆中间对象：\n\nflights1 &lt;- filter(flights, dest == \"IAH\")\nflights2 &lt;- mutate(flights1, speed = distance / air_time * 60)\nflights3 &lt;- select(flights2, year:day, dep_time, carrier, flight, speed)\narrange(flights3, desc(speed))\n\n虽然这两种形式都有其适用的场合，但管道通常产生的数据分析代码更易于编写和阅读。\n要在你的代码中添加管道，我们建议使用内置的键盘快捷键 Ctrl/Cmd + Shift + M。你需要对你的 RStudio 选项做一个更改，以使用 |&gt; 而不是 %&gt;%，如 Figure 3.1 所示；关于 %&gt;% 的更多内容稍后介绍。\n\n\n\n\n\n\n\nFigure 3.1: 要插入 |&gt;，请确保勾选了“使用原生管道运算符”选项。\n\n\n\n\n\n\n\n\n\n\nmagrittr\n\n\n\n如果你已经使用 tidyverse 一段时间了，你可能熟悉 magrittr 包提供的 %&gt;% 管道。magrittr 包包含在核心 tidyverse 中，所以你可以在加载 tidyverse 时随时使用 %&gt;%：\n\nlibrary(tidyverse)\n\nmtcars %&gt;%\n    group_by(cyl) %&gt;%\n    summarize(n = n())\n\n在简单的情况下，|&gt; 和 %&gt;% 的行为完全相同。那么为什么我们推荐基础管道呢？首先，因为它是 R 基础包的一部分，所以即使你不使用 tidyverse，它也总是可用的。其次，|&gt; 比 %&gt;% 简单得多：在 %&gt;% 于 2014 年发明和 |&gt; 于 2021 年 R 4.1.0 中被包含之间的时间里，我们对管道有了更好的理解。这使得基础实现可以摒弃不常用和不那么重要的功能。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#分组",
    "href": "data-transform.html#分组",
    "title": "3  数据转换",
    "section": "\n3.5 分组",
    "text": "3.5 分组\n到目前为止，你已经学习了处理行和列的函数。当你加入处理分组的能力时，dplyr 会变得更加强大。在本节中，我们将重点关注最重要的函数：group_by()、summarize() 以及 slice 系列函数。\n\n3.5.1 group_by()\n\n使用 group_by() 将你的数据集划分为对你的分析有意义的组：\n\nflights |&gt;\n    group_by(month)\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   month [12]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\ngroup_by() 不会改变数据，但如果你仔细看输出，你会注意到输出表明它“按月份分组” (Groups: month [12])。这意味着后续操作现在将“按月”工作。group_by() 将这个分组特性（称为类）添加到数据框中，这改变了应用于该数据的后续动词的行为。\n\n3.5.2 summarize()\n\n最重要的分组操作是摘要 (summary)，如果用于计算单个摘要统计量，它会将数据框减少到每个组只有一行。在 dplyr 中，这个操作由 summarize()3 执行，如下例所示，该示例计算了按月份的平均出发延误：\n\nflights |&gt;\n    group_by(month) |&gt;\n    summarize(\n        avg_delay = mean(dep_delay)\n    )\n#&gt; # A tibble: 12 × 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1        NA\n#&gt; 2     2        NA\n#&gt; 3     3        NA\n#&gt; 4     4        NA\n#&gt; 5     5        NA\n#&gt; 6     6        NA\n#&gt; # ℹ 6 more rows\n\n噢！出错了，我们所有的结果都是 NA（发音为“N-A”），这是 R 中表示缺失值的符号。这是因为一些观测到的航班在延误列中有缺失数据，所以当我们计算包含这些值的平均值时，我们得到了 NA 结果。我们将在 Chapter 18 中详细讨论缺失值，但现在，我们将通过将参数 na.rm 设置为 TRUE 来告诉 mean() 函数忽略所有缺失值：\n\nflights |&gt;\n    group_by(month) |&gt;\n    summarize(\n        avg_delay = mean(dep_delay, na.rm = TRUE)\n    )\n#&gt; # A tibble: 12 × 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1      10.0\n#&gt; 2     2      10.8\n#&gt; 3     3      13.2\n#&gt; 4     4      13.9\n#&gt; 5     5      13.0\n#&gt; 6     6      20.8\n#&gt; # ℹ 6 more rows\n\n你可以在一次 summarize() 调用中创建任意数量的摘要。你将在接下来的章节中学到各种有用的摘要，但一个非常有用的摘要是 n()，它返回每个组中的行数：\n\nflights |&gt;\n    group_by(month) |&gt;\n    summarize(\n        avg_delay = mean(dep_delay, na.rm = TRUE),\n        n = n()\n    )\n#&gt; # A tibble: 12 × 3\n#&gt;   month avg_delay     n\n#&gt;   &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1     1      10.0 27004\n#&gt; 2     2      10.8 24951\n#&gt; 3     3      13.2 28834\n#&gt; 4     4      13.9 28330\n#&gt; 5     5      13.0 28796\n#&gt; 6     6      20.8 28243\n#&gt; # ℹ 6 more rows\n\n在数据科学中，平均值和计数能让你走得很远！\n\n3.5.3 slice_ 系列函数\n有五个方便的函数，允许你在每个组内提取特定的行：\n\n\ndf |&gt; slice_head(n = 1) 从每个组中取第一行。\n\ndf |&gt; slice_tail(n = 1) 从每个组中取最后一行。\n\ndf |&gt; slice_min(x, n = 1) 取列 x 值最小的行。\n\ndf |&gt; slice_max(x, n = 1) 取列 x 值最大的行。\n\ndf |&gt; slice_sample(n = 1) 取一个随机行。\n\n你可以改变 n 来选择多于一行，或者用 prop = 0.1 代替 n = 来选择（例如）每个组中 10% 的行。例如，以下代码找到了在每个目的地到达时延误最严重的航班：\n\nflights |&gt;\n    group_by(dest) |&gt;\n    slice_max(arr_delay, n = 1) |&gt;\n    relocate(dest)\n#&gt; # A tibble: 108 × 19\n#&gt; # Groups:   dest [105]\n#&gt;   dest   year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 ABQ    2013     7    22     2145           2007        98      132\n#&gt; 2 ACK    2013     7    23     1139            800       219     1250\n#&gt; 3 ALB    2013     1    25      123           2000       323      229\n#&gt; 4 ANC    2013     8    17     1740           1625        75     2042\n#&gt; 5 ATL    2013     7    22     2257            759       898      121\n#&gt; 6 AUS    2013     7    10     2056           1505       351     2347\n#&gt; # ℹ 102 more rows\n#&gt; # ℹ 11 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\n注意这里有 105 个目的地，但我们得到了 108 行。怎么回事？slice_min() 和 slice_max() 会保留值相同的行，所以 n = 1 意味着给我们所有具有最高值的行。如果你希望每个组只得到一行，你可以设置 with_ties = FALSE。\n这类似于用 summarize() 计算最大延误，但你得到的是整个对应的行（如果值相同则有多行），而不是单个摘要统计量。\n\n3.5.4 按多个变量分组\n你可以使用多个变量来创建组。例如，我们可以为每个日期创建一个组。\n\ndaily &lt;- flights |&gt;\n    group_by(year, month, day)\ndaily\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n当你对按多个变量分组的 tibble 进行摘要时，每个摘要都会剥离最后一个分组。事后看来，这不是一个让这个函数工作的很好方式，但在不破坏现有代码的情况下很难改变。为了清楚地说明发生了什么，dplyr 显示了一条消息，告诉你如何改变这种行为：\n\ndaily_flights &lt;- daily |&gt;\n    summarize(n = n())\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n\n如果你对这种行为感到满意，你可以明确请求它以抑制该消息：\n\ndaily_flights &lt;- daily |&gt;\n    summarize(\n        n = n(),\n        .groups = \"drop_last\"\n    )\n\n或者，通过设置不同的值来更改默认行为，例如，\"drop\" 用于删除所有分组，或 \"keep\" 用于保留相同的分组。\n\n3.5.5 取消分组\n你可能还想在不使用 summarize() 的情况下从数据框中移除分组。你可以使用 ungroup() 来做到这一点。\n\ndaily |&gt;\n    ungroup()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n现在让我们看看当你对一个未分组的数据框进行摘要时会发生什么。\n\ndaily |&gt;\n    ungroup() |&gt;\n    summarize(\n        avg_delay = mean(dep_delay, na.rm = TRUE),\n        flights = n()\n    )\n#&gt; # A tibble: 1 × 2\n#&gt;   avg_delay flights\n#&gt;       &lt;dbl&gt;   &lt;int&gt;\n#&gt; 1      12.6  336776\n\n你得到了一行，因为 dplyr 将未分组数据框中的所有行都视为属于一个组。\n\n3.5.6 .by\n\ndplyr 1.1.0 包含了一种新的、实验性的、用于按操作分组的语法，即 .by 参数。group_by() 和 ungroup() 不会消失，但你现在也可以使用 .by 参数在单个操作内进行分组：\n\nflights |&gt;\n    summarize(\n        delay = mean(dep_delay, na.rm = TRUE),\n        n = n(),\n        .by = month\n    )\n\n或者，如果你想按多个变量分组：\n\nflights |&gt;\n    summarize(\n        delay = mean(dep_delay, na.rm = TRUE),\n        n = n(),\n        .by = c(origin, dest)\n    )\n\n.by 适用于所有动词，并且它的优点是，你不需要使用 .groups 参数来抑制分组消息，或者在完成后使用 ungroup()。\n我们在本章中没有重点介绍这种语法，因为在我们写书时它还很新。我们想提一下它，因为我们认为它有很大的潜力，很可能会非常流行。你可以在 dplyr 1.1.0 博客文章中了解更多关于它的信息。\n\n3.5.7 练习\n\n哪个航空公司的平均延误最严重？挑战：你能分清是机场不好还是航空公司不好的影响吗？为什么/为什么不？（提示：想想 flights |&gt; group_by(carrier, dest) |&gt; summarize(n())）\n找出从每个目的地出发时延误最严重的航班。\n延误在一天中是如何变化的？用图表来说明你的答案。\n如果你向 slice_min() 及类似函数提供一个负的 n 会发生什么？\n用你刚学过的 dplyr 动词解释 count() 的作用。count() 的 sort 参数是做什么的？\n\n假设我们有以下这个小数据框：\n\ndf &lt;- tibble(\nx = 1:5,\ny = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\nz = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\n\n\n写下你认为输出会是什么样子，然后检查你是否正确，并描述 group_by() 的作用。\n\n\ndf |&gt;\n  group_by(y)\n\n\nb.  写下你认为输出会是什么样子，然后检查你是否正确，并描述 `arrange()` 的作用。另外，评论它与 (a) 部分中的 `group_by()` 有何不同。\n\n\ndf |&gt;\n  arrange(y)\n\n\nc.  写下你认为输出会是什么样子，然后检查你是否正确，并描述这个管道的作用。\n\n\ndf |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\n\n\nd.  写下你认为输出会是什么样子，然后检查你是否正确，并描述这个管道的作用。然后，评论消息说了什么。\n\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\n\n写下你认为输出会是什么样子，然后检查你是否正确，并描述这个管道的作用。它的输出与 (d) 部分的输出有何不同？\n\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\n\n写下你认为输出会是什么样子，然后检查你是否正确，并描述每个管道的作用。这两个管道的输出有何不同？\n\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  mutate(mean_x = mean(x))",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-sample-size",
    "href": "data-transform.html#sec-sample-size",
    "title": "3  数据转换",
    "section": "\n3.6 案例",
    "text": "3.6 案例\n每当你进行任何聚合操作时，包含一个计数（n()）总是一个好主意。这样，你可以确保你不是基于非常少量的数据得出结论。我们将用 Lahman 包中的一些棒球数据来演示这一点。具体来说，我们将比较一个球员击中安打（H）的比例与他们尝试将球打入场内（AB）的次数：\n\nbatters &lt;- Lahman::Batting |&gt;\n    group_by(playerID) |&gt;\n    summarize(\n        performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),\n        n = sum(AB, na.rm = TRUE)\n    )\nbatters\n#&gt; # A tibble: 20,730 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 aardsda01      0          4\n#&gt; 2 aaronha01      0.305  12364\n#&gt; 3 aaronto01      0.229    944\n#&gt; 4 aasedo01       0          5\n#&gt; 5 abadan01       0.0952    21\n#&gt; 6 abadfe01       0.111      9\n#&gt; # ℹ 20,724 more rows\n\n当我们绘制击球手的技术水平（用击球率 performance 衡量）与击球机会次数（用打数 n 衡量）的关系图时，你会看到两种模式：\n\n在打数较少的球员中，performance 的变异更大。这个图的形状非常有特点：每当你绘制平均值（或其他摘要统计量）与组大小时，你都会看到随着样本量的增加，变异会减小4。\n技术水平 (performance) 和击球机会 (n) 之间存在正相关关系，因为球队希望给他们最好的击球手最多的击球机会。\n\n\nbatters |&gt;\n    filter(n &gt; 100) |&gt;\n    ggplot(aes(x = n, y = performance)) +\n    geom_point(alpha = 1 / 10) +\n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n注意 ggplot2 和 dplyr 组合使用的便捷模式。你只需要记住从用于数据处理的 |&gt; 切换到用于向图表添加图层的 +。\n这对排名也有重要影响。如果你天真地按 desc(performance) 排序，击球率最高的人显然是那些尝试将球打入场内次数很少且碰巧击中安打的人，他们不一定是最有技术的球员：\n\nbatters |&gt;\n    arrange(desc(performance))\n#&gt; # A tibble: 20,730 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 abramge01           1     1\n#&gt; 2 alberan01           1     1\n#&gt; 3 banisje01           1     1\n#&gt; 4 bartocl01           1     1\n#&gt; 5 bassdo01            1     1\n#&gt; 6 birasst01           1     2\n#&gt; # ℹ 20,724 more rows\n\n你可以在 http://varianceexplained.org/r/empirical_bayes_baseball/ 和 https://www.evanmiller.org/how-not-to-sort-by-average-rating.html 找到对这个问题以及如何克服它的很好解释。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#小结",
    "href": "data-transform.html#小结",
    "title": "3  数据转换",
    "section": "\n3.7 小结",
    "text": "3.7 小结\n在本章中，你学习了 dplyr 为处理数据框提供的工具。这些工具大致分为三类：操作行的（如 filter() 和 arrange()），操作列的（如 select() 和 mutate()），以及操作分组的（如 group_by() 和 summarize()）。在本章中，我们重点关注了这些“整个数据框”的工具，但你还没有学到太多关于可以对单个变量做什么的知识。我们将在本书的“转换”部分回到这个问题，其中每一章都为特定类型的变量提供工具。\n在下一章中，我们将转回工作流程，讨论代码风格的重要性以及保持代码良好组织，以便你和他人都能轻松阅读和理解。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "data-transform.html#footnotes",
    "href": "data-transform.html#footnotes",
    "title": "3  数据转换",
    "section": "",
    "text": "稍后，你将学习 slice_*() 系列函数，它允许你根据行的位置选择行。↩︎\n记住，在 RStudio 中，查看多列数据集最简单的方法是 View()。↩︎\n或者 summarise()，如果你更喜欢英式英语。↩︎\n大数定律。↩︎",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>数据转换</span>"
    ]
  },
  {
    "objectID": "workflow-style.html",
    "href": "workflow-style.html",
    "title": "4  工作流：代码风格",
    "section": "",
    "text": "4.1 命名\n良好的代码风格就像正确的标点符号：没有它也能行，但它确实能让内容更容易阅读。 即使是编程新手，也应该努力培养良好的代码风格。 使用一致的风格可以让其他人 (包括未来的你！) 更容易读懂你的代码，当需要从他人那里获得帮助时，这一点尤为重要。 本章将介绍 tidyverse 风格指南 中最重要的几点，本书通篇都使用了该风格。\n一开始，对代码进行风格化会让你觉得有点乏味，但只要多加练习，它很快就会成为你的第二天性。 此外，还有一些很棒的工具可以快速重塑现有代码的风格，比如 Lorenz Walthert 开发的 styler 包。 用 install.packages(\"styler\") 安装它之后，一个简便的使用方法是通过 RStudio 的命令面板 (command palette)。 命令面板可以让你使用任何内置的 RStudio 命令以及许多由包提供的插件。 按 Cmd/Ctrl + Shift + P 打开命令面板，然后输入 “styler” 就可以看到 styler 提供的所有快捷方式。 Figure 4.1 展示了结果。\n在本章的代码示例中，我们将使用 tidyverse 和 nycflights13 包。\n我们在 Section 2.3 中简要讨论过命名。 记住，变量名 (用 &lt;- 创建的和用 mutate() 创建的) 应该只使用小写字母、数字和 _。 使用 _ 来分隔名称中的单词。\n# 提倡：\nshort_flights &lt;- flights |&gt; filter(air_time &lt; 60)\n\n# 避免：\nSHORTFLIGHTS &lt;- flights |&gt; filter(air_time &lt; 60)\n作为一条通用经验法则，最好是选择易于理解的长描述性名称，而不是为了输入快捷而使用简洁的名称。 在编写代码时，短名称节省的时间相对较少 (特别是因为自动补全会帮你完成输入)，但当你回过头来看旧代码时，却可能要花很多时间去琢磨一个晦涩的缩写。\n如果你有一组相关事物的名称，请尽量保持一致。 当你忘记了之前的约定，不一致的情况就很容易出现，所以如果你需要回去重命名一些东西，不要觉得不好意思。 总的来说，如果你有一组属于同一主题的变量，最好给它们一个共同的前缀，而不是共同的后缀，因为自动补全在变量的开头部分效果最好。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#空格",
    "href": "workflow-style.html#空格",
    "title": "4  工作流：代码风格",
    "section": "\n4.2 空格",
    "text": "4.2 空格\n在数学运算符的两侧都要加上空格，除了 ^ (即 +、-、==、&lt; 等)，在赋值运算符 (&lt;-) 的两侧也要加上空格。\n\n# 提倡：\nz &lt;- (a + b)^2 / d\n\n# 避免：\nz &lt;- (a + b)^2 / d\n\n在常规函数调用的括号内外不要加空格。 逗号后面要始终加一个空格，就像标准的英语书写一样。\n\n# 提倡：\nmean(x, na.rm = TRUE)\n\n# 避免：\nmean(x, na.rm = TRUE)\n\n如果能改善对齐，可以添加额外的空格。 例如，如果你在 mutate() 中创建多个变量，你可能想添加空格以便所有的 = 对齐。1 这让代码更容易浏览。\n\nflights |&gt;\n    mutate(\n        speed      = distance / air_time,\n        dep_hour   = dep_time %/% 100,\n        dep_minute = dep_time %% 100\n    )",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#sec-pipes",
    "href": "workflow-style.html#sec-pipes",
    "title": "4  工作流：代码风格",
    "section": "\n4.3 管道",
    "text": "4.3 管道\n|&gt; 前面应该总有一个空格，并且通常应该是一行的最后一个字符。 这使得添加新步骤、重新排列现有步骤、修改步骤中的元素以及通过浏览左侧的动词来获得宏观视角都变得更加容易。\n\n# 提倡：\nflights |&gt;\n    filter(!is.na(arr_delay), !is.na(tailnum)) |&gt;\n    count(dest)\n\n# 避免：\nflights |&gt;\n    filter(!is.na(arr_delay), !is.na(tailnum)) |&gt;\n    count(dest)\n\n如果你正在管道输送到的函数有命名参数 (如 mutate() 或 summarize())，请将每个参数放在新的一行。 如果函数没有命名参数 (如 select() 或 filter())，请将所有内容保持在一行，除非一行放不下，此时你应该将每个参数放在它自己的一行。\n\n# 提倡：\nflights |&gt;\n    group_by(tailnum) |&gt;\n    summarize(\n        delay = mean(arr_delay, na.rm = TRUE),\n        n = n()\n    )\n\n# 避免：\nflights |&gt;\n    group_by(\n        tailnum\n    ) |&gt;\n    summarize(delay = mean(arr_delay, na.rm = TRUE), n = n())\n\n在管道的第一步之后，每一行都缩进两个空格。 在 |&gt; 后的换行符处，RStudio 会自动为你添加空格。 如果你将每个参数放在单独的一行，则再额外缩进两个空格。 确保 ) 在它自己的一行，并且不缩进，与函数名的水平位置对齐。\n\n# 提倡：\nflights |&gt;\n    group_by(tailnum) |&gt;\n    summarize(\n        delay = mean(arr_delay, na.rm = TRUE),\n        n = n()\n    )\n\n# 避免：\nflights |&gt;\n    group_by(tailnum) |&gt;\n    summarize(\n        delay = mean(arr_delay, na.rm = TRUE),\n        n = n()\n    )\n\n# 避免：\nflights |&gt;\n    group_by(tailnum) |&gt;\n    summarize(\n        delay = mean(arr_delay, na.rm = TRUE),\n        n = n()\n    )\n\n如果你的管道能很轻松地放在一行里，那么可以不遵循这些规则中的某几条。 但根据我们的集体经验，短小的代码片段常常会变长，所以从一开始就留出足够的垂直空间，从长远来看通常会节省时间。\n\n# 这能紧凑地放在一行\ndf |&gt; mutate(y = x + 1)\n\n# 而这样虽然占用了 4 倍的行数，但未来很容易扩展到更多变量和更多步骤\ndf |&gt;\n    mutate(\n        y = x + 1\n    )\n\n最后，要警惕编写非常长的管道，比如超过 10-15 行。 尝试将它们分解成更小的子任务，并给每个任务一个信息丰富的名称。 这些名称将有助于提示读者正在发生什么，并使得检查中间结果是否符合预期变得更容易。 只要你能给某样东西起一个信息丰富的名字，你就应该这样做，例如，当你从根本上改变了数据的结构时 (比如在透视或汇总之后)。 不要指望一次就能做对！ 这意味着如果存在可以获得好名称的中间状态，就应该把长管道拆分开。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#ggplot2",
    "href": "workflow-style.html#ggplot2",
    "title": "4  工作流：代码风格",
    "section": "\n4.4 ggplot2",
    "text": "4.4 ggplot2\n适用于管道的基本规则同样适用于 ggplot2；只需将 + 当作 |&gt; 一样处理即可。\n\nflights |&gt;\n    group_by(month) |&gt;\n    summarize(\n        delay = mean(arr_delay, na.rm = TRUE)\n    ) |&gt;\n    ggplot(aes(x = month, y = delay)) +\n    geom_point() +\n    geom_line()\n\n同样，如果你无法将函数的所有参数放在一行，就将每个参数放在单独的一行：\n\nflights |&gt;\n    group_by(dest) |&gt;\n    summarize(\n        distance = mean(distance),\n        speed = mean(distance / air_time, na.rm = TRUE)\n    ) |&gt;\n    ggplot(aes(x = distance, y = speed)) +\n    geom_smooth(\n        method = \"loess\",\n        span = 0.5,\n        se = FALSE,\n        color = \"white\",\n        linewidth = 4\n    ) +\n    geom_point()\n\n注意从 |&gt; 到 + 的转换。 我们希望这种转换没有必要，但不幸的是，ggplot2 是在管道被发现之前编写的。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#分节注释",
    "href": "workflow-style.html#分节注释",
    "title": "4  工作流：代码风格",
    "section": "\n4.5 分节注释",
    "text": "4.5 分节注释\n当你的脚本变得越来越长时，你可以使用分节 (sectioning) 注释将你的文件分成易于管理的小块：\n\n# 加载数据 --------------------------------------\n\n# 绘制数据 --------------------------------------\n\nRStudio 提供了一个创建这些标题的键盘快捷键 (Cmd/Ctrl + Shift + R)，并会在编辑器左下角的代码导航下拉菜单中显示它们，如 Figure 4.2 所示。\n\n\n\n\n\n\n\nFigure 4.2: 向脚本添加分节注释后，你可以使用脚本编辑器左下角的代码导航工具轻松地跳转到它们。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#练习",
    "href": "workflow-style.html#练习",
    "title": "4  工作流：代码风格",
    "section": "\n4.6 练习",
    "text": "4.6 练习\n\n\n按照上面的指导原则，重新调整以下管道的风格。\n\nflights |&gt;\nfilter(dest == \"IAH\") |&gt;\ngroup_by(year, month, day) |&gt;\nsummarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n) |&gt;\nfilter(n &gt; 10)\n\nflights |&gt;\nfilter(carrier == \"UA\", dest %in% c(\"IAH\", \"HOU\"), sched_dep_time &gt;\n    0900, sched_arr_time &lt; 2000) |&gt;\ngroup_by(flight) |&gt;\nsummarize(delay = mean(\n    arr_delay,\n    na.rm = TRUE\n), cancelled = sum(is.na(arr_delay)), n = n()) |&gt;\nfilter(n &gt; 10)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#小结",
    "href": "workflow-style.html#小结",
    "title": "4  工作流：代码风格",
    "section": "\n4.7 小结",
    "text": "4.7 小结\n在本章中，你学习了代码风格最重要的原则。 起初，这些可能感觉像是一套武断的规则 (因为它们确实是！)，但随着时间的推移，当你编写更多代码并与更多人共享代码时，你就会明白一致的风格有多么重要。 别忘了 styler 包：它是一种快速改善风格不佳代码质量的好方法。\n在下一章中，我们将切换回数据科学工具，学习有关整洁数据 (tidy data) 的知识。 整洁数据是一种组织数据框的一致方式，整个 tidyverse 都在使用它。 这种一致性使你的生活更轻松，因为一旦你拥有了整洁数据，它就可以与绝大多数 tidyverse 函数一起工作。 当然，生活从来都不是一帆风顺的，你在现实世界中遇到的大多数数据集都不会是现成整洁的。 所以我们还将教你如何使用 tidyr 包来整理你的不整洁数据。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#footnotes",
    "href": "workflow-style.html#footnotes",
    "title": "4  工作流：代码风格",
    "section": "",
    "text": "由于 dep_time 的格式是 HMM 或 HHMM，我们使用整数除法 (%/%) 来获取小时，使用求余 (也称为模运算，%%) 来获取分钟。↩︎",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>工作流：代码风格</span>"
    ]
  },
  {
    "objectID": "data-tidy.html",
    "href": "data-tidy.html",
    "title": "5  数据整理",
    "section": "",
    "text": "5.1 引言\n在本章中，你将学习一种使用名为整洁数据 (tidy data) 的系统来在 R 中一致地组织数据的方法。将数据转换成这种格式需要一些前期工作，但从长远来看，这些工作是值得的。一旦你有了整洁的数据和 tidyverse 中各个包提供的整洁工具，你将花更少的时间在不同表示形式之间转换数据，从而能将更多时间用于你所关心的数据问题上。\n在本章中，你将首先学习整洁数据的定义，并看到它如何应用于一个简单的示例数据集。然后，我们将深入探讨你将用于整理数据的主要工具：转换 (pivoting)。转换可以让你在不改变任何值的情况下改变数据的形态。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据整理</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#引言",
    "href": "data-tidy.html#引言",
    "title": "5  数据整理",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.”\n— Leo Tolstoy\n“幸福的家庭都是相似的；不幸的家庭各有各的不幸。”   — 列夫·托尔斯泰\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.”\n— Hadley Wickham\n“整洁的数据集都是相似的，但每个凌乱的数据集各有各的凌乱。”\n— 哈德利·威克姆\n\n\n\n\n5.1.1 先决条件\n在本章中，我们将重点关注 tidyr，这是一个提供了大量工具来帮助你整理凌乱数据集的包。tidyr 是核心 tidyverse 的成员之一。\n\nlibrary(tidyverse)\n\n从本章开始，我们将抑制 library(tidyverse) 加载时显示的消息。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据整理</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-tidy-data",
    "href": "data-tidy.html#sec-tidy-data",
    "title": "5  数据整理",
    "section": "\n5.2 整洁数据",
    "text": "5.2 整洁数据\n你可以用多种方式来表示相同的基础数据。下面的例子展示了用三种不同方式组织的相同数据。每个数据集都显示了四个变量的相同值：country (国家)、year (年份)、population (人口) 和记录在案的 cases (结核病案例) 数量，但每个数据集以不同的方式组织这些值。\n\ntable1\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\ntable2\n#&gt; # A tibble: 12 × 4\n#&gt;   country      year type           count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999 cases            745\n#&gt; 2 Afghanistan  1999 population  19987071\n#&gt; 3 Afghanistan  2000 cases           2666\n#&gt; 4 Afghanistan  2000 population  20595360\n#&gt; 5 Brazil       1999 cases          37737\n#&gt; 6 Brazil       1999 population 172006362\n#&gt; # ℹ 6 more rows\n\ntable3\n#&gt; # A tibble: 6 × 3\n#&gt;   country      year rate             \n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n#&gt; 1 Afghanistan  1999 745/19987071     \n#&gt; 2 Afghanistan  2000 2666/20595360    \n#&gt; 3 Brazil       1999 37737/172006362  \n#&gt; 4 Brazil       2000 80488/174504898  \n#&gt; 5 China        1999 212258/1272915272\n#&gt; 6 China        2000 213766/1280428583\n\n这些都是相同基础数据的表示形式，但它们的使用便利性并不相同。其中之一，table1，在 tidyverse 中使用起来会容易得多，因为它是整洁的 (tidy)。\n有三条相互关联的规则可以使一个数据集变得整洁：\n\n每个变量是一列；每列是一个变量。\n每个观测是一行；每行是一个观测。\n每个值是一个单元格；每个单元格是一个值。\n\nFigure 5.1 直观地展示了这些规则。\n\n\n\n\n\n\n\nFigure 5.1: 以下三条规则构成一个整洁的数据集：变量是列，观测是行，值是单元格。\n\n\n\n\n为什么需要确保你的数据是整洁的呢？主要有两个优点：\n\n选择一种一致的方式来存储数据具有普遍的优势。如果你有了一致的数据结构，学习使用与之配套的工具就会更容易，因为它们具有内在的一致性。\n将变量放在列中有其特殊的优势，因为这能让 R 的向量化特性大放异彩。正如你在 Section 3.3.1 和 Section 3.5.2 中学到的，大多数内置的 R 函数都处理值的向量。这使得转换整洁数据感觉特别自然。\n\ndplyr、ggplot2 以及 tidyverse 中的所有其他包都是为处理整洁数据而设计的。以下是一些小例子，展示了你可能会如何使用 table1。\n\n# 计算每万人的比率\ntable1 |&gt;\n  mutate(rate = cases / population * 10000)\n#&gt; # A tibble: 6 × 5\n#&gt;   country      year  cases population  rate\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071 0.373\n#&gt; 2 Afghanistan  2000   2666   20595360 1.29 \n#&gt; 3 Brazil       1999  37737  172006362 2.19 \n#&gt; 4 Brazil       2000  80488  174504898 4.61 \n#&gt; 5 China        1999 212258 1272915272 1.67 \n#&gt; 6 China        2000 213766 1280428583 1.67\n\n# 计算每年的总病例数\ntable1 |&gt; \n  group_by(year) |&gt; \n  summarize(total_cases = sum(cases))\n#&gt; # A tibble: 2 × 2\n#&gt;    year total_cases\n#&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1  1999      250740\n#&gt; 2  2000      296920\n\n# 可视化随时间的变化\nggplot(table1, aes(x = year, y = cases)) +\n  geom_line(aes(group = country), color = \"grey50\") +\n  geom_point(aes(color = country, shape = country)) +\n  scale_x_continuous(breaks = c(1999, 2000)) # x 轴刻度在 1999 和 2000\n\n\n\n\n\n\n\n\n5.2.1 练习\n\n对于每个示例表格，描述每个观测和每列代表什么。\n\n简要描述你将如何为 table2 和 table3 计算 rate 的过程。你需要执行四个操作：\n\n提取每个国家每年的结核病病例数。\n提取每个国家每年匹配的人口数。\n将病例数除以人口数，然后乘以 10000。\n将结果存回适当的位置。\n\n你还没有学到实际执行这些操作所需的所有函数，但你应该能够思考出你需要的转换过程。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据整理</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-pivoting",
    "href": "data-tidy.html#sec-pivoting",
    "title": "5  数据整理",
    "section": "\n5.3 拉长数据",
    "text": "5.3 拉长数据\n整洁数据的原则可能看起来如此显而易见，以至于你可能会怀疑自己是否会遇到不整洁的数据集。然而，不幸的是，大多数真实数据都是不整洁的。主要有两个原因：\n\n数据的组织方式通常是为了方便某些分析之外的目标。例如，为了方便数据录入而非分析而组织数据是很常见的。\n大多数人并不熟悉整洁数据的原则，除非你花大量时间处理数据，否则很难自己推导出这些原则。\n\n这意味着大多数真实的分析至少需要一些整理工作。你将从弄清楚基础的变量和观测是什么开始。有时这很容易；其他时候你可能需要咨询最初生成数据的人。接下来，你将转换 (pivot) 你的数据，使其成为变量在列、观测在行的整洁形式。\ntidyr 提供了两个用于转换数据的函数：pivot_longer() 和 pivot_wider()。我们先从 pivot_longer() 开始，因为这是最常见的情况。让我们来看一些例子。\n\n5.3.1 列名中包含数据\nbillboard 数据集记录了 2000 年歌曲的广告牌排名：\n\nbillboard\n#&gt; # A tibble: 317 × 79\n#&gt;   artist       track               date.entered   wk1   wk2   wk3   wk4   wk5\n#&gt;   &lt;chr&gt;        &lt;chr&gt;               &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac        Baby Don't Cry (Ke… 2000-02-26      87    82    72    77    87\n#&gt; 2 2Ge+her      The Hardest Part O… 2000-09-02      91    87    92    NA    NA\n#&gt; 3 3 Doors Down Kryptonite          2000-04-08      81    70    68    67    66\n#&gt; 4 3 Doors Down Loser               2000-10-21      76    76    72    69    67\n#&gt; 5 504 Boyz     Wobble Wobble       2000-04-15      57    34    25    17    17\n#&gt; 6 98^0         Give Me Just One N… 2000-08-19      51    39    34    26    26\n#&gt; # ℹ 311 more rows\n#&gt; # ℹ 71 more variables: wk6 &lt;dbl&gt;, wk7 &lt;dbl&gt;, wk8 &lt;dbl&gt;, wk9 &lt;dbl&gt;, …\n\n在这个数据集中，每个观测是一首歌。前三列 (artist, track 和 date.entered) 是描述歌曲的变量。然后我们有 76 列 (wk1-wk76) 描述了歌曲在每周的排名1。在这里，列名是一个变量 (周，week)，而单元格的值是另一个变量 (排名，rank)。\n为了整理这个数据，我们将使用 pivot_longer()：\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\"\n  )\n#&gt; # A tibble: 24,092 × 5\n#&gt;    artist track                   date.entered week   rank\n#&gt;    &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt;  1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt;  2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt;  3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt;  4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt;  5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt;  6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt;  7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n#&gt;  8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n#&gt;  9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n#&gt; 10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n#&gt; # ℹ 24,082 more rows\n\n在数据之后，有三个关键参数：\n\n\ncols 指定哪些列需要被转换，即哪些列不是变量。这个参数使用与 select() 相同的语法，所以在这里我们可以使用 !c(artist, track, date.entered) 或 starts_with(\"wk\")。\n\nnames_to 为存储在列名中的变量命名，我们将其命名为 week。\n\nvalues_to 为存储在单元格值中的变量命名，我们将其命名为 rank。\n\n请注意，在代码中 \"week\" 和 \"rank\" 是带引号的，因为它们是我们正在创建的新变量，在运行 pivot_longer() 调用时它们还不存在于数据中。\n现在让我们把注意力转向结果中这个更长的数据框。如果一首歌在前 100 名的时间少于 76 周会发生什么？以 2 Pac 的 “Baby Don’t Cry” 为例。上面的输出表明它只在前 100 名中待了 7 周，所有剩余的周都用缺失值填充。这些 NA 并不真正代表未知的观测；它们是被数据集的结构强制存在的2，所以我们可以通过设置 values_drop_na = TRUE 来让 pivot_longer() 移除它们：\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  )\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered week   rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt; # ℹ 5,301 more rows\n\n现在行数少了很多，这表明许多带有 NA 的行被删除了。\n你可能还会想，如果一首歌在前 100 名的时间超过 76 周会发生什么？我们无法从这些数据中得知，但你可能会猜到，数据集中会添加额外的列 wk77、wk78……\n这个数据现在是整洁的了，但我们可以通过使用 mutate() 和 readr::parse_number() 将 week 的值从字符字符串转换为数字，来使未来的计算更容易一些。parse_number() 是一个方便的函数，它会从字符串中提取第一个数字，忽略所有其他文本。\n\nbillboard_longer &lt;- billboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  ) |&gt; \n  mutate(\n    week = parse_number(week)\n  )\nbillboard_longer\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered  week  rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26       1    87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26       2    82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26       3    72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26       4    77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26       5    87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26       6    94\n#&gt; # ℹ 5,301 more rows\n\n现在我们把所有的周数都放在一个变量里，所有的排名值都放在另一个变量里，我们就很方便地可以可视化歌曲排名随时间的变化了。代码如下所示，结果在 Figure 5.2 中。我们可以看到，很少有歌曲在前 100 名中停留超过 20 周。\n\nbillboard_longer |&gt; \n  ggplot(aes(x = week, y = rank, group = track)) + \n  geom_line(alpha = 0.25) + \n  scale_y_reverse()\n\n\n\n\n\n\nFigure 5.2: 一个折线图，显示了歌曲排名随时间的变化。\n\n\n\n\n\n5.3.2 转换是如何工作的？\n现在你已经看到了我们如何使用转换来重塑数据，让我们花一点时间来直观地理解转换对数据做了什么。让我们从一个非常简单的数据集开始，以便更容易地看到发生了什么。假设我们有三个病人，id 分别是 A、B 和 C，我们对每个病人进行了两次血压测量。我们将用 tribble() 创建数据，这是一个方便手动构建小型 tibble 的函数：\n\ndf &lt;- tribble(\n  ~id,  ~bp1, ~bp2,\n   \"A\",   100,  120,\n   \"B\",   140,  115,\n   \"C\",   120,  125\n)\n\n我们希望我们的新数据集有三个变量：id (已存在)、measurement (测量，即列名) 和 value (值，即单元格值)。为了实现这一点，我们需要将 df 拉长：\n\ndf |&gt; \n  pivot_longer(\n    cols = bp1:bp2,\n    names_to = \"measurement\",\n    values_to = \"value\"\n  )\n#&gt; # A tibble: 6 × 3\n#&gt;   id    measurement value\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 A     bp1           100\n#&gt; 2 A     bp2           120\n#&gt; 3 B     bp1           140\n#&gt; 4 B     bp2           115\n#&gt; 5 C     bp1           120\n#&gt; 6 C     bp2           125\n\n重塑是如何工作的呢？如果我们逐列思考，就更容易理解了。如 Figure 5.3 所示，原始数据集中已经是变量的列中的值 (id) 需要被重复，每个被转换的列重复一次。\n\n\n\n\n\n\n\nFigure 5.3: 已经是变量的列需要被重复，每个被转换的列重复一次。\n\n\n\n\n列名会成为一个新变量中的值，该新变量的名称由 names_to 定义，如 Figure 5.4 所示。它们需要为原始数据集中的每一行重复一次。\n\n\n\n\n\n\n\nFigure 5.4: 被转换列的列名成为新列中的值。这些值需要为原始数据集的每一行重复一次。\n\n\n\n\n单元格的值也成为一个新变量中的值，其名称由 values_to 定义。它们被逐行展开。Figure 5.5 展示了这个过程。\n\n\n\n\n\n\n\nFigure 5.5: 值的数量被保留（不重复），但被逐行展开。\n\n\n\n\n\n5.3.3 列名中包含多个变量\n一个更具挑战性的情况是，当你的列名中塞入了多条信息，而你希望将这些信息存储在不同的新变量中时。例如，拿 who2 数据集来说，这是你上面看到的 table1 及其他表格的来源：\n\nwho2\n#&gt; # A tibble: 7,240 × 58\n#&gt;   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980       NA        NA        NA        NA        NA\n#&gt; 2 Afghanistan  1981       NA        NA        NA        NA        NA\n#&gt; 3 Afghanistan  1982       NA        NA        NA        NA        NA\n#&gt; 4 Afghanistan  1983       NA        NA        NA        NA        NA\n#&gt; 5 Afghanistan  1984       NA        NA        NA        NA        NA\n#&gt; 6 Afghanistan  1985       NA        NA        NA        NA        NA\n#&gt; # ℹ 7,234 more rows\n#&gt; # ℹ 51 more variables: sp_m_5564 &lt;dbl&gt;, sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, …\n\n这个由世界卫生组织收集的数据集记录了关于结核病诊断的信息。有两列已经是变量并且很容易解释：country 和 year。它们后面跟着 56 列，如 sp_m_014、ep_m_4554 和 rel_m_3544。如果你盯着这些列足够长的时间，你会注意到一个模式。每个列名都由三部分组成，用 _ 分隔。第一部分，sp/rel/ep，描述了诊断所用的方法；第二部分，m/f 是 gender (性别，在这个数据集中编码为二元变量)；第三部分，014/1524/2534/3544/4554/5564/65 是 age (年龄) 范围 (例如，014 代表 0-14 岁)。\n所以在这种情况下，我们在 who2 中记录了六条信息：国家和年份 (已经是列)；诊断方法、性别类别和年龄范围类别 (包含在其他列名中)；以及该类别中的患者计数 (单元格值)。为了将这六条信息组织在六个独立的列中，我们使用 pivot_longer()，并为 names_to 提供一个列名向量，为 names_sep 提供将原始变量名拆分成块的指令，以及为 values_to 提供一个列名：\n\nwho2 |&gt; \n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"), \n    names_sep = \"_\",\n    values_to = \"count\"\n  )\n#&gt; # A tibble: 405,440 × 6\n#&gt;   country      year diagnosis gender age   count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980 sp        m      014      NA\n#&gt; 2 Afghanistan  1980 sp        m      1524     NA\n#&gt; 3 Afghanistan  1980 sp        m      2534     NA\n#&gt; 4 Afghanistan  1980 sp        m      3544     NA\n#&gt; 5 Afghanistan  1980 sp        m      4554     NA\n#&gt; 6 Afghanistan  1980 sp        m      5564     NA\n#&gt; # ℹ 405,434 more rows\n\nnames_sep 的一个替代方案是 names_pattern，在你学习了 Chapter 15 中的正则表达式后，可以用它从更复杂的命名场景中提取变量。\n从概念上讲，这只是你已经看过的更简单情况的一个小变种。Figure 5.6 展示了基本思想：现在，列名不再是转换成单个列，而是转换成多个列。你可以想象这分两步发生 (先转换再分离)，但实际上它是在一个步骤中完成的，因为这样更快。\n\n\n\n\n\n\n\nFigure 5.6: 转换名称中包含多条信息的列，意味着每个列名现在都会填充到输出的多个列中。\n\n\n\n\n\n5.3.4 列标题中包含数据和变量名\n复杂性的下一个台阶是当列名中混合了变量值和变量名。例如，拿 household 数据集来说：\n\nhousehold\n#&gt; # A tibble: 5 × 5\n#&gt;   family dob_child1 dob_child2 name_child1 name_child2\n#&gt;    &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      \n#&gt; 1      1 1998-11-26 2000-01-29 Susan       Jose       \n#&gt; 2      2 1996-06-22 NA         Mark        &lt;NA&gt;       \n#&gt; 3      3 2002-07-11 2004-04-05 Sam         Seth       \n#&gt; 4      4 2004-10-10 2009-08-27 Craig       Khai       \n#&gt; 5      5 2000-12-05 2005-02-28 Parker      Gracie\n\n这个数据集包含了五个家庭的数据，以及最多两个孩子的姓名和出生日期。这个数据集中的新挑战是，列名包含了两个变量的名称 (dob、name) 和另一个变量 (child，值为 1 或 2) 的值。为了解决这个问题，我们再次需要向 names_to 提供一个向量，但这次我们使用特殊的 \".value\" 指示符；这不是一个变量名，而是一个告诉 pivot_longer() 做些不同事情的唯一值。这会覆盖通常的 values_to 参数，转而使用被转换列名的第一部分作为输出中的变量名。\n\nhousehold |&gt; \n  pivot_longer(\n    cols = !family, \n    names_to = c(\".value\", \"child\"), \n    names_sep = \"_\", \n    values_drop_na = TRUE\n  )\n#&gt; # A tibble: 9 × 4\n#&gt;   family child  dob        name \n#&gt;    &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;\n#&gt; 1      1 child1 1998-11-26 Susan\n#&gt; 2      1 child2 2000-01-29 Jose \n#&gt; 3      2 child1 1996-06-22 Mark \n#&gt; 4      3 child1 2002-07-11 Sam  \n#&gt; 5      3 child2 2004-04-05 Seth \n#&gt; 6      4 child1 2004-10-10 Craig\n#&gt; # ℹ 3 more rows\n\n我们再次使用 values_drop_na = TRUE，因为输入的形状强制创建了显式的缺失变量 (例如，对于只有一个孩子的家庭)。\nFigure 5.7 用一个更简单的例子阐述了基本思想。当你在 names_to 中使用 \".value\" 时，输入中的列名同时贡献了输出中的值和变量名。\n\n\n\n\n\n\n\nFigure 5.7: 使用 names_to = c(\".value\", \"num\") 进行转换会将列名分成两个部分：第一部分决定输出列的名称（x 或 y），第二部分决定 num 列的值。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据整理</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#加宽数据",
    "href": "data-tidy.html#加宽数据",
    "title": "5  数据整理",
    "section": "\n5.4 加宽数据",
    "text": "5.4 加宽数据\n到目前为止，我们已经使用 pivot_longer() 来解决一类常见的问题，即值最终出现在列名中。接下来，我们将转向 pivot_wider()，它通过增加列数和减少行数来使数据集变宽，并在一个观测分布在多行时提供帮助。这种情况在现实世界中似乎不那么常见，但在处理政府数据时似乎经常出现。\n我们将从查看 cms_patient_experience 开始，这是一个来自医疗保险和医疗补助服务中心的数据集，收集了关于患者体验的数据：\n\ncms_patient_experience\n#&gt; # A tibble: 500 × 5\n#&gt;   org_pac_id org_nm                     measure_cd   measure_title   prf_rate\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                      &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_1  CAHPS for MIPS…       63\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_2  CAHPS for MIPS…       87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_3  CAHPS for MIPS…       86\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_5  CAHPS for MIPS…       57\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_8  CAHPS for MIPS…       85\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_12 CAHPS for MIPS…       24\n#&gt; # ℹ 494 more rows\n\n被研究的核心单位是一个组织，但每个组织都分布在六行中，每一行对应于在该组织调查中进行的一次测量。我们可以通过使用 distinct() 来查看 measure_cd 和 measure_title 的完整值集：\n\ncms_patient_experience |&gt; \n  distinct(measure_cd, measure_title)\n#&gt; # A tibble: 6 × 2\n#&gt;   measure_cd   measure_title                                                 \n#&gt;   &lt;chr&gt;        &lt;chr&gt;                                                         \n#&gt; 1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and In…\n#&gt; 2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate            \n#&gt; 3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider              \n#&gt; 4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education            \n#&gt; 5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff        \n#&gt; 6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources\n\n这两列都不会成为特别好的变量名：measure_cd 没有暗示变量的含义，而 measure_title 是一个包含空格的长句子。我们现在将使用 measure_cd 作为新列名的来源，但在实际分析中，你可能想要创建既简短又有意义的自己的变量名。\npivot_wider() 的接口与 pivot_longer() 相反：我们不是选择新的列名，而是需要提供定义值的现有列 (values_from) 和定义列名的列 (names_from)：\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n#&gt; # A tibble: 500 × 9\n#&gt;   org_pac_id org_nm                   measure_title   CAHPS_GRP_1 CAHPS_GRP_2\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                    &lt;chr&gt;                 &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          63          NA\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; # ℹ 494 more rows\n#&gt; # ℹ 4 more variables: CAHPS_GRP_3 &lt;dbl&gt;, CAHPS_GRP_5 &lt;dbl&gt;, …\n\n输出看起来不太对；我们似乎每个组织仍然有多行。这是因为，我们还需要告诉 pivot_wider() 哪个或哪些列的值唯一标识每一行；在这种情况下，是那些以 \"org\" 开头的变量：\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    id_cols = starts_with(\"org\"),\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n#&gt; # A tibble: 95 × 8\n#&gt;   org_pac_id org_nm           CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICA…          63          87          86          57\n#&gt; 2 0446162697 ASSOCIATION OF …          59          85          83          63\n#&gt; 3 0547164295 BEAVER MEDICAL …          49          NA          75          44\n#&gt; 4 0749333730 CAPE PHYSICIANS…          67          84          85          65\n#&gt; 5 0840104360 ALLIANCE PHYSIC…          66          87          87          64\n#&gt; 6 0840109864 REX HOSPITAL INC          73          87          84          67\n#&gt; # ℹ 89 more rows\n#&gt; # ℹ 2 more variables: CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\n这样我们就得到了我们想要的输出。\n\n5.4.1 pivot_wider() 是如何工作的？\n为了理解 pivot_wider() 是如何工作的，让我们再次从一个非常简单的数据集开始。这次我们有两个病人，id 分别是 A 和 B，我们对病人 A 进行了三次血压测量，对病人 B 进行了两次：\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"B\",        \"bp1\",    140,\n  \"B\",        \"bp2\",    115, \n  \"A\",        \"bp2\",    120,\n  \"A\",        \"bp3\",    105\n)\n\n我们将从 value 列取值，从 measurement 列取名：\n\ndf |&gt; \n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   id      bp1   bp2   bp3\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A       100   120   105\n#&gt; 2 B       140   115    NA\n\n为了开始这个过程，pivot_wider() 首先需要弄清楚行和列中将放什么。新的列名将是 measurement 的唯一值。\n\ndf |&gt; \n  distinct(measurement) |&gt; \n  pull()\n#&gt; [1] \"bp1\" \"bp2\" \"bp3\"\n\n默认情况下，输出中的行由所有不进入新名称或值的变量决定。这些被称为 id_cols。这里只有一个列，但通常可以有任意数量。\n\ndf |&gt; \n  select(-measurement, -value) |&gt; \n  distinct()\n#&gt; # A tibble: 2 × 1\n#&gt;   id   \n#&gt;   &lt;chr&gt;\n#&gt; 1 A    \n#&gt; 2 B\n\n然后 pivot_wider() 结合这些结果生成一个空的数据框：\n\ndf |&gt; \n  select(-measurement, -value) |&gt; \n  distinct() |&gt; \n  mutate(x = NA, y = NA, z = NA)\n#&gt; # A tibble: 2 × 4\n#&gt;   id    x     y     z    \n#&gt;   &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 A     NA    NA    NA   \n#&gt; 2 B     NA    NA    NA\n\n然后它用输入中的数据填充所有缺失值。在这种情况下，并非输出中的每个单元格在输入中都有对应的值，因为病人 B 没有第三次血压测量，所以那个单元格保持缺失。我们将在 Chapter 18 中回到 pivot_wider() 可以“制造”缺失值的这个概念。\n你可能还会想，如果输入中有多个行对应于输出中的一个单元格会发生什么。下面的例子有两行对应于 id “A” 和 measurement “bp1”：\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"A\",        \"bp1\",    102,\n  \"A\",        \"bp2\",    120,\n  \"B\",        \"bp1\",    140, \n  \"B\",        \"bp2\",    115\n)\n\n如果我们尝试转换这个，我们会得到一个包含列表列 (list-columns) 的输出，你将在 Chapter 23 中学到更多关于它的知识：\n\ndf |&gt;\n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n#&gt; Warning: Values from `value` are not uniquely identified; output will contain\n#&gt; list-cols.\n#&gt; • Use `values_fn = list` to suppress this warning.\n#&gt; • Use `values_fn = {summary_fun}` to summarise duplicates.\n#&gt; • Use the following dplyr code to identify duplicates.\n#&gt;   {data} |&gt;\n#&gt;   dplyr::summarise(n = dplyr::n(), .by = c(id, measurement)) |&gt;\n#&gt;   dplyr::filter(n &gt; 1L)\n#&gt; # A tibble: 2 × 3\n#&gt;   id    bp1       bp2      \n#&gt;   &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n#&gt; 2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\n因为你还不知道如何处理这种数据，你可能需要根据警告中的提示来找出问题所在：\n\ndf |&gt; \n  group_by(id, measurement) |&gt; \n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 × 3\n#&gt;   id    measurement     n\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 A     bp1             2\n\n然后就得由你来弄清楚你的数据出了什么问题，要么修复底层的数据损坏，要么使用你的分组和汇总技能来确保行和列值的每个组合只有一个单行。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据整理</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#小结",
    "href": "data-tidy.html#小结",
    "title": "5  数据整理",
    "section": "\n5.5 小结",
    "text": "5.5 小结\n在本章中，你学习了关于整洁数据的知识：即变量在列、观测在行的数据。整洁数据使得在 tidyverse 中工作更容易，因为它是一个被大多数函数所理解的一致结构，主要的挑战是将你收到的任何结构的数据转换成整洁的格式。为此，你学习了 pivot_longer() 和 pivot_wider()，它们可以让你整理许多不整洁的数据集。我们在这里展示的例子是从 vignette(\"pivot\", package = \"tidyr\") 中挑选的一部分，所以如果你遇到的问题本章没有帮助你解决，那么那个小品文是一个值得尝试的下一个地方。\n另一个挑战是，对于一个给定的数据集，可能无法将更长或更宽的版本标记为“整洁”的那个。这部分反映了我们对整洁数据的定义，我们说整洁数据每个列中有一个变量，但我们实际上没有定义什么是变量 (而且定义它出奇地困难)。务实地说，一个变量可以是任何使你的分析最容易的东西，这是完全可以接受的。所以如果你在 figuring out 如何进行某些计算时卡住了，考虑改变你的数据组织方式；不要害怕按需进行非整洁化、转换和重新整洁化！\n如果你喜欢本章并想了解更多关于其底层理论的知识，你可以在发表于《统计软件杂志》(Journal of Statistical Software) 的论文 Tidy Data 中了解更多关于其历史和理论基础。\n现在你正在编写大量的 R 代码，是时候学习更多关于将你的代码组织到文件和目录中的知识了。在下一章中，你将学习到脚本和项目的所有优点，以及它们提供的许多使你的生活更轻松的工具。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据整理</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#footnotes",
    "href": "data-tidy.html#footnotes",
    "title": "5  数据整理",
    "section": "",
    "text": "只要一首歌在 2000 年的某个时间点进入过前 100 名，它就会被收录，并且在出现后最多被追踪 72 周。↩︎\n我们将在 Chapter 18 中回到这个概念。↩︎",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>数据整理</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html",
    "href": "workflow-scripts.html",
    "title": "6  工作流：脚本和项目",
    "section": "",
    "text": "6.1 脚本\n本章将向你介绍两个用于组织代码的重要工具：脚本和项目。\n到目前为止，你一直在使用控制台来运行代码。 这是一个很好的起点，但当你创建更复杂的 ggplot2 图形和更长的 dplyr 管道时，你会发现它很快就会变得拥挤不堪。 为了给自己更多的工作空间，请使用脚本编辑器。 通过点击文件 (File) 菜单，选择新建文件 (New File)，然后选择 R 脚本 (R script)，或者使用键盘快捷键 Cmd/Ctrl + Shift + N 来打开它。 现在你会看到四个窗格，如 Figure 6.1 所示。 脚本编辑器是试验代码的好地方。 当你想修改某些东西时，你不必重新输入所有内容，只需编辑脚本并重新运行即可。 而且，一旦你编写了能够正常工作并实现你想要的功能的代码，你就可以将其保存为脚本文件，以便日后轻松返回。\nFigure 6.1: 打开脚本编辑器会在 IDE 的左上方添加一个新窗格。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>工作流：脚本和项目</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#脚本",
    "href": "workflow-scripts.html#脚本",
    "title": "6  工作流：脚本和项目",
    "section": "",
    "text": "6.1.1 运行代码\n脚本编辑器是构建复杂 ggplot2 图或长序列 dplyr 操作的绝佳场所。 有效使用脚本编辑器的关键是记住一个最重要的键盘快捷键：Cmd/Ctrl + Enter。 这个快捷键会在控制台中执行当前的 R 表达式。 例如，看下面的代码。\n\nlibrary(dplyr)\nlibrary(nycflights13)\n\nnot_cancelled &lt;- flights |&gt; \n  filter(!is.na(dep_delay)█, !is.na(arr_delay))\n\nnot_cancelled |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(mean = mean(dep_delay))\n\n如果你的光标在 █ 处，按下 Cmd/Ctrl + Enter 将会运行生成 not_cancelled 的完整命令。 它还会将光标移动到下一个语句（以 not_cancelled |&gt; 开头）。 这使得通过重复按 Cmd/Ctrl + Enter 来逐步执行你的完整脚本变得容易。\n除了逐个表达式运行代码外，你还可以使用 Cmd/Ctrl + Shift + S 一步执行整个脚本。 定期这样做是确保你已将代码的所有重要部分都保存在脚本中的好方法。\n我们建议你始终以所需的包开始你的脚本。 这样，如果你与他人共享代码，他们可以轻松看到需要安装哪些包。 但请注意，你永远不应该在你共享的脚本中包含 install.packages()。 如果别人不小心，你递给他们的脚本可能会在他们的计算机上改变某些东西，这是不体贴的！\n在学习后续章节时，我们强烈建议从脚本编辑器开始，并练习你的键盘快捷键。 随着时间的推移，以这种方式向控制台发送代码将变得如此自然，以至于你甚至不会去想它。\n\n6.1.2 RStudio 诊断功能\n在脚本编辑器中，RStudio 会用红色波浪线和侧边栏中的叉号高亮显示语法错误：\n\n\n\n\n\n\n\n\n将鼠标悬停在叉号上可以看到问题所在：\n\n\n\n\n\n\n\n\nRStudio 也会提示你潜在的问题：\n\n\n\n\n\n\n\n\n\n6.1.3 保存与命名\n当你退出 RStudio 时，它会自动保存脚本编辑器的内容，并在你重新打开时自动重新加载。 尽管如此，最好还是避免使用 Untitled1、Untitled2、Untitled3 等名称，而是保存你的脚本并给它们起一些信息丰富的名字。\n你可能会想把文件命名为 code.R 或 myscript.R，但在为文件选择名称之前，你应该再多考虑一下。 文件命名的三个重要原则如下：\n\n文件名应该是机器可读的：避免使用空格、符号和特殊字符。不要依赖大小写来区分文件。\n文件名应该是人类可读的：使用文件名来描述文件内容。\n文件名应该与默认排序方式良好配合：以数字开头的文件名可以使它们按字母顺序排序时，也按使用顺序排列。\n\n例如，假设你的项目文件夹中有以下文件。\nalternative model.R\ncode for exploratory analysis.r\nfinalreport.qmd\nFinalReport.qmd\nfig 1.png\nFigure_02.png\nmodel_first_try.R\nrun-first.r\ntemp.txt\n这里存在各种问题：很难找到首先要运行哪个文件，文件名包含空格，有两个同名但大小写不同的文件（finalreport vs. FinalReport1），还有一些文件名没有描述其内容（run-first 和 temp）。\n以下是命名和组织同一组文件的更好方式：\n01-load-data.R\n02-exploratory-analysis.R\n03-model-approach-1.R\n04-model-approach-2.R\nfig-01.png\nfig-02.png\nreport-2022-03-20.qmd\nreport-2022-04-02.qmd\nreport-draft-notes.txt\n为关键脚本编号使得运行顺序一目了然，而一致的命名方案也更容易看出变化之处。 此外，图形的标签也类似，报告通过文件名中包含的日期来区分，temp被重命名为 report-draft-notes 以更好地描述其内容。 如果你一个目录中有很多文件，建议更进一步，将不同类型的文件（脚本、图形等）放在不同的目录中。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>工作流：脚本和项目</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#项目",
    "href": "workflow-scripts.html#项目",
    "title": "6  工作流：脚本和项目",
    "section": "\n6.2 项目",
    "text": "6.2 项目\n总有一天，你需要退出 R，去做些别的事情，然后再回来继续你的分析。 总有一天，你会同时进行多个分析，并且你希望将它们分开。 总有一天，你需要将外部世界的数据导入 R，并将数值结果和图形从 R 输出到外部世界。\n为了处理这些现实生活中的情况，你需要做出两个决定：\n\n什么是事实的唯一来源 (source of truth)？ 你将保存什么作为你所做工作的持久记录？\n你的分析工作存放在哪里？\n\n\n6.2.1 什么是事实的唯一来源？\n作为初学者，依赖当前环境 (Environment) 来包含你在整个分析过程中创建的所有对象是可以的。 然而，为了更容易地处理大型项目或与他人协作，你的事实的唯一来源应该是 R 脚本。 有了你的 R 脚本（和你的数据文件），你就可以重现环境。 而只有你的环境，要重现你的 R 脚本就困难得多：你要么得凭记忆重新输入大量代码（不可避免地会出错），要么就得仔细挖掘你的 R 历史记录。\n为了帮助你将 R 脚本作为分析的事实的唯一来源，我们强烈建议你设置 RStudio 在会话之间不保存你的工作区。 你可以通过运行 usethis::use_blank_slate()2 或模仿 Figure 6.2 中显示的选项来做到这一点。这会给你带来一些短期的痛苦，因为现在当你重启 RStudio 时，它将不再记得你上次运行的代码，你创建的对象或读取的数据集也无法使用。 但是这种短期的痛苦可以让你免于长期的折磨，因为它迫使你将所有重要的过程都记录在你的代码中。 没有什么比在三个月后发现你只把一个重要计算的结果保存在你的环境中，而不是把计算本身保存在你的代码中更糟糕的了。\n\n\n\n\n\n\n\nFigure 6.2: 在你的 RStudio 选项中复制这些设置，以便总是以一个全新的状态开始你的 RStudio 会话。\n\n\n\n\n有一对很棒的键盘快捷键可以协同工作，确保你已经将代码的重要部分保存在编辑器中：\n\n按 Cmd/Ctrl + Shift + 0/F10 重启 R。\n按 Cmd/Ctrl + Shift + S 重新运行当前脚本。\n\n我们每周会集体使用这个模式数百次。\n另外，如果你不使用键盘快捷键，你可以去菜单栏的 Session &gt; Restart R，然后高亮并重新运行你当前的脚本。\n\n\n\n\n\n\nRStudio Server\n\n\n\n如果你正在使用 RStudio Server，你的 R 会话默认是永远不会重启的。 当你关闭你的 RStudio Server 标签页时，可能感觉像是在关闭 R，但服务器实际上在后台保持它的运行。 下次你回来时，你将回到你离开时的确切位置。 这使得定期重启 R 以便从一个干净的状态开始变得更加重要。\n\n\n\n6.2.2 你的分析工作存放在哪里？\nR 有一个强大的概念，叫做工作目录 (working directory)。 这是 R 寻找你要求它加载的文件的位置，也是它存放你要求它保存的任何文件的位置。 RStudio 在控制台的顶部显示你当前的工作目录：\n\n\n\n\n\n\n\n\n你也可以通过运行 getwd() 在 R 代码中打印出这个路径：\n\ngetwd()\n#&gt; [1] \"/Users/hadley/Documents/r4ds\"\n\n在这个 R 会话中，当前的工作目录（可以把它想象成“家”）在 hadley 的 Documents 文件夹下的一个名为 r4ds 的子文件夹中。 当你运行这段代码时，会返回一个不同的结果，因为你的计算机有与 Hadley 不同的目录结构！\n作为 R 的初学者，让你的工作目录是你的主目录、文档目录或你电脑上任何其他奇怪的目录都是可以的。 但你已经读了这本书好几章了，你不再是初学者了。 很快你就应该进化到将你的项目组织到目录中，并且在处理一个项目时，将 R 的工作目录设置到相关的目录。\n你可以在 R 内部设置工作目录，但我们不推荐这样做：\n\nsetwd(\"/path/to/my/CoolProject\")\n\n有一个更好的方法；一个也能让你走上像专家一样管理你的 R 工作之路的方法。 这个方法就是 RStudio 项目。\n\n6.2.3 RStudio 项目\n将与某个特定项目相关的所有文件（输入数据、R 脚本、分析结果和图表）都放在一个目录中，这是一个非常明智和普遍的做法，以至于 RStudio 通过项目 (projects) 内置了对此的支持。 让我们为你创建一个项目，以便你在学习本书余下部分时使用。 点击 File &gt; New Project，然后按照 Figure 6.3 中显示的步骤操作。\n\n\n\n\n\n\n\nFigure 6.3: 创建新项目：(上) 首先点击新目录 (New Directory)，然后 (中) 点击新项目 (New Project)，最后 (下) 填写目录（项目）名称， 为其选择一个合适的子目录作为其主目录，然后点击创建项目 (Create Project)。\n\n\n\n\n将你的项目命名为 r4ds，并仔细考虑你将项目放在哪个子目录中。 如果你不把它存放在某个合理的地方，将来会很难找到它！\n这个过程完成后，你将为这本书得到一个新的 RStudio 项目。 检查一下你的项目的“家”是否就是当前的工作目录：\n\ngetwd()\n#&gt; [1] /Users/hadley/Documents/r4ds\n\n现在在脚本编辑器中输入以下命令，并将文件保存为 “diamonds.R”。 然后，创建一个名为 “data” 的新文件夹。 你可以通过点击 RStudio 中文件窗格的“新建文件夹”按钮来完成此操作。 最后，运行整个脚本，这会将一个 PNG 和一个 CSV 文件保存到你的项目目录中。 不用担心细节，你将在本书的后面学到它们。\n\nlibrary(tidyverse)\n\nggplot(diamonds, aes(x = carat, y = price)) + \n  geom_hex()\nggsave(\"diamonds.png\")\n\nwrite_csv(diamonds, \"data/diamonds.csv\")\n\n退出 RStudio。 检查与你的项目关联的文件夹 —— 注意那个 .Rproj 文件。 双击该文件以重新打开项目。 你会发现你回到了你离开的地方：工作目录和命令历史都一样，你正在处理的所有文件也仍然打开着。 因为你遵循了我们上面的指示，你将会有一个全新的环境，保证你从一个干净的状态开始。\n用你喜欢的操作系统特有的方式，在你的电脑上搜索 diamonds.png，你会找到这个 PNG 文件（不奇怪），但同时也能找到创建它的脚本 (diamonds.R)。 这是一个巨大的胜利！ 总有一天，你会想要重制一张图，或者只是想了解它是从哪里来的。 如果你严格地用 R 代码将图表保存到文件，而不是用鼠标或剪贴板，你将能够轻松地重现以前的工作！\n\n6.2.4 相对路径和绝对路径\n一旦你进入一个项目中，你应该只使用相对路径，而不是绝对路径。 有什么区别呢？ 相对路径是相对于工作目录的，也就是项目的主目录。 当 Hadley 在上面写 data/diamonds.csv 时，它是 /Users/hadley/Documents/r4ds/data/diamonds.csv 的一个快捷方式。 但重要的是，如果 Mine 在她的电脑上运行这段代码，它会指向 /Users/Mine/Documents/r4ds/data/diamonds.csv。 这就是为什么相对路径很重要：无论 R 项目文件夹最终在哪里，它们都能工作。\n绝对路径无论你的工作目录在哪里，都指向同一个地方。 它们根据你的操作系统看起来有点不同。 在 Windows 上，它们以一个驱动器字母（例如，C:）或两个反斜杠（例如，\\\\servername）开头，而在 Mac/Linux 上，它们以一个斜杠 “/” 开头（例如，/users/hadley）。 你永远不应该在你的脚本中使用绝对路径，因为它们妨碍了共享：没有其他人会有和你完全相同的目录配置。\n操作系统之间还有一个重要的区别：你如何分隔路径的组件。 Mac 和 Linux 使用斜杠（例如 data/diamonds.csv），而 Windows 使用反斜杠（例如 data\\diamonds.csv）。 R 可以处理任何一种类型（无论你当前使用的是哪个平台），但不幸的是，反斜杠对 R 来说有特殊的含义，要在路径中得到一个反斜杠，你需要输入两个反斜杠！ 这让生活变得很烦恼，所以我们建议总是使用 Linux/Mac 风格的正斜杠。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>工作流：脚本和项目</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#练习",
    "href": "workflow-scripts.html#练习",
    "title": "6  工作流：脚本和项目",
    "section": "\n6.3 练习",
    "text": "6.3 练习\n\n访问 RStudio Tips 的 Twitter 账户 https://twitter.com/rstudiotips，找到一条你觉得有趣的技巧。 练习使用它！\nRStudio 的诊断功能还会报告哪些其他常见的错误？ 阅读 https://support.posit.co/hc/en-us/articles/205753617-Code-Diagnostics 来找出答案。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>工作流：脚本和项目</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#总结",
    "href": "workflow-scripts.html#总结",
    "title": "6  工作流：脚本和项目",
    "section": "\n6.4 总结",
    "text": "6.4 总结\n在本章中，你学会了如何将你的 R 代码组织在脚本（文件）和项目（目录）中。 就像代码风格一样，这起初可能感觉像是繁琐的工作。 但随着你在多个项目中积累了越来越多的代码，你将学会欣赏一点点前期的组织工作能在未来为你节省大量时间。\n总而言之，脚本和项目为你提供了一个坚实的工作流，将在未来为你带来很好的服务：\n\n为每个数据分析项目创建一个 RStudio 项目。\n将你的脚本（用信息丰富的名称）保存在项目中，编辑它们，分部分或整体运行它们。频繁重启 R 以确保你已经将所有内容都保存在你的脚本中。\n只使用相对路径，绝不使用绝对路径。\n\n这样，你需要的一切都在一个地方，并与你正在进行的所有其他项目清晰地分离开来。\n到目前为止，我们一直使用的是 R 包中捆绑的数据集。 这使得在预先准备好的数据上进行一些练习变得更容易，但显然你的数据不会以这种方式提供。 因此，在下一章中，你将学习如何使用 readr 包将数据从磁盘加载到你的 R 会话中。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>工作流：脚本和项目</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#footnotes",
    "href": "workflow-scripts.html#footnotes",
    "title": "6  工作流：脚本和项目",
    "section": "",
    "text": "更不用说，你在文件名中使用“final”这个词是在挑战命运 😆。《Piled Higher and Deeper》这本漫画对此有一个有趣的条漫。↩︎\n如果你没有安装 usethis，可以用 install.packages(\"usethis\") 来安装它。↩︎",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>工作流：脚本和项目</span>"
    ]
  },
  {
    "objectID": "data-import.html",
    "href": "data-import.html",
    "title": "7  数据导入",
    "section": "",
    "text": "7.1 引言\n使用 R 包提供的数据是学习数据科学工具的好方法，但总有一天，你会希望将所学知识应用到自己的数据上。 在本章中，你将学习将数据文件读入 R 的基础知识。\n具体来说，本章将重点介绍如何读取纯文本矩形文件。 我们将从处理列名、类型和缺失数据等特性的实用建议开始。 然后，你将学习如何一次性从多个文件中读取数据，以及如何将数据从 R 写入文件。 最后，你将学习如何在 R 中手动创建数据框。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#引言",
    "href": "data-import.html#引言",
    "title": "7  数据导入",
    "section": "",
    "text": "7.1.1 先决条件\n在本章中，你将学习如何使用 readr 包将纯文本文件加载到 R 中，该包是核心 tidyverse 的一部分。\n\nlibrary(tidyverse)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#从文件中读取数据",
    "href": "data-import.html#从文件中读取数据",
    "title": "7  数据导入",
    "section": "\n7.2 从文件中读取数据",
    "text": "7.2 从文件中读取数据\n首先，我们将重点关注最常见的矩形数据文件类型：CSV，即逗号分隔值 (comma-separated values) 的缩写。 下面是一个简单的 CSV 文件的样子。 第一行，通常称为标题行 (header row)，给出了列名，接下来的六行提供了数据。 这些列由逗号分隔，也称为定界 (delimited)。\n\nStudent ID,Full Name,favourite.food,mealPlan,AGE\n1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4\n2,Barclay Lynn,French fries,Lunch only,5\n3,Jayendra Lyne,N/A,Breakfast and lunch,7\n4,Leon Rossini,Anchovies,Lunch only,\n5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five\n6,Güvenç Attila,Ice cream,Lunch only,6\n\nTable 7.1 以表格形式展示了相同的数据。\n\n\n\nTable 7.1: 来自 students.csv 文件的数据表格。\n\n\n\n\n\n\n\n\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\n\n1\nSunil Huffmann\nStrawberry yoghurt\nLunch only\n4\n\n\n2\nBarclay Lynn\nFrench fries\nLunch only\n5\n\n\n3\nJayendra Lyne\nN/A\nBreakfast and lunch\n7\n\n\n4\nLeon Rossini\nAnchovies\nLunch only\nNA\n\n\n5\nChidiegwu Dunkel\nPizza\nBreakfast and lunch\nfive\n\n\n6\nGüvenç Attila\nIce cream\nLunch only\n6\n\n\n\n\n\n\n\n\n我们可以使用 read_csv() 将这个文件读入 R。 第一个参数是最重要的：文件的路径。 你可以将路径看作是文件的地址：文件名为 students.csv，它位于 data 文件夹中。\n\nstudents &lt;- read_csv(\"data/students.csv\")\n#&gt; Rows: 6 Columns: 5\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr (4): Full Name, favourite.food, mealPlan, AGE\n#&gt; dbl (1): Student ID\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n如果你的项目中的 data 文件夹里有 students.csv 文件，上面的代码就能正常工作。 你可以从 https://pos.it/r4ds-students-csv 下载 students.csv 文件，或者用下面的代码直接从那个 URL 读取它：\n\nstudents &lt;- read_csv(\"https://pos.it/r4ds-students-csv\")\n\n当你运行 read_csv() 时，它会打印一条消息，告诉你数据的行数和列数、使用的分隔符以及列的规格（按列所含数据类型组织的列名）。 它还会打印一些关于检索完整列规格和如何静默此消息的信息。 这条消息是 readr 的一个组成部分，我们将在 Section 7.3 中再次讨论它。\n\n7.2.1 实用建议\n一旦你读入数据，第一步通常是进行某种方式的转换，以便在后续分析中更容易处理。 让我们带着这个想法再看一次 students 数据。\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\n在 favourite.food 列中，有一堆食物项目，然后是字符串 N/A，这本应是一个真正的 NA，R 会将其识别为“不可用”(not available)。 这是我们可以使用 na 参数来解决的问题。 默认情况下，read_csv() 在这个数据集中只识别空字符串 (\"\") 为 NA，我们希望它也能识别字符串 \"N/A\"。\n\nstudents &lt;- read_csv(\"data/students.csv\", na = c(\"N/A\", \"\"))\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\n你可能还会注意到 Student ID 和 Full Name 这两列被反引号包围。 这是因为它们包含空格，破坏了 R 的常规变量命名规则；它们是非语法 (non-syntactic) 名称。 要引用这些变量，你需要用反引号 ` 将它们包围起来：\n\nstudents |&gt; \n  rename(\n    student_id = `Student ID`,\n    full_name = `Full Name`\n  )\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite.food     mealPlan            AGE  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n另一种方法是使用 janitor::clean_names()，它会运用一些启发式方法一次性将所有列名转换为蛇形命名法 (snake case)1。\n\nstudents |&gt; janitor::clean_names()\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n读入数据后的另一个常见任务是考虑变量类型。 例如，meal_plan 是一个分类变量，具有一组已知的可能值，在 R 中应表示为因子 (factor)：\n\nstudents |&gt;\n  janitor::clean_names() |&gt;\n  mutate(meal_plan = factor(meal_plan))\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n注意，meal_plan 变量中的值保持不变，但变量名下方表示的变量类型已从字符 (&lt;chr&gt;) 变为因子 (&lt;fct&gt;)。 你将在 Chapter 16 中学到更多关于因子的知识。\n在分析这些数据之前，你可能想修复 age 列。 目前，age 是一个字符变量，因为其中一个观测值被输入为 five 而不是数字 5。 我们将在 Chapter 20 中讨论修复这个问题的细节。\n\nstudents &lt;- students |&gt;\n  janitor::clean_names() |&gt;\n  mutate(\n    meal_plan = factor(meal_plan),\n    age = parse_number(if_else(age == \"five\", \"5\", age))\n  )\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n这里有一个新函数 if_else()，它有三个参数。 第一个参数 test 应该是一个逻辑向量。 当 test 为 TRUE 时，结果将包含第二个参数 yes 的值；当 test 为 FALSE 时，结果将包含第三个参数 no 的值。 这里我们是说，如果 age 是字符串 \"five\"，就把它变成 \"5\"，如果不是，就保持 age 不变。 你将在 Chapter 12 中学到更多关于 if_else() 和逻辑向量的知识。\n\n7.2.2 其他参数\n我们还需要提到几个其他重要的参数，如果我们先向你展示一个方便的技巧，会更容易演示：read_csv() 可以读取你创建并格式化为 CSV 文件那样的文本字符串：\n\nread_csv(\n  \"a,b,c\n  1,2,3\n  4,5,6\"\n)\n#&gt; # A tibble: 2 × 3\n#&gt;       a     b     c\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\n通常，read_csv() 使用数据的第一行作为列名，这是一个非常普遍的惯例。 但文件顶部包含几行元数据的情况也并不少见。 你可以使用 skip = n 来跳过前 n 行，或者使用 comment = \"#\" 来删除所有以（例如）# 开头的行：\n\nread_csv(\n  \"元数据的第一行\n  元数据的第二行\n  x,y,z\n  1,2,3\",\n  skip = 2\n)\n#&gt; # A tibble: 1 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\nread_csv(\n  \"# 我想跳过的一条注释\n  x,y,z\n  1,2,3\",\n  comment = \"#\"\n)\n#&gt; # A tibble: 1 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\n在其他情况下，数据可能没有列名。 你可以使用 col_names = FALSE 来告诉 read_csv() 不要将第一行作为标题，而是按顺序将它们标记为 X1 到 Xn：\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = FALSE\n)\n#&gt; # A tibble: 2 × 3\n#&gt;      X1    X2    X3\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\n或者，你可以给 col_names 传递一个字符向量，它将被用作列名：\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = c(\"x\", \"y\", \"z\")\n)\n#&gt; # A tibble: 2 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\n这些参数就是你在实践中读取大多数 CSV 文件所需要知道的全部内容了。 （至于其余情况，你需要仔细检查你的 .csv 文件，并阅读 read_csv() 许多其他参数的文档。）\n\n7.2.3 其他文件类型\n一旦你掌握了 read_csv()，使用 readr 的其他函数就很直接了；这只是知道该用哪个函数的问题：\n\nread_csv2() 读取分号分隔的文件。 这些文件使用 ; 而不是 , 来分隔字段，在那些使用 , 作为小数点的国家很常见。\nread_tsv() 读取制表符分隔的文件。\nread_delim() 读取任何分隔符的文件，如果你不指定分隔符，它会尝试自动猜测。\nread_fwf() 读取固定宽度文件。 你可以用 fwf_widths() 按宽度指定字段，或用 fwf_positions() 按位置指定字段。\nread_table() 读取一种常见的固定宽度文件变体，其中列由空白分隔。\nread_log() 读取 Apache 风格的日志文件。\n\n7.2.4 练习\n\n你会用哪个函数来读取字段由 “|” 分隔的文件？\n除了 file、skip 和 comment，read_csv() 和 read_tsv() 还有哪些共同的参数？\nread_fwf() 最重要的参数是什么？\n\n有时 CSV 文件中的字符串包含逗号。 为了防止它们引起问题，它们需要被引号字符包围，比如 \" 或 '。默认情况下，read_csv() 假设引号字符是 \"。 要将以下文本读入一个数据框，你需要为 read_csv() 指定哪个参数？\n\n\"x,y\\n1,'a,b'\"\n\n\n\n找出以下每个内联 CSV 文件有什么问题。 当你运行这些代码时会发生什么？\n\nread_csv(\"a,b\\n1,2,3\\n4,5,6\")\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\nread_csv(\"a,b\\n\\\"1\")\nread_csv(\"a,b\\n1,2\\na,b\")\nread_csv(\"a;b\\n1;3\")\n\n\n\n在下面的数据框中练习引用非语法名称：\n\n提取名为 1 的变量。\n绘制 1 与 2 的散点图。\n创建一个名为 3 的新列，它是 2 除以 1 的结果。\n将列重命名为 one、two 和 three。\n\n\nannoying &lt;- tibble(\n  `1` = 1:10,\n  `2` = `1` * 2 + rnorm(length(`1`))\n)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-col-types",
    "href": "data-import.html#sec-col-types",
    "title": "7  数据导入",
    "section": "\n7.3 控制列类型",
    "text": "7.3 控制列类型\nCSV 文件不包含关于每个变量类型的信息（即它是逻辑值、数字、字符串等），所以 readr 会尝试猜测类型。 本节描述了猜测过程是如何工作的，如何解决一些导致它失败的常见问题，以及如果需要，如何自己提供列类型。 最后，我们将提到一些通用的策略，如果 readr 彻底失败，而你需要更深入地了解你的文件结构，这些策略会很有用。\n\n7.3.1 猜测类型\nreadr 使用一种启发式方法来判断列类型。 对于每一列，它从第一行到最后一行均匀地抽取 1000 行2 的值，并忽略缺失值。 然后它会按顺序考虑以下问题：\n\n它是否只包含 F、T、FALSE 或 TRUE（忽略大小写）？如果是，它就是一个逻辑值 (logical)。\n它是否只包含数字（例如，1、-4.5、5e6、Inf）？如果是，它就是一个数字 (number)。\n它是否符合 ISO8601 标准？如果是，它就是一个日期或日期时间。(我们将在 Section 17.2 中更详细地回到日期时间)。\n否则，它必须是一个字符串 (string)。\n\n你可以在这个简单的例子中看到这种行为：\n\nread_csv(\"\n  logical,numeric,date,string\n  TRUE,1,2021-01-15,abc\n  false,4.5,2021-02-15,def\n  T,Inf,2021-02-16,ghi\n\")\n#&gt; # A tibble: 3 × 4\n#&gt;   logical numeric date       string\n#&gt;   &lt;lgl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt; \n#&gt; 1 TRUE        1   2021-01-15 abc   \n#&gt; 2 FALSE       4.5 2021-02-15 def   \n#&gt; 3 TRUE      Inf   2021-02-16 ghi\n\n如果你的数据集很干净，这个启发式方法效果很好，但在现实生活中，你会遇到各种各样稀奇古怪的失败情况。\n\n7.3.2 缺失值、列类型和问题\n列检测最常见的失败方式是某一列包含了意料之外的值，导致你得到一个字符列而不是更具体的类型。 最常见的原因之一是缺失值，它被记录为 readr 不期望的其他形式，而不是 NA。\n以这个简单的单列 CSV 文件为例：\n\nsimple_csv &lt;- \"\n  x\n  10\n  .\n  20\n  30\"\n\n如果我们不带任何额外参数来读取它，x 会变成一个字符列：\n\nread_csv(simple_csv)\n#&gt; # A tibble: 4 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 10   \n#&gt; 2 .    \n#&gt; 3 20   \n#&gt; 4 30\n\n在这个非常小的情况下，你可以轻易看到缺失值 .。 但是，如果你有成千上万行，其中只有少数几个由 . 表示的缺失值散布其中，会发生什么呢？ 一种方法是告诉 readr x 是一个数值列，然后看它在哪里失败。 你可以通过 col_types 参数来做到这一点，该参数接受一个命名列表，其中名称与 CSV 文件中的列名匹配：\n\ndf &lt;- read_csv(\n  simple_csv, \n  col_types = list(x = col_double())\n)\n#&gt; Warning: One or more parsing issues, call `problems()` on your data frame for\n#&gt; details, e.g.:\n#&gt;   dat &lt;- vroom(...)\n#&gt;   problems(dat)\n\n现在 read_csv() 报告说有问题，并告诉我们可以用 problems() 了解更多信息：\n\nproblems(df)\n#&gt; # A tibble: 1 × 5\n#&gt;     row   col expected actual file                                           \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;                                          \n#&gt; 1     3     1 a double .      C:/Users/14913/AppData/Local/Temp/RtmpiSxJyZ/f…\n\n这告诉我们，在第 3 行第 1 列有一个问题，readr 期望一个双精度数 (double)，但得到了一个 .。 这表明这个数据集使用 . 来表示缺失值。 所以我们设置 na = \".\"，自动猜测就成功了，得到了我们想要的数值列：\n\nread_csv(simple_csv, na = \".\")\n#&gt; # A tibble: 4 × 1\n#&gt;       x\n#&gt;   &lt;dbl&gt;\n#&gt; 1    10\n#&gt; 2    NA\n#&gt; 3    20\n#&gt; 4    30\n\n\n7.3.3 列类型\nreadr 总共提供了九种列类型供你使用：\n\n\ncol_logical() 和 col_double() 读取逻辑值和实数。它们相对来说很少需要（除非像上面那样），因为 readr 通常会为你猜到它们。\n\ncol_integer() 读取整数。本书中我们很少区分整数和双精度数，因为它们在功能上是等效的，但明确读取整数偶尔会很有用，因为它们占用的内存是双精度数的一半。\n\ncol_character() 读取字符串。当你的某一列是数值标识符时，明确指定它会很有用，即一长串数字，它标识一个对象，但对其进行数学运算没有意义。例子包括电话号码、社会安全号码、信用卡号码等。\n\ncol_factor()、col_date() 和 col_datetime() 分别创建因子、日期和日期时间；当我们在 Chapter 16 和 Chapter 17 中讲到这些数据类型时，你将学到更多关于它们的内容。\n\ncol_number() 是一个宽容的数值解析器，会忽略非数值部分，对货币特别有用。你将在 Chapter 13 中学到更多关于它的知识。\n\ncol_skip() 会跳过一列，使其不被包含在结果中，这在你有大型 CSV 文件并且只想使用其中一部分列时，可以加快数据读取速度。\n\n也可以通过从 list() 切换到 cols() 并指定 .default 来覆盖默认的列类型：\n\nanother_csv &lt;- \"\nx,y,z\n1,2,3\"\n\nread_csv(\n  another_csv, \n  col_types = cols(.default = col_character())\n)\n#&gt; # A tibble: 1 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     2     3\n\n另一个有用的辅助函数是 cols_only()，它只会读入你指定的列：\n\nread_csv(\n  another_csv,\n  col_types = cols_only(x = col_character())\n)\n#&gt; # A tibble: 1 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-readr-directory",
    "href": "data-import.html#sec-readr-directory",
    "title": "7  数据导入",
    "section": "\n7.4 从多个文件中读取数据",
    "text": "7.4 从多个文件中读取数据\n有时你的数据分散在多个文件中，而不是包含在单个文件中。 例如，你可能有多個月的销售数据，每个月的数据都在一个单独的文件中：01-sales.csv 代表一月，02-sales.csv 代表二月，03-sales.csv 代表三月。 使用 read_csv()，你可以一次性读取这些数据，并将它们堆叠在一个单一的数据框中。\n\nsales_files &lt;- c(\"data/01-sales.csv\", \"data/02-sales.csv\", \"data/03-sales.csv\")\nread_csv(sales_files, id = \"file\")\n#&gt; # A tibble: 19 × 6\n#&gt;   file              month    year brand  item     n\n#&gt;   &lt;chr&gt;             &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 data/01-sales.csv January  2019     1  1234     3\n#&gt; 2 data/01-sales.csv January  2019     1  8721     9\n#&gt; 3 data/01-sales.csv January  2019     1  1822     2\n#&gt; 4 data/01-sales.csv January  2019     2  3333     1\n#&gt; 5 data/01-sales.csv January  2019     2  2156     9\n#&gt; 6 data/01-sales.csv January  2019     2  3987     6\n#&gt; # ℹ 13 more rows\n\n同样，如果你的项目中的 data 文件夹里有这些 CSV 文件，上面的代码就能正常工作。 你可以从 https://pos.it/r4ds-01-sales、https://pos.it/r4ds-02-sales 和 https://pos.it/r4ds-03-sales 下载这些文件，或者用下面的代码直接读取它们：\n\nsales_files &lt;- c(\n  \"https://pos.it/r4ds-01-sales\",\n  \"https://pos.it/r4ds-02-sales\",\n  \"https://pos.it/r4ds-03-sales\"\n)\nread_csv(sales_files, id = \"file\")\n\nid 参数会在结果数据框中添加一个名为 file 的新列，用于标识数据来自哪个文件。 这在读取的文件本身没有标识列，无法帮助你将观测值追溯到其原始来源的情况下特别有用。\n如果你有很多文件要读取，将它们的名字写成一个列表可能会很麻烦。 相反，你可以使用基础 R 的 list.files() 函数，通过匹配文件名中的一个模式来为你找到文件。 你将在 Chapter 15 中学到更多关于这些模式的知识。\n\nsales_files &lt;- list.files(\"data\", pattern = \"sales\\\\.csv$\", full.names = TRUE)\nsales_files\n#&gt; [1] \"data/01-sales.csv\" \"data/02-sales.csv\" \"data/03-sales.csv\"",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-writing-to-a-file",
    "href": "data-import.html#sec-writing-to-a-file",
    "title": "7  数据导入",
    "section": "\n7.5 写入文件",
    "text": "7.5 写入文件\nreadr 也附带了两个有用的函数，用于将数据写回磁盘：write_csv() 和 write_tsv()。 这些函数最重要的参数是 x（要保存的数据框）和 file（保存的位置）。 你还可以用 na 指定如何写入缺失值，以及如果你想 append到一个现有文件。\n\nwrite_csv(students, \"students.csv\")\n\n现在让我们把那个 csv 文件读回来。 注意，当你保存为 CSV 时，你刚刚设置的变量类型信息会丢失，因为你又从一个纯文本文件开始读取了：\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\nwrite_csv(students, \"students-2.csv\")\nread_csv(\"students-2.csv\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n这使得 CSV 对于缓存中间结果有点不可靠——你每次加载时都需要重新创建列规格。 主要有两种替代方案：\n\n\nwrite_rds() 和 read_rds() 是对基础函数 readRDS() 和 saveRDS() 的统一包装。 它们以 R 的自定义二进制格式 RDS 存储数据。 这意味着当你重新加载对象时，你加载的是你存储的完全相同的 R 对象。\n\nwrite_rds(students, \"students.rds\")\nread_rds(\"students.rds\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\narrow 包允许你读写 parquet 文件，这是一种快速的二进制文件格式，可以在不同编程语言之间共享。 我们将在 Chapter 22 中更深入地讨论 arrow。\n\nlibrary(arrow)\nwrite_parquet(students, \"students.parquet\")\nread_parquet(\"students.parquet\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan               age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;                 &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only                4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only                5\n#&gt; 3          3 Jayendra Lyne    NA                 Breakfast and lunch       7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only               NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch       5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only                6\n\n\n\nParquet 通常比 RDS 快得多，并且可以在 R 之外使用，但需要 arrow 包。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#数据录入",
    "href": "data-import.html#数据录入",
    "title": "7  数据导入",
    "section": "\n7.6 数据录入",
    "text": "7.6 数据录入\n有时你需要“手动”组装一个 tibble，在你的 R 脚本中进行少量的数据录入。 有两个有用的函数可以帮助你做到这一点，它们的区别在于你是按列还是按行来布局 tibble。 tibble() 是按列工作的：\n\ntibble(\n  x = c(1, 2, 5), \n  y = c(\"h\", \"m\", \"g\"),\n  z = c(0.08, 0.83, 0.60)\n)\n#&gt; # A tibble: 3 × 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6\n\n按列布局数据可能很难看出行与行之间的关系，所以另一种选择是 tribble()，即转置的 tibble (transposed tibble) 的缩写，它让你逐行布局你的数据。 tribble() 是为在代码中进行数据录入而定制的：列标题以 ~ 开头，条目由逗号分隔。 这使得可以用一种易于阅读的形式来布局少量数据：\n\ntribble(\n  ~x, ~y, ~z,\n  1, \"h\", 0.08,\n  2, \"m\", 0.83,\n  5, \"g\", 0.60\n)\n#&gt; # A tibble: 3 × 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#总结",
    "href": "data-import.html#总结",
    "title": "7  数据导入",
    "section": "\n7.7 总结",
    "text": "7.7 总结\n在本章中，你学会了如何使用 read_csv() 加载 CSV 文件，以及如何使用 tibble() 和 tribble() 进行你自己的数据录入。 你了解了 CSV 文件的工作原理，你可能会遇到的一些问题，以及如何克服它们。 在本书中，我们会几次回到数据导入这个话题：Chapter 20 讲从 Excel 和 Google Sheets 导入，Chapter 21 将向你展示如何从数据库加载数据，Chapter 22 从 parquet 文件，Chapter 23 从 JSON，以及 Chapter 24 从网站。\n我们即将结束本书的这一部分，但还有一个重要的最后话题要讲：如何获得帮助。 所以在下一章中，你将学到一些寻求帮助的好地方，如何创建一个 reprex (可复现示例) 来最大化你获得良好帮助的机会，以及一些关于跟上 R 世界发展的一般性建议。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "data-import.html#footnotes",
    "href": "data-import.html#footnotes",
    "title": "7  数据导入",
    "section": "",
    "text": "janitor 包不属于 tidyverse，但它提供了便捷的数据清理函数，并且能很好地在使 用 |&gt; 的数据管道中工作。↩︎\n你可以用 guess_max 参数覆盖默认的 1000 行。↩︎",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>数据导入</span>"
    ]
  },
  {
    "objectID": "workflow-help.html",
    "href": "workflow-help.html",
    "title": "8  工作流：获取帮助",
    "section": "",
    "text": "8.1 谷歌是你的好朋友\n这本书并非一座孤岛；没有任何单一的资源能让你精通 R。 当你开始将本书中描述的技术应用于自己的数据时，你很快就会发现我们没有回答的问题。 本节将介绍一些获取帮助和持续学习的技巧。\n如果你遇到困难，从谷歌开始。 通常，在查询中加上“R”就足以将其限制在相关的结果中：如果搜索结果没有用，通常意味着没有 R 特定的结果可用。 此外，添加像 “tidyverse” 或 “ggplot2” 这样的包名也会帮助你将结果范围缩小到你更熟悉的代码，例如，“how to make a boxplot in R” (如何在 R 中制作箱线图) vs. “how to make a boxplot in R with ggplot2” (如何用 ggplot2 在 R 中制作箱线图)。 对于错误信息，谷歌尤其有用。 如果你得到一个错误信息，并且你不知道它是什么意思，试试谷歌搜索它！ 很可能过去有人也曾对此感到困惑，网上某个地方会有帮助。 （如果错误信息不是英文的，运行 Sys.setenv(LANGUAGE = \"en\") 并重新运行代码；你更有可能为英文错误信息找到帮助。）\n如果谷歌没有帮助，试试 Stack Overflow。 首先花点时间搜索现有的答案，记得加上 [R]，将你的搜索限制在使用 R 的问题和答案上。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>工作流：获取帮助</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#制作一个可复现示例-reprex",
    "href": "workflow-help.html#制作一个可复现示例-reprex",
    "title": "8  工作流：获取帮助",
    "section": "\n8.2 制作一个可复现示例 (reprex)",
    "text": "8.2 制作一个可复现示例 (reprex)\n如果你的谷歌搜索没有找到任何有用的东西，那么准备一个 reprex，即最小可复现示例 (minimal reproducible example) 是一个非常好的主意。 一个好的 reprex 能让其他人更容易帮助你，而且通常你会在制作它的过程中自己找出问题所在。 创建 reprex 有两个部分：\n\n首先，你需要让你的代码可复现 (reproducible)。 这意味着你需要捕获所有东西，即包含任何 library() 调用并创建所有必要的对象。 确保你做到这一点的最简单方法是使用 reprex 包。\n其次，你需要让它最小化 (minimal)。 剥离掉所有与你的问题不直接相关的东西。 这通常涉及到创建一个比你在现实生活中面对的要小得多、简单得多的 R 对象，甚至使用内置数据。\n\n这听起来像很多工作！ 而且确实可能如此，但它有巨大的回报：\n\n80% 的情况下，创建一个优秀的 reprex 会揭示你问题的根源。 令人惊讶的是，编写一个独立的、最小化的例子的过程，常常能让你自己回答自己的问题。\n另外 20% 的情况下，你将以一种便于他人上手的方式捕捉到你问题的本质。 这大大提高了你获得帮助的机会！\n\n当手动创建 reprex 时，很容易不小心漏掉某些东西，这意味着你的代码无法在别人的电脑上运行。 通过使用 reprex 包可以避免这个问题，该包是作为 tidyverse 的一部分安装的。 假设你将这段代码复制到剪贴板上（或者，在 RStudio Server 或 Cloud 上，选中它）：\n\ny &lt;- 1:4\nmean(y)\n\n然后调用 reprex()，其默认输出是为 GitHub 格式化的：\nreprex::reprex()\n一个渲染精美的 HTML 预览将显示在 RStudio 的 Viewer 窗格中（如果你在 RStudio 中）或你的默认浏览器中。 reprex 会自动复制到你的剪贴板（在 RStudio Server 或 Cloud 上，你需要自己复制）：\n``` r\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n```\n这段文本以一种特殊的方式格式化，称为 Markdown，可以粘贴到像 StackOverflow 或 Github 这样的网站上，它们会自动将其渲染成代码的样子。 这是该 Markdown 在 GitHub 上渲染后的样子：\n\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n\n其他任何人都可以立即复制、粘贴并运行它。\n要使你的示例可复现，你需要包含三件事：所需的包、数据和代码。\n\n包 应该在脚本的顶部加载，这样可以很容易地看到示例需要哪些包。 这是一个检查你是否正在使用每个包的最新版本的好时机；你可能发现了一个自你安装或上次更新包以来已经修复的错误。 对于 tidyverse 中的包，最简单的检查方法是运行 tidyverse_update()。\n\n包含数据的最简单方法是使用 dput() 来生成重新创建它所需的 R 代码。 例如，要在 R 中重新创建 mtcars 数据集，请执行以下步骤：\n\n在 R 中运行 dput(mtcars)\n\n复制输出\n在 reprex 中，输入 mtcars &lt;-，然后粘贴。\n\n尽量使用能揭示问题的最小数据子集。\n\n\n花一点时间确保你的代码易于他人阅读：\n\n确保你使用了空格，并且你的变量名既简洁又信息丰富。\n使用注释来指出你的问题所在。\n尽力删除所有与问题无关的内容。\n\n你的代码越短，就越容易理解，也越容易修复。\n\n\n最后，通过启动一个新的 R 会话并复制粘贴你的脚本，来检查你是否真的创建了一个可复现的示例。\n创建 reprex 并非易事，需要一些练习才能学会创建好的、真正最小化的 reprex。 然而，学会提出包含代码的问题，并投入时间使其可复现，将随着你学习和掌握 R 的过程而持续带来回报。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>工作流：获取帮助</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#投资自己",
    "href": "workflow-help.html#投资自己",
    "title": "8  工作流：获取帮助",
    "section": "\n8.3 投资自己",
    "text": "8.3 投资自己\n你也应该花一些时间在问题发生前就做好解决问题的准备。 每天投入一点时间学习 R，从长远来看将获得丰厚的回报。 一种方法是在 tidyverse 博客上关注 tidyverse 团队的动态。 为了更广泛地了解 R 社区，我们推荐阅读 R Weekly：这是一个社区项目，每周汇总 R 社区最有趣的新闻。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>工作流：获取帮助</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#总结",
    "href": "workflow-help.html#总结",
    "title": "8  工作流：获取帮助",
    "section": "\n8.4 总结",
    "text": "8.4 总结\n本章结束了本书的“全局概览”部分。 你现在已经看到了数据科学过程中最重要的部分：可视化、转换、整理和导入。 现在你对整个过程有了整体的看法，我们将开始深入探讨各个小部分的细节。\n本书的下一部分，“可视化”，将更深入地探讨图形语法和使用 ggplot2 创建数据可视化，展示如何使用你目前学到的工具进行探索性数据分析，并介绍为沟通交流创建图表的良好实践。",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>工作流：获取帮助</span>"
    ]
  },
  {
    "objectID": "visualize.html",
    "href": "visualize.html",
    "title": "可视化",
    "section": "",
    "text": "读完本书的第一部分后，你已经（至少在表面上）了解了从事数据科学所需的最重要的工具。 现在是时候开始深入细节了。 在本书的这一部分，你将更深入地学习数据可视化。\n\n\n\n\n\n\n\nFigure 1: 数据可视化通常是数据探索的第一步。\n\n\n\n\n每一章都将探讨创建数据可视化的一个或几个方面。\n\n在 9  图层 中，你将学习图形的 layered grammar (分层语法)。\n在 10  探索性数据分析 中，你将把可视化与你的好奇心和怀疑精神结合起来，从而提出并回答有关数据的有趣问题。\n最后，在 11  沟通 中，你将学习如何将你的探索性图形进行升华，将其转化为解释性图形，这种图形可以帮助初次接触你分析的人尽可能快速、轻松地理解当前的情况。\n\n这三章将带你进入可视化世界的大门，但还有更多的知识有待学习。 学习更多知识的最佳途径是阅读 ggplot2 专著：ggplot2: Elegant graphics for data analysis。 该书更深入地探讨了底层理论，并提供了更多关于如何组合各个部分来解决实际问题的示例。 另一个很棒的资源是 ggplot2 扩展库 https://exts.ggplot2.tidyverse.org/gallery/。 这个网站列出了许多用新的几何对象 (geom) 和标度 (scale) 来扩展 ggplot2 的包。 如果你想用 ggplot2 做一些看起来很困难的事情，这里是一个很好的起点。",
    "crumbs": [
      "可视化"
    ]
  },
  {
    "objectID": "layers.html",
    "href": "layers.html",
    "title": "9  图层",
    "section": "",
    "text": "9.1 引言\n在 Chapter 1 中，你学到的远不止如何制作散点图、条形图和箱线图。你学到了一个基础，可以用它来通过 ggplot2 制作任何类型的图表。\n本章中，你将在学习图形的分层语法时扩展这一基础。我们将从更深入地探讨图形属性映射 (aesthetic mappings)、几何对象 (geometric objects) 和分面 (facets) 开始。然后，你将学习 ggplot2 在创建图表时在幕后进行的统计变换 (statistical transformations)。这些变换用于计算要绘制的新值，例如条形图中条形的高度或箱线图中的中位数。你还将学习位置调整 (position adjustments)，它会修改几何对象在图中的显示方式。最后，我们将简要介绍坐标系。\n我们不会涵盖这些图层中每一个的全部函数和选项，但我们会引导你了解 ggplot2 提供的最重要和最常用的功能，并向你介绍扩展 ggplot2 的包。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#引言",
    "href": "layers.html#引言",
    "title": "9  图层",
    "section": "",
    "text": "9.1.1 前提条件\n本章重点介绍 ggplot2。要访问本章中使用的数据集、帮助页面和函数，请运行以下代码加载 tidyverse：\n\nlibrary(tidyverse)",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#图形属性映射",
    "href": "layers.html#图形属性映射",
    "title": "9  图层",
    "section": "\n9.2 图形属性映射",
    "text": "9.2 图形属性映射\n\n“图片的最大价值在于，它迫使我们注意到我们从未预料会看到的东西。” — John Tukey\n\n请记住，ggplot2 包中附带的 mpg 数据框包含 234 条关于 38 种车型的观测数据。\n\nmpg\n#&gt; # A tibble: 234 × 11\n#&gt;   manufacturer model displ  year   cyl trans      drv     cty   hwy fl   \n#&gt;   &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n#&gt; 1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p    \n#&gt; 2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p    \n#&gt; 3 audi         a4      2    2008     4 manual(m6) f        20    31 p    \n#&gt; 4 audi         a4      2    2008     4 auto(av)   f        21    30 p    \n#&gt; 5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p    \n#&gt; 6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p    \n#&gt; # ℹ 228 more rows\n#&gt; # ℹ 1 more variable: class &lt;chr&gt;\n\nmpg 中的变量包括：\n\ndispl：汽车的发动机尺寸，单位是升 (liters)。这是一个数值变量。\nhwy：汽车在高速公路上的燃油效率，单位是每加仑英里数 (miles per gallon, mpg)。燃油效率低的汽车在行驶相同距离时比燃油效率高的汽车消耗更多的燃料。这是一个数值变量。\nclass：汽车的类型。这是一个分类变量。\n\n我们先从可视化不同 class 的汽车中 displ 和 hwy 之间的关系开始。我们可以用一个散点图来做到这一点，其中数值变量被映射到 x 和 y 图形属性，而分类变量被映射到像 color 或 shape 这样的图形属性。\n# 左\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point()\n\n# 右\nggplot(mpg, aes(x = displ, y = hwy, shape = class)) +\n  geom_point()\n#&gt; Warning: The shape palette can deal with a maximum of 6 discrete values because more\n#&gt; than 6 becomes difficult to discriminate\n#&gt; ℹ you have requested 7 values. Consider specifying shapes manually if you\n#&gt;   need that many of them.\n#&gt; Warning: Removed 62 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n当 class 被映射到 shape 时，我们会收到两条警告：\n\n1: The shape palette can deal with a maximum of 6 discrete values because more than 6 becomes difficult to discriminate; you have 7. Consider specifying shapes manually if you must have them. (形状调色板最多只能处理 6 个离散值，因为超过 6 个就很难区分了；而你有 7 个。如果必须使用，请考虑手动指定形状。)\n2: Removed 62 rows containing missing values (geom_point()). (移除了 62 行包含缺失值的记录 (geom_point()))\n\n由于 ggplot2 默认一次只使用六种形状，当你使用形状属性时，额外的组将不会被绘制。第二条警告与此相关——数据集中有 62 辆 SUV 没有被绘制出来。\n类似地，我们也可以将 class 映射到 size 或 alpha 图形属性，它们分别控制点的大小和透明度。\n# 左\nggplot(mpg, aes(x = displ, y = hwy, size = class)) +\n  geom_point()\n#&gt; Warning: Using size for a discrete variable is not advised.\n\n# 右\nggplot(mpg, aes(x = displ, y = hwy, alpha = class)) +\n  geom_point()\n#&gt; Warning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n这两个图也都会产生警告：\n\nUsing alpha for a discrete variable is not advised. (不建议对离散变量使用 alpha。)\n\n将一个无序的离散 (分类) 变量 (class) 映射到一个有序的图形属性 (size 或 alpha) 通常不是一个好主意，因为它暗示了一个实际上不存在的排序。\n一旦你映射了一个图形属性，ggplot2 会处理剩下的事情。它会选择一个合理的标度 (scale) 与该属性一起使用，并构建一个图例来解释水平 (levels) 和值 (values) 之间的映射关系。对于 x 和 y 图形属性，ggplot2 不会创建图例，但它会创建一个带有刻度标记和标签的坐标轴。坐标轴线提供与图例相同的信息；它解释了位置和值之间的映射。\n你也可以手动设置几何对象的视觉属性，将其作为几何对象函数的参数 (在 aes() 之外)，而不是依赖于变量映射来决定外观。例如，我们可以使图中所有的点都为蓝色：\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(color = \"blue\")\n\n\n\n\n\n\n\n在这里，颜色并不传达关于变量的信息，而只是改变了图的外观。你需要为该图形属性选择一个有意义的值：\n\n颜色的名称作为字符串，例如 color = \"blue\"\n\n点的大小，单位是毫米 (mm)，例如 size = 1\n\n点的形状，用数字表示，例如 shape = 1，如 Figure 9.1 所示。\n\n\n\n\n\n\n\n\nFigure 9.1: R 有 26 种内置形状，用数字标识。有一些看起来是重复的：例如，0、15 和 22 都是正方形。 区别在于 color 和 fill 图形属性的交互。 空心形状 (0-14) 的边框由 color 决定； 实心形状 (15-20) 用 color 填充；填充形状 (21-25) 的边框是 color，内部用 fill 填充。 形状的排列是为了让相似的形状相邻。\n\n\n\n\n到目前为止，我们已经讨论了在使用点几何对象 (point geom) 制作散点图时可以映射或设置的图形属性。你可以在图形属性规范说明文档 https://ggplot2.tidyverse.org/articles/ggplot2-specs.html 中了解所有可能的图形属性映射。\n你可以为图表使用的具体图形属性取决于你用来表示数据的几何对象 (geom)。在下一节中，我们将更深入地探讨几何对象。\n\n9.2.1 练习\n\n创建一个 hwy 对 displ 的散点图，其中的点是粉色填充的三角形。\n\n为什么下面的代码没有生成一个带有蓝色点的图？\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = \"blue\"))\n\n\nstroke 图形属性有什么作用？它适用于哪些形状？（提示：使用 ?geom_point）\n如果你将一个图形属性映射到变量名以外的东西，比如 aes(color = displ &lt; 5)，会发生什么？注意，你还需要指定 x 和 y。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#sec-geometric-objects",
    "href": "layers.html#sec-geometric-objects",
    "title": "9  图层",
    "section": "\n9.3 几何对象",
    "text": "9.3 几何对象\n下面这两幅图有何相似之处？\n\n\n\n\n\n\n\n\n\n\n两幅图都包含相同的 x 变量，相同的 y 变量，并且都描述了相同的数据。但这两幅图并不完全相同。每幅图使用不同的几何对象 (geom) 来表示数据。左边的图使用点几何对象 (point geom)，右边的图使用平滑几何对象 (smooth geom)，即一条拟合数据的平滑线。\n要改变图中的几何对象，只需改变你添加到 ggplot() 的几何对象函数即可。例如，要制作上面的图，你可以使用以下代码：\n\n# 左图\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n# 右图\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_smooth()\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nggplot2 中的每个几何对象函数都接受一个 mapping 参数，这个参数可以在几何对象图层中局部定义，也可以在 ggplot() 图层中全局定义。然而，并非每个图形属性都适用于每个几何对象。你可以设置一个点的形状，但不能设置一条线的“形状”。如果你尝试这样做，ggplot2 会默默地忽略该图形属性映射。另一方面，你可以设置一条线的线型 (linetype)。geom_smooth() 会为映射到线型的变量的每个唯一值绘制一条不同的线，具有不同的线型。\n# 左图\nggplot(mpg, aes(x = displ, y = hwy, shape = drv)) + \n  geom_smooth()\n\n# 右图\nggplot(mpg, aes(x = displ, y = hwy, linetype = drv)) + \n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n在这里，geom_smooth() 根据汽车的 drv 值（描述汽车的驱动系统）将汽车分成三条线。一条线描述所有 drv 值为 4 的点，一条线描述所有值为 f 的点，还有一条线描述所有值为 r 的点。在这里，4 代表四轮驱动 (four-wheel drive)，f 代表前轮驱动 (front-wheel drive)，r 代表后轮驱动 (rear-wheel drive)。\n如果这听起来有些奇怪，我们可以通过将线条叠加在原始数据之上，并根据 drv 对所有元素进行着色，来使其更清晰。\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) + \n  geom_point() +\n  geom_smooth(aes(linetype = drv))\n\n\n\n\n\n\n\n请注意，这幅图在同一个图形中包含了两个几何对象。\n许多几何对象，如 geom_smooth()，使用单个几何对象来显示多行数据。对于这些几何对象，你可以将 group 图形属性设置为一个分类变量，以绘制多个对象。ggplot2 会为分组变量的每个唯一值绘制一个独立的对象。实际上，每当你将一个图形属性映射到一个离散变量时（如 linetype 的例子），ggplot2 都会自动为这些几何对象进行数据分组。依赖这个特性很方便，因为 group 图形属性本身不会为几何对象添加图例或区分特征。\n# 左图\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth()\n\n# 中间\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(group = drv))\n\n# 右图\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n如果你将映射放在一个几何对象函数中，ggplot2 会将它们视为该图层的局部映射。它将使用这些映射来扩展或覆盖仅该图层的全局映射。这使得在不同图层中显示不同的图形属性成为可能。\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(aes(color = class)) + \n  geom_smooth()\n\n\n\n\n\n\n\n你可以使用同样的想法为每个图层指定不同的 data。在这里，我们使用红点和空心圆来突出显示双座车。geom_point() 中的局部数据参数会覆盖 ggplot() 中仅该图层的全局数据参数。\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    color = \"red\"\n  ) +\n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    shape = \"circle open\", size = 3, color = \"red\"\n  )\n\n\n\n\n\n\n\n几何对象是 ggplot2 的基本构建模块。你可以通过改变其几何对象来完全改变图的外观，不同的几何对象可以揭示你数据的不同特征。例如，下面的直方图和密度图显示高速公路里程的分布是双峰且右偏的，而箱线图则揭示了两个潜在的异常值。\n# 左图\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram(binwidth = 2)\n\n# 中间\nggplot(mpg, aes(x = hwy)) +\n  geom_density()\n\n# 右图\nggplot(mpg, aes(x = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2 提供了超过 40 种几何对象，但这并不能涵盖所有可能制作的图。如果你需要一种不同的几何对象，我们建议先查看扩展包，看看是否已经有人实现了它（参见 https://exts.ggplot2.tidyverse.org/gallery/ 的一些例子）。例如，ggridges 包 (https://wilkelab.org/ggridges) 对于制作山脊图 (ridgeline plots) 很有用，这对于可视化一个数值变量在不同分类变量水平上的密度非常有用。在下面的图中，我们不仅使用了一个新的几何对象 (geom_density_ridges())，还将同一个变量映射到了多个图形属性（drv 映射到 y、fill 和 color），并设置了一个图形属性 (alpha = 0.5) 来使密度曲线透明。\n\nlibrary(ggridges)\n\nggplot(mpg, aes(x = hwy, y = drv, fill = drv, color = drv)) +\n  geom_density_ridges(alpha = 0.5, show.legend = FALSE)\n#&gt; Picking joint bandwidth of 1.28\n\n\n\n\n\n\n\n要全面了解 ggplot2 提供的所有几何对象以及包中的所有函数，最好的地方是参考页面：https://ggplot2.tidyverse.org/reference。要了解任何单个几何对象的更多信息，请使用帮助（例如，?geom_smooth）。\n\n9.3.1 练习\n\n你会用什么几何对象来绘制折线图？箱线图？直方图？面积图？\n\n在本章前面，我们使用了 show.legend 但没有解释它：\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\nshow.legend = FALSE 在这里有什么作用？如果去掉它会发生什么？你认为我们之前为什么要使用它？\n\ngeom_smooth() 的 se 参数有什么作用？\n\n重新创建生成以下图形所需的 R 代码。请注意，图中凡是使用分类变量的地方，都是 drv。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#分面",
    "href": "layers.html#分面",
    "title": "9  图层",
    "section": "\n9.4 分面",
    "text": "9.4 分面\n在 Chapter 1 中，你学习了使用 facet_wrap() 进行分面，它根据一个分类变量将一个图分割成多个子图，每个子图显示数据的一个子集。\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_wrap(~cyl)\n\n\n\n\n\n\n\n要根据两个变量的组合来分面你的图，请从 facet_wrap() 切换到 facet_grid()。facet_grid() 的第一个参数也是一个公式，但现在它是一个双边公式：rows ~ cols。\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl)\n\n\n\n\n\n\n\n默认情况下，每个分面共享相同的 x 轴和 y 轴的标度 (scale) 和范围 (range)。这在你想要跨分面比较数据时很有用，但当你想要更好地可视化每个分面内部的关系时，这可能会有限制。在分面函数中将 scales 参数设置为 \"free_x\" 将允许跨列使用不同的 x 轴标度，\"free_y\" 将允许跨行使用不同的 y 轴标度，而 \"free\" 将同时允许两者。\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl, scales = \"free\")\n\n\n\n\n\n\n\n\n9.4.1 练习\n\n如果你对一个连续变量进行分面会发生什么？\n\n在上面使用 facet_grid(drv ~ cyl) 的图中，空的单元格意味着什么？运行下面的代码。它们与最终的图有什么关系？\n\nggplot(mpg) + \n  geom_point(aes(x = drv, y = cyl))\n\n\n\n下面的代码生成了什么图？. 有什么作用？\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)\n\n\n\n看本节的第一个分面图：\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ cyl, nrow = 2)\n\n使用分面代替颜色图形属性有什么优点？有什么缺点？如果你有一个更大的数据集，这种权衡可能会如何改变？\n\n阅读 ?facet_wrap。nrow 有什么作用？ncol 有什么作用？还有哪些其他选项可以控制单个面板的布局？为什么 facet_grid() 没有 nrow 和 ncol 参数？\n\n下面的哪个图更容易比较不同驱动系统汽车的发动机尺寸（displ）？这对于何时将分面变量放在行或列上有什么启示？\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(drv ~ .)\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() +\n  facet_grid(. ~ drv)\n\n\n\n使用 facet_wrap() 而不是 facet_grid() 重新创建以下图。分面标签的位置有何变化？\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#统计变换",
    "href": "layers.html#统计变换",
    "title": "9  图层",
    "section": "\n9.5 统计变换",
    "text": "9.5 统计变换\n考虑一个基本的条形图，用 geom_bar() 或 geom_col() 绘制。下面的图表显示了 diamonds 数据集中钻石的总数，按 cut 分组。diamonds 数据集在 ggplot2 包中，包含了约 54,000 颗钻石的信息，包括每颗钻石的 price、carat、color、clarity 和 cut。该图表显示，高质量切工的钻石比低质量切工的钻石更多。\n\nggplot(diamonds, aes(x = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\n在 x 轴上，图表显示了 cut，这是 diamonds 中的一个变量。在 y 轴上，它显示了计数 (count)，但计数不是 diamonds 中的一个变量！计数是从哪里来的？许多图形，比如散点图，绘制的是你数据集的原始值。而其他图形，比如条形图，会计算新的值来绘制：\n\n条形图、直方图和频率多边图会对你的数据进行分箱 (bin)，然后绘制每个箱中的计数，即落入每个箱中的点的数量。\n平滑器 (smoothers) 会对你的数据拟合一个模型，然后绘制模型的预测值。\n箱线图会计算分布的五数概括 (five-number summary)，然后将该概括显示为一个特殊格式的盒子。\n\n用于为图形计算新值的算法被称为 stat，即统计变换 (statistical transformation) 的缩写。Figure 9.2 展示了这个过程如何与 geom_bar() 一起工作。\n\n\n\n\n\n\n\nFigure 9.2: 在创建条形图时，我们首先从原始数据开始，然后 对其进行聚合以计算每个条中的观测数量， 最后将这些计算出的变量映射到图的图形属性上。\n\n\n\n\n你可以通过检查 stat 参数的默认值来了解一个几何对象使用的是哪个 stat。例如，?geom_bar 显示 stat 的默认值是 “count”，这意味着 geom_bar() 使用 stat_count()。stat_count() 与 geom_bar() 在同一个帮助页面上有文档。如果你向下滚动，名为“Computed variables”的部分解释说它计算了两个新变量：count 和 prop。\n每个几何对象都有一个默认的 stat；每个 stat 也有一个默认的几何对象。这意味着你通常可以使用几何对象而无需担心底层的统计变换。然而，有三个原因可能让你需要明确地使用一个 stat：\n\n\n你可能想覆盖默认的 stat。在下面的代码中，我们将 geom_bar() 的 stat 从 count（默认值）改为 identity。这使我们能够将条形的高度映射到 y 变量的原始值。\n\ndiamonds |&gt;\n  count(cut) |&gt;\n  ggplot(aes(x = cut, y = n)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n你可能想覆盖从变换后的变量到图形属性的默认映射。例如，你可能想显示一个比例的条形图，而不是计数的条形图：\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop), group = 1)) + \n  geom_bar()\n\n\n\n\n\n\n\n要查找 stat 可能计算的所有变量，请在 geom_bar() 的帮助文档中查找标题为“computed variables”（计算变量）的部分。\n\n\n你可能想在代码中更着重地突出统计变换。例如，你可能会使用 stat_summary()，它为每个唯一的 x 值总结 y 值，以突出你正在计算的摘要：\n\nggplot(diamonds) + \n  stat_summary(\n    aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )\n\n\n\n\n\n\n\n\n\nggplot2 提供了超过 20 个 stat 供你使用。每个 stat 都是一个函数，所以你可以用通常的方式获取帮助，例如 ?stat_bin。\n\n9.5.1 练习\n\n与 stat_summary() 关联的默认几何对象是什么？你如何重写上一个图，使用该几何对象函数而不是 stat 函数？\ngeom_col() 做什么？它与 geom_bar() 有何不同？\n大多数几何对象和统计变换都成对出现，几乎总是同时使用。列出所有的配对。它们有什么共同点？（提示：通读文档。）\nstat_smooth() 计算哪些变量？哪些参数控制其行为？\n\n在我们的比例条形图中，我们需要设置 group = 1。为什么？换句话说，下面这两张图有什么问题？\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop))) + \n  geom_bar()\nggplot(diamonds, aes(x = cut, fill = color, y = after_stat(prop))) + \n  geom_bar()",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#位置调整",
    "href": "layers.html#位置调整",
    "title": "9  图层",
    "section": "\n9.6 位置调整",
    "text": "9.6 位置调整\n条形图还有另外一个神奇之处。你可以使用 color 图形属性来为条形图上色，或者更有用地，使用 fill 图形属性：\n# 左图\nggplot(mpg, aes(x = drv, color = drv)) + \n  geom_bar()\n\n# 右图\nggplot(mpg, aes(x = drv, fill = drv)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n注意，如果你将 fill 图形属性映射到另一个变量，比如 class，会发生什么：条形会自动堆叠。每个彩色矩形代表 drv 和 class 的一个组合。\n\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar()\n\n\n\n\n\n\n\n堆叠是使用由 position 参数指定的位置调整 (position adjustment) 自动执行的。如果你不想要堆叠条形图，你可以使用其他三个选项之一：\"identity\"、\"dodge\" 或 \"fill\"。\n\n\nposition = \"identity\" 会将每个对象精确地放置在它在图上下文中所在的位置。这对条形图不是很有用，因为它会使它们重叠。为了看到重叠，我们要么需要通过将 alpha 设置为一个较小的值来使条形略微透明，要么通过设置 fill = NA 来使其完全透明。\n# 左图\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(alpha = 1/5, position = \"identity\")\n\n# 右图\nggplot(mpg, aes(x = drv, color = class)) + \n  geom_bar(fill = NA, position = \"identity\")\n\n\n\n\n\n\n\n\n\n\nidentity 位置调整对于二维几何对象（如点）更有用，它是默认设置。\n\nposition = \"fill\" 的工作方式类似于堆叠，但它使每组堆叠的条形具有相同的高度。这使得比较各组之间的比例更容易。\n\nposition = \"dodge\" 将重叠的对象直接并排放置。这使得比较单个值更容易。\n# 左图\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(position = \"fill\")\n\n# 右图\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\n还有一种调整类型对条形图没有用，但对散点图可能非常有用。回想我们的第一个散点图。你是否注意到，尽管数据集中有 234 个观测值，但该图只显示了 126 个点？\n\n\n\n\n\n\n\n\nhwy 和 displ 的基础值是四舍五入的，所以点出现在一个网格上，许多点相互重叠。这个问题被称为过度绘制 (overplotting)。这种排列方式使得很难看出数据的分布。数据点是均匀地分布在整个图中，还是有一个特殊的 hwy 和 displ 组合包含了 109 个值？\n你可以通过将位置调整设置为 “jitter” 来避免这种网格化。position = \"jitter\" 为每个点添加少量随机噪声。这会使点散开，因为不太可能有两个点会接收到相同数量的随机噪声。\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(position = \"jitter\")\n\n\n\n\n\n\n\n添加随机性似乎是改进你的图的一种奇怪方式，但虽然它使你的图在小尺度上不太准确，但它使你的图在大尺度上更具揭示性。因为这是一个非常有用的操作，ggplot2 为 geom_point(position = \"jitter\") 提供了一个简写：geom_jitter()。\n要了解更多关于位置调整的信息，请查阅与每个调整相关的帮助页面：?position_dodge、?position_fill、?position_identity、?position_jitter 和 ?position_stack。\n\n9.6.1 练习\n\n\n下面的图有什么问题？你如何改进它？\n\nggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point()\n\n\n\n这两张图有什么不同（如果有的话）？为什么？\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point()\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(position = \"identity\")\n\n\ngeom_jitter() 的哪些参数控制抖动的量？\n比较和对比 geom_jitter() 和 geom_count()。\ngeom_boxplot() 的默认位置调整是什么？创建一个 mpg 数据集的可视化来展示它。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#坐标系",
    "href": "layers.html#坐标系",
    "title": "9  图层",
    "section": "\n9.7 坐标系",
    "text": "9.7 坐标系\n坐标系可能是 ggplot2 中最复杂的部分。默认的坐标系是笛卡尔坐标系 (Cartesian coordinate system)，其中 x 和 y 的位置独立地决定每个点的位置。还有另外两种偶尔有用的坐标系。\n\n\ncoord_quickmap() 为地理地图正确设置长宽比。如果你用 ggplot2 绘制空间数据，这一点非常重要。我们在这本书里没有空间讨论地图，但你可以在 ggplot2: Elegant graphics for data analysis 的 Maps 章节 中学到更多。\nnz &lt;- map_data(\"nz\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\") +\n  coord_quickmap()\n\n\n\n\n\n\n\n\n\n\n\n\ncoord_polar() 使用极坐标 (polar coordinates)。极坐标揭示了条形图和鸡冠花图 (Coxcomb chart) 之间一个有趣的联系。\nbar &lt;- ggplot(data = diamonds) + \n  geom_bar(\n    mapping = aes(x = clarity, fill = clarity), \n    show.legend = FALSE,\n    width = 1\n  ) + \n  theme(aspect.ratio = 1)\n\nbar + coord_flip()\nbar + coord_polar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.7.1 练习\n\n使用 coord_polar() 将一个堆叠条形图变成一个饼图。\ncoord_quickmap() 和 coord_map() 有什么区别？\n\n下面的图告诉你城市和高速公路 mpg 之间的关系是什么？为什么 coord_fixed() 很重要？geom_abline() 做什么？\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +\n  geom_point() + \n  geom_abline() +\n  coord_fixed()",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#图形的分层语法",
    "href": "layers.html#图形的分层语法",
    "title": "9  图层",
    "section": "\n9.8 图形的分层语法",
    "text": "9.8 图形的分层语法\n我们可以扩展你在 Section 1.3 中学到的绘图模板，加入位置调整、统计变换、坐标系和分面：\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(\n     mapping = aes(&lt;MAPPINGS&gt;),\n     stat = &lt;STAT&gt;, \n     position = &lt;POSITION&gt;\n  ) +\n  &lt;COORDINATE_FUNCTION&gt; +\n  &lt;FACET_FUNCTION&gt;\n我们的新模板有七个参数，即模板中出现的带括号的词。实际上，你很少需要提供所有七个参数来制作一个图，因为 ggplot2 会为除了数据、映射和几何对象函数之外的所有东西提供有用的默认值。\n模板中的七个参数构成了图形的语法 (grammar of graphics)，一个用于构建图的正式系统。图形的语法基于这样一个洞见：你可以将任何图唯一地描述为一个数据集、一个几何对象、一组映射、一个统计变换、一个位置调整、一个坐标系、一个分面方案和一个主题的组合。\n要了解这是如何工作的，可以考虑如何从头开始构建一个基本的图：你可以从一个数据集开始，然后将其转换为你想要显示的信息（通过一个 stat）。接下来，你可以选择一个几何对象来代表变换后数据中的每个观测值。然后，你可以使用几何对象的图形属性来代表数据中的变量。你会将每个变量的值映射到一个图形属性的水平上。这些步骤在 Figure 9.3 中有所说明。然后，你会选择一个坐标系来放置这些几何对象，使用对象的位置（其本身也是一个图形属性）来显示 x 和 y 变量的值。\n\n\n\n\n\n\n\nFigure 9.3: 从原始数据到频率表，再到条形图的步骤， 其中条形的高度代表频率。\n\n\n\n\n此时，你已经有了一个完整的图，但你可以进一步调整几何对象在坐标系内的位置（位置调整）或将图分割成子图（分面）。你还可以通过添加一个或多个额外的图层来扩展该图，其中每个额外的图层使用一个数据集、一个几何对象、一组映射、一个统计变换和一个位置调整。\n你可以用这种方法来构建你想象中的任何图。换句话说，你可以用你在本章学到的代码模板来构建成千上万个独特的图。\n如果你想更多地了解 ggplot2 的理论基础，你可能会喜欢阅读 “The Layered Grammar of Graphics”，这篇科学论文详细描述了 ggplot2 的理论。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "layers.html#总结",
    "href": "layers.html#总结",
    "title": "9  图层",
    "section": "\n9.9 总结",
    "text": "9.9 总结\n在本章中，你学习了图形的分层语法，从图形属性和几何对象开始构建简单的图，用分面将图分割成子集，用统计变换来理解几何对象是如何计算的，用位置调整来控制几何对象可能重叠时的位置细节，以及用坐标系来从根本上改变 x 和 y 的含义。我们尚未涉及的一个图层是主题 (theme)，我们将在 Section 11.5 中介绍它。\n要全面了解 ggplot2 的功能，有两个非常有用的资源：ggplot2 速查表（你可以在 https://posit.co/resources/cheatsheets 找到）和 ggplot2 包网站 (https://ggplot2.tidyverse.org)。\n你应该从本章中学到的一个重要教训是，当你觉得需要一个 ggplot2 未提供的几何对象时，先看看是否已经有人通过创建一个提供该几何对象的 ggplot2 扩展包解决了你的问题，这总是一个好主意。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>图层</span>"
    ]
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "10  探索性数据分析",
    "section": "",
    "text": "10.1 引言\n本章将向你展示如何使用可视化和转换来系统地探索数据，统计学家称这项任务为探索性数据分析 (exploratory data analysis)，简称 EDA。 EDA 是一个迭代循环。 你需要：\nEDA 不是一个有着严格规则的正式流程。 更重要的是，EDA 是一种思维状态。 在 EDA 的初始阶段，你应该自由地探索你脑海中出现的每一个想法。 有些想法会成功，有些则会是死胡同。 随着探索的深入，你将逐渐聚焦于一些特别富有成效的见解，并最终将它们整理成文，与他人交流。\nEDA 是任何数据分析的重要组成部分，即使主要的研究问题已经现成地交给你，因为你总是需要调查数据的质量。 数据清理只是 EDA 的一个应用：你提出关于数据是否符合预期的问题。 要进行数据清理，你需要运用所有 EDA 的工具：可视化、转换和建模。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#引言",
    "href": "EDA.html#引言",
    "title": "10  探索性数据分析",
    "section": "",
    "text": "生成关于数据的问题。\n通过可视化、转换和建模来寻找答案。\n利用你学到的知识来完善你的问题和/或生成新的问题。\n\n\n\n\n10.1.1 先决条件\n在本章中，我们将结合你所学的 dplyr 和 ggplot2 知识，以交互方式提出问题，用数据回答问题，然后再提出新的问题。\n\nlibrary(tidyverse)",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#问题",
    "href": "EDA.html#问题",
    "title": "10  探索性数据分析",
    "section": "\n10.2 问题",
    "text": "10.2 问题\n\n“没有常规的统计问题，只有值得怀疑的统计程序。(The greatest value of a picture is when it forces us to notice what we never expected to see.)”\n— David Cox\n\n\n“对正确问题的近似答案，远胜于对错误问题的精确答案；前者通常是模糊的，而后者总是可以做得很精确。(Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.)”\n— John Tukey\n\n你在 EDA 过程中的目标是建立对数据的理解。最简单的方法是使用问题作为工具来引导你的探索。当你提出一个问题时，这个问题会将你的注意力集中到数据集的特定部分，并帮助你决定制作哪种图表、模型或进行何种转换。\nEDA 本质上是一个创造性的过程。和大多数创造性过程一样，提出高质量问题的关键在于生成大量的问题。在分析之初很难提出有启发性的问题，因为你不知道可以从数据集中获得哪些见解。另一方面，你每提出一个新问题，都会让你接触到数据的一个新方面，增加你做出发现的机会。如果你在每个问题之后，都根据你的发现提出一个新问题，你就能迅速深入到数据最有趣的部分，并形成一系列引人深思的问题。\n关于应该提出什么问题来指导研究，没有固定的规则。然而，有两类问题对于在数据中做出发现总是很有用的。你可以将这些问题粗略地表述为：\n\n我的变量内部存在什么样的变异？\n我的变量之间存在什么样的协变？\n\n本章的其余部分将探讨这两个问题。我们将解释什么是变异和协变，并向你展示几种回答每个问题的方法。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#变异",
    "href": "EDA.html#变异",
    "title": "10  探索性数据分析",
    "section": "\n10.3 变异",
    "text": "10.3 变异\n变异 (Variation) 是指一个变量的值在不同测量中变化的趋势。你在现实生活中可以轻易看到变异；如果你对任何连续变量进行两次测量，你会得到两个不同的结果。即使你测量的是恒定的量，比如光速，也是如此。你的每一次测量都会包含少量的误差，这个误差在每次测量中都会有所不同。如果你在不同的主体（例如，不同人的眼睛颜色）或不同的时间（例如，一个电子在不同时刻的能量水平）进行测量，变量也会发生变化。每个变量都有其自身的变异模式，这可以揭示关于它在同一次观测的不同测量之间以及跨观测之间如何变化的有趣信息。理解这种模式的最佳方法是可视化变量值的分布，这在 Chapter 1 中你已经学过了。\n我们将通过可视化 diamonds 数据集中约 54,000 颗钻石的重量（carat）分布来开始我们的探索。由于 carat 是一个数值变量，我们可以使用直方图：\n\nggplot(diamonds, aes(x = carat)) +\n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\n现在你已经可以可视化变异了，那么你应该在图表中寻找什么呢？你应该提出什么样的后续问题呢？我们整理了一份清单，列出了你在图中最可能找到的有用信息类型，以及针对每种信息的一些后续问题。提出好的后续问题的关键在于依赖你的好奇心（你想更多地了解什么？）以及你的怀疑精神（这可能是如何误导人的？）。\n\n10.3.1 典型值\n在条形图和直方图中，高条显示了变量的常见值，而短条显示了不那么常见的值。没有条形图的地方揭示了你的数据中未曾出现的值。要将这些信息转化为有用的问题，请寻找任何意料之外的情况：\n\n哪些值是最常见的？为什么？\n哪些值是罕见的？为什么？这是否符合你的预期？\n你能看到任何不寻常的模式吗？可能是什么解释了它们？\n\n让我们看一下较小钻石的 carat 分布。\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt; 3)\n\nggplot(smaller, aes(x = carat)) +\n  geom_histogram(binwidth = 0.01)\n\n\n\n\n\n\n\n这个直方图引出了一些有趣的问题：\n\n为什么在整数克拉和常见的克拉分数处有更多的钻石？\n为什么在每个峰值右侧的钻石比左侧的要多？\n\n可视化还可以揭示聚类，这表明你的数据中存在子群。要理解这些子群，请问：\n\n每个子群内的观测值彼此之间有何相似之处？\n不同聚类中的观测值彼此之间有何不同？\n你如何解释或描述这些聚类？\n为什么聚类的出现可能是误导性的？\n\n这些问题中，有些可以用数据回答，有些则需要关于数据的领域专业知识。其中许多问题会促使你探索变量之间的关系，例如，看看一个变量的值是否能解释另一个变量的行为。我们很快就会谈到这一点。\n\n10.3.2 异常值\n离群点 (Outliers) 是不寻常的观测值；即那些似乎不符合模式的数据点。有时离群点是数据录入错误，有时它们仅仅是在这次数据收集中碰巧观察到的极端值，而其他时候它们则预示着重要的新发现。当数据量很大时，离群点有时在直方图中很难看到。例如，看看 diamonds 数据集中 y 变量的分布。离群点的唯一证据是 x 轴上异常宽的范围。\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\n在常见的组（bin）中有太多的观测值，以至于罕见的组非常短，使得它们很难被看到（尽管如果你仔细盯着 0 的位置，也许会发现些什么）。为了更容易地看到异常值，我们需要使用 coord_cartesian() 来放大 y 轴的较小数值范围：\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5) +\n  coord_cartesian(ylim = c(0, 50))\n\n\n\n\n\n\n\n当你需要放大 x 轴时，coord_cartesian() 也有一个 xlim() 参数。ggplot2 还有 xlim() 和 ylim() 函数，它们的工作方式略有不同：它们会丢弃限制范围之外的数据。\n这让我们能看到有三个异常值：0、约 30 和约 60。我们用 dplyr 将它们提取出来：\n\nunusual &lt;- diamonds |&gt; \n  filter(y &lt; 3 | y &gt; 20) |&gt; \n  select(price, x, y, z) |&gt;\n  arrange(y)\nunusual\n\n# A tibble: 9 × 4\n  price     x     y     z\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  5139  0      0    0   \n2  6381  0      0    0   \n3 12800  0      0    0   \n4 15686  0      0    0   \n5 18034  0      0    0   \n6  2130  0      0    0   \n7  2130  0      0    0   \n8  2075  5.15  31.8  5.12\n9 12210  8.09  58.9  8.06\n\n\ny 变量测量的是这些钻石的三个维度之一，单位是毫米 (mm)。我们知道钻石的宽度不可能是 0mm，所以这些值肯定是错误的。通过进行 EDA，我们发现了被编码为 0 的缺失数据，而仅仅通过搜索 NA 是永远找不到的。接下来，我们可能会选择将这些值重新编码为 NA，以防止误导性的计算。我们可能还会怀疑 32mm 和 59mm 的测量值是不可信的：那些钻石超过一英寸长，但价格却没有数十万美元！\n一个好的做法是，在包含和不包含离群点的情况下重复你的分析。如果它们对结果的影响微乎其微，并且你无法弄清楚它们为什么存在，那么省略它们并继续分析是合理的。然而，如果它们对你的结果有重大影响，你就不应该在没有正当理由的情况下丢弃它们。你需要弄清楚是什么导致了它们（例如，数据录入错误），并在你的报告中披露你移除了它们。\n\n10.3.3 练习\n\n探索 diamonds 数据集中 x、y 和 z 每个变量的分布。你学到了什么？思考一下一颗钻石，你可能会如何决定哪个维度是长度、宽度和深度。\n探索 price 的分布。你发现了什么不寻常或令人惊讶的事情吗？（提示：仔细考虑 binwidth 并确保你尝试了各种不同的值。）\n有多少颗钻石是 0.99 克拉？有多少是 1 克拉？你认为造成这种差异的原因是什么？\n在放大直方图时，比较并对比 coord_cartesian() 与 xlim() 或 ylim()。如果你不设置 binwidth 会发生什么？如果你尝试放大到只显示半个条形会发生什么？",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#sec-unusual-values-eda",
    "href": "EDA.html#sec-unusual-values-eda",
    "title": "10  探索性数据分析",
    "section": "\n10.4 异常值",
    "text": "10.4 异常值\n如果你在数据集中遇到了异常值，并且只想继续进行其余的分析，你有两个选择。\n\n\n删除包含异常值的整行：\n\ndiamonds2 &lt;- diamonds |&gt; \n  filter(between(y, 3, 20))\n\n我们不推荐这个选项，因为一个无效值并不意味着该观测的所有其他值也无效。此外，如果你的数据质量较差，当你对每个变量都应用这种方法后，你可能会发现你已经没有任何数据了！\n\n\n相反，我们建议用缺失值替换异常值。最简单的方法是使用 mutate() 将变量替换为一个修改后的副本。你可以使用 if_else() 函数将异常值替换为 NA：\n\ndiamonds2 &lt;- diamonds |&gt; \n  mutate(y = if_else(y &lt; 3 | y &gt; 20, NA, y))\n\n\n\nggplot2 不确定应该在哪里绘制缺失值，所以它不会在图表中包含它们，但它会警告说它们已被移除：\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point()\n\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n要抑制该警告，请设置 na.rm = TRUE：\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point(na.rm = TRUE)\n\n其他时候，你想要理解为什么有缺失值的观测值与有记录值的观测值不同。例如，在 nycflights13::flights1 中，dep_time 变量中的缺失值表示航班被取消了。所以你可能想比较已取消和未取消航班的计划起飞时间。你可以通过创建一个新变量，使用 is.na() 来检查 dep_time 是否缺失来做到这一点。\n\nnycflights13::flights |&gt; \n  mutate(\n    cancelled = is.na(dep_time),\n    sched_hour = sched_dep_time %/% 100,\n    sched_min = sched_dep_time %% 100,\n    sched_dep_time = sched_hour + (sched_min / 60)\n  ) |&gt; \n  ggplot(aes(x = sched_dep_time)) + \n  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)\n\n\n\n\n\n\n\n然而，这张图并不理想，因为未取消的航班数量远多于取消的航班。在下一节中，我们将探讨一些改善这种比较的技巧。\n\n10.4.1 练习\n\n在直方图中，缺失值会怎么样？在条形图中，缺失值会怎么样？为什么在直方图和条形图中处理缺失值的方式有差异？\nna.rm = TRUE 在 mean() 和 sum() 中有什么作用？\n重新创建按航班是否取消着色的 scheduled_dep_time 频率图。同时，按 cancelled 变量进行分面。尝试在分面函数中使用不同的 scales 变量值，以减轻未取消航班数量多于取消航班数量的影响。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#协变",
    "href": "EDA.html#协变",
    "title": "10  探索性数据分析",
    "section": "\n10.5 协变",
    "text": "10.5 协变\n如果说变异描述的是单个变量内部的行为，那么协变描述的就是变量之间的行为。协变 (Covariation) 是指两个或多个变量的值以一种相关联的方式共同变化的趋势。发现协变的最佳方法是可视化两个或多个变量之间的关系。\n\n10.5.1 一个分类变量和一个数值变量\n例如，让我们使用 geom_freqpoly() 来探索钻石价格如何随其质量（以 cut 衡量）而变化：\n\nggplot(diamonds, aes(x = price)) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\n请注意，ggplot2 为 cut 使用了有序颜色标度，因为它在数据中被定义为一个有序因子变量。你将在 Section 16.6 中学习更多关于这些的内容。\ngeom_freqpoly() 的默认外观在这里不是很有用，因为高度（由总计数决定）在不同的 cut 之间差异很大，这使得很难看出它们分布形状的差异。\n为了使比较更容易，我们需要更换 y 轴上显示的内容。我们将不再显示计数，而是显示密度 (density)，即计数经过标准化，使得每个频率多边形下的面积为一。\n\nggplot(diamonds, aes(x = price, y = after_stat(density))) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\n注意，我们将密度映射到 y，但由于 density 不是 diamonds 数据集中的变量，我们需要先计算它。我们使用 after_stat() 函数来完成这个计算。\n这张图中有一些相当令人惊讶的事情 —— 似乎 Fair 级钻石（质量最低）的平均价格最高！但这也许是因为频率多边形有点难以解读 —— 这张图中信息量太大了。\n用于探索这种关系的一种视觉上更简单的图是并排的箱线图。\n\nggplot(diamonds, aes(x = cut, y = price)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n我们看到的关于分布的信息少了很多，但是箱线图更加紧凑，所以我们可以更容易地比较它们（并且可以在一张图上容纳更多）。它支持了那个与直觉相反的发现：质量更好的钻石通常更便宜！在练习中，你将面临挑战，去找出原因。\ncut 是一个有序因子：fair 比 good 差，good 又比 very good 差，依此类推。许多分类变量没有这种内在的顺序，所以你可能想重新排序它们以获得信息更丰富的展示。一种方法是使用 fct_reorder()。你将在 Section 16.4 中学习更多关于这个函数的内容，但我们想在这里给你一个快速预览，因为它非常有用。例如，看看 mpg 数据集中的 class 变量。你可能想知道高速公路里程是如何因车型而异的：\n\nggplot(mpg, aes(x = class, y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n为了让趋势更容易看清，我们可以根据 hwy 的中位数重新排序 class：\n\nggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n如果你的变量名很长，geom_boxplot() 将其翻转 90° 会效果更好。你可以通过交换 x 和 y 的美学映射来实现。\n\nggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n10.5.1.1 练习\n\n利用你所学到的知识，改进已取消航班与未取消航班出发时间的可视化。\n根据 EDA，diamonds 数据集中的哪个变量似乎对预测钻石价格最重要？该变量与切工 cut 有何关联？为什么这两个关系的组合会导致质量较低的钻石反而更昂贵？\n不要交换 x 和 y 变量，而是在垂直箱线图中添加 coord_flip() 作为一个新图层来创建水平箱线图。这与交换变量相比如何？\n箱线图的一个问题是，它们是在数据集小得多的时代发展起来的，并且倾向于显示过多的“离群值”。解决这个问题的一种方法是字母值图 (letter value plot)。安装 lvplot 包，并尝试使用 geom_lv() 来显示价格与切工的分布。你学到了什么？你如何解释这些图？\n使用 geom_violin()、分面的 geom_histogram()、彩色的 geom_freqpoly() 和彩色的 geom_density()，分别创建一个钻石价格与 diamonds 数据集中某个分类变量的可视化。比较和对比这四种图。基于一个分类变量的水平来可视化一个数值变量的分布，每种方法的优缺点是什么？\n如果你的数据集很小，有时使用 geom_jitter() 来避免过度绘制，从而更容易地看到连续变量和分类变量之间的关系是很有用的。ggbeeswarm 包提供了许多类似于 geom_jitter() 的方法。列出它们并简要描述每种方法的作用。\n\n10.5.2 两个分类变量\n要可视化分类变量之间的协变，你需要计算这些分类变量每个水平组合的观测数量。一种方法是依赖内置的 geom_count()：\n\nggplot(diamonds, aes(x = cut, y = color)) +\n  geom_count()\n\n\n\n\n\n\n\n图中每个圆圈的大小显示了在每个值组合处有多少观测值。协变将表现为特定 x 值和特定 y 值之间的强相关性。\n探索这些变量之间关系的另一种方法是使用 dplyr 计算计数：\n\ndiamonds |&gt; \n  count(color, cut)\n\n# A tibble: 35 × 3\n   color cut           n\n   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt;\n 1 D     Fair        163\n 2 D     Good        662\n 3 D     Very Good  1513\n 4 D     Premium    1603\n 5 D     Ideal      2834\n 6 E     Fair        224\n 7 E     Good        933\n 8 E     Very Good  2400\n 9 E     Premium    2337\n10 E     Ideal      3903\n# ℹ 25 more rows\n\n\n然后使用 geom_tile() 和 fill 美学进行可视化：\n\ndiamonds |&gt; \n  count(color, cut) |&gt;  \n  ggplot(aes(x = color, y = cut)) +\n  geom_tile(aes(fill = n))\n\n\n\n\n\n\n\n如果分类变量是无序的，你可能想使用 seriation 包来同时重新排列行和列，以便更清晰地揭示有趣的模式。对于更大的图，你可能想尝试 heatmaply 包，它可以创建交互式图。\n\n10.5.2.1 练习\n\n你如何重新缩放上面的计数数据集，以更清晰地显示颜色内的切工分布，或切工内的颜色分布？\n如果将颜色映射到 x 美学，将 cut 映射到 fill 美学，使用分段条形图你会得到什么不同的数据见解？计算落入每个分段的计数。\n使用 geom_tile() 和 dplyr 来探索平均航班起飞延迟如何随目的地和年份中的月份而变化。是什么使得图表难以阅读？你如何改进它？\n\n10.5.3 两个数值变量\n你已经见过一种可视化两个数值变量之间协变的绝佳方法：用 geom_point() 绘制散点图。你可以将协变看作是点的模式。例如，你可以看到钻石的克拉大小和价格之间存在正相关关系：克拉数越大的钻石价格越高。这种关系是指数级的。\n\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_point()\n\n\n\n\n\n\n\n（在本节中，我们将使用 smaller 数据集，以专注于小于 3 克拉的大部分钻石）\n随着数据集规模的增长，散点图的用处会减小，因为点开始重叠（overplot），堆积成均匀的黑色区域，使得难以判断数据在二维空间中密度的差异，也难以发现趋势。你已经见过一种解决这个问题的方法：使用 alpha 美学来增加透明度。\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_point(alpha = 1 / 100)\n\n\n\n\n\n\n\n但是对于非常大的数据集，使用透明度可能具有挑战性。另一个解决方案是使用分箱 (bin)。之前你使用 geom_histogram() 和 geom_freqpoly() 在一维空间中进行分箱。现在你将学习如何使用 geom_bin2d() 和 geom_hex() 在二维空间中进行分箱。\ngeom_bin2d() 和 geom_hex() 将坐标平面划分为二维的箱子，然后使用填充颜色来显示有多少个点落入每个箱子。geom_bin2d() 创建矩形箱子。geom_hex() 创建六边形箱子。你需要安装 hexbin 包才能使用 geom_hex()。\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_bin2d()\n# install.packages(\"hexbin\")\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_hex()\n\n\n\n\n\n\n\n\n\n\n另一个选择是将一个连续变量分箱，使其像一个分类变量一样。然后你可以使用你学过的可视化分类变量和连续变量组合的技巧之一。例如，你可以将 carat 分箱，然后为每个组显示一个箱线图：\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_width(carat, 0.1)))\n\n\n\n\n\n\n\ncut_width(x, width)，如上所述，将 x 分成宽度为 width 的箱。默认情况下，无论有多少观测值，箱线图看起来都大致相同（除了离群点的数量），所以很难看出每个箱线图总结了不同数量的点。一种显示这一点的方法是让箱线图的宽度与点的数量成正比，使用 varwidth = TRUE。\n\n10.5.3.1 练习\n\n除了用箱线图总结条件分布，你还可以使用频率多边形。在使用 cut_width() 与 cut_number() 时，你需要考虑什么？这对 carat 和 price 的二维分布的可视化有何影响？\n可视化按 price 划分的 carat 的分布。\n非常大的钻石与小钻石的价格分布相比如何？是如你所料，还是让你感到惊讶？\n结合你学到的两种技巧，来可视化 cut、carat 和 price 的组合分布。\n\n二维图揭示了在一维图中不可见的离群点。例如，下图中有些点的 x 和 y 值组合不寻常，这使得这些点成为离群点，即使它们的 x 和 y 值在单独检查时看起来正常。为什么在这种情况下，散点图比分箱图更适合显示？\n\ndiamonds |&gt; \n  filter(x &gt;= 4) |&gt; \n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))\n\n\n\n除了用 cut_width() 创建等宽的箱子，我们还可以用 cut_number() 创建包含大致相等数量的点的箱子。这种方法的优缺点是什么？\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_number(carat, 20)))",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#模式和模型",
    "href": "EDA.html#模式和模型",
    "title": "10  探索性数据分析",
    "section": "\n10.6 模式和模型",
    "text": "10.6 模式和模型\n如果两个变量之间存在系统性关系，它将以数据中的模式出现。如果你发现一个模式，问问自己：\n\n这个模式可能是由于巧合（即随机机会）吗？\n你如何描述该模式所暗示的关系？\n该模式所暗示的关系有多强？\n还有哪些其他变量可能会影响这种关系？\n如果你观察数据的各个子群，这种关系会改变吗？\n\n数据中的模式提供了关于关系的线索，即它们揭示了协变。如果你把变异看作是一种产生不确定性的现象，那么协变就是一种减少不确定性的现象。如果两个变量协变，你可以利用一个变量的值来更好地预测另一个变量的值。如果协变是由于因果关系（一种特殊情况），那么你可以利用一个变量的值来控制另一个变量的值。\n模型是从数据中提取模式的工具。例如，考虑钻石数据。很难理解切工和价格之间的关系，因为切工和克拉，以及克拉和价格是紧密相关的。可以使用一个模型来移除价格和克拉之间非常强的关系，这样我们就可以探索剩下的细微差别。下面的代码拟合了一个从 carat 预测 price 的模型，然后计算残差（预测值和实际值之间的差异）。残差为我们提供了一个视角，来看待在移除了克拉的影响之后钻石的价格。请注意，我们没有使用 price 和 carat 的原始值，而是先对它们进行对数转换，并对对数转换后的值拟合一个模型。然后，我们对残差进行指数化，将其放回到原始价格的尺度上。\n\nlibrary(tidymodels)\n\ndiamonds &lt;- diamonds |&gt;\n  mutate(\n    log_price = log(price),\n    log_carat = log(carat)\n  )\n\ndiamonds_fit &lt;- linear_reg() |&gt;\n  fit(log_price ~ log_carat, data = diamonds)\n\ndiamonds_aug &lt;- augment(diamonds_fit, new_data = diamonds) |&gt;\n  mutate(.resid = exp(.resid))\n\nggplot(diamonds_aug, aes(x = carat, y = .resid)) + \n  geom_point()\n\n\n\n\n\n\n\n一旦你移除了克拉和价格之间的强关系，你就可以在切工和价格之间的关系中看到你所期望的：相对于它们的大小，质量更好的钻石更昂贵。\n\nggplot(diamonds_aug, aes(x = cut, y = .resid)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n我们在这本书中不讨论建模，因为理解模型是什么以及它们如何工作，在你掌握了数据整理和编程的工具之后会最容易。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#总结",
    "href": "EDA.html#总结",
    "title": "10  探索性数据分析",
    "section": "\n10.7 总结",
    "text": "10.7 总结\n在本章中，你学习了各种工具来帮助你理解数据中的变异。你看到了处理单个变量和一对变量的技巧。如果你的数据中有几十个或几百个变量，这可能看起来很痛苦地受限，但它们是所有其他技术构建的基础。\n在下一章中，我们将专注于我们可以用来交流我们结果的工具。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "EDA.html#footnotes",
    "href": "EDA.html#footnotes",
    "title": "10  探索性数据分析",
    "section": "",
    "text": "请记住，当我们需明确指出一个函数（或数据集）的来源时，我们会使用特殊形式 package::function() 或 package::dataset。↩︎",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>探索性数据分析</span>"
    ]
  },
  {
    "objectID": "communication.html",
    "href": "communication.html",
    "title": "11  沟通",
    "section": "",
    "text": "11.1 引言\n在 Chapter 10 中，你学习了如何将绘图作为探索的工具。当你制作探索性图表时，你甚至在看图之前就知道它将显示哪些变量。你为每个图表的制作都带有目的，可以快速查看，然后转向下一个图表。在大多数分析过程中，你会生成数十甚至数百个图表，其中大部分会被立即丢弃。\n现在你已经理解了你的数据，你需要将你的理解传达给他人。你的受众可能不具备你的背景知识，也不会对数据投入很深。为了帮助他人快速建立对数据的良好心智模型，你需要投入大量精力，让你的图表尽可能地不言自明。在本章中，你将学习 ggplot2 为此提供的一些工具。\n本章重点介绍创建优质图形所需的工具。我们假设你知道自己想要什么，只需要知道如何实现它。因此，我们强烈建议将本章与一本优秀的通用可视化书籍结合起来阅读。我们特别喜欢 Albert Cairo 的 The Truthful Art。这本书不教创建可视化的具体方法，而是侧重于为了创建有效的图形你需要思考什么。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#引言",
    "href": "communication.html#引言",
    "title": "11  沟通",
    "section": "",
    "text": "11.1.1 先决条件\n在本章中，我们将再次重点关注 ggplot2。我们还将使用一些 dplyr 进行数据处理，使用 scales 包来覆盖默认的刻度、标签、转换和调色板，以及一些 ggplot2 扩展包，包括 Kamil Slowikowski 的 ggrepel (https://ggrepel.slowkow.com) 和 Thomas Lin Pedersen 的 patchwork (https://patchwork.data-imaginist.com)。如果你还没有安装这些包，别忘了用 install.packages() 来安装它们。\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(patchwork)",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#标签",
    "href": "communication.html#标签",
    "title": "11  沟通",
    "section": "\n11.2 标签",
    "text": "11.2 标签\n将探索性图表转变为说明性图表时，最简单的入手点就是使用好的标签。你可以使用 labs() 函数添加标签。\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"发动机排量 (L)\",\n    y = \"高速公路燃油经济性 (mpg)\",\n    color = \"汽车类型\",\n    title = \"燃油效率通常随发动机尺寸的增大而降低\",\n    subtitle = \"双座车（跑车）因其重量轻而成为例外\",\n    caption = \"数据来自 fueleconomy.gov\"\n  )\n\n\n\n\n\n\n\n图表标题的目的是总结主要发现。避免使用仅仅描述图表内容的标题，例如“发动机排量与燃油经济性的散点图”。\n如果你需要添加更多文本，还有另外两个有用的标签：subtitle 会在标题下方用较小的字体添加额外细节，而 caption 会在图表右下角添加文本，通常用于描述数据来源。你也可以使用 labs() 来替换坐标轴和图例的标题。通常，用更详细的描述替换简短的变量名，并包含单位，是一个好主意。\n除了文本字符串，还可以使用数学表达式。只需将 \"\" 换成 quote()，并在 ?plotmath 中阅读可用的选项：\n\ndf &lt;- tibble(\n  x = 1:10,\n  y = cumsum(x^2)\n)\n\nggplot(df, aes(x, y)) +\n  geom_point() +\n  labs(\n    x = quote(x[i]),\n    y = quote(sum(x[i] ^ 2, i == 1, n))\n  )\n\n\n\n\n\n\n\n\n11.2.1 练习\n\n使用燃油经济性数据创建一张图，并自定义 title、subtitle、caption、x、y 和 color 标签。\n\n使用燃油经济性数据重新创建下图。请注意，点的颜色和形状都随驱动系统类型而变化。\n\n\n\n\n\n\n\n\n\n找一个你在上个月创建的探索性图表，并为其添加信息丰富的标题，以便他人更容易理解。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#注释",
    "href": "communication.html#注释",
    "title": "11  沟通",
    "section": "\n11.3 注释",
    "text": "11.3 注释\n除了为图表的主要组成部分添加标签外，为单个观测或观测组添加标签也常常很有用。你可以使用的第一个工具是 geom_text()。geom_text() 类似于 geom_point()，但它有一个额外的美学属性：label。这使得在图表中添加文本标签成为可能。\n标签有两个可能的来源。首先，你可能有一个提供标签的 tibble。在下面的图表中，我们筛选出每种驱动类型中发动机尺寸最大的汽车，并将其信息保存为一个名为 label_info 的新数据框。\n\nlabel_info &lt;- mpg |&gt;\n  group_by(drv) |&gt;\n  arrange(desc(displ)) |&gt;\n  slice_head(n = 1) |&gt;\n  mutate(\n    drive_type = case_when(\n      drv == \"f\" ~ \"前轮驱动\",\n      drv == \"r\" ~ \"后轮驱动\",\n      drv == \"4\" ~ \"四轮驱动\"\n    )\n  ) |&gt;\n  select(displ, hwy, drv, drive_type)\n\nlabel_info\n#&gt; # A tibble: 3 × 4\n#&gt; # Groups:   drv [3]\n#&gt;   displ   hwy drv   drive_type\n#&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;     \n#&gt; 1   6.5    17 4     四轮驱动  \n#&gt; 2   5.3    25 f     前轮驱动  \n#&gt; 3   7      24 r     后轮驱动\n\n然后，我们使用这个新的数据框直接标记这三个组，用直接放置在图上的标签来替换图例。通过使用 fontface 和 size 参数，我们可以自定义文本标签的外观。它们比图上的其他文本更大，并且是粗体的。（theme(legend.position = \"none\") 会关闭所有图例 —— 我们稍后会更详细地讨论它。）\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_text(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, hjust = \"right\", vjust = \"bottom\"\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n注意使用 hjust (水平对齐) 和 vjust (垂直对齐) 来控制标签的对齐方式。\n然而，我们上面制作的带注释的图表很难阅读，因为标签之间以及标签与点之间存在重叠。我们可以使用 ggrepel 包中的 geom_label_repel() 函数来解决这两个问题。这个有用的包会自动调整标签，使其不重叠：\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_label_repel(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, nudge_y = 2\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n你也可以用同样的方法，使用 ggrepel 包中的 geom_text_repel() 来突出图上的某些点。注意这里使用的另一个便捷技巧：我们添加了第二层大的空心点，以进一步突出被标记的点。\n\npotential_outliers &lt;- mpg |&gt;\n  filter(hwy &gt; 40 | (hwy &gt; 20 & displ &gt; 5))\n  \nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_text_repel(data = potential_outliers, aes(label = model)) +\n  geom_point(data = potential_outliers, color = \"red\") +\n  geom_point(\n    data = potential_outliers,\n    color = \"red\", size = 3, shape = \"circle open\"\n  )\n\n\n\n\n\n\n\n记住，除了 geom_text() 和 geom_label()，ggplot2 中还有许多其他几何对象可以帮助你注释图表。一些想法：\n\n使用 geom_hline() 和 geom_vline() 添加参考线。我们通常让它们变粗 (linewidth = 2) 并且是白色的 (color = white)，然后将它们绘制在主数据层的下方。这样它们很容易看到，又不会分散对数据的注意力。\n使用 geom_rect() 在感兴趣的点周围绘制一个矩形。矩形的边界由美学属性 xmin、xmax、ymin、ymax 定义。或者，可以研究一下 ggforce 包，特别是 geom_mark_hull()，它允许你用凸包来注释点的子集。\n使用带 arrow 参数的 geom_segment()，用箭头来吸引对某个点的注意。使用美学属性 x 和 y 定义起始位置，xend 和 yend 定义结束位置。\n\n另一个用于向图表添加注释的便捷函数是 annotate()。根据经验，几何对象 (geom) 通常用于高亮数据的子集，而 annotate() 则用于向图表添加一个或少数几个注释元素。\n为了演示 annotate() 的用法，让我们创建一些要添加到图表中的文本。这段文本有点长，所以我们将使用 stringr::str_wrap()，根据你想要的每行字符数来自动为其添加换行符：\n\ntrend_text &lt;- \"Larger engine sizes tend to have lower fuel economy.\" |&gt;\n  str_wrap(width = 30)\ntrend_text\n#&gt; [1] \"Larger engine sizes tend to\\nhave lower fuel economy.\"\n\n然后，我们添加两层注释：一层使用标签几何对象 (label geom)，另一层使用线段几何对象 (segment geom)。两者中的 x 和 y 美学属性定义了注释的起始位置，而线段注释中的 xend 和 yend 美学属性定义了线段的结束位置。另请注意，该线段被样式化为箭头。\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  annotate(\n    geom = \"label\", x = 3.5, y = 38,\n    label = trend_text,\n    hjust = \"left\", color = \"red\"\n  ) +\n  annotate(\n    geom = \"segment\",\n    x = 3, y = 35, xend = 5, yend = 25, color = \"red\",\n    arrow = arrow(type = \"closed\")\n  )\n\n\n\n\n\n\n\n注释是传达可视化主要结论和有趣特征的强大工具。唯一的限制是你的想象力（以及你为使注释美观而定位它们的耐心）！\n\n11.3.1 练习\n\n使用 geom_text() 和无限大的位置，将文本放置在图表的四个角上。\n使用 annotate() 在你上一张图的中间添加一个点几何对象，而无需创建一个 tibble。自定义该点的形状、大小或颜色。\ngeom_text() 的标签如何与分面 (faceting) 交互？你如何为一个单独的分面添加标签？你如何在每个分面中放置不同的标签？（提示：考虑传递给 geom_text() 的数据集。）\ngeom_label() 的哪些参数控制背景框的外观？\narrow() 的四个参数是什么？它们如何工作？创建一系列图表来演示最重要的选项。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#标度",
    "href": "communication.html#标度",
    "title": "11  沟通",
    "section": "\n11.4 标度",
    "text": "11.4 标度\n让你的图表更适合沟通的第三种方法是调整标度 (scales)。标度控制了美学映射如何以视觉方式呈现。\n\n11.4.1 默认标度\n通常，ggplot2 会自动为你添加标度。例如，当你输入：\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nggplot2 会在后台自动添加默认标度：\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  scale_color_discrete()\n\n注意标度的命名方案：scale_ 后跟美学名称，然后是 _，再后跟标度名称。默认标度根据它们所对应的变量类型来命名：连续型 (continuous)、离散型 (discrete)、日期时间型 (datetime) 或日期型 (date)。scale_x_continuous() 将 displ 的数值放在 x 轴的连续数轴上，scale_color_discrete() 为每种汽车的 class 选择颜色，等等。下面你将学到许多非默认的标度。\n默认标度经过精心挑选，能在各种输入下表现良好。尽管如此，你可能还是想覆盖默认设置，原因有二：\n\n你可能想微调默认标度的一些参数。这允许你做一些事情，比如改变坐标轴上的刻度，或者图例上的键标签。\n你可能想完全替换掉标度，使用一种完全不同的算法。通常你可以做得比默认更好，因为你对数据有更多的了解。\n\n11.4.2 坐标轴刻度和图例键\n坐标轴和图例统称为引导 (guides)。坐标轴用于 x 和 y 美学；图例用于其他所有美学。\n有两个主要参数会影响坐标轴上刻度的外观和图例上键的外观：breaks 和 labels。Breaks 控制刻度的位置，或与键相关联的值。Labels 控制与每个刻度/键相关联的文本标签。breaks 最常见的用途是覆盖默认选择：\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(15, 40, by = 5)) \n\n\n\n\n\n\n\n你可以用同样的方式使用 labels（一个与 breaks 长度相同的字符向量），但你也可以将其设置为 NULL 来完全抑制标签。这对于地图，或者在不能分享绝对数值的情况下发布图表时很有用。你也可以使用 breaks 和 labels 来控制图例的外观。对于分类变量的离散标度，labels 可以是一个命名列表，包含现有的级别名称和它们期望的标签。\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_x_continuous(labels = NULL) +\n  scale_y_continuous(labels = NULL) +\n  scale_color_discrete(labels = c(\"4\" = \"四轮\", \"f\" = \"前轮\", \"r\" = \"后轮\"))\n\n\n\n\n\n\n\nlabels 参数与 scales 包中的标签函数相结合，对于将数字格式化为货币、百分比等也很有用。左边的图显示了使用 label_dollar() 的默认标签，它添加了美元符号以及千位分隔符逗号。右边的图通过将美元值除以 1000 并添加后缀 “K”（代表 “千”）以及添加自定义刻度，进行了进一步的定制。注意 breaks 是在数据的原始标度上。\n# 左图\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(labels = label_dollar())\n\n# 右图\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(\n    labels = label_dollar(scale = 1/1000, suffix = \"K\"), \n    breaks = seq(1000, 19000, by = 6000)\n  )\n\n\n\n\n\n\n\n\n\n\n另一个方便的标签函数是 label_percent():\n\nggplot(diamonds, aes(x = cut, fill = clarity)) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(name = \"百分比\", labels = label_percent())\n\n\n\n\n\n\n\nbreaks 的另一个用途是当你数据点相对较少，并想确切地突出显示观测发生的位置时。例如，看这张图，它显示了每位美国总统任期的开始和结束时间。\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_x_date(name = NULL, breaks = presidential$start, date_labels = \"'%y\")\n\n\n\n\n\n\n\n请注意，对于 breaks 参数，我们使用 presidential$start 提取了 start 变量作为向量，因为我们不能为这个参数进行美学映射。另请注意，日期和日期时间标度的 breaks 和 labels 的指定方式略有不同：\n\ndate_labels 接受一个格式说明，其格式与 parse_datetime() 相同。\ndate_breaks（此处未显示）接受一个像 “2 days” 或 “1 month” 这样的字符串。\n\n11.4.3 图例布局\n你最常使用 breaks 和 labels 来调整坐标轴。虽然它们也对图例起作用，但你更可能使用其他一些技巧。\n要控制图例的整体位置，你需要使用 theme() 设置。我们将在本章末尾回到主题，但简而言之，它们控制图表的非数据部分。主题设置 legend.position 控制图例的绘制位置：\nbase &lt;- ggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nbase + theme(legend.position = \"right\") # 默认\nbase + theme(legend.position = \"left\")\nbase + \n  theme(legend.position = \"top\") +\n  guides(color = guide_legend(nrow = 3))\nbase + \n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n如果你的图表又短又宽，就把图例放在顶部或底部；如果它又高又窄，就把图例放在左侧或右侧。你也可以使用 legend.position = \"none\" 来完全抑制图例的显示。\n要控制单个图例的显示，请使用 guides() 以及 guide_legend() 或 guide_colorbar()。下面的例子展示了两个重要的设置：使用 nrow 控制图例使用的行数，以及覆盖其中一个美学属性使点变大。如果你在一个图表上使用了较低的 alpha 来显示许多点，这尤其有用。\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2, override.aes = list(size = 4)))\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n注意，guides() 中的参数名称与美学名称相匹配，就像在 labs() 中一样。\n\n11.4.4 替换标度\n除了稍微调整细节，你还可以完全替换标度。你最可能想替换的两种标度是：连续位置标度和颜色标度。幸运的是，同样的原则也适用于所有其他美学，所以一旦你掌握了位置和颜色，你就能很快学会其他标度的替换。\n对你的变量进行变换绘图非常有用。例如，如果我们对 carat 和 price 进行对数变换，就更容易看出它们之间的精确关系：\n# 左图\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d()\n\n# 右图\nggplot(diamonds, aes(x = log10(carat), y = log10(price))) +\n  geom_bin2d()\n\n\n\n\n\n\n\n\n\n\n然而，这种变换的缺点是坐标轴现在用变换后的值来标记，这使得解读图表变得困难。我们可以在标度中进行变换，而不是在美学映射中进行。这在视觉上是完全相同的，除了坐标轴是用原始数据标度来标记的。\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d() + \n  scale_x_log10() + \n  scale_y_log10()\n\n\n\n\n\n\n\n另一个经常被定制的标度是颜色。默认的分类标度选择的颜色在色轮上均匀分布。有用的替代方案是 ColorBrewer 标度，这些标度经过手工调整，对有常见色盲类型的人更友好。下面的两张图看起来相似，但红色和绿色的色调有足够的差异，使得右边的点即使对于红绿色盲的人也能区分。1\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv))\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n别忘了使用更简单的技巧来提高可访问性。如果只有几种颜色，你可以添加一个冗余的形状映射。这也有助于确保你的图表在黑白模式下也是可解释的。\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv, shape = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\nColorBrewer 标度在 https://colorbrewer2.org/ 上有在线文档，并通过 Erich Neuwirth 的 RColorBrewer 包在 R 中可用。Figure 11.1 展示了所有调色板的完整列表。如果你的分类值是有序的，或者有一个“中间值”，那么顺序（顶部）和发散（底部）调色板特别有用。这种情况通常在你使用 cut() 将连续变量转换为分类变量时出现。\n\n\n\n\n\n\n\nFigure 11.1: 所有的 ColorBrewer 标度。\n\n\n\n\n当你有一个预定义的值与颜色之间的映射时，使用 scale_color_manual()。例如，如果我们将总统党派映射到颜色，我们希望使用标准的映射，即红色代表共和党，蓝色代表民主党。分配这些颜色的一种方法是使用十六进制颜色代码：\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id, color = party)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_color_manual(values = c(Republican = \"#E81B23\", Democratic = \"#00AEF3\"))\n\n\n\n\n\n\n\n对于连续颜色，你可以使用内置的 scale_color_gradient() 或 scale_fill_gradient()。如果你有一个发散标度，你可以使用 scale_color_gradient2()。这允许你，例如，给正值和负值不同的颜色。如果你想区分高于或低于平均值的点，这有时也很有用。\n另一个选择是使用 viridis 颜色标度。其设计者 Nathaniel Smith 和 Stéfan van der Walt 精心定制了连续颜色方案，这些方案对于各种形式色盲的人来说都是可感知的，并且在颜色和黑白模式下都是感知均匀的。这些标度在 ggplot2 中以连续 (c)、离散 (d) 和分箱 (b) 调色板的形式提供。\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  labs(title = \"默认，连续\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_c() +\n  labs(title = \"Viridis, 连续\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_b() +\n  labs(title = \"Viridis, 分箱\", x = NULL, y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n请注意，所有颜色标度都有两种变体：scale_color_*() 和 scale_fill_*()，分别用于 color 和 fill 美学（颜色标度同时提供英式和美式拼写）。\n\n11.4.5 缩放\n有三种方法可以控制图表的限制范围：\n\n调整绘制的数据。\n在每个标度中设置限制。\n在 coord_cartesian() 中设置 xlim 和 ylim。\n\n我们将在系列图表中演示这些选项。左边的图显示了发动机尺寸和燃油效率之间的关系，按驱动系统类型着色。右边的图显示了相同的变量，但对绘制的数据进行了子集化。对数据进行子集化影响了 x 和 y 轴的标度以及平滑曲线。\n# 左图\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n# 右图\nmpg |&gt;\n  filter(displ &gt;= 5 & displ &lt;= 6 & hwy &gt;= 10 & hwy &lt;= 25) |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n让我们将这些与下面的两张图进行比较，其中左边的图在单个标度上设置了 limits，而右边的图在 coord_cartesian() 中设置了它们。我们可以看到，缩小 limits 等同于对数据进行子集化。因此，要放大图表的某个区域，通常最好使用 coord_cartesian()。\n# 左图\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  scale_x_continuous(limits = c(5, 6)) +\n  scale_y_continuous(limits = c(10, 25))\n\n# 右图\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  coord_cartesian(xlim = c(5, 6), ylim = c(10, 25))\n\n\n\n\n\n\n\n\n\n\n另一方面，如果你想 扩展 限制范围，例如，为了在不同图表间匹配标度，在单个标度上设置 limits 通常更有用。例如，如果我们提取两种类型的汽车并分别绘制它们，很难比较这些图表，因为所有三个标度（x 轴、y 轴和颜色美学）的范围都不同。\nsuv &lt;- mpg |&gt; filter(class == \"suv\")\ncompact &lt;- mpg |&gt; filter(class == \"compact\")\n\n# 左图\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n# 右图\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n克服这个问题的一种方法是在多个图表之间共享标度，使用完整数据的 limits 来训练标度。\nx_scale &lt;- scale_x_continuous(limits = range(mpg$displ))\ny_scale &lt;- scale_y_continuous(limits = range(mpg$hwy))\ncol_scale &lt;- scale_color_discrete(limits = unique(mpg$drv))\n\n# 左图\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n# 右图\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n\n\n\n\n\n\n\n\n\n在这种特殊情况下，你可以简单地使用分面，但这种技术在更一般的情况下也很有用，例如，如果你想将图表分布在报告的多个页面上。\n\n11.4.6 练习\n\n\n为什么下面的代码没有覆盖默认的标度？\n\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  scale_color_gradient(low = \"white\", high = \"red\") +\n  coord_fixed()\n\n\n每个标度的第一个参数是什么？它与 labs() 有何不同？\n\n通过以下方式更改总统任期的显示：\n\n结合定制颜色和 x 轴刻度的两个变体。\n改进 y 轴的显示。\n用总统的名字标记每个任期。\n添加信息丰富的图表标签。\n每 4 年设置一个刻度（这比看起来要棘手！）。\n\n\n\n首先，创建以下图表。然后，使用 override.aes 修改代码，使图例更容易看清。\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_point(aes(color = cut), alpha = 1/20)",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#sec-themes",
    "href": "communication.html#sec-themes",
    "title": "11  沟通",
    "section": "\n11.5 主题",
    "text": "11.5 主题\n最后，你可以使用主题 (theme) 来自定义图表的非数据元素：\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme_bw()\n\n\n\n\n\n\n\nggplot2 包含了 Figure 11.2 中显示的八个主题，其中 theme_gray() 是默认主题。2 更多的主题包含在附加包中，如 Jeffrey Arnold 的 ggthemes (https://jrnold.github.io/ggthemes)。如果你试图匹配特定的公司或期刊风格，你也可以创建自己的主题。\n\n\n\n\n\n\n\nFigure 11.2: ggplot2 内置的八个主题。\n\n\n\n\n也可以控制每个主题的单个组件，比如 y 轴使用的字体大小和颜色。我们已经看到 legend.position 控制图例的绘制位置。还有许多其他图例方面可以通过 theme() 进行自定义。例如，在下面的图中，我们改变了图例的方向，并给它加上了黑色的边框。注意，图例框和图表标题元素的自定义是通过 element_*() 函数完成的。这些函数指定了非数据组件的样式，例如，标题文本在 element_text() 的 face 参数中被加粗，图例边框颜色在 element_rect() 的 color 参数中定义。控制标题和脚注位置的主题元素分别是 plot.title.position 和 plot.caption.position。在下面的图中，这些被设置为 \"plot\"，表示这些元素与整个绘图区域对齐，而不是绘图面板（默认）。还使用了一些其他有用的 theme() 组件来更改标题和脚注文本的位置或格式。\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  labs(\n    title = \"发动机尺寸越大，燃油经济性越低\",\n    caption = \"来源: https://fueleconomy.gov.\"\n  ) +\n  theme(\n    legend.position = c(0.6, 0.7),\n    legend.direction = \"horizontal\",\n    legend.box.background = element_rect(color = \"black\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.title.position = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.caption = element_text(hjust = 0)\n  )\n#&gt; Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n#&gt; 3.5.0.\n#&gt; ℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n有关所有 theme() 组件的概述，请参阅 ?theme 的帮助文档。ggplot2 book 也是了解主题全部细节的好去处。\n\n11.5.1 练习\n\n从 ggthemes 包中选择一个主题，并将其应用于你制作的最后一张图。\n将你的图表的坐标轴标签设置为蓝色和粗体。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#布局",
    "href": "communication.html#布局",
    "title": "11  沟通",
    "section": "\n11.6 布局",
    "text": "11.6 布局\n到目前为止，我们讨论了如何创建和修改单个图表。如果你有多个图表，并希望以某种方式将它们布局，该怎么办？patchwork 包允许你将单独的图表组合成同一个图形。我们在本章前面加载了这个包。\n要将两个图表并排放置，你可以简单地将它们相加。注意，你首先需要创建图表并将它们保存为对象（在下面的例子中，它们被称为 p1 和 p2）。然后，你用 + 将它们并排。\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"图 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"图 2\")\np1 + p2\n\n\n\n\n\n\n\n值得注意的是，在上面的代码块中，我们没有使用 patchwork 包的新函数。相反，该包为 + 运算符添加了新功能。\n你也可以用 patchwork 创建复杂的图表布局。在下面，| 将 p1 和 p3 并排放置，而 / 将 p2 移动到下一行。\n\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"图 3\")\n(p1 | p3) / p2\n\n\n\n\n\n\n\n此外，patchwork 允许你将多个图表的图例收集到一个公共图例中，自定义图例的位置以及图表的尺寸，并为你的图表添加一个共同的标题、副标题、脚注等。下面我们创建 5 张图。我们关闭了箱线图和散点图的图例，并用 & theme(legend.position = \"top\") 将密度图的图例收集到图表的顶部。注意这里使用了 & 运算符而不是通常的 +。这是因为我们正在修改 patchwork 图的主题，而不是单个 ggplot 对象。图例被放置在顶部，在 guide_area() 内部。最后，我们还自定义了 patchwork 中各个组件的高度——引导区高度为 1，箱线图为 3，密度图为 2，分面散点图为 4。Patchwork 使用这个比例来划分你为图表分配的区域，并相应地放置组件。\n\np1 &lt;- ggplot(mpg, aes(x = drv, y = cty, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"图 1\")\n\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"图 2\")\n\np3 &lt;- ggplot(mpg, aes(x = cty, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"图 3\")\n\np4 &lt;- ggplot(mpg, aes(x = hwy, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"图 4\")\n\np5 &lt;- ggplot(mpg, aes(x = cty, y = hwy, color = drv)) + \n  geom_point(show.legend = FALSE) + \n  facet_wrap(~drv) +\n  labs(title = \"图 5\")\n\n(guide_area() / (p1 + p2) / (p3 + p4) / p5) +\n  plot_annotation(\n    title = \"不同驱动方式汽车的城市和高速公路里程\",\n    caption = \"来源: https://fueleconomy.gov.\"\n  ) +\n  plot_layout(\n    guides = \"collect\",\n    heights = c(1, 3, 2, 4)\n    ) &\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n如果你想了解更多关于用 patchwork 组合和布局多个图表的信息，我们建议你浏览该包网站上的指南：https://patchwork.data-imaginist.com。\n\n11.6.1 练习\n\n\n如果在下面的图表布局中省略括号，会发生什么？你能解释为什么会这样吗？\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"图 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"图 2\")\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"图 3\")\n\n(p1 | p2) / p3\n\n\n\n使用上一个练习中的三张图，重新创建下面的 patchwork。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#总结",
    "href": "communication.html#总结",
    "title": "11  沟通",
    "section": "\n11.7 总结",
    "text": "11.7 总结\n在本章中，你学习了如何添加图表标签，如标题、副标题、脚注，以及如何修改默认的坐标轴标签，如何使用注释为你的图表添加信息性文本或突出显示特定数据点，如何自定义坐标轴标度，以及如何更改图表的主题。你还学习了如何使用简单和复杂的图表布局将多个图表组合成一个单一的图形。\n虽然到目前为止你已经学会了如何制作许多不同类型的图表以及如何使用各种技术来定制它们，但我们仅仅触及了你能用 ggplot2 创造的东西的皮毛。如果你想全面了解 ggplot2，我们推荐阅读 ggplot2: Elegant Graphics for Data Analysis 这本书。其他有用的资源包括 Winston Chang 的 R Graphics Cookbook 和 Claus Wilke 的 Fundamentals of Data Visualization。",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "communication.html#footnotes",
    "href": "communication.html#footnotes",
    "title": "11  沟通",
    "section": "",
    "text": "你可以使用像 SimDaltonism 这样的工具来模拟色盲，以测试这些图像。↩︎\n很多人想知道为什么默认主题有一个灰色的背景。这是一个故意的选择，因为它既突出了数据，又使网格线可见。白色的网格线是可见的（这很重要，因为它们显著地辅助了位置判断），但它们的视觉影响很小，我们可以轻易地忽略它们。灰色的背景使图表具有与文本相似的排版颜色，确保图形与文档的流程融为一体，而不会因为明亮的白色背景而跳脱出来。最后，灰色的背景创造了一个连续的颜色区域，确保图表被感知为一个单一的视觉实体。↩︎",
    "crumbs": [
      "可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>沟通</span>"
    ]
  },
  {
    "objectID": "transform.html",
    "href": "transform.html",
    "title": "数据转换",
    "section": "",
    "text": "本书的第二部分深入探讨了数据可视化。在本书的这一部分，你将学习数据框 (data frame) 中会遇到的最重要变量类型，以及可以用来处理它们的工具。\n\n\n\n\n\n\n\nFigure 1: 数据转换的选项在很大程度上取决于所涉及的数据类型，这也是本书这一部分的主题。\n\n\n\n\n你可以根据需要阅读这些章节；它们的设计初衷是使其在很大程度上保持独立，因此可以不按顺序阅读。\n\n12  逻辑向量 将教你有关逻辑向量的知识。这是最简单的向量类型，但功能却极其强大。你将学习如何通过数值比较来创建它们，如何用布尔代数 (Boolean algebra) 来组合它们，如何在汇总摘要中使用它们，以及如何利用它们进行条件转换。\n13  数值 深入探讨了处理数值向量的工具，数值向量是数据科学的动力源泉。你将学到更多关于计数以及一系列重要的转换和汇总函数的知识。\n14  字符串 将为你提供处理字符串的工具：你将对它们进行切片、分割，然后再将它们粘合在一起。本章主要关注 stringr 包，但你也会学到一些用于从字符串中提取数据的 tidyr 函数。\n15  正则表达式 向你介绍正则表达式 (regular expressions)，这是一种强大的字符串处理工具。本章将带你从看到它们就觉得像是猫踩过键盘一样，到能够读懂并编写复杂的字符串模式。\n16  因子 介绍因子 (factor)：R 用来存储分类数据的类型。当一个变量具有固定的可能值集合时，或者当你希望使用非字母顺序对字符串进行排序时，你就会使用因子。\n17  日期和时间 将为你提供处理日期和日期时间的关键工具。不幸的是，你对日期时间了解得越多，它们似乎就变得越复杂，但在 lubridate 包的帮助下，你将学会如何克服最常见的挑战。\n18  缺失值 深入讨论缺失值。我们已经单独讨论过几次缺失值，但现在是时候全面地讨论它们了，帮助你掌握隐式和显式缺失值之间的区别，以及如何在它们之间进行转换以及为什么要这样做。\n19  连接 作为本书这一部分的收尾，为你提供了将两个 (或多个) 数据框连接在一起的工具。学习连接操作将迫使你深入理解“键” (key) 的概念，并思考如何识别数据集中的每一行。",
    "crumbs": [
      "数据转换"
    ]
  },
  {
    "objectID": "logicals.html",
    "href": "logicals.html",
    "title": "12  逻辑向量",
    "section": "",
    "text": "12.1 引言\n在本章中，你将学习处理逻辑向量的工具。逻辑向量是最简单的向量类型，因为每个元素只能是三个可能的值之一：TRUE、FALSE 和 NA。在原始数据中很少会遇到逻辑向量，但在几乎每一次分析的过程中，你都会创建和操作它们。\n我们将首先讨论创建逻辑向量最常用的方法：使用数值比较。然后，你将学习如何使用布尔代数来组合不同的逻辑向量，以及一些有用的汇总方法。最后，我们将介绍 if_else() 和 case_when()，这是两个非常有用的函数，可以利用逻辑向量进行条件性更改。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "logicals.html#引言",
    "href": "logicals.html#引言",
    "title": "12  逻辑向量",
    "section": "",
    "text": "12.1.1 先决条件\n本章中你将学到的大部分函数都由 R base 提供，所以我们并不需要 tidyverse，但我们仍然会加载它，以便使用 mutate()、filter() 等函数来处理数据框。我们也将继续使用 nycflights13::flights 数据集中的示例。\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\n然而，随着我们开始涉及更多的工具，并不总能找到一个完美的真实示例。因此，我们将开始使用 c() 来创建一些虚拟数据：\n\nx &lt;- c(1, 2, 3, 5, 7, 11, 13)\nx * 2\n#&gt; [1]  2  4  6 10 14 22 26\n\n这样做虽然更容易解释单个函数，但代价是更难看出它如何应用于你的数据问题。只需记住，我们对一个独立向量进行的任何操作，你都可以通过 mutate() 及相关函数对数据框中的变量进行同样的操作。\n\ndf &lt;- tibble(x)\ndf |&gt; \n  mutate(y = x * 2)\n#&gt; # A tibble: 7 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2\n#&gt; 2     2     4\n#&gt; 3     3     6\n#&gt; 4     5    10\n#&gt; 5     7    14\n#&gt; 6    11    22\n#&gt; # ℹ 1 more row",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "logicals.html#比较",
    "href": "logicals.html#比较",
    "title": "12  逻辑向量",
    "section": "\n12.2 比较",
    "text": "12.2 比较\n创建逻辑向量的一种非常常见的方法是通过数值比较运算符：&lt;、&lt;=、&gt;、&gt;=、!= 和 ==。到目前为止，我们主要是在 filter() 中临时创建逻辑变量——它们被计算、使用，然后被丢弃。例如，下面的筛选器会找出所有在白天出发且大致准点到达的航班：\n\nflights |&gt; \n  filter(dep_time &gt; 600 & dep_time &lt; 2000 & abs(arr_delay) &lt; 20)\n#&gt; # A tibble: 172,286 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      601            600         1      844            850\n#&gt; 2  2013     1     1      602            610        -8      812            820\n#&gt; 3  2013     1     1      602            605        -3      821            805\n#&gt; 4  2013     1     1      606            610        -4      858            910\n#&gt; 5  2013     1     1      606            610        -4      837            845\n#&gt; 6  2013     1     1      607            607         0      858            915\n#&gt; # ℹ 172,280 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n知道这其实是一种简便写法是很有用的，你完全可以使用 mutate() 显式地创建底层的逻辑变量：\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 4\n#&gt;   dep_time arr_delay daytime approx_ontime\n#&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;lgl&gt;   &lt;lgl&gt;        \n#&gt; 1      517        11 FALSE   TRUE         \n#&gt; 2      533        20 FALSE   FALSE        \n#&gt; 3      542        33 FALSE   FALSE        \n#&gt; 4      544       -18 FALSE   TRUE         \n#&gt; 5      554       -25 FALSE   FALSE        \n#&gt; 6      554        12 FALSE   TRUE         \n#&gt; # ℹ 336,770 more rows\n\n这对于更复杂的逻辑尤其有用，因为给中间步骤命名能让你的代码更易于阅读，也更容易检查每一步是否计算正确。\n总而言之，最初的筛选器等同于：\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n  ) |&gt; \n  filter(daytime & approx_ontime)\n\n\n12.2.1 浮点数比较\n注意不要对数值使用 ==。例如，看起来这个向量包含了数字 1 和 2：\n\nx &lt;- c(1 / 49 * 49, sqrt(2) ^ 2)\nx\n#&gt; [1] 1 2\n\n但如果你测试它们是否相等，会得到 FALSE：\n\nx == c(1, 2)\n#&gt; [1] FALSE FALSE\n\n这是怎么回事？计算机使用固定的小数位数来存储数字，所以无法精确表示 1/49 或 sqrt(2)，后续的计算会有非常微小的偏差。我们可以通过调用 print() 并使用 digits1 参数来查看确切的值：\n\nprint(x, digits = 16)\n#&gt; [1] 0.9999999999999999 2.0000000000000004\n\n你可以看到为什么 R 默认会对这些数字进行四舍五入；它们确实非常接近你期望的值。\n既然你已经明白了 == 为什么会失效，那你该怎么办呢？一个选项是使用 dplyr::near()，它会忽略微小的差异：\n\nnear(x, c(1, 2))\n#&gt; [1] TRUE TRUE\n\n\n12.2.2 缺失值\n缺失值代表未知，所以它们是“会传染的”：几乎任何涉及未知值的操作，其结果也将是未知的：\n\nNA &gt; 5\n#&gt; [1] NA\n10 == NA\n#&gt; [1] NA\n\n最令人困惑的结果是这一个：\n\nNA == NA\n#&gt; [1] NA\n\n如果我们人为地提供一些上下文，就最容易理解为什么会这样：\n\n# 我们不知道 Mary 的年龄\nage_mary &lt;- NA\n\n# 我们不知道 John 的年龄\nage_john &lt;- NA\n\n# Mary 和 John 同龄吗？\nage_mary == age_john\n#&gt; [1] NA\n# 我们不知道！\n\n所以，如果你想找出 dep_time 缺失的所有航班，下面的代码是行不通的，因为 dep_time == NA 对每一行都会产生 NA，而 filter() 会自动丢弃缺失值：\n\nflights |&gt; \n  filter(dep_time == NA)\n#&gt; # A tibble: 0 × 19\n#&gt; # ℹ 19 variables: year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;, dep_time &lt;int&gt;,\n#&gt; #   sched_dep_time &lt;int&gt;, dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, …\n\n为此，我们需要一个新工具：is.na()。\n\n12.2.3 is.na()\n\nis.na(x) 适用于任何类型的向量，它对缺失值返回 TRUE，对其他所有值返回 FALSE：\n\nis.na(c(TRUE, NA, FALSE))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(1, NA, 3))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(\"a\", NA, \"b\"))\n#&gt; [1] FALSE  TRUE FALSE\n\n我们可以使用 is.na() 来找到 dep_time 缺失的所有行：\n\nflights |&gt; \n  filter(is.na(dep_time))\n#&gt; # A tibble: 8,255 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     2       NA           1540        NA       NA           1747\n#&gt; 6  2013     1     2       NA           1620        NA       NA           1746\n#&gt; # ℹ 8,249 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nis.na() 在 arrange() 中也很有用。arrange() 通常将所有缺失值放在末尾，但你可以通过先按 is.na() 排序来覆盖这个默认行为：\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(dep_time)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(desc(is.na(dep_time)), dep_time)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     1      517            515         2      830            819\n#&gt; 6  2013     1     1      533            529         4      850            830\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n我们将在 Chapter 18 中更深入地探讨缺失值。\n\n12.2.4 练习\n\n\ndplyr::near() 是如何工作的？输入 near 查看源代码。sqrt(2)^2 是否接近 2？\n结合使用 mutate()、is.na() 和 count() 来描述 dep_time、sched_dep_time 和 dep_delay 中的缺失值是如何相互关联的。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "logicals.html#布尔代数",
    "href": "logicals.html#布尔代数",
    "title": "12  逻辑向量",
    "section": "\n12.3 布尔代数",
    "text": "12.3 布尔代数\n一旦你有了多个逻辑向量，你就可以使用布尔代数将它们组合起来。在 R 中，& 是“与”，| 是“或”，! 是“非”，而 xor() 是“异或”2。例如，df |&gt; filter(!is.na(x)) 会找出 x 不缺失的所有行，而 df |&gt; filter(x &lt; -10 | x &gt; 0) 会找出 x 小于 -10 或大于 0 的所有行。Figure 12.1 展示了完整的布尔运算集合及其工作方式。\n\n\n\n\n\n\n\nFigure 12.1: 完整的布尔运算集合。x 是左边的圆，y 是右边的圆， 阴影区域显示了每个运算符选择的部分。\n\n\n\n\n除了 & 和 |，R 还有 && 和 ||。不要在 dplyr 函数中使用它们！这些被称为短路运算符，它们只返回单个 TRUE 或 FALSE。它们对于编程很重要，但对于数据科学则不然。\n\n12.3.1 缺失值\n布尔代数中关于缺失值的规则解释起来有点棘手，因为它们初看起来似乎不一致：\n\ndf &lt;- tibble(x = c(TRUE, FALSE, NA))\n\ndf |&gt; \n  mutate(\n    and = x & NA,\n    or = x | NA\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   x     and   or   \n#&gt;   &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 TRUE  NA    TRUE \n#&gt; 2 FALSE FALSE NA   \n#&gt; 3 NA    NA    NA\n\n要理解发生了什么，可以思考一下 NA | TRUE（NA 或 TRUE）。逻辑向量中的一个缺失值意味着这个值可能是 TRUE 或 FALSE。TRUE | TRUE 和 FALSE | TRUE 都为 TRUE，因为至少有一个是 TRUE。因此 NA | TRUE 也必须是 TRUE，因为 NA 可能是 TRUE 或 FALSE。然而，NA | FALSE 的结果是 NA，因为我们不知道 NA 是 TRUE 还是 FALSE。类似的推理也适用于 &，考虑到 & 要求两个条件都必须满足。因此，NA & TRUE 的结果是 NA，因为 NA 可能是 TRUE 或 FALSE；而 NA & FALSE 的结果是 FALSE，因为至少有一个条件是 FALSE。\n\n12.3.2 运算顺序\n请注意，运算顺序不像英语那样。看下面这段代码，它用于查找所有在十一月或十二月出发的航班：\n\nflights |&gt; \n   filter(month == 11 | month == 12)\n\n你可能会想当然地像说英语一样写它：“查找所有在十一月或十二月出发的航班。”：\n\nflights |&gt; \n   filter(month == 11 | 12)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n这段代码不会报错，但似乎也没有起作用。这是怎么回事？在这里，R 首先评估 month == 11，创建了一个我们称之为 nov 的逻辑向量。然后它计算 nov | 12。当你对一个逻辑运算符使用数字时，它会把除了 0 之外的所有数都转换为 TRUE，所以这等价于 nov | TRUE，结果将永远是 TRUE，因此每一行都会被选中：\n\nflights |&gt; \n  mutate(\n    nov = month == 11,\n    final = nov | 12,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;   month nov   final\n#&gt;   &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1     1 FALSE TRUE \n#&gt; 2     1 FALSE TRUE \n#&gt; 3     1 FALSE TRUE \n#&gt; 4     1 FALSE TRUE \n#&gt; 5     1 FALSE TRUE \n#&gt; 6     1 FALSE TRUE \n#&gt; # ℹ 336,770 more rows\n\n\n12.3.3 %in%\n\n避免 == 和 | 顺序出错的一个简单方法是使用 %in%。x %in% y 返回一个与 x 长度相同的逻辑向量，当 x 中的值出现在 y 中的任何位置时，该向量对应位置的值为 TRUE。\n\n1:12 %in% c(1, 5, 11)\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\nletters[1:10] %in% c(\"a\", \"e\", \"i\", \"o\", \"u\")\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n\n因此，要查找所有十一月和十二月的航班，我们可以这样写：\n\nflights |&gt; \n  filter(month %in% c(11, 12))\n\n注意，%in% 对于 NA 的处理规则与 == 不同，因为 NA %in% NA 的结果是 TRUE。\n\nc(1, 2, NA) == NA\n#&gt; [1] NA NA NA\nc(1, 2, NA) %in% NA\n#&gt; [1] FALSE FALSE  TRUE\n\n这可以成为一个有用的简便写法：\n\nflights |&gt; \n  filter(dep_time %in% c(NA, 0800))\n#&gt; # A tibble: 8,803 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      800            800         0     1022           1014\n#&gt; 2  2013     1     1      800            810       -10      949            955\n#&gt; 3  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 4  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 5  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 6  2013     1     1       NA            600        NA       NA            901\n#&gt; # ℹ 8,797 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n\n12.3.4 练习\n\n找出所有 arr_delay 缺失但 dep_delay 不缺失的航班。找出所有 arr_time 和 sched_arr_time 都不缺失，但 arr_delay 缺失的航班。\n有多少航班的 dep_time 是缺失的？这些行中还有哪些其他变量是缺失的？这些行可能代表什么？\n假设缺失的 dep_time 意味着航班被取消了，查看每天被取消航班的数量。是否存在某种模式？被取消航班的比例与未取消航班的平均延误之间是否存在联系？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "logicals.html#sec-logical-summaries",
    "href": "logicals.html#sec-logical-summaries",
    "title": "12  逻辑向量",
    "section": "\n12.4 汇总",
    "text": "12.4 汇总\n以下各节描述了一些用于汇总逻辑向量的有用技术。除了专门用于逻辑向量的函数外，你也可以使用那些适用于数值向量的函数。\n\n12.4.1 逻辑汇总\n有两个主要的逻辑汇总函数：any() 和 all()。any(x) 相当于 |；如果 x 中有任何 TRUE，它将返回 TRUE。all(x) 相当于 &；只有当 x 的所有值都是 TRUE 时，它才会返回 TRUE。与大多数汇总函数一样，你可以通过 na.rm = TRUE 来忽略缺失值。\n例如，我们可以使用 all() 和 any() 来查看是否每天的所有航班出发延误都不超过一小时，或者是否有任何航班到达延误达到五小时或更长。并且，使用 group_by() 允许我们按天来进行这种分析：\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    all_delayed = all(dep_delay &lt;= 60, na.rm = TRUE),\n    any_long_delay = any(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day all_delayed any_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;       &lt;lgl&gt;         \n#&gt; 1  2013     1     1 FALSE       TRUE          \n#&gt; 2  2013     1     2 FALSE       TRUE          \n#&gt; 3  2013     1     3 FALSE       FALSE         \n#&gt; 4  2013     1     4 FALSE       FALSE         \n#&gt; 5  2013     1     5 FALSE       TRUE          \n#&gt; 6  2013     1     6 FALSE       FALSE         \n#&gt; # ℹ 359 more rows\n\n然而，在大多数情况下，any() 和 all() 有点过于粗略，如果能获得更多关于有多少值是 TRUE 或 FALSE 的细节会更好。这就引出了数值汇总。\n\n12.4.2 逻辑向量的数值汇总\n当你在数值上下文中使用逻辑向量时，TRUE 会变成 1，FALSE 会变成 0。这使得 sum() 和 mean() 在处理逻辑向量时非常有用，因为 sum(x) 给出 TRUE 的数量，而 mean(x) 给出 TRUE 的比例（因为 mean() 就是 sum() 除以 length()）。\n例如，这可以让我们看到出发延误不超过一小时的航班比例，以及到达延误五小时或更长时间的航班数量：\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    proportion_delayed = mean(dep_delay &lt;= 60, na.rm = TRUE),\n    count_long_delay = sum(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day proportion_delayed count_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;dbl&gt;            &lt;int&gt;\n#&gt; 1  2013     1     1              0.939                3\n#&gt; 2  2013     1     2              0.914                3\n#&gt; 3  2013     1     3              0.941                0\n#&gt; 4  2013     1     4              0.953                0\n#&gt; 5  2013     1     5              0.964                1\n#&gt; 6  2013     1     6              0.959                0\n#&gt; # ℹ 359 more rows\n\n\n12.4.3 逻辑子集\n在汇总中，逻辑向量还有最后一个用途：你可以使用一个逻辑向量来将单个变量筛选到感兴趣的子集。这利用了 R base 的 [（读作 subset）运算符，你将在 Section 27.2 中学到更多相关内容。\n假设我们想查看仅仅是那些实际延误了的航班的平均延误。一种方法是先筛选出航班，然后计算平均延误：\n\nflights |&gt; \n  filter(arr_delay &gt; 0) |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day behind     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5   461\n#&gt; 2  2013     1     2   32.0   535\n#&gt; 3  2013     1     3   27.7   460\n#&gt; 4  2013     1     4   28.3   297\n#&gt; 5  2013     1     5   22.6   238\n#&gt; 6  2013     1     6   24.4   381\n#&gt; # ℹ 359 more rows\n\n这行得通，但如果我们还想计算那些提早到达航班的平均延误呢？我们就需要执行一个单独的筛选步骤，然后想办法将这两个数据框合并在一起3。相反，你可以使用 [ 来执行内联筛选：arr_delay[arr_delay &gt; 0] 将只产生正的到达延误值。\n这样就会得到：\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay[arr_delay &gt; 0], na.rm = TRUE),\n    ahead = mean(arr_delay[arr_delay &lt; 0], na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 6\n#&gt;    year month   day behind ahead     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5 -12.5   842\n#&gt; 2  2013     1     2   32.0 -14.3   943\n#&gt; 3  2013     1     3   27.7 -18.2   914\n#&gt; 4  2013     1     4   28.3 -17.0   915\n#&gt; 5  2013     1     5   22.6 -14.0   720\n#&gt; 6  2013     1     6   24.4 -13.6   832\n#&gt; # ℹ 359 more rows\n\n同时请注意组大小的差异：在第一个代码块中，n() 给出的是每天延误的航班数量；在第二个代码块中，n() 给出的是总航班数。\n\n12.4.4 练习\n\n\nsum(is.na(x)) 会告诉你什么？mean(is.na(x)) 呢？\n当 prod() 应用于逻辑向量时返回什么？它等同于哪个逻辑汇总函数？当 min() 应用于逻辑向量时返回什么？它等同于哪个逻辑汇总函数？阅读文档并进行一些实验。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "logicals.html#条件转换",
    "href": "logicals.html#条件转换",
    "title": "12  逻辑向量",
    "section": "\n12.5 条件转换",
    "text": "12.5 条件转换\n逻辑向量最强大的特性之一是它们在条件转换中的应用，即对条件 x 做一件事，对条件 y 做另一件事。有两个重要的工具可以实现这一点：if_else() 和 case_when()。\n\n12.5.1 if_else()\n\n如果你想在条件为 TRUE 时使用一个值，而在条件为 FALSE 时使用另一个值，你可以使用 dplyr::if_else()4。你总是会使用 if_else() 的前三个参数。第一个参数 condition 是一个逻辑向量；第二个参数 true 给出条件为真时的输出；第三个参数 false 给出条件为假时的输出。\n我们从一个简单的例子开始，将一个数值向量标记为 “+ve” (正数) 或 “-ve” (负数)：\n\nx &lt;- c(-3:3, NA)\nif_else(x &gt; 0, \"+ve\", \"-ve\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" NA\n\n还有一个可选的第四个参数 missing，如果输入是 NA，就会使用这个值：\n\nif_else(x &gt; 0, \"+ve\", \"-ve\", \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\n你也可以为 true 和 false 参数使用向量。例如，这允许我们创建一个 abs() 的最小化实现：\n\nif_else(x &lt; 0, -x, x)\n#&gt; [1]  3  2  1  0  1  2  3 NA\n\n到目前为止，所有的参数都使用了相同的向量，但你当然可以混合搭配。例如，你可以像这样实现一个 coalesce() 的简单版本：\n\nx1 &lt;- c(NA, 1, 2, NA)\ny1 &lt;- c(3, NA, 4, 6)\nif_else(is.na(x1), y1, x1)\n#&gt; [1] 3 1 2 6\n\n你可能已经注意到我们上面标签示例中的一个小瑕疵：零既不是正数也不是负数。我们可以通过添加一个额外的 if_else() 来解决这个问题：\n\nif_else(x == 0, \"0\", if_else(x &lt; 0, \"-ve\", \"+ve\"), \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\n这已经有点难读了，你可以想象如果你有更多的条件，情况只会变得更糟。此时，你可以转而使用 dplyr::case_when()。\n\n12.5.2 case_when()\n\ndplyr 的 case_when() 受到 SQL 的 CASE 语句的启发，提供了一种为不同条件执行不同计算的灵活方式。它有一种特殊的语法，不幸的是，它看起来与你在 tidyverse 中使用的其他任何东西都不一样。它接受形如 condition ~ output 的配对。condition 必须是一个逻辑向量；当它为 TRUE 时，将使用 output。\n这意味着我们可以像下面这样重新创建我们之前的嵌套 if_else()：\n\nx &lt;- c(-3:3, NA)\ncase_when(\n  x == 0   ~ \"0\",\n  x &lt; 0    ~ \"-ve\", \n  x &gt; 0    ~ \"+ve\",\n  is.na(x) ~ \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\n这代码量更多，但也更明确。\n为了解释 case_when() 的工作原理，让我们来探讨一些更简单的情况。如果没有一个条件匹配，输出会得到一个 NA：\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" NA    \"+ve\" \"+ve\" \"+ve\" NA\n\n如果你想创建一个“默认”或“全收”的值，可以使用 .default：\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\",\n  .default = \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"???\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\n并且请注意，如果多个条件匹配，只有第一个会被使用：\n\ncase_when(\n  x &gt; 0 ~ \"+ve\",\n  x &gt; 2 ~ \"big\"\n)\n#&gt; [1] NA    NA    NA    NA    \"+ve\" \"+ve\" \"+ve\" NA\n\n就像 if_else() 一样，你可以在 ~ 的两边都使用变量，并且可以根据你的问题需要混合搭配变量。例如，我们可以使用 case_when() 为到达延误提供一些人类可读的标签：\n\nflights |&gt; \n  mutate(\n    status = case_when(\n      is.na(arr_delay)    ~ \"cancelled\",\n      arr_delay &lt; -30     ~ \"very early\",\n      arr_delay &lt; -15     ~ \"early\",\n      abs(arr_delay) &lt;= 15 ~ \"on time\",\n      arr_delay &lt; 60      ~ \"late\",\n      arr_delay &lt; Inf     ~ \"very late\",\n    ),\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 2\n#&gt;   arr_delay status \n#&gt;       &lt;dbl&gt; &lt;chr&gt;  \n#&gt; 1        11 on time\n#&gt; 2        20 late   \n#&gt; 3        33 late   \n#&gt; 4       -18 early  \n#&gt; 5       -25 early  \n#&gt; 6        12 on time\n#&gt; # ℹ 336,770 more rows\n\n在编写这类复杂的 case_when() 语句时要小心；我前两次的尝试混合使用了 &lt; 和 &gt;，结果不小心创建了重叠的条件。\n\n12.5.3 兼容的类型\n请注意，if_else() 和 case_when() 都要求输出中的类型是兼容的。如果它们不兼容，你会看到类似这样的错误：\n\nif_else(TRUE, \"a\", 1)\n#&gt; Error in `if_else()`:\n#&gt; ! Can't combine `true` &lt;character&gt; and `false` &lt;double&gt;.\n\ncase_when(\n  x &lt; -1 ~ TRUE,  \n  x &gt; 0  ~ now()\n)\n#&gt; Error in `case_when()`:\n#&gt; ! Can't combine `..1 (right)` &lt;logical&gt; and `..2 (right)` &lt;datetime&lt;local&gt;&gt;.\n\n总的来说，相对较少的类型是兼容的，因为自动将一种类型的向量转换为另一种是常见的错误来源。以下是兼容的最重要的几种情况：\n\n数值和逻辑向量是兼容的，正如我们在 Section 12.4.2 中讨论的那样。\n字符串和因子 (Chapter 16) 是兼容的，因为你可以把因子看作是具有一组受限值的字符串。\n日期和日期时间，我们将在 Chapter 17 中讨论，是兼容的，因为你可以把日期看作是日期时间的一种特殊情况。\n\nNA，技术上是一个逻辑向量，与所有类型都兼容，因为每个向量都有某种方式来表示缺失值。\n\n我们不期望你记住这些规则，但它们应该会随着时间的推移成为你的第二天性，因为它们在整个 tidyverse 中都是一致应用的。\n\n12.5.4 练习\n\n一个数如果是偶数，那么它能被 2 整除，在 R 中你可以用 x %% 2 == 0 来判断。利用这个事实和 if_else() 来判断 0 到 20 之间的每个数是奇数还是偶数。\n给定一个像 x &lt;- c(\"Monday\", \"Saturday\", \"Wednesday\") 这样的日期向量，使用一个 if_else() 语句将它们标记为周末或工作日。\n使用 if_else() 来计算一个名为 x 的数值向量的绝对值。\n编写一个 case_when() 语句，使用 flights 数据集中的 month 和 day 列来标记一些重要的美国节日（例如，元旦、7月4日独立日、感恩节和圣诞节）。首先创建一个值为 TRUE 或 FALSE 的逻辑列，然后创建一个字符列，该列要么给出节日的名称，要么是 NA。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "logicals.html#总结",
    "href": "logicals.html#总结",
    "title": "12  逻辑向量",
    "section": "\n12.6 总结",
    "text": "12.6 总结\n逻辑向量的定义很简单，因为每个值必须是 TRUE、FALSE 或 NA 之一。但逻辑向量提供了巨大的能力。在本章中，你学习了如何使用 &gt;、&lt;、&lt;=、&gt;=、==、!= 和 is.na() 创建逻辑向量，如何使用 !、& 和 | 组合它们，以及如何使用 any()、all()、sum() 和 mean() 汇总它们。你还学习了强大的 if_else() 和 case_when() 函数，它们允许你根据逻辑向量的值返回不同的结果。\n在接下来的章节中，我们将一次又一次地看到逻辑向量。例如，在 Chapter 14 中，你将学习 str_detect(x, pattern)，它返回一个逻辑向量，对于 x 中匹配 pattern 的元素为 TRUE；在 Chapter 17 中，你将通过比较日期和时间来创建逻辑向量。但现在，我们将转向下一个最重要的向量类型：数值向量。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "logicals.html#footnotes",
    "href": "logicals.html#footnotes",
    "title": "12  逻辑向量",
    "section": "",
    "text": "R 通常会为你调用 print（即 x 是 print(x) 的简写），但如果你想提供其他参数，显式调用它会很有用。↩︎\n也就是说，如果 x 为真，或者 y 为真，但不是两者都为真，那么 xor(x, y) 就为真。这与我们在英语中通常使用“or”的方式类似。“两者都”通常不是“你想要冰淇淋还是蛋糕？”这个问题的可接受答案。↩︎\n我们将在 Chapter 19 中讨论这个问题。↩︎\ndplyr 的 if_else() 与 R base 的 ifelse() 非常相似。if_else() 相对于 ifelse() 有两个主要优点：你可以选择如何处理缺失值，并且如果你的变量类型不兼容，if_else() 更有可能给出有意义的错误信息。↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>逻辑向量</span>"
    ]
  },
  {
    "objectID": "numbers.html",
    "href": "numbers.html",
    "title": "13  数值",
    "section": "",
    "text": "13.1 引言\n数值向量是数据科学的支柱，在本书的前面部分你已经多次使用过它们。现在是时候系统地审视一下在 R 中你能用它们做什么，以确保你能够很好地应对未来任何涉及数值向量的问题。\n我们将首先为你提供一些工具，以便在你有字符串的情况下创建数值，然后更详细地介绍 count()。接着，我们将深入探讨与 mutate() 搭配使用的各种数值转换，包括那些可以应用于其他类型向量但常用于数值向量的更通用的转换。最后，我们将介绍与 summarize() 搭配使用的汇总函数，并向你展示它们如何也能与 mutate() 一起使用。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#引言",
    "href": "numbers.html#引言",
    "title": "13  数值",
    "section": "",
    "text": "13.1.1 先决条件\n本章主要使用 R base 中的函数，这些函数无需加载任何包即可使用。但我们仍然需要 tidyverse，因为我们将在 mutate() 和 filter() 等 tidyverse 函数内部使用这些 R base 函数。与上一章一样，我们将使用 nycflights13 中的真实示例，以及用 c() 和 tribble() 创建的玩具示例。\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#创建数值",
    "href": "numbers.html#创建数值",
    "title": "13  数值",
    "section": "\n13.2 创建数值",
    "text": "13.2 创建数值\n在大多数情况下，你得到的数值已经是 R 的数值类型之一：整数（integer）或双精度浮点数（double）。然而，在某些情况下，你会遇到以字符串形式存在的数值，这可能是因为你通过列标题进行透视操作创建了它们，或者是在数据导入过程中出了问题。\nreadr 提供了两个有用的函数来将字符串解析为数值：parse_double() 和 parse_number()。当你有名为字符串的数字时，使用 parse_double()：\n\nx &lt;- c(\"1.2\", \"5.6\", \"1e3\")\nparse_double(x)\n#&gt; [1]    1.2    5.6 1000.0\n\n当字符串中包含你想要忽略的非数值文本时，使用 parse_number()。这对于处理货币数据和百分比特别有用：\n\nx &lt;- c(\"$1,234\", \"USD 3,513\", \"59%\")\nparse_number(x)\n#&gt; [1] 1234 3513   59",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#sec-counts",
    "href": "numbers.html#sec-counts",
    "title": "13  数值",
    "section": "\n13.3 计数",
    "text": "13.3 计数\n仅凭计数和一些基本算术就能完成如此多的数据科学工作，这着实令人惊讶，因此 dplyr 致力于通过 count() 使计数尽可能简单。这个函数非常适合在分析过程中进行快速探索和检查：\n\nflights |&gt; count(dest)\n#&gt; # A tibble: 105 × 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ABQ     254\n#&gt; 2 ACK     265\n#&gt; 3 ALB     439\n#&gt; 4 ANC       8\n#&gt; 5 ATL   17215\n#&gt; 6 AUS    2439\n#&gt; # ℹ 99 more rows\n\n（尽管在 Chapter 4 中有相关建议，我们通常将 count() 写在单行上，因为它通常在控制台中使用，用于快速检查计算是否按预期工作。）\n如果你想查看最常见的值，可以添加 sort = TRUE：\n\nflights |&gt; count(dest, sort = TRUE)\n#&gt; # A tibble: 105 × 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ORD   17283\n#&gt; 2 ATL   17215\n#&gt; 3 LAX   16174\n#&gt; 4 BOS   15508\n#&gt; 5 MCO   14082\n#&gt; 6 CLT   14064\n#&gt; # ℹ 99 more rows\n\n请记住，如果你想查看所有值，可以使用 |&gt; View() 或 |&gt; print(n = Inf)。\n你可以使用 group_by()、summarize() 和 n() 来“手动”执行相同的计算。这很有用，因为它允许你同时计算其他汇总统计量：\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 105 × 3\n#&gt;   dest      n delay\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n#&gt; 1 ABQ     254  4.38\n#&gt; 2 ACK     265  4.85\n#&gt; 3 ALB     439 14.4 \n#&gt; 4 ANC       8 -2.5 \n#&gt; 5 ATL   17215 11.3 \n#&gt; 6 AUS    2439  6.02\n#&gt; # ℹ 99 more rows\n\nn() 是一个特殊的汇总函数，它不接受任何参数，而是访问关于“当前”组的信息。这意味着它只能在 dplyr 的动词（verb）内部工作：\n\nn()\n#&gt; Error in `n()`:\n#&gt; ! Must only be used inside data-masking verbs like `mutate()`,\n#&gt;   `filter()`, and `group_by()`.\n\nn() 和 count() 有几个你可能会觉得有用的变体：\n\n\nn_distinct(x) 计算一个或多个变量的不同（唯一）值的数量。例如，我们可以找出哪些目的地由最多的航空公司提供服务：\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(carriers = n_distinct(carrier)) |&gt; \n  arrange(desc(carriers))\n#&gt; # A tibble: 105 × 2\n#&gt;   dest  carriers\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 ATL          7\n#&gt; 2 BOS          7\n#&gt; 3 CLT          7\n#&gt; 4 ORD          7\n#&gt; 5 TPA          7\n#&gt; 6 AUS          6\n#&gt; # ℹ 99 more rows\n\n\n\n加权计数就是求和。例如，你可以“计算”每架飞机飞行的总英里数：\n\nflights |&gt; \n  group_by(tailnum) |&gt; \n  summarize(miles = sum(distance))\n#&gt; # A tibble: 4,044 × 2\n#&gt;   tailnum  miles\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 D942DN    3418\n#&gt; 2 N0EGMQ  250866\n#&gt; 3 N10156  115966\n#&gt; 4 N102UW   25722\n#&gt; 5 N103US   24619\n#&gt; 6 N104UW   25157\n#&gt; # ℹ 4,038 more rows\n\n加权计数是一个常见的问题，所以 count() 有一个 wt 参数可以做同样的事情：\n\nflights |&gt; count(tailnum, wt = distance)\n\n\n\n你可以通过组合 sum() 和 is.na() 来计算缺失值的数量。在 flights 数据集中，这代表了被取消的航班：\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(n_cancelled = sum(is.na(dep_time))) \n#&gt; # A tibble: 105 × 2\n#&gt;   dest  n_cancelled\n#&gt;   &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 ABQ             0\n#&gt; 2 ACK             0\n#&gt; 3 ALB            20\n#&gt; 4 ANC             0\n#&gt; 5 ATL           317\n#&gt; 6 AUS            21\n#&gt; # ℹ 99 more rows\n\n\n\n\n13.3.1 练习\n\n你如何使用 count() 来计算给定变量中含有缺失值的行数？\n将以下 count() 调用展开，改用 group_by()、summarize() 和 arrange() 来实现：\n\nflights |&gt; count(dest, sort = TRUE)\nflights |&gt; count(tailnum, wt = distance)",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#数值转换",
    "href": "numbers.html#数值转换",
    "title": "13  数值",
    "section": "\n13.4 数值转换",
    "text": "13.4 数值转换\n转换函数与 mutate() 配合得很好，因为它们的输出与输入长度相同。绝大多数转换函数已经内置于 R base 中。列出所有这些函数是不切实际的，所以本节将展示最有用的那些。例如，虽然 R 提供了你可能梦想到的所有三角函数，但我们在这里不列出它们，因为它们在数据科学中很少需要。\n\n13.4.1 算术和循环补齐规则\n我们在 Chapter 2 中介绍了算术（+, -, *, /, ^）的基础知识，并且从那以后已经多次使用它们。这些函数不需要太多的解释，因为它们做的就是你在小学学到的东西。但是我们需要简要地谈谈循环补齐规则（recycling rules），它决定了当左右两边的长度不同时会发生什么。这对于像 flights |&gt; mutate(air_time = air_time / 60) 这样的操作很重要，因为 / 的左边有 336,776 个数字，而右边只有一个。\nR 通过循环补齐（recycling）或重复较短的向量来处理长度不匹配的问题。如果我们在数据框之外创建一些向量，我们可以更容易地看到这个操作：\n\nx &lt;- c(1, 2, 10, 20)\nx / 5\n#&gt; [1] 0.2 0.4 2.0 4.0\n# 是下面写法的简写\nx / c(5, 5, 5, 5)\n#&gt; [1] 0.2 0.4 2.0 4.0\n\n通常，你只想循环补齐单个数字（即长度为 1 的向量），但 R 会循环补齐任何较短长度的向量。如果较长的向量不是较短向量的倍数，它通常（但并非总是）会给你一个警告：\n\nx * c(1, 2)\n#&gt; [1]  1  4 10 40\nx * c(1, 2, 3)\n#&gt; Warning in x * c(1, 2, 3): longer object length is not a multiple of shorter\n#&gt; object length\n#&gt; [1]  1  4 30 20\n\n这些循环补齐规则也适用于逻辑比较（==, &lt;, &lt;=, &gt;, &gt;=, !=），如果你不小心用了 == 而不是 %in%，并且数据框的行数碰巧很凑巧，可能会导致令人惊讶的结果。例如，看这段试图找出所有一月和二月航班的代码：\n\nflights |&gt; \n  filter(month == c(1, 2))\n#&gt; # A tibble: 25,977 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      542            540         2      923            850\n#&gt; 3  2013     1     1      554            600        -6      812            837\n#&gt; 4  2013     1     1      555            600        -5      913            854\n#&gt; 5  2013     1     1      557            600        -3      838            846\n#&gt; 6  2013     1     1      558            600        -2      849            851\n#&gt; # ℹ 25,971 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n这段代码运行没有错误，但它没有返回你想要的结果。由于循环补齐规则，它找到了奇数行中一月份出发的航班和偶数行中二月份出发的航班。而且不幸的是，因为 flights 的行数是偶数，所以没有警告。\n为了保护你免受这种静默失败的影响，大多数 tidyverse 函数使用一种更严格的循环补齐形式，只循环补齐单个值。不幸的是，这在这里或许多其他情况下没有帮助，因为关键的计算是由 R base 函数 == 执行的，而不是 filter()。\n\n13.4.2 最小值和最大值\n算术函数处理成对的变量。两个密切相关的函数是 pmin() 和 pmax()，当给定两个或更多变量时，它们将返回每行中的最小值或最大值：\n\ndf &lt;- tribble(\n  ~x, ~y,\n  1,  3,\n  5,  2,\n  7, NA,\n)\n\ndf |&gt; \n  mutate(\n    min = pmin(x, y, na.rm = TRUE),\n    max = pmax(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     3\n#&gt; 2     5     2     2     5\n#&gt; 3     7    NA     7     7\n\n请注意，这些不同于汇总函数 min() 和 max()，后者接受多个观测值并返回单个值。当你发现所有的最小值和所有的最大值都相同时，你就知道你用错了形式：\n\ndf |&gt; \n  mutate(\n    min = min(x, y, na.rm = TRUE),\n    max = max(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     7\n#&gt; 2     5     2     1     7\n#&gt; 3     7    NA     1     7\n\n\n13.4.3 模运算\n模运算（Modular arithmetic）是你学会小数之前所做的那种数学的专业名称，即产生一个整数和一个余数的除法。在 R 中，%/% 进行整除，%% 计算余数：\n\n1:10 %/% 3\n#&gt;  [1] 0 0 1 1 1 2 2 2 3 3\n1:10 %% 3\n#&gt;  [1] 1 2 0 1 2 0 1 2 0 1\n\n模运算对 flights 数据集很方便，因为我们可以用它来将 sched_dep_time 变量分解为 hour 和 minute：\n\nflights |&gt; \n  mutate(\n    hour = sched_dep_time %/% 100,\n    minute = sched_dep_time %% 100,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;   sched_dep_time  hour minute\n#&gt;            &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1            515     5     15\n#&gt; 2            529     5     29\n#&gt; 3            540     5     40\n#&gt; 4            545     5     45\n#&gt; 5            600     6      0\n#&gt; 6            558     5     58\n#&gt; # ℹ 336,770 more rows\n\n我们可以将其与 Section 12.4 中的 mean(is.na(x)) 技巧结合起来，看看取消航班的比例在一天中是如何变化的。结果显示在 Figure 13.1 中。\n\nflights |&gt; \n  group_by(hour = sched_dep_time %/% 100) |&gt; \n  summarize(prop_cancelled = mean(is.na(dep_time)), n = n()) |&gt; \n  filter(hour &gt; 1) |&gt; \n  ggplot(aes(x = hour, y = prop_cancelled)) +\n  geom_line(color = \"grey50\") + \n  geom_point(aes(size = n))\n\n\n\n\n\n\nFigure 13.1: 一张线图，x 轴为计划出发小时，y 轴为取消航班的比例。 取消似乎在一天中不断累积，直到晚上 8 点，很晚的航班 被取消的可能性要小得多。\n\n\n\n\n\n13.4.4 对数\n对数是一种非常有用的转换，用于处理跨越多个数量级的数据，并将指数增长转换为线性增长。在 R 中，你可以选择三种对数：log()（自然对数，以 e 为底）、log2()（以 2 为底）和 log10()（以 10 为底）。我们建议使用 log2() 或 log10()。log2() 很容易解释，因为对数尺度上 1 的差异对应于原始尺度上的加倍，而 -1 的差异对应于减半；而 log10() 很容易反向转换，因为（例如）3 是 10^3 = 1000。log() 的逆运算是 exp()；要计算 log2() 或 log10() 的逆运算，你需要使用 2^ 或 10^。\n\n13.4.5 四舍五入\n使用 round(x) 将一个数四舍五入到最近的整数：\n\nround(123.456)\n#&gt; [1] 123\n\n你可以用第二个参数 digits 来控制四舍五入的精度。round(x, digits) 四舍五入到最近的 10^-n，所以 digits = 2 会四舍五入到最近的 0.01。这个定义很有用，因为它意味着 round(x, -3) 会四舍五入到最近的千位，事实也确实如此：\n\nround(123.456, 2)  # 两位小数\n#&gt; [1] 123.46\nround(123.456, 1)  # 一位小数\n#&gt; [1] 123.5\nround(123.456, -1) # 四舍五入到最近的十位\n#&gt; [1] 120\nround(123.456, -2) # 四舍五入到最近的百位\n#&gt; [1] 100\n\nround() 有一个初看起来很奇怪的特性：\n\nround(c(1.5, 2.5))\n#&gt; [1] 2 2\n\nround() 使用的是所谓的“四舍五入到偶数”或“银行家舍入法”（Banker’s rounding）：如果一个数恰好在两个整数的中间，它将被舍入到偶数。这是一个很好的策略，因为它能保持舍入的无偏性：所有 0.5 的一半向上舍入，一半向下舍入。\nround() 与 floor()（总是向下取整）和 ceiling()（总是向上取整）配对使用：\n\nx &lt;- 123.456\n\nfloor(x)\n#&gt; [1] 123\nceiling(x)\n#&gt; [1] 124\n\n这些函数没有 digits 参数，所以你可以先缩小，再取整，然后再放大回去：\n\n# 向下取整到最近的两位小数\nfloor(x / 0.01) * 0.01\n#&gt; [1] 123.45\n# 向上取整到最近的两位小数\nceiling(x / 0.01) * 0.01\n#&gt; [1] 123.46\n\n如果你想将数字 round() 到某个其他数的倍数，也可以使用同样的技术：\n\n# 四舍五入到最近的 4 的倍数\nround(x / 4) * 4\n#&gt; [1] 124\n\n# 四舍五入到最近的 0.25\nround(x / 0.25) * 0.25\n#&gt; [1] 123.5\n\n\n13.4.6 将数值切割成范围\n使用 cut()1 将一个数值向量分割（即分箱）成离散的桶：\n\nx &lt;- c(1, 2, 5, 10, 15, 20)\ncut(x, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] (0,5]   (0,5]   (0,5]   (5,10]  (10,15] (15,20]\n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\n分割点不必是等距的：\n\ncut(x, breaks = c(0, 5, 10, 100))\n#&gt; [1] (0,5]    (0,5]    (0,5]    (5,10]   (10,100] (10,100]\n#&gt; Levels: (0,5] (5,10] (10,100]\n\n你可以选择性地提供自己的 labels。注意 labels 的数量应该比 breaks 少一个。\n\ncut(x, \n  breaks = c(0, 5, 10, 15, 20), \n  labels = c(\"sm\", \"md\", \"lg\", \"xl\")\n)\n#&gt; [1] sm sm sm md lg xl\n#&gt; Levels: sm md lg xl\n\n任何超出分割点范围的值都会变成 NA：\n\ny &lt;- c(NA, -10, 5, 10, 30)\ncut(y, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] &lt;NA&gt;   &lt;NA&gt;   (0,5]  (5,10] &lt;NA&gt;  \n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\n请参阅文档以了解其他有用的参数，如 right 和 include.lowest，它们控制区间是 [a, b) 还是 (a, b]，以及最低的区间是否应为 [a, b]。\n\n13.4.7 累积和滚动聚合\nR base 提供了 cumsum()、cumprod()、cummin()、cummax() 用于运行或累积的求和、求积、最小值和最大值。dplyr 提供了 cummean() 用于累积均值。累积和在实践中最为常见：\n\nx &lt;- 1:10\ncumsum(x)\n#&gt;  [1]  1  3  6 10 15 21 28 36 45 55\n\n如果你需要更复杂的滚动或滑动聚合，可以试试 slider 包。\n\n13.4.8 练习\n\n用语言解释用于生成 Figure 13.1 的代码每一行都在做什么。\nR 提供了哪些三角函数？猜一些名字并查阅文档。它们是使用度还是弧度？\n\n目前 dep_time 和 sched_dep_time 便于查看，但难以进行计算，因为它们并不是真正的连续数值。你可以通过运行下面的代码看到基本问题：每个小时之间都存在一个间隙。\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  ggplot(aes(x = sched_dep_time, y = dep_delay)) +\n  geom_point()\n\n将它们转换为更真实的时间表示（可以是小数小时或自午夜以来的分钟数）。\n\n将 dep_time 和 arr_time 四舍五入到最近的五分钟。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#通用转换",
    "href": "numbers.html#通用转换",
    "title": "13  数值",
    "section": "\n13.5 通用转换",
    "text": "13.5 通用转换\n以下各节描述了一些通常用于数值向量但也适用于所有其他列类型的通用转换。\n\n13.5.1 排名\ndplyr 提供了许多受 SQL 启发的排名函数，但你应始终从 dplyr::min_rank() 开始。它使用处理并列名次的典型方法，例如，第 1 名、第 2 名、第 2 名、第 4 名。\n\nx &lt;- c(1, 2, 2, 3, 4, NA)\nmin_rank(x)\n#&gt; [1]  1  2  2  4  5 NA\n\n注意，最小值获得最低的排名；使用 desc(x) 可以让最大值获得最低的排名：\n\nmin_rank(desc(x))\n#&gt; [1]  5  3  3  2  1 NA\n\n如果 min_rank() 不能满足你的需求，可以看看它的变体 dplyr::row_number()、dplyr::dense_rank()、dplyr::percent_rank() 和 dplyr::cume_dist()。详情请参阅文档。\n\ndf &lt;- tibble(x = x)\ndf |&gt; \n  mutate(\n    row_number = row_number(x),\n    dense_rank = dense_rank(x),\n    percent_rank = percent_rank(x),\n    cume_dist = cume_dist(x)\n  )\n#&gt; # A tibble: 6 × 5\n#&gt;       x row_number dense_rank percent_rank cume_dist\n#&gt;   &lt;dbl&gt;      &lt;int&gt;      &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1          1          1         0          0.2\n#&gt; 2     2          2          2         0.25       0.6\n#&gt; 3     2          3          2         0.25       0.6\n#&gt; 4     3          4          3         0.75       0.8\n#&gt; 5     4          5          4         1          1  \n#&gt; 6    NA         NA         NA        NA         NA\n\n你可以通过为 R base 的 rank() 函数选择合适的 ties.method 参数来达到许多相同的结果；你可能还想设置 na.last = \"keep\" 以将 NA 保留为 NA。\nrow_number() 也可以在 dplyr 动词内部不带任何参数使用。在这种情况下，它会给出“当前”行的行号。当与 %% 或 %/% 结合使用时，这可以成为将数据分成大小相似的组的有用工具：\n\ndf &lt;- tibble(id = 1:10)\n\ndf |&gt; \n  mutate(\n    row0 = row_number() - 1,\n    three_groups = row0 %% 3,\n    three_in_each_group = row0 %/% 3\n  )\n#&gt; # A tibble: 10 × 4\n#&gt;      id  row0 three_groups three_in_each_group\n#&gt;   &lt;int&gt; &lt;dbl&gt;        &lt;dbl&gt;               &lt;dbl&gt;\n#&gt; 1     1     0            0                   0\n#&gt; 2     2     1            1                   0\n#&gt; 3     3     2            2                   0\n#&gt; 4     4     3            0                   1\n#&gt; 5     5     4            1                   1\n#&gt; 6     6     5            2                   1\n#&gt; # ℹ 4 more rows\n\n\n13.5.2 偏移\ndplyr::lead() 和 dplyr::lag() 允许你引用“当前”值之前或之后的值。它们返回一个与输入长度相同的向量，在开头或结尾用 NA 填充：\n\nx &lt;- c(2, 5, 11, 11, 19, 35)\nlag(x)\n#&gt; [1] NA  2  5 11 11 19\nlead(x)\n#&gt; [1]  5 11 11 19 35 NA\n\n\n\nx - lag(x) 给出当前值与前一个值之间的差值。\n\nx - lag(x)\n#&gt; [1] NA  3  6  0  8 16\n\n\n\nx == lag(x) 告诉你当前值何时发生变化。\n\nx == lag(x)\n#&gt; [1]    NA FALSE FALSE  TRUE FALSE FALSE\n\n\n\n你可以通过使用第二个参数 n 来向前或向后偏移超过一个位置。\n\n13.5.3 连续标识符\n有时你希望在每次某个事件发生时开始一个新的组。例如，在查看网站数据时，通常希望将事件分成会话（session），即在距离上次活动超过 x 分钟的间隙后开始一个新的会话。例如，假设你有一个人访问网站的时间记录：\n\nevents &lt;- tibble(\n  time = c(0, 1, 2, 3, 5, 10, 12, 15, 17, 19, 20, 27, 28, 30)\n)\n\n并且你已经计算了每个事件之间的时间，并判断是否存在足够大的间隙：\n\nevents &lt;- events |&gt; \n  mutate(\n    diff = time - lag(time, default = first(time)),\n    has_gap = diff &gt;= 5\n  )\nevents\n#&gt; # A tibble: 14 × 3\n#&gt;    time  diff has_gap\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  \n#&gt; 1     0     0 FALSE  \n#&gt; 2     1     1 FALSE  \n#&gt; 3     2     1 FALSE  \n#&gt; 4     3     1 FALSE  \n#&gt; 5     5     2 FALSE  \n#&gt; 6    10     5 TRUE   \n#&gt; # ℹ 8 more rows\n\n但是我们如何从那个逻辑向量得到一个可以用于 group_by() 的东西呢？来自 Section 13.4.7 的 cumsum() 派上了用场，因为间隙，即 has_gap 为 TRUE时，会将 group 增加一（Section 12.4.2）：\n\nevents |&gt; mutate(\n  group = cumsum(has_gap)\n)\n#&gt; # A tibble: 14 × 4\n#&gt;    time  diff has_gap group\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;   &lt;int&gt;\n#&gt; 1     0     0 FALSE       0\n#&gt; 2     1     1 FALSE       0\n#&gt; 3     2     1 FALSE       0\n#&gt; 4     3     1 FALSE       0\n#&gt; 5     5     2 FALSE       0\n#&gt; 6    10     5 TRUE        1\n#&gt; # ℹ 8 more rows\n\n另一种创建分组变量的方法是 consecutive_id()，它在每次其参数之一发生变化时开始一个新组。例如，受 这个 Stack Overflow 问题 的启发，假设你有一个包含大量重复值的数据框：\n\ndf &lt;- tibble(\n  x = c(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"d\", \"e\", \"a\", \"a\", \"b\", \"b\"),\n  y = c(1, 2, 3, 2, 4, 1, 3, 9, 4, 8, 10, 199)\n)\n\n如果你想保留每个重复的 x 的第一行，你可以使用 group_by()、consecutive_id() 和 slice_head()：\n\ndf |&gt; \n  group_by(id = consecutive_id(x)) |&gt; \n  slice_head(n = 1)\n#&gt; # A tibble: 7 × 3\n#&gt; # Groups:   id [7]\n#&gt;   x         y    id\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 a         1     1\n#&gt; 2 b         2     2\n#&gt; 3 c         4     3\n#&gt; 4 d         3     4\n#&gt; 5 e         9     5\n#&gt; 6 a         4     6\n#&gt; # ℹ 1 more row\n\n\n13.5.4 练习\n\n使用排名函数找出延误最严重的 10 个航班。你希望如何处理并列排名？仔细阅读 min_rank() 的文档。\n哪架飞机（tailnum）的准点记录最差？\n如果你想尽可能避免延误，应该在一天中的什么时间飞行？\nflights |&gt; group_by(dest) |&gt; filter(row_number() &lt; 4) 会做什么？flights |&gt; group_by(dest) |&gt; filter(row_number(dep_delay) &lt; 4) 又会做什么？\n对于每个目的地，计算总的延误分钟数。对于每个航班，计算其延误占其目的地总延误的比例。\n\n延误通常在时间上是相关的：即使导致初始延误的问题已经解决，后续的航班也会被延误，以便让较早的航班先行离开。使用 lag()，探讨一个小时的平均航班延误与前一个小时的平均延误之间的关系。\n\nflights |&gt; \n  mutate(hour = dep_time %/% 100) |&gt; \n  group_by(year, month, day, hour) |&gt; \n  summarize(\n    dep_delay = mean(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(n &gt; 5)\n\n\n查看每个目的地。你能找到飞行速度可疑的航班吗（即可能代表数据输入错误的航班）？计算一个航班的飞行时间相对于到该目的地的最短飞行时间的比例。哪些航班在空中延误最严重？\n找出所有由至少两家航空公司执飞的目的地。使用这些目的地，根据它们在同一目的地的表现，为航空公司创建一个相对排名。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#数值汇总",
    "href": "numbers.html#数值汇总",
    "title": "13  数值",
    "section": "\n13.6 数值汇总",
    "text": "13.6 数值汇总\n仅使用我们已经介绍过的计数、均值和总和就可以让你走得很远，但 R 提供了许多其他有用的汇总函数。这里是一些你可能会觉得有用的选择。\n\n13.6.1 中心位置\n到目前为止，我们主要使用 mean() 来概括一个数值向量的中心位置。正如我们在 Section 3.6 中看到的，因为均值是总和除以计数，所以它对少数异常高或低的值很敏感。一个替代方法是使用 median()，它找到一个位于向量“中间”的值，即 50% 的值在它之上，50% 的值在它之下。根据你感兴趣的变量的分布形状，均值或中位数可能是衡量中心位置的更好指标。例如，对于对称分布，我们通常报告均值，而对于偏态分布，我们通常报告中位数。\nFigure 13.2 比较了每个目的地出发延误（分钟）的均值与中位数。中位数延误总是小于均值延误，因为航班有时会晚点数小时，但从不会提早数小时出发。\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    mean = mean(dep_delay, na.rm = TRUE),\n    median = median(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  ggplot(aes(x = mean, y = median)) + \n  geom_abline(slope = 1, intercept = 0, color = \"white\", linewidth = 2) +\n  geom_point()\n\n\n\n\n\n\nFigure 13.2: 一张散点图，显示了用中位数代替均值来汇总每日出发延误的差异。\n\n\n\n\n你可能也想知道众数（mode），即最常见的值。这是一个只在非常简单的情况下才好用的汇总统计量（这可能是你在高中学到它的原因），但它对许多真实数据集效果不佳。如果数据是离散的，可能会有多个最常见的值；如果数据是连续的，可能根本没有最常见的值，因为每个值都略有不同。由于这些原因，统计学家倾向于不使用众数，R base 中也没有包含众数函数2。\n\n13.6.2 最小值、最大值和分位数\n如果你感兴趣的不是中心位置呢？min() 和 max() 会给你最大值和最小值。另一个强大的工具是 quantile()，它是中位数的推广：quantile(x, 0.25) 会找到 x 中大于 25% 值的值，quantile(x, 0.5) 等同于中位数，而 quantile(x, 0.95) 会找到大于 95% 值的值。\n对于 flights 数据，你可能想查看延误的 95% 分位数，而不是最大值，因为它会忽略那 5% 最为极端的延误航班。\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    max = max(dep_delay, na.rm = TRUE),\n    q95 = quantile(dep_delay, 0.95, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day   max   q95\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2013     1     1   853  70.1\n#&gt; 2  2013     1     2   379  85  \n#&gt; 3  2013     1     3   291  68  \n#&gt; 4  2013     1     4   288  60  \n#&gt; 5  2013     1     5   327  41  \n#&gt; 6  2013     1     6   202  51  \n#&gt; # ℹ 359 more rows\n\n\n13.6.3 离散程度\n有时你不太关心数据的主体在哪里，而是关心它是如何分布的。两个常用的汇总统计量是标准差 sd(x) 和四分位距 IQR()。我们在这里不解释 sd()，因为你可能已经熟悉它了，但 IQR() 可能对你来说是新的——它是 quantile(x, 0.75) - quantile(x, 0.25)，并告诉你包含中间 50% 数据的范围。\n我们可以用它来揭示 flights 数据中的一个小小的奇特之处。你可能期望始发地和目的地之间的距离离散程度为零，因为机场总是在同一个地方。但下面的代码揭示了机场 EGE 的一个数据奇特之处：\n\nflights |&gt; \n  group_by(origin, dest) |&gt; \n  summarize(\n    distance_iqr = IQR(distance), \n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(distance_iqr &gt; 0)\n#&gt; # A tibble: 2 × 4\n#&gt;   origin dest  distance_iqr     n\n#&gt;   &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 EWR    EGE              1   110\n#&gt; 2 JFK    EGE              1   103\n\n\n13.6.4 分布\n值得记住的是，上面描述的所有汇总统计量都是将分布简化为单个数字的一种方式。这意味着它们从根本上是简化的，如果你选择了错误的汇总统计量，你很容易会忽略组间的重要差异。这就是为什么在确定你的汇总统计量之前，总是先将分布可视化是一个好主意。\nFigure 13.3 显示了出发延误的总体分布。分布非常偏斜，以至于我们必须放大才能看到数据的主体部分。这表明均值不太可能是一个好的汇总指标，我们可能更倾向于使用中位数。\n\n\n\n\n\n\n\nFigure 13.3: （左图）完整数据的直方图极度偏斜，很难看清任何细节。 （右图）放大到延误小于两小时的范围，可以看清大部分观测值的情况。\n\n\n\n\n检查子组的分布是否与整体相似也是一个好主意。在下面的图中，叠加了 365 个 dep_delay 的频率多边形图，每天一个。这些分布似乎遵循一个共同的模式，这表明对每天使用相同的汇总统计量是可以的。\n\nflights |&gt;\n  filter(dep_delay &lt; 120) |&gt; \n  ggplot(aes(x = dep_delay, group = interaction(day, month))) + \n  geom_freqpoly(binwidth = 5, alpha = 1/5)\n\n\n\n\n\n\n\n不要害怕探索专门为你正在处理的数据量身定制的自定义汇总。在这种情况下，这可能意味着分别汇总提早出发的航班和晚点出发的航班，或者鉴于数值偏斜严重，你可能会尝试对数转换。最后，不要忘记你在 Section 3.6 中学到的：在创建数值汇总时，最好包含每个组中的观测数量。\n\n13.6.5 位置\n还有最后一种对数值向量很有用，但也适用于所有其他类型值的汇总：提取特定位置的值：first(x)、last(x) 和 nth(x, n)。\n例如，我们可以找到每天的第一次、第五次和最后一次出发：\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    first_dep = first(dep_time, na_rm = TRUE), \n    fifth_dep = nth(dep_time, 5, na_rm = TRUE),\n    last_dep = last(dep_time, na_rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n#&gt; # A tibble: 365 × 6\n#&gt; # Groups:   year, month [12]\n#&gt;    year month   day first_dep fifth_dep last_dep\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt;     &lt;int&gt;    &lt;int&gt;\n#&gt; 1  2013     1     1       517       554     2356\n#&gt; 2  2013     1     2        42       535     2354\n#&gt; 3  2013     1     3        32       520     2349\n#&gt; 4  2013     1     4        25       531     2358\n#&gt; 5  2013     1     5        14       534     2357\n#&gt; 6  2013     1     6        16       555     2355\n#&gt; # ℹ 359 more rows\n\n（注意：因为 dplyr 函数使用 _ 来分隔函数和参数名称的组成部分，所以这些函数使用 na_rm 而不是 na.rm。）\n如果你熟悉 [（我们将在 Section 27.2 中回过头来讨论），你可能会想知道你是否真的需要这些函数。有三个原因：default 参数允许你在指定位置不存在时提供一个默认值，order_by 参数允许你局部覆盖行的顺序，而 na_rm 参数允许你删除缺失值。\n提取位置上的值与按排名筛选是互补的。筛选会给你所有的变量，每个观测值占一行：\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  mutate(r = min_rank(sched_dep_time)) |&gt; \n  filter(r %in% c(1, max(r)))\n#&gt; # A tibble: 1,195 × 20\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1     2353           2359        -6      425            445\n#&gt; 3  2013     1     1     2353           2359        -6      418            442\n#&gt; 4  2013     1     1     2356           2359        -3      425            437\n#&gt; 5  2013     1     2       42           2359        43      518            442\n#&gt; 6  2013     1     2      458            500        -2      703            650\n#&gt; # ℹ 1,189 more rows\n#&gt; # ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n\n13.6.6 与 mutate() 结合使用\n顾名思义，汇总函数通常与 summarize() 配对使用。然而，由于我们在 Section 13.4.1 中讨论的循环补齐规则，它们也可以与 mutate() 有效地配对使用，特别是当你想要进行某种分组标准化时。例如：\n\n\nx / sum(x) 计算占总数的比例。\n\n(x - mean(x)) / sd(x) 计算一个 Z 分数（标准化为均值为 0，标准差为 1）。\n\n(x - min(x)) / (max(x) - min(x)) 标准化到 [0, 1] 的范围。\n\nx / first(x) 计算一个基于第一个观测值的指数。\n\n13.6.7 练习\n\n集思广益，想出至少 5 种不同的方法来评估一组航班的典型延误特征。什么时候 mean() 有用？什么时候 median() 有用？什么时候你可能想用别的方法？你应该使用到达延误还是出发延误？为什么你可能想使用来自 planes 的数据？\n哪些目的地的空速变化最大？\n创建一个图表来进一步探索 EGE 的奇遇。你能找到任何证据表明机场搬迁了吗？你能找到另一个可能解释这种差异的变量吗？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#总结",
    "href": "numbers.html#总结",
    "title": "13  数值",
    "section": "\n13.7 总结",
    "text": "13.7 总结\n你已经熟悉了许多处理数值的工具，在阅读本章后，你现在知道如何在 R 中使用它们。你还学到了一些有用的通用转换，这些转换通常（但不仅限于）应用于数值向量，如排名和偏移。最后，你详细研究了一些数值汇总方法，并讨论了你应该考虑的一些统计挑战。\n在接下来的两章中，我们将深入探讨使用 stringr 包处理字符串。字符串是一个很大的主题，所以它们占了两章，一章是关于字符串的基础知识，另一章是关于正则表达式。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "numbers.html#footnotes",
    "href": "numbers.html#footnotes",
    "title": "13  数值",
    "section": "",
    "text": "ggplot2 在 cut_interval()、cut_number() 和 cut_width() 中为常见情况提供了一些辅助函数。承认 ggplot2 是这些函数存在的一个奇怪的地方，但它们作为直方图计算的一部分很有用，并且在 tidyverse 的任何其他部分存在之前就已经编写好了。↩︎\nmode() 函数做的是完全不同的事情！↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>数值</span>"
    ]
  },
  {
    "objectID": "strings.html",
    "href": "strings.html",
    "title": "14  字符串",
    "section": "",
    "text": "14.1 引言\n到目前为止，你已经使用了很多字符串，但对细节知之甚少。现在是时候深入了解它们，学习字符串的运作原理，并掌握一些你可以使用的强大字符串处理工具。\n我们将从创建字符串和字符向量的细节开始。然后，你将深入学习如何从数据创建字符串，以及反过来：如何从数据中提取字符串。接着，我们将讨论处理单个字母的工具。本章最后会介绍处理单个字母的函数，并简要讨论在处理其他语言时，你从英语中获得的期望可能会如何误导你。\n我们将在下一章继续学习字符串，届时你将学到更多关于正则表达式的强大功能。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#引言",
    "href": "strings.html#引言",
    "title": "14  字符串",
    "section": "",
    "text": "14.1.1 先决条件\n在本章中，我们将使用 stringr 包中的函数，它是核心 tidyverse 的一部分。我们还将使用 babynames 数据，因为它提供了一些有趣的字符串供我们操作。\n\nlibrary(tidyverse)\nlibrary(babynames)\n\n你可以很快分辨出你正在使用的是一个 stringr 函数，因为所有 stringr 函数都以 str_ 开头。如果你使用 RStudio，这一点特别有用，因为输入 str_ 会触发自动补全，让你回想起可用的函数。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#创建字符串",
    "href": "strings.html#创建字符串",
    "title": "14  字符串",
    "section": "\n14.2 创建字符串",
    "text": "14.2 创建字符串\n我们在本书的前面部分已经顺便创建过字符串，但没有讨论细节。首先，你可以使用单引号 (') 或双引号 (\") 来创建字符串。这两者在行为上没有区别，因此为了保持一致性，tidyverse 风格指南 建议使用 \"，除非字符串中包含多个 \"。\n\nstring1 &lt;- \"This is a string\"\nstring2 &lt;- 'If I want to include a \"quote\" inside a string, I use single quotes'\n\n如果你忘记关闭引号，你会看到 +，即续行提示符：\n&gt; \"This is a string without a closing quote\n+ \n+ \n+ HELP I'M STUCK IN A STRING\n如果发生这种情况，而你又不知道该关闭哪个引号，可以按 Escape 键取消并重试。\n\n14.2.1 转义\n要在字符串中包含字面意义上的单引号或双引号，你可以使用 \\ 来“转义”它：\n\ndouble_quote &lt;- \"\\\"\" # 或者 '\"'\nsingle_quote &lt;- '\\'' # 或者 \"'\"\n\n所以，如果你想在字符串中包含一个字面意义上的反斜杠，你需要对它进行转义：\"\\\\\"：\n\nbackslash &lt;- \"\\\\\"\n\n请注意，字符串的打印表示形式与字符串本身不同，因为打印表示形式会显示转义符（换句话说，当你打印一个字符串时，你可以复制并粘贴输出来重新创建那个字符串）。要查看字符串的原始内容，请使用 str_view()1：\n\nx &lt;- c(single_quote, double_quote, backslash)\nx\n#&gt; [1] \"'\"  \"\\\"\" \"\\\\\"\nstr_view(x)\n#&gt; [1] │ '\n#&gt; [2] │ \"\n#&gt; [3] │ \\\n\n\n14.2.2 原始字符串\n创建一个包含多个引号或反斜杠的字符串很快就会变得混乱。为了说明这个问题，让我们创建一个字符串，它包含我们定义 double_quote 和 single_quote 变量的代码块的内容：\n\ntricky &lt;- \"double_quote &lt;- \\\"\\\\\\\"\\\" # or '\\\"'\nsingle_quote &lt;- '\\\\'' # or \\\"'\\\"\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     │ single_quote &lt;- '\\'' # or \"'\"\n\n这可真是一大堆反斜杠！（这有时被称为倾斜的牙签综合症 (leaning toothpick syndrome)。）为了消除转义，你可以改用原始字符串 (raw string)2：\n\ntricky &lt;- r\"(double_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\")\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     │ single_quote &lt;- '\\'' # or \"'\"\n\n原始字符串通常以 r\"( 开始，以 )\" 结束。但是，如果你的字符串包含 )\"，你可以改用 r\"[]\" 或 r\"{}\"，如果这还不够，你可以插入任意数量的破折号来使开始和结束对唯一，例如 r\"--()--\"、r\"---()---\" 等。原始字符串足够灵活，可以处理任何文本。\n\n14.2.3 其他特殊字符\n除了 \\\"、\\' 和 \\\\，还有一些其他特殊字符可能会派上用场。最常见的是 \\n（换行符）和 \\t（制表符）。你有时还会看到包含以 \\u 或 \\U 开头的 Unicode 转义的字符串。这是一种书写非英文字符的方法，能在所有系统上工作。你可以在 ?Quotes 中看到其他特殊字符的完整列表。\n\nx &lt;- c(\"one\\ntwo\", \"one\\ttwo\", \"\\u00b5\", \"\\U0001f604\")\nx\n#&gt; [1] \"one\\ntwo\" \"one\\ttwo\" \"µ\"        \"😄\"\nstr_view(x)\n#&gt; [1] │ one\n#&gt;     │ two\n#&gt; [2] │ one{\\t}two\n#&gt; [3] │ µ\n#&gt; [4] │ 😄\n\n请注意，str_view() 对制表符使用花括号，以便更容易发现它们3。处理文本的挑战之一是，空白字符有多种方式进入文本，所以这个背景能帮助你识别出有异常情况正在发生。\n\n14.2.4 练习\n\n\n创建包含以下值的字符串：\n\nHe said \"That's amazing!\"\n\\a\\b\\c\\d\n\\\\\\\\\\\\\n\n\n\n在你的 R 会话中创建以下字符串并打印它。特殊的 \\u00a0 发生了什么？str_view() 如何显示它？你能用 Google 搜索一下，找出这个特殊字符是什么吗？\n\nx &lt;- \"This\\u00a0is\\u00a0tricky\"",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#从数据创建多个字符串",
    "href": "strings.html#从数据创建多个字符串",
    "title": "14  字符串",
    "section": "\n14.3 从数据创建多个字符串",
    "text": "14.3 从数据创建多个字符串\n现在你已经学会了“手动”创建一个或两个字符串的基础知识，我们将深入探讨从其他字符串创建字符串的细节。这将帮助你解决一个常见问题：你有一些自己写的文本，想把它与数据框中的字符串结合起来。例如，你可能会将 “Hello” 与一个 name 变量结合起来，创建一个问候语。我们将向你展示如何使用 str_c() 和 str_glue() 来做到这一点，以及如何将它们与 mutate() 一起使用。这自然会引出一个问题：你可能会在 summarize() 中使用哪些 stringr 函数？因此，我们将在本节最后讨论 str_flatten()，这是一个用于字符串的汇总函数。\n\n14.3.1 str_c()\n\nstr_c() 接受任意数量的向量作为参数，并返回一个字符向量：\n\nstr_c(\"x\", \"y\")\n#&gt; [1] \"xy\"\nstr_c(\"x\", \"y\", \"z\")\n#&gt; [1] \"xyz\"\nstr_c(\"Hello \", c(\"John\", \"Susan\"))\n#&gt; [1] \"Hello John\"  \"Hello Susan\"\n\nstr_c() 与 R base 的 paste0() 非常相似，但它被设计为与 mutate() 一起使用，遵循了 tidyverse 的常规规则，即循环补齐和传播缺失值：\n\ndf &lt;- tibble(name = c(\"Flora\", \"David\", \"Terra\", NA))\ndf |&gt; mutate(greeting = str_c(\"Hi \", name, \"!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  &lt;NA&gt;\n\n如果你希望缺失值以另一种方式显示，可以使用 coalesce() 来替换它们。根据你的需求，你可以在 str_c() 内部或外部使用它：\n\ndf |&gt; \n  mutate(\n    greeting1 = str_c(\"Hi \", coalesce(name, \"you\"), \"!\"),\n    greeting2 = coalesce(str_c(\"Hi \", name, \"!\"), \"Hi!\")\n  )\n#&gt; # A tibble: 4 × 3\n#&gt;   name  greeting1 greeting2\n#&gt;   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora! Hi Flora!\n#&gt; 2 David Hi David! Hi David!\n#&gt; 3 Terra Hi Terra! Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi you!   Hi!\n\n\n14.3.2 str_glue()\n\n如果你用 str_c() 混合许多固定的和可变的字符串，你会注意到你输入了大量的 \"，这使得代码的整体目标难以看清。另一种方法是由 glue 包 通过 str_glue()4 提供的。你给它一个具有特殊功能的单一字符串：{} 里的任何东西都会像在引号外面一样被求值：\n\ndf |&gt; mutate(greeting = str_glue(\"Hi {name}!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;glue&gt;   \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi NA!\n\n如你所见，str_glue() 目前将缺失值转换为字符串 \"NA\"，不幸的是，这与 str_c() 不一致。\n你可能还会想，如果需要在字符串中包含一个常规的 { 或 }，会发生什么。如果你猜到需要以某种方式转义它，那你的思路是正确的。诀窍在于 glue 使用了一种稍微不同的转义技术：不是用像 \\ 这样的特殊字符作为前缀，而是将特殊字符加倍：\n\ndf |&gt; mutate(greeting = str_glue(\"{{Hi {name}!}}\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting   \n#&gt;   &lt;chr&gt; &lt;glue&gt;     \n#&gt; 1 Flora {Hi Flora!}\n#&gt; 2 David {Hi David!}\n#&gt; 3 Terra {Hi Terra!}\n#&gt; 4 &lt;NA&gt;  {Hi NA!}\n\n\n14.3.3 str_flatten()\n\nstr_c() 和 str_glue() 与 mutate() 配合得很好，因为它们的输出与输入长度相同。如果你想要一个能与 summarize() 很好配合的函数，即一个总是返回单个字符串的东西呢？这就是 str_flatten()5 的工作：它接受一个字符向量，并将向量的每个元素组合成一个单一的字符串：\n\nstr_flatten(c(\"x\", \"y\", \"z\"))\n#&gt; [1] \"xyz\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \")\n#&gt; [1] \"x, y, z\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \", last = \", and \")\n#&gt; [1] \"x, y, and z\"\n\n这使得它能与 summarize() 很好地配合工作：\n\ndf &lt;- tribble(\n  ~ name, ~ fruit,\n  \"Carmen\", \"banana\",\n  \"Carmen\", \"apple\",\n  \"Marvin\", \"nectarine\",\n  \"Terence\", \"cantaloupe\",\n  \"Terence\", \"papaya\",\n  \"Terence\", \"mandarin\"\n)\ndf |&gt;\n  group_by(name) |&gt; \n  summarize(fruits = str_flatten(fruit, \", \"))\n#&gt; # A tibble: 3 × 2\n#&gt;   name    fruits                      \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                       \n#&gt; 1 Carmen  banana, apple               \n#&gt; 2 Marvin  nectarine                   \n#&gt; 3 Terence cantaloupe, papaya, mandarin\n\n\n14.3.4 练习\n\n\n对于以下输入，比较并对比 paste0() 与 str_c() 的结果：\n\nstr_c(\"hi \", NA)\nstr_c(letters[1:2], letters[1:3])\n\n\npaste() 和 paste0() 有什么区别？你如何用 str_c() 重现与 paste() 等价的功能？\n\n将以下表达式从 str_c() 转换为 str_glue()，或反之：\n\nstr_c(\"The price of \", food, \" is \", price)\nstr_glue(\"I'm {age} years old and live in {country}\")\nstr_c(\"\\\\section{\", title, \"}\")",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#从字符串中提取数据",
    "href": "strings.html#从字符串中提取数据",
    "title": "14  字符串",
    "section": "\n14.4 从字符串中提取数据",
    "text": "14.4 从字符串中提取数据\n将多个变量塞进一个字符串中是很常见的。在本节中，你将学习如何使用四个 tidyr 函数来提取它们：\n\ndf |&gt; separate_longer_delim(col, delim)\ndf |&gt; separate_longer_position(col, width)\ndf |&gt; separate_wider_delim(col, delim, names)\ndf |&gt; separate_wider_position(col, widths)\n\n如果你仔细观察，你会发现这里有一个共同的模式：separate_，然后是 longer 或 wider，然后是 _，然后是 delim 或 position。这是因为这四个函数是由两个更简单的原语组成的：\n\n就像 pivot_longer() 和 pivot_wider() 一样，_longer 函数通过创建新行来使输入的数据框变长，而 _wider 函数通过生成新列来使输入的数据框变宽。\n\ndelim 用像 \", \" 或 \" \" 这样的分隔符来分割字符串；position 在指定的宽度处分割，比如 c(3, 5, 2)。\n\n我们将在 Chapter 15 中回到这个家族的最后一个成员，separate_wider_regex()。它是 wider 函数中最灵活的一个，但在使用它之前，你需要对正则表达式有所了解。\n接下来的两节将为你介绍这些 separate 函数背后的基本思想，首先是分成行（这稍微简单一些），然后是分成列。最后，我们将讨论 wider 函数为你提供的诊断问题的工具。\n\n14.4.1 分成行\n当不同行中组件的数量不同时，将字符串分成行通常最有用。最常见的情况是需要 separate_longer_delim() 根据分隔符进行分割：\n\ndf1 &lt;- tibble(x = c(\"a,b,c\", \"d,e\", \"f\"))\ndf1 |&gt; \n  separate_longer_delim(x, delim = \",\")\n#&gt; # A tibble: 6 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a    \n#&gt; 2 b    \n#&gt; 3 c    \n#&gt; 4 d    \n#&gt; 5 e    \n#&gt; 6 f\n\nseparate_longer_position() 在实践中比较少见，但一些较老的数据集确实使用一种非常紧凑的格式，其中每个字符都用来记录一个值：\n\ndf2 &lt;- tibble(x = c(\"1211\", \"131\", \"21\"))\ndf2 |&gt; \n  separate_longer_position(x, width = 1)\n#&gt; # A tibble: 9 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1    \n#&gt; 2 2    \n#&gt; 3 1    \n#&gt; 4 1    \n#&gt; 5 1    \n#&gt; 6 3    \n#&gt; # ℹ 3 more rows\n\n\n14.4.2 分成列\n当每个字符串中都有固定数量的组件，并且你希望将它们分散到列中时，将字符串分成列通常最有用。它们比它们的 longer 等价物稍微复杂一些，因为你需要命名这些列。例如，在下面的数据集中，x 由一个代码、一个版本号和一个年份组成，用 . 分隔。要使用 separate_wider_delim()，我们需要在两个参数中提供分隔符和名称：\n\ndf3 &lt;- tibble(x = c(\"a10.1.2022\", \"b10.2.2011\", \"e15.1.2015\"))\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", \"edition\", \"year\")\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   code  edition year \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 a10   1       2022 \n#&gt; 2 b10   2       2011 \n#&gt; 3 e15   1       2015\n\n如果某个特定的部分没有用，你可以使用 NA 名称来从结果中省略它：\n\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", NA, \"year\")\n  )\n#&gt; # A tibble: 3 × 2\n#&gt;   code  year \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 a10   2022 \n#&gt; 2 b10   2011 \n#&gt; 3 e15   2015\n\nseparate_wider_position() 的工作方式略有不同，因为你通常需要指定每列的宽度。所以你给它一个命名的整数向量，其中名称给出新列的名称，值是它占用的字符数。你可以通过不命名来从输出中省略值：\n\ndf4 &lt;- tibble(x = c(\"202215TX\", \"202122LA\", \"202325CA\")) \ndf4 |&gt; \n  separate_wider_position(\n    x,\n    widths = c(year = 4, age = 2, state = 2)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   year  age   state\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 2022  15    TX   \n#&gt; 2 2021  22    LA   \n#&gt; 3 2023  25    CA\n\n\n14.4.3 诊断变宽问题\nseparate_wider_delim()6 需要一个固定的、已知的列集合。如果某些行没有预期的片段数量，会发生什么？可能存在两种问题：片段太少或太多，所以 separate_wider_delim() 提供了两个参数来帮助解决：too_few 和 too_many。我们首先用下面的示例数据集来看一下 too_few 的情况：\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3\", \"1-3-2\", \"1\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too short.\n#&gt; ℹ Use `too_few = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_few = \"align_start\"/\"align_end\"` to silence this message.\n\n你会注意到我们得到了一个错误，但错误信息给了我们一些关于如何继续的建议。让我们从调试问题开始：\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug\n#&gt; # A tibble: 5 × 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-1-1 1     1     TRUE         3 \"\"         \n#&gt; 2 1-1-2 1     2     TRUE         3 \"\"         \n#&gt; 3 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 4 1-3-2 3     2     TRUE         3 \"\"         \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\n当你使用调试模式时，输出中会增加三列：x_ok、x_pieces 和 x_remainder（如果你分离一个不同名称的变量，你会得到一个不同的前缀）。在这里，x_ok 让你能够快速找到失败的输入：\n\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 × 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 2 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\nx_pieces 告诉我们找到了多少个片段，而预期是 3 个（names 的长度）。当片段太少时，x_remainder 没有用，但我们很快会再次看到它。\n有时，查看这些调试信息会揭示你的分隔符策略存在问题，或者表明你需要在分离前进行更多的预处理。在这种情况下，修复上游的问题，并确保移除 too_few = \"debug\"，以确保新问题会变成错误。\n在其他情况下，你可能希望用 NA 填充缺失的片段然后继续。这就是 too_few = \"align_start\" 和 too_few = \"align_end\" 的工作，它们允许你控制 NA 应该放在哪里：\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"align_start\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     &lt;NA&gt; \n#&gt; 4 1     3     2    \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;\n\n如果你有太多的片段，同样的原则也适用：\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3-5-6\", \"1-3-2\", \"1-3-5-7-9\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too long.\n#&gt; ℹ Use `too_many = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_many = \"drop\"/\"merge\"` to silence this message.\n\n但是现在，当我们调试结果时，你可以看到 x_remainder 的用途：\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 × 6\n#&gt;   x         y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3-5-6   3     5     FALSE        4 -6         \n#&gt; 2 1-3-5-7-9 3     5     FALSE        5 -7-9\n\n对于处理过多的片段，你有一套略有不同的选项：你可以静默地“drop”（丢弃）任何额外的片段，或者将它们全部“merge”（合并）到最后一列：\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"drop\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5    \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5\n\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"merge\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5-6  \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5-7-9",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#字母",
    "href": "strings.html#字母",
    "title": "14  字符串",
    "section": "\n14.5 字母",
    "text": "14.5 字母\n在本节中，我们将向你介绍一些函数，让你能够处理字符串中的单个字母。你将学习如何找到字符串的长度，提取子字符串，以及在图表和表格中处理长字符串。\n\n14.5.1 长度\nstr_length() 告诉你字符串中有多少个字母：\n\nstr_length(c(\"a\", \"R for data science\", NA))\n#&gt; [1]  1 18 NA\n\n你可以将此与 count() 一起使用，以找出美国婴儿姓名长度的分布，然后用 filter() 查看最长的名字，这些名字恰好有 15 个字母7：\n\nbabynames |&gt;\n  count(length = str_length(name), wt = n)\n#&gt; # A tibble: 14 × 2\n#&gt;   length        n\n#&gt;    &lt;int&gt;    &lt;int&gt;\n#&gt; 1      2   338150\n#&gt; 2      3  8589596\n#&gt; 3      4 48506739\n#&gt; 4      5 87011607\n#&gt; 5      6 90749404\n#&gt; 6      7 72120767\n#&gt; # ℹ 8 more rows\n\nbabynames |&gt; \n  filter(str_length(name) == 15) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 34 × 2\n#&gt;   name                n\n#&gt;   &lt;chr&gt;           &lt;int&gt;\n#&gt; 1 Franciscojavier   123\n#&gt; 2 Christopherjohn   118\n#&gt; 3 Johnchristopher   118\n#&gt; 4 Christopherjame   108\n#&gt; 5 Christophermich    52\n#&gt; 6 Ryanchristopher    45\n#&gt; # ℹ 28 more rows\n\n\n14.5.2 子集\n你可以使用 str_sub(string, start, end) 来提取字符串的一部分，其中 start 和 end 是子字符串应该开始和结束的位置。start 和 end 参数是包含性的，所以返回的字符串长度将是 end - start + 1：\n\nx &lt;- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n#&gt; [1] \"App\" \"Ban\" \"Pea\"\n\n你可以使用负值从字符串的末尾向前计数：-1 是最后一个字符，-2 是倒数第二个字符，依此类推。\n\nstr_sub(x, -3, -1)\n#&gt; [1] \"ple\" \"ana\" \"ear\"\n\n请注意，如果字符串太短，str_sub() 不会失败：它只会返回尽可能多的内容：\n\nstr_sub(\"a\", 1, 5)\n#&gt; [1] \"a\"\n\n我们可以使用 str_sub() 和 mutate() 来找出每个名字的首字母和末尾字母：\n\nbabynames |&gt; \n  mutate(\n    first = str_sub(name, 1, 1),\n    last = str_sub(name, -1, -1)\n  )\n#&gt; # A tibble: 1,924,665 × 7\n#&gt;    year sex   name          n   prop first last \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1  1880 F     Mary       7065 0.0724 M     y    \n#&gt; 2  1880 F     Anna       2604 0.0267 A     a    \n#&gt; 3  1880 F     Emma       2003 0.0205 E     a    \n#&gt; 4  1880 F     Elizabeth  1939 0.0199 E     h    \n#&gt; 5  1880 F     Minnie     1746 0.0179 M     e    \n#&gt; 6  1880 F     Margaret   1578 0.0162 M     t    \n#&gt; # ℹ 1,924,659 more rows\n\n\n14.5.3 练习\n\n在计算婴儿姓名长度的分布时，我们为什么使用 wt = n？\n使用 str_length() 和 str_sub() 从每个婴儿名字中提取中间的字母。如果字符串有偶数个字符，你该怎么办？\n婴儿姓名的长度随时间变化有任何主要趋势吗？首字母和末尾字母的流行度呢？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#sec-other-languages",
    "href": "strings.html#sec-other-languages",
    "title": "14  字符串",
    "section": "\n14.6 非英文文本",
    "text": "14.6 非英文文本\n到目前为止，我们主要关注英文文本，处理英文文本特别容易，原因有二。首先，英文字母相对简单：只有 26 个字母。其次（也许更重要），我们今天使用的计算基础设施主要是由说英语的人设计的。不幸的是，我们没有足够的篇幅来全面处理非英文语言。尽管如此，我们还是想提醒你注意一些你可能会遇到的最大挑战：编码、字母变体和依赖于区域设置的函数。\n\n14.6.1 编码\n在处理非英文文本时，第一个挑战通常是编码 (encoding)。要理解发生了什么，我们需要深入了解计算机是如何表示字符串的。在 R 中，我们可以使用 charToRaw() 来获取字符串的底层表示：\n\ncharToRaw(\"Hadley\")\n#&gt; [1] 48 61 64 6c 65 79\n\n这六个十六进制数中的每一个都代表一个字母：48 是 H，61 是 a，依此类推。从十六进制数到字符的映射称为编码，在这种情况下，编码被称为 ASCII。ASCII 在表示英文字符方面做得很好，因为它是美国信息交换标准代码。\n对于非英语语言来说，事情就没那么简单了。在计算的早期，有许多竞争性的标准用于编码非英文字符。例如，欧洲有两种不同的编码：Latin1（又名 ISO-8859-1）用于西欧语言，而 Latin2（又名 ISO-8859-2）用于中欧语言。在 Latin1 中，字节 b1 是 “±”，但在 Latin2 中，它是 “ą”！幸运的是，今天有一个几乎在任何地方都支持的标准：UTF-8。UTF-8 几乎可以编码当今人类使用的所有字符，以及许多额外的符号，如表情符号。\nreadr 处处使用 UTF-8。这是一个很好的默认设置，但对于由不使用 UTF-8 的旧系统产生的数据来说，这会失败。如果发生这种情况，你的字符串在打印时会看起来很奇怪。有时可能只有一两个字符出错；其他时候，你会得到完全的乱码。例如，这里是两个带有不寻常编码的内联 CSV8：\n\nx1 &lt;- \"text\\nEl Ni\\xf1o was particularly bad this year\"\nread_csv(x1)$text\n#&gt; [1] \"El Ni\\xf1o was particularly bad this year\"\n\nx2 &lt;- \"text\\n\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd\"\nread_csv(x2)$text\n#&gt; [1] \"\\x82\\xb1\\x82\\xf1\\x82ɂ\\xbf\\x82\\xcd\"\n\n要正确读取这些内容，你需要通过 locale 参数指定编码：\n\nread_csv(x1, locale = locale(encoding = \"Latin1\"))$text\n#&gt; [1] \"El Niño was particularly bad this year\"\n\nread_csv(x2, locale = locale(encoding = \"Shift-JIS\"))$text\n#&gt; [1] \"こんにちは\"\n\n你如何找到正确的编码？如果幸运的话，它会包含在数据文档的某个地方。不幸的是，这种情况很少见，所以 readr 提供了 guess_encoding() 来帮助你找出它。它不是万无一失的，并且在你有很多文本时效果更好（不像这里），但它是一个合理的起点。预计你需要尝试几种不同的编码才能找到正确的那个。\n编码是一个丰富而复杂的主题；我们在这里只触及了皮毛。如果你想了解更多，我们建议阅读 http://kunststube.net/encoding/ 上的详细解释。\n\n14.6.2 字母变体\n在处理带重音的语言时，确定字母的位置（例如，使用 str_length() 和 str_sub()）会带来一个重大挑战，因为带重音的字母可能被编码为单个独立的字符（例如，ü），或者通过组合一个不带重音的字母（例如，u）和一个变音符号（例如，¨）来编码为两个字符。例如，这段代码显示了两种看起来相同的 ü 的表示方法：\n\nu &lt;- c(\"\\u00fc\", \"u\\u0308\")\nstr_view(u)\n#&gt; [1] │ ü\n#&gt; [2] │ ü\n\n但这两个字符串的长度不同，并且它们的第一个字符也不同：\n\nstr_length(u)\n#&gt; [1] 1 2\nstr_sub(u, 1, 1)\n#&gt; [1] \"ü\" \"u\"\n\n最后，请注意，使用 == 比较这些字符串会将它们解释为不同的，而 stringr 中方便的 str_equal() 函数则能识别出它们俩具有相同的外观：\n\nu[[1]] == u[[2]]\n#&gt; [1] FALSE\n\nstr_equal(u[[1]], u[[2]])\n#&gt; [1] TRUE\n\n\n14.6.3 依赖于区域设置的函数\n最后，还有一些 stringr 函数的行为取决于你的区域设置 (locale)。区域设置类似于一种语言，但包含一个可选的地区说明符，以处理一种语言内部的地区差异。区域设置由一个小写的语言缩写指定，后面可以选择性地跟一个 _ 和一个大写的地区标识符。例如，“en” 是英语，“en_GB” 是英式英语，“en_US” 是美式英语。如果你还不知道你语言的代码，维基百科 有一个很好的列表，你可以通过查看 stringi::stri_locale_list() 来看看 stringr 支持哪些。\nR base 的字符串函数会自动使用你的操作系统设置的区域设置。这意味着 R base 的字符串函数会按照你期望的方式对你的语言进行操作，但如果你的代码与生活在不同国家的人共享，它可能会有不同的表现。为了避免这个问题，stringr 默认使用 “en” 区域设置的英语规则，并要求你指定 locale 参数来覆盖它。幸运的是，只有两组函数的区域设置真正重要：改变大小写和排序。\n改变大小写的规则在不同语言中有所不同。例如，土耳其语中有两个 i：带点和不带点的。由于它们是两个不同的字母，它们的大小写转换也不同：\n\nstr_to_upper(c(\"i\", \"ı\"))\n#&gt; [1] \"I\" \"I\"\nstr_to_upper(c(\"i\", \"ı\"), locale = \"tr\")\n#&gt; [1] \"İ\" \"I\"\n\n对字符串进行排序取决于字母表的顺序，而字母表的顺序在每种语言中都不尽相同9！这里有一个例子：在捷克语中，“ch” 是一个复合字母，它在字母表中出现在 h 之后。\n\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"))\n#&gt; [1] \"a\"  \"c\"  \"ch\" \"h\"  \"z\"\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"), locale = \"cs\")\n#&gt; [1] \"a\"  \"c\"  \"h\"  \"ch\" \"z\"\n\n这在使用 dplyr::arrange() 对字符串进行排序时也会出现，这就是为什么它也有一个 locale 参数。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#总结",
    "href": "strings.html#总结",
    "title": "14  字符串",
    "section": "\n14.7 总结",
    "text": "14.7 总结\n在本章中，你已经了解了 stringr 包的一些强大功能：如何创建、组合和提取字符串，以及在处理非英语字符串时可能面临的一些挑战。现在是时候学习一个处理字符串最重要、最强大的工具之一了：正则表达式。正则表达式是一种非常简洁但表达能力极强的语言，用于描述字符串内的模式，它是下一章的主题。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "strings.html#footnotes",
    "href": "strings.html#footnotes",
    "title": "14  字符串",
    "section": "",
    "text": "或者使用 R base 函数 writeLines()。↩︎\nR 4.0.0 及以上版本可用。↩︎\nstr_view() 还使用颜色来提请你注意制表符、空格、匹配项等。这些颜色目前在书中不显示，但你在交互式运行代码时会注意到它们。↩︎\n如果你没有使用 stringr，你也可以直接用 glue::glue() 来访问它。↩︎\nR base 中与之等价的是使用 collapse 参数的 paste()。↩︎\n同样的原则也适用于 separate_wider_position() 和 separate_wider_regex()。↩︎\n查看这些条目，我们猜测 babynames 数据丢弃了空格或连字符，并在 15 个字母后截断。↩︎\n在这里，我使用特殊的 \\x 将二进制数据直接编码到字符串中。↩︎\n在没有字母表的语言（如中文）中排序则更为复杂。↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>字符串</span>"
    ]
  },
  {
    "objectID": "regexps.html",
    "href": "regexps.html",
    "title": "15  正则表达式",
    "section": "",
    "text": "15.1 引言\n在 Chapter 14 中，你学习了许多处理字符串的有用函数。本章将重点介绍使用正则表达式的函数，这是一种用于描述字符串内模式的简洁而强大的语言。术语“regular expression”有点拗口，所以大多数人将其缩写为“regex”1 或“regexp”。\n本章首先介绍正则表达式的基础知识和用于数据分析的最有用的 stringr 函数。然后，我们将扩展你对模式的知识，并涵盖七个重要的新主题（转义、锚点、字符类、简写类、量词、优先级和分组）。接下来，我们将讨论 stringr 函数可以处理的其他类型的模式以及允许你调整正则表达式操作的各种“标志”。最后，我们将概述在 tidyverse 和 R base 中可能使用正则表达式的其他地方。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#引言",
    "href": "regexps.html#引言",
    "title": "15  正则表达式",
    "section": "",
    "text": "15.1.1 先决条件\n在本章中，我们将使用 stringr 和 tidyr 中的正则表达式函数，它们都是 tidyverse 的核心成员，以及来自 babynames 包的数据。\n\nlibrary(tidyverse)\nlibrary(babynames)\n\n在本章中，我们将混合使用非常简单的内联示例以便你掌握基本概念，同时也会使用 babynames 数据以及来自 stringr 的三个字符向量：\n\n\nfruit 包含了 80 种水果的名称。\n\nwords 包含了 980 个常见的英语单词。\n\nsentences 包含了 720 个简短的句子。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-reg-basics",
    "href": "regexps.html#sec-reg-basics",
    "title": "15  正则表达式",
    "section": "\n15.2 模式基础",
    "text": "15.2 模式基础\n我们将使用 str_view() 来学习正则表达式模式是如何工作的。在上一章中，我们使用 str_view() 来更好地理解字符串与其打印表示形式的区别，现在我们将使用它的第二个参数——一个正则表达式。当提供这个参数时，str_view() 将只显示字符串向量中匹配的元素，用 &lt;&gt; 包围每个匹配项，并在可能的情况下用蓝色高亮显示匹配项。\n最简单的模式由字母和数字组成，它们精确匹配那些字符：\n\nstr_view(fruit, \"berry\")\n#&gt;  [6] │ bil&lt;berry&gt;\n#&gt;  [7] │ black&lt;berry&gt;\n#&gt; [10] │ blue&lt;berry&gt;\n#&gt; [11] │ boysen&lt;berry&gt;\n#&gt; [19] │ cloud&lt;berry&gt;\n#&gt; [21] │ cran&lt;berry&gt;\n#&gt; ... and 8 more\n\n字母和数字精确匹配，被称为字面量字符 (literal characters)。大多数标点符号，如 .、+、*、[、] 和 ?，具有特殊含义2，被称为元字符 (metacharacters)。例如，. 将匹配任何字符3，所以 \"a.\" 将匹配任何包含一个 “a” 后跟另一个字符的字符串：\n\nstr_view(c(\"a\", \"ab\", \"ae\", \"bd\", \"ea\", \"eab\"), \"a.\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ae&gt;\n#&gt; [6] │ e&lt;ab&gt;\n\n或者我们可以找到所有包含一个 “a”，后跟三个字母，再后跟一个 “e” 的水果：\n\nstr_view(fruit, \"a...e\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt;  [7] │ bl&lt;ackbe&gt;rry\n#&gt; [48] │ mand&lt;arine&gt;\n#&gt; [51] │ nect&lt;arine&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [64] │ pomegr&lt;anate&gt;\n#&gt; ... and 2 more\n\n量词 (Quantifiers) 控制一个模式可以匹配多少次：\n\n\n? 使一个模式成为可选的（即它匹配 0 次或 1 次）\n\n+ 让一个模式重复（即它至少匹配一次）\n\n* 让一个模式既是可选的又可以重复（即它匹配任意次数，包括 0 次）。\n\n\n# ab? 匹配一个 \"a\"，后面可选地跟着一个 \"b\"。\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ab&gt;b\n\n# ab+ 匹配一个 \"a\"，后面跟着至少一个 \"b\"。\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\n# ab* 匹配一个 \"a\"，后面跟着任意数量的 \"b\"。\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\n字符类 (Character classes) 由 [] 定义，让你匹配一组字符中的任意一个，例如 [abcd] 匹配 “a”、“b”、“c” 或 “d”。你也可以通过以 ^ 开头来反转匹配：[^abcd] 匹配除了 “a”、“b”、“c” 或 “d” 之外的任何东西。我们可以用这个思想来找到包含一个被元音包围的 “x” 的单词，或者一个被辅音包围的 “y” 的单词：\n\nstr_view(words, \"[aeiou]x[aeiou]\")\n#&gt; [284] │ &lt;exa&gt;ct\n#&gt; [285] │ &lt;exa&gt;mple\n#&gt; [288] │ &lt;exe&gt;rcise\n#&gt; [289] │ &lt;exi&gt;st\nstr_view(words, \"[^aeiou]y[^aeiou]\")\n#&gt; [836] │ &lt;sys&gt;tem\n#&gt; [901] │ &lt;typ&gt;e\n\n你可以使用交替 (alternation)，即 |，来在一个或多个备选模式之间进行选择。例如，下面的模式查找包含 “apple”、“melon” 或 “nut” 的水果，或者包含重复元音的水果。\n\nstr_view(fruit, \"apple|melon|nut\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [13] │ canary &lt;melon&gt;\n#&gt; [20] │ coco&lt;nut&gt;\n#&gt; [52] │ &lt;nut&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [72] │ rock &lt;melon&gt;\n#&gt; ... and 1 more\nstr_view(fruit, \"aa|ee|ii|oo|uu\")\n#&gt;  [9] │ bl&lt;oo&gt;d orange\n#&gt; [33] │ g&lt;oo&gt;seberry\n#&gt; [47] │ lych&lt;ee&gt;\n#&gt; [66] │ purple mangost&lt;ee&gt;n\n\n正则表达式非常紧凑，使用了大量的标点符号，所以初看起来可能会让人不知所措，难以阅读。别担心，多加练习你就会越来越好，简单的模式很快就会成为你的第二天性。让我们通过一些有用的 stringr 函数来开始这个过程吧。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-stringr-regex-funs",
    "href": "regexps.html#sec-stringr-regex-funs",
    "title": "15  正则表达式",
    "section": "\n15.3 关键函数",
    "text": "15.3 关键函数\n既然你已经掌握了正则表达式的基础知识，让我们将它们与一些 stringr 和 tidyr 函数一起使用。在接下来的部分，你将学习如何检测匹配的存在与否，如何计算匹配的数量，如何用固定的文本替换匹配项，以及如何使用模式提取文本。\n\n15.3.1 检测匹配\nstr_detect() 返回一个逻辑向量，如果模式匹配字符向量中的某个元素，则为 TRUE，否则为 FALSE：\n\nstr_detect(c(\"a\", \"b\", \"c\"), \"[aeiou]\")\n#&gt; [1]  TRUE FALSE FALSE\n\n由于 str_detect() 返回一个与初始向量长度相同的逻辑向量，它与 filter() 配合得很好。例如，这段代码找到了所有包含小写字母 “x” 的最受欢迎的名字：\n\nbabynames |&gt; \n  filter(str_detect(name, \"x\")) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 974 × 2\n#&gt;   name           n\n#&gt;   &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 Alexander 665492\n#&gt; 2 Alexis    399551\n#&gt; 3 Alex      278705\n#&gt; 4 Alexandra 232223\n#&gt; 5 Max       148787\n#&gt; 6 Alexa     123032\n#&gt; # ℹ 968 more rows\n\n我们也可以将 str_detect() 与 summarize() 一起使用，方法是将其与 sum() 或 mean() 配对：sum(str_detect(x, pattern)) 告诉你匹配的观测数量，而 mean(str_detect(x, pattern)) 告诉你匹配的比例。例如，下面的代码片段计算并可视化了包含 “x” 的婴儿名字4的比例，并按年份进行了分解。看起来它们最近的受欢迎程度急剧上升了！\n\nbabynames |&gt; \n  group_by(year) |&gt; \n  summarize(prop_x = mean(str_detect(name, \"x\"))) |&gt; \n  ggplot(aes(x = year, y = prop_x)) + \n  geom_line()\n\n\n\n\n\n\n\n有两个与 str_detect() 密切相关的函数：str_subset() 和 str_which()。str_subset() 返回一个字符向量，仅包含匹配的字符串。str_which() 返回一个整数向量，给出匹配字符串的位置。\n\n15.3.2 计数匹配\n比 str_detect() 复杂一步的是 str_count()：它不是返回 TRUE 或 FALSE，而是告诉你每个字符串中有多少个匹配项。\n\nx &lt;- c(\"apple\", \"banana\", \"pear\")\nstr_count(x, \"p\")\n#&gt; [1] 2 0 1\n\n请注意，每个匹配都从前一个匹配的末尾开始，即正则表达式的匹配从不重叠。例如，在 \"abababa\" 中，模式 \"aba\" 会匹配多少次？正则表达式会说两次，而不是三次：\n\nstr_count(\"abababa\", \"aba\")\n#&gt; [1] 2\nstr_view(\"abababa\", \"aba\")\n#&gt; [1] │ &lt;aba&gt;b&lt;aba&gt;\n\n很自然地，str_count() 会与 mutate() 一起使用。下面的例子使用 str_count() 和字符类来计算每个名字中元音和辅音的数量。\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 Aaban        10      2          3\n#&gt; 2 Aabha         5      2          3\n#&gt; 3 Aabid         2      2          3\n#&gt; 4 Aabir         1      2          3\n#&gt; 5 Aabriella     5      4          5\n#&gt; 6 Aada          1      2          2\n#&gt; # ℹ 97,304 more rows\n\n如果你仔细观察，你会发现我们的计算有些问题：“Aaban” 包含三个 “a”，但我们的摘要只报告了两个元音。这是因为正则表达式是区分大小写的。我们有三种方法可以解决这个问题：\n\n将大写元音添加到字符类中：str_count(name, \"[aeiouAEIOU]\")。\n告诉正则表达式忽略大小写：str_count(name, regex(\"[aeiou]\", ignore_case = TRUE))。我们将在 Section 15.5.1 中详细讨论。\n使用 str_to_lower() 将名字转换为小写：str_count(str_to_lower(name), \"[aeiou]\")。\n\n这种多样化的方法在处理字符串时非常典型——通常有多种方法可以达到你的目标，要么使你的模式更复杂，要么对你的字符串进行一些预处理。如果你在尝试一种方法时遇到困难，转换思路从不同的角度解决问题通常会很有帮助。\n在这种情况下，由于我们对名字应用了两个函数，我认为先转换它会更容易：\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    name = str_to_lower(name),\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 aaban        10      3          2\n#&gt; 2 aabha         5      3          2\n#&gt; 3 aabid         2      3          2\n#&gt; 4 aabir         1      3          2\n#&gt; 5 aabriella     5      5          4\n#&gt; 6 aada          1      3          1\n#&gt; # ℹ 97,304 more rows\n\n\n15.3.3 替换值\n除了检测和计数匹配，我们还可以用 str_replace() 和 str_replace_all() 来修改它们。str_replace() 替换第一个匹配项，而顾名思义，str_replace_all() 替换所有匹配项。\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_replace_all(x, \"[aeiou]\", \"-\")\n#&gt; [1] \"-ppl-\"  \"p--r\"   \"b-n-n-\"\n\nstr_remove() 和 str_remove_all() 是 str_replace(x, pattern, \"\") 的便捷快捷方式：\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_remove_all(x, \"[aeiou]\")\n#&gt; [1] \"ppl\" \"pr\"  \"bnn\"\n\n在进行数据清理时，这些函数很自然地与 mutate() 配对使用，你通常会反复应用它们来剥离不一致的格式层。\n\n15.3.4 提取变量\n我们要讨论的最后一个函数使用正则表达式将数据从一列提取到一个或多个新列中：separate_wider_regex()。它是你在 Section 14.4.2 中学到的 separate_wider_position() 和 separate_wider_delim() 函数的同类。这些函数位于 tidyr 中，因为它们操作的是（数据框的）列，而不是单个向量。\n让我们创建一个简单的数据集来展示它是如何工作的。这里我们有一些源自 babynames 的数据，其中我们以一种相当奇怪的格式记录了一群人的名字、性别和年龄5：\n\ndf &lt;- tribble(\n  ~str,\n  \"&lt;Sheryl&gt;-F_34\",\n  \"&lt;Kisha&gt;-F_45\", \n  \"&lt;Brandon&gt;-N_33\",\n  \"&lt;Sharon&gt;-F_38\", \n  \"&lt;Penny&gt;-F_58\",\n  \"&lt;Justin&gt;-M_41\", \n  \"&lt;Patricia&gt;-F_84\", \n)\n\n要使用 separate_wider_regex() 提取这些数据，我们只需要构建一个匹配每个部分的正则表达式序列。如果我们希望该部分的内容出现在输出中，我们就给它一个名字：\n\ndf |&gt; \n  separate_wider_regex(\n    str,\n    patterns = c(\n      \"&lt;\", \n      name = \"[A-Za-z]+\", \n      \"&gt;-\", \n      gender = \".\",\n      \"_\",\n      age = \"[0-9]+\"\n    )\n  )\n#&gt; # A tibble: 7 × 3\n#&gt;   name    gender age  \n#&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 Sheryl  F      34   \n#&gt; 2 Kisha   F      45   \n#&gt; 3 Brandon N      33   \n#&gt; 4 Sharon  F      38   \n#&gt; 5 Penny   F      58   \n#&gt; 6 Justin  M      41   \n#&gt; # ℹ 1 more row\n\n如果匹配失败，你可以使用 too_few = \"debug\" 来找出问题所在，就像 separate_wider_delim() 和 separate_wider_position() 一样。\n\n15.3.5 练习\n\n哪个婴儿名字的元音最多？哪个名字的元音比例最高？（提示：分母是什么？）\n将 \"a/b/c/d/e\" 中所有的正斜杠替换为反斜杠。如果你试图通过将所有反斜杠替换为正斜杠来撤销转换，会发生什么？（我们很快就会讨论这个问题。）\n使用 str_replace_all() 实现一个简单版本的 str_to_lower()。\n创建一个正则表达式，以匹配你所在国家通常书写的电话号码。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#模式细节",
    "href": "regexps.html#模式细节",
    "title": "15  正则表达式",
    "section": "\n15.4 模式细节",
    "text": "15.4 模式细节\n既然你已经了解了模式语言的基础知识，以及如何将它与一些 stringr 和 tidyr 函数一起使用，现在是时候深入了解更多细节了。首先，我们将从转义 (escaping) 开始，它允许你匹配那些原本会被特殊处理的元字符。接下来，你将学习锚点 (anchors)，它允许你匹配字符串的开头或结尾。然后，你将学习更多关于字符类 (character classes) 和它们的快捷方式，这使你能够匹配一个集合中的任何字符。接下来，你将学习量词 (quantifiers) 的最后细节，它控制一个模式可以匹配多少次。然后，我们必须涵盖重要（但复杂）的操作符优先级 (operator precedence) 和括号。最后，我们将以分组 (grouping) 模式组件的一些细节来结束。\n我们在这里使用的术语是每个组件的专业名称。它们并不总是最能说明其用途，但如果你以后想用谷歌搜索更多细节，了解正确的术语会非常有帮助。\n\n15.4.1 转义\n为了匹配一个字面意义上的 .，你需要一个转义 (escape)，它告诉正则表达式要字面匹配元字符6。像字符串一样，正则表达式也使用反斜杠进行转义。所以，要匹配一个 .，你需要正则表达式 \\.。不幸的是，这带来了一个问题。我们用字符串来表示正则表达式，而 \\ 在字符串中也用作转义符号。所以要创建正则表达式 \\.，我们需要字符串 \"\\\\.\"，如下例所示。\n\n# 要创建正则表达式 \\.，我们需要使用 \\\\.\ndot &lt;- \"\\\\.\"\n\n# 但表达式本身只包含一个 \\\nstr_view(dot)\n#&gt; [1] │ \\.\n\n# 这告诉 R 查找一个明确的 .\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n#&gt; [2] │ &lt;a.c&gt;\n\n在本书中，我们通常会不带引号地写正则表达式，比如 \\.。如果我们需要强调你实际会输入什么，我们会用引号把它括起来，并加上额外的转义，比如 \"\\\\.\"。\n如果 \\ 在正则表达式中用作转义字符，那么你如何匹配一个字面意义上的 \\ 呢？嗯，你需要对它进行转义，创建正则表达式 \\\\。要创建那个正则表达式，你需要使用一个字符串，而字符串也需要对 \\ 进行转义。这意味着要匹配一个字面意义上的 \\，你需要写 \"\\\\\\\\\" —— 你需要四个反斜杠来匹配一个！\n\nx &lt;- \"a\\\\b\"\nstr_view(x)\n#&gt; [1] │ a\\b\nstr_view(x, \"\\\\\\\\\")\n#&gt; [1] │ a&lt;\\&gt;b\n\n或者，你可能会发现使用你在 Section 14.2.2 中学到的原始字符串更容易。那样可以让你避免一层转义：\n\nstr_view(x, r\"{\\\\}\")\n#&gt; [1] │ a&lt;\\&gt;b\n\n如果你想匹配一个字面意义上的 .、$、|、*、+、?、{、}、(、)，除了使用反斜杠转义外，还有一种替代方法：你可以使用字符类：[.]、[$]、[|]……它们都匹配字面值。\n\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[.]c\")\n#&gt; [2] │ &lt;a.c&gt;\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \".[*]c\")\n#&gt; [3] │ &lt;a*c&gt;\n\n\n15.4.2 锚点\n默认情况下，正则表达式会匹配字符串的任何部分。如果你想在开头或结尾进行匹配，你需要使用锚点 (anchor) 来固定正则表达式，使用 ^ 匹配开头，或 $ 匹配结尾：\n\nstr_view(fruit, \"^a\")\n#&gt; [1] │ &lt;a&gt;pple\n#&gt; [2] │ &lt;a&gt;pricot\n#&gt; [3] │ &lt;a&gt;vocado\nstr_view(fruit, \"a$\")\n#&gt;  [4] │ banan&lt;a&gt;\n#&gt; [15] │ cherimoy&lt;a&gt;\n#&gt; [30] │ feijo&lt;a&gt;\n#&gt; [36] │ guav&lt;a&gt;\n#&gt; [56] │ papay&lt;a&gt;\n#&gt; [74] │ satsum&lt;a&gt;\n\n人们很容易认为 $ 应该匹配字符串的开头，因为我们就是这样写美元金额的，但这并不是正则表达式的意图。\n要强制一个正则表达式只匹配完整的字符串，用 ^ 和 $ 将它锚定：\n\nstr_view(fruit, \"apple\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [62] │ pine&lt;apple&gt;\nstr_view(fruit, \"^apple$\")\n#&gt; [1] │ &lt;apple&gt;\n\n你也可以用 \\b 来匹配单词边界（即单词的开头或结尾）。这在 RStudio 的查找和替换工具中特别有用。例如，要查找 sum() 的所有用法，你可以搜索 \\bsum\\b 来避免匹配 summarize、summary、rowsum 等等：\n\nx &lt;- c(\"summary(x)\", \"summarize(df)\", \"rowsum(x)\", \"sum(x)\")\nstr_view(x, \"sum\")\n#&gt; [1] │ &lt;sum&gt;mary(x)\n#&gt; [2] │ &lt;sum&gt;marize(df)\n#&gt; [3] │ row&lt;sum&gt;(x)\n#&gt; [4] │ &lt;sum&gt;(x)\nstr_view(x, \"\\\\bsum\\\\b\")\n#&gt; [4] │ &lt;sum&gt;(x)\n\n当单独使用时，锚点会产生一个零宽度的匹配：\n\nstr_view(\"abc\", c(\"$\", \"^\", \"\\\\b\"))\n#&gt; [1] │ abc&lt;&gt;\n#&gt; [2] │ &lt;&gt;abc\n#&gt; [3] │ &lt;&gt;abc&lt;&gt;\n\n这有助于你理解当你替换一个独立的锚点时会发生什么：\n\nstr_replace_all(\"abc\", c(\"$\", \"^\", \"\\\\b\"), \"--\")\n#&gt; [1] \"abc--\"   \"--abc\"   \"--abc--\"\n\n\n15.4.3 字符类\n字符类 (character class)，或称字符集 (set)，允许你匹配集合中的任何一个字符。正如我们上面讨论的，你可以用 [] 来构建自己的集合，其中 [abc] 匹配 “a”、“b” 或 “c”，而 [^abc] 匹配除了 “a”、“b” 或 “c” 之外的任何字符。除了 ^，[] 内部还有两个其他具有特殊含义的字符：\n\n\n- 定义一个范围，例如 [a-z] 匹配任何小写字母，[0-9] 匹配任何数字。\n\n\\ 对特殊字符进行转义，所以 [\\^\\-\\]] 匹配 ^、- 或 ]。\n\n这里有几个例子：\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"[abc]+\")\n#&gt; [1] │ &lt;abc&gt;d ABCD 12345 -!@#%.\nstr_view(x, \"[a-z]+\")\n#&gt; [1] │ &lt;abcd&gt; ABCD 12345 -!@#%.\nstr_view(x, \"[^a-z0-9]+\")\n#&gt; [1] │ abcd&lt; ABCD &gt;12345&lt; -!@#%.&gt;\n\n# 你需要转义才能匹配在 [] 中有特殊含义的字符\nstr_view(\"a-b-c\", \"[a-c]\")\n#&gt; [1] │ &lt;a&gt;-&lt;b&gt;-&lt;c&gt;\nstr_view(\"a-b-c\", \"[a\\\\-c]\")\n#&gt; [1] │ &lt;a&gt;&lt;-&gt;b&lt;-&gt;&lt;c&gt;\n\n一些字符类非常常用，以至于它们有自己的快捷方式。你已经见过了 .，它匹配除了换行符之外的任何字符。还有三对特别有用的快捷方式7：\n\n\n\\d 匹配任何数字； \\D 匹配任何非数字的字符。\n\n\\s 匹配任何空白字符（例如，空格、制表符、换行符）； \\S 匹配任何非空白字符的字符。\n\n\\w 匹配任何“单词”字符，即字母和数字； \\W 匹配任何“非单词”字符。\n\n下面的代码用一系列字母、数字和标点符号演示了这六个快捷方式。\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"\\\\d+\")\n#&gt; [1] │ abcd ABCD &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\D+\")\n#&gt; [1] │ &lt;abcd ABCD &gt;12345&lt; -!@#%.&gt;\nstr_view(x, \"\\\\s+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; &gt;-!@#%.\nstr_view(x, \"\\\\S+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; &lt;-!@#%.&gt;\nstr_view(x, \"\\\\w+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\W+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; -!@#%.&gt;\n\n\n15.4.4 量词\n量词 (Quantifiers) 控制一个模式匹配的次数。在 Section 15.2 中，你学习了 ?（0 或 1 次匹配）、+（1 次或多次匹配）和 *（0 次或多次匹配）。例如，colou?r 会匹配美式或英式拼写，\\d+ 会匹配一个或多个数字，\\s? 会可选地匹配一个空白字符。你也可以用 {} 来精确指定匹配的次数：\n\n\n{n} 精确匹配 n 次。\n\n{n,} 至少匹配 n 次。\n\n{n,m} 匹配 n 到 m 次之间。\n\n15.4.5 操作符优先级和括号\nab+ 匹配什么？是匹配一个 “a” 后面跟着一个或多个 “b”，还是匹配 “ab” 重复任意次数？^a|b$ 匹配什么？是匹配完整的字符串 a 或完整的字符串 b，还是匹配以 a 开头的字符串或以 b 结尾的字符串？\n这些问题的答案由操作符优先级决定，类似于你在学校可能学过的 PEMDAS 或 BEDMAS 规则。你知道 a + b * c 等同于 a + (b * c) 而不是 (a + b) * c，因为 * 的优先级高于 +：你先计算 * 再计算 +。\n同样，正则表达式也有自己的优先级规则：量词的优先级高，而交替的优先级低，这意味着 ab+ 等同于 a(b+)，^a|b$ 等同于 (^a)|(b$)。就像代数一样，你可以使用括号来覆盖常规顺序。但与代数不同的是，你不太可能记住正则表达式的优先级规则，所以请随意大量使用括号。\n\n15.4.6 分组和捕获\n除了覆盖操作符优先级，括号还有另一个重要作用：它们创建捕获组 (capturing groups)，允许你使用匹配的子组件。\n使用捕获组的第一种方法是在匹配内部通过反向引用 (back reference) 来引用它：\\1 引用第一个括号中包含的匹配，\\2 引用第二个括号中的匹配，依此类推。例如，下面的模式找到所有具有重复字母对的水果：\n\nstr_view(fruit, \"(..)\\\\1\")\n#&gt;  [4] │ b&lt;anan&gt;a\n#&gt; [20] │ &lt;coco&gt;nut\n#&gt; [22] │ &lt;cucu&gt;mber\n#&gt; [41] │ &lt;juju&gt;be\n#&gt; [56] │ &lt;papa&gt;ya\n#&gt; [73] │ s&lt;alal&gt; berry\n\n而这个模式找到所有以相同字母对开头和结尾的单词：\n\nstr_view(words, \"^(..).*\\\\1$\")\n#&gt; [152] │ &lt;church&gt;\n#&gt; [217] │ &lt;decide&gt;\n#&gt; [617] │ &lt;photograph&gt;\n#&gt; [699] │ &lt;require&gt;\n#&gt; [739] │ &lt;sense&gt;\n\n你也可以在 str_replace() 中使用反向引用。例如，这段代码交换了 sentences 中第二个和第三个单词的顺序：\n\nsentences |&gt; \n  str_replace(\"(\\\\w+) (\\\\w+) (\\\\w+)\", \"\\\\1 \\\\3 \\\\2\") |&gt; \n  str_view()\n#&gt; [1] │ The canoe birch slid on the smooth planks.\n#&gt; [2] │ Glue sheet the to the dark blue background.\n#&gt; [3] │ It's to easy tell the depth of a well.\n#&gt; [4] │ These a days chicken leg is a rare dish.\n#&gt; [5] │ Rice often is served in round bowls.\n#&gt; [6] │ The of juice lemons makes fine punch.\n#&gt; ... and 714 more\n\n如果你想提取每个组的匹配项，你可以使用 str_match()。但是 str_match() 返回一个矩阵，所以处理起来不是特别容易8：\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  head()\n#&gt;      [,1]                [,2]     [,3]    \n#&gt; [1,] \"the smooth planks\" \"smooth\" \"planks\"\n#&gt; [2,] \"the sheet to\"      \"sheet\"  \"to\"    \n#&gt; [3,] \"the depth of\"      \"depth\"  \"of\"    \n#&gt; [4,] NA                  NA       NA      \n#&gt; [5,] NA                  NA       NA      \n#&gt; [6,] NA                  NA       NA\n\n你可以将它转换为一个 tibble 并命名列：\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  as_tibble(.name_repair = \"minimal\") |&gt; \n  set_names(\"match\", \"word1\", \"word2\")\n#&gt; # A tibble: 720 × 3\n#&gt;   match             word1  word2 \n#&gt;   &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 the smooth planks smooth planks\n#&gt; 2 the sheet to      sheet  to    \n#&gt; 3 the depth of      depth  of    \n#&gt; 4 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 5 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 6 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; # ℹ 714 more rows\n\n但这样一来，你基本上是自己重新创建了 separate_wider_regex() 的一个版本。实际上，在幕后，separate_wider_regex() 将你的模式向量转换为一个使用分组来捕获命名组件的单一正则表达式。\n偶尔，你会想使用括号而不创建匹配组。你可以用 (?:) 创建一个非捕获组。\n\nx &lt;- c(\"a gray cat\", \"a grey dog\")\nstr_match(x, \"gr(e|a)y\")\n#&gt;      [,1]   [,2]\n#&gt; [1,] \"gray\" \"a\" \n#&gt; [2,] \"grey\" \"e\"\nstr_match(x, \"gr(?:e|a)y\")\n#&gt;      [,1]  \n#&gt; [1,] \"gray\"\n#&gt; [2,] \"grey\"\n\n\n15.4.7 练习\n\n你将如何匹配字面字符串 \"'\\\"？\"$^$\" 呢？\n解释为什么这些模式中的每一个都不匹配 \\：\"\\\"、\"\\\\\"、\"\\\\\\\"。\n\n给定 stringr::words 中的常用词语料库，创建正则表达式以找到所有满足以下条件的单词：\n\n以 “y” 开头。\n不以 “y” 开头。\n以 “x” 结尾。\n长度恰好为三个字母。（不要用 str_length() 作弊！）\n有七个或更多字母。\n包含一个元音-辅音对。\n连续包含至少两个元音-辅音对。\n仅由重复的元音-辅音对组成。\n\n\n为以下每个单词创建 11 个正则表达式，以匹配它们的英式或美式拼写：airplane/aeroplane, aluminum/aluminium, analog/analogue, ass/arse, center/centre, defense/defence, donut/doughnut, gray/grey, modeling/modelling, skeptic/sceptic, summarize/summarise。尝试制作可能的最短的正则表达式！\n交换 words 中的首字母和尾字母。这些字符串中有哪些仍然是 words 中的单词？\n\n用文字描述这些正则表达式匹配什么：（仔细阅读以判断每个条目是正则表达式还是定义正则表达式的字符串。）\n\n^.*$\n\"\\\\{.+\\\\}\"\n\\d{4}-\\d{2}-\\d{2}\n\"\\\\\\\\{4}\"\n\\..\\..\\..\n(.)\\1\\1\n\"(..)\\\\1\"\n\n\n解决 https://regexcrossword.com/challenges/beginner 上的初学者正则表达式填字游戏。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#模式控制",
    "href": "regexps.html#模式控制",
    "title": "15  正则表达式",
    "section": "\n15.5 模式控制",
    "text": "15.5 模式控制\n通过使用模式对象而不是仅仅一个字符串，可以对匹配的细节进行额外的控制。这允许你控制所谓的正则表达式标志，并匹配各种类型的固定字符串，如下所述。\n\n15.5.1 正则表达式标志\n有许多设置可以用来控制正则表达式的细节。这些设置在其他编程语言中通常被称为标志 (flags)。在 stringr 中，你可以通过将模式包装在对 regex() 的调用中来使用这些设置。最有用的标志可能就是 ignore_case = TRUE，因为它允许字符匹配其大写或小写形式：\n\nbananas &lt;- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n#&gt; [1] │ &lt;banana&gt;\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n#&gt; [1] │ &lt;banana&gt;\n#&gt; [2] │ &lt;Banana&gt;\n#&gt; [3] │ &lt;BANANA&gt;\n\n如果你正在处理大量多行字符串（即包含 \\n 的字符串），dotall 和 multiline 可能也很有用：\n\n\ndotall = TRUE 让 . 匹配所有东西，包括 \\n：\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \".Line\")\nstr_view(x, regex(\".Line\", dotall = TRUE))\n#&gt; [1] │ Line 1&lt;\n#&gt;     │ Line&gt; 2&lt;\n#&gt;     │ Line&gt; 3\n\n\n\nmultiline = TRUE 使 ^ 和 $ 匹配每行的开始和结束，而不是整个字符串的开始和结束：\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \"^Line\")\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ Line 2\n#&gt;     │ Line 3\nstr_view(x, regex(\"^Line\", multiline = TRUE))\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ &lt;Line&gt; 2\n#&gt;     │ &lt;Line&gt; 3\n\n\n\n最后，如果你正在编写一个复杂的正则表达式，并且担心将来可能无法理解它，你可能会尝试 comments = TRUE。它会调整模式语言，以忽略空格和换行符，以及 # 之后的所有内容。这允许你使用注释和空白来使复杂的正则表达式更易于理解9，如下例所示：\n\nphone &lt;- regex(\n  r\"(\n    \\(?      # 可选的左括号\n    (\\d{3})  # 区号\n    [)\\-]?   # 可选的右括号或破折号\n    \\ ?      # 可选的空格\n    (\\d{3})  # 另外三个数字\n    [\\ -]?   # 可选的空格或破折号\n    (\\d{4})  # 另外四个数字\n  )\", \n  comments = TRUE\n)\n\nstr_extract(c(\"514-791-8141\", \"(123) 456 7890\", \"123456\"), phone)\n#&gt; [1] \"514-791-8141\"   \"(123) 456 7890\" NA\n\n如果你使用注释，并且想要匹配空格、换行符或 #，你需要用 \\ 来转义它。\n\n15.5.2 固定匹配\n你可以通过使用 fixed() 来选择不使用正则表达式规则：\n\nstr_view(c(\"\", \"a\", \".\"), fixed(\".\"))\n#&gt; [3] │ &lt;.&gt;\n\nfixed() 还让你能够忽略大小写：\n\nstr_view(\"x X\", \"X\")\n#&gt; [1] │ x &lt;X&gt;\nstr_view(\"x X\", fixed(\"X\", ignore_case = TRUE))\n#&gt; [1] │ &lt;x&gt; &lt;X&gt;\n\n如果你正在处理非英语文本，你可能更想要 coll() 而不是 fixed()，因为它实现了你指定的 locale 所使用的完整大写规则。有关区域设置的更多详细信息，请参见 Section 14.6。\n\nstr_view(\"i İ ı I\", fixed(\"İ\", ignore_case = TRUE))\n#&gt; [1] │ i &lt;İ&gt; ı I\nstr_view(\"i İ ı I\", coll(\"İ\", ignore_case = TRUE, locale = \"tr\"))\n#&gt; [1] │ &lt;i&gt; &lt;İ&gt; ı I",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#实践",
    "href": "regexps.html#实践",
    "title": "15  正则表达式",
    "section": "\n15.6 实践",
    "text": "15.6 实践\n为了将这些想法付诸实践，我们接下来将解决一些半真实的问题。我们将讨论三种通用技术：\n\n通过创建简单的正向和反向控制来检查你的工作\n将正则表达式与布尔代数组合\n使用字符串操作创建复杂的模式\n\n\n15.6.1 检查你的工作\n首先，让我们找到所有以 “The” 开头的句子。仅仅使用 ^ 锚点是不够的：\n\nstr_view(sentences, \"^The\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [4] │ &lt;The&gt;se days a chicken leg is a rare dish.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; ... and 271 more\n\n因为那个模式也匹配了以 They 或 These 等单词开头的句子。我们需要确保 “e” 是单词中的最后一个字母，我们可以通过添加一个单词边界来实现：\n\nstr_view(sentences, \"^The\\\\b\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; [13] │ &lt;The&gt; source of the huge river is the clear spring.\n#&gt; ... and 250 more\n\n那么，找到所有以代词开头的句子呢？\n\nstr_view(sentences, \"^She|He|It|They\\\\b\")\n#&gt;  [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt; [15] │ &lt;He&gt;lp the woman get back to her feet.\n#&gt; [27] │ &lt;He&gt;r purse was full of useless trash.\n#&gt; [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt; [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt; [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; ... and 57 more\n\n快速检查结果显示我们得到了一些错误的匹配。这是因为我们忘记了使用括号：\n\nstr_view(sentences, \"^(She|He|It|They)\\\\b\")\n#&gt;   [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt;  [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt;  [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt;  [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; [116] │ &lt;He&gt; ordered peach pie with ice cream.\n#&gt; [127] │ &lt;It&gt; caught its hind paw in a rusty trap.\n#&gt; ... and 51 more\n\n你可能会想，如果这样的错误没有出现在前几个匹配中，你该如何发现它。一个好的技术是创建一些正向和反向的匹配，并用它们来测试你的模式是否按预期工作：\n\npos &lt;- c(\"He is a boy\", \"She had a good time\")\nneg &lt;- c(\"Shells come from the sea\", \"Hadley said 'It's a great day'\")\n\npattern &lt;- \"^(She|He|It|They)\\\\b\"\nstr_detect(pos, pattern)\n#&gt; [1] TRUE TRUE\nstr_detect(neg, pattern)\n#&gt; [1] FALSE FALSE\n\n通常，想出好的正向例子比想出反向例子要容易得多，因为在你对正则表达式足够熟练以预测你的弱点在哪里之前，需要一段时间。尽管如此，它们仍然很有用：在你解决问题的过程中，你可以慢慢积累你的错误集合，确保你永远不会犯同样的错误两次。\n\n15.6.2 布尔运算\n假设我们想找到只包含辅音的单词。一种技术是创建一个包含除元音外的所有字母的字符类（[^aeiou]），然后让它匹配任意数量的字母（[^aeiou]+），最后通过锚定到开头和结尾来强制它匹配整个字符串（^[^aeiou]+$）：\n\nstr_view(words, \"^[^aeiou]+$\")\n#&gt; [123] │ &lt;by&gt;\n#&gt; [249] │ &lt;dry&gt;\n#&gt; [328] │ &lt;fly&gt;\n#&gt; [538] │ &lt;mrs&gt;\n#&gt; [895] │ &lt;try&gt;\n#&gt; [952] │ &lt;why&gt;\n\n但是你可以通过反向思考来使这个问题变得简单一些。与其寻找只包含辅音的单词，我们可以寻找不包含任何元音的单词：\n\nstr_view(words[!str_detect(words, \"[aeiou]\")])\n#&gt; [1] │ by\n#&gt; [2] │ dry\n#&gt; [3] │ fly\n#&gt; [4] │ mrs\n#&gt; [5] │ try\n#&gt; [6] │ why\n\n每当你处理逻辑组合时，这都是一种有用的技术，特别是那些涉及“与”或“非”的组合。例如，假设你想找到所有包含 “a” 和 “b” 的单词。正则表达式中没有内置的“与”操作符，所以我们必须通过寻找所有包含一个 “a” 后面跟着一个 “b” 的单词，或者一个 “b” 后面跟着一个 “a” 的单词来解决它：\n\nstr_view(words, \"a.*b|b.*a\")\n#&gt;  [2] │ &lt;ab&gt;le\n#&gt;  [3] │ &lt;ab&gt;out\n#&gt;  [4] │ &lt;ab&gt;solute\n#&gt; [62] │ &lt;availab&gt;le\n#&gt; [66] │ &lt;ba&gt;by\n#&gt; [67] │ &lt;ba&gt;ck\n#&gt; ... and 24 more\n\n将两次 str_detect() 调用的结果组合起来更简单：\n\nwords[str_detect(words, \"a\") & str_detect(words, \"b\")]\n#&gt;  [1] \"able\"      \"about\"     \"absolute\"  \"available\" \"baby\"      \"back\"     \n#&gt;  [7] \"bad\"       \"bag\"       \"balance\"   \"ball\"      \"bank\"      \"bar\"      \n#&gt; [13] \"base\"      \"basis\"     \"bear\"      \"beat\"      \"beauty\"    \"because\"  \n#&gt; [19] \"black\"     \"board\"     \"boat\"      \"break\"     \"brilliant\" \"britain\"  \n#&gt; [25] \"debate\"    \"husband\"   \"labour\"    \"maybe\"     \"probable\"  \"table\"\n\n如果我们想看看是否有包含所有元音的单词呢？如果我们用模式来做，我们需要生成 5!（120）种不同的模式：\n\nwords[str_detect(words, \"a.*e.*i.*o.*u\")]\n# ...\nwords[str_detect(words, \"u.*o.*i.*e.*a\")]\n\n将五次 str_detect() 调用的结果组合起来要简单得多：\n\nwords[\n  str_detect(words, \"a\") &\n  str_detect(words, \"e\") &\n  str_detect(words, \"i\") &\n  str_detect(words, \"o\") &\n  str_detect(words, \"u\")\n]\n#&gt; character(0)\n\n总的来说，如果你在尝试创建一个单一的正则表达式来解决问题时遇到困难，退一步思考一下，你是否可以把问题分解成更小的部分，在解决下一个挑战之前先解决每一个挑战。\n\n15.6.3 用代码创建模式\n如果我们想找到所有提到某种颜色的 sentences 呢？基本思想很简单：我们只需将交替与单词边界结合起来。\n\nstr_view(sentences, \"\\\\b(red|green|blue)\\\\b\")\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [148] │ The spot on the blotter was made by &lt;green&gt; ink.\n#&gt; [160] │ The sofa cushion is &lt;red&gt; and of light weight.\n#&gt; [174] │ The sky that morning was clear and bright &lt;blue&gt;.\n#&gt; ... and 20 more\n\n但随着颜色数量的增加，手动构建这个模式会很快变得乏味。如果我们能把颜色存储在一个向量里，那不是很好吗？\n\nrgb &lt;- c(\"red\", \"green\", \"blue\")\n\n嗯，我们可以！我们只需要用 str_c() 和 str_flatten() 从向量创建模式：\n\nstr_c(\"\\\\b(\", str_flatten(rgb, \"|\"), \")\\\\b\")\n#&gt; [1] \"\\\\b(red|green|blue)\\\\b\"\n\n如果我们有一个好的颜色列表，我们可以使这个模式更全面。我们可以从 R 中可用于绘图的内置颜色列表开始：\n\nstr_view(colors())\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ antiquewhite1\n#&gt; [5] │ antiquewhite2\n#&gt; [6] │ antiquewhite3\n#&gt; ... and 651 more\n\n但让我们首先消除带编号的变体：\n\ncols &lt;- colors()\ncols &lt;- cols[!str_detect(cols, \"\\\\d\")]\nstr_view(cols)\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ aquamarine\n#&gt; [5] │ azure\n#&gt; [6] │ beige\n#&gt; ... and 137 more\n\n然后我们可以把它变成一个巨大的模式。我们在这里不显示这个模式，因为它太大了，但你可以看到它的工作效果：\n\npattern &lt;- str_c(\"\\\\b(\", str_flatten(cols, \"|\"), \")\\\\b\")\nstr_view(sentences, pattern)\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [12] │ A rod is used to catch &lt;pink&gt; &lt;salmon&gt;.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [66] │ Cars and busses stalled in &lt;snow&gt; drifts.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [112] │ Leaves turn &lt;brown&gt; and &lt;yellow&gt; in the fall.\n#&gt; ... and 57 more\n\n在这个例子中，cols 只包含数字和字母，所以你不需要担心元字符。但总的来说，每当你从现有字符串创建模式时，明智的做法是先用 str_escape() 处理它们，以确保它们是字面匹配。\n\n15.6.4 练习\n\n\n对于以下每个挑战，尝试使用单一的正则表达式和多个 str_detect() 调用的组合来解决它。\n\n找到所有以 x 开头或结尾的 words。\n找到所有以元音开头并以辅音结尾的 words。\n是否有任何 words 至少包含每种不同元音中的一个？\n\n\n构建模式来寻找支持和反对“i before e except after c”（i 在 e 前，c 后除外）这一规则的证据。\ncolors() 包含一些修饰词，如 “lightgray” 和 “darkblue”。你如何能自动识别这些修饰词？（想想你可能如何检测然后移除被修饰的颜色）。\n创建一个正则表达式，以查找任何 R base 数据集。你可以通过 data() 函数的一种特殊用法获取这些数据集的列表：data(package = \"datasets\")$results[, \"Item\"]。注意，一些旧的数据集是单个向量；它们在括号中包含了分组“数据框”的名称，所以你需要把那些去掉。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#其他地方的正则表达式",
    "href": "regexps.html#其他地方的正则表达式",
    "title": "15  正则表达式",
    "section": "\n15.7 其他地方的正则表达式",
    "text": "15.7 其他地方的正则表达式\n就像在 stringr 和 tidyr 函数中一样，R 中还有许多其他地方可以使用正则表达式。以下各节描述了在更广泛的 tidyverse 和 R base 中的一些其他有用函数。\n\n15.7.1 tidyverse\n还有三个特别有用的地方，你可能想使用正则表达式：\n\nmatches(pattern) 会选择所有名称与所提供模式匹配的变量。它是一个“tidyselect”函数，你可以在任何选择变量的 tidyverse 函数中使用（例如，select()、rename_with() 和 across()）。\npivot_longer() 的 names_pattern 参数接受一个正则表达式向量，就像 separate_wider_regex() 一样。当从具有复杂结构的变量名中提取数据时，它很有用。\nseparate_longer_delim() 和 separate_wider_delim() 中的 delim 参数通常匹配一个固定的字符串，但你可以使用 regex() 使其匹配一个模式。例如，如果你想匹配一个逗号，后面可选地跟着一个空格，即 regex(\", ?\")，这就很有用。\n\n15.7.2 Base R\napropos(pattern) 在全局环境中搜索所有与给定模式匹配的可用对象。如果你不太记得一个函数的名字，这很有用：\n\napropos(\"replace\")\n#&gt; [1] \"%+replace%\"       \"replace\"          \"replace_na\"      \n#&gt; [4] \"setReplaceMethod\" \"str_replace\"      \"str_replace_all\" \n#&gt; [7] \"str_replace_na\"   \"theme_replace\"\n\nlist.files(path, pattern) 列出 path 中所有与正则表达式 pattern 匹配的文件。例如，你可以用以下方式找到当前目录中所有的 R Markdown 文件：\n\nhead(list.files(pattern = \"\\\\.Rmd$\"))\n#&gt; character(0)\n\n值得注意的是，base R 使用的模式语言与 stringr 使用的略有不同。这是因为 stringr 是建立在 stringi 包之上的，而 stringi 又是建立在 ICU 引擎之上的，而 base R 函数则使用 TRE 引擎或 PCRE 引擎，这取决于你是否设置了 perl = TRUE。幸运的是，正则表达式的基础知识已经非常成熟，当使用你在本书中学到的模式时，你几乎不会遇到什么变化。只有当你开始依赖高级功能，如复杂的 Unicode 字符范围或使用 (?…) 语法的特殊功能时，你才需要注意这种差异。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#总结",
    "href": "regexps.html#总结",
    "title": "15  正则表达式",
    "section": "\n15.8 总结",
    "text": "15.8 总结\n由于每个标点符号都可能被赋予了多重含义，正则表达式是现存最紧凑的语言之一。它们起初确实令人困惑，但随着你训练你的眼睛去阅读它们，你的大脑去理解它们，你就解锁了一项强大的技能，可以在 R 和许多其他地方使用。\n在本章中，你通过学习最有用的 stringr 函数和正则表达式语言最重要的组成部分，开始了成为正则表达式大师的旅程。而且还有大量的资源可以让你学到更多。\n一个好的起点是 vignette(\"regular-expressions\", package = \"stringr\")：它记录了 stringr 支持的全部语法。另一个有用的参考是 https://www.regular-expressions.info/。它不是 R 特有的，但你可以用它来学习正则表达式最高级的功能以及它们在幕后是如何工作的。\n同样值得了解的是，stringr 是在 Marek Gagolewski 的 stringi 包之上实现的。如果你在 stringr 中找不到能满足你需要的功能，不要害怕去 stringi 中寻找。你会发现 stringi 很容易上手，因为它遵循了许多与 stringr 相同的约定。\n在下一章，我们将讨论一个与字符串密切相关的数据结构：因子。因子在 R 中用于表示分类数据，即具有固定的、已知的可能值集合的数据，这些值由一个字符串向量来标识。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "regexps.html#footnotes",
    "href": "regexps.html#footnotes",
    "title": "15  正则表达式",
    "section": "",
    "text": "你可以读作硬 g（reg-x）或软 g（rej-x）。↩︎\n你将在 Section 15.4.1 中学习如何转义这些特殊含义。↩︎\n嗯，除了 \\n 之外的任何字符。↩︎\n这给了我们包含 “x” 的名字的比例；如果你想要的是名字中含 x 的婴儿的比例，你需要进行加权平均。↩︎\n我们希望可以向你保证，在现实生活中你永远不会看到这么奇怪的东西，但不幸的是，在你的职业生涯中，你很可能会看到更奇怪的！↩︎\n元字符的完整集合是 .^$\\|*+?{}[]()↩︎\n记住，要创建一个包含 \\d 或 \\s 的正则表达式，你需要为字符串转义 \\，所以你会输入 \"\\\\d\" 或 \"\\\\s\"。↩︎\n主要是因为我们在本书中从未讨论过矩阵！↩︎\ncomments = TRUE 与原始字符串结合使用尤其有效，就像我们在这里使用的那样。↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>正则表达式</span>"
    ]
  },
  {
    "objectID": "factors.html",
    "href": "factors.html",
    "title": "16  因子",
    "section": "",
    "text": "16.1 引言\n因子 (factor) 用于处理分类变量，即那些具有固定且已知的一组可能值的变量。当你希望以非字母顺序显示字符向量时，因子也很有用。\n我们将首先阐述为什么数据分析需要因子1，以及你如何用 factor() 创建它们。接着，我们将向你介绍 gss_cat 数据集，其中包含大量分类变量供你试验。然后，你将使用该数据集练习修改因子的顺序和值，最后我们以讨论有序因子作为结束。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#引言",
    "href": "factors.html#引言",
    "title": "16  因子",
    "section": "",
    "text": "16.1.1 先决条件\nR base 提供了一些创建和操作因子的基本工具。我们将用 forcats 包来补充这些工具，该包是核心 tidyverse 的一部分。它提供了一系列处理分类变量 (categorical variables) 的工具（并且它也是 factors 的一个字母重组词！），包含了大量用于处理因子的辅助函数。\n\nlibrary(tidyverse)",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#因子基础",
    "href": "factors.html#因子基础",
    "title": "16  因子",
    "section": "\n16.2 因子基础",
    "text": "16.2 因子基础\n假设你有一个记录月份的变量：\n\nx1 &lt;- c(\"Dec\", \"Apr\", \"Jan\", \"Mar\")\n\n使用字符串来记录这个变量有两个问题：\n\n\n只有十二个可能的月份，但没有任何东西能防止你打字错误：\n\nx2 &lt;- c(\"Dec\", \"Apr\", \"Jam\", \"Mar\")\n\n\n\n它的排序方式没有用处：\n\nsort(x1)\n#&gt; [1] \"Apr\" \"Dec\" \"Jan\" \"Mar\"\n\n\n\n你可以用因子来解决这两个问题。要创建一个因子，你必须首先创建一个有效水平 (levels) 的列表：\n\nmonth_levels &lt;- c(\n  \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n)\n\n现在你可以创建一个因子：\n\ny1 &lt;- factor(x1, levels = month_levels)\ny1\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nsort(y1)\n#&gt; [1] Jan Mar Apr Dec\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n任何不在水平中的值都会被静默地转换为 NA：\n\ny2 &lt;- factor(x2, levels = month_levels)\ny2\n#&gt; [1] Dec  Apr  &lt;NA&gt; Mar \n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n这看起来有风险，所以你可能想改用 forcats::fct()：\n\ny2 &lt;- fct(x2, levels = month_levels)\n#&gt; Error in `fct()`:\n#&gt; ! All values of `x` must appear in `levels` or `na`\n#&gt; ℹ Missing level: \"Jam\"\n\n如果你省略了水平，它们将从数据中按字母顺序提取：\n\nfactor(x1)\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Apr Dec Jan Mar\n\n按字母顺序排序有点风险，因为并非每台计算机都会以相同的方式对字符串进行排序。所以 forcats::fct() 会按首次出现的顺序排序：\n\nfct(x1)\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Dec Apr Jan Mar\n\n如果你需要直接访问有效的水平集，你可以使用 levels()：\n\nlevels(y2)\n#&gt;  [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\n你也可以在使用 readr 读取数据时，通过 col_factor() 创建一个因子：\n\ncsv &lt;- \"\nmonth,value\nJan,12\nFeb,56\nMar,12\"\n\ndf &lt;- read_csv(csv, col_types = cols(month = col_factor(month_levels)))\ndf$month\n#&gt; [1] Jan Feb Mar\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#综合社会调查",
    "href": "factors.html#综合社会调查",
    "title": "16  因子",
    "section": "\n16.3 综合社会调查",
    "text": "16.3 综合社会调查\n在本章的其余部分，我们将使用 forcats::gss_cat。这是来自综合社会调查 (General Social Survey) 的数据样本，该调查是由芝加哥大学的独立研究机构 NORC 进行的一项长期美国调查。该调查有数千个问题，在 gss_cat 中，Hadley 选择了一小部分，用以说明你在处理因子时会遇到的一些常见挑战。\n\ngss_cat\n#&gt; # A tibble: 21,483 × 9\n#&gt;    year marital         age race  rincome        partyid           \n#&gt;   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;             \n#&gt; 1  2000 Never married    26 White $8000 to 9999  Ind,near rep      \n#&gt; 2  2000 Divorced         48 White $8000 to 9999  Not str republican\n#&gt; 3  2000 Widowed          67 White Not applicable Independent       \n#&gt; 4  2000 Never married    39 White Not applicable Ind,near rep      \n#&gt; 5  2000 Divorced         25 White Not applicable Not str democrat  \n#&gt; 6  2000 Married          25 White $20000 - 24999 Strong democrat   \n#&gt; # ℹ 21,477 more rows\n#&gt; # ℹ 3 more variables: relig &lt;fct&gt;, denom &lt;fct&gt;, tvhours &lt;int&gt;\n\n（请记住，由于这个数据集是由一个包提供的，你可以使用 ?gss_cat 获取更多关于变量的信息。）\n当因子存储在 tibble 中时，你无法轻易看到它们的水平。一种查看它们的方法是使用 count()：\n\ngss_cat |&gt;\n  count(race)\n#&gt; # A tibble: 3 × 2\n#&gt;   race      n\n#&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1 Other  1959\n#&gt; 2 Black  3129\n#&gt; 3 White 16395\n\n在处理因子时，两个最常见的操作是改变水平的顺序和改变水平的值。这些操作将在下面的章节中描述。\n\n16.3.1 练习\n\n探索 rincome（报告的收入）的分布。是什么使得默认的条形图难以理解？你如何改进这个图？\n在这次调查中，最常见的 relig（宗教）是什么？最常见的 partyid（政党认同）是什么？\ndenom（教派）适用于哪个 relig？你如何通过表格找出答案？你如何通过可视化找出答案？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-modifying-factor-order",
    "href": "factors.html#sec-modifying-factor-order",
    "title": "16  因子",
    "section": "\n16.4 修改因子顺序",
    "text": "16.4 修改因子顺序\n在可视化中改变因子水平的顺序通常很有用。例如，假设你想探索不同宗教每天平均观看电视的小时数：\n\nrelig_summary &lt;- gss_cat |&gt;\n  group_by(relig) |&gt;\n  summarize(\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(relig_summary, aes(x = tvhours, y = relig)) +\n  geom_point()\n\n\n\n\n\n\n\n这个图很难读，因为没有整体模式。我们可以通过使用 fct_reorder() 来重新排序 relig 的水平来改进它。fct_reorder() 接受三个参数：\n\n\n.f，你想要修改其水平的因子。\n\n.x，你想要用来重新排序水平的数值向量。\n可选的 .fun，一个函数，如果 .f 的每个值对应多个 .x 的值，则使用该函数。默认值是 median。\n\n\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n  geom_point()\n\n\n\n\n\n\n\n重新排序宗教使得更容易看出“不知道”类别的人看电视的时间要多得多，而印度教和其他东方宗教的人看电视的时间要少得多。\n当你开始进行更复杂的转换时，我们建议将它们从 aes() 中移出，放到一个单独的 mutate() 步骤中。例如，你可以像下面这样重写上面的图：\n\nrelig_summary |&gt;\n  mutate(\n    relig = fct_reorder(relig, tvhours)\n  ) |&gt;\n  ggplot(aes(x = tvhours, y = relig)) +\n  geom_point()\n\n如果我们创建一个类似的图，看看平均年龄在不同报告收入水平上是如何变化的呢？\n\nrincome_summary &lt;- gss_cat |&gt;\n  group_by(rincome) |&gt;\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(rincome_summary, aes(x = age, y = fct_reorder(rincome, age))) +\n  geom_point()\n\n\n\n\n\n\n\n在这里，任意重新排序水平不是一个好主意！这是因为 rincome 已经有了一个我们不应该打乱的原则性顺序。请将 fct_reorder() 保留给那些水平是任意排序的因子。\n然而，将“不适用 (Not applicable)”和其他特殊水平一起移到前面是有意义的。你可以使用 fct_relevel()。它接受一个因子 .f，然后是任意数量的你想要移到最前面的水平。\n\nggplot(rincome_summary, aes(x = age, y = fct_relevel(rincome, \"Not applicable\"))) +\n  geom_point()\n\n\n\n\n\n\n\n你认为为什么“不适用”的平均年龄这么高？\n当你在图上为线条着色时，另一种类型的重新排序也很有用。fct_reorder2(.f, .x, .y) 通过与最大 .x 值相关联的 .y 值来重新排序因子 .f。这使得图更容易阅读，因为图右侧的线条颜色将与图例对齐。\nby_age &lt;- gss_cat |&gt;\n  filter(!is.na(age)) |&gt;\n  count(age, marital) |&gt;\n  group_by(age) |&gt;\n  mutate(\n    prop = n / sum(n)\n  )\n\nggplot(by_age, aes(x = age, y = prop, color = marital)) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\")\n\nggplot(by_age, aes(x = age, y = prop, color = fct_reorder2(marital, age, prop))) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(color = \"marital\")\n\n\n\n\n\n\n\n\n\n\n最后，对于条形图，你可以使用 fct_infreq() 按频率降序排列水平：这是最简单的重新排序类型，因为它不需要任何额外的变量。如果你希望它们按频率升序排列，可以与 fct_rev() 结合使用，这样在条形图中最大的值就会在右边，而不是左边。\n\ngss_cat |&gt;\n  mutate(marital = marital |&gt; fct_infreq() |&gt; fct_rev()) |&gt;\n  ggplot(aes(x = marital)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n16.4.1 练习\n\ntvhours 中有一些可疑的高数值。均值是一个好的汇总统计量吗？\n对于 gss_cat 中的每个因子，判断其水平的顺序是任意的还是有原则的。\n为什么将“不适用 (Not applicable)”移到水平的前面会使它移动到图的底部？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#修改因子水平",
    "href": "factors.html#修改因子水平",
    "title": "16  因子",
    "section": "\n16.5 修改因子水平",
    "text": "16.5 修改因子水平\n比改变水平顺序更强大的是改变它们的值。这可以让你为出版物澄清标签，并为高层次的展示折叠水平。最通用和最强大的工具是 fct_recode()。它允许你重编码或更改每个水平的值。例如，以 gss_cat 数据框中的 partyid 变量为例：\n\ngss_cat |&gt; count(partyid)\n#&gt; # A tibble: 10 × 2\n#&gt;   partyid                n\n#&gt;   &lt;fct&gt;              &lt;int&gt;\n#&gt; 1 No answer            154\n#&gt; 2 Don't know             1\n#&gt; 3 Other party          393\n#&gt; 4 Strong republican   2314\n#&gt; 5 Not str republican  3032\n#&gt; 6 Ind,near rep        1791\n#&gt; # ℹ 4 more rows\n\n这些水平很简短且不一致。让我们调整它们，让它们更长并使用平行的结构。像 tidyverse 中大多数重命名和重编码函数一样，新值在左边，旧值在右边：\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\"\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 10 × 2\n#&gt;   partyid                   n\n#&gt;   &lt;fct&gt;                 &lt;int&gt;\n#&gt; 1 No answer               154\n#&gt; 2 Don't know                1\n#&gt; 3 Other party             393\n#&gt; 4 Republican, strong     2314\n#&gt; 5 Republican, weak       3032\n#&gt; 6 Independent, near rep  1791\n#&gt; # ℹ 4 more rows\n\nfct_recode() 会保持未明确提及的水平不变，并且如果你意外地引用了不存在的水平，它会警告你。\n要组合组别，你可以将多个旧水平分配给同一个新水平：\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\",\n      \"Other\"                 = \"No answer\",\n      \"Other\"                 = \"Don't know\",\n      \"Other\"                 = \"Other party\"\n    )\n  )\n\n请谨慎使用这种技术：如果你将真正不同的类别组合在一起，你最终会得到误导性的结果。\n如果你想折叠很多水平，fct_collapse() 是 fct_recode() 的一个有用变体。对于每个新变量，你可以提供一个旧水平的向量：\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_collapse(partyid,\n      \"other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n      \"rep\" = c(\"Strong republican\", \"Not str republican\"),\n      \"ind\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n      \"dem\" = c(\"Not str democrat\", \"Strong democrat\")\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 4 × 2\n#&gt;   partyid     n\n#&gt;   &lt;fct&gt;   &lt;int&gt;\n#&gt; 1 other     548\n#&gt; 2 rep      5346\n#&gt; 3 ind      8409\n#&gt; 4 dem      7180\n\n有时你只是想把小的组别集中在一起，以简化图表或表格。这就是 fct_lump_*() 系列函数的工作。fct_lump_lowfreq() 是一个简单的起点，它逐步将最小的组别类别归入“Other”，并始终保持“Other”为最小的类别。\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_lowfreq(relig)) |&gt;\n  count(relig)\n#&gt; # A tibble: 2 × 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Other      10637\n\n在这种情况下，它不是很有帮助：这次调查中大多数美国人确实是新教徒，但我们可能想看到更多细节！相反，我们可以使用 fct_lump_n() 来指定我们想要恰好 10 个组别：\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_n(relig, n = 10)) |&gt;\n  count(relig, sort = TRUE)\n#&gt; # A tibble: 10 × 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Catholic    5124\n#&gt; 3 None        3523\n#&gt; 4 Christian    689\n#&gt; 5 Other        458\n#&gt; 6 Jewish       388\n#&gt; # ℹ 4 more rows\n\n阅读文档以了解 fct_lump_min() 和 fct_lump_prop()，它们在其他情况下很有用。\n\n16.5.1 练习\n\n认同为民主党、共和党和独立派的人的比例随时间有何变化？\n你如何将 rincome 折叠成一小组类别？\n注意在上面的 fct_lump 示例中有 9 个组（不包括 other）。为什么不是 10 个？（提示：输入 ?fct_lump，找到 other_level 参数的默认值是 “Other”。）",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-ordered-factors",
    "href": "factors.html#sec-ordered-factors",
    "title": "16  因子",
    "section": "\n16.6 有序因子",
    "text": "16.6 有序因子\n在继续之前，有必要简要提及一种特殊类型的因子：有序因子 (ordered factors)。用 ordered() 函数创建的有序因子意味着水平之间存在严格的顺序，但没有指定水平之间差异的大小。当你知道水平有排名，但没有精确的数值排名时，你会使用有序因子。\n当一个有序因子被打印时，你可以识别它，因为它在因子水平之间使用 &lt; 符号：\n\nordered(c(\"a\", \"b\", \"c\"))\n#&gt; [1] a b c\n#&gt; Levels: a &lt; b &lt; c\n\n在 R base 和 tidyverse 中，有序因子的行为与常规因子非常相似。只有在两个地方你可能会注意到不同的行为：\n\n如果你在 ggplot2 中将一个有序因子映射到颜色或填充，它将默认为 scale_color_viridis()/scale_fill_viridis()，这是一个暗示排名的颜色标度。\n如果你在线性模型中使用一个有序预测变量，它将使用“多项式对比”。这些有点用，但除非你有统计学博士学位，否则你不太可能听说过它们，即使那样，你可能也不常解释它们。如果你想了解更多，我们推荐 Lisa DeBruine 的 vignette(\"contrasts\", package = \"faux\")。\n\n就本书而言，正确区分常规因子和有序因子并不是特别重要。然而，在更广泛的范围内，某些领域（特别是社会科学）确实广泛使用有序因子。在这些背景下，正确识别它们很重要，以便其他分析包可以提供适当的行为。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#总结",
    "href": "factors.html#总结",
    "title": "16  因子",
    "section": "\n16.7 总结",
    "text": "16.7 总结\n本章向你介绍了用于处理因子的便捷 forcats 包，并介绍了最常用的函数。forcats 包含了我们没有篇幅在这里讨论的各种其他辅助函数，所以每当你遇到以前没有遇到过的因子分析挑战时，我强烈建议你浏览一下参考索引，看看是否有现成的函数可以帮助解决你的问题。\n如果你在阅读本章后想了解更多关于因子的信息，我们推荐阅读 Amelia McNamara 和 Nicholas Horton 的论文 Wrangling categorical data in R。这篇论文阐述了在 stringsAsFactors: An unauthorized biography 和 stringsAsFactors = &lt;sigh&gt; 中讨论的一些历史，并比较了本书中概述的 tidyverse 分类数据处理方法与 R base 方法。该论文的早期版本帮助激发和确定了 forcats 包的范围；感谢 Amelia 和 Nick！\n在下一章中，我们将转换方向，开始学习 R 中的日期和时间。日期和时间看起来 deceptively 简单，但你很快就会看到，你对它们了解得越多，它们似乎就变得越复杂！",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "factors.html#footnotes",
    "href": "factors.html#footnotes",
    "title": "16  因子",
    "section": "",
    "text": "它们对于建模也非常重要。↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>因子</span>"
    ]
  },
  {
    "objectID": "datetimes.html",
    "href": "datetimes.html",
    "title": "17  日期和时间",
    "section": "",
    "text": "17.1 引言\n本章将向你展示如何在 R 中处理日期和时间。乍一看，日期和时间似乎很简单。你在日常生活中一直在使用它们，并且它们似乎没有引起太多困惑。然而，你对日期和时间了解得越多，它们似乎就变得越复杂！\n为了热身，请思考一下一年有多少天，一天有多少小时。你可能记得大多数年份有 365 天，但闰年有 366 天。你知道判断一年是否为闰年的完整规则吗1？一天中的小时数则不那么明显：大多数日子有 24 小时，但在使用夏令时 (Daylight Saving Time, DST) 的地方，每年有一天是 23 小时，另一天是 25 小时。\n日期和时间之所以困难，是因为它们必须调和两种物理现象（地球的自转和它围绕太阳的公转）与一系列地缘政治现象，包括月份、时区和夏令时。本章不会教你关于日期和时间的每一个细节，但它会为你提供坚实的实践技能基础，帮助你应对常见的数据分析挑战。\n我们将首先向你展示如何从各种输入创建日期时间，然后一旦你有了一个日期时间，你如何可以提取年、月、日等组成部分。接着，我们将深入探讨处理时间跨度的棘手话题，根据你的不同需求，时间跨度有多种形式。最后，我们将简要讨论时区带来的额外挑战。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "datetimes.html#引言",
    "href": "datetimes.html#引言",
    "title": "17  日期和时间",
    "section": "",
    "text": "17.1.1 前提条件\n本章将重点介绍 lubridate 包，它使得在 R 中处理日期和时间变得更加容易。自最新的 tidyverse 版本发布以来，lubridate 已成为核心 tidyverse 的一部分。我们还需要 nycflights13 来获取练习数据。\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "datetimes.html#sec-creating-datetimes",
    "href": "datetimes.html#sec-creating-datetimes",
    "title": "17  日期和时间",
    "section": "\n17.2 创建日期/时间",
    "text": "17.2 创建日期/时间\n有三种类型的日期/时间数据指代一个时间点：\n\n日期 (date)。Tibble 将其打印为 &lt;date&gt;。\n一天中的时间 (time)。Tibble 将其打印为 &lt;time&gt;。\n日期时间 (date-time) 是日期加上时间：它唯一地标识了一个时间点（通常精确到秒）。Tibble 将其打印为 &lt;dttm&gt;。基础 R 称之为 POSIXct，但这名字并不上口。\n\n在本章中，我们将重点关注日期和日期时间，因为 R 没有用于存储时间的原生类。如果你需要一个，可以使用 hms 包。\n你应该始终使用能满足你需求的最简单的数据类型。这意味着如果你可以使用日期而不是日期时间，你就应该这样做。日期时间要复杂得多，因为需要处理时区问题，我们将在本章末尾再回到这个问题。\n要获取当前日期或日期时间，你可以使用 today() 或 now()：\n\ntoday()\n#&gt; [1] \"2025-07-10\"\nnow()\n#&gt; [1] \"2025-07-10 17:58:54 CST\"\n\n此外，以下各节描述了你可能创建日期/时间的四种方式：\n\n使用 readr 读取文件时。\n从字符串。\n从单独的日期时间组件。\n从现有的日期/时间对象。\n\n\n17.2.1 在导入期间\n如果你的 CSV 文件包含 ISO8601 格式的日期或日期时间，你无需做任何事情；readr 会自动识别它：\n\ncsv &lt;- \"\n  date,datetime\n  2022-01-02,2022-01-02 05:12\n\"\nread_csv(csv)\n#&gt; # A tibble: 1 × 2\n#&gt;   date       datetime           \n#&gt;   &lt;date&gt;     &lt;dttm&gt;             \n#&gt; 1 2022-01-02 2022-01-02 05:12:00\n\n如果你之前没有听说过 ISO8601，它是一个书写日期的国际标准2，其中日期的各个部分从大到小排列，并用 - 分隔。例如，在 ISO8601 中，2022 年 5 月 3 日写作 2022-05-03。ISO8601 日期也可以包含时间，其中小时、分钟和秒用 : 分隔，日期和时间部分用 T 或空格分隔。例如，你可以将 2022 年 5 月 3 日下午 4:26 写成 2022-05-03 16:26 或 2022-05-03T16:26。\n对于其他日期时间格式，你需要使用 col_types 加上 col_date() 或 col_datetime() 以及一个日期时间格式。readr 使用的日期时间格式是许多编程语言通用的标准，用一个 % 后跟一个字符来描述日期组件。例如，%Y-%m-%d 指定一个由年、-、月（数字）、-、日组成的日期。表 Table 17.1 列出了所有选项。\n\n\nTable 17.1: readr 能理解的所有日期格式\n\n\n\n类型\n代码\n含义\n示例\n\n\n\n年\n%Y\n4 位数年份\n2021\n\n\n\n%y\n2 位数年份\n21\n\n\n月\n%m\n数字\n2\n\n\n\n%b\n缩写名称\nFeb\n\n\n\n%B\n完整名称\nFebruary\n\n\n日\n%d\n一位或两位数\n2\n\n\n\n%e\n两位数\n02\n\n\n时间\n%H\n24 小时制小时\n13\n\n\n\n%I\n12 小时制小时\n1\n\n\n\n%p\nAM/PM\npm\n\n\n\n%M\n分钟\n35\n\n\n\n%S\n秒\n45\n\n\n\n%OS\n带小数的秒\n45.35\n\n\n\n%Z\n时区名称\nAmerica/Chicago\n\n\n\n%z\n与 UTC 的偏移量\n+0800\n\n\n其他\n%.\n跳过一个非数字字符\n:\n\n\n\n%*\n跳过任意数量的非数字字符\n\n\n\n\n\n\n\n下面的代码展示了几个应用于一个非常模糊的日期的选项：\n\ncsv &lt;- \"\n  date\n  01/02/15\n\"\n\nread_csv(csv, col_types = cols(date = col_date(\"%m/%d/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-01-02\n\nread_csv(csv, col_types = cols(date = col_date(\"%d/%m/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-02-01\n\nread_csv(csv, col_types = cols(date = col_date(\"%y/%m/%d\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2001-02-15\n\n请注意，无论你如何指定日期格式，一旦将其导入 R，它总是以相同的方式显示。\n如果你使用 %b 或 %B 并且处理非英语日期，你还需要提供一个 locale()。请参阅 date_names_langs() 中的内置语言列表，或使用 date_names() 创建你自己的。\n\n17.2.2 从字符串\n日期时间格式规范语言功能强大，但需要仔细分析日期格式。另一种方法是使用 lubridate 的辅助函数，这些函数在你指定了组件顺序后会尝试自动确定格式。要使用它们，请确定年、月、日在你的日期中出现的顺序，然后按相同的顺序排列 “y”、“m” 和 “d”。这就得到了将解析你日期的 lubridate 函数的名称。例如：\n\nymd(\"2017-01-31\")\n#&gt; [1] \"2017-01-31\"\nmdy(\"January 31st, 2017\")\n#&gt; [1] \"2017-01-31\"\ndmy(\"31-Jan-2017\")\n#&gt; [1] \"2017-01-31\"\n\nymd() 和类似的函数创建日期。要创建一个日期时间，请在解析函数名称的末尾加上一个下划线和 “h”、“m”、“s” 中的一个或多个：\n\nymd_hms(\"2017-01-31 20:11:59\")\n#&gt; [1] \"2017-01-31 20:11:59 UTC\"\nmdy_hm(\"01/31/2017 08:01\")\n#&gt; [1] \"2017-01-31 08:01:00 UTC\"\n\n你也可以通过提供一个时区来强制从一个日期创建一个日期时间：\n\nymd(\"2017-01-31\", tz = \"UTC\")\n#&gt; [1] \"2017-01-31 UTC\"\n\n这里我使用了 UTC3 时区，你可能也知道它是 GMT，即格林尼治标准时间 (Greenwich Mean Time)，是 0° 经度的时间4。它不使用夏令时，这使得计算起来稍微容易一些。\n\n17.2.3 从单个组件\n有时，你不会有一个单一的字符串，而是将日期时间的各个组件分布在多个列中。这就是我们在 flights 数据中遇到的情况：\n\nflights |&gt; \n  select(year, month, day, hour, minute)\n#&gt; # A tibble: 336,776 × 5\n#&gt;    year month   day  hour minute\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  2013     1     1     5     15\n#&gt; 2  2013     1     1     5     29\n#&gt; 3  2013     1     1     5     40\n#&gt; 4  2013     1     1     5     45\n#&gt; 5  2013     1     1     6      0\n#&gt; 6  2013     1     1     5     58\n#&gt; # ℹ 336,770 more rows\n\n要从这类输入创建一个日期/时间，对日期使用 make_date()，对日期时间使用 make_datetime()：\n\nflights |&gt; \n  select(year, month, day, hour, minute) |&gt; \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year month   day  hour minute departure          \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n#&gt; 1  2013     1     1     5     15 2013-01-01 05:15:00\n#&gt; 2  2013     1     1     5     29 2013-01-01 05:29:00\n#&gt; 3  2013     1     1     5     40 2013-01-01 05:40:00\n#&gt; 4  2013     1     1     5     45 2013-01-01 05:45:00\n#&gt; 5  2013     1     1     6      0 2013-01-01 06:00:00\n#&gt; 6  2013     1     1     5     58 2013-01-01 05:58:00\n#&gt; # ℹ 336,770 more rows\n\n让我们对 flights 中的四个时间列做同样的事情。这些时间的表示格式有点奇特，所以我们使用模运算来提取小时和分钟组件。一旦我们创建了日期时间变量，我们就专注于本章其余部分将要探讨的变量。\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\nflights_dt &lt;- flights |&gt; \n  filter(!is.na(dep_time), !is.na(arr_time)) |&gt; \n  mutate(\n    dep_time = make_datetime_100(year, month, day, dep_time),\n    arr_time = make_datetime_100(year, month, day, arr_time),\n    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)\n  ) |&gt; \n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\nflights_dt\n#&gt; # A tibble: 328,063 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n#&gt; 2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n#&gt; 3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n#&gt; 4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n#&gt; 5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n#&gt; 6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n#&gt; # ℹ 328,057 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\n有了这些数据，我们可以可视化一年中出发时间的分布情况：\n\nflights_dt |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 86400) # 86400 秒 = 1 天\n\n\n\n\n\n\n\n或者在一天之内：\n\nflights_dt |&gt; \n  filter(dep_time &lt; ymd(20130102)) |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 600) # 600 秒 = 10 分钟\n\n\n\n\n\n\n\n请注意，当你在数值上下文中使用日期时间（如在直方图中），1 表示 1 秒，所以 binwidth 为 86400 意味着一天。对于日期，1 表示 1 天。\n\n17.2.4 从其他类型\n你可能想要在日期时间和日期之间切换。这是 as_datetime() 和 as_date() 的工作：\n\nas_datetime(today())\n#&gt; [1] \"2025-07-10 UTC\"\nas_date(now())\n#&gt; [1] \"2025-07-10\"\n\n有时你会得到以距离“Unix 纪元”（1970-01-01）的数值偏移量表示的日期/时间。如果偏移量以秒为单位，使用 as_datetime()；如果以天为单位，使用 as_date()。\n\nas_datetime(60 * 60 * 10)\n#&gt; [1] \"1970-01-01 10:00:00 UTC\"\nas_date(365 * 10 + 2)\n#&gt; [1] \"1980-01-01\"\n\n\n17.2.5 练习\n\n\n如果你解析一个包含无效日期的字符串会发生什么？\n\nymd(c(\"2010-10-10\", \"bananas\"))\n\n\ntoday() 的 tzone 参数有什么作用？为什么它很重要？\n\n对于以下每一个日期时间，展示你将如何使用 readr 的列规范和 lubridate 函数来解析它。\n\nd1 &lt;- \"January 1, 2010\"\nd2 &lt;- \"2015-Mar-07\"\nd3 &lt;- \"06-Jun-2017\"\nd4 &lt;- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 &lt;- \"12/30/14\" # 2014 年 12 月 30 日\nt1 &lt;- \"1705\"\nt2 &lt;- \"11:15:10.12 PM\"",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "datetimes.html#日期时间组件",
    "href": "datetimes.html#日期时间组件",
    "title": "17  日期和时间",
    "section": "\n17.3 日期时间组件",
    "text": "17.3 日期时间组件\n既然你知道了如何将日期时间数据导入 R 的日期时间数据结构中，让我们来探索一下你可以用它们做什么。本节将重点介绍让你获取和设置单个组件的访问器函数。下一节将探讨日期时间的算术运算如何工作。\n\n17.3.1 获取组件\n你可以使用访问器函数 year()、month()、mday() (月中的天)、yday() (年中的天)、wday() (周中的天)、hour()、minute() 和 second() 来提取日期的各个部分。这些函数实际上是 make_datetime() 的反向操作。\n\ndatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n#&gt; [1] 2026\nmonth(datetime)\n#&gt; [1] 7\nmday(datetime)\n#&gt; [1] 8\n\nyday(datetime)\n#&gt; [1] 189\nwday(datetime)\n#&gt; [1] 4\n\n对于 month() 和 wday()，你可以设置 label = TRUE 来返回月份或星期几的缩写名称。设置 abbr = FALSE 来返回完整名称。\n\nmonth(datetime, label = TRUE)\n#&gt; [1] 7月\n#&gt; 12 Levels: 1月 &lt; 2月 &lt; 3月 &lt; 4月 &lt; 5月 &lt; 6月 &lt; 7月 &lt; 8月 &lt; 9月 &lt; ... &lt; 12月\nwday(datetime, label = TRUE, abbr = FALSE)\n#&gt; [1] 星期三\n#&gt; 7 Levels: 星期日 &lt; 星期一 &lt; 星期二 &lt; 星期三 &lt; 星期四 &lt; ... &lt; 星期六\n\n我们可以使用 wday() 看到，工作日起飞的航班比周末多：\n\nflights_dt |&gt; \n  mutate(wday = wday(dep_time, label = TRUE)) |&gt; \n  ggplot(aes(x = wday)) +\n  geom_bar()\n\n\n\n\n\n\n\n我们还可以查看一小时内按分钟划分的平均出发延误。有一个有趣的模式：在 20-30 分钟和 50-60 分钟之间起飞的航班延误时间远低于该小时的其他时间！\n\nflights_dt |&gt; \n  mutate(minute = minute(dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE),\n    n = n()\n  ) |&gt; \n  ggplot(aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\n有趣的是，如果我们看计划出发时间，我们没有看到这么强的模式：\n\nsched_dep &lt;- flights_dt |&gt; \n  mutate(minute = minute(sched_dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(sched_dep, aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\n那么为什么我们在实际出发时间上看到了那种模式呢？嗯，就像许多由人类收集的数据一样，航班倾向于在“整点”出发时间起飞，存在着强烈的偏好，如 Figure 17.1 所示。每当你处理涉及人类判断的数据时，都要警惕这种模式！\n\n\n\n\n\n\n\nFigure 17.1: 一个频率多边形图，显示了每小时计划起飞的航班数量。 你可以看到对像 0 和 30 这样的整数时间点的强烈偏好，以及通常对五的倍数的时间点的偏好。\n\n\n\n\n\n17.3.2 取整\n绘制单个组件的另一种方法是将日期取整到附近的时间单位，使用 floor_date()、round_date() 和 ceiling_date()。每个函数都接受一个要调整的日期向量，然后是要向下取整 (floor)、向上取整 (ceiling) 或四舍五入的单位名称。例如，这使我们能够绘制每周的航班数量：\n\nflights_dt |&gt; \n  count(week = floor_date(dep_time, \"week\")) |&gt; \n  ggplot(aes(x = week, y = n)) +\n  geom_line() + \n  geom_point()\n\n\n\n\n\n\n\n你可以通过计算 dep_time 与当天最早时刻之间的差值，来展示一天中航班的分布情况：\n\nflights_dt |&gt; \n  mutate(dep_hour = dep_time - floor_date(dep_time, \"day\")) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n#&gt; Don't know how to automatically pick scale for object of type &lt;difftime&gt;.\n#&gt; Defaulting to continuous.\n\n\n\n\n\n\n\n计算一对日期时间之间的差值会得到一个 difftime 对象（更多内容见 Section 17.4.3）。我们可以将其转换为 hms 对象，以获得更有用的 x 轴：\n\nflights_dt |&gt; \n  mutate(dep_hour = hms::as_hms(dep_time - floor_date(dep_time, \"day\"))) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n\n\n\n\n\n\n\n\n17.3.3 修改组件\n你也可以使用每个访问器函数来修改日期/时间的组件。这在数据分析中不常用，但在清理有明显错误日期的数据时可能很有用。\n\n(datetime &lt;- ymd_hms(\"2026-07-08 12:34:56\"))\n#&gt; [1] \"2026-07-08 12:34:56 UTC\"\n\nyear(datetime) &lt;- 2030\ndatetime\n#&gt; [1] \"2030-07-08 12:34:56 UTC\"\nmonth(datetime) &lt;- 01\ndatetime\n#&gt; [1] \"2030-01-08 12:34:56 UTC\"\nhour(datetime) &lt;- hour(datetime) + 1\ndatetime\n#&gt; [1] \"2030-01-08 13:34:56 UTC\"\n\n或者，你也可以不修改现有变量，而是使用 update() 创建一个新的日期时间。这也允许你一步设置多个值：\n\nupdate(datetime, year = 2030, month = 2, mday = 2, hour = 2)\n#&gt; [1] \"2030-02-02 02:34:56 UTC\"\n\n如果值过大，它们会“滚动”到下一个单位：\n\nupdate(ymd(\"2023-02-01\"), mday = 30)\n#&gt; [1] \"2023-03-02\"\nupdate(ymd(\"2023-02-01\"), hour = 400)\n#&gt; [1] \"2023-02-17 16:00:00 UTC\"\n\n\n17.3.4 练习\n\n一天中航班时间的分布如何随着年份的推移而变化？\n比较 dep_time、sched_dep_time 和 dep_delay。它们是否一致？解释你的发现。\n比较 air_time 与出发和到达之间的时间差。解释你的发现。（提示：考虑机场的位置。）\n平均延误时间在一天中是如何变化的？你应该使用 dep_time 还是 sched_dep_time？为什么？\n如果你想最小化延误的几率，应该选择星期几出发？\n是什么使得 diamonds$carat 和 flights$sched_dep_time 的分布相似？\n证实我们的假设：20-30 分钟和 50-60 分钟内航班的提早出发是由计划航班提早起飞造成的。提示：创建一个二元变量，告诉你一个航班是否延误。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "datetimes.html#时间跨度",
    "href": "datetimes.html#时间跨度",
    "title": "17  日期和时间",
    "section": "\n17.4 时间跨度",
    "text": "17.4 时间跨度\n接下来你将学习日期的算术运算，包括减法、加法和除法。在此过程中，你将学习到三个表示时间跨度的重要类：\n\n\ndurations（时长），表示精确的秒数。\n\nperiods（周期），表示人类的单位，如周和月。\n\nintervals（区间），表示一个起点和一个终点。\n\n你如何在时长 (duration)、周期 (period) 和区间 (interval) 之间选择？一如既往，选择能解决你问题的最简单的数据结构。如果你只关心物理时间，使用时长；如果你需要加上人类的时间单位，使用周期；如果你需要计算一个跨度在人类单位中有多长，使用区间。\n\n17.4.1 时长 (Durations)\n在 R 中，当你用一个日期减去另一个日期时，你会得到一个 difftime 对象：\n\n# Hadley 多大了？\nh_age &lt;- today() - ymd(\"1979-10-14\")\nh_age\n#&gt; Time difference of 16706 days\n\n一个 difftime 类的对象记录了一个以秒、分钟、小时、天或周为单位的时间跨度。这种模糊性可能会让 difftime 的使用有些痛苦，所以 lubridate 提供了一个总是使用秒的替代方案：duration（时长）。\n\nas.duration(h_age)\n#&gt; [1] \"1443398400s (~45.74 years)\"\n\nDurations（时长）附带了一系列方便的构造函数：\n\ndseconds(15)\n#&gt; [1] \"15s\"\ndminutes(10)\n#&gt; [1] \"600s (~10 minutes)\"\ndhours(c(12, 24))\n#&gt; [1] \"43200s (~12 hours)\" \"86400s (~1 days)\"\nddays(0:5)\n#&gt; [1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n#&gt; [4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\ndweeks(3)\n#&gt; [1] \"1814400s (~3 weeks)\"\ndyears(1)\n#&gt; [1] \"31557600s (~1 years)\"\n\n时长总是以秒为单位记录时间跨度。更大的单位是通过将分钟、小时、天、周和年转换为秒来创建的：1 分钟 60 秒，1 小时 60 分钟，1 天 24 小时，1 周 7 天。更大的时间单位问题更多。一年使用一年中的“平均”天数，即 365.25 天。没有办法将一个月转换为时长，因为变数太多了。\n你可以对时长进行加法和乘法运算：\n\n2 * dyears(1)\n#&gt; [1] \"63115200s (~2 years)\"\ndyears(1) + dweeks(12) + dhours(15)\n#&gt; [1] \"38869200s (~1.23 years)\"\n\n你可以将时长加到日期上或从日期中减去：\n\ntomorrow &lt;- today() + ddays(1)\nlast_year &lt;- today() - dyears(1)\n\n然而，因为时长代表的是一个精确的秒数，有时你可能会得到一个意想不到的结果：\n\none_am &lt;- ymd_hms(\"2026-03-08 01:00:00\", tz = \"America/New_York\")\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\n\n为什么 3 月 8 日凌晨 1 点之后的一天是 3 月 9 日凌晨 2 点？如果你仔细看日期，你可能还会注意到时区已经改变了。3 月 8 日只有 23 个小时，因为那天是夏令时开始的时候，所以如果我们加上一整天的秒数，我们最终会得到一个不同的时间。\n\n17.4.2 周期 (Periods)\n为了解决这个问题，lubridate 提供了 periods（周期）。周期也是时间跨度，但没有固定的秒数长度，而是使用“人类”的时间单位，比如天和月。这使得它们能以更直观的方式工作：\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\n和时长一样，周期也可以通过一些方便的构造函数创建。\n\nhours(c(12, 24))\n#&gt; [1] \"12H 0M 0S\" \"24H 0M 0S\"\ndays(7)\n#&gt; [1] \"7d 0H 0M 0S\"\nmonths(1:6)\n#&gt; [1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n#&gt; [5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\n\n你可以对周期进行加法和乘法运算：\n\n10 * (months(6) + days(1))\n#&gt; [1] \"60m 10d 0H 0M 0S\"\ndays(50) + hours(25) + minutes(2)\n#&gt; [1] \"50d 25H 2M 0S\"\n\n当然，还可以把它们加到日期上。与时长相比，周期更可能做到你所期望的：\n\n# 闰年\nymd(\"2024-01-01\") + dyears(1)\n#&gt; [1] \"2024-12-31 06:00:00 UTC\"\nymd(\"2024-01-01\") + years(1)\n#&gt; [1] \"2025-01-01\"\n\n# 夏令时\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\n让我们用周期来修正一个与我们航班日期有关的奇怪现象。一些飞机似乎在从纽约市起飞之前就到达了目的地。\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 10,633 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    BQN           9        -4 2013-01-01 19:29:00 2013-01-01 19:20:00\n#&gt; 2 JFK    DFW          59        NA 2013-01-01 19:39:00 2013-01-01 18:40:00\n#&gt; 3 EWR    TPA          -2         9 2013-01-01 20:58:00 2013-01-01 21:00:00\n#&gt; 4 EWR    SJU          -6       -12 2013-01-01 21:02:00 2013-01-01 21:08:00\n#&gt; 5 EWR    SFO          11       -14 2013-01-01 21:08:00 2013-01-01 20:57:00\n#&gt; 6 LGA    FLL         -10        -2 2013-01-01 21:20:00 2013-01-01 21:30:00\n#&gt; # ℹ 10,627 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\n这些是过夜航班。我们对出发和到达时间使用了相同的日期信息，但这些航班是在第二天到达的。我们可以通过给每个过夜航班的到达时间加上 days(1) 来修正这个问题。\n\nflights_dt &lt;- flights_dt |&gt; \n  mutate(\n    overnight = arr_time &lt; dep_time,\n    arr_time = arr_time + days(overnight),\n    sched_arr_time = sched_arr_time + days(overnight)\n  )\n\n现在我们所有的航班都遵守物理定律了。\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 0 × 10\n#&gt; # ℹ 10 variables: origin &lt;chr&gt;, dest &lt;chr&gt;, dep_delay &lt;dbl&gt;,\n#&gt; #   arr_delay &lt;dbl&gt;, dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, …\n\n\n17.4.3 区间 (Intervals)\ndyears(1) / ddays(365) 返回什么？它不完全是 1，因为 dyears() 被定义为平均每年所含的秒数，也就是 365.25 天。\nyears(1) / days(1) 返回什么？嗯，如果年份是 2015 年，它应该返回 365，但如果是 2016 年，它应该返回 366！lubridate 没有足够的信息来给出一个明确的答案。它所做的是给出一个估计值：\n\nyears(1) / days(1)\n#&gt; [1] 365.25\n\n如果你想要一个更精确的度量，你将需要使用 interval (区间)。一个区间是一对开始和结束的日期时间，或者你可以把它看作是一个有起点的时长。\n你可以通过 start %--% end 来创建一个区间：\n\ny2023 &lt;- ymd(\"2023-01-01\") %--% ymd(\"2024-01-01\")\ny2024 &lt;- ymd(\"2024-01-01\") %--% ymd(\"2025-01-01\")\n\ny2023\n#&gt; [1] 2023-01-01 UTC--2024-01-01 UTC\ny2024\n#&gt; [1] 2024-01-01 UTC--2025-01-01 UTC\n\n然后你可以用 days() 来除它，以找出一年中包含多少天：\n\ny2023 / days(1)\n#&gt; [1] 365\ny2024 / days(1)\n#&gt; [1] 366\n\n\n17.4.4 练习\n\n向一个刚开始学习 R 的人解释 days(!overnight) 和 days(overnight)。你需要知道的关键事实是什么？\n创建一个日期向量，给出 2015 年每个月的第一天。创建一个日期向量，给出当前年份每个月的第一天。\n编写一个函数，给定你的生日（作为日期），返回你的年龄（以年为单位）。\n为什么 (today() %--% (today() + years(1))) / months(1) 不起作用？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "datetimes.html#时区",
    "href": "datetimes.html#时区",
    "title": "17  日期和时间",
    "section": "\n17.5 时区",
    "text": "17.5 时区\n时区是一个极其复杂的话题，因为它与地缘政治实体相互作用。幸运的是，我们不需要深入了解所有细节，因为它们对数据分析并非都重要，但我们确实需要正面应对一些挑战。\n第一个挑战是时区的日常名称往往是模棱两可的。例如，如果你是美国人，你可能熟悉 EST，即东部标准时间 (Eastern Standard Time)。然而，澳大利亚和加拿大也有 EST！为了避免混淆，R 使用国际标准的 IANA 时区。这些时区使用一致的命名方案 {地区}/{位置}，通常形式为 {大洲}/{城市} 或 {大洋}/{城市}。例如 “America/New_York”, “Europe/Paris” 和 “Pacific/Auckland”。\n你可能会好奇为什么时区使用城市名称，而通常你认为时区是与一个国家或国家内的某个区域相关联的。这是因为 IANA 数据库必须记录数十年的时区规则。几十年来，国家名称（或分裂）变更相当频繁，但城市名称往往保持不变。另一个问题是，名称不仅需要反映当前的行为，还需要反映完整的历史。例如，“America/New_York” 和 “America/Detroit” 都有时区。这两个城市目前都使用东部标准时间，但在 1969-1972 年，密歇根州（底特律所在的州）没有遵循夏令时，所以它需要一个不同的名称。值得一读原始的时区数据库（可在 https://www.iana.org/time-zones 获取），仅仅为了读一些这样的故事！\n你可以用 Sys.timezone() 来查看 R 认为你当前的时区是什么：\n\nSys.timezone()\n#&gt; [1] \"Asia/Shanghai\"\n\n（如果 R 不知道，你会得到一个 NA。）\n并用 OlsonNames() 查看所有时区名称的完整列表：\n\nlength(OlsonNames())\n#&gt; [1] 597\nhead(OlsonNames())\n#&gt; [1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n#&gt; [4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"\n\n在 R 中，时区是日期时间的一个属性，只控制打印显示。例如，下面这三个对象代表同一时刻：\n\nx1 &lt;- ymd_hms(\"2024-06-01 12:00:00\", tz = \"America/New_York\")\nx1\n#&gt; [1] \"2024-06-01 12:00:00 EDT\"\n\nx2 &lt;- ymd_hms(\"2024-06-01 18:00:00\", tz = \"Europe/Copenhagen\")\nx2\n#&gt; [1] \"2024-06-01 18:00:00 CEST\"\n\nx3 &lt;- ymd_hms(\"2024-06-02 04:00:00\", tz = \"Pacific/Auckland\")\nx3\n#&gt; [1] \"2024-06-02 04:00:00 NZST\"\n\n你可以用减法来验证它们是同一时间：\n\nx1 - x2\n#&gt; Time difference of 0 secs\nx1 - x3\n#&gt; Time difference of 0 secs\n\n除非另有说明，lubridate 总是使用 UTC。UTC（协调世界时）是科学界使用的标准时区，大致相当于 GMT（格林尼治标准时间）。它没有夏令时，这使其成为一个方便的计算表示。结合日期时间的运算，比如 c()，通常会丢掉时区。在这种情况下，日期时间将以第一个元素的时区显示：\n\nx4 &lt;- c(x1, x2, x3)\nx4\n#&gt; [1] \"2024-06-01 12:00:00 EDT\" \"2024-06-01 12:00:00 EDT\"\n#&gt; [3] \"2024-06-01 12:00:00 EDT\"\n\n你可以用两种方式改变时区：\n\n\n保持时间点不变，改变它的显示方式。当时间点是正确的，但你想要一个更自然的显示时，使用这种方式。\n\nx4a &lt;- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n#&gt; [1] \"2024-06-02 02:30:00 +1030\" \"2024-06-02 02:30:00 +1030\"\n#&gt; [3] \"2024-06-02 02:30:00 +1030\"\nx4a - x4\n#&gt; Time differences in secs\n#&gt; [1] 0 0 0\n\n（这也说明了时区的另一个挑战：它们并非都是整数小时的偏移！）\n\n\n改变底层的时间点。当一个时间点被标记了错误的时区，而你需要修正它时，使用这种方式。\n\nx4b &lt;- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n#&gt; [1] \"2024-06-01 12:00:00 +1030\" \"2024-06-01 12:00:00 +1030\"\n#&gt; [3] \"2024-06-01 12:00:00 +1030\"\nx4b - x4\n#&gt; Time differences in hours\n#&gt; [1] -14.5 -14.5 -14.5",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "datetimes.html#总结",
    "href": "datetimes.html#总结",
    "title": "17  日期和时间",
    "section": "\n17.6 总结",
    "text": "17.6 总结\n本章向你介绍了 lubridate 提供的帮助你处理日期时间数据的工具。处理日期和时间似乎比必要的要困难，但希望本章能帮助你理解原因——日期时间比初看起来要复杂得多，处理每一种可能的情况都增加了复杂性。即使你的数据从未跨越夏令时边界或涉及闰年，函数也需要能够处理这些情况。\n下一章将总结缺失值。你已经在一些地方看到过它们，并且无疑在自己的分析中遇到过，现在是时候提供一系列处理它们的有用技巧了。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "datetimes.html#footnotes",
    "href": "datetimes.html#footnotes",
    "title": "17  日期和时间",
    "section": "",
    "text": "如果一个年份能被 4 整除，那么它就是闰年，除非它也能被 100 整除，但如果它同时能被 400 整除，那它仍然是闰年。换句话说，每 400 年中，有 97 个闰年。↩︎\nhttps://xkcd.com/1179/↩︎\n你可能会想 UTC 代表什么。它是英语 “Coordinated Universal Time”（协调世界时）和法语 “Temps Universel Coordonné” 之间的一个妥协。↩︎\n猜猜是哪个国家提出了经度系统，没有奖品。↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日期和时间</span>"
    ]
  },
  {
    "objectID": "missing-values.html",
    "href": "missing-values.html",
    "title": "18  缺失值",
    "section": "",
    "text": "18.1 引言\n你在本书的前面部分已经学习了关于缺失值的基础知识。你第一次见到它们是在 Chapter 1，当时它们在绘图时导致了一个警告；在 Section 3.5.2，它们干扰了汇总统计的计算；在 Section 12.2.2，你了解了它们的传染性以及如何检查它们的存在。现在，我们将更深入地探讨它们，以便你学习更多细节。\n我们将首先讨论一些处理记录为 NA 的缺失值的通用工具。然后，我们将探讨隐式缺失值的概念，即那些仅仅在你的数据中不存在的值，并展示一些你可以用来使它们显式化的工具。最后，我们将以一个相关的话题——空组来结束，这是由数据中未出现的因子水平引起的。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>缺失值</span>"
    ]
  },
  {
    "objectID": "missing-values.html#引言",
    "href": "missing-values.html#引言",
    "title": "18  缺失值",
    "section": "",
    "text": "18.1.1 前提条件\n处理缺失数据的函数主要来自 dplyr 和 tidyr，它们是 tidyverse 的核心成员。\n\nlibrary(tidyverse)",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>缺失值</span>"
    ]
  },
  {
    "objectID": "missing-values.html#显式缺失值",
    "href": "missing-values.html#显式缺失值",
    "title": "18  缺失值",
    "section": "\n18.2 显式缺失值",
    "text": "18.2 显式缺失值\n首先，让我们探讨一些用于创建或消除显式缺失值（即你看到 NA 的单元格）的便捷工具。\n\n18.2.1 末次观测值结转\n缺失值的一个常见用途是作为数据录入的便利手段。当数据是手动输入时，缺失值有时表示前一行中的值被重复（或结转）了：\n\ntreatment &lt;- tribble(\n  ~person,          ~treatment, ~response,\n  \"Derrick Whitmore\", 1,          7,\n  NA,                 2,          10,\n  NA,                 3,          NA,\n  \"Katherine Burke\",  1,          4\n)\n\n你可以使用 tidyr::fill() 来填充这些缺失值。它的工作方式类似于 select()，接受一组列：\n\ntreatment |&gt;\n  fill(everything())\n#&gt; # A tibble: 4 × 3\n#&gt;   person           treatment response\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 Derrick Whitmore         1        7\n#&gt; 2 Derrick Whitmore         2       10\n#&gt; 3 Derrick Whitmore         3       10\n#&gt; 4 Katherine Burke          1        4\n\n这种处理方法有时被称为“末次观测值结转”(last observation carried forward)，简称 locf。你可以使用 .direction 参数来填充以更奇特方式产生的缺失值。\n\n18.2.2 固定值\n有时缺失值代表某个固定的已知值，最常见的是 0。你可以使用 dplyr::coalesce() 来替换它们：\n\nx &lt;- c(1, 4, 5, 7, NA)\ncoalesce(x, 0)\n#&gt; [1] 1 4 5 7 0\n\n有时你会遇到相反的问题，即某个具体值实际上代表一个缺失值。这通常出现在由没有适当方式表示缺失值的旧软件生成的数据中，因此它必须使用一些特殊值，如 99 或 -999。\n如果可能，在读入数据时处理这个问题，例如，使用 readr::read_csv() 的 na 参数，例如 read_csv(path, na = \"99\")。如果你后来才发现这个问题，或者你的数据源没有提供在读取时处理它的方法，你可以使用 dplyr::na_if()：\n\nx &lt;- c(1, 4, 5, 7, -99)\nna_if(x, -99)\n#&gt; [1]  1  4  5  7 NA\n\n\n18.2.3 NaN\n在我们继续之前，有一种特殊类型的缺失值你偶尔会遇到：NaN（读作 “nan”），即非数值 (not a number)。了解它并不那么重要，因为它通常的行为就像 NA 一样：\n\nx &lt;- c(NA, NaN)\nx * 10\n#&gt; [1]  NA NaN\nx == 1\n#&gt; [1] NA NA\nis.na(x)\n#&gt; [1] TRUE TRUE\n\n在极少数情况下，如果你需要区分 NA 和 NaN，你可以使用 is.nan(x)。\n当你执行一个结果不确定的数学运算时，通常会遇到 NaN：\n\n0 / 0 \n#&gt; [1] NaN\n0 * Inf\n#&gt; [1] NaN\nInf - Inf\n#&gt; [1] NaN\nsqrt(-1)\n#&gt; Warning in sqrt(-1): NaNs produced\n#&gt; [1] NaN",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>缺失值</span>"
    ]
  },
  {
    "objectID": "missing-values.html#sec-missing-implicit",
    "href": "missing-values.html#sec-missing-implicit",
    "title": "18  缺失值",
    "section": "\n18.3 隐式缺失值",
    "text": "18.3 隐式缺失值\n到目前为止，我们讨论的缺失值都是显式缺失的，也就是说，你可以在数据中看到一个 NA。但缺失值也可能是隐式缺失的，如果一整行数据根本就不存在于数据中。让我们用一个记录某支股票每个季度价格的简单数据集来说明这两者的区别：\n\nstocks &lt;- tibble(\n  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),\n  qtr   = c(   1,    2,    3,    4,    2,    3,    4),\n  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)\n)\n\n这个数据集中有两个缺失的观测值：\n\n2020 年第四季度的 price 是显式缺失的，因为它的值是 NA。\n2021 年第一季度的 price 是隐式缺失的，因为它根本没有出现在数据集中。\n\n思考这两者区别的一种方式是这个富有禅意的公案：\n\n显式缺失值是一种存在着的“缺失”。\n隐式缺失值是一种不存在着的“存在”。\n\n有时你想让隐式缺失变得显式，以便有一个可以操作的实体。在其他情况下，显式缺失是由数据结构强加给你的，而你想摆脱它们。以下各节讨论了一些在隐式和显式缺失之间转换的工具。\n\n18.3.1 数据重塑 (Pivoting)\n你已经见过一个可以使隐式缺失变显式以及反之亦然的工具：数据重塑 (pivoting)。将数据变宽可以使隐式缺失值变得显式，因为行和新列的每种组合都必须有某个值。例如，如果我们重塑 stocks 数据，把 quarter 放到列中，两个缺失值都变得显式了：\n\nstocks |&gt;\n  pivot_wider(\n    names_from = qtr, \n    values_from = price\n  )\n#&gt; # A tibble: 2 × 5\n#&gt;    year   `1`   `2`   `3`   `4`\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020  1.88  0.59  0.35 NA   \n#&gt; 2  2021 NA     0.92  0.17  2.66\n\n默认情况下，将数据变长会保留显式缺失值，但如果它们是仅因数据不整洁而存在的结构性缺失值，你可以通过设置 values_drop_na = TRUE 来丢弃它们（使它们变为隐式）。更多细节请参见 Section 5.2 中的示例。\n\n18.3.2 补全 (Complete)\ntidyr::complete() 允许你通过提供一组定义了应该存在的行组合的变量来生成显式缺失值。例如，我们知道 year 和 qtr 的所有组合都应该存在于 stocks 数据中：\n\nstocks |&gt;\n  complete(year, qtr)\n#&gt; # A tibble: 8 × 3\n#&gt;    year   qtr price\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020     1  1.88\n#&gt; 2  2020     2  0.59\n#&gt; 3  2020     3  0.35\n#&gt; 4  2020     4 NA   \n#&gt; 5  2021     1 NA   \n#&gt; 6  2021     2  0.92\n#&gt; # ℹ 2 more rows\n\n通常，你会用现有变量的名称来调用 complete()，以填充缺失的组合。然而，有时单个变量本身就是不完整的，所以你可以提供自己的数据。例如，你可能知道 stocks 数据集应该从 2019 年到 2021 年，所以你可以为 year 明确提供这些值：\n\nstocks |&gt;\n  complete(year = 2019:2021, qtr)\n#&gt; # A tibble: 12 × 3\n#&gt;    year   qtr price\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2019     1 NA   \n#&gt; 2  2019     2 NA   \n#&gt; 3  2019     3 NA   \n#&gt; 4  2019     4 NA   \n#&gt; 5  2020     1  1.88\n#&gt; 6  2020     2  0.59\n#&gt; # ℹ 6 more rows\n\n如果一个变量的范围是正确的，但并非所有值都存在，你可以使用 full_seq(x, 1) 来生成从 min(x) 到 max(x) 之间以 1 为间隔的所有值。\n在某些情况下，完整的观测集合不能通过变量的简单组合生成。在这种情况下，你可以手动完成 complete() 为你做的事情：创建一个包含所有应该存在的行的数据框（使用你需要的任何技术组合），然后用 dplyr::full_join() 将它与你的原始数据集结合起来。\n\n18.3.3 连接 (Joins)\n这引出了揭示隐式缺失观测值的另一种重要方式：连接 (joins)。你将在 Chapter 19 中学习更多关于连接的知识，但我们想在这里快速提及它们，因为你通常只有在将一个数据集与另一个数据集进行比较时，才能知道值是缺失的。\ndplyr::anti_join(x, y) 在这里是一个特别有用的工具，因为它只选择 x 中在 y 中没有匹配的行。例如，我们可以使用两个 anti_join() 来揭示我们缺少 flights 中提到的四个机场和 722 架飞机的信息：\n\nlibrary(nycflights13)\n\nflights |&gt; \n  distinct(faa = dest) |&gt; \n  anti_join(airports)\n#&gt; Joining with `by = join_by(faa)`\n#&gt; # A tibble: 4 × 1\n#&gt;   faa  \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\nflights |&gt; \n  distinct(tailnum) |&gt; \n  anti_join(planes)\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 722 × 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # ℹ 716 more rows\n\n\n18.3.4 练习\n\n你能找到航空公司和那些似乎从 planes 数据集中缺失的行之间的任何关系吗？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>缺失值</span>"
    ]
  },
  {
    "objectID": "missing-values.html#因子和空组",
    "href": "missing-values.html#因子和空组",
    "title": "18  缺失值",
    "section": "\n18.4 因子和空组",
    "text": "18.4 因子和空组\n最后一种缺失类型是空组 (empty group)，即不包含任何观测值的组，这在处理因子时可能出现。例如，假设我们有一个包含一些人健康信息的数据集：\n\nhealth &lt;- tibble(\n  name   = c(\"Ikaia\", \"Oletta\", \"Leriah\", \"Dashay\", \"Tresaun\"),\n  smoker = factor(c(\"no\", \"no\", \"no\", \"no\", \"no\"), levels = c(\"yes\", \"no\")),\n  age    = c(34, 88, 75, 47, 56),\n)\n\n我们想用 dplyr::count() 来计算吸烟者的数量：\n\nhealth |&gt; count(smoker)\n#&gt; # A tibble: 1 × 2\n#&gt;   smoker     n\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 no         5\n\n这个数据集只包含非吸烟者，但我们知道吸烟者是存在的；非吸烟者组是空的。我们可以通过使用 .drop = FALSE 来要求 count() 保留所有的组，即使是那些在数据中未见到的组：\n\nhealth |&gt; count(smoker, .drop = FALSE)\n#&gt; # A tibble: 2 × 2\n#&gt;   smoker     n\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 yes        0\n#&gt; 2 no         5\n\n同样的原则也适用于 ggplot2 的离散坐标轴，它也会丢弃没有任何值的水平。你可以通过向相应的离散坐标轴提供 drop = FALSE 来强制它们显示：\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete()\n\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete(drop = FALSE)\n\n\n\n\n\n\n\n\n\n\n同样的问题在 dplyr::group_by() 中也更普遍地出现。你同样可以使用 .drop = FALSE 来保留所有因子水平：\n\nhealth |&gt; \n  group_by(smoker, .drop = FALSE) |&gt; \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  )\n#&gt; # A tibble: 2 × 6\n#&gt;   smoker     n mean_age min_age max_age sd_age\n#&gt;   &lt;fct&gt;  &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 yes        0      NaN     Inf    -Inf   NA  \n#&gt; 2 no         5       60      34      88   21.6\n\n我们在这里得到了一些有趣的结果，因为当对一个空组进行汇总时，汇总函数被应用于零长度的向量。空向量（长度为 0）和缺失值（每个长度为 1）之间有一个重要的区别。\n\n# 一个包含两个缺失值的向量\nx1 &lt;- c(NA, NA)\nlength(x1)\n#&gt; [1] 2\n\n# 一个不包含任何东西的向量\nx2 &lt;- numeric()\nlength(x2)\n#&gt; [1] 0\n\n所有汇总函数都适用于零长度向量，但它们可能返回乍一看令人惊讶的结果。这里我们看到 mean(age) 返回 NaN，因为 mean(age) = sum(age)/length(age)，在这里是 0/0。max() 和 min() 对空向量返回 -Inf 和 Inf，所以如果你将结果与一个非空的新数据向量结合并重新计算，你将得到新数据的最小值或最大值1。\n有时一个更简单的方法是先执行汇总，然后用 complete() 使隐式缺失变得显式。\n\nhealth |&gt; \n  group_by(smoker) |&gt; \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  ) |&gt; \n  complete(smoker)\n#&gt; # A tibble: 2 × 6\n#&gt;   smoker     n mean_age min_age max_age sd_age\n#&gt;   &lt;fct&gt;  &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 yes       NA       NA      NA      NA   NA  \n#&gt; 2 no         5       60      34      88   21.6\n\n这种方法的主要缺点是，你得到的计数是 NA，即使你知道它应该是零。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>缺失值</span>"
    ]
  },
  {
    "objectID": "missing-values.html#总结",
    "href": "missing-values.html#总结",
    "title": "18  缺失值",
    "section": "\n18.5 总结",
    "text": "18.5 总结\n缺失值很奇怪！有时它们被记录为显式的 NA，但其他时候你只能通过它们的缺席来注意到它们。本章为你提供了一些处理显式缺失值的工具，揭示隐式缺失值的工具，并讨论了隐式如何变为显式以及反之亦然的一些方法。\n在下一章，我们将 affrontare 本书这一部分的最后一章：连接 (joins)。这与到目前为止的章节有些不同，因为我们将讨论作用于整个数据框的工具，而不是你放在数据框内部的东西。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>缺失值</span>"
    ]
  },
  {
    "objectID": "missing-values.html#footnotes",
    "href": "missing-values.html#footnotes",
    "title": "18  缺失值",
    "section": "",
    "text": "换句话说，min(c(x, y)) 总是等于 min(min(x), min(y))。↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>缺失值</span>"
    ]
  },
  {
    "objectID": "joins.html",
    "href": "joins.html",
    "title": "19  连接",
    "section": "",
    "text": "19.1 引言\n数据分析很少只涉及单个数据框。通常你会有多个数据框，并且必须将它们连接 (join) 在一起以回答你感兴趣的问题。本章将向你介绍两种重要的连接类型：\n我们将首先讨论键 (keys)，即用于在连接中连接一对数据框的变量。我们将通过检查 nycflights13 包中数据集的键来巩固理论，然后利用这些知识开始连接数据框。接下来，我们将讨论连接的工作原理，重点关注它们对行的操作。最后，我们将讨论非等值连接 (non-equi joins)，这是一类连接，它提供了一种比默认的相等关系更灵活的键匹配方式。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "joins.html#引言",
    "href": "joins.html#引言",
    "title": "19  连接",
    "section": "",
    "text": "变连接 (Mutating joins)，它将一个数据框中的匹配观测值的新变量添加到另一个数据框中。\n过滤连接 (Filtering joins)，它根据一个数据框中的观测值是否与另一个数据框中的观测值匹配来过滤该数据框中的观测值。\n\n\n\n19.1.1 前提条件\n在本章中，我们将使用 dplyr 中的连接函数来探索 nycflights13 中的五个相关数据集。\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "joins.html#键",
    "href": "joins.html#键",
    "title": "19  连接",
    "section": "\n19.2 键",
    "text": "19.2 键\n要理解连接，你首先需要了解两个表如何通过每个表内的一对键连接起来。在本节中，你将学习两种类型的键，并在 nycflights13 包的数据集中看到这两种键的示例。你还将学习如何检查你的键是否有效，以及当你的表缺少键时该怎么办。\n\n19.2.1 主键和外键\n每个连接都涉及一对键：一个主键和一个外键。 主键 (primary key) 是一个或一组唯一标识每个观测值的变量。当需要多个变量时，该键称为复合键 (compound key)。例如，在 nycflights13 中：\n\n\nairlines 记录了关于每家航空公司的两条数据：其航空公司代码和全名。你可以用它的两个字母的航空公司代码来识别一家航空公司，这使得 carrier 成为主键。\n\nairlines\n#&gt; # A tibble: 16 × 2\n#&gt;   carrier name                    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                   \n#&gt; 1 9E      Endeavor Air Inc.       \n#&gt; 2 AA      American Airlines Inc.  \n#&gt; 3 AS      Alaska Airlines Inc.    \n#&gt; 4 B6      JetBlue Airways         \n#&gt; 5 DL      Delta Air Lines Inc.    \n#&gt; 6 EV      ExpressJet Airlines Inc.\n#&gt; # ℹ 10 more rows\n\n\n\nairports 记录了关于每个机场的数据。你可以用它的三个字母的机场代码来识别每个机场，这使得 faa 成为主键。\n\nairports\n#&gt; # A tibble: 1,458 × 8\n#&gt;   faa   name                            lat   lon   alt    tz dst  \n#&gt;   &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A    \n#&gt; 2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A    \n#&gt; 3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A    \n#&gt; 4 06N   Randall Airport                41.4 -74.4   523    -5 A    \n#&gt; 5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A    \n#&gt; 6 0A9   Elizabethton Municipal Airpo…  36.4 -82.2  1593    -5 A    \n#&gt; # ℹ 1,452 more rows\n#&gt; # ℹ 1 more variable: tzone &lt;chr&gt;\n\n\n\nplanes 记录了关于每架飞机的数据。你可以用它的尾号来识别一架飞机，这使得 tailnum 成为主键。\n\nplanes\n#&gt; # A tibble: 3,322 × 9\n#&gt;   tailnum  year type              manufacturer    model     engines\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 N10156   2004 Fixed wing multi… EMBRAER         EMB-145XR       2\n#&gt; 2 N102UW   1998 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 3 N103US   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 4 N104UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 5 N10575   2002 Fixed wing multi… EMBRAER         EMB-145LR       2\n#&gt; 6 N105UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; # ℹ 3,316 more rows\n#&gt; # ℹ 3 more variables: seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\n\n\nweather 记录了始发机场的天气数据。你可以通过位置和时间的组合来识别每个观测值，这使得 origin 和 time_hour 成为复合主键。\n\nweather\n#&gt; # A tibble: 26,115 × 15\n#&gt;   origin  year month   day  hour  temp  dewp humid wind_dir\n#&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 EWR     2013     1     1     1  39.0  26.1  59.4      270\n#&gt; 2 EWR     2013     1     1     2  39.0  27.0  61.6      250\n#&gt; 3 EWR     2013     1     1     3  39.0  28.0  64.4      240\n#&gt; 4 EWR     2013     1     1     4  39.9  28.0  62.2      250\n#&gt; 5 EWR     2013     1     1     5  39.0  28.0  64.4      260\n#&gt; 6 EWR     2013     1     1     6  37.9  28.0  67.2      240\n#&gt; # ℹ 26,109 more rows\n#&gt; # ℹ 6 more variables: wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, …\n\n\n\n外键 (foreign key) 是一个（或一组）与另一个表中的主键相对应的变量。例如：\n\n\nflights$tailnum 是一个外键，对应于主键 planes$tailnum。\n\nflights$carrier 是一个外键，对应于主键 airlines$carrier。\n\nflights$origin 是一个外键，对应于主键 airports$faa。\n\nflights$dest 是一个外键，对应于主键 airports$faa。\n\nflights$origin-flights$time_hour 是一个复合外键，对应于复合主键 weather$origin-weather$time_hour。\n\n这些关系在 Figure 19.1 中进行了可视化总结。\n\n\n\n\n\n\n\nFigure 19.1: nycflights13 包中所有五个数据框之间的连接。构成主键的变量用灰色着色，并通过箭头连接到它们对应的外键。\n\n\n\n\n你会注意到这些键的设计中有一个很好的特性：主键和外键几乎总是有相同的名称，正如你稍后将看到的，这将使你的连接工作变得容易得多。同样值得注意的是相反的关系：几乎每个在多个表中使用的变量名在每个地方都有相同的含义。只有一个例外：在 flights 中 year 表示出发年份，在 planes 中表示制造年份。当我们开始实际连接表时，这将变得很重要。\n\n19.2.2 检查主键\n既然我们已经确定了每个表中的主键，一个好的做法是验证它们确实唯一地标识了每个观测值。一种方法是 count() 主键，并查找 n 大于 1 的条目。这表明 planes 和 weather 都看起来不错：\n\nplanes |&gt; \n  count(tailnum) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 2\n#&gt; # ℹ 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt;\n\nweather |&gt; \n  count(time_hour, origin) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 3\n#&gt; # ℹ 3 variables: time_hour &lt;dttm&gt;, origin &lt;chr&gt;, n &lt;int&gt;\n\n你还应该检查主键中是否有缺失值——如果一个值是缺失的，那么它就不能标识一个观测值！\n\nplanes |&gt; \n  filter(is.na(tailnum))\n#&gt; # A tibble: 0 × 9\n#&gt; # ℹ 9 variables: tailnum &lt;chr&gt;, year &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;,\n#&gt; #   model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\nweather |&gt; \n  filter(is.na(time_hour) | is.na(origin))\n#&gt; # A tibble: 0 × 15\n#&gt; # ℹ 15 variables: origin &lt;chr&gt;, year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;,\n#&gt; #   hour &lt;int&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;, humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;, …\n\n\n19.2.3 代理键\n到目前为止，我们还没有讨论 flights 的主键。它在这里不是非常重要，因为没有数据框使用它作为外键，但考虑它仍然是有用的，因为如果我们有某种方式向他人描述观测值，那么处理观测值会更容易。\n经过一番思考和实验，我们确定有三个变量可以共同唯一地标识每个航班：\n\nflights |&gt; \n  count(time_hour, carrier, flight) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: time_hour &lt;dttm&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, n &lt;int&gt;\n\n没有重复值是否自动使 time_hour-carrier-flight 成为一个主键？这当然是一个好的开始，但并不能保证它。例如，海拔和纬度是 airports 的一个好的主键吗？\n\nairports |&gt;\n  count(alt, lat) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 × 3\n#&gt;     alt   lat     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    13  40.6     2\n\n通过海拔和纬度来识别一个机场显然是一个坏主意，而且总的来说，仅从数据本身不可能知道一个变量组合是否构成一个好的主键。但对于航班来说，time_hour、carrier 和 flight 的组合似乎是合理的，因为如果同一时间同一家航空公司有多个相同航班号的航班在空中，那对航空公司及其客户来说会非常混乱。\n话虽如此，我们最好还是引入一个简单的数字代理键，使用行号：\n\nflights2 &lt;- flights |&gt; \n  mutate(id = row_number(), .before = 1)\nflights2\n#&gt; # A tibble: 336,776 × 20\n#&gt;      id  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1     1  2013     1     1      517            515         2      830\n#&gt; 2     2  2013     1     1      533            529         4      850\n#&gt; 3     3  2013     1     1      542            540         2      923\n#&gt; 4     4  2013     1     1      544            545        -1     1004\n#&gt; 5     5  2013     1     1      554            600        -6      812\n#&gt; 6     6  2013     1     1      554            558        -4      740\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\n代理键在与他人交流时特别有用：告诉某人查看航班 2001 比告诉他们查看 2013 年 1 月 3 日上午 9 点出发的 UA430 要容易得多。\n\n19.2.4 练习\n\n我们在 Figure 19.1 中忘记绘制 weather 和 airports 之间的关系了。这个关系是什么？它应该如何在图中显示？\nweather 只包含纽约市三个始发机场的信息。如果它包含了美国所有机场的天气记录，它会与 flights 建立什么额外的连接？\nyear、month、day、hour 和 origin 变量几乎构成了 weather 的一个复合键，但有一个小时有重复的观测值。你能找出那个小时有什么特别之处吗？\n我们知道一年中的某些日子是特殊的，飞行的人比平时少（例如，平安夜和圣诞节）。你如何将这些数据表示为一个数据框？主键会是什么？它将如何与现有的数据框连接？\n在 Lahman 包中，绘制一个图表来说明 Batting、People 和 Salaries 数据框之间的连接。再绘制一个图表来显示 People、Managers 和 AwardsManagers 之间的关系。你将如何描述 Batting、Pitching 和 Fielding 数据框之间的关系？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-mutating-joins",
    "href": "joins.html#sec-mutating-joins",
    "title": "19  连接",
    "section": "\n19.3 基本连接",
    "text": "19.3 基本连接\n既然你已经了解了数据框如何通过键连接，我们就可以开始使用连接来更好地理解 flights 数据集了。dplyr 提供了六个连接函数：left_join()、inner_join()、right_join()、full_join()、semi_join() 和 anti_join()。它们都有相同的接口：它们接受一对数据框（x 和 y），并返回一个数据框。输出的行和列的顺序主要由 x 决定。\n在本节中，你将学习如何使用一个变连接 left_join() 和两个过滤连接 semi_join() 和 anti_join()。在下一节中，你将确切地学习这些函数如何工作，以及剩下的 inner_join()、right_join() 和 full_join()。\n\n19.3.1 变连接\n变连接 (mutating join) 允许你组合两个数据框中的变量：它首先通过它们的键来匹配观测值，然后将一个数据框中的变量复制到另一个数据框中。像 mutate() 一样，连接函数在右侧添加变量，所以如果你的数据集有很多变量，你将看不到新的变量。对于这些例子，我们将通过创建一个只有六个变量的较窄的数据集来使其更容易看清发生了什么1：\n\nflights2 &lt;- flights |&gt; \n  select(year, time_hour, origin, dest, tailnum, carrier)\nflights2\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year time_hour           origin dest  tailnum carrier\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA     \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA     \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA     \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL     \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA     \n#&gt; # ℹ 336,770 more rows\n\n有四种类型的变连接，但有一种你几乎总是会使用：left_join()。它很特别，因为输出将始终与 x（你正在连接的数据框）具有相同的行2。left_join() 的主要用途是添加额外的元数据。例如，我们可以使用 left_join() 将完整的航空公司名称添加到 flights2 数据中：\n\nflights2 |&gt;\n  left_join(airlines)\n#&gt; Joining with `by = join_by(carrier)`\n#&gt; # A tibble: 336,776 × 7\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines In…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines In…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines I…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines In…\n#&gt; # ℹ 336,770 more rows\n\n或者我们可以找出每架飞机起飞时的温度和风速：\n\nflights2 |&gt; \n  left_join(weather |&gt; select(origin, time_hour, temp, wind_speed))\n#&gt; Joining with `by = join_by(time_hour, origin)`\n#&gt; # A tibble: 336,776 × 8\n#&gt;    year time_hour           origin dest  tailnum carrier  temp wind_speed\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA       39.0       12.7\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA       39.9       15.0\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA       39.0       15.0\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6       39.0       15.0\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL       39.9       16.1\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA       39.0       12.7\n#&gt; # ℹ 336,770 more rows\n\n或者是什么尺寸的飞机在飞行：\n\nflights2 |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 336,776 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Fixed wing multi en…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      Fixed wing multi en…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Fixed wing multi en…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      Fixed wing multi en…\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Fixed wing multi en…\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Fixed wing multi en…\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 2 more variables: engines &lt;int&gt;, seats &lt;int&gt;\n\n当 left_join() 未能为 x 中的某一行找到匹配项时，它会用缺失值填充新变量。例如，没有关于尾号为 N3ALAA 的飞机的信息，所以 type、engines 和 seats 将是缺失的：\n\nflights2 |&gt; \n  filter(tailnum == \"N3ALAA\") |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 63 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type  engines seats\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 2  2013 2013-01-02 18:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 3  2013 2013-01-03 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 4  2013 2013-01-07 19:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 5  2013 2013-01-08 17:00:00 JFK    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 6  2013 2013-01-16 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; # ℹ 57 more rows\n\n我们将在本章的其余部分几次回到这个问题。\n\n19.3.2 指定连接键\n默认情况下，left_join() 将使用同时出现在两个数据框中的所有变量作为连接键，这被称为自然 (natural) 连接。这是一个有用的启发式方法，但它并不总是有效。例如，如果我们尝试将 flights2 与完整的 planes 数据集连接会发生什么？\n\nflights2 |&gt; \n  left_join(planes)\n#&gt; Joining with `by = join_by(year, tailnum)`\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier type  manufacturer\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 5 more variables: model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, …\n\n我们得到了很多缺失的匹配，因为我们的连接正在尝试使用 tailnum 和 year 作为复合键。flights 和 planes 都有一个 year 列，但它们的含义不同：flights$year 是航班发生的年份，而 planes$year 是飞机制造的年份。我们只想在 tailnum上连接，所以我们需要使用 join_by() 提供一个明确的规范：\n\nflights2 |&gt; \n  left_join(planes, join_by(tailnum))\n#&gt; # A tibble: 336,776 × 14\n#&gt;   year.x time_hour           origin dest  tailnum carrier year.y\n#&gt;    &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999\n#&gt; 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998\n#&gt; 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990\n#&gt; 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012\n#&gt; 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991\n#&gt; 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 7 more variables: type &lt;chr&gt;, manufacturer &lt;chr&gt;, model &lt;chr&gt;, …\n\n请注意，year 变量在输出中通过后缀（year.x 和 year.y）进行了区分，这告诉你变量是来自 x 参数还是 y 参数。你可以使用 suffix 参数覆盖默认的后缀。\njoin_by(tailnum) 是 join_by(tailnum == tailnum) 的简写。了解这种更完整的形式很重要，原因有二。首先，它描述了两个表之间的关系：键必须相等。这就是为什么这种类型的连接通常被称为等值连接 (equi join)。你将在 Section 19.5 中学习非等值连接。\n其次，这是你在每个表中指定不同连接键的方式。例如，有两种方法可以连接 flight2 和 airports 表：通过 dest 或 origin：\n\nflights2 |&gt; \n  left_join(airports, join_by(dest == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      George Bush Interco…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      George Bush Interco…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Miami Intl          \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;                \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Hartsfield Jackson …\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Chicago Ohare Intl  \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\nflights2 |&gt; \n  left_join(airports, join_by(origin == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name               \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;              \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Newark Liberty Intl\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      La Guardia         \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      John F Kennedy Intl\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      John F Kennedy Intl\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      La Guardia         \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Newark Liberty Intl\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\n在旧代码中，你可能会看到一种不同的指定连接键的方式，使用一个字符向量：\n\n\nby = \"x\" 对应于 join_by(x)。\n\nby = c(\"a\" = \"x\") 对应于 join_by(a == x)。\n\n既然 join_by() 已经存在，我们更喜欢使用它，因为它提供了更清晰和更灵活的规范。\ninner_join()、right_join()、full_join() 的接口与 left_join() 相同。区别在于它们保留哪些行：左连接保留 x 中的所有行，右连接保留 y 中的所有行，全连接保留 x 或 y 中的所有行，而内连接只保留同时出现在 x 和 y 中的行。我们稍后会更详细地回到这些。\n\n19.3.3 过滤连接\n你可能猜到，过滤连接 (filtering join) 的主要作用是过滤行。有两种类型：半连接 (semi-joins) 和反连接 (anti-joins)。 半连接保留 x 中所有在 y 中有匹配的行。例如，我们可以使用半连接来过滤 airports 数据集，只显示始发机场：\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == origin))\n#&gt; # A tibble: 3 × 8\n#&gt;   faa   name                  lat   lon   alt    tz dst   tzone           \n#&gt;   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n#&gt; 1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York\n#&gt; 2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n#&gt; 3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York\n\n或者只显示目的地：\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == dest))\n#&gt; # A tibble: 101 × 8\n#&gt;   faa   name                     lat    lon   alt    tz dst   tzone          \n#&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          \n#&gt; 1 ABQ   Albuquerque Internati…  35.0 -107.   5355    -7 A     America/Denver \n#&gt; 2 ACK   Nantucket Mem           41.3  -70.1    48    -5 A     America/New_Yo…\n#&gt; 3 ALB   Albany Intl             42.7  -73.8   285    -5 A     America/New_Yo…\n#&gt; 4 ANC   Ted Stevens Anchorage…  61.2 -150.    152    -9 A     America/Anchor…\n#&gt; 5 ATL   Hartsfield Jackson At…  33.6  -84.4  1026    -5 A     America/New_Yo…\n#&gt; 6 AUS   Austin Bergstrom Intl   30.2  -97.7   542    -6 A     America/Chicago\n#&gt; # ℹ 95 more rows\n\n反连接则相反：它们返回 x 中所有在 y 中没有匹配的行。它们对于查找数据中隐式的缺失值很有用，这是 Section 18.3 的主题。隐式缺失值不会显示为 NA，而是仅仅以缺席的形式存在。例如，我们可以通过查找没有匹配目的地机场的航班来找到 airports 中缺失的行：\n\nflights2 |&gt; \n  anti_join(airports, join_by(dest == faa)) |&gt; \n  distinct(dest)\n#&gt; # A tibble: 4 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\n或者我们可以找出哪些 tailnum 在 planes 中是缺失的：\n\nflights2 |&gt;\n  anti_join(planes, join_by(tailnum)) |&gt; \n  distinct(tailnum)\n#&gt; # A tibble: 722 × 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # ℹ 716 more rows\n\n\n19.3.4 练习\n\n找出（全年）延误最严重的 48 个小时。与 weather 数据进行交叉引用。你能看到任何模式吗？\n\n想象你已经用这段代码找到了排名前 10 的最受欢迎的目的地：\n\ntop_dest &lt;- flights2 |&gt;\n  count(dest, sort = TRUE) |&gt;\n  head(10)\n\n你如何找到所有飞往这些目的地的航班？\n\n每个出发的航班都有对应那个小时的天气数据吗？\n那些在 planes 中没有匹配记录的尾号有什么共同点？（提示：一个变量解释了约 90% 的问题。）\n向 planes 添加一列，列出飞过那架飞机的每个 carrier。你可能期望飞机和航空公司之间存在一种隐式关系，因为每架飞机都由一家航空公司运营。使用你在前面章节中学到的工具来证实或否定这个假设。\n将始发地和目的地机场的纬度和经度添加到 flights 中。是在连接之前还是之后重命名列更容易？\n\n按目的地计算平均延误，然后与 airports 数据框连接，这样你就可以显示延误的空间分布。这里有一个绘制美国地图的简单方法：\n\nairports |&gt;\n  semi_join(flights, join_by(faa == dest)) |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n    borders(\"state\") +\n    geom_point() +\n    coord_quickmap()\n\n你可能想用点的大小或颜色来显示每个机场的平均延误。\n\n2013 年 6 月 13 日发生了什么？绘制一张延误地图，然后用谷歌与天气进行交叉引用。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "joins.html#连接如何工作",
    "href": "joins.html#连接如何工作",
    "title": "19  连接",
    "section": "\n19.4 连接如何工作？",
    "text": "19.4 连接如何工作？\n既然你已经使用过几次连接了，是时候学习更多关于它们如何工作的知识了，重点是 x 中的每一行如何与 y 中的行匹配。我们将首先介绍一种连接的可视化表示法，使用下面定义的简单 tibble，并如 Figure 19.2 所示。在这些例子中，我们将使用一个名为 key 的单个键和一个单个值列（val_x 和 val_y），但这些思想都适用于多个键和多个值。\n\nx &lt;- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     3, \"x3\"\n)\ny &lt;- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     4, \"y3\"\n)\n\n\n\n\n\n\n\n\nFigure 19.2: 两个简单表格的图形表示。带颜色的 key 列将背景色映射到键值。灰色列代表被“携带”的值列。\n\n\n\n\nFigure 19.3 介绍了我们可视化表示法的基础。它将 x 和 y 之间的所有潜在匹配显示为从 x 的每一行和 y 的每一行画出的线的交点。输出中的行和列主要由 x 决定，所以 x 表是水平的，并与输出对齐。\n\n\n\n\n\n\n\nFigure 19.3: 要理解连接如何工作，将每种可能的匹配都考虑进去是很有用的。这里我们用一个连接线的网格来展示这一点。\n\n\n\n\n为了描述一种特定类型的连接，我们用点来表示匹配。匹配决定了输出中的行，这是一个新的数据框，包含键、x 值和 y 值。例如，Figure 19.4 展示了一个内连接，当且仅当键相等时，行才被保留。\n\n\n\n\n\n\n\nFigure 19.4: 内连接将 x 中的每一行与 y 中具有相同 key 值的行进行匹配。每个匹配都成为输出中的一行。\n\n\n\n\n我们可以应用相同的原则来解释外连接 (outer joins)，它保留出现在至少一个数据框中的观测值。这些连接通过向每个数据框添加一个额外的“虚拟”观测值来工作。这个观测值有一个在没有其他键匹配时能够匹配的键，并且值用 NA 填充。有三种类型的外连接：\n\n\n左连接 (left join) 保留 x 中的所有观测值，Figure 19.5。x 的每一行都在输出中被保留，因为它可以回退到匹配 y 中的一行 NA。\n\n\n\n\n\n\n\nFigure 19.5: 左连接的可视化表示，其中 x 中的每一行都出现在输出中。\n\n\n\n\n\n\n右连接 (right join) 保留 y 中的所有观测值，Figure 19.6。y 的每一行都在输出中被保留，因为它可以回退到匹配 x 中的一行 NA。输出仍然尽可能地与 x 匹配；来自 y 的任何多余的行都被添加到末尾。\n\n\n\n\n\n\n\nFigure 19.6: 右连接的可视化表示，其中 y 的每一行都出现在输出中。\n\n\n\n\n\n\n全连接 (full join) 保留出现在 x 或 y 中的所有观测值，Figure 19.7。x 和 y 的每一行都包含在输出中，因为 x 和 y 都有一个回退的 NA 行。同样，输出以 x 的所有行开始，然后是剩余的未匹配的 y 行。\n\n\n\n\n\n\n\nFigure 19.7: 全连接的可视化表示，其中 x 和 y 中的每一行都出现在输出中。\n\n\n\n\n\n\n另一种显示外连接类型差异的方法是使用维恩图，如 Figure 19.8 所示。然而，这不是一个很好的表示方法，因为尽管它可能会让你记起哪些行被保留了，但它未能说明列发生了什么。\n\n\n\n\n\n\n\nFigure 19.8: 维恩图显示内连接、左连接、右连接和全连接之间的差异。\n\n\n\n\n这里显示的连接是所谓的等值 (equi) 连接，其中如果键相等则行匹配。等值连接是最常见的连接类型，所以我们通常会省略等值前缀，只说“内连接”而不是“等值内连接”。我们将在 Section 19.5 中回到非等值连接。\n\n19.4.1 行匹配\n到目前为止，我们已经探讨了如果 x 中的一行与 y 中的零行或一行匹配会发生什么。如果它匹配多于一行会发生什么？要理解发生了什么，让我们首先将焦点缩小到 inner_join()，然后画一幅图，Figure 19.9。\n\n\n\n\n\n\n\nFigure 19.9: x 中的一行可以有三种匹配方式。x1 匹配 y 中的一行，x2 匹配 y 中的两行，x3 匹配 y 中的零行。注意，虽然 x 中有三行，输出中也有三行，但这些行之间没有直接的对应关系。\n\n\n\n\nx 中的一行有三种可能的结果：\n\n如果它不匹配任何东西，它就会被丢弃。\n如果它匹配 y 中的 1 行，它就会被保留。\n如果它匹配 y 中的多于 1 行，它会为每个匹配复制一次。\n\n原则上，这意味着输出中的行与 x 中的行之间没有保证的对应关系，但在实践中，这很少引起问题。然而，有一个特别危险的情况可能会导致行的组合爆炸。想象一下连接以下两个表：\n\ndf1 &lt;- tibble(key = c(1, 2, 2), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 &lt;- tibble(key = c(1, 2, 2), val_y = c(\"y1\", \"y2\", \"y3\"))\n\n虽然 df1 中的第一行只匹配 df2 中的一行，但第二行和第三行都匹配两行。这有时被称为多对多 (many-to-many)连接，并且会导致 dplyr 发出警告：\n\ndf1 |&gt; \n  inner_join(df2, join_by(key))\n#&gt; Warning in inner_join(df1, df2, join_by(key)): Detected an unexpected many-to-many relationship between `x` and `y`.\n#&gt; ℹ Row 2 of `x` matches multiple rows in `y`.\n#&gt; ℹ Row 2 of `y` matches multiple rows in `x`.\n#&gt; ℹ If a many-to-many relationship is expected, set `relationship =\n#&gt;   \"many-to-many\"` to silence this warning.\n#&gt; # A tibble: 5 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     2 x2    y3   \n#&gt; 4     2 x3    y2   \n#&gt; 5     2 x3    y3\n\n如果你是故意这样做的，你可以设置 relationship = \"many-to-many\"，正如警告所建议的那样。\n\n19.4.2 过滤连接\n匹配的数量也决定了过滤连接的行为。半连接保留 x 中在 y 中有一个或多个匹配的行，如 Figure 19.10 所示。反连接保留 x 中匹配 y 中零行的行，如 Figure 19.11 所示。在这两种情况下，只有匹配的存在是重要的；它匹配多少次并不重要。这意味着过滤连接从不像变连接那样复制行。\n\n\n\n\n\n\n\nFigure 19.10: 在半连接中，重要的是存在匹配；否则 y 中的值不会影响输出。\n\n\n\n\n\n\n\n\n\n\n\nFigure 19.11: 反连接是半连接的逆操作，从 x 中删除在 y 中有匹配的行。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-non-equi-joins",
    "href": "joins.html#sec-non-equi-joins",
    "title": "19  连接",
    "section": "\n19.5 非等值连接",
    "text": "19.5 非等值连接\n到目前为止，你只看到了等值连接，即如果 x 键等于 y 键，行就匹配。现在我们将放宽这个限制，讨论确定一对行是否匹配的其他方法。\n但在此之前，我们需要重新审视我们上面做的一个简化。在等值连接中，x 键和 y 键总是相等的，所以我们只需要在输出中显示一个。我们可以通过 keep = TRUE 来请求 dplyr 保留两个键，这导致了下面的代码和 Figure 19.12 中重新绘制的 inner_join()。\n\nx |&gt; inner_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 2 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2\n\n\n\n\n\n\n\n\nFigure 19.12: 一个内连接，在输出中显示 x 和 y 的键。\n\n\n\n\n当我们从等值连接转向其他类型时，我们将总是显示键，因为键值通常会不同。例如，我们可以不再仅仅在 x$key 和 y$key 相等时匹配，而是在 x$key 大于或等于 y$key 时匹配，这导致了 Figure 19.13。dplyr 的连接函数理解等值连接和非等值连接之间的这种区别，所以当你执行非等值连接时，它总是会显示两个键。\n\n\n\n\n\n\n\nFigure 19.13: 一个非等值连接，其中 x 键必须大于或等于 y 键。许多行会产生多个匹配。\n\n\n\n\n非等值连接不是一个特别有用的术语，因为它只告诉你连接不是什么，而不是它是什么。dplyr 通过识别四种特别有用的非等值连接类型来提供帮助：\n\n\n交叉连接 (Cross joins) 匹配每一对行。\n\n不等连接 (Inequality joins) 使用 &lt;、&lt;=、&gt; 和 &gt;= 而不是 ==。\n\n滚动连接 (Rolling joins) 类似于不等连接，但只找到最接近的匹配。\n\n重叠连接 (Overlap joins) 是一种特殊类型的不等连接，旨在处理范围。\n\n以下各节将更详细地描述这些类型中的每一种。\n\n19.5.1 交叉连接\n交叉连接匹配所有内容，如 Figure 19.14 所示，生成行的笛卡尔积。这意味着输出将有 nrow(x) * nrow(y) 行。\n\n\n\n\n\n\n\nFigure 19.14: 交叉连接将 x 中的每一行与 y 中的每一行进行匹配。\n\n\n\n\n交叉连接在生成排列时很有用。例如，下面的代码生成了所有可能的名字对。由于我们将 df 与自身连接，这有时被称为自连接 (self-join)。交叉连接使用一个不同的连接函数，因为当你匹配每一行时，内/左/右/全连接之间没有区别。\n\ndf &lt;- tibble(name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\ndf |&gt; cross_join(df)\n#&gt; # A tibble: 16 × 2\n#&gt;   name.x name.y\n#&gt;   &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 John   John  \n#&gt; 2 John   Simon \n#&gt; 3 John   Tracy \n#&gt; 4 John   Max   \n#&gt; 5 Simon  John  \n#&gt; 6 Simon  Simon \n#&gt; # ℹ 10 more rows\n\n\n19.5.2 不等连接\n不等连接使用 &lt;、&lt;=、&gt;= 或 &gt; 来限制可能的匹配集，如 Figure 19.13 和 Figure 19.15 所示。\n\n\n\n\n\n\n\nFigure 19.15: 一个不等连接，其中 x 与 y 在 x 的键小于 y 的键的行上连接。这在左上角形成了一个三角形。\n\n\n\n\n不等连接非常通用，以至于很难想出有意义的具体用例。一个有用的小技巧是使用它们来限制交叉连接，这样我们就可以生成所有组合而不是所有排列：\n\ndf &lt;- tibble(id = 1:4, name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\n\ndf |&gt; inner_join(df, join_by(id &lt; id))\n#&gt; # A tibble: 6 × 4\n#&gt;    id.x name.x  id.y name.y\n#&gt;   &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; \n#&gt; 1     1 John       2 Simon \n#&gt; 2     1 John       3 Tracy \n#&gt; 3     1 John       4 Max   \n#&gt; 4     2 Simon      3 Tracy \n#&gt; 5     2 Simon      4 Max   \n#&gt; 6     3 Tracy      4 Max\n\n\n19.5.3 滚动连接\n滚动连接是一种特殊类型的不等连接，在这种连接中，你得到的不是满足不等式的每一行，而只是最接近的那一行，如 Figure 19.16 所示。你可以通过添加 closest() 将任何不等连接变成滚动连接。例如，join_by(closest(x &lt;= y)) 匹配大于或等于 x 的最小的 y，而 join_by(closest(x &gt; y)) 匹配小于 x 的最大的 y。\n\n\n\n\n\n\n\nFigure 19.16: 滚动连接类似于大于或等于的不等连接，但只匹配第一个值。\n\n\n\n\n当你有两个日期表不能完美对齐，并且你想找到（例如）表 1 中在表 2 中某个日期之前（或之后）的最接近的日期时，滚动连接特别有用。\n例如，假设你负责你办公室的派对策划委员会。你的公司相当吝啬，所以你们不是举办单独的派对，而是每个季度只举办一次派对。确定派对何时举行的规则有点复杂：派对总是在星期一，你跳过一月的第一周，因为很多人都在度假，而 2022 年第三季度的第一个星期一是 7 月 4 日，所以那必须推迟一周。这导致了以下的派对日期：\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\"))\n)\n\n现在假设你有一张员工生日表：\n\nset.seed(123)\nemployees &lt;- tibble(\n  name = sample(babynames::babynames$name, 100),\n  birthday = ymd(\"2022-01-01\") + (sample(365, 100, replace = TRUE) - 1)\n)\nemployees\n#&gt; # A tibble: 100 × 2\n#&gt;   name     birthday  \n#&gt;   &lt;chr&gt;    &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22\n#&gt; 2 Orean    2022-06-26\n#&gt; 3 Kirstyn  2022-02-11\n#&gt; 4 Amparo   2022-11-11\n#&gt; 5 Belen    2022-03-25\n#&gt; 6 Rayshaun 2022-01-11\n#&gt; # ℹ 94 more rows\n\n对于每个员工，我们想找到在他们生日前（或生日当天）的最后一个派对日期。我们可以用一个滚动连接来表示这一点：\n\nemployees |&gt; \n  left_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 100 × 4\n#&gt;   name     birthday       q party     \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10\n#&gt; 2 Orean    2022-06-26     2 2022-04-04\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03\n#&gt; 5 Belen    2022-03-25     1 2022-01-10\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10\n#&gt; # ℹ 94 more rows\n\n然而，这种方法有一个问题：生日在 1 月 10 日之前的员工没有派对：\n\nemployees |&gt; \n  anti_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 2 × 2\n#&gt;   name   birthday  \n#&gt;   &lt;chr&gt;  &lt;date&gt;    \n#&gt; 1 Maks   2022-01-07\n#&gt; 2 Nalani 2022-01-04\n\n为了解决这个问题，我们需要用一种不同的方式来处理问题，即使用重叠连接。\n\n19.5.4 重叠连接\n重叠连接提供了三个使用不等连接来简化处理区间的辅助函数：\n\n\nbetween(x, y_lower, y_upper) 是 x &gt;= y_lower, x &lt;= y_upper 的简写。\n\nwithin(x_lower, x_upper, y_lower, y_upper) 是 x_lower &gt;= y_lower, x_upper &lt;= y_upper 的简写。\n\noverlaps(x_lower, x_upper, y_lower, y_upper) 是 x_lower &lt;= y_upper, x_upper &gt;= y_lower 的简写。\n\n让我们继续生日的例子，看看你可能会如何使用它们。我们上面使用的策略有一个问题：在 1 月 1-9 日的生日前没有派对。所以，明确每个派对跨越的日期范围，并为那些早生的生日做一个特殊情况处理可能会更好：\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-11\", \"2022-10-02\", \"2022-12-31\"))\n)\nparties\n#&gt; # A tibble: 4 × 4\n#&gt;       q party      start      end       \n#&gt;   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2     2 2022-04-04 2022-04-04 2022-07-11\n#&gt; 3     3 2022-07-11 2022-07-11 2022-10-02\n#&gt; 4     4 2022-10-03 2022-10-03 2022-12-31\n\nHadley 在数据录入方面非常糟糕，所以他还想检查派对期间是否有重叠。一种方法是使用自连接来检查是否有任何开始-结束区间与另一个重叠：\n\nparties |&gt; \n  inner_join(parties, join_by(overlaps(start, end, start, end), q &lt; q)) |&gt; \n  select(start.x, end.x, start.y, end.y)\n#&gt; # A tibble: 1 × 4\n#&gt;   start.x    end.x      start.y    end.y     \n#&gt;   &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 2022-04-04 2022-07-11 2022-07-11 2022-10-02\n\n哎呀，有重叠，所以让我们解决这个问题然后继续：\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-10\", \"2022-10-02\", \"2022-12-31\"))\n)\n\n现在我们可以将每个员工与他们的派对匹配起来了。这是一个使用 unmatched = \"error\" 的好地方，因为我们想快速发现是否有任何员工没有被分配到派对。\n\nemployees |&gt; \n  inner_join(parties, join_by(between(birthday, start, end)), unmatched = \"error\")\n#&gt; # A tibble: 100 × 6\n#&gt;   name     birthday       q party      start      end       \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2 Orean    2022-06-26     2 2022-04-04 2022-04-04 2022-07-10\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03 2022-10-03 2022-12-31\n#&gt; 5 Belen    2022-03-25     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; # ℹ 94 more rows\n\n\n19.5.5 练习\n\n\n你能解释一下在这个等值连接中键发生了什么吗？为什么它们不同？\n\nx |&gt; full_join(y, join_by(key == key))\n#&gt; # A tibble: 4 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt; \n#&gt; 4     4 &lt;NA&gt;  y3\n\nx |&gt; full_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 4 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2   \n#&gt; 3     3 x3       NA &lt;NA&gt; \n#&gt; 4    NA &lt;NA&gt;      4 y3\n\n\n在查找是否有任何派对期间与另一个派对期间重叠时，我们在 join_by() 中使用了 q &lt; q？为什么？如果移除这个不等式会发生什么？",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "joins.html#总结",
    "href": "joins.html#总结",
    "title": "19  连接",
    "section": "\n19.6 总结",
    "text": "19.6 总结\n在本章中，你学习了如何使用变连接和过滤连接来组合来自一对数据框的数据。在此过程中，你学习了如何识别键，以及主键和外键之间的区别。你也理解了连接如何工作以及如何计算输出将有多少行。最后，你对非等值连接的力量有了初步的了解，并看到了一些有趣的用例。\n本章结束了本书的“转换”部分，该部分的重点是你可以用于单个列和 tibble 的工具。你学习了用于处理逻辑向量、数字和完整表格的 dplyr 和基础函数，用于处理字符串的 stringr 函数，用于处理日期时间的 lubridate 函数，以及用于处理因子的 forcats 函数。\n在本书的下一部分，你将学习更多关于如何将各种类型的数据以整洁的形式导入 R 的知识。",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "joins.html#footnotes",
    "href": "joins.html#footnotes",
    "title": "19  连接",
    "section": "",
    "text": "记住，在 RStudio 中你也可以使用 View() 来避免这个问题。↩︎\n这并非 100% 正确，但每当不是这样时你都会收到一个警告。↩︎",
    "crumbs": [
      "数据转换",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>连接</span>"
    ]
  },
  {
    "objectID": "import.html",
    "href": "import.html",
    "title": "导入",
    "section": "",
    "text": "在本书的这一部分，你将学习如何将更广泛的数据导入 R，以及如何将其转化为对分析有用的形式。有时，这只是调用相应数据导入包中的一个函数那么简单。但在更复杂的情况下，为了得到你更喜欢使用的整洁矩形数据，可能需要进行整理和转换。\n\n\n\n\n\n\n\nFigure 1: 数据导入是数据科学过程的开始；没有数据你就无法进行数据科学！\n\n\n\n\n在本书的这一部分，你将学习如何访问以下列方式存储的数据：\n\n在 20  电子表格 中，你将学习如何从 Excel 电子表格和谷歌表格 (Google Sheets) 导入数据。\n在 21  数据库 中，你将学习如何从数据库中获取数据并导入 R（你还将学到一点如何将数据从 R 导出到数据库）。\n在 22  Arrow 中，你将学习 Arrow，这是一个处理内存外 (out-of-memory) 数据的强大工具，特别是当数据存储在 parquet 格式中时。\n在 23  层级数据 中，你将学习如何处理层级数据，包括由 JSON 格式存储的数据产生的深度嵌套列表。\n在 24  网络抓取 中，你将学习网页“抓取” (web scraping)，即从网页中提取数据的艺术和科学。\n\n我们在这里没有讨论两个重要的 tidyverse 包：haven 和 xml2。如果你正在处理来自 SPSS、Stata 和 SAS 文件的数据，请查看 haven 包，https://haven.tidyverse.org。如果你正在处理 XML 数据，请查看 xml2 包，https://xml2.r-lib.org。否则，你需要做一些研究来确定你需要使用哪个包；谷歌是你的好朋友 😃。",
    "crumbs": [
      "导入"
    ]
  },
  {
    "objectID": "spreadsheets.html",
    "href": "spreadsheets.html",
    "title": "20  电子表格",
    "section": "",
    "text": "20.1 引言\n在 Chapter 7 中，你学习了如何从像 .csv 和 .tsv 这样的纯文本文件导入数据。现在是时候学习如何从电子表格中获取数据了，无论是 Excel 电子表格还是谷歌表格 (Google Sheet)。这将在你于 Chapter 7 中学到的许多知识的基础上进行，但我们也将讨论处理来自电子表格的数据时需要考虑的额外因素和复杂性。\n如果你或你的合作者正在使用电子表格来组织数据，我们强烈建议阅读 Karl Broman 和 Kara Woo 的论文“电子表格中的数据组织”(Data Organization in Spreadsheets)：https://doi.org/10.1080/00031305.2017.1375989。这篇论文中提出的最佳实践将在你将数据从电子表格导入 R 进行分析和可视化时为你省去很多麻烦。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>电子表格</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#excel",
    "href": "spreadsheets.html#excel",
    "title": "20  电子表格",
    "section": "\n20.2 Excel",
    "text": "20.2 Excel\nMicrosoft Excel 是一款广泛使用的电子表格软件程序，数据在电子表格文件中的工作表 (worksheets) 里进行组织。\n\n20.2.1 前提条件\n在本节中，你将学习如何使用 readxl 包在 R 中加载来自 Excel 电子表格的数据。这个包不是 tidyverse 的核心包，所以你需要显式地加载它，但当你安装 tidyverse 包时它会自动被安装。稍后，我们还将使用 writexl 包，它允许我们创建 Excel 电子表格。\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(writexl)\n\n\n20.2.2 入门\nreadxl 的大部分函数允许你将 Excel 电子表格加载到 R 中：\n\n\nread_xls() 读取 xls 格式的 Excel 文件。\n\nread_xlsx() 读取 xlsx 格式的 Excel 文件。\n\nread_excel() 可以读取 xls 和 xlsx 两种格式的文件。它会根据输入来猜测文件类型。\n\n这些函数的语法都与我们之前介绍的用于读取其他类型文件的函数类似，例如 read_csv()、read_table() 等。在本章的其余部分，我们将重点使用 read_excel()。\n\n20.2.3 读取 Excel 电子表格\nFigure 20.1 展示了我们即将读入 R 的电子表格在 Excel 中的样子。这个电子表格可以从 https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w/ 下载为 Excel 文件。\n\n\n\n\n\n\n\nFigure 20.1: 在 Excel 中名为 students.xlsx 的电子表格。\n\n\n\n\nread_excel() 的第一个参数是要读取的文件的路径。\n\nstudents &lt;- read_excel(\"data/students.xlsx\")\n\nread_excel() 会将文件读作一个 tibble。\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\n数据中有六名学生，每名学生有五个变量。然而，这个数据集中有几件事情我们可能想要处理：\n\n\n列名各式各样，不统一。你可以提供遵循一致格式的列名；我们推荐使用 col_names 参数来指定 snake_case (蛇形命名法) 格式的列名。\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\")\n)\n#&gt; # A tibble: 7 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1 Student ID Full Name        favourite.food     mealPlan            AGE  \n#&gt; 2 1          Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 3 2          Barclay Lynn     French fries       Lunch only          5    \n#&gt; 4 3          Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 5 4          Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 6 5          Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 7 6          Güvenç Attila    Ice cream          Lunch only          6\n\n不幸的是，这并没有完全解决问题。我们现在有了想要的变量名，但之前作为标题行的那一行现在作为第一个观测值出现在数据中。你可以使用 skip 参数明确跳过那一行。\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\n在 favourite_food 列中，其中一个观测值是 N/A，代表“不可用”(not available)，但它目前没有被识别为 NA（注意这个 N/A 和列表中第四名学生的年龄 NA 之间的区别）。你可以使用 na 参数指定哪些字符串应该被识别为 NA。默认情况下，只有 \"\"（空字符串，或者在从电子表格读取时，是一个空单元格或带有公式 =NA() 的单元格）被识别为 NA。\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\")\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\n另一个遗留问题是 age 被读作字符变量，但它真的应该是数值型。就像使用 read_csv() 及其系列函数从平面文件读取数据一样，你可以向 read_excel() 提供一个 col_types 参数，并为你读入的变量指定列类型。不过，语法有点不同。你的选项是 \"skip\"、\"guess\"、\"logical\"、\"numeric\"、\"date\"、\"text\" 或 \"list\"。\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"numeric\")\n)\n#&gt; Warning: Expecting numeric in E6 / R6C5: got 'five'\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch    NA\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n然而，这也没有产生我们期望的结果。通过指定 age 应该是数值型，我们将一个带有非数值条目（其值为 five）的单元格变成了 NA。在这种情况下，我们应该将 age 读作 \"text\"，然后在数据加载到 R 后再进行更改。\n\nstudents &lt;- read_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"text\")\n)\n\nstudents &lt;- students |&gt;\n  mutate(\n    age = if_else(age == \"five\", \"5\", age),\n    age = parse_number(age)\n  )\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\n我们通过多个步骤和反复试错才将数据加载成我们想要的确切格式，这并不意外。数据科学是一个迭代的过程，与从其他纯文本、矩形数据文件读取数据相比，从电子表格读取数据时的迭代过程可能更加繁琐，因为人们倾向于将数据输入电子表格，并不仅将其用于数据存储，还用于共享和交流。\n除非你加载并查看数据，否则没有办法确切知道数据会是什么样子。嗯，实际上有一种方法。你可以在 Excel 中打开文件并看一眼。如果你打算这样做，我们建议复制一份 Excel 文件进行交互式打开和浏览，同时保持原始数据文件不变，并从这个未动过的文件中读取到 R。这将确保你在检查电子表格时不会意外覆盖任何内容。你也不应该害怕做我们在这里做的事情：加载数据，看一眼，调整你的代码，再次加载，重复这个过程直到你对结果满意为止。\n\n20.2.4 读取工作表\n电子表格与平面文件的一个重要区别是多个工作表 (sheets) 的概念。Figure 20.2 展示了一个包含多个工作表的 Excel 电子表格。数据来自 palmerpenguins 包，你可以从 https://docs.google.com/spreadsheets/d/1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY/ 下载这个电子表格作为 Excel 文件。每个工作表包含了来自不同岛屿的企鹅信息，这些岛屿是数据收集的地点。\n\n\n\n\n\n\n\nFigure 20.2: 在 Excel 中名为 penguins.xlsx 的电子表格，包含三个工作表。\n\n\n\n\n你可以使用 read_excel() 中的 sheet 参数从电子表格中读取单个工作表。默认情况下，也就是我们到目前为止一直依赖的，是第一个工作表。\n\nread_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\")\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm     bill_depth_mm      flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;            \n#&gt; 1 Adelie  Torgersen 39.1               18.7               181              \n#&gt; 2 Adelie  Torgersen 39.5               17.399999999999999 186              \n#&gt; 3 Adelie  Torgersen 40.299999999999997 18                 195              \n#&gt; 4 Adelie  Torgersen NA                 NA                 NA               \n#&gt; 5 Adelie  Torgersen 36.700000000000003 19.3               193              \n#&gt; 6 Adelie  Torgersen 39.299999999999997 20.6               190              \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;chr&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\n一些看起来包含数值数据的变量被读作字符型，因为字符串 \"NA\" 没有被识别为真正的 NA。\n\npenguins_torgersen &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\", na = \"NA\")\n\npenguins_torgersen\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\n或者，你可以使用 excel_sheets() 来获取 Excel 电子表格中所有工作表的信息，然后读取你感兴趣的一个或多个。\n\nexcel_sheets(\"data/penguins.xlsx\")\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\n一旦你知道了工作表的名称，你就可以用 read_excel() 单独读取它们。\n\npenguins_biscoe &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Biscoe Island\", na = \"NA\")\npenguins_dream  &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Dream Island\", na = \"NA\")\n\n在这种情况下，完整的企鹅数据集分布在电子表格的三个工作表中。每个工作表有相同的列数，但行数不同。\n\ndim(penguins_torgersen)\n#&gt; [1] 52  8\ndim(penguins_biscoe)\n#&gt; [1] 168   8\ndim(penguins_dream)\n#&gt; [1] 124   8\n\n我们可以用 bind_rows() 将它们合并在一起。\n\npenguins &lt;- bind_rows(penguins_torgersen, penguins_biscoe, penguins_dream)\npenguins\n#&gt; # A tibble: 344 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 338 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\n在 Chapter 26 中，我们将讨论如何用不重复的代码来完成这类任务。\n\n20.2.5 读取部分工作表\n由于许多人使用 Excel 电子表格进行展示和数据存储，因此在电子表格中发现不属于你想读入 R 的数据的单元格条目是相当普遍的。Figure 20.3 展示了这样一个电子表格：在工作表的中间看起来像一个数据框，但在数据上方和下方有无关的文本。\n\n\n\n\n\n\n\nFigure 20.3: 在 Excel 中名为 deaths.xlsx 的电子表格。\n\n\n\n\n这个电子表格是 readxl 包中提供的示例电子表格之一。你可以使用 readxl_example() 函数在你系统上该包安装的目录中找到这个电子表格。这个函数返回电子表格的路径，你可以像往常一样在 read_excel() 中使用它。\n\ndeaths_path &lt;- readxl_example(\"deaths.xlsx\")\ndeaths &lt;- read_excel(deaths_path)\n#&gt; New names:\n#&gt; • `` -&gt; `...2`\n#&gt; • `` -&gt; `...3`\n#&gt; • `` -&gt; `...4`\n#&gt; • `` -&gt; `...5`\n#&gt; • `` -&gt; `...6`\ndeaths\n#&gt; # A tibble: 18 × 6\n#&gt;   `Lots of people`    ...2       ...3  ...4     ...5          ...6           \n#&gt;   &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;          \n#&gt; 1 simply cannot resi… &lt;NA&gt;       &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          some notes     \n#&gt; 2 at                  the        top   &lt;NA&gt;     of            their spreadsh…\n#&gt; 3 or                  merging    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          cells          \n#&gt; 4 Name                Profession Age   Has kids Date of birth Date of death  \n#&gt; 5 David Bowie         musician   69    TRUE     17175         42379          \n#&gt; 6 Carrie Fisher       actor      60    TRUE     20749         42731          \n#&gt; # ℹ 12 more rows\n\n顶部三行和底部四行不属于数据框。可以使用 skip 和 n_max 参数来消除这些多余的行，但我们建议使用单元格范围。在 Excel 中，左上角的单元格是 A1。当你向右移动列时，单元格标签会沿着字母表向下移动，即 B1、C1 等。当你向下移动一列时，单元格标签中的数字会增加，即 A2、A3 等。\n这里我们想要读入的数据从单元格 A5 开始，到单元格 F15 结束。在电子表格表示法中，这是 A5:F15，我们将其提供给 range 参数：\n\nread_excel(deaths_path, range = \"A5:F15\")\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.2.6 数据类型\n在 CSV 文件中，所有值都是字符串。这并不特别忠实于数据，但很简单：一切都是字符串。\nExcel 电子表格中的底层数据更复杂。一个单元格可以是以下四种类型之一：\n\n布尔值，如 TRUE、FALSE 或 NA。\n数字，如 “10” 或 “10.5”。\n日期时间，也可以包含时间，如 “11/1/21” 或 “11/1/21 3:00 PM”。\n文本字符串，如 “ten”。\n\n处理电子表格数据时，重要的是要记住，底层数据可能与你在单元格中看到的非常不同。例如，Excel 没有整数的概念。所有数字都存储为浮点数，但你可以选择以可自定义的小数位数来显示数据。同样，日期实际上是作为数字存储的，具体来说是从 1970 年 1 月 1 日以来的秒数。你可以通过在 Excel 中应用格式来自定义日期的显示方式。令人困惑的是，也可能有一个看起来像数字但实际上是字符串的东西（例如，在 Excel 单元格中输入 '10）。\n这些底层数据存储方式与显示方式之间的差异，在数据加载到 R 时可能会导致意外。默认情况下，readxl 会猜测给定列的数据类型。一个推荐的工作流程是让 readxl 猜测列类型，确认你对猜测的列类型满意，如果不满意，则返回并重新导入，并指定 col_types，如 Section 20.2.3 所示。\n另一个挑战是当你的 Excel 电子表格中的一列混合了这些类型时，例如，一些单元格是数值型，一些是文本，一些是日期。在将数据导入 R 时，readxl 必须做出一些决定。在这些情况下，你可以将该列的类型设置为 \"list\"，这会将该列加载为一个长度为 1 的向量列表，其中列表的每个元素的类型都会被猜测。\n\n\n\n\n\n\n有时数据以更奇特的方式存储，比如单元格背景的颜色，或者文本是否加粗。在这种情况下，你可能会发现 tidyxl 包 很有用。有关处理来自 Excel 的非表格数据的策略，请参见 https://nacnudus.github.io/spreadsheet-munging-strategies/。\n\n\n\n\n20.2.7 写入 Excel\n让我们创建一个小的数据框，然后可以把它写出去。注意 item 是一个因子，quantity 是一个整数。\n\nbake_sale &lt;- tibble(\n  item       = factor(c(\"brownie\", \"cupcake\", \"cookie\")),\n  quantity = c(10, 5, 8)\n)\n\nbake_sale\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;fct&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\n你可以使用 writexl 包 中的 write_xlsx() 函数将数据写回到磁盘上的 Excel 文件中：\n\nwrite_xlsx(bake_sale, path = \"data/bake-sale.xlsx\")\n\nFigure 20.4 展示了数据在 Excel 中的样子。注意列名被包含并加粗了。可以通过将 col_names 和 format_headers 参数设置为 FALSE 来关闭这些功能。\n\n\n\n\n\n\n\nFigure 20.4: 在 Excel 中名为 bake-sale.xlsx 的电子表格。\n\n\n\n\n就像从 CSV 读取一样，当我们再次读入数据时，关于数据类型的信息会丢失。这也使得 Excel 文件不适合用于缓存中间结果。有关替代方案，请参见 Section 7.5。\n\nread_excel(\"data/bake-sale.xlsx\")\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\n\n20.2.8 格式化输出\nwritexl 包是一个用于写入简单 Excel 电子表格的轻量级解决方案，但如果你对额外的功能感兴趣，比如写入电子表格中的工作表和设置样式，你会想使用 openxlsx 包。我们在这里不会详细介绍使用这个包的细节，但我们建议阅读 https://ycphs.github.io/openxlsx/articles/Formatting.html，那里有关于用 openxlsx 从 R 写入 Excel 的数据的进一步格式化功能的广泛讨论。\n注意，这个包不是 tidyverse 的一部分，所以函数和工作流程可能会感觉不熟悉。例如，函数名是驼峰式命名法 (camelCase)，多个函数不能用管道符组合，并且参数的顺序可能与 tidyverse 中的不同。然而，这没关系。随着你的 R 学习和使用扩展到本书之外，你会遇到各种 R 包中使用的许多不同风格，你可能会用它们来在 R 中完成特定的目标。熟悉一个新包的编码风格的一个好方法是运行函数文档中提供的示例，以感受其语法和输出格式，以及阅读包可能附带的任何小品文 (vignettes)。\n\n20.2.9 练习\n\n\n在一个 Excel 文件中，创建以下数据集并将其保存为 survey.xlsx。或者，你可以从这里下载 Excel 文件。\n\n\n\n\n\n\n\n\n然后，将其读入 R，将 survey_id 作为字符变量，n_pets 作为数值变量。\n\n#&gt; # A tibble: 6 × 2\n#&gt;   survey_id n_pets\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 1              0\n#&gt; 2 2              1\n#&gt; 3 3             NA\n#&gt; 4 4              2\n#&gt; 5 5              2\n#&gt; 6 6             NA\n\n\n\n在另一个 Excel 文件中，创建以下数据集并将其保存为 roster.xlsx。或者，你可以从这里下载 Excel 文件。\n\n\n\n\n\n\n\n\n然后，将其读入 R。结果数据框应命名为 roster，并应如下所示。\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12\n\n\n\n在一个新的 Excel 文件中，创建以下数据集并将其保存为 sales.xlsx。或者，你可以从这里下载 Excel 文件。\n\n\n\n\n\n\n\n\n\n读入 sales.xlsx 并保存为 sales。数据框应如下所示，列名为 id 和 n，有 9 行。\n\n\n#&gt; # A tibble: 9 × 2\n#&gt;   id      n    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 Brand 1 n    \n#&gt; 2 1234    8    \n#&gt; 3 8721    2    \n#&gt; 4 1822    3    \n#&gt; 5 Brand 2 n    \n#&gt; 6 3333    1    \n#&gt; 7 2156    3    \n#&gt; 8 3987    6    \n#&gt; 9 3216    5\n\n\n进一步修改 sales，使其成为以下具有三列（brand、id 和 n）和 7 行数据的整洁格式。注意 id 和 n 是数值型，brand 是字符变量。\n\n\n#&gt; # A tibble: 7 × 3\n#&gt;   brand      id     n\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Brand 1  1234     8\n#&gt; 2 Brand 1  8721     2\n#&gt; 3 Brand 1  1822     3\n#&gt; 4 Brand 2  3333     1\n#&gt; 5 Brand 2  2156     3\n#&gt; 6 Brand 2  3987     6\n#&gt; 7 Brand 2  3216     5\n\n\n重新创建 bake_sale 数据框，使用 openxlsx 包中的 write.xlsx() 函数将其写出到一个 Excel 文件中。\n在 Chapter 7 中，你学习了 janitor::clean_names() 函数，可以将列名转换为蛇形命名法 (snake case)。读入我们本节前面介绍的 students.xlsx 文件，并使用此函数来“清理”列名。\n如果你尝试用 read_xls() 读取一个扩展名为 .xlsx 的文件会发生什么？",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>电子表格</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#谷歌表格",
    "href": "spreadsheets.html#谷歌表格",
    "title": "20  电子表格",
    "section": "\n20.3 谷歌表格",
    "text": "20.3 谷歌表格\n谷歌表格 (Google Sheets) 是另一个广泛使用的电子表格程序。它是免费且基于网络的。就像 Excel 一样，在谷歌表格中，数据在电子表格文件中的工作表 (worksheets) 里进行组织。\n\n20.3.1 前提条件\n本节也将重点介绍电子表格，但这次你将使用 googlesheets4 包从谷歌表格中加载数据。这个包同样不是 tidyverse 的核心包，你需要显式地加载它。\n\nlibrary(googlesheets4)\nlibrary(tidyverse)\n\n关于包名的一个快速说明：googlesheets4 使用了 Sheets API v4 来提供一个 R 接口到谷歌表格，因此得名。\n\n20.3.2 入门\ngooglesheets4 包的主要函数是 read_sheet()，它从一个 URL 或文件 ID 读取一个谷歌表格。这个函数还有一个别名 range_read()。\n你也可以用 gs4_create() 创建一个全新的表格，或者用 sheet_write() 及其系列函数写入一个现有的表格。\n在本节中，我们将使用与 Excel 部分相同的数据集，以突出从 Excel 和谷歌表格读取数据的工作流程之间的相似点和不同点。readxl 和 googlesheets4 包都被设计为模仿 readr 包的功能，后者提供了你在 Chapter 7 中见过的 read_csv() 函数。因此，许多任务可以通过简单地将 read_excel() 替换为 read_sheet() 来完成。然而，你也会看到 Excel 和谷歌表格的行为并不完全相同，因此其他任务可能需要对函数调用进行进一步的更新。\n\n20.3.3 读取谷歌表格\nFigure 20.5 展示了我们即将读入 R 的电子表格在谷歌表格中的样子。这与 Figure 20.1 中的数据集相同，只是它存储在谷歌表格中而不是 Excel 中。\n\n\n\n\n\n\n\nFigure 20.5: 在浏览器窗口中名为 students 的谷歌表格。\n\n\n\n\nread_sheet() 的第一个参数是要读取的文件的 URL，它返回一个 tibble： https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w。 这些 URL 不好用，所以你通常会想通过其 ID 来识别一个表格。\n\ngs4_deauth()\n\n\nstudents_sheet_id &lt;- \"1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w\"\nstudents &lt;- read_sheet(students_sheet_id)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range Sheet1.\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE   \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;list&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          &lt;dbl&gt; \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          &lt;dbl&gt; \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch &lt;dbl&gt; \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NULL&gt;\n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch &lt;chr&gt; \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          &lt;dbl&gt;\n\n就像我们对 read_excel() 做的那样，我们可以向 read_sheet() 提供列名、NA 字符串和列类型。\n\nstudents &lt;- read_sheet(\n  students_sheet_id,\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = \"dcccc\"\n)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range 2:10000000.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n注意，我们在这里定义列类型的方式略有不同，使用了短代码。例如，“dcccc” 代表 “double, character, character, character, character”。\n也可以从谷歌表格中读取单个工作表。让我们从企鹅谷歌表格中读取 “Torgersen Island” 工作表：\n\npenguins_sheet_id &lt;- \"1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY\"\nread_sheet(penguins_sheet_id, sheet = \"Torgersen Island\")\n#&gt; ✔ Reading from penguins.\n#&gt; ✔ Range ''Torgersen Island''.\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;list&gt;         &lt;list&gt;        &lt;list&gt;           \n#&gt; 1 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 2 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 3 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 4 Adelie  Torgersen &lt;chr [1]&gt;      &lt;chr [1]&gt;     &lt;chr [1]&gt;        \n#&gt; 5 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 6 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;list&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\n你可以使用 sheet_names() 获取一个谷歌表格中所有工作表的列表：\n\nsheet_names(penguins_sheet_id)\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\n最后，就像使用 read_excel() 一样，我们可以通过在 read_sheet() 中定义一个 range 来读取谷歌表格的一部分。注意，我们下面也使用了 gs4_example() 函数来定位 googlesheets4 包附带的一个示例谷歌表格。\n\ndeaths_url &lt;- gs4_example(\"deaths\")\ndeaths &lt;- read_sheet(deaths_url, range = \"A5:F15\")\n#&gt; ✔ Reading from deaths.\n#&gt; ✔ Range A5:F15.\ndeaths\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.3.4 写入谷歌表格\n你可以使用 write_sheet() 从 R 写入谷歌表格。第一个参数是要写入的数据框，第二个参数是要写入的谷歌表格的名称（或其他标识符）：\n\nwrite_sheet(bake_sale, ss = \"bake-sale\")\n\n如果你想将数据写入谷歌表格中的特定（工作）表，你也可以使用 sheet 参数来指定。\n\nwrite_sheet(bake_sale, ss = \"bake-sale\", sheet = \"Sales\")\n\n\n20.3.5 身份验证\n虽然你可以从未经身份验证的公共谷歌表格中读取数据，并使用 gs4_deauth()，但读取私有表格或写入表格需要进行身份验证，以便 googlesheets4 可以查看和管理你的谷歌表格。\n当你尝试读取一个需要身份验证的表格时，googlesheets4 会将你引导到一个网页浏览器，提示你登录你的谷歌账户并授权其代表你操作谷歌表格。然而，如果你想指定一个特定的谷歌账户、身份验证范围等，你可以使用 gs4_auth() 来实现，例如，gs4_auth(email = \"mine@example.com\")，这将强制使用与特定电子邮件关联的令牌。有关进一步的身份验证细节，我们建议阅读 googlesheets4 的 auth 小品文文档：https://googlesheets4.tidyverse.org/articles/auth.html。\n\n20.3.6 练习\n\n从 Excel 和谷歌表格中读取本章早些时候的 students 数据集，不向 read_excel() 和 read_sheet() 函数提供任何额外参数。结果在 R 中的数据框完全相同吗？如果不是，它们有何不同？\n从 https://pos.it/r4ds-survey 读取名为 survey 的谷歌表格，将 survey_id 作为字符变量，n_pets 作为数值变量。\n\n从 https://pos.it/r4ds-roster 读取名为 roster 的谷歌表格。结果数据框应命名为 roster，并应如下所示。\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>电子表格</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#总结",
    "href": "spreadsheets.html#总结",
    "title": "20  电子表格",
    "section": "\n20.4 总结",
    "text": "20.4 总结\nMicrosoft Excel 和谷歌表格是两种最流行的电子表格系统。能够直接从 R 中与存储在 Excel 和谷歌表格文件中的数据进行交互是一项超能力！在本章中，你学习了如何使用 readxl 包中的 read_excel() 从 Excel 的电子表格中读取数据到 R，以及如何使用 googlesheets4 包中的 read_sheet() 从谷歌表格中读取数据。这些函数的工作方式非常相似，并且有类似的参数用于指定列名、NA 字符串、在读取文件时跳过顶部的行等。此外，这两个函数都使得可以从一个电子表格中读取单个工作表。\n另一方面，写入 Excel 文件需要一个不同的包和函数 (writexl::write_xlsx())，而你可以使用 googlesheets4 包中的 write_sheet() 来写入谷歌表格。\n在下一章中，你将学习一个不同的数据源以及如何从该源读取数据到 R：数据库。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>电子表格</span>"
    ]
  },
  {
    "objectID": "databases.html",
    "href": "databases.html",
    "title": "21  数据库",
    "section": "",
    "text": "21.1 引言\n大量的数据存储在数据库中，因此了解如何访问这些数据至关重要。有时你可以请人为你下载一个快照到 .csv 文件中，但这很快就会变得痛苦：每当你需要做一次更改，你就必须与另一个人沟通。你希望能够直接访问数据库，在需要时获取所需的数据。\n在本章中，你将首先学习 DBI 包的基础知识：如何使用它连接到数据库，然后用 SQL1 查询检索数据。SQL，即结构化查询语言 (structured query language) 的缩写，是数据库的通用语言，也是所有数据科学家需要学习的一门重要语言。话虽如此，我们不会从 SQL 开始，而是会教你 dbplyr，它可以将你的 dplyr 代码翻译成 SQL。我们将以此为途径，教你一些 SQL 最重要的特性。在本章结束时，你不会成为 SQL 大师，但你将能够识别最重要的组件并理解它们的作用。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#引言",
    "href": "databases.html#引言",
    "title": "21  数据库",
    "section": "",
    "text": "21.1.1 前提条件\n在本章中，我们将介绍 DBI 和 dbplyr。DBI 是一个底层接口，用于连接数据库和执行 SQL；dbplyr 是一个高层接口，它将你的 dplyr 代码翻译成 SQL 查询，然后用 DBI 执行它们。\n\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(tidyverse)",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#数据库基础",
    "href": "databases.html#数据库基础",
    "title": "21  数据库",
    "section": "\n21.2 数据库基础",
    "text": "21.2 数据库基础\n在最简单的层面上，你可以把数据库看作是数据框的集合，在数据库术语中称为表 (tables)。就像数据框一样，数据库表是命名列的集合，其中一列中的每个值都是相同类型的。数据框和数据库表之间有三个高层次的区别：\n\n数据库表存储在磁盘上，可以任意大。数据框存储在内存中，并且有根本的大小限制（尽管这个限制对于许多问题来说仍然足够大）。\n数据库表几乎总是有索引。就像书的索引一样，数据库索引可以快速找到感兴趣的行，而无需查看每一行。数据框和 tibble 没有索引，但 data.table 有，这是它们速度快的原因之一。\n大多数传统数据库都是为快速收集数据而优化的，而不是为分析现有数据。这些数据库被称为行式 (row-oriented) 数据库，因为数据是逐行存储的，而不是像 R 那样逐列存储。最近，列式 (column-oriented) 数据库得到了很大发展，它使得分析现有数据变得更快。\n\n数据库由数据库管理系统（DBMS）运行，DBMS 有三种基本形式：\n\n\n客户端-服务器 (Client-server) DBMS 运行在一台强大的中央服务器上，你从你的计算机（客户端）连接到它。它们非常适合在组织内与多人共享数据。流行的客户端-服务器 DBMS 包括 PostgreSQL、MariaDB、SQL Server 和 Oracle。\n\n云 (Cloud) DBMS，如 Snowflake、Amazon 的 RedShift 和 Google 的 BigQuery，与客户端-服务器 DBMS 类似，但它们运行在云端。这意味着它们可以轻松处理极大的数据集，并可以根据需要自动提供更多的计算资源。\n\n进程内 (In-process) DBMS，如 SQLite 或 duckdb，完全在你的计算机上运行。它们非常适合处理你是主要用户的大型数据集。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#连接到数据库",
    "href": "databases.html#连接到数据库",
    "title": "21  数据库",
    "section": "\n21.3 连接到数据库",
    "text": "21.3 连接到数据库\n要从 R 连接到数据库，你需要使用一对包：\n\n你总是会使用 DBI（database interface，数据库接口），因为它提供了一组通用函数，用于连接数据库、上传数据、运行 SQL 查询等。\n你还需要一个为你所连接的 DBMS 定制的包。这个包将通用的 DBI 命令翻译成特定 DBMS 所需的具体指令。通常每个 DBMS 都有一个包，例如 RPostgres 用于 PostgreSQL，RMariaDB 用于 MySQL。\n\n如果找不到你的 DBMS 的特定包，你通常可以使用 odbc 包来代替。它使用许多 DBMS 都支持的 ODBC 协议。odbc 需要多一点设置，因为你还需要安装一个 ODBC 驱动程序，并告诉 odbc 包在哪里找到它。\n具体来说，你使用 DBI::dbConnect() 创建一个数据库连接。第一个参数选择 DBMS2，然后第二个及后续的参数描述如何连接到它（即它在哪里以及你访问它所需的凭据）。下面的代码展示了几个典型的例子：\n\ncon &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(), \n  username = \"foo\"\n)\ncon &lt;- DBI::dbConnect(\n  RPostgres::Postgres(), \n  hostname = \"databases.mycompany.com\", \n  port = 1234\n)\n\n连接的具体细节因 DBMS 而异，所以很遗憾我们无法在这里涵盖所有细节。这意味着你需要自己做一些研究。通常你可以问你团队中的其他数据科学家或与你的 DBA（database administrator，数据库管理员）交谈。初始设置通常需要一些小调整（可能还需要一些谷歌搜索）才能正确，但你通常只需要做一次。\n\n21.3.1 本书中\n为本书设置一个客户端-服务器或云 DBMS 会很麻烦，所以我们将使用一个完全存在于 R 包中的进程内 DBMS：duckdb。多亏了 DBI 的魔力，使用 duckdb 和任何其他 DBMS 之间的唯一区别就是你如何连接到数据库。这使得它非常适合教学，因为你可以轻松地运行这段代码，也可以轻松地将你学到的东西应用到其他地方。\n连接到 duckdb 特别简单，因为默认设置会创建一个临时数据库，当你退出 R 时它会被删除。这对于学习来说很棒，因为它保证了每次重启 R 时你都会从一个干净的状态开始：\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\n\nduckdb 是一个高性能的数据库，它非常适合数据科学家的需求。我们在这里使用它是因为它非常容易上手，但它也能够以极快的速度处理千兆字节的数据。如果你想在一个真实的数据分析项目中使用 duckdb，你还需要提供 dbdir 参数来创建一个持久性数据库，并告诉 duckdb 在哪里保存它。假设你正在使用一个项目（Chapter 6），把它存储在当前项目的 duckdb 目录中是合理的：\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), dbdir = \"duckdb\")\n\n\n21.3.2 加载一些数据\n由于这是一个新的数据库，我们需要先添加一些数据。这里我们将使用 DBI::dbWriteTable() 添加 ggplot2 中的 mpg 和 diamonds 数据集。dbWriteTable() 最简单的用法需要三个参数：一个数据库连接，要在数据库中创建的表的名称，以及一个数据的数据框。\n\ndbWriteTable(con, \"mpg\", ggplot2::mpg)\ndbWriteTable(con, \"diamonds\", ggplot2::diamonds)\n\n如果你在一个真实的项目中使用 duckdb，我们强烈建议你学习 duckdb_read_csv() 和 duckdb_register_arrow()。它们为你提供了强大且高效的方式来快速将数据直接加载到 duckdb 中，而无需先将其加载到 R 中。我们还将在 Section 26.4.1 中展示一个将多个文件加载到数据库的有用技巧。\n\n21.3.3 DBI 基础\n你可以通过使用其他几个 DBI 函数来检查数据是否已正确加载：dbListTables() 列出数据库中的所有表3，dbReadTable() 检索一个表的内容。\n\ndbListTables(con)\n#&gt; [1] \"diamonds\" \"mpg\"\n\ncon |&gt; \n  dbReadTable(\"diamonds\") |&gt; \n  as_tibble()\n#&gt; # A tibble: 53,940 × 10\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # ℹ 53,934 more rows\n\ndbReadTable() 返回一个 data.frame，所以我们使用 as_tibble() 将其转换为一个 tibble，以便它能很好地打印出来。\n如果你已经了解 SQL，你可以使用 dbGetQuery() 来获取在数据库上运行查询的结果：\n\nsql &lt;- \"\n  SELECT carat, cut, clarity, color, price \n  FROM diamonds \n  WHERE price &gt; 15000\n\"\nas_tibble(dbGetQuery(con, sql))\n#&gt; # A tibble: 1,655 × 5\n#&gt;   carat cut       clarity color price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1  1.54 Premium   VS2     E     15002\n#&gt; 2  1.19 Ideal     VVS1    F     15005\n#&gt; 3  2.1  Premium   SI1     I     15007\n#&gt; 4  1.69 Ideal     SI1     D     15011\n#&gt; 5  1.5  Very Good VVS2    G     15013\n#&gt; 6  1.73 Very Good VS1     G     15014\n#&gt; # ℹ 1,649 more rows\n\n如果你以前从未见过 SQL，别担心！你很快就会学到更多关于它的知识。但如果你仔细阅读它，你可能会猜到它从 diamonds 数据集中选择了五个列，以及 price 大于 15,000 的所有行。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#dbplyr-基础",
    "href": "databases.html#dbplyr-基础",
    "title": "21  数据库",
    "section": "\n21.4 dbplyr 基础",
    "text": "21.4 dbplyr 基础\n现在我们已经连接到数据库并加载了一些数据，我们可以开始学习 dbplyr 了。dbplyr 是一个 dplyr 的后端 (backend)，这意味着你继续写 dplyr 代码，但后端会以不同的方式执行它。在这里，dbplyr 将代码翻译成 SQL；其他后端包括将代码翻译成 data.table 的 dtplyr，以及在多个核心上执行你的代码的 multidplyr。\n要使用 dbplyr，你必须首先使用 tbl() 创建一个代表数据库表的对象：\n\ndiamonds_db &lt;- tbl(con, \"diamonds\")\ndiamonds_db\n#&gt; # Source:   table&lt;diamonds&gt; [?? x 10]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # ℹ more rows\n\n\n\n\n\n\n\n还有两种与其他数据库交互的常见方式。首先，许多企业数据库非常大，所以你需要一些层次结构来组织所有的表。在这种情况下，你可能需要提供一个模式 (schema)，或者一个目录 (catalog) 和一个模式，以便选择你感兴趣的表：\n\ndiamonds_db &lt;- tbl(con, in_schema(\"sales\", \"diamonds\"))\ndiamonds_db &lt;- tbl(con, in_catalog(\"north_america\", \"sales\", \"diamonds\"))\n\n其他时候，你可能想用你自己的 SQL 查询作为起点：\n\ndiamonds_db &lt;- tbl(con, sql(\"SELECT * FROM diamonds\"))\n\n\n\n\n这个对象是惰性 (lazy) 的；当你在它上面使用 dplyr 动词时，dplyr 不会做任何工作：它只是记录下你想要执行的操作序列，并且只在需要时才执行它们。例如，看下面的管道：\n\nbig_diamonds_db &lt;- diamonds_db |&gt; \n  filter(price &gt; 15000) |&gt; \n  select(carat:clarity, price)\n\nbig_diamonds_db\n#&gt; # Source:   SQL [?? x 5]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # ℹ more rows\n\n你可以看出这个对象代表一个数据库查询，因为它在顶部打印了 DBMS 的名称，并且虽然它告诉了你列的数量，但它通常不知道行的数量。这是因为找到总行数通常需要执行完整的查询，而这正是我们试图避免的。\n你可以看到由 dplyr 函数 show_query() 生成的 SQL 代码。如果你了解 dplyr，这是学习 SQL 的一个好方法！写一些 dplyr 代码，让 dbplyr 将其翻译成 SQL，然后试着弄清楚这两种语言是如何对应的。\n\nbig_diamonds_db |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT carat, cut, color, clarity, price\n#&gt; FROM diamonds\n#&gt; WHERE (price &gt; 15000.0)\n\n要将所有数据取回 R 中，你可以调用 collect()。在幕后，它会生成 SQL，调用 dbGetQuery() 获取数据，然后将结果转换成一个 tibble：\n\nbig_diamonds &lt;- big_diamonds_db |&gt; \n  collect()\nbig_diamonds\n#&gt; # A tibble: 1,655 × 5\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # ℹ 1,649 more rows\n\n通常，你会使用 dbplyr 从数据库中选择你想要的数据，使用下面描述的翻译进行基本的过滤和聚合。然后，一旦你准备好用 R 特有的函数分析数据，你就会 collect() 数据以获得一个内存中的 tibble，然后用纯 R 代码继续你的工作。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#sql",
    "href": "databases.html#sql",
    "title": "21  数据库",
    "section": "\n21.5 SQL",
    "text": "21.5 SQL\n本章的其余部分将通过 dbplyr 的视角教你一些 SQL。这是一个相当非传统的 SQL 入门，但我们希望它能让你快速掌握基础知识。幸运的是，如果你理解 dplyr，你就处在一个很好的位置，可以快速掌握 SQL，因为很多概念都是相同的。\n我们将使用 nycflights13 包中的两个老朋友来探讨 dplyr 和 SQL 之间的关系：flights 和 planes。这些数据集很容易进入我们的学习数据库，因为 dbplyr 自带一个函数，可以将 nycflights13 中的表复制到我们的数据库中：\n\ndbplyr::copy_nycflights13(con)\n#&gt; Creating table: airlines\n#&gt; Creating table: airports\n#&gt; Creating table: flights\n#&gt; Creating table: planes\n#&gt; Creating table: weather\nflights &lt;- tbl(con, \"flights\")\nplanes &lt;- tbl(con, \"planes\")\n\n\n21.5.1 SQL 基础\nSQL 的顶层组件被称为语句 (statements)。常见的语句包括用于定义新表的 CREATE，用于添加数据的 INSERT，以及用于检索数据的 SELECT。我们将专注于 SELECT 语句，也称为查询 (queries)，因为它们几乎是你作为数据科学家唯一会使用的。\n一个查询由子句 (clauses) 组成。有五个重要的子句：SELECT、FROM、WHERE、ORDER BY 和 GROUP BY。每个查询都必须有 SELECT4 和 FROM5 子句，最简单的查询是 SELECT * FROM table，它从指定的表中选择所有列。这是 dbplyr 为一个未经处理的表生成的代码：\n\nflights |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM flights\nplanes |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM planes\n\nWHERE 和 ORDER BY 控制包含哪些行以及它们如何排序：\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  arrange(dep_delay) |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH')\n#&gt; ORDER BY dep_delay\n\nGROUP BY 将查询转换为一个摘要，导致聚合发生：\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(dep_delay = mean(dep_delay, na.rm = TRUE)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT dest, AVG(dep_delay) AS dep_delay\n#&gt; FROM flights\n#&gt; GROUP BY dest\n\ndplyr 动词和 SELECT 子句之间有两个重要的区别：\n\n在 SQL 中，大小写不重要：你可以写 select、SELECT，甚至是 SeLeCt。在本书中，我们将坚持使用将 SQL 关键字大写的常见约定，以区别于表或变量名。\n在 SQL 中，顺序很重要：你必须总是按照 SELECT、FROM、WHERE、GROUP BY、ORDER BY 的顺序编写子句。令人困惑的是，这个顺序与子句实际求值的顺序不匹配，后者首先是 FROM，然后是 WHERE、GROUP BY、SELECT 和 ORDER BY。\n\n以下各节将更详细地探讨每个子句。\n\n\n\n\n\n\n注意，虽然 SQL 是一个标准，但它极其复杂，没有一个数据库完全遵循它。虽然我们将在本书中重点关注的主要组件在不同 DBMS 之间非常相似，但存在许多细微的差异。幸运的是，dbplyr 旨在处理这个问题，并为不同的数据库生成不同的翻译。它并不完美，但它在不断改进，如果你遇到问题，可以在 GitHub 上提交一个 issue 来帮助我们做得更好。\n\n\n\n\n21.5.2 SELECT\nSELECT 子句是查询的主力，它执行与 select()、mutate()、rename()、relocate() 相同的工作，并且，正如你将在下一节中学到的，还有 summarize()。\nselect()、rename() 和 relocate() 到 SELECT 的翻译非常直接，因为它们只影响列出现的位置（如果有的话）及其名称：\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\"\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  rename(year_built = year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\" AS year_built\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  relocate(manufacturer, model, .before = type) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, manufacturer, model, \"type\", \"year\"\n#&gt; FROM planes\n\n这个例子也向你展示了 SQL 是如何进行重命名的。在 SQL 术语中，重命名被称为别名 (aliasing)，并用 AS 完成。注意，与 mutate() 不同，旧名称在左边，新名称在右边。\n\n\n\n\n\n\n在上面的例子中，请注意 \"year\" 和 \"type\" 被双引号包裹。这是因为它们在 duckdb 中是保留字 (reserved words)，所以 dbplyr 将它们引用起来以避免列/表名和 SQL 运算符之间任何潜在的混淆。\n在与其他数据库工作时，你可能会看到每个变量名都被引用，因为只有少数客户端包（如 duckdb）知道所有的保留字是什么，所以它们为了安全起见会引用所有内容。\nSELECT \"tailnum\", \"type\", \"manufacturer\", \"model\", \"year\"\nFROM \"planes\"\n一些其他数据库系统使用反引号而不是引号：\nSELECT `tailnum`, `type`, `manufacturer`, `model`, `year`\nFROM `planes`\n\n\n\nmutate() 的翻译同样直接：每个变量都成为 SELECT 中的一个新表达式：\n\nflights |&gt; \n  mutate(\n    speed = distance / (air_time / 60)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*, distance / (air_time / 60.0) AS speed\n#&gt; FROM flights\n\n我们将在 Section 21.6 中回到单个组件（如 /）的翻译。\n\n21.5.3 FROM\nFROM 子句定义了数据源。在一段时间内它会相当无趣，因为我们只使用单个表。一旦我们接触到连接函数，你就会看到更复杂的例子。\n\n21.5.4 GROUP BY\ngroup_by() 被翻译成 GROUP BY6 子句，而 summarize() 被翻译成 SELECT 子句：\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(\n    n = n(),\n    avg_price = mean(price, na.rm = TRUE)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n, AVG(price) AS avg_price\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n\n我们将在 Section 21.6 中回到 n() 和 mean() 的翻译发生了什么。\n\n21.5.5 WHERE\nfilter() 被翻译成 WHERE 子句：\n\nflights |&gt; \n  filter(dest == \"IAH\" | dest == \"HOU\") |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH' OR dest = 'HOU')\n\nflights |&gt; \n  filter(arr_delay &gt; 0 & arr_delay &lt; 20) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (arr_delay &gt; 0.0 AND arr_delay &lt; 20.0)\n\n这里有几个重要的细节需要注意：\n\n\n| 变成 OR，& 变成 AND。\nSQL 使用 = 进行比较，而不是 ==。SQL 没有赋值操作，所以那里没有潜在的混淆。\nSQL 只使用 '' 来表示字符串，而不是 \"\"。在 SQL 中，\"\" 用于标识变量，就像 R 的 ``。\n\n另一个有用的 SQL 运算符是 IN，它非常接近 R 的 %in%：\n\nflights |&gt; \n  filter(dest %in% c(\"IAH\", \"HOU\")) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest IN ('IAH', 'HOU'))\n\nSQL 使用 NULL 而不是 NA。NULL 的行为与 NA 类似。主要区别在于，虽然它们在比较和算术中是“传染性的”，但在汇总时它们会被悄悄地丢弃。dbplyr 在你第一次遇到这种情况时会提醒你：\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(delay = mean(arr_delay))\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;   dest   delay\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 CLT    7.36 \n#&gt; 2 MDW   12.4  \n#&gt; 3 SDF   12.7  \n#&gt; 4 LAS    0.258\n#&gt; 5 IAH    4.24 \n#&gt; 6 CAK   19.7  \n#&gt; # ℹ more rows\n\n如果你想更多地了解 NULL 是如何工作的，你可能会喜欢 Markus Winand 的文章“SQL 的三值逻辑”。\n总的来说，你可以用你在 R 中用于 NA 的函数来处理 NULL：\n\nflights |&gt; \n  filter(!is.na(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (NOT((dep_delay IS NULL)))\n\n这个 SQL 查询说明了 dbplyr 的一个缺点：虽然 SQL 是正确的，但它并不像你手写的那样简单。在这种情况下，你可以去掉括号并使用一个更易读的特殊运算符：\nWHERE \"dep_delay\" IS NOT NULL\n请注意，如果你 filter() 一个你刚刚用 summarize 创建的变量，dbplyr 会生成一个 HAVING 子句，而不是一个 WHERE 子句。这是 SQL 的一个特异之处：WHERE 在 SELECT 和 GROUP BY 之前被求值，所以 SQL 需要另一个在之后被求值的子句。\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(n = n()) |&gt; \n  filter(n &gt; 100) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n#&gt; HAVING (COUNT(*) &gt; 100.0)\n\n\n21.5.6 ORDER BY\n对行进行排序涉及从 arrange() 到 ORDER BY 子句的直接翻译：\n\nflights |&gt; \n  arrange(year, month, day, desc(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; ORDER BY \"year\", \"month\", \"day\", dep_delay DESC\n\n注意 desc() 是如何被翻译成 DESC 的：这是众多直接受到 SQL 启发的 dplyr 函数之一。\n\n21.5.7 子查询\n有时，将一个 dplyr 管道翻译成一个单一的 SELECT 语句是不可能的，你需要使用一个子查询。子查询 (subquery) 只是一个在 FROM 子句中用作数据源的查询，而不是通常的表。\ndbplyr 通常使用子查询来绕过 SQL 的限制。例如，SELECT 子句中的表达式不能引用刚刚创建的列。这意味着以下（愚蠢的）dplyr 管道需要分两步进行：第一步（内部）查询计算 year1，然后第二步（外部）查询才能计算 year2。\n\nflights |&gt; \n  mutate(\n    year1 = year + 1,\n    year2 = year1 + 1\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*, year1 + 1.0 AS year2\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n\n如果你试图 filter() 一个你刚刚创建的变量，你也会看到这种情况。记住，尽管 WHERE 写在 SELECT 之后，但它是在 SELECT 之前被求值的，所以在这个（愚蠢的）例子中我们需要一个子查询：\n\nflights |&gt; \n  mutate(year1 = year + 1) |&gt; \n  filter(year1 == 2014) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n#&gt; WHERE (year1 = 2014.0)\n\n有时 dbplyr 会在不需要的地方创建一个子查询，因为它还不知道如何优化该翻译。随着 dbplyr 随时间的改进，这些情况会越来越少，但可能永远不会完全消失。\n\n21.5.8 连接\n如果你熟悉 dplyr 的连接，SQL 连接非常相似。这里有一个简单的例子：\n\nflights |&gt; \n  left_join(planes |&gt; rename(year_built = year), join_by(tailnum)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   flights.*,\n#&gt;   planes.\"year\" AS year_built,\n#&gt;   \"type\",\n#&gt;   manufacturer,\n#&gt;   model,\n#&gt;   engines,\n#&gt;   seats,\n#&gt;   speed,\n#&gt;   engine\n#&gt; FROM flights\n#&gt; LEFT JOIN planes\n#&gt;   ON (flights.tailnum = planes.tailnum)\n\n这里主要要注意的是语法：SQL 连接使用 FROM 子句的子子句来引入额外的表，并使用 ON 来定义表之间的关系。\ndplyr 为这些函数起的名字与 SQL 的联系非常紧密，以至于你可以轻松猜出 inner_join()、right_join() 和 full_join() 的等效 SQL：\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nINNER JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nRIGHT JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nFULL JOIN planes ON (flights.tailnum = planes.tailnum)\n在处理来自数据库的数据时，你可能需要进行很多连接。这是因为数据库表通常以高度规范化的形式存储，其中每个“事实”都存储在一个单一的地方，为了保持一个完整的分析数据集，你需要浏览一个由主键和外键连接的复杂表网络。如果你遇到这种情况，由 Tobias Schieferdecker、Kirill Müller 和 Darko Bergant 开发的 dm 包 将是你的救星。它可以自动确定表之间的连接，使用 DBA 通常提供的约束，可视化连接以便你了解情况，并生成你需要用来连接一个表到另一个表的连接。\n\n21.5.9 其他动词\ndbplyr 还翻译其他动词，如 distinct()、slice_*() 和 intersect()，以及越来越多的 tidyr 函数，如 pivot_longer() 和 pivot_wider()。查看当前可用功能的完整集合的最简单方法是访问 dbplyr 网站：https://dbplyr.tidyverse.org/reference/。\n\n21.5.10 练习\n\ndistinct() 被翻译成什么？head() 呢？\n\n解释以下每个 SQL 查询的作用，并尝试使用 dbplyr 重新创建它们。\nSELECT * FROM flights\nWHERE dep_delay &lt; arr_delay\n\nSELECT *, distance / (air_time / 60) AS speed\nFROM flights",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-sql-expressions",
    "href": "databases.html#sec-sql-expressions",
    "title": "21  数据库",
    "section": "\n21.6 函数翻译",
    "text": "21.6 函数翻译\n到目前为止，我们一直关注 dplyr 动词如何被翻译成查询的子句这个大局。现在我们将稍微深入一点，讨论处理单个列的 R 函数的翻译，例如，当你在 summarize() 中使用 mean(x) 时会发生什么？\n为了帮助看清发生了什么，我们将使用几个小的辅助函数，它们运行一个 summarize() 或 mutate() 并显示生成的 SQL。这将使我们更容易探索一些变化，并看到摘要和转换有何不同。\n\nsummarize_query &lt;- function(df, ...) {\n  df |&gt; \n    summarize(...) |&gt; \n    show_query()\n}\nmutate_query &lt;- function(df, ...) {\n  df |&gt; \n    mutate(..., .keep = \"none\") |&gt; \n    show_query()\n}\n\n让我们从一些摘要开始吧！看下面的代码，你会注意到一些摘要函数，比如 mean()，有一个相对简单的翻译，而另一些，比如 median()，则复杂得多。对于在统计学中常见但在数据库中不那么常见的操作，其复杂性通常更高。\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  summarize_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n    median = median(arr_delay, na.rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by \"year\" and \"month\". You can override\n#&gt; using the `.groups` argument.\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) AS mean,\n#&gt;   MEDIAN(arr_delay) AS median\n#&gt; FROM flights\n#&gt; GROUP BY \"year\", \"month\", \"day\"\n\n当你在 mutate() 中使用摘要函数时，它们的翻译会变得更加复杂，因为它们必须变成所谓的窗口 (window) 函数。在 SQL 中，你通过在普通聚合函数后添加 OVER 来将其变成窗口函数：\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  mutate_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) OVER (PARTITION BY \"year\", \"month\", \"day\") AS mean\n#&gt; FROM flights\n\n在 SQL 中，GROUP BY 子句专门用于摘要，所以在这里你可以看到分组已经从 GROUP BY 子句移到了 OVER。\n窗口函数包括所有向前或向后看的函数，比如 lead() 和 lag()，它们分别查看“下一个”或“上一个”值：\n\nflights |&gt; \n  group_by(dest) |&gt;  \n  arrange(time_hour) |&gt; \n  mutate_query(\n    lead = lead(arr_delay),\n    lag = lag(arr_delay)\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   dest,\n#&gt;   LEAD(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lead,\n#&gt;   LAG(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lag\n#&gt; FROM flights\n#&gt; ORDER BY time_hour\n\n在这里，arrange() 数据很重要，因为 SQL 表没有内在的顺序。事实上，如果你不使用 arrange()，你每次可能会得到不同顺序的行！注意对于窗口函数，排序信息是重复的：主查询的 ORDER BY 子句不自动应用于窗口函数。\n另一个重要的 SQL 函数是 CASE WHEN。它被用作 if_else() 和 case_when() 的翻译，后者是直接受到它启发的 dplyr 函数。这里有几个简单的例子：\n\nflights |&gt; \n  mutate_query(\n    description = if_else(arr_delay &gt; 0, \"delayed\", \"on-time\")\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE WHEN (arr_delay &gt; 0.0) THEN 'delayed' WHEN NOT (arr_delay &gt; 0.0) THEN 'on-time' END AS description\n#&gt; FROM flights\nflights |&gt; \n  mutate_query(\n    description = \n      case_when(\n        arr_delay &lt; -5 ~ \"early\", \n        arr_delay &lt; 5 ~ \"on-time\",\n        arr_delay &gt;= 5 ~ \"late\"\n      )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt; -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt; 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt;= 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\nCASE WHEN 也用于一些其他没有从 R 到 SQL 的直接翻译的函数。一个很好的例子是 cut()：\n\nflights |&gt; \n  mutate_query(\n    description =  cut(\n      arr_delay, \n      breaks = c(-Inf, -5, 5, Inf), \n      labels = c(\"early\", \"on-time\", \"late\")\n    )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt;= -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt;= 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt; 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\ndbplyr 还翻译常见的字符串和日期时间操作函数，你可以在 vignette(\"translation-function\", package = \"dbplyr\") 中了解它们。dbplyr 的翻译肯定不完美，还有很多 R 函数尚未被翻译，但 dbplyr 在覆盖你大多数时候会使用的函数方面做得出奇地好。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#总结",
    "href": "databases.html#总结",
    "title": "21  数据库",
    "section": "\n21.7 总结",
    "text": "21.7 总结\n在本章中，你学习了如何从数据库访问数据。我们专注于 dbplyr，一个 dplyr 的“后端”，它允许你编写你熟悉的 dplyr 代码，并让它自动翻译成 SQL。我们利用这种翻译教了你一些 SQL；学习一些 SQL 很重要，因为它是最常用的数据处理语言，了解一些将使你更容易与其他不使用 R 的数据人员交流。\n如果你已经完成了本章，并想学习更多关于 SQL 的知识，我们有两个推荐：\n\nRenée M. P. Teate 的 《面向数据科学家的 SQL》 (SQL for Data Scientists)，https://sqlfordatascientists.com，是专为数据科学家的需求设计的 SQL 入门，并包含了你在真实组织中可能遇到的那种高度互联数据的例子。\nAnthony DeBarros 的 《实用 SQL》 (Practical SQL)，https://www.practicalsql.com，是从数据记者（专门讲述引人入胜故事的数据科学家）的角度写的，并更详细地介绍了如何将你的数据导入数据库和运行你自己的 DBMS。\n\n在下一章中，我们将学习另一个用于处理大数据的 dplyr 后端：arrow。Arrow 是为处理磁盘上的大文件而设计的，是数据库的天然补充。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "databases.html#footnotes",
    "href": "databases.html#footnotes",
    "title": "21  数据库",
    "section": "",
    "text": "SQL 的发音是“s”-“q”-“l”或“sequel”。↩︎\n通常，这是你将从客户端包中使用的唯一函数，所以我们建议使用 :: 来提取那一个函数，而不是用 library() 加载整个包。↩︎\n至少，是你被授权查看的所有表。↩︎\n令人困惑的是，根据上下文，SELECT 可以是一个语句或一个子句。为了避免这种混淆，我们通常会用 SELECT 查询而不是 SELECT 语句。↩︎\n好吧，从技术上讲，只需要 SELECT，因为你可以写像 SELECT 1+1 这样的查询来执行基本计算。但如果你想处理数据（你总是这样做的！），你还需要一个 FROM 子句。↩︎\n这并非巧合：dplyr 函数的名称受到了 SQL 子句的启发。↩︎",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据库</span>"
    ]
  },
  {
    "objectID": "arrow.html",
    "href": "arrow.html",
    "title": "22  Arrow",
    "section": "",
    "text": "22.1 引言\nCSV 文件被设计为易于人类阅读。它们是一种很好的交换格式，因为它们非常简单，并且几乎所有工具都能读取它们。但 CSV 文件效率不高：你需要做相当多的工作才能将数据读入 R。在本章中，你将学习一种强大的替代方案：parquet 格式，这是一种被大数据系统广泛使用的基于开放标准的格式。\n我们将把 parquet 文件与 Apache Arrow 配对使用，这是一个为高效分析和传输大型数据集而设计的多语言工具箱。我们将通过 arrow 包 来使用 Apache Arrow，它提供了一个 dplyr 后端，允许你使用熟悉的 dplyr 语法来分析大于内存的数据集。另外一个好处是，arrow 非常快：你将在本章后面看到一些例子。\narrow 和 dbplyr 都提供了 dplyr 后端，所以你可能会想知道何时使用哪一个。在很多情况下，选择已经为你做好了，因为数据已经存在于数据库或 parquet 文件中，而你希望直接使用它。但如果你是从自己的数据（也许是 CSV 文件）开始，你可以将其加载到数据库中或转换为 parquet。总的来说，很难知道哪种方法效果最好，所以在你分析的早期阶段，我们鼓励你尝试两者，并选择最适合你的那一个。\n（非常感谢 Danielle Navarro，她贡献了本章的初版。）",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#引言",
    "href": "arrow.html#引言",
    "title": "22  Arrow",
    "section": "",
    "text": "22.1.1 前提条件\n在本章中，我们将继续使用 tidyverse，特别是 dplyr，但我们会将其与专门为处理大数据而设计的 arrow 包配对使用。\n\nlibrary(tidyverse)\nlibrary(arrow)\n\n在本章的后面，我们还会看到 arrow 和 duckdb 之间的一些联系，所以我们还需要 dbplyr 和 duckdb。\n\nlibrary(dbplyr, warn.conflicts = FALSE)\nlibrary(duckdb)\n#&gt; 载入需要的程序包：DBI",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#获取数据",
    "href": "arrow.html#获取数据",
    "title": "22  Arrow",
    "section": "\n22.2 获取数据",
    "text": "22.2 获取数据\n我们首先获取一个值得使用这些工具的数据集：西雅图公共图书馆的图书借阅数据集，可在线获取：data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6。这个数据集包含 41,389,465 行，告诉你从 2005 年 4 月到 2022 年 10 月，每本书每月被借阅了多少次。\n以下代码将为你获取该数据的缓存副本。数据是一个 9GB 的 CSV 文件，所以下载需要一些时间。我强烈推荐使用 curl::multi_download() 来获取非常大的文件，因为它正是为此目的而构建的：它会给你一个进度条，并且如果下载中断，它可以恢复下载。\n\n# eval: !expr \"!file.exists('data/seattle-library-checkouts.csv')\"\ndir.create(\"data\", showWarnings = FALSE)\n\ncurl::multi_download(\n    \"https://r4ds.s3.us-west-2.amazonaws.com/seattle-library-checkouts.csv\",\n    \"data/seattle-library-checkouts.csv\",\n    resume = TRUE\n)\n#&gt; # A tibble: 1 × 10\n#&gt;   success status_code resumefrom url                    destfile        error\n#&gt;   &lt;lgl&gt;         &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;\n#&gt; 1 TRUE            416          0 https://r4ds.s3.us-we… \"E:\\\\r4ds-cn\\\\… &lt;NA&gt; \n#&gt; # ℹ 4 more variables: type &lt;chr&gt;, modified &lt;dttm&gt;, time &lt;dbl&gt;,\n#&gt; #   headers &lt;list&gt;",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#打开数据集",
    "href": "arrow.html#打开数据集",
    "title": "22  Arrow",
    "section": "\n22.3 打开数据集",
    "text": "22.3 打开数据集\n让我们先来看看数据。这个文件有 9 GB，足够大，我们可能不想把整个文件都加载到内存中。一个好的经验法则是，你通常需要至少是数据大小两倍的内存，而许多笔记本电脑的内存上限是 16 GB。这意味着我们想避免使用 read_csv()，而是使用 arrow::open_dataset()：\n\nseattle_csv &lt;- open_dataset(\n    sources = \"data/seattle-library-checkouts.csv\",\n    col_types = schema(ISBN = string()),\n    format = \"csv\"\n)\n\n当这段代码运行时发生了什么？open_dataset() 会扫描几千行来确定数据集的结构。ISBN 列在前 80,000 行包含空白值，所以我们必须指定列类型来帮助 arrow 确定数据结构。一旦数据被 open_dataset() 扫描过，它会记录下它所发现的内容然后停止；它只会在你明确请求时才读取更多的行。这个元数据就是我们打印 seattle_csv 时看到的内容：\n\nseattle_csv\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 12 columns\n#&gt; UsageClass: string\n#&gt; CheckoutType: string\n#&gt; MaterialType: string\n#&gt; CheckoutYear: int64\n#&gt; CheckoutMonth: int64\n#&gt; Checkouts: int64\n#&gt; Title: string\n#&gt; ISBN: string\n#&gt; Creator: string\n#&gt; Subjects: string\n#&gt; Publisher: string\n#&gt; PublicationYear: string\n\n输出的第一行告诉你 seattle_csv 是作为单个 CSV 文件存储在本地磁盘上的；它只会在需要时才被加载到内存中。输出的其余部分告诉了你 arrow 为每一列推断出的列类型。\n我们可以用 glimpse() 来看实际内容。这揭示了有大约 4100 万行和 12 列，并向我们展示了几个值。\n\nseattle_csv |&gt; glimpse()\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 41,389,465 rows x 12 columns\n#&gt; $ UsageClass      &lt;string&gt; \"Physical\", \"Physical\", \"Digital\", \"Physical\", \"Ph…\n#&gt; $ CheckoutType    &lt;string&gt; \"Horizon\", \"Horizon\", \"OverDrive\", \"Horizon\", \"Hor…\n#&gt; $ MaterialType    &lt;string&gt; \"BOOK\", \"BOOK\", \"EBOOK\", \"BOOK\", \"SOUNDDISC\", \"BOO…\n#&gt; $ CheckoutYear     &lt;int64&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 20…\n#&gt; $ CheckoutMonth    &lt;int64&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n#&gt; $ Checkouts        &lt;int64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 3, 2,…\n#&gt; $ Title           &lt;string&gt; \"Super rich : a guide to having it all / Russell S…\n#&gt; $ ISBN            &lt;string&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#&gt; $ Creator         &lt;string&gt; \"Simmons, Russell\", \"Barclay, James, 1965-\", \"Tim …\n#&gt; $ Subjects        &lt;string&gt; \"Self realization, Conduct of life, Attitude Psych…\n#&gt; $ Publisher       &lt;string&gt; \"Gotham Books,\", \"Pyr,\", \"Random House, Inc.\", \"Di…\n#&gt; $ PublicationYear &lt;string&gt; \"c2011.\", \"2010.\", \"2015\", \"2005.\", \"c2004.\", \"c20…\n\n我们可以开始用 dplyr 动词来使用这个数据集，并用 collect() 来强制 arrow 执行计算并返回一些数据。例如，这段代码告诉我们每年的总借阅量：\n\nseattle_csv |&gt;\n    group_by(CheckoutYear) |&gt;\n    summarise(Checkouts = sum(Checkouts)) |&gt;\n    arrange(CheckoutYear) |&gt;\n    collect()\n#&gt; # A tibble: 18 × 2\n#&gt;   CheckoutYear Checkouts\n#&gt;          &lt;int&gt;     &lt;int&gt;\n#&gt; 1         2005   3798685\n#&gt; 2         2006   6599318\n#&gt; 3         2007   7126627\n#&gt; 4         2008   8438486\n#&gt; 5         2009   9135167\n#&gt; 6         2010   8608966\n#&gt; # ℹ 12 more rows\n\n多亏了 arrow，无论底层数据集有多大，这段代码都能工作。但它目前相当慢：在 Hadley 的电脑上，它运行了大约 10 秒。考虑到我们拥有的数据量，这不算太糟，但我们可以通过切换到更好的格式来使其快得多。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#sec-parquet",
    "href": "arrow.html#sec-parquet",
    "title": "22  Arrow",
    "section": "\n22.4 parquet 格式",
    "text": "22.4 parquet 格式\n为了让这个数据更容易处理，让我们切换到 parquet 文件格式，并将其分割成多个文件。接下来的部分将首先向你介绍 parquet 和分区 (partitioning)，然后将我们学到的知识应用到西雅图图书馆的数据上。\n\n22.4.1 parquet 的优势\n像 CSV 一样，parquet 用于矩形数据，但它不是一个你可以用任何文件编辑器读取的文本格式，而是一个专为大数据需求设计的自定义二进制格式。这意味着：\n\nParquet 文件通常比等效的 CSV 文件小。Parquet 依赖于高效的编码方式来减小文件大小，并支持文件压缩。这有助于使 parquet 文件快速，因为从磁盘移动到内存的数据更少。\nParquet 文件有丰富的类型系统。正如我们在 Section 7.3 中讨论的，CSV 文件不提供任何关于列类型的信息。例如，CSV 读取器必须猜测 \"08-10-2022\" 应该被解析为字符串还是日期。相比之下，parquet 文件以一种记录了类型和数据的方式存储数据。\nParquet 文件是“列式”(column-oriented) 的。这意味着它们是按列组织的，很像 R 的数据框。与按行组织的 CSV 文件相比，这通常为数据分析任务带来更好的性能。\nParquet 文件是“分块”(chunked) 的，这使得可以同时处理文件的不同部分，并且，如果你幸运的话，可以完全跳过一些块。\n\nparquet 文件有一个主要缺点：它们不再是“人类可读的”，也就是说，如果你用 readr::read_file() 查看一个 parquet 文件，你只会看到一堆乱码。\n\n22.4.2 分区 (Partitioning)\n随着数据集变得越来越大，将所有数据存储在单个文件中变得越来越痛苦，将大数据集分割到多个文件中通常很有用。当这种结构化做得巧妙时，这种策略可以带来显著的性能提升，因为许多分析只会需要文件的一个子集。\n关于如何对你的数据集进行分区，没有硬性规定：结果将取决于你的数据、访问模式以及读取数据的系统。你可能需要做一些实验才能找到适合你情况的理想分区方式。作为一个粗略的指南，arrow 建议你避免小于 20MB 和大于 2GB 的文件，并避免产生超过 10,000 个文件的分区。你还应该尝试按你过滤时使用的变量进行分区；正如你稍后将看到的，这允许 arrow 通过只读取相关文件来跳过大量工作。\n\n22.4.3 重写西雅图图书馆数据\n让我们将这些想法应用到西雅图图书馆的数据上，看看它们在实践中是如何发挥作用的。我们将按 CheckoutYear 进行分区，因为很可能一些分析只想看最近的数据，而按年分区会产生 18 个大小合理的块。\n为了重写数据，我们使用 dplyr::group_by() 定义分区，然后用 arrow::write_dataset() 将分区保存到一个目录中。write_dataset() 有两个重要的参数：一个是我们将在其中创建文件的目录，另一个是我们使用的格式。\n\npq_path &lt;- \"data/seattle-library-checkouts\"\n\n\n## | eval: !expr \"!file.exists(pq_path)\"\n\nseattle_csv |&gt;\n    group_by(CheckoutYear) |&gt;\n    write_dataset(path = pq_path, format = \"parquet\")\n\n这需要大约一分钟的时间来运行；正如我们稍后将看到的，这是一项初步的投资，它通过使未来的操作快得多来得到回报。\n让我们看看我们刚刚产生了什么：\n\ntibble(\n    files = list.files(pq_path, recursive = TRUE),\n    size_MB = file.size(file.path(pq_path, files)) / 1024^2\n)\n#&gt; # A tibble: 18 × 2\n#&gt;   files                            size_MB\n#&gt;   &lt;chr&gt;                              &lt;dbl&gt;\n#&gt; 1 CheckoutYear=2005/part-0.parquet    109.\n#&gt; 2 CheckoutYear=2006/part-0.parquet    164.\n#&gt; 3 CheckoutYear=2007/part-0.parquet    177.\n#&gt; 4 CheckoutYear=2008/part-0.parquet    194.\n#&gt; 5 CheckoutYear=2009/part-0.parquet    214.\n#&gt; 6 CheckoutYear=2010/part-0.parquet    222.\n#&gt; # ℹ 12 more rows\n\n我们单个 9GB 的 CSV 文件被重写成了 18 个 parquet 文件。文件名使用了 Apache Hive 项目使用的“自描述”约定。Hive 风格的分区 (Hive-style partitions) 使用“键=值”的约定来命名文件夹，所以你可能猜到，CheckoutYear=2005 目录包含了所有 CheckoutYear 是 2005 的数据。每个文件在 100 到 300 MB 之间，总大小现在约为 4 GB，略多于原始 CSV 文件的一半大小。这正如我们预期的那样，因为 parquet 是一种更高效的格式。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#结合使用-dplyr-和-arrow",
    "href": "arrow.html#结合使用-dplyr-和-arrow",
    "title": "22  Arrow",
    "section": "\n22.5 结合使用 dplyr 和 arrow",
    "text": "22.5 结合使用 dplyr 和 arrow\n现在我们已经创建了这些 parquet 文件，我们需要再次读取它们。我们再次使用 open_dataset()，但这次我们给它一个目录：\n\nseattle_pq &lt;- open_dataset(pq_path)\n\n现在我们可以编写我们的 dplyr 管道了。例如，我们可以计算过去五年中每个月借出的图书总数：\n\nquery &lt;- seattle_pq |&gt;\n    filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n    group_by(CheckoutYear, CheckoutMonth) |&gt;\n    summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n    arrange(CheckoutYear, CheckoutMonth)\n\n为 arrow 数据编写 dplyr 代码在概念上与 dbplyr 类似，Chapter 21：你编写 dplyr 代码，它被自动转换为 Apache Arrow C++ 库能理解的查询，然后在你调用 collect() 时执行。如果我们打印出 query 对象，我们可以看到一些关于我们期望 Arrow 在执行发生时返回什么的信息：\n\nquery\n#&gt; FileSystemDataset (query)\n#&gt; CheckoutYear: int32\n#&gt; CheckoutMonth: int64\n#&gt; TotalCheckouts: int64\n#&gt; \n#&gt; * Grouped by CheckoutYear\n#&gt; * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#&gt; See $.data for the source Arrow object\n\n我们可以通过调用 collect() 来得到结果：\n\n#&gt; # A tibble: 58 × 3\n#&gt; # Groups:   CheckoutYear [5]\n#&gt;   CheckoutYear CheckoutMonth TotalCheckouts\n#&gt;          &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n#&gt; 1         2018             1         355101\n#&gt; 2         2018             2         309813\n#&gt; 3         2018             3         344487\n#&gt; 4         2018             4         330988\n#&gt; 5         2018             5         318049\n#&gt; 6         2018             6         341825\n#&gt; # ℹ 52 more rows\n\n像 dbplyr 一样，arrow 只理解一些 R 表达式，所以你可能无法编写与平时完全相同的代码。然而，支持的操作和函数列表相当广泛，并且在不断增长；在 ?acero 中可以找到当前支持的函数的完整列表。\n\n22.5.1 性能\n让我们快速看一下从 CSV 切换到 parquet 对性能的影响。首先，让我们计时计算 2021 年每个月借出的图书数量需要多长时间，当数据存储为单个大型 csv 时：\n\nseattle_csv |&gt;\n    filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n    group_by(CheckoutMonth) |&gt;\n    summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n    arrange(desc(CheckoutMonth)) |&gt;\n    collect() |&gt;\n    system.time()\n#&gt;  用户  系统  流逝 \n#&gt; 11.53  1.61 11.09\n\n现在让我们使用我们新版本的数据集，其中西雅图图书馆的借阅数据被分成了 18 个较小的 parquet 文件：\n\nseattle_pq |&gt;\n    filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n    group_by(CheckoutMonth) |&gt;\n    summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n    arrange(desc(CheckoutMonth)) |&gt;\n    collect() |&gt;\n    system.time()\n#&gt; 用户 系统 流逝 \n#&gt; 0.29 0.00 0.11\n\n性能上约 100 倍的提速归因于两个因素：多文件分区和单个文件的格式：\n\n分区提高了性能，因为这个查询使用 CheckoutYear == 2021 来过滤数据，而 arrow 足够聪明，能识别出它只需要读取 18 个 parquet 文件中的 1 个。\nparquet 格式通过以二进制格式存储数据来提高性能，这种格式可以更直接地读入内存。列式格式和丰富的元数据意味着 arrow 只需要读取查询中实际使用的四列（CheckoutYear、MaterialType、CheckoutMonth 和 Checkouts）。\n\n这种巨大的性能差异就是为什么将大型 CSV 转换为 parquet 是值得的！\n\n22.5.2 结合使用 duckdb 和 arrow\nparquet 和 arrow 还有一个最后的优势——通过调用 arrow::to_duckdb()，将 arrow 数据集转换为 DuckDB 数据库（Chapter 21）非常容易：\n\nseattle_pq |&gt;\n    to_duckdb() |&gt;\n    filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n    group_by(CheckoutYear) |&gt;\n    summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n    arrange(desc(CheckoutYear)) |&gt;\n    collect()\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # A tibble: 5 × 2\n#&gt;   CheckoutYear TotalCheckouts\n#&gt;          &lt;int&gt;          &lt;dbl&gt;\n#&gt; 1         2022        2431502\n#&gt; 2         2021        2266438\n#&gt; 3         2020        1241999\n#&gt; 4         2019        3931688\n#&gt; 5         2018        3987569\n\nto_duckdb() 的妙处在于传输不涉及任何内存复制，这体现了 arrow 生态系统的目标：实现从一个计算环境到另一个计算环境的无缝过渡。\n\n22.5.3 练习\n\n找出每年最受欢迎的书。\n哪位作者在西雅图图书馆系统中的图书最多？\n在过去 10 年中，实体书与电子书的借阅情况是如何变化的？",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#总结",
    "href": "arrow.html#总结",
    "title": "22  Arrow",
    "section": "\n22.6 总结",
    "text": "22.6 总结\n在本章中，你初步了解了 arrow 包，它提供了一个用于处理大型磁盘数据集的 dplyr 后端。它可以处理 CSV 文件，但如果你将数据转换为 parquet，速度会快得多。Parquet 是一种专为现代计算机上的数据分析而设计的二进制数据格式。与 CSV 相比，能处理 parquet 文件的工具要少得多，但其分区、压缩和列式结构使其分析效率高得多。\n接下来，你将学习你的第一个非矩形数据源，你将使用 tidyr 包提供的工具来处理它。我们将专注于来自 JSON 文件的数据，但通用原则适用于任何树状数据，无论其来源如何。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "rectangling.html",
    "href": "rectangling.html",
    "title": "23  层级数据",
    "section": "",
    "text": "23.1 引言\n在本章中，你将学习数据 矩形化 (rectangling) 的艺术：将本质上是层级结构或树状结构的数据，转换为由行和列组成的矩形数据框。这一点非常重要，因为层级数据非常普遍，尤其是在处理来自网络的数据时。\n要学习数据矩形化，你首先需要了解列表 (list)，这种数据结构使得层级数据成为可能。然后，你将学习两个关键的 tidyr 函数：tidyr::unnest_longer() 和 tidyr::unnest_wider()。接着，我们将通过几个案例研究，反复应用这些简单的函数来解决实际问题。最后，我们将讨论 JSON，它是层级数据集最常见的来源，也是网络上一种常用的数据交换格式。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "rectangling.html#引言",
    "href": "rectangling.html#引言",
    "title": "23  层级数据",
    "section": "",
    "text": "23.1.1 先决条件\n在本章中，我们将使用 tidyr 包中的许多函数，它是 tidyverse 的核心成员。我们还将使用 repurrrsive 包来提供一些有趣的数据集用于矩形化练习，最后我们将使用 jsonlite 包将 JSON 文件读入 R 列表。\n\nlibrary(tidyverse)\nlibrary(repurrrsive)\nlibrary(jsonlite)",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "rectangling.html#列表",
    "href": "rectangling.html#列表",
    "title": "23  层级数据",
    "section": "\n23.2 列表",
    "text": "23.2 列表\n到目前为止，你所处理的数据框都包含简单的向量，如整数、数字、字符、日期时间和因子。这些向量之所以简单，是因为它们是同质的 (homogeneous)：每个元素都具有相同的数据类型。如果你想在同一个向量中存储不同类型的元素，你就需要一个 列表 (list)，你可以用 list() 来创建它：\n\nx1 &lt;- list(1:4, \"a\", TRUE)\nx1\n#&gt; [[1]]\n#&gt; [1] 1 2 3 4\n#&gt; \n#&gt; [[2]]\n#&gt; [1] \"a\"\n#&gt; \n#&gt; [[3]]\n#&gt; [1] TRUE\n\n为列表的组件 (component) 或 子元素 (children) 命名通常很方便，这和为 tibble 的列命名的方式相同：\n\nx2 &lt;- list(a = 1:2, b = 1:3, c = 1:4)\nx2\n#&gt; $a\n#&gt; [1] 1 2\n#&gt; \n#&gt; $b\n#&gt; [1] 1 2 3\n#&gt; \n#&gt; $c\n#&gt; [1] 1 2 3 4\n\n即使对于这些非常简单的列表，打印出来也会占用相当大的空间。一个有用的替代方法是 str()，它会生成一个紧凑的 结构 (structure) 展示，淡化其内容：\n\nstr(x1)\n#&gt; List of 3\n#&gt;  $ : int [1:4] 1 2 3 4\n#&gt;  $ : chr \"a\"\n#&gt;  $ : logi TRUE\nstr(x2)\n#&gt; List of 3\n#&gt;  $ a: int [1:2] 1 2\n#&gt;  $ b: int [1:3] 1 2 3\n#&gt;  $ c: int [1:4] 1 2 3 4\n\n如你所见，str() 将列表的每个子元素显示在单独的一行上。它会显示名称 (如果存在)，然后是类型的缩写，最后是前几个值。\n\n23.2.1 层级结构\n列表可以包含任何类型的对象，包括其他列表。这使得它们非常适合表示层级 (树状) 结构：\n\nx3 &lt;- list(list(1, 2), list(3, 4))\nstr(x3)\n#&gt; List of 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 1\n#&gt;   ..$ : num 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 3\n#&gt;   ..$ : num 4\n\n这与 c() 有显著不同，c() 会生成一个扁平的向量：\n\nc(c(1, 2), c(3, 4))\n#&gt; [1] 1 2 3 4\n\nx4 &lt;- c(list(1, 2), list(3, 4))\nstr(x4)\n#&gt; List of 4\n#&gt;  $ : num 1\n#&gt;  $ : num 2\n#&gt;  $ : num 3\n#&gt;  $ : num 4\n\n随着列表变得越来越复杂，str() 的作用也越来越大，因为它能让你一目了然地看到层级结构：\n\nx5 &lt;- list(1, list(2, list(3, list(4, list(5)))))\nstr(x5)\n#&gt; List of 2\n#&gt;  $ : num 1\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 2\n#&gt;   ..$ :List of 2\n#&gt;   .. ..$ : num 3\n#&gt;   .. ..$ :List of 2\n#&gt;   .. .. ..$ : num 4\n#&gt;   .. .. ..$ :List of 1\n#&gt;   .. .. .. ..$ : num 5\n\n当列表变得更大、更复杂时，str() 最终会开始失效，这时你就需要切换到 View()1。Figure 23.1 展示了调用 View(x5) 的结果。查看器开始只显示列表的顶层，但你可以交互地展开任何组件以查看更多内容，如 Figure 23.2 所示。RStudio 还会显示访问该元素所需写的代码，如 Figure 23.3 所示。我们将在 Section 27.3 回顾这段代码是如何工作的。\n\n\n\n\n\n\n\nFigure 23.1: RStudio 的视图让你能够交互式地探索一个复杂的列表。 查看器打开时只显示列表的顶层。\n\n\n\n\n\n\n\n\n\n\n\nFigure 23.2: 点击朝右的三角形会展开该列表组件，这样你也可以看到它的子元素。\n\n\n\n\n\n\n\n\n\n\n\nFigure 23.3: 你可以根据需要重复此操作多次，以找到你感兴趣的数据。注意左下角： 如果你点击列表中的一个元素，RStudio 会给你提供访问它所需的子集代码， 在本例中是 x5[[2]][[2]][[2]]。\n\n\n\n\n\n23.2.2 列表列\n列表也可以存在于 tibble 中，我们称之为列表列 (list-columns)。列表列很有用，因为它们允许你将通常不属于数据框的对象放入其中。特别地，列表列在 tidymodels 生态系统中使用很多，因为它们允许你将模型输出或重采样等内容存储在数据框中。\n下面是列表列的一个简单示例：\n\ndf &lt;- tibble(\n  x = 1:2, \n  y = c(\"a\", \"b\"),\n  z = list(list(1, 2), list(3, 4, 5))\n)\ndf\n#&gt; # A tibble: 2 × 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n#&gt; 2     2 b     &lt;list [3]&gt;\n\ntibble 中的列表没有什么特别之处；它们的行为就像任何其他列一样：\n\ndf |&gt; \n  filter(x == 1)\n#&gt; # A tibble: 1 × 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n\n使用列表列进行计算更加困难，但这是因为通常使用列表进行计算就更困难；我们将在 Chapter 26 中再讨论这个问题。在本章中，我们将专注于将列表列展开 (unnest) 为常规变量，以便你可以使用现有的工具来处理它们。\n默认的打印方法只显示内容的粗略摘要。列表列可能任意复杂，所以没有很好的方法来打印它。如果你想查看它，你需要单独抽取出那个列表列，并应用你上面学到的技术之一，比如 df |&gt; pull(z) |&gt; str() 或 df |&gt; pull(z) |&gt; View()。\n\n\n\n\n\n\n基础 R\n\n\n\n可以将列表放入 data.frame 的一列中，但这要麻烦得多，因为 data.frame() 将列表视为列的列表：\n\ndata.frame(x = list(1:3, 3:5))\n#&gt;   x.1.3 x.3.5\n#&gt; 1     1     3\n#&gt; 2     2     4\n#&gt; 3     3     5\n\n你可以通过将其包装在 I() 中来强制 data.frame() 将列表视为行的列表，但结果打印得不是很好：\n\ndata.frame(\n  x = I(list(1:2, 3:5)), \n  y = c(\"1, 2\", \"3, 4, 5\")\n)\n#&gt;         x       y\n#&gt; 1    1, 2    1, 2\n#&gt; 2 3, 4, 5 3, 4, 5\n\n使用 tibble 的列表列更容易，因为 tibble() 将列表视为向量，并且其打印方法是为列表设计的。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "rectangling.html#展开",
    "href": "rectangling.html#展开",
    "title": "23  层级数据",
    "section": "\n23.3 展开",
    "text": "23.3 展开\n既然你已经学习了列表和列表列的基础知识，让我们来探讨如何将它们变回常规的行和列。这里我们将使用非常简单的示例数据，以便你了解基本思想；在下一节中，我们将切换到真实数据。\n列表列倾向于以两种基本形式出现：命名的和未命名的。当子元素是 命名 的时，它们在每一行中往往具有相同的名称。例如，在 df1 中，列表列 y 的每个元素都有两个名为 a 和 b 的元素。命名的列表列很自然地展开为列：每个命名元素都成为一个新的命名列。\n\ndf1 &lt;- tribble(\n  ~x, ~y,\n  1, list(a = 11, b = 12),\n  2, list(a = 21, b = 22),\n  3, list(a = 31, b = 32),\n)\n\n当子元素是 未命名 的时，元素的数量往往因行而异。例如，在 df2 中，列表列 y 的元素是未命名的，长度从一到三不等。未命名的列表列很自然地展开为行：每个子元素将得到一行。\n\ndf2 &lt;- tribble(\n  ~x, ~y,\n  1, list(11, 12, 13),\n  2, list(21),\n  3, list(31, 32),\n)\n\ntidyr 为这两种情况提供了两个函数：unnest_wider() 和 unnest_longer()。以下各节将解释它们如何工作。\n\n23.3.1 unnest_wider()\n\n当每一行都有相同数量且名称相同的元素时，比如 df1，很自然地可以用 unnest_wider() 将每个组件放入其自己的列中：\n\ndf1 |&gt; \n  unnest_wider(y)\n#&gt; # A tibble: 3 × 3\n#&gt;       x     a     b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\n默认情况下，新列的名称完全来自列表元素的名称，但你可以使用 names_sep 参数来要求它们将列名和元素名组合起来。这对于消除重复的名称很有用。\n\ndf1 |&gt; \n  unnest_wider(y, names_sep = \"_\")\n#&gt; # A tibble: 3 × 3\n#&gt;       x   y_a   y_b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\n\n23.3.2 unnest_longer()\n\n当每一行都包含一个未命名的列表时，最自然的方式是用 unnest_longer() 将每个元素放入其自己的行中：\n\ndf2 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 6 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11\n#&gt; 2     1    12\n#&gt; 3     1    13\n#&gt; 4     2    21\n#&gt; 5     3    31\n#&gt; 6     3    32\n\n请注意 x 是如何为 y 中的每个元素复制的：对于列表列中的每个元素，我们都会得到一行输出。但是，如果其中一个元素是空的，如下面的例子所示，会发生什么呢？\n\ndf6 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1, 2),\n  \"b\", list(3),\n  \"c\", list()\n)\ndf6 |&gt; unnest_longer(y)\n#&gt; # A tibble: 3 × 2\n#&gt;   x         y\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 a         1\n#&gt; 2 a         2\n#&gt; 3 b         3\n\n我们在输出中得到零行，所以该行实际上消失了。如果你想保留那一行，并在 y 中添加 NA，请设置 keep_empty = TRUE。\n\n23.3.3 类型不一致\n如果你展开一个包含不同类型向量的列表列，会发生什么？例如，看下面的数据集，其中列表列 y 包含两个数字、一个字符和一个逻辑值，这些通常不能混合在单个列中。\n\ndf4 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1),\n  \"b\", list(\"a\", TRUE, 5)\n)\n\nunnest_longer() 总是保持列集合不变，同时改变行的数量。那么会发生什么呢？unnest_longer() 如何在保持 y 中所有内容的同时产生五行？\n\ndf4 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 4 × 2\n#&gt;   x     y        \n#&gt;   &lt;chr&gt; &lt;list&gt;   \n#&gt; 1 a     &lt;dbl [1]&gt;\n#&gt; 2 b     &lt;chr [1]&gt;\n#&gt; 3 b     &lt;lgl [1]&gt;\n#&gt; 4 b     &lt;dbl [1]&gt;\n\n如你所见，输出包含一个列表列，但该列表列的每个元素都包含一个单一元素。因为 unnest_longer() 找不到一个通用的向量类型，它将原始类型保留在一个列表列中。你可能会想，这是否违反了列的每个元素必须是相同类型的规定。并没有：每个元素都是一个列表，尽管其内容是不同类型的。\n处理不一致的类型具有挑战性，具体细节取决于问题的确切性质和你的目标，但你很可能需要来自 Chapter 26 的工具。\n\n23.3.4 其他函数\ntidyr 还有一些其他有用的矩形化函数，我们在这本书中不会涉及：\n\n\nunnest_auto() 会根据列表列的结构自动在 unnest_longer() 和 unnest_wider() 之间进行选择。它对于快速探索非常棒，但最终这不是一个好主意，因为它没有强迫你理解你的数据是如何组织的，并使你的代码更难理解。\n\nunnest() 会同时扩展行和列。当你有一个包含二维结构（如数据框）的列表列时，它很有用，这在这本书中你看不到，但如果你使用 tidymodels 生态系统，你可能会遇到。\n\n了解这些函数是很好的，因为你在阅读他人的代码或自己处理更罕见的矩形化挑战时可能会遇到它们。\n\n23.3.5 练习\n\n当你对像 df2 这样的未命名列表列使用 unnest_wider() 时会发生什么？现在需要哪个参数？缺失值会发生什么变化？\n当你对像 df1 这样的命名列表列使用 unnest_longer() 时会发生什么？你在输出中得到了哪些额外的信息？你如何抑制这些额外的细节？\n\n你有时会遇到具有多个值对齐的列表列的数据框。例如，在下面的数据框中，y 和 z 的值是对齐的（即在一行内 y 和 z 的长度总是相同的，并且 y 的第一个值对应于 z 的第一个值）。如果你对这个数据框应用两次 unnest_longer() 调用会发生什么？你如何保留 x 和 y 之间的关系？（提示：仔细阅读文档）。\n\ndf4 &lt;- tribble(\n  ~x, ~y, ~z,\n  \"a\", list(\"y-a-1\", \"y-a-2\"), list(\"z-a-1\", \"z-a-2\"),\n  \"b\", list(\"y-b-1\", \"y-b-2\", \"y-b-3\"), list(\"z-b-1\", \"z-b-2\", \"z-b-3\")\n)",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "rectangling.html#案例研究",
    "href": "rectangling.html#案例研究",
    "title": "23  层级数据",
    "section": "\n23.4 案例研究",
    "text": "23.4 案例研究\n我们上面使用的简单示例与真实数据之间的主要区别在于，真实数据通常包含多层嵌套，需要多次调用 unnest_longer() 和/或 unnest_wider()。为了展示这一点，本节将使用 repurrrsive 包中的数据集来解决三个真实的矩形化挑战。\n\n23.4.1 非常宽的数据\n我们从 gh_repos 开始。这是一个列表，包含了从 GitHub API 检索到的一系列 GitHub 仓库的数据。这是一个非常深层嵌套的列表，因此很难在本书中展示其结构；我们建议在继续之前，先用 View(gh_repos) 自己探索一下。\ngh_repos 是一个列表，但我们的工具是针对列表列的，所以我们首先将它放入一个 tibble 中。由于我们稍后会讲到的原因，我们称此列为 json。\n\nrepos &lt;- tibble(json = gh_repos)\nrepos\n#&gt; # A tibble: 6 × 1\n#&gt;   json       \n#&gt;   &lt;list&gt;     \n#&gt; 1 &lt;list [30]&gt;\n#&gt; 2 &lt;list [30]&gt;\n#&gt; 3 &lt;list [30]&gt;\n#&gt; 4 &lt;list [26]&gt;\n#&gt; 5 &lt;list [30]&gt;\n#&gt; 6 &lt;list [30]&gt;\n\n这个 tibble 包含 6 行，每行对应 gh_repos 的一个子元素。每一行都包含一个未命名的列表，有 26 或 30 行。由于这些是未命名的，我们将从 unnest_longer() 开始，将每个子元素放入其自己的行中：\n\nrepos |&gt; \n  unnest_longer(json)\n#&gt; # A tibble: 176 × 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [68]&gt;\n#&gt; 2 &lt;named list [68]&gt;\n#&gt; 3 &lt;named list [68]&gt;\n#&gt; 4 &lt;named list [68]&gt;\n#&gt; 5 &lt;named list [68]&gt;\n#&gt; 6 &lt;named list [68]&gt;\n#&gt; # ℹ 170 more rows\n\n乍一看，似乎我们并没有改善情况：虽然我们有了更多的行（176 而不是 6），但 json 的每个元素仍然是一个列表。然而，有一个重要的区别：现在每个元素都是一个 命名 列表，所以我们可以使用 unnest_wider() 将每个元素放入其自己的列中：\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) \n#&gt; # A tibble: 176 × 68\n#&gt;         id name        full_name         owner        private html_url       \n#&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;list&gt;       &lt;lgl&gt;   &lt;chr&gt;          \n#&gt; 1 61160198 after       gaborcsardi/after &lt;named list&gt; FALSE   https://github…\n#&gt; 2 40500181 argufy      gaborcsardi/argu… &lt;named list&gt; FALSE   https://github…\n#&gt; 3 36442442 ask         gaborcsardi/ask   &lt;named list&gt; FALSE   https://github…\n#&gt; 4 34924886 baseimports gaborcsardi/base… &lt;named list&gt; FALSE   https://github…\n#&gt; 5 61620661 citest      gaborcsardi/cite… &lt;named list&gt; FALSE   https://github…\n#&gt; 6 33907457 clisymbols  gaborcsardi/clis… &lt;named list&gt; FALSE   https://github…\n#&gt; # ℹ 170 more rows\n#&gt; # ℹ 62 more variables: description &lt;chr&gt;, fork &lt;lgl&gt;, url &lt;chr&gt;, …\n\n这已经成功了，但结果有点让人不知所措：列太多了，以至于 tibble 甚至没有打印出所有的列！我们可以用 names() 看到所有的列；这里我们看一下前 10 个：\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  names() |&gt; \n  head(10)\n#&gt;  [1] \"id\"          \"name\"        \"full_name\"   \"owner\"       \"private\"    \n#&gt;  [6] \"html_url\"    \"description\" \"fork\"        \"url\"         \"forks_url\"\n\n让我们挑出一些看起来有趣的列：\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description)\n#&gt; # A tibble: 176 × 4\n#&gt;         id full_name               owner             description             \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;list&gt;            &lt;chr&gt;                   \n#&gt; 1 61160198 gaborcsardi/after       &lt;named list [17]&gt; Run Code in the Backgro…\n#&gt; 2 40500181 gaborcsardi/argufy      &lt;named list [17]&gt; Declarative function ar…\n#&gt; 3 36442442 gaborcsardi/ask         &lt;named list [17]&gt; Friendly CLI interactio…\n#&gt; 4 34924886 gaborcsardi/baseimports &lt;named list [17]&gt; Do we get warnings for …\n#&gt; 5 61620661 gaborcsardi/citest      &lt;named list [17]&gt; Test R package and repo…\n#&gt; 6 33907457 gaborcsardi/clisymbols  &lt;named list [17]&gt; Unicode symbols for CLI…\n#&gt; # ℹ 170 more rows\n\n你可以利用这个来回溯理解 gh_repos 的结构：每个子元素都是一个 GitHub 用户，包含一个他们创建的最多 30 个 GitHub 仓库的列表。\nowner 是另一个列表列，由于它包含一个命名的列表，我们可以使用 unnest_wider() 来获取其值：\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner)\n#&gt; Error in `unnest_wider()`:\n#&gt; ! Can't duplicate names between the affected columns and the original\n#&gt;   data.\n#&gt; ✖ These names are duplicated:\n#&gt;   ℹ `id`, from `owner`.\n#&gt; ℹ Use `names_sep` to disambiguate using the column name.\n#&gt; ℹ Or use `names_repair` to specify a repair strategy.\n\n哦哦，这个列表列也包含一个 id 列，我们不能在同一个数据框中有两个 id 列。如建议的那样，让我们使用 names_sep 来解决这个问题：\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner, names_sep = \"_\")\n#&gt; # A tibble: 176 × 20\n#&gt;         id full_name               owner_login owner_id owner_avatar_url     \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;                \n#&gt; 1 61160198 gaborcsardi/after       gaborcsardi   660288 https://avatars.gith…\n#&gt; 2 40500181 gaborcsardi/argufy      gaborcsardi   660288 https://avatars.gith…\n#&gt; 3 36442442 gaborcsardi/ask         gaborcsardi   660288 https://avatars.gith…\n#&gt; 4 34924886 gaborcsardi/baseimports gaborcsardi   660288 https://avatars.gith…\n#&gt; 5 61620661 gaborcsardi/citest      gaborcsardi   660288 https://avatars.gith…\n#&gt; 6 33907457 gaborcsardi/clisymbols  gaborcsardi   660288 https://avatars.gith…\n#&gt; # ℹ 170 more rows\n#&gt; # ℹ 15 more variables: owner_gravatar_id &lt;chr&gt;, owner_url &lt;chr&gt;, …\n\n这又得到了一个很宽的数据集，但你可以感觉到 owner 似乎包含了大量关于“拥有”该仓库的人的额外数据。\n\n23.4.2 关系数据\n嵌套数据有时用于表示我们通常会分散在多个数据框中的数据。例如，got_chars 包含了关于《权力的游戏》书籍和电视剧中出现的角色的数据。和 gh_repos 一样，它是一个列表，所以我们首先将它转换成一个 tibble 的列表列：\n\nchars &lt;- tibble(json = got_chars)\nchars\n#&gt; # A tibble: 30 × 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [18]&gt;\n#&gt; 2 &lt;named list [18]&gt;\n#&gt; 3 &lt;named list [18]&gt;\n#&gt; 4 &lt;named list [18]&gt;\n#&gt; 5 &lt;named list [18]&gt;\n#&gt; 6 &lt;named list [18]&gt;\n#&gt; # ℹ 24 more rows\n\njson 列包含命名的元素，所以我们先用 unnest_wider() 将其展开：\n\nchars |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 30 × 18\n#&gt;   url                    id name            gender culture    born           \n#&gt;   &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          \n#&gt; 1 https://www.anapio…  1022 Theon Greyjoy   Male   \"Ironborn\" \"In 278 AC or …\n#&gt; 2 https://www.anapio…  1052 Tyrion Lannist… Male   \"\"         \"In 273 AC, at…\n#&gt; 3 https://www.anapio…  1074 Victarion Grey… Male   \"Ironborn\" \"In 268 AC or …\n#&gt; 4 https://www.anapio…  1109 Will            Male   \"\"         \"\"             \n#&gt; 5 https://www.anapio…  1166 Areo Hotah      Male   \"Norvoshi\" \"In 257 AC or …\n#&gt; 6 https://www.anapio…  1267 Chett           Male   \"\"         \"At Hag's Mire\"\n#&gt; # ℹ 24 more rows\n#&gt; # ℹ 12 more variables: died &lt;chr&gt;, alive &lt;lgl&gt;, titles &lt;list&gt;, …\n\n然后选择几列以便于阅读：\n\ncharacters &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, name, gender, culture, born, died, alive)\ncharacters\n#&gt; # A tibble: 30 × 7\n#&gt;      id name              gender culture    born              died           \n#&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          \n#&gt; 1  1022 Theon Greyjoy     Male   \"Ironborn\" \"In 278 AC or 27… \"\"             \n#&gt; 2  1052 Tyrion Lannister  Male   \"\"         \"In 273 AC, at C… \"\"             \n#&gt; 3  1074 Victarion Greyjoy Male   \"Ironborn\" \"In 268 AC or be… \"\"             \n#&gt; 4  1109 Will              Male   \"\"         \"\"                \"In 297 AC, at…\n#&gt; 5  1166 Areo Hotah        Male   \"Norvoshi\" \"In 257 AC or be… \"\"             \n#&gt; 6  1267 Chett             Male   \"\"         \"At Hag's Mire\"   \"In 299 AC, at…\n#&gt; # ℹ 24 more rows\n#&gt; # ℹ 1 more variable: alive &lt;lgl&gt;\n\n这个数据集也包含许多列表列：\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list))\n#&gt; # A tibble: 30 × 8\n#&gt;      id titles    aliases    allegiances books     povBooks tvSeries playedBy\n#&gt;   &lt;int&gt; &lt;list&gt;    &lt;list&gt;     &lt;list&gt;      &lt;list&gt;    &lt;list&gt;   &lt;list&gt;   &lt;list&gt;  \n#&gt; 1  1022 &lt;chr [2]&gt; &lt;chr [4]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 2  1052 &lt;chr [2]&gt; &lt;chr [11]&gt; &lt;chr [1]&gt;   &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 3  1074 &lt;chr [2]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 4  1109 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [1]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 5  1166 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 6  1267 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; # ℹ 24 more rows\n\n让我们来探索 titles 列。它是一个未命名的列表列，所以我们把它展开成行：\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles)\n#&gt; # A tibble: 59 × 2\n#&gt;      id titles                                              \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # ℹ 53 more rows\n\n你可能期望看到这些数据在它自己的表中，因为这样很容易按需连接到角色数据。让我们这样做，这需要一点清理：删除包含空字符串的行，并将 titles 重命名为 title，因为现在每行只包含一个头衔。\n\ntitles &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles) |&gt; \n  filter(titles != \"\") |&gt; \n  rename(title = titles)\ntitles\n#&gt; # A tibble: 52 × 2\n#&gt;      id title                                               \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # ℹ 46 more rows\n\n你可以想象为每个列表列创建这样的一个表，然后在需要时使用连接将它们与角色数据结合起来。\n\n23.4.3 深度嵌套\n我们将用一个非常深度嵌套的列表列来结束这些案例研究，它需要反复使用 unnest_wider() 和 unnest_longer() 来解开：gmaps_cities。这是一个两列的 tibble，包含五个城市名称和使用谷歌的 地理编码 API 来确定它们位置的结果：\n\ngmaps_cities\n#&gt; # A tibble: 5 × 2\n#&gt;   city       json            \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [2]&gt;\n#&gt; 2 Washington &lt;named list [2]&gt;\n#&gt; 3 New York   &lt;named list [2]&gt;\n#&gt; 4 Chicago    &lt;named list [2]&gt;\n#&gt; 5 Arlington  &lt;named list [2]&gt;\n\njson 是一个带有内部名称的列表列，所以我们从 unnest_wider() 开始：\n\ngmaps_cities |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 5 × 3\n#&gt;   city       results    status\n#&gt;   &lt;chr&gt;      &lt;list&gt;     &lt;chr&gt; \n#&gt; 1 Houston    &lt;list [1]&gt; OK    \n#&gt; 2 Washington &lt;list [2]&gt; OK    \n#&gt; 3 New York   &lt;list [1]&gt; OK    \n#&gt; 4 Chicago    &lt;list [1]&gt; OK    \n#&gt; 5 Arlington  &lt;list [2]&gt; OK\n\n这给了我们 status 和 results。我们将丢弃 status 列，因为它们都是 OK；在真实的分析中，你还需要捕获所有 status != \"OK\" 的行，并找出问题所在。results 是一个未命名的列表，有一或两个元素（我们很快会看到为什么），所以我们将它展开成行：\n\ngmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results)\n#&gt; # A tibble: 7 × 2\n#&gt;   city       results         \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [5]&gt;\n#&gt; 2 Washington &lt;named list [5]&gt;\n#&gt; 3 Washington &lt;named list [5]&gt;\n#&gt; 4 New York   &lt;named list [5]&gt;\n#&gt; 5 Chicago    &lt;named list [5]&gt;\n#&gt; 6 Arlington  &lt;named list [5]&gt;\n#&gt; # ℹ 1 more row\n\n现在 results 是一个命名的列表，所以我们使用 unnest_wider()：\n\nlocations &lt;- gmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\nlocations\n#&gt; # A tibble: 7 × 6\n#&gt;   city       address_components formatted_address   geometry        \n#&gt;   &lt;chr&gt;      &lt;list&gt;             &lt;chr&gt;               &lt;list&gt;          \n#&gt; 1 Houston    &lt;list [4]&gt;         Houston, TX, USA    &lt;named list [4]&gt;\n#&gt; 2 Washington &lt;list [2]&gt;         Washington, USA     &lt;named list [4]&gt;\n#&gt; 3 Washington &lt;list [4]&gt;         Washington, DC, USA &lt;named list [4]&gt;\n#&gt; 4 New York   &lt;list [3]&gt;         New York, NY, USA   &lt;named list [4]&gt;\n#&gt; 5 Chicago    &lt;list [4]&gt;         Chicago, IL, USA    &lt;named list [4]&gt;\n#&gt; 6 Arlington  &lt;list [4]&gt;         Arlington, TX, USA  &lt;named list [4]&gt;\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 2 more variables: place_id &lt;chr&gt;, types &lt;list&gt;\n\n现在我们可以看到为什么有两个城市得到了两个结果：华盛顿 (Washington) 匹配了华盛顿州 (Washington state) 和华盛顿特区 (Washington, DC)，阿灵顿 (Arlington) 匹配了弗吉尼亚州的阿灵顿 (Arlington, Virginia) 和德克萨斯州的阿灵顿 (Arlington, Texas)。\n从这里我们可以走向几个不同的方向。我们可能想确定匹配的精确位置，这存储在 geometry 列表列中：\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry)\n#&gt; # A tibble: 7 × 6\n#&gt;   city       formatted_address   bounds           location     location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;       &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: viewport &lt;list&gt;\n\n这给了我们新的 bounds（一个矩形区域）和 location（一个点）。我们可以展开 location 来查看纬度 (lat) 和经度 (lng)：\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  unnest_wider(location)\n#&gt; # A tibble: 7 × 7\n#&gt;   city       formatted_address   bounds             lat    lng location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt;  29.8  -95.4 APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt;  47.8 -121.  APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt;  38.9  -77.0 APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt;  40.7  -74.0 APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt;  41.9  -87.6 APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt;  32.7  -97.1 APPROXIMATE  \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: viewport &lt;list&gt;\n\n提取边界需要更多几个步骤：\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  # 专注于感兴趣的变量\n  select(!location:viewport) |&gt;\n  unnest_wider(bounds)\n#&gt; # A tibble: 7 × 4\n#&gt;   city       formatted_address   northeast        southwest       \n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;          \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; # ℹ 1 more row\n\n然后我们重命名 southwest 和 northeast（矩形的角点），这样我们就可以使用 names_sep 来创建简短但有意义的名称：\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  select(!location:viewport) |&gt;\n  unnest_wider(bounds) |&gt; \n  rename(ne = northeast, sw = southwest) |&gt; \n  unnest_wider(c(ne, sw), names_sep = \"_\") \n#&gt; # A tibble: 7 × 6\n#&gt;   city       formatted_address   ne_lat ne_lng sw_lat sw_lng\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Houston    Houston, TX, USA      30.1  -95.0   29.5  -95.8\n#&gt; 2 Washington Washington, USA       49.0 -117.    45.5 -125. \n#&gt; 3 Washington Washington, DC, USA   39.0  -76.9   38.8  -77.1\n#&gt; 4 New York   New York, NY, USA     40.9  -73.7   40.5  -74.3\n#&gt; 5 Chicago    Chicago, IL, USA      42.0  -87.5   41.6  -87.9\n#&gt; 6 Arlington  Arlington, TX, USA    32.8  -97.0   32.6  -97.2\n#&gt; # ℹ 1 more row\n\n注意我们如何通过向 unnest_wider() 提供一个变量名称的向量来同时展开两列。\n一旦你找到了到达你感兴趣的组件的路径，你可以使用另一个 tidyr 函数 hoist() 直接提取它们：\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  hoist(\n    geometry,\n    ne_lat = c(\"bounds\", \"northeast\", \"lat\"),\n    sw_lat = c(\"bounds\", \"southwest\", \"lat\"),\n    ne_lng = c(\"bounds\", \"northeast\", \"lng\"),\n    sw_lng = c(\"bounds\", \"southwest\", \"lng\"),\n  )\n\n如果这些案例研究激发了你对更多现实生活中的矩形化问题的兴趣，你可以在 vignette(\"rectangling\", package = \"tidyr\") 中看到更多例子。\n\n23.4.4 练习\n\n粗略估计 gh_repos 是何时创建的。为什么你只能粗略估计日期？\ngh_repo 的 owner 列包含大量重复信息，因为每个所有者可以有多个仓库。你能否构建一个 owners 数据框，其中每个所有者只有一行？（提示：distinct() 对 list-cols 有效吗？）\n按照用于 titles 的步骤，为《权力的游戏》角色的别名 (aliases)、效忠 (allegiances)、书籍 (books) 和电视剧集 (TV series) 创建类似的表。\n\n逐行解释以下代码。它为什么有趣？为什么它对 got_chars 有效，但在一般情况下可能无效？\n\ntibble(json = got_chars) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list)) |&gt; \n  pivot_longer(\n    where(is.list), \n    names_to = \"name\", \n    values_to = \"value\"\n  ) |&gt;  \n  unnest_longer(value)\n\n\n在 gmaps_cities 中，address_components 包含什么？为什么行与行之间的长度不同？适当地展开它来找出答案。（提示：types 似乎总是包含两个元素。使用 unnest_wider() 是否比 unnest_longer() 更容易处理？）",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "rectangling.html#json",
    "href": "rectangling.html#json",
    "title": "23  层级数据",
    "section": "\n23.5 JSON",
    "text": "23.5 JSON\n上一节的所有案例研究都来源于现实世界中捕获的 JSON。JSON 是 JavaScript Object Notation (JavaScript 对象表示法) 的缩写，是大多数 Web API 返回数据的方式。理解它很重要，因为尽管 JSON 和 R 的数据类型非常相似，但并不存在完美的 1 对 1 映射，所以如果出现问题，了解一些关于 JSON 的知识是很有好处的。\n\n23.5.1 数据类型\nJSON 是一种简单的格式，设计用于机器轻松读写，而不是人类。它有六种关键的数据类型。其中四种是标量 (scalar)：\n\n最简单的类型是空值 (null)，它在 R 中扮演与 NA 相同的角色。它表示数据的缺失。\n\n字符串 (string) 很像 R 中的字符串，但必须始终使用双引号。\n\n数字 (number) 类似于 R 的数字：它们可以使用整数（例如，123）、小数（例如，123.45）或科学记数法（例如，1.23e3）。JSON 不支持 Inf、-Inf 或 NaN。\n\n布尔值 (boolean) 类似于 R 的 TRUE 和 FALSE，但使用小写的 true 和 false。\n\nJSON 的字符串、数字和布尔值与 R 的字符、数值和逻辑向量非常相似。主要区别在于 JSON 的标量只能表示单个值。要表示多个值，你需要使用剩下的两种类型之一：数组 (array) 和对象 (object)。\n数组和对象都类似于 R 中的列表；区别在于它们是否被命名。数组 就像一个未命名的列表，用 [] 书写。例如 [1, 2, 3] 是一个包含 3 个数字的数组，而 [null, 1, \"string\", false] 是一个包含空值、数字、字符串和布尔值的数组。对象 就像一个命名的列表，用 {} 书写。名称（在 JSON 术语中称为键 (key)）是字符串，因此必须用引号括起来。例如，{\"x\": 1, \"y\": 2} 是一个将 x 映射到 1，y 映射到 2 的对象。\n请注意，JSON 没有任何表示日期或日期时间的本地方式，因此它们通常作为字符串存储，你需要使用 readr::parse_date() 或 readr::parse_datetime() 将它们转换为正确的数据结构。同样，JSON 表示浮点数的规则有点不精确，所以你有时也会发现数字存储在字符串中。根据需要应用 readr::parse_double() 来获得正确的变量类型。\n\n23.5.2 jsonlite\n要将 JSON 转换为 R 的数据结构，我们推荐 Jeroen Ooms 开发的 jsonlite 包。我们将只使用两个 jsonlite 函数：read_json() 和 parse_json()。在实际生活中，你会使用 read_json() 从磁盘读取 JSON 文件。例如，repurrrsive 包也提供了 gh_user 的源数据作为 JSON 文件，你可以用 read_json() 读取它：\n\n# 包内一个 json 文件的路径：\ngh_users_json()\n#&gt; [1] \"C:/Users/14913/AppData/Local/R/win-library/4.5/repurrrsive/extdata/gh_users.json\"\n\n# 用 read_json() 读取它\ngh_users2 &lt;- read_json(gh_users_json())\n\n# 检查它是否与我们之前使用的数据相同\nidentical(gh_users, gh_users2)\n#&gt; [1] TRUE\n\n在本书中，我们还会使用 parse_json()，因为它接受一个包含 JSON 的字符串，这对于生成简单的例子很有用。首先，这里有三个简单的 JSON 数据集，从一个数字开始，然后将几个数字放入一个数组，再将该数组放入一个对象中：\n\nstr(parse_json('1'))\n#&gt;  int 1\nstr(parse_json('[1, 2, 3]'))\n#&gt; List of 3\n#&gt;  $ : int 1\n#&gt;  $ : int 2\n#&gt;  $ : int 3\nstr(parse_json('{\"x\": [1, 2, 3]}'))\n#&gt; List of 1\n#&gt;  $ x:List of 3\n#&gt;   ..$ : int 1\n#&gt;   ..$ : int 2\n#&gt;   ..$ : int 3\n\njsonlite 还有另一个重要的函数叫做 fromJSON()。我们在这里不使用它，因为它会执行自动简化 (simplifyVector = TRUE)。这在简单情况下通常效果很好，但我们认为你自己进行矩形化会更好，这样你就确切地知道发生了什么，并且可以更容易地处理最复杂的嵌套结构。\n\n23.5.3 开始矩形化过程\n在大多数情况下，JSON 文件包含一个单一的顶层数组，因为它们被设计用来提供关于多个“事物”的数据，例如，多个页面、多个记录或多个结果。在这种情况下，你将以 tibble(json) 开始你的矩形化，以便每个元素都成为一行：\n\njson &lt;- '[\n  {\"name\": \"John\", \"age\": 34},\n  {\"name\": \"Susan\", \"age\": 27}\n]'\ndf &lt;- tibble(json = parse_json(json))\ndf\n#&gt; # A tibble: 2 × 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n#&gt; 2 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 2 × 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\n在更罕见的情况下，JSON 文件由一个单一的顶层 JSON 对象组成，代表一个“事物”。在这种情况下，你需要通过将其包装在一个列表中来启动矩形化过程，然后再将其放入 tibble 中。\n\njson &lt;- '{\n  \"status\": \"OK\", \n  \"results\": [\n    {\"name\": \"John\", \"age\": 34},\n    {\"name\": \"Susan\", \"age\": 27}\n ]\n}\n'\ndf &lt;- tibble(json = list(parse_json(json)))\ndf\n#&gt; # A tibble: 1 × 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 × 3\n#&gt;   status name    age\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 OK     John     34\n#&gt; 2 OK     Susan    27\n\n或者，你可以深入到解析后的 JSON 内部，从你真正关心的部分开始：\n\ndf &lt;- tibble(results = parse_json(json)$results)\ndf |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 × 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\n\n23.5.4 练习\n\n\n将下面的 df_col 和 df_row 进行矩形化。它们代表了在 JSON 中编码数据框的两种方式。\n\njson_col &lt;- parse_json('\n  {\n    \"x\": [\"a\", \"x\", \"z\"],\n    \"y\": [10, null, 3]\n  }\n')\njson_row &lt;- parse_json('\n  [\n    {\"x\": \"a\", \"y\": 10},\n    {\"x\": \"x\", \"y\": null},\n    {\"x\": \"z\", \"y\": 3}\n  ]\n')\n\ndf_col &lt;- tibble(json = list(json_col)) \ndf_row &lt;- tibble(json = json_row)",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "rectangling.html#总结",
    "href": "rectangling.html#总结",
    "title": "23  层级数据",
    "section": "\n23.6 总结",
    "text": "23.6 总结\n在本章中，你学习了什么是列表，如何从 JSON 文件生成它们，以及如何将它们转换为矩形数据框。令人惊讶的是，我们只需要两个新函数：unnest_longer() 用于将列表元素放入行中，unnest_wider() 用于将列表元素放入列中。无论列表列的嵌套有多深，你所需要做的就是重复调用这两个函数。\nJSON 是 Web API 返回的最常见的数据格式。如果网站没有 API，但你可以在网站上看到你想要的数据，那该怎么办呢？这就是下一章的主题：网络抓取 (web scraping)，从 HTML 网页中提取数据。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "rectangling.html#footnotes",
    "href": "rectangling.html#footnotes",
    "title": "23  层级数据",
    "section": "",
    "text": "这是 RStudio 的一个功能。↩︎",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>层级数据</span>"
    ]
  },
  {
    "objectID": "webscraping.html",
    "href": "webscraping.html",
    "title": "24  网络抓取",
    "section": "",
    "text": "24.1 引言\n本章将向你介绍使用 rvest 进行网络抓取 (web scraping) 的基础知识。网络抓取是从网页中提取数据的一个非常有用的工具。有些网站会提供 API，这是一组结构化的 HTTP 请求，以 JSON 格式返回数据，你可以使用 Chapter 23 中介绍的技术来处理这些数据。如果可能，你应该使用 API 1，因为它通常会为你提供更可靠的数据。然而，不幸的是，使用 Web API 进行编程超出了本书的范围。因此，我们教授的是抓取技术，无论网站是否提供 API，这种技术都适用。\n在本章中，我们首先会讨论抓取的伦理和法律问题，然后再深入探讨 HTML 的基础知识。接着，你将学习 CSS 选择器的基础知识，以定位页面上的特定元素，以及如何使用 rvest 函数从 HTML 中提取文本和属性数据并将其导入 R。然后，我们将讨论一些技巧，以帮助你确定所需页面的 CSS 选择器，最后通过几个案例研究结束，并简要讨论动态网站。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#引言",
    "href": "webscraping.html#引言",
    "title": "24  网络抓取",
    "section": "",
    "text": "24.1.1 先决条件\n在本章中，我们将重点介绍 rvest 提供的工具。rvest 是 tidyverse 的一个成员，但不是核心成员，所以你需要显式加载它。我们还将加载完整的 tidyverse，因为在处理我们抓取的数据时，它通常很有用。\n\nlibrary(tidyverse)\nlibrary(rvest)",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#抓取的伦理和法律",
    "href": "webscraping.html#抓取的伦理和法律",
    "title": "24  网络抓取",
    "section": "\n24.2 抓取的伦理和法律",
    "text": "24.2 抓取的伦理和法律\n在我们开始讨论执行网络抓取所需的代码之前，我们需要谈谈这样做是否合法和合乎道德。总的来说，这两种情况都很复杂。\n合法性在很大程度上取决于你所在的地区。然而，作为一般原则，如果数据是公开的、非个人的和事实性的，你很可能是安全的 2。这三个因素很重要，因为它们与网站的服务条款、个人身份信息和版权有关，我们将在下面讨论。\n如果数据不是公开的、非个人的或事实性的，或者你抓取数据的目的就是为了赚钱，那么你需要咨询律师。在任何情况下，你都应该尊重托管你正在抓取的页面的服务器资源。最重要的是，这意味着如果你要抓取许多页面，你应该确保在每个请求之间稍作等待。一个简单的方法是使用 Dmytro Perepolkin 的 polite 包。它会自动在请求之间暂停，并缓存结果，这样你就永远不会两次请求同一个页面。\n\n24.2.1 服务条款\n如果你仔细观察，你会发现许多网站在页面的某个地方包含一个“条款和条件”或“服务条款”的链接，如果你仔细阅读那个页面，你通常会发现该网站明确禁止网络抓取。这些页面往往是公司提出非常宽泛主张的法律“圈地”。在可能的情况下，尊重这些服务条款是礼貌的，但对任何主张都要持保留态度。\n美国法院通常认为，仅仅将服务条款放在网站页脚不足以使你受其约束，例如 HiQ Labs v. LinkedIn。通常，要受服务条款约束，你必须采取一些明确的行动，比如创建账户或勾选一个框。这就是为什么数据是否公开很重要的原因；如果你不需要账户就能访问它们，你就不太可能受服务条款的约束。但请注意，在欧洲情况大不相同，法院认为即使你没有明确同意，服务条款也是可执行的。\n\n24.2.2 个人身份信息\n即使数据是公开的，你也应该极其小心地抓取个人身份信息 (personally identifiable information)，如姓名、电子邮件地址、电话号码、出生日期等。欧洲对收集或存储此类数据有特别严格的法律 (GDPR)，无论你住在哪里，你都可能陷入道德困境。例如，2016 年，一组研究人员抓取了约会网站 OkCupid 上 70,000 人的公开个人资料信息（例如，用户名、年龄、性别、位置等），并在没有任何匿名化尝试的情况下公开发布了这些数据。虽然研究人员认为这样做没有错，因为数据已经是公开的，但这项工作因涉及用户身份可识别性的伦理问题而受到广泛谴责。如果你的工作涉及抓取个人身份信息，我们强烈建议阅读关于 OkCupid 研究 3 以及涉及获取和发布个人身份信息且研究伦理存疑的类似研究的资料。\n\n24.2.3 版权\n最后，你还需要担心版权法。版权法很复杂，但值得一看的是美国法律，它准确描述了受保护的内容：“[…] 固定在任何有形表达媒介中的原创作者作品 […]”。然后它继续描述了它适用的具体类别，如文学作品、音乐作品、电影等。值得注意的是，数据不在版权保护之列。这意味着，只要你将抓取限制在事实上，版权保护就不适用。（但请注意，欧洲有一项单独的“特殊权利” (sui generis)，用于保护数据库。）\n举个简单的例子，在美国，配料和说明的列表不受版权保护，所以版权不能用来保护食谱。但是，如果那份食谱列表伴随着大量新颖的文学内容，那么这些内容是受版权保护的。这就是为什么当你在互联网上寻找食谱时，总是有那么多前置内容的原因。\n如果你确实需要抓取原创内容（如文本或图片），你可能仍然受到合理使用原则 (doctrine of fair use) 的保护。合理使用不是一个硬性规定，而是权衡了许多因素。如果你是为了研究或非商业目的收集数据，并且你将抓取的内容限制在所需范围内，那么它更有可能适用。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#html-基础",
    "href": "webscraping.html#html-基础",
    "title": "24  网络抓取",
    "section": "\n24.3 HTML 基础",
    "text": "24.3 HTML 基础\n要抓取网页，你首先需要对 HTML 有一点了解，这是一种描述网页的语言。HTML 是超文本标记语言 (HyperText Markup Language) 的缩写，看起来像这样：\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;页面标题&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='first'&gt;一个标题&lt;/h1&gt;\n  &lt;p&gt;一些文本 & &lt;b&gt;一些粗体文本。&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\nHTML 具有由元素 (elements) 构成的层次结构，元素由一个开始标签 (start tag)（例如 &lt;tag&gt;）、可选的属性 (attributes)（id='first'）、一个结束标签 (end tag) 4（例如 &lt;/tag&gt;）和内容 (contents)（开始和结束标签之间的所有内容）组成。\n由于 &lt; 和 &gt; 用于开始和结束标签，你不能直接写它们。你必须使用 HTML 转义 (escapes) &gt; (大于) 和 &lt; (小于)。并且由于这些转义使用了 &，如果你想要一个字面上的 & 符号，你必须将其转义为 &amp;。有各种各样的 HTML 转义，但你不需要太担心它们，因为 rvest 会自动为你处理。\n网络抓取之所以可行，是因为大多数包含你想要抓取的数据的页面通常都有一个一致的结构。\n\n24.3.1 元素\nHTML 元素有 100 多种。其中一些最重要的元素是：\n\n每个 HTML 页面都必须在一个 &lt;html&gt; 元素中，并且它必须有两个子元素：&lt;head&gt;，包含文档元数据，如页面标题；以及 &lt;body&gt;，包含你在浏览器中看到的内容。\n块级标签，如 &lt;h1&gt; (一级标题)、&lt;section&gt; (区域)、&lt;p&gt; (段落) 和 &lt;ol&gt; (有序列表)，构成了页面的整体结构。\n内联标签，如 &lt;b&gt; (粗体)、&lt;i&gt; (斜体) 和 &lt;a&gt; (链接)，用于格式化块级标签内的文本。\n\n如果你遇到一个你从未见过的标签，你可以通过谷歌搜索来了解它的作用。另一个好的起点是 MDN Web Docs，它描述了几乎所有 Web 编程的方面。\n大多数元素在其开始和结束标签之间可以有内容。这个内容可以是文本，也可以是更多的元素。例如，下面的 HTML 包含一个文本段落，其中一个词是粗体的。\n&lt;p&gt;\n  嗨！我的&lt;b&gt;名字&lt;/b&gt;是 Hadley。\n&lt;/p&gt;\n子元素 (children) 是它包含的元素，所以上面的 &lt;p&gt; 元素有一个子元素，即 &lt;b&gt; 元素。&lt;b&gt; 元素没有子元素，但它有内容（文本“名字”）。\n\n24.3.2 属性\n标签可以有命名的属性 (attributes)，看起来像 name1='value1' name2='value2'。两个最重要的属性是 id 和 class，它们与 CSS (Cascading Style Sheets) 结合使用，以控制页面的视觉外观。在抓取数据时，这些属性通常很有用。属性还用于记录链接的目的地（&lt;a&gt; 元素的 href 属性）和图像的来源（&lt;img&gt; 元素的 src 属性）。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#提取数据",
    "href": "webscraping.html#提取数据",
    "title": "24  网络抓取",
    "section": "\n24.4 提取数据",
    "text": "24.4 提取数据\n要开始抓取，你需要你想要抓取的页面的 URL，你通常可以从你的网络浏览器中复制。然后，你需要使用 read_html() 将该页面的 HTML 读入 R。这将返回一个 xml_document 5 对象，然后你将使用 rvest 函数来操作它：\n\nhtml &lt;- read_html(\"http://rvest.tidyverse.org/\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html lang=\"en\"&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n    &lt;a href=\"#container\" class=\"visually-hidden-focusable\"&gt;Ski ...\n\nrvest 还包含一个函数，可以让你内联编写 HTML。在本章中，我们将大量使用这个函数，因为我们通过简单的例子来教授各种 rvest 函数的工作方式。\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;这是一个段落&lt;/p&gt;\n  &lt;ul&gt;\n    &lt;li&gt;这是一个项目符号列表&lt;/li&gt;\n  &lt;/ul&gt;\n\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n&lt;p&gt;这是一个段落&lt;/p&gt;\\n  &lt;ul&gt;\\n&lt;li&gt;这是一个项目符号列表&lt;/li&gt;\\n  &lt;/ul&gt;\\n&lt;/body&gt;\n\n现在你已经在 R 中有了 HTML，是时候提取感兴趣的数据了。你将首先学习 CSS 选择器，它允许你识别感兴趣的元素，以及你可以用来从中提取数据的 rvest 函数。然后我们将简要介绍 HTML 表格，它有一些特殊的工具。\n\n24.4.1 查找元素\nCSS 是层叠样式表 (cascading style sheets) 的缩写，是一种用于定义 HTML 文档视觉样式的工具。CSS 包括一种用于在页面上选择元素的微型语言，称为 CSS 选择器 (CSS selectors)。CSS 选择器定义了定位 HTML 元素的模式，对于抓取很有用，因为它们提供了一种简洁的方式来描述你想要提取的元素。\n我们将在 Section 24.5 中更详细地回到 CSS 选择器，但幸运的是，你只需掌握三个就可以走得很远：\n\np 选择所有 &lt;p&gt; 元素。\n.title 选择所有 class 为 “title” 的元素。\n#title 选择 id 属性等于 “title” 的元素。Id 属性在文档中必须是唯一的，所以这只会选择一个元素。\n\n让我们用一个简单的例子来试试这些选择器：\n\nhtml &lt;- minimal_html(\"\n  &lt;h1&gt;这是一个标题&lt;/h1&gt;\n  &lt;p id='first'&gt;这是一个段落&lt;/p&gt;\n  &lt;p class='important'&gt;这是一个重要的段落&lt;/p&gt;\n\")\n\n使用 html_elements() 来查找所有匹配选择器的元素：\n\nhtml |&gt; html_elements(\"p\")\n#&gt; {xml_nodeset (2)}\n#&gt; [1] &lt;p id=\"first\"&gt;这是一个段落&lt;/p&gt;\n#&gt; [2] &lt;p class=\"important\"&gt;这是一个重要的段落&lt;/p&gt;\nhtml |&gt; html_elements(\".important\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p class=\"important\"&gt;这是一个重要的段落&lt;/p&gt;\nhtml |&gt; html_elements(\"#first\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p id=\"first\"&gt;这是一个段落&lt;/p&gt;\n\n另一个重要的函数是 html_element()，它总是返回与输入相同数量的输出。如果你将它应用于整个文档，它会给你第一个匹配项：\n\nhtml |&gt; html_element(\"p\")\n#&gt; {html_node}\n#&gt; &lt;p id=\"first\"&gt;\n\n当你使用一个不匹配任何元素的选择器时，html_element() 和 html_elements() 之间有一个重要的区别。html_elements() 返回一个长度为 0 的向量，而 html_element() 返回一个缺失值。这一点很快就会变得很重要。\n\nhtml |&gt; html_elements(\"b\")\n#&gt; {xml_nodeset (0)}\nhtml |&gt; html_element(\"b\")\n#&gt; {xml_missing}\n#&gt; &lt;NA&gt;\n\n\n24.4.2 嵌套选择\n在大多数情况下，你会一起使用 html_elements() 和 html_element()，通常使用 html_elements() 来识别将成为观测值的元素，然后使用 html_element() 来查找将成为变量的元素。让我们通过一个简单的例子来看看这个过程。这里我们有一个无序列表 (&lt;ul&gt;)，其中每个列表项 (&lt;li&gt;) 都包含一些关于星球大战中四个角色的信息：\n\nhtml &lt;- minimal_html(\"\n  &lt;ul&gt;\n    &lt;li&gt;&lt;b&gt;C-3PO&lt;/b&gt; 是一个&lt;i&gt;机器人&lt;/i&gt;，重 &lt;span class='weight'&gt;167 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R4-P17&lt;/b&gt; 是一个&lt;i&gt;机器人&lt;/i&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R2-D2&lt;/b&gt; 是一个&lt;i&gt;机器人&lt;/i&gt;，重 &lt;span class='weight'&gt;96 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;Yoda&lt;/b&gt; 重 &lt;span class='weight'&gt;66 kg&lt;/span&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n  \")\n\n我们可以使用 html_elements() 来创建一个向量，其中每个元素对应一个不同的角色：\n\ncharacters &lt;- html |&gt; html_elements(\"li\")\ncharacters\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;li&gt;\\n&lt;b&gt;C-3PO&lt;/b&gt; 是一个&lt;i&gt;机器人&lt;/i&gt;，重 &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;\\ ...\n#&gt; [2] &lt;li&gt;\\n&lt;b&gt;R4-P17&lt;/b&gt; 是一个&lt;i&gt;机器人&lt;/i&gt;\\n&lt;/li&gt;\n#&gt; [3] &lt;li&gt;\\n&lt;b&gt;R2-D2&lt;/b&gt; 是一个&lt;i&gt;机器人&lt;/i&gt;，重 &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;\\n ...\n#&gt; [4] &lt;li&gt;\\n&lt;b&gt;Yoda&lt;/b&gt; 重 &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\\n&lt;/li&gt;\n\n要提取每个角色的名字，我们使用 html_element()，因为当它应用于 html_elements() 的输出时，它保证为每个元素返回一个响应：\n\ncharacters |&gt; html_element(\"b\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;b&gt;C-3PO&lt;/b&gt;\n#&gt; [2] &lt;b&gt;R4-P17&lt;/b&gt;\n#&gt; [3] &lt;b&gt;R2-D2&lt;/b&gt;\n#&gt; [4] &lt;b&gt;Yoda&lt;/b&gt;\n\nhtml_element() 和 html_elements() 之间的区别对于名字来说并不重要，但对于体重来说很重要。我们希望为每个角色获得一个体重，即使没有体重 &lt;span&gt;。这就是 html_element() 所做的：\n\ncharacters |&gt; html_element(\".weight\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;\n#&gt; [2] NA\n#&gt; [3] &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;\n#&gt; [4] &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\n\nhtml_elements() 查找所有作为 characters 子元素的体重 &lt;span&gt;。这里只有三个，所以我们失去了名字和体重之间的联系：\n\ncharacters |&gt; html_elements(\".weight\")\n#&gt; {xml_nodeset (3)}\n#&gt; [1] &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;\n#&gt; [2] &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;\n#&gt; [3] &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\n\n现在你已经选择了感兴趣的元素，你需要提取数据，可以从文本内容或某些属性中提取。\n\n24.4.3 文本和属性\nhtml_text2()6 提取 HTML 元素的纯文本内容：\n\ncharacters |&gt; \n  html_element(\"b\") |&gt; \n  html_text2()\n#&gt; [1] \"C-3PO\"  \"R4-P17\" \"R2-D2\"  \"Yoda\"\n\ncharacters |&gt; \n  html_element(\".weight\") |&gt; \n  html_text2()\n#&gt; [1] \"167 kg\" NA       \"96 kg\"  \"66 kg\"\n\n注意，任何转义都会被自动处理；你只会在源 HTML 中看到 HTML 转义，而不会在 rvest 返回的数据中看到。\nhtml_attr() 从属性中提取数据：\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Cat'&gt;猫&lt;/a&gt;&lt;/p&gt;\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Dog'&gt;狗&lt;/a&gt;&lt;/p&gt;\n\")\n\nhtml |&gt; \n  html_elements(\"p\") |&gt; \n  html_element(\"a\") |&gt; \n  html_attr(\"href\")\n#&gt; [1] \"https://en.wikipedia.org/wiki/Cat\" \"https://en.wikipedia.org/wiki/Dog\"\n\nhtml_attr() 总是返回一个字符串，所以如果你正在提取数字或日期，你需要进行一些后处理。\n\n24.4.4 表格\n如果幸运的话，你的数据已经存储在 HTML 表格中，那么只需要从该表格中读取即可。在浏览器中识别表格通常很简单：它会有一个行和列的矩形结构，你可以将其复制并粘贴到像 Excel 这样的工具中。\nHTML 表格由四个主要元素构成：&lt;table&gt;、&lt;tr&gt;（表格行）、&lt;th&gt;（表格标题）和 &lt;td&gt;（表格数据）。这是一个简单的 HTML 表格，有两列三行：\n\nhtml &lt;- minimal_html(\"\n  &lt;table class='mytable'&gt;\n    &lt;tr&gt;&lt;th&gt;x&lt;/th&gt;    &lt;th&gt;y&lt;/th&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;1.5&lt;/td&gt; &lt;td&gt;2.7&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;4.9&lt;/td&gt; &lt;td&gt;1.3&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;7.2&lt;/td&gt; &lt;td&gt;8.1&lt;/td&gt;&lt;/tr&gt;\n  &lt;/table&gt;\n  \")\n\nrvest 提供了一个知道如何读取这类数据的函数：html_table()。它返回一个列表，其中包含页面上找到的每个表格的一个 tibble。使用 html_element() 来识别你想要提取的表格：\n\nhtml |&gt; \n  html_element(\".mytable\") |&gt; \n  html_table()\n#&gt; # A tibble: 3 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   1.5   2.7\n#&gt; 2   4.9   1.3\n#&gt; 3   7.2   8.1\n\n注意 x 和 y 已经自动转换为数字。这种自动转换并不总是有效，所以在更复杂的场景中，你可能需要使用 convert = FALSE 关闭它，然后自己进行转换。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#sec-css-selectors",
    "href": "webscraping.html#sec-css-selectors",
    "title": "24  网络抓取",
    "section": "\n24.5 找到正确的选择器",
    "text": "24.5 找到正确的选择器\n找出你需要的数据的选择器通常是问题中最难的部分。你通常需要进行一些实验，才能找到一个既具体（即它不选择你不在乎的东西）又敏感（即它确实选择了你关心的所有东西）的选择器。大量的反复试验是这个过程的正常部分！有两个主要工具可以帮助你完成这个过程：SelectorGadget 和你浏览器的开发者工具。\nSelectorGadget 是一个 javascript 书签工具，它会根据你提供的正面和负面例子自动生成 CSS 选择器。它并不总是有效，但当它有效时，简直是魔法！你可以通过阅读 https://rvest.tidyverse.org/articles/selectorgadget.html 或观看 Mine 在 https://www.youtube.com/watch?v=PetWV5g1Xsc 上的视频来学习如何安装和使用 SelectorGadget。\n每个现代浏览器都带有一些面向开发者的工具包，但我们推荐 Chrome，即使它不是你的常规浏览器：它的 Web 开发者工具是最好的之一，而且立即可用。在页面上的一个元素上右键单击，然后点击 Inspect (检查)。这将打开一个可展开的完整 HTML 页面视图，并以你刚刚点击的元素为中心。你可以用它来探索页面，并了解哪些选择器可能有效。要特别注意 class 和 id 属性，因为它们通常用于形成页面的视觉结构，因此是提取你正在寻找的数据的好工具。\n在 Elements (元素) 视图中，你还可以右键单击一个元素并选择 Copy as Selector (复制为选择器)，以生成一个将唯一标识感兴趣元素的选择器。\n如果 SelectorGadget 或 Chrome DevTools 生成了一个你看不懂的 CSS 选择器，可以试试 Selectors Explained，它将 CSS 选择器翻译成通俗易懂的英语。如果你发现自己经常这样做，你可能想更多地了解 CSS 选择器。我们推荐从有趣的 CSS dinner 教程开始，然后参考 MDN web docs。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#整合所有内容",
    "href": "webscraping.html#整合所有内容",
    "title": "24  网络抓取",
    "section": "\n24.6 整合所有内容",
    "text": "24.6 整合所有内容\n让我们把所有这些整合起来，抓取一些网站。当你运行这些例子时，它们可能不再有效——这是网络抓取的根本挑战；如果网站的结构改变了，你就必须改变你的抓取代码。\n\n24.6.1 星球大战\nrvest 在 vignette(\"starwars\") 中包含了一个非常简单的例子。这是一个简单的页面，HTML 最少，所以是一个很好的起点。我鼓励你现在就导航到那个页面，并使用“检查元素”来检查一个作为星球大战电影标题的标题。使用键盘或鼠标来探索 HTML 的层次结构，看看你是否能感觉到每部电影使用的共享结构。\n你应该能看到每部电影都有一个共享的结构，看起来像这样：\n&lt;section&gt;\n  &lt;h2 data-id=\"1\"&gt;The Phantom Menace&lt;/h2&gt;\n  &lt;p&gt;Released: 1999-05-19&lt;/p&gt;\n  &lt;p&gt;Director: &lt;span class=\"director\"&gt;George Lucas&lt;/span&gt;&lt;/p&gt;\n  \n  &lt;div class=\"crawl\"&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n  &lt;/div&gt;\n&lt;/section&gt;\n我们的目标是将这些数据转换成一个 7 行的数据框，包含 title、year、director 和 intro 变量。我们将从读取 HTML 并提取所有 &lt;section&gt; 元素开始：\n\nurl &lt;- \"https://rvest.tidyverse.org/articles/starwars.html\"\nhtml &lt;- read_html(url)\n\nsection &lt;- html |&gt; html_elements(\"section\")\nsection\n#&gt; {xml_nodeset (7)}\n#&gt; [1] &lt;section&gt;&lt;h2 data-id=\"1\"&gt;\\nThe Phantom Menace\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [2] &lt;section&gt;&lt;h2 data-id=\"2\"&gt;\\nAttack of the Clones\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: ...\n#&gt; [3] &lt;section&gt;&lt;h2 data-id=\"3\"&gt;\\nRevenge of the Sith\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased:  ...\n#&gt; [4] &lt;section&gt;&lt;h2 data-id=\"4\"&gt;\\nA New Hope\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1977-05-2 ...\n#&gt; [5] &lt;section&gt;&lt;h2 data-id=\"5\"&gt;\\nThe Empire Strikes Back\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleas ...\n#&gt; [6] &lt;section&gt;&lt;h2 data-id=\"6\"&gt;\\nReturn of the Jedi\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [7] &lt;section&gt;&lt;h2 data-id=\"7\"&gt;\\nThe Force Awakens\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 20 ...\n\n这检索到了七个元素，与该页面上找到的七部电影相匹配，这表明使用 section 作为选择器是好的。提取单个元素很简单，因为数据总是可以在文本中找到。只需要找到正确的选择器：\n\nsection |&gt; html_element(\"h2\") |&gt; html_text2()\n#&gt; [1] \"The Phantom Menace\"      \"Attack of the Clones\"   \n#&gt; [3] \"Revenge of the Sith\"     \"A New Hope\"             \n#&gt; [5] \"The Empire Strikes Back\" \"Return of the Jedi\"     \n#&gt; [7] \"The Force Awakens\"\n\nsection |&gt; html_element(\".director\") |&gt; html_text2()\n#&gt; [1] \"George Lucas\"     \"George Lucas\"     \"George Lucas\"    \n#&gt; [4] \"George Lucas\"     \"Irvin Kershner\"   \"Richard Marquand\"\n#&gt; [7] \"J. J. Abrams\"\n\n一旦我们为每个组件都这样做了，我们就可以将所有结果包装成一个 tibble：\n\ntibble(\n  title = section |&gt; \n    html_element(\"h2\") |&gt; \n    html_text2(),\n  released = section |&gt; \n    html_element(\"p\") |&gt; \n    html_text2() |&gt; \n    str_remove(\"Released: \") |&gt; \n    parse_date(),\n  director = section |&gt; \n    html_element(\".director\") |&gt; \n    html_text2(),\n  intro = section |&gt; \n    html_element(\".crawl\") |&gt; \n    html_text2()\n)\n#&gt; # A tibble: 7 × 4\n#&gt;   title                   released   director         intro                  \n#&gt;   &lt;chr&gt;                   &lt;date&gt;     &lt;chr&gt;            &lt;chr&gt;                  \n#&gt; 1 The Phantom Menace      1999-05-19 George Lucas     \"Turmoil has engulfed …\n#&gt; 2 Attack of the Clones    2002-05-16 George Lucas     \"There is unrest in th…\n#&gt; 3 Revenge of the Sith     2005-05-19 George Lucas     \"War! The Republic is …\n#&gt; 4 A New Hope              1977-05-25 George Lucas     \"It is a period of civ…\n#&gt; 5 The Empire Strikes Back 1980-05-17 Irvin Kershner   \"It is a dark time for…\n#&gt; 6 Return of the Jedi      1983-05-25 Richard Marquand \"Luke Skywalker has re…\n#&gt; # ℹ 1 more row\n\n我们对 released 做了一点额外的处理，以得到一个在我们后续分析中易于使用的变量。\n\n24.6.2 IMDB 热门电影\n对于我们的下一个任务，我们将处理一个稍微棘手一点的问题，从互联网电影数据库 (IMDb) 中提取前 250 部电影。在我们写这一章的时候，页面看起来像 Figure 24.1。\n\n\n\n\n\n\n\nFigure 24.1: 2022-12-05 拍摄的 IMDb 热门电影网页截图。\n\n\n\n\n这个数据有清晰的表格结构，所以值得从 html_table() 开始：\n\nurl &lt;- \"https://web.archive.org/web/20220201012049/https://www.imdb.com/chart/top/\"\nhtml &lt;- read_html(url)\n\ntable &lt;- html |&gt; \n  html_element(\"table\") |&gt; \n  html_table()\ntable\n#&gt; # A tibble: 250 × 5\n#&gt;   ``    `Rank & Title`                    `IMDb Rating` `Your Rating`   ``   \n#&gt;   &lt;lgl&gt; &lt;chr&gt;                                     &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt;\n#&gt; 1 NA    \"1.\\n      The Shawshank Redempt…           9.2 \"12345678910\\n… NA   \n#&gt; 2 NA    \"2.\\n      The Godfather\\n      …           9.1 \"12345678910\\n… NA   \n#&gt; 3 NA    \"3.\\n      The Godfather: Part I…           9   \"12345678910\\n… NA   \n#&gt; 4 NA    \"4.\\n      The Dark Knight\\n    …           9   \"12345678910\\n… NA   \n#&gt; 5 NA    \"5.\\n      12 Angry Men\\n       …           8.9 \"12345678910\\n… NA   \n#&gt; 6 NA    \"6.\\n      Schindler's List\\n   …           8.9 \"12345678910\\n… NA   \n#&gt; # ℹ 244 more rows\n\n这包含了一些空列，但总的来说，它很好地捕捉了表格中的信息。然而，我们需要做一些更多的处理，使其更易于使用。首先，我们将重命名列，使其更易于使用，并删除排名和标题中多余的空格。我们将使用 select()（而不是 rename()）一步完成重命名和选择这两列。然后我们将删除换行符和多余的空格，然后应用 separate_wider_regex()（来自 Section 15.3.4）将标题、年份和排名提取到它们自己的变量中。\n\nratings &lt;- table |&gt;\n  select(\n    rank_title_year = `Rank & Title`,\n    rating = `IMDb Rating`\n  ) |&gt; \n  mutate(\n    rank_title_year = str_replace_all(rank_title_year, \"\\n +\", \" \")\n  ) |&gt; \n  separate_wider_regex(\n    rank_title_year,\n    patterns = c(\n      rank = \"\\\\d+\", \"\\\\. \",\n      title = \".+\", \" +\\\\(\",\n      year = \"\\\\d+\", \"\\\\)\"\n    )\n  )\nratings\n#&gt; # A tibble: 250 × 4\n#&gt;   rank  title                    year  rating\n#&gt;   &lt;chr&gt; &lt;chr&gt;                    &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 1     The Shawshank Redemption 1994     9.2\n#&gt; 2 2     The Godfather            1972     9.1\n#&gt; 3 3     The Godfather: Part II   1974     9  \n#&gt; 4 4     The Dark Knight          2008     9  \n#&gt; 5 5     12 Angry Men             1957     8.9\n#&gt; 6 6     Schindler's List         1993     8.9\n#&gt; # ℹ 244 more rows\n\n即使在这种大部分数据来自表格单元格的情况下，查看原始 HTML 仍然是值得的。如果你这样做，你会发现我们可以通过使用其中一个属性来添加一些额外的数据。这是值得花点时间探索页面源代码的原因之一；你可能会找到额外的数据，或者找到一个稍微容易一些的解析路径。\n\nhtml |&gt; \n  html_elements(\"td strong\") |&gt; \n  head() |&gt; \n  html_attr(\"title\")\n#&gt; [1] \"9.2 based on 2,536,415 user ratings\"\n#&gt; [2] \"9.1 based on 1,745,675 user ratings\"\n#&gt; [3] \"9.0 based on 1,211,032 user ratings\"\n#&gt; [4] \"9.0 based on 2,486,931 user ratings\"\n#&gt; [5] \"8.9 based on 749,563 user ratings\"  \n#&gt; [6] \"8.9 based on 1,295,705 user ratings\"\n\n我们可以将此与表格数据结合起来，并再次应用 separate_wider_regex() 来提取我们关心的数据：\n\nratings |&gt;\n  mutate(\n    rating_n = html |&gt; html_elements(\"td strong\") |&gt; html_attr(\"title\")\n  ) |&gt; \n  separate_wider_regex(\n    rating_n,\n    patterns = c(\n      \"[0-9.]+ based on \",\n      number = \"[0-9,]+\",\n      \" user ratings\"\n    )\n  ) |&gt; \n  mutate(\n    number = parse_number(number)\n  )\n#&gt; # A tibble: 250 × 5\n#&gt;   rank  title                    year  rating  number\n#&gt;   &lt;chr&gt; &lt;chr&gt;                    &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 1     The Shawshank Redemption 1994     9.2 2536415\n#&gt; 2 2     The Godfather            1972     9.1 1745675\n#&gt; 3 3     The Godfather: Part II   1974     9   1211032\n#&gt; 4 4     The Dark Knight          2008     9   2486931\n#&gt; 5 5     12 Angry Men             1957     8.9  749563\n#&gt; 6 6     Schindler's List         1993     8.9 1295705\n#&gt; # ℹ 244 more rows",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#动态网站",
    "href": "webscraping.html#动态网站",
    "title": "24  网络抓取",
    "section": "\n24.7 动态网站",
    "text": "24.7 动态网站\n到目前为止，我们专注于那些 html_elements() 返回你在浏览器中看到的内容的网站，并讨论了如何解析其返回的内容以及如何将这些信息组织成整洁的数据框。然而，有时你会遇到一个网站，其中 html_elements() 和相关函数返回的内容与你在浏览器中看到的完全不同。在许多情况下，这是因为你试图抓取一个用 javascript 动态生成页面内容的网站。这目前不适用于 rvest，因为 rvest 下载的是原始 HTML，不运行任何 javascript。\n抓取这类网站仍然是可能的，但 rvest 需要使用一个更昂贵的过程：完全模拟网络浏览器，包括运行所有 javascript。在撰写本文时，此功能尚不可用，但这是我们正在积极开发的内容，可能在你阅读本文时已经可用。它使用了 chromote 包，该包实际上在后台运行 Chrome 浏览器，并为你提供了与网站交互的额外工具，就像人类输入文本和点击按钮一样。查看 rvest 网站了解更多详情。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#总结",
    "href": "webscraping.html#总结",
    "title": "24  网络抓取",
    "section": "\n24.8 总结",
    "text": "24.8 总结\n在本章中，你学习了为什么、为什么不以及如何从网页上抓取数据。首先，你学习了 HTML 的基础知识和使用 CSS 选择器来引用特定元素，然后你学习了使用 rvest 包将数据从 HTML 中提取到 R。接着，我们通过两个案例研究演示了网络抓取：一个是在 rvest 包网站上抓取星球大战电影数据的简单场景，另一个是从 IMDB 抓取前 250 部电影的更复杂场景。\n从网络上抓取数据的技术细节可能很复杂，尤其是在处理网站时，然而法律和伦理方面的考虑可能更为复杂。在你开始抓取数据之前，了解这两方面的情况对你来说很重要。\n这就结束了本书的导入部分，你已经学习了将数据从它所在的地方（电子表格、数据库、JSON 文件和网站）导入到 R 中的整洁形式的技术。现在是时候将我们的目光转向一个新的主题：充分利用 R 作为一种编程语言。",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "webscraping.html#footnotes",
    "href": "webscraping.html#footnotes",
    "title": "24  网络抓取",
    "section": "",
    "text": "许多流行的 API 已经有对应的 CRAN 包，所以可以先做一些研究！↩︎\n显然我们不是律师，这也不是法律建议。但这是我们在阅读了大量关于这个主题的资料后能给出的最好总结。↩︎\n《连线》杂志发表了一篇关于 OkCupid 研究的文章，https://www.wired.com/2016/05/okcupid-study-reveals-perils-big-data-science。↩︎\n许多标签（包括 &lt;p&gt; 和 &lt;li&gt;）不需要结束标签，但我们认为最好还是加上，因为这能让 HTML 的结构看得更清楚一些。↩︎\n这个类来自 xml2 包。xml2 是一个底层包，rvest 在其之上构建。↩︎\nrvest 也提供了 html_text()，但你几乎总是应该使用 html_text2()，因为它在将嵌套的 HTML 转换为文本方面做得更好。↩︎",
    "crumbs": [
      "导入",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>网络抓取</span>"
    ]
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "编程",
    "section": "",
    "text": "在本书的这一部分，你将提升自己的编程技能。编程是所有数据科学工作都需要的一项贯穿性技能：你必须使用计算机来做数据科学；你无法在脑海中，或者用纸和笔来完成。\n\n\n\n\n\n\n\nFigure 1: 编程就像是水，所有其他组件都在其中遨游。\n\n\n\n\n编程会产出代码，而代码是一种沟通工具。显然，代码会告诉计算机你希望它做什么。但它也向其他人类传达意义。将代码视为一种沟通媒介非常重要，因为你所做的每一个项目本质上都是协作性的。即使你没有和别人一起工作，你也肯定会和未来的自己合作！编写清晰的代码非常重要，这样其他人（比如未来的你）才能理解你为什么用那样的方式来处理一项分析。这意味着，提升编程能力也包括提升沟通能力。随着时间的推移，你希望你的代码不仅更容易编写，而且更容易被他人阅读。\n在接下来的三章中，你将学习提升编程技能的技巧：\n\n复制粘贴是一个强大的工具，但你应该避免重复使用它超过两次。在代码中重复自己是危险的，因为它很容易导致错误和不一致。因此，在 25  函数 中，你将学习如何编写函数 (functions)，这能让你将重复的 tidyverse 代码提取出来，以便轻松复用。\n函数能提取出重复的代码，但你经常需要对不同的输入重复相同的操作。你需要迭代 (iteration) 的工具，让你能一遍又一遍地做类似的事情。这些工具包括 for 循环和函数式编程，你将在 26  迭代 中学习它们。\n当你阅读更多他人编写的代码时，你会看到更多不使用 tidyverse 的代码。在 27  Base R 实战指南 中，你将学习一些你在实践中会遇到的最重要的基础 R 函数。\n\n这些章节的目标是教会你数据科学所需的最低限度的编程知识。一旦你掌握了这里的内容，我们强烈建议你继续投入时间提升你的编程技能。我们写了两本书，你可能会觉得有帮助。《Hands on Programming with R》，由 Garrett Grolemund 撰写，是 R 作为一门编程语言的入门介绍，如果 R 是你的第一门编程语言，这本书是一个很好的起点。《Advanced R》由 Hadley Wickham 撰写，深入探讨了 R 编程语言的细节；如果你有现成的编程经验，这本书是一个很好的起点，一旦你内化了这些章节中的思想，它也是一个很好的进阶选择。",
    "crumbs": [
      "编程"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "25  函数",
    "section": "",
    "text": "25.1 引言\n提升你作为数据科学家影响力的最佳途径之一就是编写函数。函数能让你以比复制粘贴更强大、更通用的方式自动化处理常见任务。与复制粘贴相比，编写函数有四大优势：\n一个很好的经验法则是，当你复制粘贴一个代码块超过两次（即你现在有了同一代码的三个副本）时，就应该考虑编写一个函数。在本章中，你将学习三种有用的函数类型：\n每个部分都包含许多示例，以帮助你归纳所见的模式。没有 Twitter 上朋友们的帮助，这些示例是不可能完成的，我们鼓励你点击注释中的链接查看原始灵感。你可能还想阅读关于通用函数和绘图函数的原始激励推文，以看到更多函数。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "functions.html#引言",
    "href": "functions.html#引言",
    "title": "25  函数",
    "section": "",
    "text": "你可以给函数起一个富有表现力的名字，让你的代码更易于理解。\n当需求变化时，你只需要在一个地方更新代码，而不是多处。\n你消除了在复制粘贴时可能出现的偶然错误（例如，在一个地方更新了变量名，但在另一个地方却没有）。\n它让你更容易在不同项目间重用代码，从而随着时间的推移提高你的生产力。\n\n\n\n\n向量函数：接收一个或多个向量作为输入，并返回一个向量作为输出。\n\n数据框函数：接收一个数据框作为输入，并返回一个数据框作为输出。\n\n绘图函数：接收一个数据框作为输入，并返回一个绘图作为输出。\n\n\n\n25.1.1 前提条件\n我们将封装来自 tidyverse 各处的多种函数。我们还将使用 nycflights13 作为熟悉的数据源来应用我们的函数。\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "functions.html#向量函数",
    "href": "functions.html#向量函数",
    "title": "25  函数",
    "section": "\n25.2 向量函数",
    "text": "25.2 向量函数\n我们从向量函数开始：这类函数接收一个或多个向量并返回一个向量结果。例如，看看这段代码。它做了什么？\n\ndf &lt;- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |&gt; mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(a, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(b, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a       b     c     d\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339  0.387  0.291 0    \n#&gt; 2 0.880 -0.613  0.611 0.557\n#&gt; 3 0     -0.0833 1     0.752\n#&gt; 4 0.795 -0.0822 0     1    \n#&gt; 5 1     -0.0952 0.580 0.394\n\n你或许能琢磨出来，这是将每一列重新缩放到 0 到 1 的范围内。但你发现那个错误了吗？Hadley 在写这段代码时，复制粘贴时犯了个错误，忘记了把一个 a 改成 b。防止这类错误的发生是学习如何编写函数的一个很好的理由。\n\n25.2.1 编写一个函数\n要编写一个函数，你首先需要分析你重复的代码，找出哪些部分是固定不变的，哪些部分是变化的。如果我们把上面的代码从 mutate() 中拿出来，模式会看得更清楚一些，因为现在每次重复都只有一行：\n\n(a - min(a, na.rm = TRUE)) / (max(a, na.rm = TRUE) - min(a, na.rm = TRUE))\n(b - min(b, na.rm = TRUE)) / (max(b, na.rm = TRUE) - min(b, na.rm = TRUE))\n(c - min(c, na.rm = TRUE)) / (max(c, na.rm = TRUE) - min(c, na.rm = TRUE))\n(d - min(d, na.rm = TRUE)) / (max(d, na.rm = TRUE) - min(d, na.rm = TRUE))  \n\n为了让这更清晰，我们可以用 █ 替换变化的部分：\n\n(█ - min(█, na.rm = TRUE)) / (max(█, na.rm = TRUE) - min(█, na.rm = TRUE))\n\n要把它变成一个函数，你需要三样东西：\n\n一个名字。这里我们用 rescale01，因为这个函数将一个向量重新缩放到 0 和 1 之间。\n参数 (arguments)。参数是在不同调用中变化的东西，我们上面的分析告诉我们只有一个。我们称它为 x，因为这是数值向量的常规名称。\n函数体 (body)。函数体是在所有调用中重复的代码。\n\n然后你按照这个模板创建一个函数：\n\nname &lt;- function(arguments) {\n  body\n}\n\n对于这个例子，就得到了：\n\nrescale01 &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\n此时，你可能会用一些简单的输入来测试，以确保你正确地捕捉了逻辑：\n\nrescale01(c(-10, 0, 10))\n#&gt; [1] 0.0 0.5 1.0\nrescale01(c(1, 2, 3, NA, 5))\n#&gt; [1] 0.00 0.25 0.50   NA 1.00\n\n然后你可以将对 mutate() 的调用重写为：\n\ndf |&gt; mutate(\n  a = rescale01(a),\n  b = rescale01(b),\n  c = rescale01(c),\n  d = rescale01(d),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339 1     0.291 0    \n#&gt; 2 0.880 0     0.611 0.557\n#&gt; 3 0     0.530 1     0.752\n#&gt; 4 0.795 0.531 0     1    \n#&gt; 5 1     0.518 0.580 0.394\n\n（在 Chapter 26 中，你将学习如何使用 across() 来进一步减少重复，这样你只需要 df |&gt; mutate(across(a:d, rescale01))）。\n\n25.2.2 改进我们的函数\n你可能会注意到 rescale01() 函数做了一些不必要的工作 — 与其计算两次 min() 和一次 max()，我们不如用 range() 一步计算出最小值和最大值：\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\n或者你可以用一个包含无穷大值的向量来试试这个函数：\n\nx &lt;- c(1:10, Inf)\nrescale01(x)\n#&gt;  [1]   0   0   0   0   0   0   0   0   0   0 NaN\n\n这个结果不是特别有用，所以我们可以让 range() 忽略无穷大值：\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE, finite = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nrescale01(x)\n#&gt;  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n#&gt;  [8] 0.7777778 0.8888889 1.0000000       Inf\n\n这些改动展示了函数的一个重要好处：因为我们把重复的代码移到了一个函数里，我们只需要在一个地方做改动。\n\n25.2.3 变换函数\n现在你已经掌握了函数的基本概念，让我们来看一大堆例子。我们将从“变换 (mutate)”函数开始，即那些在 mutate() 和 filter() 内部工作得很好的函数，因为它们返回的输出与输入长度相同。\n让我们从 rescale01() 的一个简单变体开始。也许你想要计算 Z 分数 (Z-score)，将一个向量重新缩放，使其均值为零，标准差为一：\n\nz_score &lt;- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\n或者，你可能想封装一个简单的 case_when() 并给它一个有用的名字。例如，这个 clamp() 函数确保一个向量的所有值都介于一个最小值和一个最大值之间：\n\nclamp &lt;- function(x, min, max) {\n  case_when(\n    x &lt; min ~ min,\n    x &gt; max ~ max,\n    .default = x\n  )\n}\n\nclamp(1:10, min = 3, max = 7)\n#&gt;  [1] 3 3 3 4 5 6 7 7 7 7\n\n当然，函数不只适用于数值变量。你可能想做一些重复的字符串操作。也许你需要将第一个字符大写：\n\nfirst_upper &lt;- function(x) {\n  str_sub(x, 1, 1) &lt;- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nfirst_upper(\"hello\")\n#&gt; [1] \"Hello\"\n\n或者，你可能想在将字符串转换为数字之前，从中剥离百分号、逗号和美元符号：\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nclean_number &lt;- function(x) {\n  is_pct &lt;- str_detect(x, \"%\")\n  num &lt;- x |&gt; \n    str_remove_all(\"%\") |&gt; \n    str_remove_all(\",\") |&gt; \n    str_remove_all(fixed(\"$\")) |&gt; \n    as.numeric()\n  if_else(is_pct, num / 100, num)\n}\n\nclean_number(\"$12,300\")\n#&gt; [1] 12300\nclean_number(\"45%\")\n#&gt; [1] 0.45\n\n有时候你的函数会高度专用于某个数据分析步骤。例如，如果你有一堆变量将缺失值记录为 997、998 或 999，你可能想写一个函数来将它们替换为 NA：\n\nfix_na &lt;- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\n我们专注于接收单个向量的例子，因为我们认为它们是最常见的。但是，你的函数没有理由不能接收多个向量输入。\n\n25.2.4 摘要函数\n另一个重要的向量函数家族是摘要函数 (summary functions)，即在 summarize() 中使用并返回单个值的函数。有时，这可能只是设置一个或两个默认参数的问题：\n\ncommas &lt;- function(x) {\n  str_flatten(x, collapse = \", \", last = \" and \")\n}\n\ncommas(c(\"cat\", \"dog\", \"pigeon\"))\n#&gt; [1] \"cat, dog and pigeon\"\n\n或者你可能想封装一个简单的计算，比如变异系数 (coefficient of variation)，它用标准差除以均值：\n\ncv &lt;- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n#&gt; [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n#&gt; [1] 0.5652554\n\n或者你只是想通过给一个常见的模式起一个好记的名字来让它更容易记住：\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nn_missing &lt;- function(x) {\n  sum(is.na(x))\n} \n\n你也可以编写具有多个向量输入的函数。例如，也许你想计算平均绝对百分比误差 (mean absolute percentage error)，以帮助你比较模型预测值与实际值：\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nmape &lt;- function(actual, predicted) {\n  sum(abs((actual - predicted) / actual)) / length(actual)\n}\n\n\n\n\n\n\n\nRStudio\n\n\n\n一旦你开始编写函数，有两个 RStudio 快捷键非常有用：\n\n要查找你编写的函数的定义，将光标放在函数名上，然后按 F2。\n要快速跳转到一个函数，按 Ctrl + . 打开模糊文件和函数查找器，然后输入你函数名的前几个字母。你也可以用它来导航到文件、Quarto 章节等，使其成为一个非常方便的导航工具。\n\n\n\n\n25.2.5 练习\n\n\n练习将以下代码片段转换成函数。思考每个函数的作用是什么？你会怎么称呼它？它需要多少个参数？\n\nmean(is.na(x))\nmean(is.na(y))\nmean(is.na(z))\n\nx / sum(x, na.rm = TRUE)\ny / sum(y, na.rm = TRUE)\nz / sum(z, na.rm = TRUE)\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n\n在 rescale01() 的第二个变体中，无穷大值保持不变。你能否重写 rescale01()，使得 -Inf 映射到 0，而 Inf 映射到 1？\n给定一个出生日期向量，编写一个函数来计算以年为单位的年龄。\n编写你自己的函数来计算一个数值向量的方差和偏度。你可以在维基百科或其他地方查找定义。\n编写 both_na()，一个摘要函数，它接收两个相同长度的向量，并返回两个向量中在相同位置上都为 NA 的数量。\n\n阅读文档，弄清楚以下函数的作用。为什么它们虽然很短，但仍然很有用？\n\nis_directory &lt;- function(x) {\n  file.info(x)$isdir\n}\nis_readable &lt;- function(x) {\n  file.access(x, 4) == 0\n}",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "functions.html#数据框函数",
    "href": "functions.html#数据框函数",
    "title": "25  函数",
    "section": "\n25.3 数据框函数",
    "text": "25.3 数据框函数\n向量函数对于提取在 dplyr 动词内部重复的代码很有用。但你通常也会重复动词本身，尤其是在一个大型的管道中。当你注意到自己多次复制粘贴多个动词时，你可能会考虑编写一个数据框函数。数据框函数的工作方式类似于 dplyr 动词：它们接收一个数据框作为第一个参数，一些额外的参数来说明如何处理它，并返回一个数据框或一个向量。\n为了让你能够编写使用 dplyr 动词的函数，我们将首先向你介绍间接性 (indirection) 的挑战，以及如何通过拥抱 (embracing)，即 {{ }} 来克服它。掌握了这一理论之后，我们将向你展示一系列例子，来说明你可以用它做什么。\n\n25.3.1 间接性与整洁求值\n当你开始编写使用 dplyr 动词的函数时，你很快就会遇到间接性问题。让我们用一个非常简单的函数 grouped_mean() 来说明这个问题。这个函数的目的是计算按 group_var 分组后 mean_var 的均值：\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by(group_var) |&gt; \n    summarize(mean(mean_var))\n}\n\n如果我们尝试使用它，会得到一个错误：\n\ndiamonds |&gt; grouped_mean(cut, carat)\n#&gt; Error in `group_by()`:\n#&gt; ! Must group by variables found in `.data`.\n#&gt; ✖ Column `group_var` is not found.\n\n为了让问题更清晰，我们可以使用一个虚构的数据框：\n\ndf &lt;- tibble(\n  mean_var = 1,\n  group_var = \"g\",\n  group = 1,\n  x = 10,\n  y = 100\n)\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\ndf |&gt; grouped_mean(group, y)\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\n\n无论我们如何调用 grouped_mean()，它总是执行 df |&gt; group_by(group_var) |&gt; summarize(mean(mean_var))，而不是 df |&gt; group_by(group) |&gt; summarize(mean(x)) 或 df |&gt; group_by(group) |&gt; summarize(mean(y))。这是一个间接性问题，它的出现是因为 dplyr 使用整洁求值 (tidy evaluation) 来允许你引用数据框内的变量名而无需任何特殊处理。\n整洁求值在 95% 的情况下都很棒，因为它使你的数据分析非常简洁，你永远不必说一个变量来自哪个数据框；从上下文中可以很明显地看出来。整洁求值的缺点在于，当我们想把重复的 tidyverse 代码封装成函数时。在这里，我们需要一种方法告诉 group_by() 和 summarize() 不要把 group_var 和 mean_var 当作变量的字面名称，而是查看它们内部，找到我们实际想用的变量。\n整洁求值为这个问题提供了一个解决方案，叫做拥抱 (embracing) 🤗。拥抱一个变量意味着用大括号把它包起来，例如 var 变成 {{ var }}。拥抱一个变量会告诉 dplyr 使用存储在参数内的值，而不是把参数本身当作字面上的变量名。记住正在发生什么的一个方法是把 {{ }} 想象成在看一条隧道 — {{ var }} 会让 dplyr 函数查看 var 的内部，而不是寻找一个名为 var 的变量。\n所以，要让 grouped_mean() 工作，我们需要用 {{ }} 把 group_var 和 mean_var 包围起来：\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by({{ group_var }}) |&gt; \n    summarize(mean({{ mean_var }}))\n}\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   group `mean(x)`\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1        10\n\n成功了！\n\n25.3.2 何时拥抱？\n所以，编写数据框函数的关键挑战是弄清楚哪些参数需要被拥抱。幸运的是，这很容易，因为你可以从文档中查到 😄。在文档中有两个术语需要注意，它们对应于整洁求值最常见的两种子类型：\n\n数据掩码 (Data-masking)：用于像 arrange()、filter() 和 summarize() 这样用变量进行计算的函数中。\n整洁选择 (Tidy-selection)：用于像 select()、relocate() 和 rename() 这样选择变量的函数中。\n\n对于许多常用函数，你关于哪些参数使用整洁求值的直觉应该是准确的 — 只需思考你是否可以进行计算（例如，x + 1）或选择（例如，a:x）。\n在接下来的部分中，我们将探讨一旦你理解了拥抱，你可能会编写的各种方便函数。\n\n25.3.3 常见用例\n如果你在进行初步数据探索时经常执行同一组摘要计算，你可能会考虑将它们封装在一个辅助函数中：\n\nsummary6 &lt;- function(data, var) {\n  data |&gt; summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    mean = mean({{ var }}, na.rm = TRUE),\n    median = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_miss = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamonds |&gt; summary6(carat)\n#&gt; # A tibble: 1 × 6\n#&gt;     min  mean median   max     n n_miss\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1   0.2 0.798    0.7  5.01 53940      0\n\n(每当你将 summarize() 封装在一个辅助函数中时，我们认为设置 .groups = \"drop\" 是一个好习惯，这样既可以避免消息提示，又能使数据处于未分组状态。)\n这个函数的好处在于，因为它封装了 summarize()，你可以在分组数据上使用它：\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(carat)\n#&gt; # A tibble: 5 × 7\n#&gt;   cut         min  mean median   max     n n_miss\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair       0.22 1.05    1     5.01  1610      0\n#&gt; 2 Good       0.23 0.849   0.82  3.01  4906      0\n#&gt; 3 Very Good  0.2  0.806   0.71  4    12082      0\n#&gt; 4 Premium    0.2  0.892   0.86  4.01 13791      0\n#&gt; 5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\n此外，由于 summarize 的参数是数据掩码的，所以 summary6() 的 var 参数也是。这意味着你也可以对计算出的变量进行摘要：\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(log10(carat))\n#&gt; # A tibble: 5 × 7\n#&gt;   cut          min    mean  median   max     n n_miss\n#&gt;   &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair      -0.658 -0.0273  0      0.700  1610      0\n#&gt; 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n#&gt; 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n#&gt; 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n#&gt; 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\n要对多个变量进行摘要，你需要等到 Section 26.2，在那里你将学习如何使用 across()。\n另一个流行的 summarize() 辅助函数是 count() 的一个版本，它也计算比例：\n\n# https://twitter.com/Diabb6/status/1571635146658402309\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}\n\ndiamonds |&gt; count_prop(clarity)\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity     n   prop\n#&gt;   &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 I1        741 0.0137\n#&gt; 2 SI2      9194 0.170 \n#&gt; 3 SI1     13065 0.242 \n#&gt; 4 VS2     12258 0.227 \n#&gt; 5 VS1      8171 0.151 \n#&gt; 6 VVS2     5066 0.0939\n#&gt; # ℹ 2 more rows\n\n这个函数有三个参数：df、var 和 sort，只有 var 需要被拥抱，因为它被传递给 count()，而 count() 对所有变量都使用数据掩码。注意，我们为 sort 使用了默认值，这样如果用户不提供自己的值，它将默认为 FALSE。\n或者，你可能想为数据的子集找到一个变量的已排序的唯一值。与其提供一个变量和一个值来进行筛选，我们将允许用户提供一个条件：\n\nunique_where &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    distinct({{ var }}) |&gt; \n    arrange({{ var }})\n}\n\n# 查找十二月的所有目的地\nflights |&gt; unique_where(month == 12, dest)\n#&gt; # A tibble: 96 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 ABQ  \n#&gt; 2 ALB  \n#&gt; 3 ATL  \n#&gt; 4 AUS  \n#&gt; 5 AVL  \n#&gt; 6 BDL  \n#&gt; # ℹ 90 more rows\n\n这里我们拥抱 condition 是因为它被传递给 filter()，拥抱 var 是因为它被传递给 distinct() 和 arrange()。\n我们把所有这些例子都设置为接收一个数据框作为第一个参数，但如果你反复处理相同的数据，将其硬编码可能是有意义的。例如，下面的函数总是处理 flights 数据集，并且总是选择 time_hour、carrier 和 flight，因为它们构成了可以识别一行的复合主键。\n\nsubset_flights &lt;- function(rows, cols) {\n  flights |&gt; \n    filter({{ rows }}) |&gt; \n    select(time_hour, carrier, flight, {{ cols }})\n}\n\n\n25.3.4 数据掩码 vs. 整洁选择\n有时你想在一个使用数据掩码的函数内部选择变量。例如，假设你想写一个 count_missing() 来计算行中缺失观测值的数量。你可能会尝试写成这样：\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by({{ group_vars }}) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; Error in `group_by()`:\n#&gt; ℹ In argument: `c(year, month, day)`.\n#&gt; Caused by error:\n#&gt; ! `c(year, month, day)` must be size 336776 or 1, not 1010328.\n\n这不起作用，因为 group_by() 使用数据掩码，而不是整洁选择。我们可以通过使用方便的 pick() 函数来解决这个问题，它允许你在数据掩码函数内部使用整洁选择：\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; # A tibble: 365 × 4\n#&gt;    year month   day n_miss\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1  2013     1     1      4\n#&gt; 2  2013     1     2      8\n#&gt; 3  2013     1     3     10\n#&gt; 4  2013     1     4      6\n#&gt; 5  2013     1     5      3\n#&gt; 6  2013     1     6      1\n#&gt; # ℹ 359 more rows\n\npick() 的另一个方便用法是制作一个二维的计数表。这里我们使用 rows 和 columns 中的所有变量进行计数，然后使用 pivot_wider() 将计数重新排列成一个网格：\n\n# https://twitter.com/pollicipes/status/1571606508944719876\ncount_wide &lt;- function(data, rows, cols) {\n  data |&gt; \n    count(pick(c({{ rows }}, {{ cols }}))) |&gt; \n    pivot_wider(\n      names_from = {{ cols }}, \n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamonds |&gt; count_wide(c(clarity, color), cut)\n#&gt; # A tibble: 56 × 7\n#&gt;   clarity color  Fair  Good `Very Good` Premium Ideal\n#&gt;   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 I1      D         4     8           5      12    13\n#&gt; 2 I1      E         9    23          22      30    18\n#&gt; 3 I1      F        35    19          13      34    42\n#&gt; 4 I1      G        53    19          16      46    16\n#&gt; 5 I1      H        52    14          12      46    38\n#&gt; 6 I1      I        34     9           8      24    17\n#&gt; # ℹ 50 more rows\n\n虽然我们的例子主要集中在 dplyr 上，但整洁求值也支撑着 tidyr，如果你查看 pivot_wider() 的文档，你会看到 names_from 使用了整洁选择。\n\n25.3.5 练习\n\n\n使用 nycflights13 中的数据集，编写一个函数：\n\n\n找到所有被取消（即 is.na(arr_time)）或延误超过一小时的航班。\n\nflights |&gt; filter_severe()\n\n\n\n计算被取消的航班数量和延误超过一小时的航班数量。\n\nflights |&gt; group_by(dest) |&gt; summarize_severe()\n\n\n\n找到所有被取消或延误超过用户提供的小时数的航班：\n\nflights |&gt; filter_severe(hours = 2)\n\n\n\n对天气进行摘要，计算用户提供的变量的最小值、平均值和最大值：\n\nweather |&gt; summarize_weather(temp)\n\n\n\n将用户提供的、使用时钟时间（例如 dep_time、arr_time 等）的变量转换为十进制时间（即 小时 + (分钟 / 60)）。\n\nflights |&gt; standardize_time(sched_dep_time)\n\n\n\n\n对于以下每个函数，列出所有使用整洁求值的参数，并描述它们是使用数据掩码还是整洁选择：distinct()、count()、group_by()、rename_with()、slice_min()、slice_sample()。\n\n泛化以下函数，以便你可以提供任意数量的变量进行计数。\n\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "functions.html#绘图函数",
    "href": "functions.html#绘图函数",
    "title": "25  函数",
    "section": "\n25.4 绘图函数",
    "text": "25.4 绘图函数\n你可能想要返回一个绘图，而不是一个数据框。幸运的是，你可以在 ggplot2 中使用相同的技术，因为 aes() 是一个数据掩码函数。例如，想象你正在制作很多直方图：\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.05)\n\n如果你能把这个封装成一个直方图函数，那不是很好吗？一旦你知道 aes() 是一个数据掩码函数并且你需要拥抱，这就易如反掌了：\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\n请注意，histogram() 返回一个 ggplot2 绘图对象，这意味着你仍然可以根据需要添加其他组件。只需记住从 |&gt; 切换到 +：\n\ndiamonds |&gt; \n  histogram(carat, 0.1) +\n  labs(x = \"Size (in carats)\", y = \"Number of diamonds\")\n\n\n25.4.1 更多变量\n将更多变量加入进来也很直接。例如，你可能想通过叠加一条平滑曲线和一条直线来轻松地目测一个数据集是否是线性的：\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nlinearity_check &lt;- function(df, x, y) {\n  df |&gt;\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\nstarwars |&gt; \n  filter(mass &lt; 1000) |&gt; \n  linearity_check(mass, height)\n\n\n\n\n\n\n\n或者，对于点重叠问题严重的大型数据集，你可能想要一种替代彩色散点图的方法：\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\nhex_plot &lt;- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |&gt; \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # 使边框颜色与填充色相同\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamonds |&gt; hex_plot(carat, price, depth)\n\n\n\n\n\n\n\n\n25.4.2 与其他 tidyverse 功能结合\n一些最有用的辅助函数是将少量数据操作与 ggplot2 结合起来。例如，你可能想制作一个垂直条形图，并使用 fct_infreq() 自动按频率顺序对条形进行排序。由于条形图是垂直的，我们还需要反转通常的顺序，以使最高的值在顶部：\n\nsorted_bars &lt;- function(df, var) {\n  df |&gt; \n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |&gt;\n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamonds |&gt; sorted_bars(clarity)\n\n\n\n\n\n\n\n这里我们必须使用一个新的操作符 :=（通常被称为“海象操作符”），因为我们正在根据用户提供的数据生成变量名。变量名通常放在 = 的左侧，但 R 的语法不允许在 = 的左侧有除了单个字面名称之外的任何东西。为了解决这个问题，我们使用特殊的操作符 :=，整洁求值会将其与 = 完全相同地对待。\n或者，你可能想方便地为数据的某个子集绘制条形图：\n\nconditional_bars &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamonds |&gt; conditional_bars(cut == \"Good\", clarity)\n\n\n\n\n\n\n\n你也可以发挥创意，用其他方式展示数据摘要。你可以在 https://gist.github.com/GShotwell/b19ef520b6d56f61a830fabb3454965b 找到一个很酷的应用；它使用坐标轴标签来显示最高值。随着你对 ggplot2 的了解越来越多，你函数的功能也会不断增强。\n我们以一个更复杂的例子来结束：为你创建的图表添加标签。\n\n25.4.3 标签\n还记得我们之前给你看的直方图函数吗？\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\n如果我们能用所使用的变量和组距来标记输出，那不是很好吗？为此，我们将不得不深入了解整洁求值的底层，并使用一个我们尚未提及的包中的函数：rlang。rlang 是一个低级包，几乎 tidyverse 中的所有其他包都在使用它，因为它实现了整洁求值（以及许多其他有用的工具）。\n为了解决标签问题，我们可以使用 rlang::englue()。它的工作方式类似于 str_glue()，所以任何用 { } 包裹的值都将被插入到字符串中。但它也理解 {{ }}，它会自动插入适当的变量名：\n\nhistogram &lt;- function(df, var, binwidth) {\n  label &lt;- rlang::englue(\"A histogram of {{var}} with binwidth {binwidth}\")\n  \n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = label)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\n你可以在 ggplot2 图中任何想提供字符串的地方使用同样的方法。\n\n25.4.4 练习\n通过逐步实现以下每个步骤，构建一个功能丰富的绘图函数：\n\n给定数据集以及 x 和 y 变量，绘制一个散点图。\n添加一条最佳拟合线（即没有标准误差的线性模型）。\n添加一个标题。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "functions.html#风格",
    "href": "functions.html#风格",
    "title": "25  函数",
    "section": "\n25.5 风格",
    "text": "25.5 风格\nR 不在乎你的函数或参数叫什么名字，但这些名字对人类来说却有很大的不同。理想情况下，你的函数名应该简短，但能清晰地唤起函数的功能。这很难！但清晰比简短更好，因为 RStudio 的自动补全功能使得输入长名称变得容易。\n通常，函数名应该是动词，参数应该是名词。也有一些例外：如果函数计算的是一个非常众所周知的名词（即 mean() 比 compute_mean() 好），或者访问对象的某个属性（即 coef() 比 get_coefficients() 好），那么名词也是可以的。运用你的最佳判断，如果以后想到了更好的名字，不要害怕重命名函数。\n\n# 太短\nf()\n\n# 不是动词，或不具描述性\nmy_awesome_function()\n\n# 长，但清晰\nimpute_missing()\ncollapse_years()\n\nR 也不在乎你在函数中如何使用空白，但未来的读者会在乎。请继续遵循 Chapter 4 中的规则。此外，function() 后面应始终跟着花括号 ({})，并且内容应该额外缩进两个空格。这样通过扫视左边距，可以更容易地看到代码的层次结构。\n\n# 缺少额外的两个空格\ndensity &lt;- function(color, facets, binwidth = 0.1) {\ndiamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\n# 管道缩进不正确\ndensity &lt;- function(color, facets, binwidth = 0.1) {\n  diamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\n如你所见，我们建议在 {{ }} 内部多加一些空格。这使得有不寻常的事情发生变得非常明显。\n\n25.5.1 练习\n\n\n阅读以下两个函数的源代码，弄清楚它们的作用，然后集思广益想出更好的名字。\n\nf1 &lt;- function(string, prefix) {\n  str_sub(string, 1, str_length(prefix)) == prefix\n}\n\nf3 &lt;- function(x, y) {\n  rep(y, length.out = length(x))\n}\n\n\n找一个你最近写的函数，花 5 分钟为它和它的参数想一个更好的名字。\n论证为什么 norm_r()、norm_d() 等会比 rnorm()、dnorm() 更好。再论证相反的观点。你如何能让这些名字更清晰？",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "functions.html#小结",
    "href": "functions.html#小结",
    "title": "25  函数",
    "section": "\n25.6 小结",
    "text": "25.6 小结\n在本章中，你学习了如何为三种有用的场景编写函数：创建向量、创建数据框或创建绘图。在此过程中，你看到了许多例子，希望这些例子能激发你的创造力，并为你提供一些关于函数如何帮助你的分析代码的想法。\n我们只向你展示了函数入门的最低要求，还有更多内容需要学习。以下是一些可以深入学习的地方：\n\n要了解更多关于使用整洁求值编程的知识，请参阅 programming with dplyr 和 programming with tidyr 中的有用秘籍，并在 What is data-masking and why do I need {{? 中学习更多理论知识。\n要了解更多关于减少 ggplot2 代码重复的知识，请阅读 ggplot2 书籍的 Programming with ggplot2 章节。\n有关函数风格的更多建议，请参阅 tidyverse 风格指南。\n\n在下一章中，我们将深入探讨迭代，它为你提供了进一步减少代码重复的工具。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "iteration.html",
    "href": "iteration.html",
    "title": "26  迭代",
    "section": "",
    "text": "26.1 引言\n在本章中，你将学习迭代的工具，即在不同对象上重复执行相同的操作。R 语言中的迭代通常看起来与其他编程语言大相径庭，因为很多迭代是隐式的，我们可以免费获得。例如，如果你想在 R 中将一个数值向量 x 的每个元素都乘以 2，你只需写 2 * x。在大多数其他语言中，你需要使用某种 for 循环来显式地将 x 的每个元素乘以 2。\n本书已经为你提供了一些小而强大的工具，可以对多个“事物”执行相同的操作：\n现在是时候学习一些更通用的工具了，这些工具通常被称为 函数式编程 (functional programming) 工具，因为它们是围绕着接收其他函数作为输入的函数构建的。学习函数式编程很容易变得抽象，但在本章中，我们将通过关注三个常见的任务来保持具体：修改多个列、读取多个文件和保存多个对象。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>迭代</span>"
    ]
  },
  {
    "objectID": "iteration.html#引言",
    "href": "iteration.html#引言",
    "title": "26  迭代",
    "section": "",
    "text": "facet_wrap() 和 facet_grid() 为每个子集绘制一幅图。\n\ngroup_by() 加上 summarize() 为每个子集计算汇总统计量。\n\nunnest_wider() 和 unnest_longer() 为列表列的每个元素创建新的行和列。\n\n\n\n26.1.1 先决条件\n在本章中，我们将重点关注 dplyr 和 purrr 提供的工具，它们都是 tidyverse 的核心成员。你之前已经见过 dplyr，但 purrr 是新内容。本章我们只会使用几个 purrr 函数，但随着你编程技能的提高，它是一个值得探索的优秀包。\n\nlibrary(tidyverse)",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>迭代</span>"
    ]
  },
  {
    "objectID": "iteration.html#sec-across",
    "href": "iteration.html#sec-across",
    "title": "26  迭代",
    "section": "\n26.2 修改多个列",
    "text": "26.2 修改多个列\n假设你有下面这个简单的 tibble，并且你想计算观测值的数量并计算每一列的中位数。\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\n你可以通过复制粘贴来完成：\n\ndf |&gt; summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\n这违反了我们“绝不复制粘贴超过两次”的经验法则，而且你可以想象，如果你有几十甚至上百列，这将变得非常繁琐。相反，你可以使用 across()：\n\ndf |&gt; summarize(\n  n = n(),\n  across(a:d, median),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nacross() 有三个特别重要的参数，我们将在接下来的部分中详细讨论。每次使用 across() 时，你都会用到前两个参数：第一个参数 .cols 指定了你想要迭代的列，第二个参数 .fns 指定了如何处理每一列。当你需要对输出列的名称进行额外控制时，可以使用 .names 参数，这在使用 across() 配合 mutate() 时尤其重要。我们还将讨论两个重要的变体，if_any() 和 if_all()，它们与 filter() 一起工作。\n\n26.2.1 使用 .cols 选择列\nacross() 的第一个参数 .cols 用于选择要转换的列。这与 select() 使用相同的规范，详见 Section 3.3.2，因此你可以使用像 starts_with() 和 ends_with() 这样的函数来根据列名选择列。\n还有两种对 across() 特别有用的选择技术：everything() 和 where()。everything() 很直接：它选择所有（非分组）列：\n\ndf &lt;- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median))\n#&gt; # A tibble: 2 × 5\n#&gt;     grp       a       b     c     d\n#&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1 -0.0935 -0.0163 0.363 0.364\n#&gt; 2     2  0.312  -0.0576 0.208 0.565\n\n注意，分组列（这里是 grp）不包含在 across() 的选择范围内，因为它们会被 summarize() 自动保留。\nwhere() 允许你根据列的类型来选择列：\n\n\nwhere(is.numeric) 选择所有数值列。\n\nwhere(is.character) 选择所有字符串列。\n\nwhere(is.Date) 选择所有日期列。\n\nwhere(is.POSIXct) 选择所有日期时间列。\n\nwhere(is.logical) 选择所有逻辑列。\n\n就像其他选择器一样，你可以将它们与布尔代数结合起来。例如，!where(is.numeric) 选择所有非数值列，而 starts_with(\"a\") & where(is.logical) 选择所有名称以 “a” 开头的逻辑列。\n\n26.2.2 调用单个函数\nacross() 的第二个参数定义了每一列将如何被转换。在简单的情况下，如上所示，这将是一个现有的函数。这是 R 的一个很特别的特性：我们将一个函数（median、mean、str_flatten 等）传递给另一个函数（across）。这是使 R 成为一门函数式编程语言的特性之一。\n需要注意的是，我们是将这个函数传递给 across()，以便 across() 可以调用它；我们不是自己调用它。这意味着函数名后面不应该有 ()。如果你忘了这一点，你会得到一个错误：\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median()))\n#&gt; Error in `summarize()`:\n#&gt; ℹ In argument: `across(everything(), median())`.\n#&gt; Caused by error in `median.default()`:\n#&gt; ! argument \"x\" is missing, with no default\n\n这个错误是因为你调用函数时没有提供输入，例如：\n\nmedian()\n#&gt; Error in median.default(): argument \"x\" is missing, with no default\n\n\n26.2.3 调用多个函数\n在更复杂的情况下，你可能想要提供额外的参数或执行多个转换。让我们用一个简单的例子来引出这个问题：如果我们的数据中有一些缺失值会发生什么？median() 会传播这些缺失值，给我们一个次优的输出：\n\nrnorm_na &lt;- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss &lt;- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |&gt; \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b     c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    NA    NA    NA  1.15     5\n\n如果我们能将 na.rm = TRUE 传递给 median() 来移除这些缺失值，那就太好了。为此，我们需要创建一个新函数，该函数使用所需的参数调用 median()，而不是直接调用 median()：\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b      c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 0.139 -1.11 -0.387  1.15     5\n\n这种写法有点冗长，所以 R 提供了一个方便的快捷方式：对于这种一次性的或匿名1函数，你可以用 \\ 替换 function2：\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\n无论哪种情况，across() 实际上都等同于以下代码：\n\ndf_miss |&gt; \n  summarize(\n    a = median(a, na.rm = TRUE),\n    b = median(b, na.rm = TRUE),\n    c = median(c, na.rm = TRUE),\n    d = median(d, na.rm = TRUE),\n    n = n()\n  )\n\n当我们从 median() 中移除缺失值时，知道究竟移除了多少个值会很有用。我们可以通过向 across() 提供两个函数来实现这一点：一个用于计算中位数，另一个用于计算缺失值的数量。你可以通过向 .fns 参数提供一个命名的列表来提供多个函数：\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\n如果你仔细观察，你可能会直观地感觉到列名是使用了一个类似 {.col}_{.fn} 的 glue 规范（Section 14.3.2）来命名的，其中 .col 是原始列的名称，.fn 是函数的名称。这并非巧合！正如你将在下一节中学到的，你可以使用 .names 参数来提供你自己的 glue 规范。\n\n26.2.4 列名\nacross() 的结果根据 .names 参数中提供的规范来命名。如果我们想让函数名排在前面，我们可以指定自己的命名方式3：\n\ndf_miss |&gt; \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\n当你将 across() 与 mutate() 一起使用时，.names 参数尤其重要。默认情况下，across() 的输出与输入的名称相同。这意味着在 mutate() 内部使用 across() 将会替换现有的列。例如，这里我们使用 coalesce() 将 NA 替换为 0：\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n#&gt; # A tibble: 5 × 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25   0     1.60 \n#&gt; 2  0     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980  0     1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13 \n#&gt; 5  1.11   0     -0.387 0.704\n\n如果你想创建新的列，可以使用 .names 参数为输出指定新的名称：\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0), .names = \"{.col}_na_zero\")\n  )\n#&gt; # A tibble: 5 × 8\n#&gt;        a      b      c     d a_na_zero b_na_zero c_na_zero d_na_zero\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60      0.434    -1.25      0         1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776     0        -1.43     -0.297     0.776\n#&gt; 3 -0.156 -0.980 NA     1.15     -0.156    -0.980     0         1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13     -2.61     -0.683    -0.785     2.13 \n#&gt; 5  1.11  NA     -0.387 0.704     1.11      0        -0.387     0.704\n\n\n26.2.5 筛选\nacross() 与 summarize() 和 mutate() 是绝佳的搭配，但与 filter() 一起使用时就比较尴尬了，因为你通常需要用 | 或 & 来组合多个条件。很明显，across() 可以帮助创建多个逻辑列，但接下来该怎么办呢？因此，dplyr 提供了 across() 的两个变体，名为 if_any() 和 if_all()：\n\n# 等同于 df_miss |&gt; filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\ndf_miss |&gt; filter(if_any(a:d, is.na))\n#&gt; # A tibble: 4 × 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980 NA     1.15 \n#&gt; 4  1.11  NA     -0.387 0.704\n\n# 等同于 df_miss |&gt; filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\ndf_miss |&gt; filter(if_all(a:d, is.na))\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n\n26.2.6 在函数中使用 across()\n\nacross() 在编程中特别有用，因为它允许你对多个列进行操作。例如，Jacob Scott 使用了这个小助手函数，它包装了一系列 lubridate 函数，将所有日期列扩展为年、月、日列：\n\nexpand_dates &lt;- function(df) {\n  df |&gt; \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date &lt;- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |&gt; \n  expand_dates()\n#&gt; # A tibble: 2 × 5\n#&gt;   name  date       date_year date_month date_day\n#&gt;   &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 Amy   2009-08-03      2009          8        3\n#&gt; 2 Bob   2010-01-16      2010          1       16\n\nacross() 还可以方便地在单个参数中提供多个列，因为它的第一个参数使用了 tidy-select；你只需要记住要拥抱 (embrace) 该参数，正如我们在 Section 25.3.2 中讨论的那样。例如，下面这个函数默认会计算数值列的均值。但是通过提供第二个参数，你可以选择只对选定的列进行汇总：\n\nsummarize_means &lt;- function(df, summary_vars = where(is.numeric)) {\n  df |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means()\n#&gt; # A tibble: 5 × 9\n#&gt;   cut       carat depth table price     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means(c(carat, x:z))\n#&gt; # A tibble: 5 × 6\n#&gt;   cut       carat     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  5.51  5.52  3.40 21551\n\n\n26.2.7 与 pivot_longer() 比较\n在我们继续之前，有必要指出 across() 和 pivot_longer() (Section 5.3) 之间一个有趣的联系。在许多情况下，你可以通过先转换数据，然后按组而不是按列执行操作来完成相同的计算。例如，看下面这个多函数汇总：\n\ndf |&gt; \n  summarize(across(a:d, list(median = median, mean = mean)))\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\n我们可以通过先将数据转换为长格式，然后进行汇总来计算相同的值：\n\nlong &lt;- df |&gt; \n  pivot_longer(a:d) |&gt; \n  group_by(name) |&gt; \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n#&gt; # A tibble: 4 × 3\n#&gt;   name   median   mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 a      0.0380 0.205 \n#&gt; 2 b     -0.0163 0.0910\n#&gt; 3 c      0.260  0.0716\n#&gt; 4 d      0.540  0.508\n\n如果你想要与 across() 相同的结构，你可以再次进行转换：\n\nlong |&gt; \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\n这是一个很有用的技巧，因为有时你会遇到一个目前无法用 across() 解决的问题：当你有多组列，并且想要同时对它们进行计算时。例如，假设我们的数据框包含值和权重，我们想要计算加权平均值：\n\ndf_paired &lt;- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n\n目前没有办法用 across() 来实现这个功能4，但用 pivot_longer() 就相对直接了：\n\ndf_long &lt;- df_paired |&gt; \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n#&gt; # A tibble: 40 × 3\n#&gt;   group    val   wts\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 a      0.715 0.518\n#&gt; 2 b     -0.709 0.691\n#&gt; 3 c      0.718 0.216\n#&gt; 4 d     -0.217 0.733\n#&gt; 5 a     -1.09  0.979\n#&gt; 6 b     -0.209 0.675\n#&gt; # ℹ 34 more rows\n\ndf_long |&gt; \n  group_by(group) |&gt; \n  summarize(mean = weighted.mean(val, wts))\n#&gt; # A tibble: 4 × 2\n#&gt;   group    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a      0.126 \n#&gt; 2 b     -0.0704\n#&gt; 3 c     -0.360 \n#&gt; 4 d     -0.248\n\n如果需要，你可以用 pivot_wider() 将其转换回原始形式。\n\n26.2.8 练习\n\n\n通过以下方式练习你的 across() 技能：\n\n计算 palmerpenguins::penguins 数据集中每一列的唯一值数量。\n计算 mtcars 数据集中每一列的平均值。\n将 diamonds 按 cut、clarity 和 color 分组，然后计算观测数量和每个数值列的平均值。\n\n\n如果在 across() 中使用一个函数列表，但不给它们命名，会发生什么？输出是如何命名的？\n修改 expand_dates() 函数，使其在扩展日期列后自动删除它们。你需要拥抱 (embrace) 任何参数吗？\n\n解释下面这个函数中管道的每一步都做了什么。我们利用了 where() 的什么特殊功能？\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\nnycflights13::flights |&gt; show_missing(c(year, month, day))",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>迭代</span>"
    ]
  },
  {
    "objectID": "iteration.html#读取多个文件",
    "href": "iteration.html#读取多个文件",
    "title": "26  迭代",
    "section": "\n26.3 读取多个文件",
    "text": "26.3 读取多个文件\n在上一节中，你学习了如何使用 dplyr::across() 对多个列重复进行转换。在本节中，你将学习如何使用 purrr::map() 对目录中的每个文件执行某些操作。让我们从一个小小的动机开始：假设你有一个装满了你想要读取的 Excel 电子表格的目录5。你可以通过复制粘贴来完成：\n\ndata2019 &lt;- readxl::read_excel(\"data/y2019.xlsx\")\ndata2020 &lt;- readxl::read_excel(\"data/y2020.xlsx\")\ndata2021 &lt;- readxl::read_excel(\"data/y2021.xlsx\")\ndata2022 &lt;- readxl::read_excel(\"data/y2022.xlsx\")\n\n然后使用 dplyr::bind_rows() 将它们全部合并在一起：\n\ndata &lt;- bind_rows(data2019, data2020, data2021, data2022)\n\n你可以想象这会很快变得乏味，特别是如果你有数百个文件，而不仅仅是四个。接下来的部分将向你展示如何自动化这类任务。有三个基本步骤：使用 list.files() 列出目录中的所有文件，然后使用 purrr::map() 将每个文件读入一个列表中，最后使用 purrr::list_rbind() 将它们合并成一个单一的数据框。然后我们将讨论如何处理异质性越来越高的情况，即你不能对每个文件都做完全相同的事情。\n\n26.3.1 列出目录中的文件\n顾名思义，list.files() 列出目录中的文件。你几乎总是会使用三个参数：\n\n第一个参数 path 是要查看的目录。\npattern 是一个用于过滤文件名的正则表达式。最常见的模式是类似 [.]xlsx$ 或 [.]csv$ 这样的，用来查找所有具有指定扩展名的文件。\nfull.names 决定是否应将目录名包含在输出中。你几乎总是希望它为 TRUE。\n\n为了使我们的动机示例更具体，本书包含一个文件夹，其中有 12 个 Excel 电子表格，包含了来自 gapminder 包的数据。每个文件包含 142 个国家一年的数据。我们可以通过适当的 list.files() 调用来列出它们：\n\npaths &lt;- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\npaths\n#&gt;  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#&gt;  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#&gt;  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#&gt;  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#&gt;  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#&gt; [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n\n26.3.2 列表\n现在我们有了这 12 个路径，我们可以调用 read_excel() 12 次来得到 12 个数据框：\n\ngapminder_1952 &lt;- readxl::read_excel(\"data/gapminder/1952.xlsx\")\ngapminder_1957 &lt;- readxl::read_excel(\"data/gapminder/1957.xlsx\")\ngapminder_1962 &lt;- readxl::read_excel(\"data/gapminder/1962.xlsx\")\n  ...,\ngapminder_2007 &lt;- readxl::read_excel(\"data/gapminder/2007.xlsx\")\n\n但是将每个表格放入其自己的变量中，会在接下来的步骤中使它们难以处理。相反，如果我们将它们放入一个单一的对象中，它们会更容易处理。列表 (list) 是完成这项工作的完美工具：\n\nfiles &lt;- list(\n  readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\n现在你已经将这些数据框放入一个列表中，你如何取出一个呢？你可以使用 files[[i]] 来提取第 i&lt;sup&gt;th&lt;/sup&gt; 个元素：\n\nfiles[[3]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\n我们将在 Section 27.3 中更详细地回到 [[。\n\n26.3.3 purrr::map() 和 list_rbind()\n\n“手动”收集这些数据框到列表中的代码，基本上和逐个读取文件的代码一样繁琐。幸运的是，我们可以使用 purrr::map() 来更好地利用我们的 paths 向量。map() 类似于 across()，但它不是对数据框中的每一列做某事，而是对向量中的每个元素做某事。map(x, f) 是以下代码的简写：\n\nlist(\n  f(x[[1]]),\n  f(x[[2]]),\n  ...,\n  f(x[[n]])\n)\n\n所以我们可以使用 map() 来得到一个包含 12 个数据框的列表：\n\nfiles &lt;- map(paths, readxl::read_excel)\nlength(files)\n#&gt; [1] 12\n\nfiles[[1]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 136 more rows\n\n(这是另一种用 str() 显示不够紧凑的数据结构，所以你可能想在 RStudio 中加载它并用 View() 来检查它)。\n现在我们可以使用 purrr::list_rbind() 将这个数据框列表合并成一个单一的数据框：\n\nlist_rbind(files)\n#&gt; # A tibble: 1,704 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n或者我们可以在一个管道中同时完成这两个步骤：\n\npaths |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind()\n\n如果我们想给 read_excel() 传入额外的参数怎么办？我们使用与 across() 相同的技术。例如，用 n_max = 1 预览数据的前几行通常很有用：\n\npaths |&gt; \n  map(\\(path) readxl::read_excel(path, n_max = 1)) |&gt; \n  list_rbind()\n#&gt; # A tibble: 12 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Afghanistan Asia         30.3  9240934      821.\n#&gt; 3 Afghanistan Asia         32.0 10267083      853.\n#&gt; 4 Afghanistan Asia         34.0 11537966      836.\n#&gt; 5 Afghanistan Asia         36.1 13079460      740.\n#&gt; 6 Afghanistan Asia         38.4 14880372      786.\n#&gt; # ℹ 6 more rows\n\n这清楚地表明缺少了某些东西：没有 year 列，因为这个值记录在路径中，而不是在单个文件中。我们将在下一步解决这个问题。\n\n26.3.4 路径中的数据\n有时文件名本身就是数据。在这个例子中，文件名包含了年份，而这个信息在单个文件中并没有记录。为了将这一列加入到最终的数据框中，我们需要做两件事：\n首先，我们为路径向量命名。最简单的方法是使用 set_names() 函数，它可以接受一个函数作为参数。这里我们使用 basename() 从完整路径中仅提取文件名：\n\npaths |&gt; set_names(basename) \n#&gt;                  1952.xlsx                  1957.xlsx \n#&gt; \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n#&gt;                  1962.xlsx                  1967.xlsx \n#&gt; \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n#&gt;                  1972.xlsx                  1977.xlsx \n#&gt; \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n#&gt;                  1982.xlsx                  1987.xlsx \n#&gt; \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n#&gt;                  1992.xlsx                  1997.xlsx \n#&gt; \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n#&gt;                  2002.xlsx                  2007.xlsx \n#&gt; \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n这些名称会被所有的 map 函数自动沿用，所以数据框列表也会有相同的名称：\n\nfiles &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel)\n\n这使得这个 map() 调用成为以下代码的简写：\n\nfiles &lt;- list(\n  \"1952.xlsx\" = readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  \"1957.xlsx\" = readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  \"1962.xlsx\" = readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  \"2007.xlsx\" = readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\n你也可以使用 [[ 按名称提取元素：\n\nfiles[[\"1962.xlsx\"]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\n然后，我们使用 list_rbind() 的 names_to 参数，告诉它将名称保存到一个名为 year 的新列中，然后使用 readr::parse_number() 从字符串中提取数字。\n\npaths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n#&gt; # A tibble: 1,704 × 6\n#&gt;    year country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  1952 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2  1952 Albania     Europe       55.2  1282697     1601.\n#&gt; 3  1952 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4  1952 Angola      Africa       30.0  4232095     3521.\n#&gt; 5  1952 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6  1952 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n在更复杂的情况下，可能还有其他变量存储在目录名中，或者文件名可能包含多个数据片段。在这种情况下，使用 set_names()（不带任何参数）来记录完整路径，然后使用 tidyr::separate_wider_delim() 及其相关函数将它们转换成有用的列。\n\npaths |&gt; \n  set_names() |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |&gt; \n  separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n#&gt; # A tibble: 1,704 × 8\n#&gt;   dir       file  ext   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n#&gt; 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n#&gt; 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n\n26.3.5 保存你的工作\n现在你已经完成了所有这些辛苦的工作，得到了一个整洁的数据框，是时候保存你的工作了：\n\ngapminder &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n\nwrite_csv(gapminder, \"gapminder.csv\")\n\n现在，当你将来再次处理这个问题时，你可以只读取一个 csv 文件。对于更大、更丰富的数据集，使用 parquet 可能比 .csv 是一个更好的选择，如 Section 22.4 中所讨论的。\n如果你在一个项目（project）中工作，我们建议将执行这类数据准备工作的文件命名为 0-cleanup.R。文件名中的 0 暗示这个文件应该在其他任何文件之前运行。\n如果你的输入数据文件会随时间变化，你可能需要考虑学习一个像 targets 这样的工具，来设置你的数据清理代码，使其在任何输入文件被修改时自动重新运行。\n\n26.3.6 多次简单迭代\n在这里，我们只是直接从磁盘加载了数据，并幸运地得到了一个整洁的数据集。在大多数情况下，你需要进行一些额外的整理工作，你有两种基本选择：你可以用一个复杂的函数进行一轮迭代，或者用简单的函数进行多轮迭代。根据我们的经验，大多数人首先会选择进行一次复杂的迭代，但通常通过进行多次简单的迭代会更好。\n例如，假设你想读入一堆文件，过滤掉缺失值，进行数据转换，然后合并。一种方法是编写一个函数，它接收一个文件并执行所有这些步骤，然后调用 map() 一次：\n\nprocess_file &lt;- function(path) {\n  df &lt;- read_csv(path)\n  \n  df |&gt; \n    filter(!is.na(id)) |&gt; \n    mutate(id = tolower(id)) |&gt; \n    pivot_longer(jan:dec, names_to = \"month\")\n}\n\npaths |&gt; \n  map(process_file) |&gt; \n  list_rbind()\n\n或者，你可以对每个文件执行 process_file() 的每一步：\n\npaths |&gt; \n  map(read_csv) |&gt; \n  map(\\(df) df |&gt; filter(!is.na(id))) |&gt; \n  map(\\(df) df |&gt; mutate(id = tolower(id))) |&gt; \n  map(\\(df) df |&gt; pivot_longer(jan:dec, names_to = \"month\")) |&gt; \n  list_rbind()\n\n我们推荐这种方法，因为它能防止你在转向处理其余文件之前，过分专注于把第一个文件处理得完美无瑕。通过在进行整理和清理时考虑所有数据，你更有可能进行整体思考，并最终得到更高质量的结果。\n在这个特定的例子中，还有另一个可以做的优化，就是更早地将所有数据框绑定在一起。然后你可以依赖常规的 dplyr 行为：\n\npaths |&gt; \n  map(read_csv) |&gt; \n  list_rbind() |&gt; \n  filter(!is.na(id)) |&gt; \n  mutate(id = tolower(id)) |&gt; \n  pivot_longer(jan:dec, names_to = \"month\")\n\n\n26.3.7 异构数据\n不幸的是，有时无法直接从 map() 转到 list_rbind()，因为数据框的异构性太高，导致 list_rbind() 要么失败，要么产生一个不太有用的数据框。在这种情况下，先加载所有文件仍然是有用的：\n\nfiles &lt;- paths |&gt; \n  map(readxl::read_excel) \n\n然后，一个非常有用的策略是捕获数据框的结构，以便你可以用你的数据科学技能来探索它。一种方法是使用这个方便的 df_types 函数6，它返回一个 tibble，每列一行：\n\ndf_types &lt;- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder)\n#&gt; # A tibble: 6 × 3\n#&gt;   col_name  col_type  n_miss\n#&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 year      double         0\n#&gt; 2 country   character      0\n#&gt; 3 continent character      0\n#&gt; 4 lifeExp   double         0\n#&gt; 5 pop       double         0\n#&gt; 6 gdpPercap double         0\n\n然后你可以将这个函数应用于所有文件，并可能进行一些转换，以便更容易地看到差异所在。例如，这使得验证我们一直在处理的 gapminder 电子表格都非常同质化变得容易：\n\nfiles |&gt; \n  map(df_types) |&gt; \n  list_rbind(names_to = \"file_name\") |&gt; \n  select(-n_miss) |&gt; \n  pivot_wider(names_from = col_name, values_from = col_type)\n#&gt; # A tibble: 12 × 6\n#&gt;   file_name country   continent lifeExp pop    gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1 1952.xlsx character character double  double double   \n#&gt; 2 1957.xlsx character character double  double double   \n#&gt; 3 1962.xlsx character character double  double double   \n#&gt; 4 1967.xlsx character character double  double double   \n#&gt; 5 1972.xlsx character character double  double double   \n#&gt; 6 1977.xlsx character character double  double double   \n#&gt; # ℹ 6 more rows\n\n如果文件具有异构格式，你可能需要进行更多的处理才能成功合并它们。不幸的是，我们现在要让你自己去解决了，但你可能想读一下关于 map_if() 和 map_at() 的内容。map_if() 允许你根据列表元素的值有选择地修改它们；map_at() 允许你根据它们的名称有选择地修改元素。\n\n26.3.8 处理失败\n有时你的数据结构可能足够混乱，以至于你甚至不能用一个命令读取所有文件。然后你会遇到 map() 的一个缺点：它要么整体成功，要么整体失败。map() 要么成功读取目录中的所有文件，要么因错误而失败，一个文件也读不进来。这很烦人：为什么一个失败会阻止你访问所有其他成功的结果？\n幸运的是，purrr 提供了一个助手来解决这个问题：possibly()。possibly() 是所谓的函数操作符：它接受一个函数并返回一个行为被修改的函数。具体来说，possibly() 将一个会出错的函数改变为返回你指定的值：\n\nfiles &lt;- paths |&gt; \n  map(possibly(\\(path) readxl::read_excel(path), NULL))\n\ndata &lt;- files |&gt; list_rbind()\n\n这在这里特别有效，因为 list_rbind()，像许多 tidyverse 函数一样，会自动忽略 NULL。\n现在你有了所有可以轻松读取的数据，是时候解决困难的部分了，即找出为什么有些文件加载失败以及该怎么处理。首先获取失败的路径：\n\nfailed &lt;- map_vec(files, is.null)\npaths[failed]\n#&gt; character(0)\n\n然后对每个失败的路径再次调用导入函数，找出问题所在。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>迭代</span>"
    ]
  },
  {
    "objectID": "iteration.html#保存多个输出",
    "href": "iteration.html#保存多个输出",
    "title": "26  迭代",
    "section": "\n26.4 保存多个输出",
    "text": "26.4 保存多个输出\n在上一节中，你学习了 map()，它对于将多个文件读入单个对象很有用。在本节中，我们将探讨一个相反的问题：如何将一个或多个 R 对象保存到一个或多个文件中？我们将通过三个例子来探讨这个挑战：\n\n将多个数据框保存到一个数据库中。\n将多个数据框保存到多个 .csv 文件中。\n将多个图保存到多个 .png 文件中。\n\n\n26.4.1 写入数据库\n有时在同时处理许多文件时，不可能一次性将所有数据都装入内存，也就无法执行 map(files, read_csv)。处理这个问题的一种方法是将数据加载到数据库中，这样你就可以用 dbplyr 只访问你需要的部分。\n如果你幸运的话，你正在使用的数据库包会提供一个方便的函数，该函数接收一个路径向量并将它们全部加载到数据库中。duckdb 的 duckdb_read_csv() 就是这种情况：\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nduckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\n这在这里会很好用，但我们没有 csv 文件，而是 Excel 电子表格。所以我们得“手动”来做。学习手动操作也能帮助你在有一堆 csv 文件，而你正在使用的数据库没有一个能一次性加载所有文件的函数时。\n我们需要从创建一个我们将用数据填充的表开始。最简单的方法是创建一个模板，一个包含我们想要的所有列但只包含部分数据的虚拟数据框。对于 gapminder 数据，我们可以通过读取单个文件并向其添加年份来制作该模板：\n\ntemplate &lt;- readxl::read_excel(paths[[1]])\ntemplate$year &lt;- 1952\ntemplate\n#&gt; # A tibble: 142 × 6\n#&gt;   country     continent lifeExp      pop gdpPercap  year\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.  1952\n#&gt; 2 Albania     Europe       55.2  1282697     1601.  1952\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.  1952\n#&gt; 4 Angola      Africa       30.0  4232095     3521.  1952\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.  1952\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.  1952\n#&gt; # ℹ 136 more rows\n\n现在我们可以连接到数据库，并使用 DBI::dbCreateTable() 将我们的模板变成一个数据库表：\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nDBI::dbCreateTable(con, \"gapminder\", template)\n\ndbCreateTable() 不使用 template 中的数据，只使用变量名和类型。所以如果我们现在检查 gapminder 表，你会看到它是空的，但它有我们需要的变量和我们期望的类型：\n\ncon |&gt; tbl(\"gapminder\")\n#&gt; # Source:   table&lt;gapminder&gt; [?? x 6]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt; # ℹ 6 variables: country &lt;chr&gt;, continent &lt;chr&gt;, lifeExp &lt;dbl&gt;, pop &lt;dbl&gt;,\n#&gt; #   gdpPercap &lt;dbl&gt;, year &lt;dbl&gt;\n\n接下来，我们需要一个函数，它接受单个文件路径，将其读入 R，并将结果添加到 gapminder 表中。我们可以通过结合 read_excel() 和 DBI::dbAppendTable() 来做到这一点：\n\nappend_file &lt;- function(path) {\n  df &lt;- readxl::read_excel(path)\n  df$year &lt;- parse_number(basename(path))\n  \n  DBI::dbAppendTable(con, \"gapminder\", df)\n}\n\n现在我们需要对 paths 的每个元素调用一次 append_file()。这当然可以用 map() 来实现：\n\npaths |&gt; map(append_file)\n\n但我们不关心 append_file() 的输出，所以使用 walk() 会比 map() 稍微好一些。walk() 的作用与 map() 完全相同，但会丢弃输出：\n\npaths |&gt; walk(append_file)\n\n现在我们可以看看我们的表中是否包含了所有数据：\n\ncon |&gt; \n  tbl(\"gapminder\") |&gt; \n  count(year)\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;    year     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1972   142\n#&gt; 2  1992   142\n#&gt; 3  1997   142\n#&gt; 4  2002   142\n#&gt; 5  1977   142\n#&gt; 6  1952   142\n#&gt; # ℹ more rows\n\n\n26.4.2 写入 csv 文件\n如果我们想为每个组写入多个 csv 文件，基本原理是相同的。让我们假设我们想取 ggplot2::diamonds 数据，并为每个 clarity 保存一个 csv 文件。首先，我们需要创建那些单独的数据集。有很多方法可以做到这一点，但有一种我们特别喜欢的方法：group_nest()。\n\nby_clarity &lt;- diamonds |&gt; \n  group_nest(clarity)\n\nby_clarity\n#&gt; # A tibble: 8 × 2\n#&gt;   clarity               data\n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n#&gt; 1 I1               [741 × 9]\n#&gt; 2 SI2            [9,194 × 9]\n#&gt; 3 SI1           [13,065 × 9]\n#&gt; 4 VS2           [12,258 × 9]\n#&gt; 5 VS1            [8,171 × 9]\n#&gt; 6 VVS2           [5,066 × 9]\n#&gt; # ℹ 2 more rows\n\n这给了我们一个有八行两列的新 tibble。clarity 是我们的分组变量，data 是一个列表列，其中包含 clarity 每个唯一值对应的一个 tibble：\n\nby_clarity$data[[1]]\n#&gt; # A tibble: 741 × 9\n#&gt;   carat cut       color depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#&gt; 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#&gt; 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#&gt; 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#&gt; 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#&gt; 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#&gt; # ℹ 735 more rows\n\n趁热打铁，让我们创建一个给出输出文件名的列，使用 mutate() 和 str_glue()：\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity               data path             \n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n#&gt; 1 I1               [741 × 9] diamonds-I1.csv  \n#&gt; 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#&gt; 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#&gt; 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#&gt; 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#&gt; 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#&gt; # ℹ 2 more rows\n\n所以如果我们要手动保存这些数据框，我们可能会这样写：\n\nwrite_csv(by_clarity$data[[1]], by_clarity$path[[1]])\nwrite_csv(by_clarity$data[[2]], by_clarity$path[[2]])\nwrite_csv(by_clarity$data[[3]], by_clarity$path[[3]])\n...\nwrite_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])\n\n这与我们之前使用 map() 的情况有点不同，因为有两个参数在变化，而不仅仅是一个。这意味着我们需要一个新的函数：map2()，它同时改变第一个和第二个参数。而且因为我们同样不关心输出，所以我们想要用 walk2() 而不是 map2()。这样我们就得到了：\n\nwalk2(by_clarity$data, by_clarity$path, write_csv)\n\n\n26.4.3 保存图表\n我们可以采用同样的基本方法来创建多个图表。让我们先创建一个函数来绘制我们想要的图表：\n\ncarat_histogram &lt;- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\n\n\n\n现在我们可以使用 map() 来创建一个包含多个图表7及其最终文件路径的列表：\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\n然后使用 walk2() 配合 ggsave() 来保存每个图表：\n\nwalk2(\n  by_clarity$path,\n  by_clarity$plot,\n  \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n)\n\n这是以下代码的简写：\n\nggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)\nggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)\nggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)\n...\nggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>迭代</span>"
    ]
  },
  {
    "objectID": "iteration.html#总结",
    "href": "iteration.html#总结",
    "title": "26  迭代",
    "section": "\n26.5 总结",
    "text": "26.5 总结\n在本章中，你已经看到了如何使用显式迭代来解决数据科学中经常出现的三个问题：操作多个列、读取多个文件以及保存多个输出。但总的来说，迭代是一种超能力：如果你知道正确的迭代技巧，你可以轻松地从解决一个问题扩展到解决所有问题。一旦你掌握了本章中的技术，我们强烈建议你通过阅读《Advanced R》的 Functionals 章节和查阅 purrr 网站来学习更多内容。\n如果你对其他语言中的迭代有很多了解，你可能会惊讶于我们没有讨论 for 循环。这是因为 R 面向数据分析的特性改变了我们迭代的方式：在大多数情况下，你可以依赖现有的惯用法来对每一列或每个组执行操作。而当你无法这样做时，你通常可以使用像 map() 这样的函数式编程工具，它对列表的每个元素执行操作。然而，你会在野外捕获的代码中看到 for 循环，所以你将在下一章中学习它们，届时我们将讨论一些重要的基础 R 工具。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>迭代</span>"
    ]
  },
  {
    "objectID": "iteration.html#footnotes",
    "href": "iteration.html#footnotes",
    "title": "26  迭代",
    "section": "",
    "text": "匿名，因为我们从未用 &lt;- 明确地给它命名。程序员们使用的另一个术语是“lambda 函数”。↩︎\n在旧代码中，你可能会看到类似 ~ .x + 1 的语法。这是编写匿名函数的另一种方式，但它只在 tidyverse 函数内部有效，并且总是使用变量名 .x。我们现在推荐使用基础语法 \\(x) x + 1。↩︎\n你目前无法更改列的顺序，但可以在事后使用 relocate() 或类似函数重新排序。↩︎\n也许有一天会有，但目前我们还没看到如何实现。↩︎\n如果你有一个包含相同格式的 csv 文件的目录，你可以使用 Section 7.4 中的技术。↩︎\n我们不打算解释它是如何工作的，但如果你查看所用函数的文档，你应该能弄明白。↩︎\n你可以打印 by_clarity$plot 来获得一个粗略的动画——你会为 plots 的每个元素得到一个图。注意：这在我这里没有发生。↩︎",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>迭代</span>"
    ]
  },
  {
    "objectID": "base-R.html",
    "href": "base-R.html",
    "title": "27  Base R 实战指南",
    "section": "",
    "text": "27.1 引言\n为了完成编程部分的学习，我们将带你快速浏览一些本书中未曾讨论但非常重要的 Base R 函数。 当你进行更多的编程工作时，这些工具会特别有用，它们也将帮助你阅读在实际工作中遇到的 R 代码。\n在此，我们想再次提醒你，tidyverse 并非解决数据科学问题的唯一途径。 我们在本书中教授 tidyverse，是因为 tidyverse 系列包共享一套通用的设计理念，这增加了函数之间的一致性，使得学习和使用每一个新函数或包都变得更加容易。 不使用 Base R 是不可能使用 tidyverse 的，所以我们实际上已经教了你大量的 Base R 函数：从用于加载包的 library()，到用于数值摘要的 sum() 和 mean()，再到因子 (factor)、日期 (date) 和 POSIXct 数据类型，当然还有所有基本运算符，如 +、-、/、*、|、& 和 !。 到目前为止，我们还没有重点介绍 Base R 的工作流程，因此在本章中，我们将重点介绍其中的一些。\n读完本书后，你将学习到使用 Base R、data.table 和其他包来解决同样问题的其他方法。 当你开始阅读他人编写的 R 代码时，尤其是在使用 StackOverflow 时，你无疑会遇到这些其他方法。 编写混合使用多种方法的代码是完全可以的，不要让任何人告诉你这有什么不对！\n在本章中，我们将重点关注四个主要主题：使用 [ 进行子集选取，使用 [[ 和 $ 进行子集选取，apply 函数族，以及 for 循环。 最后，我们将简要讨论两个必不可少的绘图函数。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#引言",
    "href": "base-R.html#引言",
    "title": "27  Base R 实战指南",
    "section": "",
    "text": "27.1.1 前提条件\n这个包侧重于 Base R，因此没有真正的前提条件，但我们将加载 tidyverse 以便解释一些差异。\n\nlibrary(tidyverse)",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-many",
    "href": "base-R.html#sec-subset-many",
    "title": "27  Base R 实战指南",
    "section": "\n27.2 使用 [ 选取多个元素",
    "text": "27.2 使用 [ 选取多个元素\n[ 用于从向量和数据框中提取子组件，调用形式为 x[i] 或 x[i, j]。 在本节中，我们将向你介绍 [ 的强大功能，首先展示如何将其用于向量，然后说明同样的原理如何直接扩展到二维 (2d) 结构，如数据框。 接着，我们将通过展示各种 dplyr 动词是如何作为 [ 的特例，来帮助你巩固这些知识。\n\n27.2.1 向量子集选取\n你可以用五种主要类型的东西来对向量进行子集选取，即 x[i] 中的 i 可以是：\n\n\n一个正整数向量。 用正整数进行子集选取会保留这些位置上的元素：\n\nx &lt;- c(\"one\", \"two\", \"three\", \"four\", \"five\")\nx[c(3, 2, 5)]\n#&gt; [1] \"three\" \"two\"   \"five\"\n\n通过重复一个位置，你实际上可以得到比输入更长的输出，这使得“子集选取 (subsetting)”这个术语有点名不副实。\n\nx[c(1, 1, 5, 5, 5, 2)]\n#&gt; [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\"\n\n\n\n一个负整数向量。 负数值会丢弃指定位置的元素：\n\nx[c(-1, -3, -5)]\n#&gt; [1] \"two\"  \"four\"\n\n\n\n一个逻辑向量。 用逻辑向量进行子集选取会保留所有对应 TRUE 值的值。 这在与比较函数结合使用时最为有用。\n\nx &lt;- c(10, 3, NA, 5, 8, 1, NA)\n\n# x 的所有非缺失值\nx[!is.na(x)]\n#&gt; [1] 10  3  5  8  1\n\n# x 的所有偶数（或缺失！）值\nx[x %% 2 == 0]\n#&gt; [1] 10 NA  8 NA\n\n与 filter() 不同，NA 索引将在输出中作为 NA 包含进来。\n\n\n一个字符向量。 如果你有一个命名的向量，你可以用字符向量来对其进行子集选取：\n\nx &lt;- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n#&gt; xyz def \n#&gt;   5   2\n\n与使用正整数进行子集选取一样，你可以使用字符向量来复制单个条目。\n\n空。 最后一种子集选取是空，即 x[]，它返回完整的 x。 这对于向量的子集选取没什么用，但我们稍后会看到，在对二维结构（如 tibble）进行子集选取时它非常有用。\n\n27.2.2 数据框子集选取\n你可以用很多不同的方式1 对数据框使用 [，但最重要的方式是使用 df[rows, cols] 独立地选择行和列。这里的 rows 和 cols 是如上所述的向量。 例如，df[rows, ] 和 df[, cols] 分别只选择行或只选择列，使用空子集来保留另一维度。\n这里有几个例子：\n\ndf &lt;- tibble(\n  x = 1:3, \n  y = c(\"a\", \"e\", \"f\"), \n  z = runif(3)\n)\n\n# 选择第一行和第二列\ndf[1, 2]\n#&gt; # A tibble: 1 × 1\n#&gt;   y    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a\n\n# 选择所有行以及 x 和 y 列\ndf[, c(\"x\" , \"y\")]\n#&gt; # A tibble: 3 × 2\n#&gt;       x y    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 a    \n#&gt; 2     2 e    \n#&gt; 3     3 f\n\n# 选择 `x` 大于 1 的行和所有列\ndf[df$x &gt; 1, ]\n#&gt; # A tibble: 2 × 3\n#&gt;       x y         z\n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2 e     0.834\n#&gt; 2     3 f     0.601\n\n我们稍后会回到 $，但你应该能从上下文中猜出 df$x 的作用：它从 df 中提取 x 变量。 我们在这里需要使用它，因为 [ 不使用整洁求值 (tidy evaluation)，所以你需要明确 x 变量的来源。\n在 [ 的使用上，tibble 和 data frame 之间有一个重要的区别。 在本书中，我们主要使用 tibble，它是一种数据框，但它们调整了一些行为以使你的工作更轻松一些。 在大多数地方，你可以互换使用“tibble”和“data frame”，所以当我们想特别指出 R 的内置 data frame 时，我们会写成 data.frame。 如果 df 是一个 data.frame，那么如果 col 选择单个列，df[, cols] 将返回一个向量；如果它选择多个列，则返回一个数据框。 如果 df 是一个 tibble，那么 [ 将始终返回一个 tibble。\n\ndf1 &lt;- data.frame(x = 1:3)\ndf1[, \"x\"]\n#&gt; [1] 1 2 3\n\ndf2 &lt;- tibble(x = 1:3)\ndf2[, \"x\"]\n#&gt; # A tibble: 3 × 1\n#&gt;       x\n#&gt;   &lt;int&gt;\n#&gt; 1     1\n#&gt; 2     2\n#&gt; 3     3\n\n一种避免与 data.frame 产生这种歧义的方法是明确指定 drop = FALSE：\n\ndf1[, \"x\" , drop = FALSE]\n#&gt;   x\n#&gt; 1 1\n#&gt; 2 2\n#&gt; 3 3\n\n\n27.2.3 dplyr 等价操作\n一些 dplyr 动词是 [ 的特例：\n\n\nfilter() 等价于使用逻辑向量对行进行子集选取，并注意排除缺失值：\n\ndf &lt;- tibble(\n  x = c(2, 3, 1, 1, NA), \n  y = letters[1:5], \n  z = runif(5)\n)\ndf |&gt; filter(x &gt; 1)\n\n# 等同于\ndf[!is.na(df$x) & df$x &gt; 1, ]\n\n在实际应用中，另一个常见的技巧是使用 which() 来达到丢弃缺失值的副作用：df[which(df$x &gt; 1), ]。\n\n\narrange() 等价于使用整数向量对行进行子集选取，这个向量通常由 order() 创建：\n\ndf |&gt; arrange(x, y)\n\n# 等同于\ndf[order(df$x, df$y), ]\n\n你可以使用 order(decreasing = TRUE) 来按降序对所有列进行排序，或者使用 -rank(col) 来单独按降序对列进行排序。\n\n\nselect() 和 relocate() 都类似于使用字符向量对列进行子集选取：\n\ndf |&gt; select(x, z)\n\n# 等同于\ndf[, c(\"x\", \"z\")]\n\n\n\nBase R 还提供了一个结合了 filter() 和 select() 功能的函数2，名为 subset()：\n\ndf |&gt; \n  filter(x &gt; 1) |&gt; \n  select(y, z)\n#&gt; # A tibble: 2 × 2\n#&gt;   y           z\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a     0.157  \n#&gt; 2 b     0.00740\n\n\n# 等同于\ndf |&gt; subset(x &gt; 1, c(y, z))\n\n这个函数是 dplyr 许多语法设计的灵感来源。\n\n27.2.4 练习\n\n\n创建函数，输入一个向量，然后返回：\n\n偶数位置上的元素。\n除了最后一个值之外的所有元素。\n只有偶数值（并且没有缺失值）。\n\n\n为什么 x[-which(x &gt; 0)] 和 x[x &lt;= 0] 不一样？ 阅读 which() 的文档并做一些实验来找出答案。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-one",
    "href": "base-R.html#sec-subset-one",
    "title": "27  Base R 实战指南",
    "section": "\n27.3 使用 $ 和 [[ 选取单个元素",
    "text": "27.3 使用 $ 和 [[ 选取单个元素\n[ 用于选取多个元素，与之配对的是 [[ 和 $，它们用于提取单个元素。 在本节中，我们将向你展示如何使用 [[ 和 $ 从数据框中提取列，讨论 data.frame 和 tibble 之间更多的几个区别，并强调在与列表一起使用时 [ 和 [[ 之间的一些重要差异。\n\n27.3.1 数据框\n[[ 和 $ 可以用来从数据框中提取列。 [[ 可以通过位置或名称访问，而 $ 专门用于按名称访问：\n\ntb &lt;- tibble(\n  x = 1:4,\n  y = c(10, 4, 1, 21)\n)\n\n# 按位置\ntb[[1]]\n#&gt; [1] 1 2 3 4\n\n# 按名称\ntb[[\"x\"]]\n#&gt; [1] 1 2 3 4\ntb$x\n#&gt; [1] 1 2 3 4\n\n它们也可以用来创建新列，这是 mutate() 在 Base R 中的等价操作：\n\ntb$z &lt;- tb$x + tb$y\ntb\n#&gt; # A tibble: 4 × 3\n#&gt;       x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    10    11\n#&gt; 2     2     4     6\n#&gt; 3     3     1     4\n#&gt; 4     4    21    25\n\n还有其他几种 Base R 创建新列的方法，包括使用 transform()、with() 和 within()。 Hadley 在 https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf 收集了一些例子。\n在进行快速摘要时，直接使用 $ 很方便。 例如，如果你只想找出最大钻石的克拉数或 cut 的可能值，就不需要使用 summarize()：\n\nmax(diamonds$carat)\n#&gt; [1] 5.01\n\nlevels(diamonds$cut)\n#&gt; [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\ndplyr 也提供了一个等价于 [[/$ 的函数，我们在 Chapter 3 中没有提到：pull()。 pull() 接受一个变量名或变量位置，并只返回那一列。 这意味着我们可以重写上面的代码来使用管道：\n\ndiamonds |&gt; pull(carat) |&gt; max()\n#&gt; [1] 5.01\n\ndiamonds |&gt; pull(cut) |&gt; levels()\n#&gt; [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\n\n27.3.2 Tibbles\n在 $ 的使用上，tibble 和 Base data.frame 之间有几个重要的区别。 Data frame 会匹配任何变量名的前缀（即所谓的部分匹配 (partial matching)），并且如果一列不存在也不会报错：\n\ndf &lt;- data.frame(x1 = 1)\ndf$x\n#&gt; [1] 1\ndf$z\n#&gt; NULL\n\nTibble 更为严格：它们只精确匹配变量名，并且如果你尝试访问的列不存在，它们会生成一个警告：\n\ntb &lt;- tibble(x1 = 1)\n\ntb$x\n#&gt; Warning: Unknown or uninitialised column: `x`.\n#&gt; NULL\ntb$z\n#&gt; Warning: Unknown or uninitialised column: `z`.\n#&gt; NULL\n\n因此，我们有时开玩笑说 tibble 是“又懒又暴躁”：它们做得更少，抱怨得更多。\n\n27.3.3 列表\n[[ 和 $ 在处理列表时也非常重要，理解它们与 [ 的区别至关重要。 让我们用一个名为 l 的列表来说明这些差异：\n\nl &lt;- list(\n  a = 1:3, \n  b = \"a string\", \n  c = pi, \n  d = list(-1, -5)\n)\n\n\n\n[ 提取一个子列表。 无论你提取多少个元素，结果总是一个列表。\n\nstr(l[1:2])\n#&gt; List of 2\n#&gt;  $ a: int [1:3] 1 2 3\n#&gt;  $ b: chr \"a string\"\n\nstr(l[1])\n#&gt; List of 1\n#&gt;  $ a: int [1:3] 1 2 3\n\nstr(l[4])\n#&gt; List of 1\n#&gt;  $ d:List of 2\n#&gt;   ..$ : num -1\n#&gt;   ..$ : num -5\n\n与向量一样，你可以用逻辑、整数或字符向量进行子集选取。\n\n\n[[ 和 $ 从列表中提取单个组件。 它们会从列表中移除一个层级。\n\nstr(l[[1]])\n#&gt;  int [1:3] 1 2 3\n\nstr(l[[4]])\n#&gt; List of 2\n#&gt;  $ : num -1\n#&gt;  $ : num -5\n\nstr(l$a)\n#&gt;  int [1:3] 1 2 3\n\n\n\n[ 和 [[ 之间的区别对于列表尤为重要，因为 [[ 会深入到列表中，而 [ 返回一个新的、更小的列表。 为了帮助你记住这个区别，请看 Figure 27.1 中展示的那个不寻常的胡椒瓶。 如果这个胡椒瓶是你的列表 pepper，那么 pepper[1] 就是一个装有单个胡椒包的胡椒瓶。 pepper[2] 看起来一样，但会装有第二个胡椒包。 pepper[1:2] 将是一个装有两个胡椒包的胡椒瓶。 而 pepper[[1]] 则会提取出胡椒包本身。\n\n\n\n\n\n\n\nFigure 27.1: (左) Hadley 曾经在他酒店房间里发现的一个胡椒瓶。 (中) pepper[1]。 (右) pepper[[1]]。\n\n\n\n\n当你对数据框使用一维 [ 时，同样的原理也适用：df[\"x\"] 返回一个单列数据框，而 df[[\"x\"]] 返回一个向量。\n\n27.3.4 练习\n\n当你用一个比向量长度大的正整数对 [[ 进行子集选取时会发生什么？ 当你用一个不存在的名称进行子集选取时会发生什么？\npepper[[1]][1] 会是什么？ pepper[[1]][[1]] 呢？",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#apply-函数族",
    "href": "base-R.html#apply-函数族",
    "title": "27  Base R 实战指南",
    "section": "\n27.4 Apply 函数族",
    "text": "27.4 Apply 函数族\n在 Chapter 26 中，你学习了 tidyverse 的迭代技术，如 dplyr::across() 和 map 系列函数。 在本节中，你将学习它们的 Base R 等价物，即 apply 函数族。 在此语境下，apply 和 map 是同义词，因为“将一个函数映射 (map) 到向量的每个元素上”的另一种说法是“将一个函数应用 (apply) 到向量的每个元素上”。 这里我们将为你简要介绍这个函数族，以便你在实际中能认出它们。\n这个函数族中最重要的成员是 lapply()，它与 purrr::map() 非常相似3。 事实上，因为我们没有使用 map() 的任何更高级的功能，你可以将 Chapter 26 中所有的 map() 调用都替换为 lapply()。\n没有完全等同于 across() 的 Base R 函数，但你可以通过结合使用 [ 和 lapply() 来接近其功能。 这是可行的，因为在底层，数据框是列的列表，所以对数据框调用 lapply() 会将函数应用于每一列。\n\ndf &lt;- tibble(a = 1, b = 2, c = \"a\", d = \"b\", e = 4)\n\n# 首先找到数值列\nnum_cols &lt;- sapply(df, is.numeric)\nnum_cols\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\n# 然后用 lapply() 转换每一列，再替换原始值\ndf[, num_cols] &lt;- lapply(df[, num_cols, drop = FALSE], \\(x) x * 2)\ndf\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b c     d         e\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2     4 a     b         8\n\n上面的代码使用了一个新函数 sapply()。 它与 lapply() 相似，但它总是尝试简化结果，因此其名称中的 s 代表简化 (simplify)，这里它产生了一个逻辑向量而不是一个列表。 我们不推荐在编程中使用它，因为简化可能会失败并给你一个意想不到的类型，但对于交互式使用来说通常没问题。 purrr 有一个类似的函数叫 map_vec()，我们在 Chapter 26 中没有提到。\nBase R 提供了一个比 sapply() 更严格的版本，叫做 vapply()，是vector apply (向量应用) 的缩写。 它接受一个额外的参数来指定预期的类型，确保无论输入如何，简化过程都以相同的方式发生。 例如，我们可以将上面的 sapply() 调用替换为这个 vapply()，在这里我们指定期望 is.numeric() 返回一个长度为 1 的逻辑向量：\n\nvapply(df, is.numeric, logical(1))\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\nsapply() 和 vapply() 之间的区别在它们位于函数内部时非常重要（因为它对函数对异常输入的鲁棒性有很大影响），但在数据分析中通常无关紧要。\napply 函数族的另一个重要成员是 tapply()，它计算单个分组摘要：\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize(price = mean(price))\n#&gt; # A tibble: 5 × 2\n#&gt;   cut       price\n#&gt;   &lt;ord&gt;     &lt;dbl&gt;\n#&gt; 1 Fair      4359.\n#&gt; 2 Good      3929.\n#&gt; 3 Very Good 3982.\n#&gt; 4 Premium   4584.\n#&gt; 5 Ideal     3458.\n\ntapply(diamonds$price, diamonds$cut, mean)\n#&gt;      Fair      Good Very Good   Premium     Ideal \n#&gt;  4358.758  3928.864  3981.760  4584.258  3457.542\n\n不幸的是，tapply() 将其结果返回在一个命名的向量中，如果你想将多个摘要和分组变量收集到一个数据框中，就需要一些技巧（当然可以不这样做，直接使用自由浮动的向量，但根据我们的经验，这只是推迟了工作）。 如果你想看看如何使用 tapply() 或其他 Base R 技术来执行其他分组摘要，Hadley 在一个 gist 中收集了一些技巧。\napply 函数族的最后一个成员是其同名函数 apply()，它用于处理矩阵和数组。 特别要注意 apply(df, 2, something)，这是一种缓慢且可能危险的方式来实现 lapply(df, something)。 这在数据科学中很少出现，因为我们通常处理的是数据框而不是矩阵。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#for-循环",
    "href": "base-R.html#for-循环",
    "title": "27  Base R 实战指南",
    "section": "\n27.5 for 循环",
    "text": "27.5 for 循环\nfor 循环是 apply 和 map 家族在底层都使用的迭代基本构建块。 for 循环是强大而通用的工具，随着你成为更富经验的 R 程序员，学习它们非常重要。 for 循环的基本结构如下：\n\nfor (element in vector) {\n  # 对 element 执行某些操作\n}\n\nfor 循环最直接的用途是实现与 walk() 相同的效果：对列表的每个元素调用某个具有副作用的函数。 例如，在 Section 26.4.1 中，我们没有使用 walk()：\n\npaths |&gt; walk(append_file)\n\n而是可以使用 for 循环：\n\nfor (path in paths) {\n  append_file(path)\n}\n\n如果你想保存 for 循环的输出，事情就会变得棘手一些，例如像我们在 Chapter 26 中做的那样，读取一个目录中所有的 excel 文件：\n\npaths &lt;- dir(\"data/gapminder\", pattern = \"\\\\.xlsx$\", full.names = TRUE)\nfiles &lt;- map(paths, readxl::read_excel)\n\n你可以使用几种不同的技术，但我们建议事先明确输出会是什么样子。 在这种情况下，我们将需要一个与 paths 长度相同的列表，我们可以用 vector() 来创建它：\n\nfiles &lt;- vector(\"list\", length(paths))\n\n然后，我们不遍历 paths 的元素，而是遍历它们的索引，使用 seq_along() 为 paths 的每个元素生成一个索引：\n\nseq_along(paths)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12\n\n使用索引很重要，因为它允许我们将输入中的每个位置与输出中的相应位置联系起来：\n\nfor (i in seq_along(paths)) {\n  files[[i]] &lt;- readxl::read_excel(paths[[i]])\n}\n\n要将 tibble 列表合并为单个 tibble，你可以使用 do.call() + rbind()：\n\ndo.call(rbind, files)\n#&gt; # A tibble: 1,704 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n与其先创建一个列表并在过程中保存结果，一个更简单的方法是逐个构建数据框：\n\nout &lt;- NULL\nfor (path in paths) {\n  out &lt;- rbind(out, readxl::read_excel(path))\n}\n\n我们建议避免这种模式，因为当向量非常长时，它会变得非常慢。 这就是“for 循环很慢”这个经久不衰的谣言的来源：它们本身不慢，但迭代地增长一个向量是慢的。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#图形",
    "href": "base-R.html#图形",
    "title": "27  Base R 实战指南",
    "section": "\n27.6 图形",
    "text": "27.6 图形\n许多不常使用 tidyverse 的 R 用户也偏爱使用 ggplot2 进行绘图，因为它具有一些有用的特性，如合理的默认设置、自动生成图例和现代的外观。 然而，Base R 的绘图函数仍然很有用，因为它们非常简洁——做一个基本的探索性图表只需要很少的打字。\n在实际应用中，你会看到两种主要的 Base R 图形：散点图和直方图，分别由 plot() 和 hist() 生成。 这里有一个来自 diamonds 数据集的快速示例：\n# 左图\nhist(diamonds$carat)\n\n# 右图\nplot(diamonds$carat, diamonds$price)\n\n\n\n\n\n\n\n\n\n\n请注意，Base R 的绘图函数作用于向量，所以你需要使用 $ 或其他技术从数据框中提取列。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#总结",
    "href": "base-R.html#总结",
    "title": "27  Base R 实战指南",
    "section": "\n27.7 总结",
    "text": "27.7 总结\n在本章中，我们向你展示了一系列用于子集选取和迭代的 Base R 函数。 与本书其他地方讨论的方法相比，这些函数更倾向于“向量”风格，而不是“数据框”风格，因为 Base R 函数倾向于接受单个向量，而不是一个数据框和一些列的规范。 这通常使编程工作更容易，因此当你编写更多函数并开始编写自己的包时，它变得更加重要。\n本章结束了本书的编程部分。 你已经在成为一名不仅使用 R 的数据科学家，而且是能够用 R 编程 的数据科学家的道路上迈出了坚实的一步。 我们希望这些章节激发了你对编程的兴趣，并期待你在本书之外学习更多内容。",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "base-R.html#footnotes",
    "href": "base-R.html#footnotes",
    "title": "27  Base R 实战指南",
    "section": "",
    "text": "阅读 https://adv-r.hadley.nz/subsetting.html#subset-multiple 来了解如何像处理一维对象一样对数据框进行子集选取，以及如何使用矩阵对其进行子集选取。↩︎\n但它不会对分组的数据框进行特殊处理，也不支持像 starts_with() 这样的选择辅助函数。↩︎\n它只是缺少了一些方便的功能，比如进度条和在出错时报告是哪个元素导致了问题。↩︎",
    "crumbs": [
      "编程",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Base R 实战指南</span>"
    ]
  },
  {
    "objectID": "communicate.html",
    "href": "communicate.html",
    "title": "沟通",
    "section": "",
    "text": "到目前为止，你已经学习了多种工具，可以将数据导入 R 中，将其整理成便于分析的形式，然后通过转换和可视化来理解你的数据。 但是，无论你的分析做得多么出色，除非你能向他人解释清楚，否则一切都是徒劳：你需要 沟通 你的结果。\n\n\n\n\n\n\n\nFigure 1: 沟通是数据科学流程的最后一个环节；如果你无法将你的结果传达给他人， 那么无论你的分析多么出色，都毫无意义。\n\n\n\n\n沟通是接下来两章的主题：\n\n在 28  Quarto 中，你将学习 Quarto，这是一个用于整合文字、代码和结果的工具。 你可以使用 Quarto 进行分析师与分析师之间的沟通，也可以用于分析师与决策者之间的沟通。 得益于 Quarto 格式的强大功能，你甚至可以为这两种目的使用同一个文档。\n在 29  Quarto 格式 中，你将简要了解可以使用 Quarto 生成的许多其他类型的输出，包括仪表板、网站和书籍。\n\n这些章节主要关注沟通的技术层面，而不是将你的想法传达给他人这一真正困难的问题。 不过，关于沟通，还有很多其他优秀的书籍，我们将在每章的末尾向你推荐。",
    "crumbs": [
      "沟通"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "28  Quarto",
    "section": "",
    "text": "28.1 引言\nQuarto 为数据科学提供了一个统一的创作框架，它将你的代码、代码的运行结果以及你的文字说明整合在一起。Quarto 文档是完全可复现的，并支持数十种输出格式，如 PDF、Word 文件、演示文稿等。\nQuarto 文件旨在以三种方式使用：\nQuarto 是一个命令行界面工具，而不是一个 R 包。这意味着，总的来说，你无法通过 ? 来获取帮助。因此，在本章的学习过程中以及将来使用 Quarto 时，你应该参考 Quarto 文档。\n如果你是 R Markdown 用户，你可能会想：“Quarto 听起来很像 R Markdown”。你没说错！Quarto 将 R Markdown 生态系统中的许多包（rmarkdown、bookdown、distill、xaringan 等）的功能统一到一个单一、一致的系统中，并且除了 R 之外，还扩展了对 Python 和 Julia 等多种编程语言的原生支持。从某种意义上说，Quarto 体现了十多年来扩展和支持 R Markdown 生TAI系统所学到的一切。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#引言",
    "href": "quarto.html#引言",
    "title": "28  Quarto",
    "section": "",
    "text": "用于与决策者沟通，他们希望关注结论，而不是分析背后的代码。\n用于与其他数据科学家（包括未来的你！）协作，他们既对你的结论感兴趣，也对你如何得出结论（即代码）感兴趣。\n作为一种从事数据科学的环境，如同现代的实验笔记，你不仅可以记录你做了什么，还可以记录你的所思所想。\n\n\n\n\n28.1.1 先决条件\n你需要 Quarto 命令行界面 (Quarto CLI)，但你不需要显式地安装或加载它，因为 RStudio 会在需要时自动完成这两项工作。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#quarto-基础",
    "href": "quarto.html#quarto-基础",
    "title": "28  Quarto",
    "section": "\n28.2 Quarto 基础",
    "text": "28.2 Quarto 基础\n这是一个 Quarto 文件——一个扩展名为 .qmd 的纯文本文件：\n\n---\ntitle: \"Diamond sizes\"\ndate: 2022-09-12\nformat: html\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt;= 2.5)\n```\n\nWe have data about `r nrow(diamonds)` diamonds.\nOnly `r nrow(diamonds) - nrow(smaller)` are larger than 2.5 carats.\nThe distribution of the remainder is shown below:\n\n```{r}\n#| label: plot-smaller-diamonds\n#| echo: false\n\nsmaller |&gt; \n  ggplot(aes(x = carat)) + \n  geom_freqpoly(binwidth = 0.01)\n```\n\n它包含三种重要的内容类型：\n\n一个（可选的）由 --- 包围的 YAML 标头。\n由 ``` 包围的 R 代码块 (chunks)。\n混合了简单文本格式的文本，如 # 标题 和 _斜体_。\n\nFigure 28.1 展示了 RStudio 中一个 .qmd 文档的笔记本界面，其中代码和输出交错显示。你可以通过点击代码块顶部的运行图标（看起来像一个播放按钮），或按 Cmd/Ctrl + Shift + Enter 来运行每个代码块。RStudio 会执行代码并将结果内联显示在代码下方。\n\n\n\n\n\n\n\nFigure 28.1: RStudio 中的一个 Quarto 文档。代码和输出在文档中交错显示， 绘图输出直接出现在代码下方。\n\n\n\n\n如果你不喜欢在文档中看到你的绘图和输出，而更愿意使用 RStudio 的控制台和绘图窗格，你可以点击“Render”旁边的齿轮图标，然后切换到“Chunk Output in Console”，如 Figure 28.2 所示。\n\n\n\n\n\n\n\nFigure 28.2: RStudio 中的一个 Quarto 文档，绘图输出显示在“绘图”窗格中。\n\n\n\n\n要生成包含所有文本、代码和结果的完整报告，请点击“Render”或按 Cmd/Ctrl + Shift + K。你也可以通过 quarto::quarto_render(\"diamond-sizes.qmd\") 以编程方式执行此操作。这将在查看器窗格中显示报告，如 Figure 28.3 所示，并创建一个 HTML 文件。\n\n\n\n\n\n\n\nFigure 28.3: RStudio 中的一个 Quarto 文档，渲染后的文档显示在“查看器”窗格中。\n\n\n\n\n当你渲染文档时，Quarto 会将 .qmd 文件发送给 knitr，https://yihui.org/knitr/，它会执行所有的代码块，并创建一个新的 markdown (.md) 文档，其中包含代码及其输出。然后，knitr 生成的 markdown 文件由 pandoc，https://pandoc.org 处理，它负责创建最终的文件。这个过程如 Figure 28.4 所示。这种两步工作流的优点是，你可以创建非常广泛的输出格式，你将在 Chapter 29 中了解到这一点。\n\n\n\n\n\n\n\nFigure 28.4: Quarto 工作流图，从 qmd，到 knitr，到 md，到 pandoc， 最后输出为 PDF、MS Word 或 HTML 格式。\n\n\n\n\n要开始使用你自己的 .qmd 文件，请在菜单栏中选择 File &gt; New File &gt; Quarto Document…。RStudio 将启动一个向导，你可以用它来预填充你的文件，其中包含有用的内容，提醒你 Quarto 的关键功能是如何工作的。\n接下来的部分将更详细地探讨 Quarto 文档的三个组成部分：markdown 文本、代码块和 YAML 标头。\n\n28.2.1 练习\n\n使用 File &gt; New File &gt; Quarto Document 创建一个新的 Quarto 文档。阅读说明。练习单独运行代码块。然后通过点击相应的按钮和使用相应的键盘快捷键来渲染文档。验证你可以修改代码，重新运行它，并看到修改后的输出。\n为三种内置格式中的每一种创建一个新的 Quarto 文档：HTML、PDF 和 Word。渲染这三个文档。输出有何不同？输入有何不同？（你可能需要安装 LaTeX 才能构建 PDF 输出——如果需要，RStudio 会提示你。）",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#可视化编辑器",
    "href": "quarto.html#可视化编辑器",
    "title": "28  Quarto",
    "section": "\n28.3 可视化编辑器",
    "text": "28.3 可视化编辑器\nRStudio 中的可视化编辑器为创作 Quarto 文档提供了一个 WYSIWYM (所见即所想，What You See Is What You Mean) 界面。在底层，Quarto 文档（.qmd 文件）中的文字是使用 Markdown 编写的，这是一种用于格式化纯文本文件的轻量级约定。事实上，Quarto 使用的是 Pandoc markdown（Quarto 能理解的一种轻微扩展的 Markdown 版本），包括表格、引文、交叉引用、脚注、divs/spans、定义列表、属性、原始 HTML/TeX 等，并且支持执行代码单元格和内联查看其输出。虽然 Markdown 被设计得易于读写，正如你将在 Section 28.4 中看到的那样，它仍然需要学习新的语法。因此，如果你是计算文档（如 .qmd 文件）的新手，但有使用 Google Docs 或 MS Word 等工具的经验，那么在 RStudio 中开始使用 Quarto 的最简单方法就是使用可视化编辑器。\n在可视化编辑器中，你可以使用菜单栏上的按钮插入图像、表格、交叉引用等，也可以使用通用的 &lt;kbd&gt;⌘&lt;/kbd&gt; + &lt;kbd&gt;/&lt;/kbd&gt; 或 &lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;/&lt;/kbd&gt; 快捷键插入几乎任何东西。如果你在一行的开头（如 Figure 28.5 所示），你也可以只输入 &lt;kbd&gt;/&lt;/kbd&gt; 来调用该快捷键。\n\n\n\n\n\n\n\nFigure 28.5: Quarto 可视化编辑器。\n\n\n\n\n可视化编辑器也方便了插入图像和自定义其显示方式。你可以直接将剪贴板中的图像粘贴到可视化编辑器中（RStudio 会将该图像的副本放置在项目目录中并链接到它），也可以使用可视化编辑器的“Insert &gt; Figure / Image”菜单浏览到要插入的图像或粘贴其 URL。此外，使用同一菜单，你可以调整图像大小，并添加标题、替代文本和链接。\n可视化编辑器还有许多我们在此未列举的功能，随着你创作经验的增加，你可能会发现它们很有用。\n最重要的是，虽然可视化编辑器以格式化的方式显示你的内容，但在底层，它以纯 Markdown 的形式保存你的内容，你可以在可视化编辑器和源代码编辑器之间来回切换，使用任一工具查看和编辑你的内容。\n\n28.3.1 练习\n\n使用可视化编辑器重新创建 Figure 28.5 中的文档。\n使用可视化编辑器，通过“Insert”菜单和“插入任何内容”工具插入一个代码块。\n使用可视化编辑器，找出如何：\n\n添加脚注。\n添加水平线。\n添加块引用。\n\n\n在可视化编辑器中，进入“Insert &gt; Citation”，并使用其 DOI (数字对象标识符) 10.21105/joss.01686 插入一篇题为 Welcome to the Tidyverse 的论文的引文。渲染文档并观察引文在文档中的显示方式。你观察到文档的 YAML 有什么变化？",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-source-editor",
    "href": "quarto.html#sec-source-editor",
    "title": "28  Quarto",
    "section": "\n28.4 源代码编辑器",
    "text": "28.4 源代码编辑器\n你也可以在没有可视化编辑器辅助的情况下，使用 RStudio 中的源代码编辑器来编辑 Quarto 文档。虽然可视化编辑器对于有使用 Google Docs 等工具写作经验的人来说会感到熟悉，但源代码编辑器对于有编写 R 脚本或 R Markdown 文档经验的人来说会感到熟悉。源代码编辑器对于调试任何 Quarto 语法错误也很有用，因为在纯文本中更容易发现这些错误。\n以下指南展示了如何在源代码编辑器中使用 Pandoc 的 Markdown 来创作 Quarto 文档。\n\n## Text formatting\n\n*italic* **bold** ~~strikeout~~ `code`\n\nsuperscript^2^ subscript~2~\n\n[underline]{.underline} [small caps]{.smallcaps}\n\n## Headings\n\n# 1st Level Header\n\n## 2nd Level Header\n\n### 3rd Level Header\n\n## Lists\n\n-   Bulleted list item 1\n\n-   Item 2\n\n    -   Item 2a\n\n    -   Item 2b\n\n1.  Numbered list item 1\n\n2.  Item 2.\n    The numbers are incremented automatically in the output.\n\n## Links and images\n\n&lt;http://example.com&gt;\n\n[linked phrase](http://example.com)\n\n![optional caption text](quarto.png){fig-alt=\"Quarto logo and the word quarto spelled in small case letters\"}\n\n## Tables\n\n| First Header | Second Header |\n|--------------|---------------|\n| Content Cell | Content Cell  |\n| Content Cell | Content Cell  |\n\n学习这些语法的最好方法就是亲手尝试。这可能需要几天时间，但很快它们就会成为你的第二天性，你将不再需要刻意去想它们。如果你忘记了，可以通过 Help &gt; Markdown Quick Reference 打开一个方便的参考表。\n\n28.4.1 练习\n\n练习你所学的知识，创建一份简短的简历。标题应该是你的名字，并且你应该包含（至少）教育或工作经历的标题。每个部分都应该包含一个职位/学位的项目符号列表。用粗体突出显示年份。\n\n使用源代码编辑器和 Markdown 快速参考，找出如何：\n\n添加脚注。\n添加水平线。\n添加块引用。\n\n\n从 https://github.com/hadley/r4ds/tree/main/quarto 复制 diamond-sizes.qmd 的内容并粘贴到本地的 R Quarto 文档中。检查你是否可以运行它，然后在频率多边形图后添加文本，描述其最显著的特征。\n在 Google Doc 或 MS Word 中创建一个文档（或找到一个你以前创建的文档），其中包含一些内容，如标题、超链接、格式化文本等。复制此文档的内容并将其粘贴到可视化编辑器的 Quarto 文档中。然后，切换到源代码编辑器并检查源代码。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#代码块",
    "href": "quarto.html#代码块",
    "title": "28  Quarto",
    "section": "\n28.5 代码块",
    "text": "28.5 代码块\n要在 Quarto 文档中运行代码，你需要插入一个代码块。有三种方法可以做到这一点：\n\n键盘快捷键 Cmd + Option + I / Ctrl + Alt + I。\n编辑器工具栏中的“Insert”按钮图标。\n手动输入代码块分隔符 ```{r} 和 ```。\n\n我们建议你学习键盘快捷键。从长远来看，它会为你节省大量时间！\n你可以继续使用你现在（我们希望！）已经熟知并喜爱的键盘快捷键来运行代码：Cmd/Ctrl + Enter。然而，代码块有了一个新的键盘快捷键：Cmd/Ctrl + Shift + Enter，它会运行代码块中的所有代码。把代码块想象成一个函数。一个代码块应该是相对独立的，并专注于一个单一的任务。\n接下来的部分描述了代码块标头，它由 ```{r} 组成，后面可以跟一个可选的代码块标签和各种其他的代码块选项，每个选项都在新的一行，并以 #| 开头。\n\n28.5.1 代码块标签\n代码块可以有一个可选的标签，例如：\n\n```{r}\n#| label: simple-addition\n1 + 1\n```\n#&gt; [1] 2\n\n这有三个优点：\n\n你可以使用脚本编辑器左下角的下拉代码导航器更轻松地导航到特定的代码块：\n\n#| echo: false #| out-width: “30%” #| fig-alt: | #| RStudio IDE 的片段，仅显示下拉代码导航器， #| 其中显示了三个代码块。代码块 1 是 setup。代码块 2 是 cars， #| 它在一个名为 Quarto 的部分中。代码块 3 是 pressure， #| 它在一个名为“包含绘图”的部分中。 knitr::include_graphics(“screenshots/quarto-chunk-nav.png”) ```\n\n由代码块生成的图形将具有有意义的名称，这使得它们在其他地方更容易使用。更多相关内容见 Section 28.6。\n你可以建立缓存代码块的网络，以避免每次运行时都重新执行耗时的计算。更多相关内容见 Section 28.8。\n\n你的代码块标签应该简短但具有描述性，并且不应包含空格。我们建议使用破折号 (-) 来分隔单词（而不是下划线 _），并避免在代码块标签中使用其他特殊字符。\n你通常可以自由地为你的代码块命名，但有一个代码块名称具有特殊行为：setup。当你在笔记模式下时，名为 setup 的代码块将在运行任何其他代码之前自动运行一次。\n此外，代码块标签不能重复。每个代码块标签必须是唯一的。\n\n28.5.2 代码块选项\n代码块的输出可以通过选项进行定制，这些选项是提供给代码块标头的字段。Knitr 提供了近 60 个选项，你可以用它们来定制你的代码块。在这里，我们将介绍你将频繁使用的最重要的代码块选项。你可以在 https://yihui.org/knitr/options 查看完整列表。\n最重要的一组选项控制你的代码块是否被执行，以及哪些结果会插入到最终的报告中：\n\neval: false 阻止代码被执行。（显然，如果代码不运行，就不会生成任何结果）。这对于显示示例代码，或者在不注释掉每一行的情况下禁用一大块代码很有用。\ninclude: false 运行代码，但不在最终文档中显示代码或结果。可用于你不想让报告变得杂乱的设置代码。\necho: false 阻止代码（而不是结果）出现在最终文件中。当编写面向不希望看到底层 R 代码的人的报告时，请使用此选项。\nmessage: false 或 warning: false 阻止消息或警告出现在最终文件中。\nresults: hide 隐藏打印输出；fig-show: hide 隐藏绘图。\nerror: true 即使代码返回错误，也会让渲染继续进行。这很少是你想要包含在报告最终版本中的东西，但如果你需要精确调试 .qmd 文件内部发生了什么，它可能非常有用。如果你正在教 R 并且想故意包含一个错误，它也很有用。默认值 error: false 会在文档中出现单个错误时导致渲染失败。\n\n这些代码块选项中的每一个都被添加到代码块的标头中，跟在 #| 之后。例如，在下面的代码块中，结果不会被打印，因为 eval 被设置为 false。\n\n```{r}\n#| label: simple-multiplication\n#| eval: false\n2 * 2\n```\n\n下表总结了每个选项抑制了哪些类型的输出：\n\n\n选项\n运行代码\n显示代码\n输出\n绘图\n消息\n警告\n\n\n\neval: false\nX\n\nX\nX\nX\nX\n\n\ninclude: false\n\nX\nX\nX\nX\nX\n\n\necho: false\n\nX\n\n\n\n\n\n\nresults: hide\n\n\nX\n\n\n\n\n\nfig-show: hide\n\n\n\nX\n\n\n\n\nmessage: false\n\n\n\n\nX\n\n\n\nwarning: false\n\n\n\n\n\nX\n\n\n\n28.5.3 全局选项\n随着你更多地使用 knitr，你会发现一些默认的代码块选项不符合你的需求，你想要更改它们。\n你可以在文档的 YAML 中，在 execute 下添加你偏好的选项来做到这一点。例如，如果你正在为一群不需要看到你的代码，只需要你的结果和叙述的观众准备报告，你可以在文档级别设置 echo: false。这将默认隐藏代码，因此只显示你特意选择显示的代码块（使用 echo: true）。你可能会考虑设置 message: false 和 warning: false，但这会使调试问题变得更加困难，因为你在最终文档中看不到任何消息。\ntitle: \"我的报告\"\nexecute:\n  echo: false\n由于 Quarto 被设计为多语言的（可与 R 以及 Python、Julia 等其他语言一起工作），所以并非所有的 knitr 选项都在文档执行级别可用，因为其中一些只适用于 knitr，而不适用于 Quarto 用于在其他语言中运行代码的其他引擎（例如 Jupyter）。然而，你仍然可以在 knitr 字段下的 opts_chunk 中将它们设置为文档的全局选项。例如，在编写书籍和教程时，我们设置：\ntitle: \"教程\"\nknitr:\n  opts_chunk:\n    comment: \"#&gt;\"\n    collapse: true\n这使用了我们偏好的注释格式，并确保代码和输出紧密地结合在一起。\n\n28.5.4 内联代码\n还有另一种将 R 代码嵌入到 Quarto 文档中的方法：直接嵌入文本中，使用：`r `。如果你在文本中提到数据的属性，这会非常有用。例如，本章开头使用的示例文档中有：\n\n我们有关于 `r nrow(diamonds)` 颗钻石的数据。 只有 `r nrow(diamonds) - nrow(smaller)` 颗钻石大于 2.5 克拉。 剩余部分的分布如下所示：\n\n当报告被渲染时，这些计算的结果会被插入到文本中：\n\n我们有关于 53940 颗钻石的数据。 只有 126 颗钻石大于 2.5 克拉。 剩余部分的分布如下所示：\n\n在文本中插入数字时，format() 是你的好帮手。它允许你设置 digits 的数量，这样你就不会打印出精度高到离谱的数字，还可以设置 big.mark 使数字更容易阅读。你可能会将这些组合成一个辅助函数：\n\ncomma &lt;- function(x) format(x, digits = 2, big.mark = \",\")\ncomma(3452345)\n#&gt; [1] \"3,452,345\"\ncomma(.12358124331)\n#&gt; [1] \"0.12\"\n\n\n28.5.5 练习\n\n添加一个部分，探讨钻石大小如何随切工、颜色和净度而变化。假设你正在为不懂 R 的人写报告，并且不要在每个代码块上设置 echo: false，而是设置一个全局选项。\n从 https://github.com/hadley/r4ds/tree/main/quarto 下载 diamond-sizes.qmd。添加一个描述最大的 20 颗钻石的部分，包括一个显示它们最重要属性的表格。\n修改 diamonds-sizes.qmd 以使用 label_comma() 来生成格式精美的输出。同时，也包括大于 2.5 克拉的钻石的百分比。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-figures",
    "href": "quarto.html#sec-figures",
    "title": "28  Quarto",
    "section": "\n28.6 图形",
    "text": "28.6 图形\nQuarto 文档中的图形可以是被嵌入的（例如，一个 PNG 或 JPEG 文件），也可以是代码块运行的结果。\n要嵌入一个外部文件中的图像，你可以在 RStudio 的可视化编辑器中使用“Insert”菜单，然后选择“Figure / Image”。这将弹出一个菜单，你可以在其中浏览到你想要插入的图像，并为其添加替代文本或标题，以及调整其大小。在可视化编辑器中，你也可以简单地将剪贴板中的图像粘贴到你的文档中，RStudio 会将该图像的副本放置在你的项目文件夹中。\n如果你包含一个生成图形的代码块（例如，包含一个 ggplot() 调用），生成的图形将自动包含在你的 Quarto 文档中。\n\n28.6.1 图形尺寸\n在 Quarto 中，图形最大的挑战是让你的图形获得正确的尺寸和形状。有五个主要的选项控制图形尺寸：fig-width、fig-height、fig-asp、out-width 和 out-height。图像尺寸之所以具有挑战性，是因为有两个尺寸（R 创建的图形的尺寸和它在输出文档中插入的尺寸），并且有多种指定尺寸的方式（即高度、宽度和纵横比：三选二）。\n我们推荐使用这五个选项中的三个：\n\n如果图形具有一致的宽度，它们往往在美学上更令人愉悦。为了实现这一点，请在默认设置中设置 fig-width: 6（6英寸）和 fig-asp: 0.618（黄金比例）。然后在单个代码块中，只调整 fig-asp。\n\n使用 out-width 控制输出尺寸，并将其设置为输出文档正文宽度的百分比。我们建议 out-width: \"70%\" 和 fig-align: center。\n这给绘图留出了呼吸的空间，而不会占用太多空间。\n\n要将多个绘图放在一行中，请为两个绘图设置 layout-ncol 为 2，为三个绘图设置 layout-ncol 为 3，依此类推。如果 layout-ncol 是 2，这实际上会将每个绘图的 out-width 设置为 “50%”；如果 layout-ncol 是 3，则为 “33%”，依此类推。根据你试图说明的内容（例如，显示数据或显示绘图变体），你可能还需要调整 fig-width，如下所述。\n\n如果你发现你需要眯着眼睛才能看清绘图中的文字，你需要调整 fig-width。如果 fig-width 大于图形在最终文档中渲染的尺寸，文字就会太小；如果 fig-width 小于最终尺寸，文字就会太大。你通常需要做一些实验来找出 fig-width 和文档中最终宽度之间的正确比例。为了说明这个原理，下面三个绘图的 fig-width 分别是 4、6 和 8：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n如果你想确保所有图形的字体大小都一致，那么每当你设置 out-width 时，你都需要调整 fig-width 以保持与你的默认 out-width 相同的比例。例如，如果你的默认 fig-width 是 6，out-width 是 “70%”，那么当你设置 out-width: \"50%\" 时，你需要将 fig-width 设置为 4.3 (6 * 0.5 / 0.7)。\n图形尺寸和缩放是一门艺术和科学，要做到恰到好处可能需要一个迭代的试错过程。你可以在 这篇关于控制绘图缩放的博客文章 中了解更多关于图形尺寸的信息。\n\n28.6.2 其他重要选项\n当像本书这样将代码和文本混合在一起时，你可以设置 fig-show: hold，这样绘图就会在代码之后显示。这有一个令人愉悦的副作用，即迫使你用解释来打断大段的代码。\n要为绘图添加标题，请使用 fig-cap。在 Quarto 中，这会将图形从内联变为“浮动”。\n如果你正在生成 PDF 输出，默认的图形类型是 PDF。这是一个很好的默认设置，因为 PDF 是高质量的矢量图形。但是，如果你要显示数千个点，它们可能会产生非常大且速度慢的绘图。在这种情况下，设置 fig-format: \"png\" 来强制使用 PNG。它们的质量稍低，但会紧凑得多。\n给生成图形的代码块命名是一个好主意，即使你不常给其他代码块加标签。代码块标签用于生成磁盘上图形的文件名，所以给你的代码块命名可以让你更容易地挑选出绘图并在其他情况下重用（例如，如果你想快速地将单个绘图放入一封电子邮件中）。\n\n28.6.3 练习\n\n在可视化编辑器中打开 diamond-sizes.qmd，找到一张钻石的图片，复制它，然后粘贴到文档中。双击图片并添加一个标题。调整图片大小并渲染你的文档。观察图片是如何保存在你当前的工作目录中的。\n编辑 diamond-sizes.qmd 中生成绘图的代码块的标签，使其以前缀 fig- 开头，并使用代码块选项 fig-cap 为图形添加一个标题。然后，编辑代码块上方的文本，使用“Insert &gt; Cross Reference”添加对该图形的交叉引用。\n使用以下代码块选项更改图形的大小，一次一个，渲染你的文档，并描述图形是如何变化的。\n\nfig-width: 10\nfig-height: 3\nout-width: \"100%\"\nout-width: \"20%\"",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#表格",
    "href": "quarto.html#表格",
    "title": "28  Quarto",
    "section": "\n28.7 表格",
    "text": "28.7 表格\n与图形类似，你可以在 Quarto 文档中包含两种类型的表格。它们可以是你直接在 Quarto 文档中创建的 markdown 表格（使用“Insert Table”菜单），也可以是代码块运行结果生成的表格。在本节中，我们将重点关注后者，即通过计算生成的表格。\n默认情况下，Quarto 会像你在控制台中看到的那样打印数据框和矩阵：\n\nmtcars[1:5, ]\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n如果你希望数据以附加格式显示，可以使用 knitr::kable() 函数。下面的代码生成了 Table 28.1。\n\nknitr::kable(mtcars[1:5, ], )\n\n\nTable 28.1: 一个 knitr kable 表格。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\n\n\n阅读 ?knitr::kable 的文档，了解你可以用来自定义表格的其他方法。如果需要更深度的定制，可以考虑 gt、huxtable、reactable、kableExtra、xtable、stargazer、pander、tables 和 ascii 这些包。它们各自提供了一套从 R 代码返回格式化表格的工具。\n\n28.7.1 练习\n\n在可视化编辑器中打开 diamond-sizes.qmd，插入一个代码块，并使用 knitr::kable() 添加一个表格，显示 diamonds 数据框的前 5 行。\n改用 gt::gt() 显示同一个表格。\n添加一个以前缀 tbl- 开头的代码块标签，并使用代码块选项 tbl-cap 为表格添加一个标题。然后，编辑代码块上方的文本，使用“Insert &gt; Cross Reference”添加对该表格的交叉引用。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-caching",
    "href": "quarto.html#sec-caching",
    "title": "28  Quarto",
    "section": "\n28.8 缓存",
    "text": "28.8 缓存\n通常情况下，每次渲染文档都是从一个完全干净的环境开始的。这对于可复现性来说非常好，因为它确保了你已经用代码捕捉到了每一个重要的计算。然而，如果你有一些计算需要很长时间，这可能会很痛苦。解决方案是 cache: true。\n你可以在文档级别启用 Knitr 缓存，以缓存文档中所有计算的结果，使用标准的 YAML 选项：\n---\ntitle: \"我的文档\"\nexecute: \n  cache: true\n---\n你也可以在代码块级别启用缓存，以缓存特定代码块中计算的结果：\n\n```{r}\n#| cache: true\n# 耗时计算的代码...\n```\n\n设置后，这会将代码块的输出保存到磁盘上一个特殊命名的文件中。在后续运行中，knitr 会检查代码是否已更改，如果未更改，它将重用缓存的结果。\n缓存系统必须谨慎使用，因为默认情况下它只基于代码本身，而不是其依赖项。例如，在这里 processed_data 代码块依赖于 raw-data 代码块：\n```{r}\n#| label: raw-data\n#| cache: true\nrawdata &lt;- readr::read_csv(\"一个_非常_大的_文件.csv\")\n```\n```{r}\n#| label: processed_data\n#| cache: true\nprocessed_data &lt;- rawdata |&gt;\n  filter(!is.na(import_var)) |&gt;\n  mutate(new_variable = complicated_transformation(x, y, z))\n```\n缓存 processed_data 代码块意味着如果 dplyr 管道被更改，它将被重新运行，但如果 read_csv() 调用发生更改，它将不会被重新运行。你可以使用 dependson 代码块选项来避免这个问题：\n```{r}\n#| label: processed-data\n#| cache: true\n#| dependson: \"raw-data\"\nprocessed_data &lt;- rawdata |&gt;\n  filter(!is.na(import_var)) |&gt;\n  mutate(new_variable = complicated_transformation(x, y, z))\n```\ndependson 应该包含一个字符向量，其中包含被缓存的代码块所依赖的每一个代码块。每当 knitr 检测到其依赖项之一发生更改时，它就会更新被缓存代码块的结果。\n请注意，如果 a_very_large_file.csv 发生更改，代码块将不会更新，因为 knitr 缓存只跟踪 .qmd 文件内部的更改。如果你还想跟踪该文件的更改，可以使用 cache.extra 选项。这是一个任意的 R 表达式，当它发生更改时将使缓存失效。一个好用的函数是 file.mtime()：它返回文件的最后修改时间。然后你可以这样写：\n```{r}\n#| label: raw-data\n#| cache: true\n#| cache.extra: !expr file.mtime(\"a_very_large_file.csv\")\nrawdata &lt;- readr::read_csv(\"a_very_large_file.csv\")\n```\n我们采纳了 David Robinson 的建议来命名这些代码块：每个代码块都以它创建的主要对象命名。这使得理解 dependson 规范变得更容易。\n随着你的缓存策略变得越来越复杂，定期使用 knitr::clean_cache() 清除所有缓存是一个好主意。\n\n28.8.1 练习\n\n建立一个代码块网络，其中 d 依赖于 c 和 b，而 b 和 c 都依赖于 a。让每个代码块打印 lubridate::now()，设置 cache: true，然后验证你对缓存的理解。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#故障排除",
    "href": "quarto.html#故障排除",
    "title": "28  Quarto",
    "section": "\n28.9 故障排除",
    "text": "28.9 故障排除\n对 Quarto 文档进行故障排除可能具有挑战性，因为你不再处于交互式的 R 环境中，你需要学习一些新技巧。此外，错误可能是由于 Quarto 文档本身的问题，也可能是由于 Quarto 文档中的 R 代码问题。\n在带有代码块的文档中，一个常见的错误是重复的代码块标签，如果你的工作流程涉及复制和粘贴代码块，这种情况尤其普遍。要解决此问题，你只需更改其中一个重复的标签即可。\n如果错误是由于文档中的 R 代码引起的，你应该首先尝试在交互式会话中重现问题。重启 R，然后“Run all chunks”（运行所有代码块），可以从“Code”菜单下的“Run region”中选择，也可以使用键盘快捷键 Ctrl + Alt + R。如果幸运的话，这会重现问题，你就可以在交互式环境中找出问题所在。\n如果这没有帮助，那么你的交互式环境和 Quarto 环境之间一定存在某些差异。你将需要系统地探索这些选项。最常见的差异是工作目录：Quarto 的工作目录是它所在的目录。通过在代码块中包含 getwd() 来检查工作目录是否如你所料。\n接下来，集思广益，想出所有可能导致该错误的因素。你需要系统地检查它们在你的 R 会话和你的 Quarto 会话中是否相同。最简单的方法是在导致问题的代码块上设置 error: true，然后使用 print() 和 str() 来检查设置是否如你所料。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#yaml-标头",
    "href": "quarto.html#yaml-标头",
    "title": "28  Quarto",
    "section": "\n28.10 YAML 标头",
    "text": "28.10 YAML 标头\n你可以通过调整 YAML 标头的参数来控制许多其他“整个文档”的设置。你可能想知道 YAML 代表什么：它是 “YAML Ain’t Markup Language”（YAML 不是一种标记语言），旨在以一种易于人类读写的方式表示分层数据。Quarto 用它来控制输出的许多细节。在这里，我们将讨论三个方面：自包含文档、文档参数和参考文献。\n\n28.10.1 自包含\nHTML 文档通常有许多外部依赖项（例如，图像、CSS 样式表、JavaScript 等），默认情况下，Quarto 会将这些依赖项放在与你的 .qmd 文件同目录下的一个 _files 文件夹中。如果你将 HTML 文件发布到托管平台（例如，QuartoPub，https://quartopub.com/），这个目录中的依赖项会与你的文档一起发布，因此在已发布的报告中可用。但是，如果你想通过电子邮件将报告发送给同事，你可能更喜欢一个单一的、自包含的 HTML 文档，它嵌入了所有的依赖项。你可以通过指定 embed-resources 选项来做到这一点：\nformat:\n  html:\n    embed-resources: true\n生成的文件将是自包含的，因此它不需要任何外部文件，也不需要互联网访问即可由浏览器正确显示。\n\n28.10.2 参数\nQuarto 文档可以包含一个或多个参数，其值可以在你渲染报告时设置。当你希望用不同的关键输入值重新渲染同一份报告时，参数非常有用。例如，你可能需要按分公司生成销售报告、按学生生成考试成绩，或者按国家生成人口统计摘要。要声明一个或多个参数，请使用 params 字段。\n这个例子使用一个 my_class 参数来决定显示哪一类汽车：\n\n---\nformat: html\nparams:\n  my_class: \"suv\"\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nclass &lt;- mpg |&gt; filter(class == params$my_class)\n```\n\n# Fuel economy for `r params$my_class`s\n\n```{r}\n#| message: false\n\nggplot(class, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n```\n\n如你所见，参数在代码块中作为一个名为 params 的只读列表可用。\n你可以将原子向量直接写入 YAML 标头。你也可以通过在参数值前加上 !expr 来运行任意 R 表达式。这是指定日期/时间参数的好方法。\nparams:\n  start: !expr lubridate::ymd(\"2015-01-01\")\n  snapshot: !expr lubridate::ymd_hms(\"2015-01-01 12:30:00\")\n\n28.10.3 参考文献和引文\nQuarto 可以自动生成多种样式的引文和参考文献。在 Quarto 文档中添加引文和参考文献最直接的方法是使用 RStudio 中的可视化编辑器。\n要使用可视化编辑器添加引文，请转到“Insert &gt; Citation”。可以从多种来源插入引文：\n\nDOI (文档对象标识符) 引用。\nZotero 个人或小组文献库。\n搜索 Crossref、DataCite 或 PubMed。\n你的文档参考文献（文档目录中的一个 .bib 文件）。\n\n在底层，可视化模式使用标准的 Pandoc markdown 表示法来表示引文（例如，[@citation]）。\n如果你使用前三种方法之一添加引文，可视化编辑器将自动为你创建一个 bibliography.bib 文件，并将参考文献添加到其中。它还会在文档的 YAML 中添加一个 bibliography 字段。随着你添加更多的参考文献，这个文件将被它们的引文填充。你也可以直接使用许多常见的参考文献格式编辑此文件，包括 BibLaTeX、BibTeX、EndNote、Medline。\n要在源代码编辑器中的 .qmd 文件内创建引文，请使用由 ‘@’ + 参考文献文件中的引文标识符组成的键。然后将引文放在方括号内。以下是一些示例：\n用分号分隔多个引文：Blah blah [@smith04; @doe99]。\n\n你可以在方括号内添加任意注释：\nBlah blah [参见 @doe99, pp. 33-35; 以及 @smith04, ch. 1]。\n\n去掉方括号以创建文内引文：@smith04 \n说 blah，或者 @smith04 [p. 33] 说 blah。\n\n在引文前添加一个 `-` 来抑制作者的名字：\nSmith 说 blah [-@smith04]。\n当 Quarto 渲染你的文件时，它将在你的文档末尾构建并附加一个参考文献列表。该参考文献列表将包含你的参考文献文件中的每一个被引用的参考文献，但它不会包含一个章节标题。因此，通常的做法是在你的文件末尾为参考文献添加一个章节标题，例如 # 参考文献 或 # Bibliography。\n你可以通过在 csl 字段中引用一个 CSL (citation style language) 文件来更改你的引文和参考文献的样式：\nbibliography: rmarkdown.bib\ncsl: apa.csl\n与 bibliography 字段一样，你的 csl 文件应包含文件的路径。这里我们假设 csl 文件与 .qmd 文件在同一个目录中。一个寻找常见参考文献样式 CSL 文件的好地方是 https://github.com/citation-style-language/styles。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#工作流",
    "href": "quarto.html#工作流",
    "title": "28  Quarto",
    "section": "\n28.11 工作流",
    "text": "28.11 工作流\n早些时候，我们讨论了捕获 R 代码的基本工作流，即你在控制台中交互式地工作，然后在脚本编辑器中捕获有效的内容。Quarto 将控制台和脚本编辑器结合在一起，模糊了交互式探索和长期代码捕获之间的界限。你可以在一个代码块内快速迭代，用 Cmd/Ctrl + Shift + Enter 编辑和重新执行。当你满意时，你就可以继续前进，开始一个新的代码块。\nQuarto 之所以重要，还因为它将文字和代码如此紧密地集成在一起。这使它成为一个很棒的分析笔记，因为它让你能够开发代码并记录你的想法。分析笔记与物理科学中的经典实验笔记有许多相同的目标。它：\n\n记录你做了什么以及为什么这么做。无论你的记忆力有多好，如果你不记录你所做的事情，总有一天你会忘记重要的细节。把它们写下来，这样你就不会忘记！\n支持严谨的思考。如果你边做边记录你的想法，并持续反思它们，你更有可能得出一个强有力的分析。当最终你写下你的分析与他人分享时，这也为你节省了时间。\n帮助他人理解你的工作。独自进行数据分析的情况很少，你通常会作为一个团队的一部分工作。实验笔记可以帮助你不仅分享你做了什么，还分享你为什么这么做给你的同事或实验室伙伴。\n\n许多关于有效使用实验笔记的好建议也可以转化为分析笔记。我们借鉴了自己的经验和 Colin Purrington 关于实验笔记的建议 (https://colinpurrington.com/tips/lab-notebooks)，总结出以下几点提示：\n\n确保每个笔记都有一个描述性的标题，一个引人入胜的文件名，以及一个简要描述分析目标的第一段。\n\n使用 YAML 标头的日期字段来记录你开始写笔记的日期：\ndate: 2016-08-23\n使用 ISO8601 YYYY-MM-DD 格式，这样就不会有歧义。即使你通常不这样写日期，也要使用它！\n\n如果你在一个分析想法上花费了大量时间，结果却发现是个死胡同，不要删除它！写一个简短的说明，说明它为什么失败，并把它留在笔记里。这会帮助你在将来回到这个分析时避免重蹈覆辙。\n一般来说，你最好在 R 之外进行数据录入。但如果你确实需要记录一小段数据，请使用 tibble::tribble() 清晰地把它列出来。\n如果你在一个数据文件中发现错误，永远不要直接修改它，而是编写代码来纠正这个值。并解释你为什么要做这个修正。\n在一天结束之前，确保你能渲染这个笔记。如果你在使用缓存，确保清除缓存。这将让你在代码还记忆犹新的时候修复任何问题。\n如果你希望你的代码长期可复现（即你可以在下个月或明年回来运行它），你需要跟踪你的代码使用的包的版本。一个严谨的方法是使用 renv，https://rstudio.github.io/renv/index.html，它将包存储在你的项目目录中。一个快速而粗略的技巧是包含一个运行 sessionInfo() 的代码块——这不能让你轻松地重现你今天的包，但至少你会知道它们曾经是什么样的。\n在你的职业生涯中，你将会创建非常非常多的分析笔记。你将如何组织它们，以便将来能再次找到它们？我们建议将它们存储在各自的项目中，并想出一个好的命名方案。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#总结",
    "href": "quarto.html#总结",
    "title": "28  Quarto",
    "section": "\n28.12 总结",
    "text": "28.12 总结\n在本章中，我们向你介绍了 Quarto，这是一个用于创作和发布可复现计算文档的工具，它将你的代码和文字说明整合在一处。你学习了如何在 RStudio 中使用可视化或源代码编辑器编写 Quarto 文档，代码块如何工作以及如何为它们自定义选项，如何在你的 Quarto 文档中包含图形和表格，以及为计算进行缓存的选项。此外，你还学习了如何调整 YAML 标头选项来创建自包含或参数化的文档，以及如何包含引文和参考文献。我们还为你提供了一些故障排除和工作流的技巧。\n虽然这个介绍应该足以让你开始使用 Quarto，但仍有许多东西需要学习。Quarto 还相对年轻，并且仍在快速发展。了解其创新的最佳去处是 Quarto 的官方网站：https://quarto.org。\n我们在这里没有涉及两个重要的主题：协作以及如何准确地将你的想法传达给其他人的细节。协作是现代数据科学的重要组成部分，通过使用像 Git 和 GitHub 这样的版本控制工具，你可以让你的生活轻松得多。我们推荐由 Jenny Bryan 编写的 “Happy Git with R”，这是一本面向 R 用户的 Git 和 GitHub 用户友好入门读物。该书可在线免费获取：https://happygitwithr.com。\n我们也没有谈及为了清晰地传达你的分析结果，你到底应该写些什么。为了提高你的写作水平，我们强烈推荐阅读 Joseph M. Williams & Joseph Bizup 的 Style: Lessons in Clarity and Grace 或 George Gopen 的 The Sense of Structure: Writing from the Reader’s Perspective。这两本书都将帮助你理解句子和段落的结构，并为你提供使你的写作更清晰的工具。（这些书如果买新的会相当昂贵，但许多英语课程都在使用它们，所以有很多便宜的二手书）。George Gopen 也在 https://www.georgegopen.com/litigation-articles.html 上发表了一些关于写作的短文。它们是针对律师的，但几乎所有内容也同样适用于数据科学家。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html",
    "href": "quarto-formats.html",
    "title": "29  Quarto 格式",
    "section": "",
    "text": "29.1 引言\n到目前为止，你已经了解了如何使用 Quarto 来生成 HTML 文档。 本章将简要概述你可以使用 Quarto 生成的许多其他类型的输出。\n有两种方法可以设置文档的输出格式：\n#| eval: false quarto::quarto_render(“diamond-sizes.qmd”, output_format = “docx”) ```\n```如果你想以编程方式生成多种类型的输出，这种方法非常有用，因为output_format` 参数也可以接受一个值列表。\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = c(\"docx\", \"pdf\"))",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#引言",
    "href": "quarto-formats.html#引言",
    "title": "29  Quarto 格式",
    "section": "",
    "text": "通过修改 YAML 标头来永久设置：\ntitle: \"Diamond sizes\"\nformat: html\n\n通过手动调用 quarto::quarto_render() 来临时设置：",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#输出选项",
    "href": "quarto-formats.html#输出选项",
    "title": "29  Quarto 格式",
    "section": "\n29.2 输出选项",
    "text": "29.2 输出选项\nQuarto 提供了多种输出格式。 你可以在 https://quarto.org/docs/output-formats/all-formats.html 找到完整的列表。 许多格式共享一些输出选项（例如，用于包含目录的 toc: true），但其他格式则具有特定于格式的选项（例如，code-fold: true 会将代码块折叠成 HTML 输出的 &lt;details&gt; 标签，以便用户可以按需显示它，但这不适用于 PDF 或 Word 文档）。\n要覆盖默认选项，你需要使用一个展开的 format 字段。 例如，如果你想渲染一个带有浮动目录的 html，你可以这样使用：\nformat:\n  html:\n    toc: true\n    toc_float: true\n你甚至可以通过提供一个格式列表来渲染到多种输出：\nformat:\n  html:\n    toc: true\n    toc_float: true\n  pdf: default\n  docx: default\n请注意，如果你不想覆盖任何默认选项，可以使用特殊语法 (pdf: default)。\n要渲染到文档 YAML 中指定的所有格式，你可以使用 output_format = \"all\"。\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"all\")",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#文档",
    "href": "quarto-formats.html#文档",
    "title": "29  Quarto 格式",
    "section": "\n29.3 文档",
    "text": "29.3 文档\n上一章重点介绍了默认的 html 输出。 这个主题有几种基本的变体，可以生成不同类型的文档。 例如：\n\npdf：使用 LaTeX（一个开源的文档排版系统）制作 PDF，你需要安装它。 如果你还没有安装，RStudio 会提示你。\ndocx：用于 Microsoft Word (.docx) 文档。\nodt：用于 OpenDocument 文本 (.odt) 文档。\nrtf：用于富文本格式 (.rtf) 文档。\ngfm：用于 GitHub 风格的 Markdown (.md) 文档。\nipynb：用于 Jupyter Notebooks (.ipynb)。\n\n请记住，在生成与决策者共享的文档时，你可以通过在文档 YAML 中设置全局选项来关闭代码的默认显示：\nexecute:\n  echo: false\n对于 html 文档，另一个选择是让代码块默认隐藏，但可以通过点击来显示：\nformat:\n  html:\n    code: true",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#演示文稿",
    "href": "quarto-formats.html#演示文稿",
    "title": "29  Quarto 格式",
    "section": "\n29.4 演示文稿",
    "text": "29.4 演示文稿\n你也可以使用 Quarto 来制作演示文稿。 与 Keynote 或 PowerPoint 等工具相比，你的视觉控制力较小，但将 R 代码的结果自动插入演示文稿可以节省大量时间。 演示文稿的工作原理是将内容分成幻灯片，每个二级 (##) 标题都会开始一张新的幻灯片。 此外，一级 (#) 标题表示一个新节的开始，带有一个节标题幻灯片，默认情况下，该幻灯片居中显示。\nQuarto 支持多种演示文稿格式，包括：\n\nrevealjs - 使用 reveal.js 制作的 HTML 演示文稿\npptx - PowerPoint 演示文稿\nbeamer - 使用 LaTeX Beamer 制作的 PDF 演示文稿。\n\n你可以在 https://quarto.org/docs/presentations 阅读更多关于使用 Quarto 创建演示文稿的信息。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#交互性",
    "href": "quarto-formats.html#交互性",
    "title": "29  Quarto 格式",
    "section": "\n29.5 交互性",
    "text": "29.5 交互性\n就像任何 HTML 文档一样，使用 Quarto 创建的 HTML 文档也可以包含交互式组件。 在这里，我们介绍两种在 Quarto 文档中包含交互性的选项：htmlwidgets 和 Shiny。\n\n29.5.1 htmlwidgets\nHTML 是一种交互式格式，你可以利用 htmlwidgets 来发挥这种交互性，htmlwidgets 是能够生成交互式 HTML 可视化的 R 函数。 例如，看看下面的 leaflet 地图。 如果你正在网页上查看此页面，你可以拖动地图、放大和缩小等。 你显然不能在书中这样做，所以 Quarto 会自动为你插入一个静态截图。\n\nlibrary(leaflet)\nleaflet() |&gt;\n    setView(174.764, -36.877, zoom = 16) |&gt;\n    addTiles() |&gt;\n    addMarkers(174.764, -36.877, popup = \"Maungawhau\")\n\n\n\n\n\nhtmlwidgets 的一大优点是你不需要了解任何关于 HTML 或 JavaScript 的知识就可以使用它们。 所有的细节都被封装在包里，所以你不用担心。\n有许多提供 htmlwidgets 的包，包括：\n\ndygraphs：用于交互式时间序列可视化。\nDT：用于交互式表格。\nthreejs：用于交互式 3D 图。\nDiagrammeR：用于图表（如流程图和简单的节点链接图）。\n\n要了解更多关于 htmlwidgets 的信息并查看提供它们的软件包的完整列表，请访问 https://www.htmlwidgets.org。\n\n29.5.2 Shiny\nhtmlwidgets 提供客户端 (client-side) 交互性——所有的交互性都发生在浏览器中，独立于 R。 一方面，这很好，因为你可以在没有任何与 R 的连接的情况下分发 HTML 文件。 然而，这从根本上限制了你只能做那些已经在 HTML 和 JavaScript 中实现的事情。 另一种方法是使用 shiny，这是一个允许你使用 R 代码而不是 JavaScript 来创建交互性的包。\n要从 Quarto 文档中调用 Shiny 代码，请将 server: shiny 添加到 YAML 标头：\ntitle: \"Shiny Web App\"\nformat: html\nserver: shiny\n然后，你可以使用“输入”函数向文档添加交互式组件：\n\nlibrary(shiny)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\n\n\n\n\n\n\n\n\n\n你还需要一个带有块选项 context: server 的代码块，其中包含需要在 Shiny 服务器中运行的代码。\n然后，你可以用 input$name 和 input$age 来引用这些值，使用它们的代码会在它们发生变化时自动重新运行。\n我们无法在这里向你展示一个实时的 Shiny 应用程序，因为 Shiny 的交互发生在服务端 (server-side)。 这意味着你可以在不了解 JavaScript 的情况下编写交互式应用程序，但你需要一个服务器来运行它们。 这就带来了一个后勤问题：Shiny 应用程序需要一个 Shiny 服务器才能在线运行。 当你在自己的计算机上运行 Shiny 应用程序时，Shiny 会自动为你设置一个 Shiny 服务器，但如果你想在线发布这种交互性，你需要一个面向公众的 Shiny 服务器。 这就是 Shiny 的根本权衡：你可以在 Shiny 文档中做任何你能在 R 中做的事情，但这需要有人在运行 R。\n要了解更多关于 Shiny 的信息，我们推荐阅读 Hadley Wickham 的《Mastering Shiny》，网址：https://mastering-shiny.org。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#网站和书籍",
    "href": "quarto-formats.html#网站和书籍",
    "title": "29  Quarto 格式",
    "section": "\n29.6 网站和书籍",
    "text": "29.6 网站和书籍\n通过一些额外的基础设置，你可以使用 Quarto 来生成一个完整的网站或书籍：\n\n将你的 .qmd 文件放在一个单独的目录中。index.qmd 将成为主页。\n\n添加一个名为 _quarto.yml 的 YAML 文件，该文件为网站提供导航。在此文件中，将 project 类型设置为 book 或 website，例如：\nproject:\n  type: book\n\n\n例如，下面的 _quarto.yml 文件从三个源文件创建一个网站：index.qmd（主页）、viridis-colors.qmd 和 terrain-colors.qmd。\n\nproject:\n  type: website\n\nwebsite:\n  title: \"A website on color scales\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: viridis-colors.qmd\n        text: Viridis colors\n      - href: terrain-colors.qmd\n        text: Terrain colors\n\n你需要的书籍的 _quarto.yml 文件结构非常相似。 下面的例子展示了如何创建一本包含四章的书，并将其渲染为三种不同的输出格式（html、pdf 和 epub）。同样，源文件是 .qmd 文件。\n\nproject:\n  type: book\n\nbook:\n  title: \"A book on color scales\"\n  author: \"Jane Coloriste\"\n  chapters:\n    - index.qmd\n    - intro.qmd\n    - viridis-colors.qmd\n    - terrain-colors.qmd\n\nformat:\n  html:\n    theme: cosmo\n  pdf: default\n  epub: default\n\n我们建议你为你的网站和书籍使用 RStudio 项目。 根据 _quarto.yml 文件，RStudio 会识别你正在处理的项目类型，并在 IDE 中添加一个“Build”选项卡，你可以用它来渲染和预览你的网站和书籍。 网站和书籍也都可以使用 quarto::quarto_render() 进行渲染。\n在 https://quarto.org/docs/websites 阅读更多关于 Quarto 网站的信息，在 https://quarto.org/docs/books 阅读更多关于书籍的信息。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#其他格式",
    "href": "quarto-formats.html#其他格式",
    "title": "29  Quarto 格式",
    "section": "\n29.7 其他格式",
    "text": "29.7 其他格式\nQuarto 还提供了更多的输出格式：\n\n你可以使用 Quarto 期刊模板撰写期刊文章：https://quarto.org/docs/journals/templates.html。\n你可以使用 format: ipynb 将 Quarto 文档输出为 Jupyter Notebooks：https://quarto.org/docs/reference/formats/ipynb.html。\n\n有关更多格式的列表，请参阅 https://quarto.org/docs/output-formats/all-formats.html。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#小结",
    "href": "quarto-formats.html#小结",
    "title": "29  Quarto 格式",
    "section": "\n29.8 小结",
    "text": "29.8 小结\n在本章中，我们向你展示了使用 Quarto 交流结果的多种选择，从静态和交互式文档到演示文稿，再到网站和书籍。\n要了解更多关于在这些不同格式中进行有效沟通的信息，我们推荐以下资源：\n\n要提高你的演示技巧，可以试试 Neal Ford、Matthew McCollough 和 Nathaniel Schutta 的 Presentation Patterns。它提供了一套行之有效的模式（包括低级和高级），你可以应用它们来改进你的演示文稿。\n如果你做学术演讲，你可能会喜欢 Leek group guide to giving talks。\n我们自己没有上过，但我们听过很多人对 Matt McGarrity 的公开演讲在线课程 https://www.coursera.org/learn/public-speaking 评价很高。\n如果你正在创建许多仪表板 (dashboards)，请务必阅读 Stephen Few 的 Information Dashboard Design: The Effective Visual Communication of Data。它将帮助你创建真正有用而不仅仅是好看的仪表板。\n有效地传达你的想法通常需要一些平面设计知识。Robin Williams 的 The Non-Designer’s Design Book 是一个很好的起点。",
    "crumbs": [
      "沟通",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 格式</span>"
    ]
  }
]