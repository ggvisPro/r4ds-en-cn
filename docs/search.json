[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R æ•°æ®ç§‘å­¦ 2e",
    "section": "",
    "text": "Welcome\nThis is the website for the 2nd edition of â€œR for Data Scienceâ€. This book will teach you how to do data science with R: Youâ€™ll learn how to get your data into R, get it into the most useful structure, transform it and visualize.\nè¿™æ˜¯ ã€ŠR æ•°æ®ç§‘å­¦ã€‹ ç¬¬äºŒç‰ˆçš„ç½‘ç«™ã€‚æœ¬ä¹¦å°†æ•™ä½ å¦‚ä½•ä½¿ç”¨ R è¿›è¡Œæ•°æ®ç§‘å­¦ï¼šä½ å°†å­¦ä¹ å¦‚ä½•å°†æ•°æ®å¯¼å…¥ Rã€å°†å…¶æ•´ç†æˆæœ€æœ‰ç”¨çš„ç»“æ„ï¼Œå¹¶å¯¹å…¶è¿›è¡Œè½¬æ¢ä¸å¯è§†åŒ–ã€‚\nIn this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, youâ€™ll learn how to clean data and draw plotsâ€”and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. Youâ€™ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. Youâ€™ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualizing, and exploring data.\nåœ¨æœ¬ä¹¦ä¸­ï¼Œä½ å°†è·å¾—ä¸€å¥—ç³»ç»Ÿçš„æ•°æ®ç§‘å­¦å®æˆ˜æŠ€èƒ½ã€‚å°±åƒåŒ–å­¦å®¶å­¦ä¹ å¦‚ä½•æ¸…æ´—è¯•ç®¡å’Œæ•´ç†å®éªŒå®¤ä¸€æ ·ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ¸…æ´—æ•°æ®ã€ç»˜åˆ¶å›¾å½¢ï¼Œä»¥åŠæ›´å¤šç›¸å…³æŠ€èƒ½ã€‚è¿™äº›æŠ€èƒ½è®©æ•°æ®ç§‘å­¦æˆä¸ºå¯èƒ½ï¼Œè€Œä½ å°†åœ¨æ­¤å¤„å­¦åˆ°ä½¿ç”¨ R å®Œæˆè¿™äº›ä»»åŠ¡çš„æœ€ä½³å®è·µã€‚ä½ å°†å­¦ä¼šä½¿ç”¨å›¾å½¢è¯­æ³•ï¼ˆgrammar of graphicsï¼‰ã€é‡Šä¹‰å¼ç¼–ç¨‹ï¼ˆliterate programmingï¼‰ä»¥åŠå¯é‡å¤æ€§ç ”ç©¶ï¼ˆreproducible researchï¼‰æ¥èŠ‚çœæ—¶é—´ã€‚ä½ è¿˜å°†å­¦ä¹ å¦‚ä½•ç®¡ç†è®¤çŸ¥èµ„æºï¼Œä»¥ä¾¿åœ¨æ•°æ®æ¸…æ´—ã€å¯è§†åŒ–å’Œæ¢ç´¢è¿‡ç¨‹ä¸­ä¿ƒè¿›å‘ç°ã€‚\nThis website is and will always be free, licensed under the CC BY-NC-ND 3.0 License. If youâ€™d like a physical copy of the book, you can order it on Amazon. If you appreciate reading the book for free and would like to give back, please make a donation to KÄkÄpÅ Recovery: the kÄkÄpÅ (which appears on the cover of R4DS) is a critically endangered parrot native to New Zealand; there are only 244 left.\næœ¬ç½‘ç«™ç°åœ¨å¹¶ä¸”æ°¸è¿œå‘æ‰€æœ‰äººå…è´¹å¼€æ”¾ï¼Œå†…å®¹éµå¾ª CC BYâ€‘NCâ€‘NDÂ 3.0 è®¸å¯è¯ã€‚å¦‚æœä½ å¸Œæœ›æ‹¥æœ‰çº¸è´¨ç‰ˆä¹¦ç±ï¼Œå¯ä»¥åœ¨ Amazon è®¢è´­ã€‚å¦‚æœä½ å–œæ¬¢å…è´¹é˜…è¯»æœ¬ä¹¦å¹¶å¸Œæœ›å›é¦ˆï¼Œè¯·å‘ KÄkÄpÅ Recovery ææ¬¾ï¼šå°é¢ä¸Šçš„ kÄkÄpÅ æ˜¯æ–°è¥¿å…°ç‰¹æœ‰çš„æå±é¹¦é¹‰ï¼Œç°å­˜ä»… 244 åªã€‚\nIf you speak another language, you might be interested in the freely available translations of the 1st edition:\nå¦‚æœä½ ä½¿ç”¨å…¶ä»–è¯­è¨€ï¼Œä¹Ÿè®¸ä¼šå¯¹ç¬¬ä¸€ç‰ˆçš„å…è´¹ç¿»è¯‘æ„Ÿå…´è¶£ï¼š\n\nSpanish è¥¿ç­ç‰™è¯­è¯‘æœ¬ï¼šhttp://es.r4ds.hadley.nz\nItalian æ„å¤§åˆ©è¯­è¯‘æœ¬ï¼šhttps://it.r4ds.hadley.nz\nTurkish åœŸè€³å…¶è¯­è¯‘æœ¬ï¼šhttps://tr.r4ds.hadley.nz\nPortuguese è‘¡è„ç‰™è¯­è¯‘æœ¬ï¼šhttps://pt.r4ds.hadley.nz\n\nYou can find suggested answers to exercises in the book at https://mine-cetinkaya-rundel.github.io/r4ds-solutions.\nä½ å¯ä»¥åœ¨ https://mine-cetinkaya-rundel.github.io/r4ds-solutions æ‰¾åˆ°æœ¬ä¹¦ç»ƒä¹ é¢˜çš„å‚è€ƒç­”æ¡ˆã€‚\nPlease note that R4DS uses a Contributor Code of Conduct. By contributing to this book, you agree to abide by its terms.\nè¯·æ³¨æ„ï¼ŒR4DS éµå¾ª è´¡çŒ®è€…è¡Œä¸ºå‡†åˆ™ã€‚å‚ä¸æœ¬ä¹¦è´¡çŒ®å³è¡¨ç¤ºä½ åŒæ„éµå®ˆå…¶æ¡æ¬¾ã€‚",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface-2e.html",
    "href": "preface-2e.html",
    "title": "Preface to the second edition",
    "section": "",
    "text": "Welcome to the second edition of â€œR for Data Scienceâ€!\næ¬¢è¿é˜…è¯» ã€ŠR for Data Scienceã€‹ ç¬¬äºŒç‰ˆï¼\nThis is a major reworking of the first edition, removing material we no longer think is useful, adding material we wish we included in the first edition, and generally updating the text and code to reflect changes in best practices.\nè¿™æ˜¯å¯¹ç¬¬ä¸€ç‰ˆçš„ä¸€æ¬¡é‡å¤§é‡æ„ï¼šå‰”é™¤äº†ä¸å†å®ç”¨çš„å†…å®¹ï¼Œè¡¥å……äº†å½“åˆæƒ³åŠ å…¥å´æœªèƒ½åŒ…å«çš„ææ–™ï¼Œå¹¶å…¨é¢æ›´æ–°äº†æ–‡æœ¬å’Œä»£ç ï¼Œä»¥åæ˜ æœ€æ–°çš„æœ€ä½³å®è·µã€‚\nWeâ€™re also very excited to welcome a new co-author: Mine Ã‡etinkaya-Rundel, a noted data-science educator and one of our colleagues at Posit (the company formerly known as RStudio).\næˆ‘ä»¬è¿˜éå¸¸é«˜å…´åœ°è¿æ¥æ–°åˆè‘—è€… â€”â€” è‘—åçš„æ•°æ®ç§‘å­¦æ•™è‚²è€…ã€Positï¼ˆå‰èº«ä¸º RStudioï¼‰åŒäº‹ Mine Ã‡etinkaya-Rundelã€‚\nA brief summary of the biggest changes follows:\nä»¥ä¸‹ç®€è¦æ¦‚è¿°æœ¬æ¬¡æœ€é‡è¦çš„æ”¹åŠ¨ï¼š\n\nThe first part of the book has been renamed to â€œWhole gameâ€.\nThe goal of this section is to give you the rough details of the â€œwhole gameâ€ of data science before we dive into the details.\nä¹¦çš„ç¬¬ä¸€éƒ¨åˆ†ç°å·²æ›´åä¸º Whole gameï¼ˆå®Œæ•´å…¨å±€ï¼‰ã€‚æœ¬èŠ‚æ—¨åœ¨è®©ä½ åœ¨æ·±å…¥ç»†èŠ‚ä¹‹å‰ï¼Œå…ˆå¯¹æ•°æ®ç§‘å­¦çš„ â€œå®Œæ•´æ¸¸æˆâ€ æœ‰ä¸€ä¸ªæ•´ä½“äº†è§£ã€‚\nThe second part of the book is â€œVisualizeâ€.\nThis part gives data-visualization tools and best practices a more thorough coverage compared to the first edition.\nThe best place to get all the details is still the ggplot2 book, but now R4DS covers more of the most important techniques.\nç¬¬äºŒéƒ¨åˆ†ä¸º Visualizeï¼ˆå¯è§†åŒ–ï¼‰ã€‚ç›¸æ¯”ç¬¬ä¸€ç‰ˆï¼Œæœ¬ç‰ˆæ›´ç³»ç»Ÿåœ°ä»‹ç»æ•°æ®å¯è§†åŒ–å·¥å…·ä¸æœ€ä½³å®è·µã€‚è¯¦ç»†ä¿¡æ¯ä»ä»¥ ã€Šggplot2ã€‹ ä¸€ä¹¦ä¸ºæœ€ä½³å‚è€ƒï¼Œä½† R4DS ç°å·²æ¶µç›–æ›´å¤šå…³é”®æ–¹æ³•ã€‚\nThe third part of the book is now called â€œTransformâ€ and gains new chapters on numbers, logical vectors, and missing values.\nThese were previously parts of the data-transformation chapter, but needed much more room to cover all the details.\nç¬¬ä¸‰éƒ¨åˆ†ç°ç§°ä¸º Transformï¼ˆè½¬æ¢ï¼‰ï¼Œå¹¶æ–°å¢äº†æ•°å­—ã€é€»è¾‘å‘é‡å’Œç¼ºå¤±å€¼ç­‰ç« èŠ‚ã€‚å®ƒä»¬åŸå…ˆåªæ˜¯æ•°æ®è½¬æ¢ç« èŠ‚ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œä½†å¦‚ä»Šéœ€è¦æ›´å¤šç¯‡å¹…æ·±å…¥ä»‹ç»ã€‚\nThe fourth part of the book is called â€œImportâ€.\nItâ€™s a new set of chapters that goes beyond reading flat text files to working with spreadsheets, getting data out of databases, working with big data, rectangling hierarchical data, and scraping data from web sites.\nç¬¬å››éƒ¨åˆ†ä¸º Importï¼ˆå¯¼å…¥ï¼‰ã€‚è¿™ä¸€æ–°ç¯‡ç« ä¸ä»…æ¶‰åŠè¯»å–çº¯æ–‡æœ¬æ–‡ä»¶ï¼Œè¿˜æ¶µç›–ç”µå­è¡¨æ ¼ã€æ•°æ®åº“æå–ã€å¤§æ•°æ®å¤„ç†ã€å±‚çº§æ•°æ®æ•´å½¢ï¼Œä»¥åŠç½‘é¡µæ•°æ®æŠ“å–ç­‰ä¸»é¢˜ã€‚\nThe â€œProgramâ€ part remains, but has been rewritten from top-to-bottom to focus on the most important parts of function writing and iteration.\nFunction writing now includes details on how to wrap tidyverse functions (dealing with the challenges of tidy evaluation), since this has become much easier and more important over the last few years.\nWeâ€™ve added a new chapter on important base R functions that youâ€™re likely to see in wild-caught R code.\nâ€œProgramâ€ éƒ¨åˆ†ä¿ç•™ï¼Œä½†å·²å½»åº•é‡å†™ï¼Œé‡ç‚¹èšç„¦å‡½æ•°ç¼–å†™ä¸è¿­ä»£çš„æ ¸å¿ƒè¦ç´ ã€‚ç°åœ¨çš„å‡½æ•°ç¼–å†™ç« èŠ‚è¯¦ç»†è®²è§£äº†å¦‚ä½•å°è£… tidyverse å‡½æ•°ï¼ˆåº”å¯¹ tidy evaluation çš„æŒ‘æˆ˜ï¼‰ï¼Œå› ä¸ºè¿‘å¹´æ¥è¿™é¡¹ä»»åŠ¡å˜å¾—æ›´ç®€å•ä¸”æ›´å…³é”®ã€‚æˆ‘ä»¬è¿˜æ–°å¢äº†è®²è§£å¸¸è§ base R å‡½æ•°çš„æ–°ç« èŠ‚ï¼Œä»¥å¸®åŠ©ä½ è¯»æ‡‚â€œé‡ç”Ÿâ€ R ä»£ç ã€‚\nThe modeling part has been removed.\nWe never had enough room to fully do modelling justice, and there are now much better resources available.\nWe generally recommend using the tidymodels packages and reading Tidy Modeling with R by Max Kuhn and Julia Silge.\næ¨¡å‹éƒ¨åˆ†å·²è¢«ç§»é™¤ã€‚ç”±äºç¯‡å¹…æ‰€é™ï¼Œæˆ‘ä»¬æ— æ³•å……åˆ†å±•ç¤ºå»ºæ¨¡çš„å…¨éƒ¨å†…å®¹ï¼Œè€Œå¦‚ä»Šå·²æœ‰æ›´ä¼˜ç§€çš„èµ„æºå¯ä¾›å­¦ä¹ ã€‚æˆ‘ä»¬æ¨èä½¿ç”¨ tidymodels å¥—ä»¶ï¼Œå¹¶é˜…è¯» Max Kuhn ä¸ Julia Silge åˆè‘—çš„ Tidy Modeling with Rã€‚\nThe â€œCommunicateâ€ part remains, but has been thoroughly updated to feature Quarto instead of R Markdown.\nThis edition of the book has been written in Quarto, and itâ€™s clearly the tool of the future.\nâ€œCommunicateâ€ éƒ¨åˆ†ä»åœ¨ï¼Œä½†å·²å…¨é¢æ›´æ–°ä¸º Quartoï¼Œæ›¿ä»£ R Markdownã€‚æœ¬ä¹¦ç¬¬äºŒç‰ˆå³ä½¿ç”¨ Quarto ç¼–å†™ï¼Œæ˜¾ç„¶å®ƒå°†æˆä¸ºæœªæ¥çš„é¦–é€‰å·¥å…·ã€‚",
    "crumbs": [
      "Preface to the second edition"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "What you will learn\nData science is an exciting discipline that allows you to transform raw data into understanding, insight, and knowledge. The goal of â€œR for Data Scienceâ€ is to help you learn the most important tools in R that will allow you to do data science efficiently and reproducibly, and to have some fun along the way ğŸ˜ƒ. After reading this book, youâ€™ll have the tools to tackle a wide variety of data science challenges using the best parts of R.\næ•°æ®ç§‘å­¦æ˜¯ä¸€é—¨æ¿€åŠ¨äººå¿ƒçš„å­¦ç§‘ï¼Œå®ƒèƒ½è®©ä½ å°†åŸå§‹æ•°æ®è½¬åŒ–ä¸ºç†è§£ã€æ´è§å’ŒçŸ¥è¯†ã€‚ ã€ŠR æ•°æ®ç§‘å­¦ã€‹çš„ç›®æ ‡æ˜¯å¸®åŠ©ä½ å­¦ä¹  R ä¸­æœ€é‡è¦çš„å·¥å…·ï¼Œè®©ä½ èƒ½å¤Ÿé«˜æ•ˆã€å¯å¤ç°åœ°è¿›è¡Œæ•°æ®ç§‘å­¦å·¥ä½œï¼Œå¹¶åœ¨æ­¤è¿‡ç¨‹ä¸­è·å¾—ä¸€äº›ä¹è¶£ ğŸ˜ƒã€‚ è¯»å®Œæœ¬ä¹¦åï¼Œä½ å°†æ‹¥æœ‰ä½¿ç”¨ R çš„ç²¾åéƒ¨åˆ†æ¥åº”å¯¹å„ç§æ•°æ®ç§‘å­¦æŒ‘æˆ˜çš„å·¥å…·ã€‚\nData science is a vast field, and thereâ€™s no way you can master it all by reading a single book. This book aims to give you a solid foundation in the most important tools and enough knowledge to find the resources to learn more when necessary. Our model of the steps of a typical data science project looks something like FigureÂ 1.\næ•°æ®ç§‘å­¦æ˜¯ä¸€ä¸ªå¹¿é˜”çš„é¢†åŸŸï¼Œä¸å¯èƒ½é€šè¿‡é˜…è¯»ä¸€æœ¬ä¹¦å°±æŒæ¡æ‰€æœ‰å†…å®¹ã€‚ æœ¬ä¹¦æ—¨åœ¨ä¸ºä½ æ‰“ä¸‹æœ€é‡è¦çš„å·¥å…·çš„åšå®åŸºç¡€ï¼Œå¹¶æä¾›è¶³å¤Ÿçš„çŸ¥è¯†ï¼Œä»¥ä¾¿ä½ åœ¨å¿…è¦æ—¶èƒ½æ‰¾åˆ°èµ„æºè¿›è¡Œæ›´æ·±å…¥çš„å­¦ä¹ ã€‚ æˆ‘ä»¬å¯¹ä¸€ä¸ªå…¸å‹æ•°æ®ç§‘å­¦é¡¹ç›®æ­¥éª¤çš„æ¨¡å‹å¦‚ FigureÂ 1 æ‰€ç¤ºã€‚\nFigureÂ 1: In our model of the data science process, you start with data import and tidying. Next, you understand your data with an iterative cycle of transforming, visualizing, and modeling. You finish the process by communicating your results to other humans.\nFirst, you must import your data into R. This typically means that you take data stored in a file, database, or web application programming interface (API) and load it into a data frame in R. If you canâ€™t get your data into R, you canâ€™t do data science on it!\né¦–å…ˆï¼Œä½ å¿…é¡»å°†æ•°æ® å¯¼å…¥ (import) R ä¸­ã€‚ è¿™é€šå¸¸æ„å‘³ç€ä½ å°†å­˜å‚¨åœ¨æ–‡ä»¶ã€æ•°æ®åº“æˆ–ç½‘ç»œåº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ (API) ä¸­çš„æ•°æ®åŠ è½½åˆ° R çš„æ•°æ®æ¡†ä¸­ã€‚ å¦‚æœä½ ä¸èƒ½å°†æ•°æ®å¯¼å…¥ Rï¼Œä½ å°±æ— æ³•å¯¹å…¶è¿›è¡Œæ•°æ®ç§‘å­¦åˆ†æï¼\nOnce youâ€™ve imported your data, it is a good idea to tidy it. Tidying your data means storing it in a consistent form that matches the semantics of the dataset with how it is stored. In brief, when your data is tidy, each column is a variable and each row is an observation. Tidy data is important because the consistent structure lets you focus your efforts on answering questions about the data, not fighting to get the data into the right form for different functions.\nå¯¼å…¥æ•°æ®åï¼Œæœ€å¥½å¯¹å…¶è¿›è¡Œ æ•´ç† (tidy)ã€‚ æ•´ç†æ•°æ®æ„å‘³ç€ä»¥ä¸€ç§ä¸€è‡´çš„å½¢å¼å­˜å‚¨æ•°æ®ï¼Œä½¿å…¶å­˜å‚¨æ–¹å¼ä¸æ•°æ®é›†çš„è¯­ä¹‰ç›¸åŒ¹é…ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œå½“ä½ çš„æ•°æ®æ˜¯æ•´æ´çš„ï¼Œæ¯ä¸€åˆ—éƒ½æ˜¯ä¸€ä¸ªå˜é‡ï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªè§‚æµ‹ã€‚ æ•´æ´çš„æ•°æ®å¾ˆé‡è¦ï¼Œå› ä¸ºä¸€è‡´çš„ç»“æ„è®©ä½ èƒ½é›†ä¸­ç²¾åŠ›å›ç­”å…³äºæ•°æ®çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯è´¹åŠ›åœ°å°†æ•°æ®è½¬æ¢æˆä¸åŒå‡½æ•°æ‰€éœ€çš„æ­£ç¡®å½¢å¼ã€‚\nOnce you have tidy data, a common next step is to transform it. Transformation includes narrowing in on observations of interest (like all people in one city or all data from the last year), creating new variables that are functions of existing variables (like computing speed from distance and time), and calculating a set of summary statistics (like counts or means). Together, tidying and transforming are called wrangling because getting your data in a form thatâ€™s natural to work with often feels like a fight!\nä¸€æ—¦ä½ æœ‰äº†æ•´æ´çš„æ•°æ®ï¼Œé€šå¸¸çš„ä¸‹ä¸€æ­¥æ˜¯è¿›è¡Œ è½¬æ¢ (transform)ã€‚ è½¬æ¢åŒ…æ‹¬ç­›é€‰æ„Ÿå…´è¶£çš„è§‚æµ‹å€¼ï¼ˆä¾‹å¦‚æŸä¸ªåŸå¸‚çš„æ‰€æœ‰äººæˆ–å»å¹´çš„æ‰€æœ‰æ•°æ®ï¼‰ï¼Œæ ¹æ®ç°æœ‰å˜é‡åˆ›å»ºæ–°å˜é‡ï¼ˆä¾‹å¦‚æ ¹æ®è·ç¦»å’Œæ—¶é—´è®¡ç®—é€Ÿåº¦ï¼‰ï¼Œä»¥åŠè®¡ç®—ä¸€ç»„æ±‡æ€»ç»Ÿè®¡æ•°æ®ï¼ˆä¾‹å¦‚è®¡æ•°æˆ–å‡å€¼ï¼‰ã€‚ æ•´ç†å’Œè½¬æ¢ä¸€èµ·è¢«ç§°ä¸º æ•°æ®æ•´ç† (wrangling)ï¼Œå› ä¸ºå°†æ•°æ®å¤„ç†æˆä¾¿äºä½¿ç”¨çš„å½¢å¼é€šå¸¸æ„Ÿè§‰åƒä¸€åœºæˆ˜æ–—ï¼\nOnce you have tidy data with the variables you need, there are two main engines of knowledge generation: visualization and modeling. These have complementary strengths and weaknesses, so any real data analysis will iterate between them many times.\nä¸€æ—¦ä½ è·å¾—äº†åŒ…å«æ‰€éœ€å˜é‡çš„æ•´æ´æ•°æ®ï¼Œä¾¿æœ‰ä¸¤ç§ä¸»è¦çš„çŸ¥è¯†ç”Ÿæˆå¼•æ“ï¼šå¯è§†åŒ–å’Œå»ºæ¨¡ã€‚ è¿™ä¸¤è€…å„æœ‰ä¼˜ç¼ºç‚¹ï¼Œäº’ä¸ºè¡¥å……ï¼Œå› æ­¤ä»»ä½•å®é™…çš„æ•°æ®åˆ†æéƒ½ä¼šåœ¨å®ƒä»¬ä¹‹é—´å¤šæ¬¡è¿­ä»£ã€‚\nVisualization is a fundamentally human activity. A good visualization will show you things you did not expect or raise new questions about the data. A good visualization might also hint that youâ€™re asking the wrong question or that you need to collect different data. Visualizations can surprise you, but they donâ€™t scale particularly well because they require a human to interpret them.å¯è§†åŒ– (Visualization) æœ¬è´¨ä¸Šæ˜¯ä¸€é¡¹äººç±»æ´»åŠ¨ã€‚ å¥½çš„å¯è§†åŒ–ä¼šå‘ä½ å±•ç¤ºæ„æƒ³ä¸åˆ°çš„äº‹æƒ…ï¼Œæˆ–å¼•å‘å…³äºæ•°æ®çš„æ–°é—®é¢˜ã€‚ å¥½çš„å¯è§†åŒ–ä¹Ÿå¯èƒ½æš—ç¤ºä½ é—®é”™äº†é—®é¢˜ï¼Œæˆ–è€…ä½ éœ€è¦æ”¶é›†ä¸åŒçš„æ•°æ®ã€‚ å¯è§†åŒ–å¯ä»¥ç»™ä½ å¸¦æ¥æƒŠå–œï¼Œä½†å®ƒä»¬çš„å¯æ‰©å±•æ€§ä¸æ˜¯ç‰¹åˆ«å¥½ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦äººæ¥è§£é‡Šã€‚\nModels are complementary tools to visualization. Once you have made your questions sufficiently precise, you can use a model to answer them. Models are fundamentally mathematical or computational tools, so they generally scale well. Even when they donâ€™t, itâ€™s usually cheaper to buy more computers than it is to buy more brains! But every model makes assumptions, and by its very nature, a model cannot question its own assumptions. That means a model cannot fundamentally surprise you.æ¨¡å‹ (Models) æ˜¯å¯è§†åŒ–çš„è¡¥å……å·¥å…·ã€‚ ä¸€æ—¦ä½ çš„é—®é¢˜è¶³å¤Ÿç²¾ç¡®ï¼Œä½ å°±å¯ä»¥ä½¿ç”¨æ¨¡å‹æ¥å›ç­”å®ƒä»¬ã€‚ æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯æ•°å­¦æˆ–è®¡ç®—å·¥å…·ï¼Œæ‰€ä»¥å®ƒä»¬é€šå¸¸å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚ å³ä½¿å®ƒä»¬ä¸å…·å¤‡ï¼Œè´­ä¹°æ›´å¤šçš„è®¡ç®—æœºé€šå¸¸ä¹Ÿæ¯”è´­ä¹°æ›´å¤šçš„äººè„‘ä¾¿å®œï¼ ä½†æ˜¯æ¯ä¸ªæ¨¡å‹éƒ½æœ‰å…¶å‡è®¾ï¼Œè€Œæ¨¡å‹æœ¬è´¨ä¸Šæ— æ³•è´¨ç–‘è‡ªèº«çš„å‡è®¾ã€‚ è¿™æ„å‘³ç€æ¨¡å‹æ ¹æœ¬ä¸Šæ— æ³•ç»™ä½ å¸¦æ¥æƒŠå–œã€‚\nThe last step of data science is communication, an absolutely critical part of any data analysis project. It doesnâ€™t matter how well your models and visualization have led you to understand the data unless you can also communicate your results to others.\næ•°æ®ç§‘å­¦çš„æœ€åä¸€æ­¥æ˜¯ æ²Ÿé€š (communication)ï¼Œè¿™æ˜¯ä»»ä½•æ•°æ®åˆ†æé¡¹ç›®ä¸­è‡³å…³é‡è¦çš„ä¸€éƒ¨åˆ†ã€‚ æ— è®ºä½ çš„æ¨¡å‹å’Œå¯è§†åŒ–è®©ä½ å¯¹æ•°æ®ç†è§£å¾—æœ‰å¤šé€å½»ï¼Œé™¤éä½ ä¹Ÿèƒ½å°†ä½ çš„ç»“æœä¼ è¾¾ç»™ä»–äººï¼Œå¦åˆ™ä¸€åˆ‡éƒ½æ˜¯å¾’åŠ³ã€‚\nSurrounding all these tools is programming. Programming is a cross-cutting tool that you use in nearly every part of a data science project. You donâ€™t need to be an expert programmer to be a successful data scientist, but learning more about programming pays off because becoming a better programmer allows you to automate common tasks and solve new problems with greater ease.\nå›´ç»•æ‰€æœ‰è¿™äº›å·¥å…·çš„æ˜¯ ç¼–ç¨‹ (programming)ã€‚ ç¼–ç¨‹æ˜¯ä¸€é¡¹è´¯ç©¿å§‹ç»ˆçš„å·¥å…·ï¼Œä½ åœ¨æ•°æ®ç§‘å­¦é¡¹ç›®çš„å‡ ä¹æ¯ä¸ªç¯èŠ‚éƒ½ä¼šç”¨åˆ°å®ƒã€‚ ä½ ä¸éœ€è¦æˆä¸ºä¸€åä¸“å®¶ç¨‹åºå‘˜æ‰èƒ½æˆä¸ºä¸€åæˆåŠŸçš„æ•°æ®ç§‘å­¦å®¶ï¼Œä½†å­¦ä¹ æ›´å¤šå…³äºç¼–ç¨‹çš„çŸ¥è¯†æ˜¯å€¼å¾—çš„ï¼Œå› ä¸ºæˆä¸ºä¸€ä¸ªæ›´å¥½çš„ç¨‹åºå‘˜å¯ä»¥è®©ä½ è‡ªåŠ¨åŒ–å¤„ç†å¸¸è§ä»»åŠ¡ï¼Œå¹¶æ›´è½»æ¾åœ°è§£å†³æ–°é—®é¢˜ã€‚\nYouâ€™ll use these tools in every data science project, but theyâ€™re not enough for most projects. Thereâ€™s a rough 80/20 rule at play: you can tackle about 80% of every project using the tools youâ€™ll learn in this book, but youâ€™ll need other tools to tackle the remaining 20%. Throughout this book, weâ€™ll point you to resources where you can learn more.\nä½ å°†åœ¨æ¯ä¸ªæ•°æ®ç§‘å­¦é¡¹ç›®ä¸­ä½¿ç”¨è¿™äº›å·¥å…·ï¼Œä½†å¯¹å¤§å¤šæ•°é¡¹ç›®æ¥è¯´ï¼Œå®ƒä»¬è¿˜ä¸å¤Ÿã€‚ è¿™é‡Œæœ‰ä¸€ä¸ªå¤§è‡´çš„ 80/20 æ³•åˆ™ï¼šä½ å¯ä»¥ä½¿ç”¨æœ¬ä¹¦ä¸­å­¦åˆ°çš„å·¥å…·å¤„ç†æ¯ä¸ªé¡¹ç›®ä¸­å¤§çº¦ 80% çš„å·¥ä½œï¼Œä½†ä½ éœ€è¦å…¶ä»–å·¥å…·æ¥å¤„ç†å‰©ä¸‹çš„ 20%ã€‚ åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¼šä¸ºä½ æŒ‡å‡ºå¯ä»¥å­¦ä¹ æ›´å¤šçŸ¥è¯†çš„èµ„æºã€‚",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#how-this-book-is-organized",
    "href": "intro.html#how-this-book-is-organized",
    "title": "Introduction",
    "section": "How this book is organized",
    "text": "How this book is organized\nThe previous description of the tools of data science is organized roughly according to the order in which you use them in an analysis (although, of course, youâ€™ll iterate through them multiple times). In our experience, however, learning data importing and tidying first is suboptimal because, 80% of the time, itâ€™s routine and boring, and the other 20% of the time, itâ€™s weird and frustrating. Thatâ€™s a bad place to start learning a new subject! Instead, weâ€™ll start with visualization and transformation of data thatâ€™s already been imported and tidied. That way, when you ingest and tidy your own data, your motivation will stay high because you know the pain is worth the effort.\nå‰æ–‡å¯¹æ•°æ®ç§‘å­¦å·¥å…·çš„æè¿°å¤§è‡´æ˜¯æŒ‰ç…§ä½ åœ¨åˆ†æä¸­ä½¿ç”¨çš„é¡ºåºæ¥ç»„ç»‡çš„ï¼ˆå½“ç„¶ï¼Œä½ ä¼šå¤šæ¬¡è¿­ä»£ä½¿ç”¨å®ƒä»¬ï¼‰ã€‚ ç„¶è€Œï¼Œæ ¹æ®æˆ‘ä»¬çš„ç»éªŒï¼Œé¦–å…ˆå­¦ä¹ æ•°æ®å¯¼å…¥å’Œæ•´ç†å¹¶éæœ€ä½³é€‰æ‹©ï¼Œå› ä¸º 80% çš„æ—¶é—´è¿™é¡¹å·¥ä½œæ˜¯å¸¸è§„ä¸”ä¹å‘³çš„ï¼Œè€Œå¦å¤– 20% çš„æ—¶é—´åˆ™æ˜¯å¤æ€ªä¸”ä»¤äººæ²®ä¸§çš„ã€‚ è¿™å¯¹äºå¼€å§‹å­¦ä¹ ä¸€ä¸ªæ–°ä¸»é¢˜æ¥è¯´æ˜¯ä¸ªç³Ÿç³•çš„èµ·ç‚¹ï¼ å› æ­¤ï¼Œæˆ‘ä»¬å°†ä»å·²ç»å¯¼å…¥å’Œæ•´ç†å¥½çš„æ•°æ®çš„å¯è§†åŒ–å’Œè½¬æ¢å¼€å§‹ã€‚ è¿™æ ·ï¼Œå½“ä½ å¤„ç†å’Œæ•´ç†è‡ªå·±çš„æ•°æ®æ—¶ï¼Œä½ çš„åŠ¨åŠ›ä¼šä¿æŒé«˜æ˜‚ï¼Œå› ä¸ºä½ çŸ¥é“è¿™äº›è¾›è‹¦æ˜¯å€¼å¾—çš„ã€‚\nWithin each chapter, we try to adhere to a consistent pattern: start with some motivating examples so you can see the bigger picture, and then dive into the details. Each section of the book is paired with exercises to help you practice what youâ€™ve learned. Although it can be tempting to skip the exercises, thereâ€™s no better way to learn than by practicing on real problems.\nåœ¨æ¯ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬éƒ½åŠ›æ±‚éµå¾ªä¸€ç§ä¸€è‡´çš„æ¨¡å¼ï¼šä»ä¸€äº›æ¿€åŠ±æ€§çš„ä¾‹å­å¼€å§‹ï¼Œè®©ä½ çœ‹åˆ°å…¨å±€ï¼Œç„¶åæ·±å…¥ç»†èŠ‚ã€‚ ä¹¦ä¸­çš„æ¯ä¸€èŠ‚éƒ½é…æœ‰ç»ƒä¹ ï¼Œä»¥å¸®åŠ©ä½ å®è·µæ‰€å­¦ã€‚ è™½ç„¶è·³è¿‡ç»ƒä¹ å¾ˆè¯±äººï¼Œä½†æ²¡æœ‰æ¯”é€šè¿‡è§£å†³å®é™…é—®é¢˜æ›´å¥½çš„å­¦ä¹ æ–¹æ³•äº†ã€‚",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#what-you-wont-learn",
    "href": "intro.html#what-you-wont-learn",
    "title": "Introduction",
    "section": "What you wonâ€™t learn",
    "text": "What you wonâ€™t learn\nThere are several important topics that this book doesnâ€™t cover. We believe itâ€™s important to stay ruthlessly focused on the essentials so you can get up and running as quickly as possible. That means this book canâ€™t cover every important topic.\næœ¬ä¹¦æœªæ¶µç›–ä¸€äº›é‡è¦ä¸»é¢˜ã€‚ æˆ‘ä»¬è®¤ä¸ºï¼Œä¸¥æ ¼ä¸“æ³¨äºæ ¸å¿ƒå†…å®¹ï¼Œä»¥ä¾¿ä½ èƒ½å°½å¿«ä¸Šæ‰‹ï¼Œè¿™ä¸€ç‚¹è‡³å…³é‡è¦ã€‚ è¿™æ„å‘³ç€æœ¬ä¹¦æ— æ³•æ¶µç›–æ‰€æœ‰é‡è¦ä¸»é¢˜ã€‚\nModeling\nModeling is super important for data science, but itâ€™s a big topic, and unfortunately, we just donâ€™t have the space to give it the coverage it deserves here. To learn more about modeling, we highly recommend Tidy Modeling with R by our colleagues Max Kuhn and Julia Silge. This book will teach you the tidymodels family of packages, which, as you might guess from the name, share many conventions with the tidyverse packages we use in this book.\nå»ºæ¨¡å¯¹äºæ•°æ®ç§‘å­¦è¶…çº§é‡è¦ï¼Œä½†å®ƒæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ä¸»é¢˜ï¼Œä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæ²¡æœ‰è¶³å¤Ÿçš„ç¯‡å¹…ç»™äºˆå®ƒåº”æœ‰çš„ä»‹ç»ã€‚ è¦å­¦ä¹ æ›´å¤šå…³äºå»ºæ¨¡çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬å¼ºçƒˆæ¨èæˆ‘ä»¬çš„åŒäº‹ Max Kuhn å’Œ Julia Silge ç¼–å†™çš„ ã€ŠTidy Modeling with Rã€‹ã€‚ è¿™æœ¬ä¹¦å°†æ•™ä½  tidymodels ç³»åˆ—çš„åŒ…ï¼Œæ­£å¦‚ä½ å¯èƒ½ä»åå­—ä¸­çŒœåˆ°çš„é‚£æ ·ï¼Œå®ƒä»¬ä¸æˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­ä½¿ç”¨çš„ tidyverse åŒ…æœ‰è®¸å¤šå…±åŒçš„çº¦å®šã€‚\nBig data\nThis book proudly and primarily focuses on small, in-memory datasets. This is the right place to start because you canâ€™t tackle big data unless you have experience with small data. The tools youâ€™ll learn throughout the majority of this book will easily handle hundreds of megabytes of data, and with a bit of care, you can typically use them to work with a few gigabytes of data. Weâ€™ll also show you how to get data out of databases and parquet files, both of which are often used to store big data. You wonâ€™t necessarily be able to work with the entire dataset, but thatâ€™s not a problem because you only need a subset or subsample to answer the question that youâ€™re interested in.\næœ¬ä¹¦ä¸»è¦ä¸”è‡ªè±ªåœ°ä¸“æ³¨äºå°å‹çš„ã€å†…å­˜ä¸­çš„æ•°æ®é›†ã€‚ è¿™æ˜¯ä¸€ä¸ªæ­£ç¡®çš„èµ·ç‚¹ï¼Œå› ä¸ºé™¤éä½ æœ‰å¤„ç†å°æ•°æ®çš„ç»éªŒï¼Œå¦åˆ™ä½ æ— æ³•å¤„ç†å¤§æ•°æ®ã€‚ ä½ åœ¨æœ¬ä¹¦å¤§éƒ¨åˆ†ç« èŠ‚ä¸­å­¦åˆ°çš„å·¥å…·å¯ä»¥è½»æ¾å¤„ç†æ•°ç™¾å…†å­—èŠ‚çš„æ•°æ®ï¼Œç¨åŠ æ³¨æ„ï¼Œä½ é€šå¸¸å¯ä»¥ç”¨å®ƒä»¬æ¥å¤„ç†å‡ åƒå…†å­—èŠ‚çš„æ•°æ®ã€‚ æˆ‘ä»¬è¿˜å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä»æ•°æ®åº“å’Œ parquet æ–‡ä»¶ä¸­è·å–æ•°æ®ï¼Œè¿™ä¸¤ç§æ–‡ä»¶éƒ½å¸¸ç”¨äºå­˜å‚¨å¤§æ•°æ®ã€‚ ä½ ä¸ä¸€å®šèƒ½å¤Ÿå¤„ç†æ•´ä¸ªæ•°æ®é›†ï¼Œä½†è¿™ä¸æˆé—®é¢˜ï¼Œå› ä¸ºä½ åªéœ€è¦ä¸€ä¸ªå­é›†æˆ–å­æ ·æœ¬æ¥å›ç­”ä½ æ„Ÿå…´è¶£çš„é—®é¢˜ã€‚\nIf youâ€™re routinely working with larger data (10â€“100 GB, say), we recommend learning more about data.table. We donâ€™t teach it here because it uses a different interface than the tidyverse and requires you to learn some different conventions. However, it is incredibly faster, and the performance payoff is worth investing some time in learning it if youâ€™re working with large data.\nå¦‚æœä½ ç»å¸¸å¤„ç†æ›´å¤§æ•°æ®ï¼ˆæ¯”å¦‚ 10-100 GBï¼‰ï¼Œæˆ‘ä»¬å»ºè®®ä½ å­¦ä¹ æ›´å¤šå…³äº data.table çš„çŸ¥è¯†ã€‚ æˆ‘ä»¬åœ¨è¿™é‡Œä¸æ•™å®ƒï¼Œå› ä¸ºå®ƒä½¿ç”¨äº†ä¸ tidyverse ä¸åŒçš„æ¥å£ï¼Œéœ€è¦ä½ å­¦ä¹ ä¸€äº›ä¸åŒçš„çº¦å®šã€‚ ç„¶è€Œï¼Œå®ƒçš„é€Ÿåº¦å¿«å¾—æƒŠäººï¼Œå¦‚æœä½ å¤„ç†çš„æ˜¯å¤§æ•°æ®ï¼Œä¸ºäº†æ€§èƒ½æå‡è€ŒèŠ±æ—¶é—´å­¦ä¹ å®ƒæ˜¯å€¼å¾—çš„ã€‚\nPython, Julia, and friends\nIn this book, you wonâ€™t learn anything about Python, Julia, or any other programming language useful for data science. This isnâ€™t because we think these tools are bad. Theyâ€™re not! And in practice, most data science teams use a mix of languages, often at least R and Python. But we strongly believe that itâ€™s best to master one tool at a time, and R is a great place to start.\nåœ¨æœ¬ä¹¦ä¸­ï¼Œä½ ä¸ä¼šå­¦åˆ°ä»»ä½•å…³äº Pythonã€Julia æˆ–å…¶ä»–ç”¨äºæ•°æ®ç§‘å­¦çš„ç¼–ç¨‹è¯­è¨€çš„çŸ¥è¯†ã€‚ è¿™å¹¶éå› ä¸ºæˆ‘ä»¬è®¤ä¸ºè¿™äº›å·¥å…·ä¸å¥½ã€‚ å®ƒä»¬å¾ˆå¥½ï¼ åœ¨å®è·µä¸­ï¼Œå¤§å¤šæ•°æ•°æ®ç§‘å­¦å›¢é˜Ÿä¼šæ··åˆä½¿ç”¨å¤šç§è¯­è¨€ï¼Œé€šå¸¸è‡³å°‘åŒ…æ‹¬ R å’Œ Pythonã€‚ ä½†æˆ‘ä»¬åšä¿¡ï¼Œæœ€å¥½ä¸€æ¬¡åªæŒæ¡ä¸€ç§å·¥å…·ï¼Œè€Œ R æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "Introduction",
    "section": "Prerequisites",
    "text": "Prerequisites\nWeâ€™ve made a few assumptions about what you already know to get the most out of this book. You should be generally numerically literate, and itâ€™s helpful if you have some basic programming experience already. If youâ€™ve never programmed before, you might find Hands on Programming with R by Garrett to be a valuable adjunct to this book.\nä¸ºäº†è®©ä½ èƒ½ä»æœ¬ä¹¦ä¸­è·å¾—æœ€å¤§æ”¶ç›Šï¼Œæˆ‘ä»¬å¯¹ä½ å·²æœ‰çš„çŸ¥è¯†åšäº†ä¸€äº›å‡è®¾ã€‚ ä½ åº”è¯¥å…·å¤‡åŸºæœ¬çš„æ•°å­¦ç´ å…»ï¼Œå¦‚æœå·²ç»æœ‰ä¸€äº›åŸºç¡€çš„ç¼–ç¨‹ç»éªŒä¼šå¾ˆæœ‰å¸®åŠ©ã€‚ å¦‚æœä½ ä»¥å‰ä»æœªç¼–ç¨‹è¿‡ï¼Œä½ å¯èƒ½ä¼šå‘ç° Garrett ç¼–å†™çš„ ã€ŠHands on Programming with Rã€‹ æ˜¯æœ¬ä¹¦çš„ä¸€ä¸ªæœ‰ä»·å€¼çš„è¡¥å……ã€‚\nYou need four things to run the code in this book: R, RStudio, a collection of R packages called the tidyverse, and a handful of other packages. Packages are the fundamental units of reproducible R code. They include reusable functions, documentation that describes how to use them, and sample data.\nè¦è¿è¡Œæœ¬ä¹¦ä¸­çš„ä»£ç ï¼Œä½ éœ€è¦å››æ ·ä¸œè¥¿ï¼šRã€RStudioã€ä¸€ä¸ªåä¸º tidyverse çš„ R åŒ…é›†åˆï¼Œä»¥åŠå…¶ä»–å‡ ä¸ªåŒ…ã€‚ åŒ…æ˜¯å¯å¤ç° R ä»£ç çš„åŸºæœ¬å•ä½ã€‚ å®ƒä»¬åŒ…å«å¯é‡ç”¨çš„å‡½æ•°ã€æè¿°å¦‚ä½•ä½¿ç”¨å®ƒä»¬çš„æ–‡æ¡£ä»¥åŠç¤ºä¾‹æ•°æ®ã€‚\nR\nTo download R, go to CRAN, the comprehensive R archive network, https://cloud.r-project.org. A new major version of R comes out once a year, and there are 2-3 minor releases each year. Itâ€™s a good idea to update regularly. Upgrading can be a bit of a hassle, especially for major versions that require you to re-install all your packages, but putting it off only makes it worse. We recommend R 4.2.0 or later for this book.\nè¦ä¸‹è½½ Rï¼Œè¯·è®¿é—® CRANï¼ˆcomprehensive R archive networkï¼Œç»¼åˆ R å­˜æ¡£ç½‘ç»œï¼‰ï¼Œç½‘å€ä¸º https://cloud.r-project.orgã€‚ R æ¯å¹´å‘å¸ƒä¸€ä¸ªæ–°çš„ä¸»ç‰ˆæœ¬ï¼Œæ¯å¹´è¿˜æœ‰ 2-3 ä¸ªæ¬¡è¦ç‰ˆæœ¬å‘å¸ƒã€‚ å®šæœŸæ›´æ–°æ˜¯ä¸ªå¥½ä¸»æ„ã€‚ å‡çº§å¯èƒ½æœ‰ç‚¹éº»çƒ¦ï¼Œç‰¹åˆ«æ˜¯ä¸»ç‰ˆæœ¬å‡çº§éœ€è¦ä½ é‡æ–°å®‰è£…æ‰€æœ‰åŒ…ï¼Œä½†æ‹–å»¶åªä¼šè®©äº‹æƒ…å˜å¾—æ›´ç³Ÿã€‚ æˆ‘ä»¬æ¨èä¸ºæœ¬ä¹¦ä½¿ç”¨ R 4.2.0 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚\nRStudio\nRStudio is an integrated development environment, or IDE, for R programming, which you can download from https://posit.co/download/rstudio-desktop/. RStudio is updated a couple of times a year, and it will automatically let you know when a new version is out, so thereâ€™s no need to check back. Itâ€™s a good idea to upgrade regularly to take advantage of the latest and greatest features. For this book, make sure you have at least RStudio 2022.02.0.\nRStudio æ˜¯ R ç¼–ç¨‹çš„é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEï¼‰ï¼Œä½ å¯ä»¥ä» https://posit.co/download/rstudio-desktop/ ä¸‹è½½ã€‚ RStudio æ¯å¹´æ›´æ–°å‡ æ¬¡ï¼Œå½“æœ‰æ–°ç‰ˆæœ¬å‘å¸ƒæ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨é€šçŸ¥ä½ ï¼Œæ‰€ä»¥æ— éœ€åå¤æ£€æŸ¥ã€‚ å®šæœŸå‡çº§ä»¥åˆ©ç”¨æœ€æ–°æœ€å¼ºå¤§çš„åŠŸèƒ½æ˜¯ä¸ªå¥½ä¸»æ„ã€‚ å¯¹äºæœ¬ä¹¦ï¼Œè¯·ç¡®ä¿ä½ è‡³å°‘å®‰è£…äº† RStudio 2022.02.0 ç‰ˆæœ¬ã€‚\nWhen you start RStudio, FigureÂ 2, youâ€™ll see two key regions in the interface: the console pane and the output pane. For now, all you need to know is that you type the R code in the console pane and press enter to run it. Youâ€™ll learn more as we go along!1\nå½“ä½ å¯åŠ¨ RStudio æ—¶ï¼ˆè§ FigureÂ 2ï¼‰ï¼Œä½ ä¼šåœ¨ç•Œé¢ä¸­çœ‹åˆ°ä¸¤ä¸ªå…³é”®åŒºåŸŸï¼šæ§åˆ¶å°çª—æ ¼å’Œè¾“å‡ºçª—æ ¼ã€‚ ç›®å‰ï¼Œä½ åªéœ€è¦çŸ¥é“ï¼Œåœ¨æ§åˆ¶å°çª—æ ¼ä¸­è¾“å…¥ R ä»£ç ï¼Œç„¶åæŒ‰ Enter é”®æ¥è¿è¡Œå®ƒã€‚ éšç€å­¦ä¹ çš„æ·±å…¥ï¼Œä½ ä¼šäº†è§£æ›´å¤šï¼1\n\n\n\n\n\n\n\nFigureÂ 2: The RStudio IDE has two key regions: type R code in the console pane on the left, and look for plots in the output pane on the right.\n\n\n\n\nThe tidyverse\nYouâ€™ll also need to install some R packages. An R package is a collection of functions, data, and documentation that extends the capabilities of base R. Using packages is key to the successful use of R. The majority of the packages that you will learn in this book are part of the so-called tidyverse. All packages in the tidyverse share a common philosophy of data and R programming and are designed to work together.\nä½ è¿˜éœ€è¦å®‰è£…ä¸€äº› R åŒ…ã€‚ R åŒ… (package) æ˜¯ä¸€ä¸ªé›†å‡½æ•°ã€æ•°æ®å’Œæ–‡æ¡£äºä¸€ä½“çš„é›†åˆï¼Œå®ƒæ‰©å±•äº†åŸºç¡€ R çš„åŠŸèƒ½ã€‚ ä½¿ç”¨åŒ…æ˜¯æˆåŠŸä½¿ç”¨ R çš„å…³é”®ã€‚ ä½ å°†åœ¨æœ¬ä¹¦ä¸­å­¦åˆ°çš„å¤§éƒ¨åˆ†åŒ…éƒ½å±äºæ‰€è°“çš„ tidyverseã€‚ tidyverse ä¸­çš„æ‰€æœ‰åŒ…éƒ½å…±äº«ä¸€å¥—å…³äºæ•°æ®å’Œ R ç¼–ç¨‹çš„å…±åŒç†å¿µï¼Œå¹¶ä¸”è¢«è®¾è®¡ä¸ºå¯ä»¥ååŒå·¥ä½œã€‚\nYou can install the complete tidyverse with a single line of code:\nä½ å¯ä»¥ç”¨ä¸€è¡Œä»£ç å®‰è£…å®Œæ•´çš„ tidyverseï¼š\n\ninstall.packages(\"tidyverse\")\n\nOn your computer, type that line of code in the console, and then press enter to run it. R will download the packages from CRAN and install them on your computer.\nåœ¨ä½ çš„ç”µè„‘ä¸Šï¼Œåœ¨æ§åˆ¶å°ä¸­è¾“å…¥é‚£è¡Œä»£ç ï¼Œç„¶åæŒ‰å›è½¦é”®è¿è¡Œå®ƒã€‚ R å°†ä» CRAN ä¸‹è½½è¿™äº›åŒ…å¹¶å®‰è£…åˆ°ä½ çš„ç”µè„‘ä¸Šã€‚\nYou will not be able to use the functions, objects, or help files in a package until you load it with library(). Once you have installed a package, you can load it using the library() function:\nåœ¨ä½ ä½¿ç”¨ library() åŠ è½½ä¸€ä¸ªåŒ…ä¹‹å‰ï¼Œä½ å°†æ— æ³•ä½¿ç”¨è¯¥åŒ…ä¸­çš„å‡½æ•°ã€å¯¹è±¡æˆ–å¸®åŠ©æ–‡ä»¶ã€‚ ä¸€æ—¦å®‰è£…äº†åŒ…ï¼Œä½ å¯ä»¥ä½¿ç”¨ library() å‡½æ•°æ¥åŠ è½½å®ƒï¼š\n\nlibrary(tidyverse)\n#&gt; â”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\n#&gt; âœ” dplyr     1.1.4     âœ” readr     2.1.5\n#&gt; âœ” forcats   1.0.0     âœ” stringr   1.5.1\n#&gt; âœ” ggplot2   3.5.2     âœ” tibble    3.3.0\n#&gt; âœ” lubridate 1.9.4     âœ” tidyr     1.3.1\n#&gt; âœ” purrr     1.0.4     \n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\n#&gt; âœ– dplyr::filter() masks stats::filter()\n#&gt; âœ– dplyr::lag()    masks stats::lag()\n#&gt; â„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nThis tells you that tidyverse loads nine packages: dplyr, forcats, ggplot2, lubridate, purrr, readr, stringr, tibble, tidyr. These are considered the core of the tidyverse because youâ€™ll use them in almost every analysis.\nè¿™ä¼šå‘Šè¯‰ä½  tidyverse åŠ è½½äº†ä¹ä¸ªåŒ…ï¼šdplyrã€forcatsã€ggplot2ã€lubridateã€purrrã€readrã€stringrã€tibble å’Œ tidyrã€‚ è¿™äº›è¢«è®¤ä¸ºæ˜¯ tidyverse çš„ æ ¸å¿ƒ (core)ï¼Œå› ä¸ºä½ å‡ ä¹åœ¨æ¯æ¬¡åˆ†æä¸­éƒ½ä¼šç”¨åˆ°å®ƒä»¬ã€‚\nPackages in the tidyverse change fairly frequently. You can see if updates are available by running tidyverse_update().\ntidyverse ä¸­çš„åŒ…æ›´æ–°ç›¸å½“é¢‘ç¹ã€‚ ä½ å¯ä»¥é€šè¿‡è¿è¡Œ tidyverse_update() æ¥æŸ¥çœ‹æ˜¯å¦æœ‰å¯ç”¨çš„æ›´æ–°ã€‚\nOther packages\nThere are many other excellent packages that are not part of the tidyverse because they solve problems in a different domain or are designed with a different set of underlying principles. This doesnâ€™t make them better or worse; it just makes them different. In other words, the complement to the tidyverse is not the messyverse but many other universes of interrelated packages. As you tackle more data science projects with R, youâ€™ll learn new packages and new ways of thinking about data.\nè¿˜æœ‰è®¸å¤šå…¶ä»–ä¼˜ç§€çš„åŒ…ä¸å±äº tidyverseï¼Œå› ä¸ºå®ƒä»¬è§£å†³çš„æ˜¯ä¸åŒé¢†åŸŸçš„é—®é¢˜ï¼Œæˆ–è€…éµå¾ªä¸åŒçš„åº•å±‚è®¾è®¡åŸåˆ™ã€‚ è¿™å¹¶ä¸èƒ½è¯´å®ƒä»¬æ›´å¥½æˆ–æ›´å·®ï¼Œåªæ˜¯å®ƒä»¬ä¸åŒã€‚ æ¢å¥è¯è¯´ï¼Œtidyverse çš„è¡¥å……ä¸æ˜¯ messyverse (æ··ä¹±å®‡å®™)ï¼Œè€Œæ˜¯è®¸å¤šå…¶ä»–ç›¸äº’å…³è”çš„åŒ…çš„å®‡å®™ã€‚ éšç€ä½ ç”¨ R æ”»å…‹æ›´å¤šçš„æ•°æ®ç§‘å­¦é¡¹ç›®ï¼Œä½ å°†å­¦åˆ°æ–°çš„åŒ…å’Œæ–°çš„æ•°æ®æ€ç»´æ–¹å¼ã€‚\nWeâ€™ll use many packages from outside the tidyverse in this book. For example, weâ€™ll use the following packages because they provide interesting datasets for us to work with in the process of learning R:\nåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è®¸å¤šæ¥è‡ª tidyverse ä¹‹å¤–çš„åŒ…ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹åŒ…ï¼Œå› ä¸ºå®ƒä»¬åœ¨æˆ‘ä»¬å­¦ä¹  R çš„è¿‡ç¨‹ä¸­æä¾›äº†æœ‰è¶£çš„æ•°æ®é›†ä¾›æˆ‘ä»¬ä½¿ç”¨ï¼š\n\ninstall.packages(\n  c(\"arrow\", \"babynames\", \"curl\", \"duckdb\", \"gapminder\", \n    \"ggrepel\", \"ggridges\", \"ggthemes\", \"hexbin\", \"janitor\", \"Lahman\", \n    \"leaflet\", \"maps\", \"nycflights13\", \"openxlsx\", \"palmerpenguins\", \n    \"repurrrsive\", \"tidymodels\", \"writexl\")\n  )\n\nWeâ€™ll also use a selection of other packages for one off examples. You donâ€™t need to install them now, just remember that whenever you see an error like this:\næˆ‘ä»¬è¿˜å°†ä¸ºä¸€äº›ä¸€æ¬¡æ€§çš„ä¾‹å­ä½¿ç”¨å…¶ä»–ä¸€äº›åŒ…ã€‚ ä½ ç°åœ¨ä¸éœ€è¦å®‰è£…å®ƒä»¬ï¼Œåªéœ€è®°ä½ï¼Œå½“ä½ çœ‹åˆ°å¦‚ä¸‹é”™è¯¯æ—¶ï¼š\n\nlibrary(ggrepel)\n#&gt; Error in library(ggrepel) : there is no package called â€˜ggrepelâ€™\n\nYou need to run install.packages(\"ggrepel\") to install the package.\nä½ éœ€è¦è¿è¡Œ install.packages(\"ggrepel\") æ¥å®‰è£…è¿™ä¸ªåŒ…ã€‚",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#running-r-code",
    "href": "intro.html#running-r-code",
    "title": "Introduction",
    "section": "Running R code",
    "text": "Running R code\nThe previous section showed you several examples of running R code. The code in the book looks like this:\nä¸Šä¸€èŠ‚å‘ä½ å±•ç¤ºäº†å‡ ä¸ªè¿è¡Œ R ä»£ç çš„ä¾‹å­ã€‚ ä¹¦ä¸­çš„ä»£ç çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼š\n\n1 + 2\n#&gt; [1] 3\n\nIf you run the same code in your local console, it will look like this:\nå¦‚æœä½ åœ¨æœ¬åœ°æ§åˆ¶å°è¿è¡ŒåŒæ ·çš„ä»£ç ï¼Œå®ƒä¼šçœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼š\n&gt; 1 + 2\n[1] 3\nThere are two main differences. In your console, you type after the &gt;, called the prompt; we donâ€™t show the prompt in the book. In the book, the output is commented out with #&gt;; in your console, it appears directly after your code. These two differences mean that if youâ€™re working with an electronic version of the book, you can easily copy code out of the book and paste it into the console.\nè¿™é‡Œæœ‰ä¸¤ä¸ªä¸»è¦åŒºåˆ«ã€‚ åœ¨ä½ çš„æ§åˆ¶å°é‡Œï¼Œä½ åœ¨ &gt;ï¼ˆç§°ä¸º æç¤ºç¬¦ (prompt)ï¼‰åé¢è¾“å…¥ï¼›æˆ‘ä»¬åœ¨ä¹¦ä¸­ä¸æ˜¾ç¤ºæç¤ºç¬¦ã€‚ åœ¨ä¹¦ä¸­ï¼Œè¾“å‡ºè¢« #&gt; æ³¨é‡Šæ‰äº†ï¼›åœ¨ä½ çš„æ§åˆ¶å°é‡Œï¼Œå®ƒç›´æ¥å‡ºç°åœ¨ä½ çš„ä»£ç åé¢ã€‚ è¿™ä¸¤ä¸ªåŒºåˆ«æ„å‘³ç€ï¼Œå¦‚æœä½ æ­£åœ¨ä½¿ç”¨æœ¬ä¹¦çš„ç”µå­ç‰ˆï¼Œä½ å¯ä»¥å¾ˆå®¹æ˜“åœ°ä»ä¹¦ä¸­å¤åˆ¶ä»£ç å¹¶ç²˜è´´åˆ°æ§åˆ¶å°ã€‚\nThroughout the book, we use a consistent set of conventions to refer to code:\nåœ¨æ•´æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€å¥—ä¸€è‡´çš„çº¦å®šæ¥å¼•ç”¨ä»£ç ï¼š\n- Functions are displayed in a code font and followed by parentheses, like sum() or mean().\nå‡½æ•°ä¼šä»¥ä»£ç å­—ä½“æ˜¾ç¤ºï¼Œå¹¶åè·Ÿæ‹¬å·ï¼Œå¦‚ sum() æˆ– mean()ã€‚\n- Other R objects (such as data or function arguments) are in a code font, without parentheses, like flights or x.\nå…¶ä»–çš„ R å¯¹è±¡ï¼ˆæ¯”å¦‚æ•°æ®æˆ–å‡½æ•°å‚æ•°ï¼‰ä¼šä»¥ä»£ç å­—ä½“æ˜¾ç¤ºï¼Œä¸å¸¦æ‹¬å·ï¼Œå¦‚ flights æˆ– xã€‚\n- Sometimes, to make it clear which package an object comes from, weâ€™ll use the package name followed by two colons, like dplyr::mutate() or nycflights13::flights. This is also valid R code.\næœ‰æ—¶ï¼Œä¸ºäº†æ˜ç¡®ä¸€ä¸ªå¯¹è±¡æ¥è‡ªå“ªä¸ªåŒ…ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨åŒ…ååè·Ÿä¸¤ä¸ªå†’å·çš„å½¢å¼ï¼Œæ¯”å¦‚ dplyr::mutate() æˆ– nycflights13::flightsã€‚ è¿™ä¹Ÿæ˜¯æœ‰æ•ˆçš„ R ä»£ç ã€‚",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#acknowledgments",
    "href": "intro.html#acknowledgments",
    "title": "Introduction",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis book isnâ€™t just the product of Hadley, Mine, and Garrett but is the result of many conversations (in person and online) that weâ€™ve had with many people in the R community. Weâ€™re incredibly grateful for all the conversations weâ€™ve had with yâ€™all; thank you so much!\nè¿™æœ¬ä¹¦ä¸ä»…ä»…æ˜¯ Hadleyã€Mine å’Œ Garrett çš„æˆæœï¼Œä¹Ÿæ˜¯æˆ‘ä»¬ä¸ R ç¤¾åŒºä¸­è®¸å¤šäººè¿›è¡Œå¤šæ¬¡å¯¹è¯ï¼ˆçº¿ä¸Šå’Œçº¿ä¸‹ï¼‰çš„ç»“æ™¶ã€‚ æˆ‘ä»¬éå¸¸æ„Ÿè°¢ä¸å„ä½è¿›è¡Œçš„æ‰€æœ‰å¯¹è¯ï¼›éå¸¸æ„Ÿè°¢ä½ ä»¬ï¼\nThis book was written in the open, and many people contributed via pull requests. A special thanks to all 259 of you who contributed improvements via GitHub pull requests (in alphabetical order by username): @a-rosenberg, Tim Becker (@a2800276), Abinash Satapathy (@Abinashbunty), Adam Gruer (@adam-gruer), adi pradhan (@adidoit), A. s. (@Adrianzo), Aep Hidyatuloh (@aephidayatuloh), Andrea Gilardi (@agila5), Ajay Deonarine (@ajay-d), @AlanFeder, Daihe Sui (@alansuidaihe), @alberto-agudo, @AlbertRapp, @aleloi, pete (@alonzi), Alex (@ALShum), Andrew M. (@amacfarland), Andrew Landgraf (@andland), @andyhuynh92, Angela Li (@angela-li), Antti Rask (@AnttiRask), LOU Xun (@aquarhead), @ariespirgel, @august-18, Michael Henry (@aviast), Azza Ahmed (@azzaea), Steven Moran (@bambooforest), Brian G. Barkley (@BarkleyBG), Mara Averick (@batpigandme), Oluwafemi OYEDELE (@BB1464), Brent Brewington (@bbrewington), Bill Behrman (@behrman), Ben Herbertson (@benherbertson), Ben Marwick (@benmarwick), Ben Steinberg (@bensteinberg), Benjamin Yeh (@bentyeh), Betul Turkoglu (@betulturkoglu), Brandon Greenwell (@bgreenwell), Bianca Peterson (@BinxiePeterson), Birger Niklas (@BirgerNi), Brett Klamer (@bklamer), @boardtc, Christian (@c-hoh), Caddy (@caddycarine), Camille V Leonard (@camillevleonard), @canovasjm, Cedric Batailler (@cedricbatailler), Christina Wei (@christina-wei), Christian Mongeau (@chrMongeau), Cooper Morris (@coopermor), Colin Gillespie (@csgillespie), Rademeyer Vermaak (@csrvermaak), Chloe Thierstein (@cthierst), Chris Saunders (@ctsa), Abhinav Singh (@curious-abhinav), Curtis Alexander (@curtisalexander), Christian G. Warden (@cwarden), Charlotte Wickham (@cwickham), Kenny Darrell (@darrkj), David Kane (@davidkane9), David (@davidrsch), David Rubinger (@davidrubinger), David Clark (@DDClark), Derwin McGeary (@derwinmcgeary), Daniel Gromer (@dgromer), @Divider85, @djbirke, Danielle Navarro (@djnavarro), Russell Shean (@DOH-RPS1303), Zhuoer Dong (@dongzhuoer), Devin Pastoor (@dpastoor), @DSGeoff, Devarshi Thakkar (@dthakkar09), Julian During (@duju211), Dylan Cashman (@dylancashman), Dirk Eddelbuettel (@eddelbuettel), Edwin Thoen (@EdwinTh), Ahmed El-Gabbas (@elgabbas), Henry Webel (@enryH), Ercan Karadas (@ercan7), Eric Kitaif (@EricKit), Eric Watt (@ericwatt), Erik Erhardt (@erikerhardt), Etienne B. Racine (@etiennebr), Everett Robinson (@evjrob), @fellennert, Flemming Miguel (@flemmingmiguel), Floris Vanderhaeghe (@florisvdh), @funkybluehen, @gabrivera, Garrick Aden-Buie (@gadenbuie), Peter Ganong (@ganong123), Gerome Meyer (@GeroVanMi), Gleb Ebert (@gl-eb), Josh Goldberg (@GoldbergData), bahadir cankardes (@gridgrad), Gustav W Delius (@gustavdelius), Hao Chen (@hao-trivago), Harris McGehee (@harrismcgehee), @hendrikweisser, Hengni Cai (@hengnicai), Iain (@Iain-S), Ian Sealy (@iansealy), Ian Lyttle (@ijlyttle), Ivan Krukov (@ivan-krukov), Jacob Kaplan (@jacobkap), Jazz Weisman (@jazzlw), John Blischak (@jdblischak), John D. Storey (@jdstorey), Gregory Jefferis (@jefferis), Jeffrey Stevens (@JeffreyRStevens), è’‹é›¨è’™ (@JeldorPKU), Jennifer (Jenny) Bryan (@jennybc), Jen Ren (@jenren), Jeroen Janssens (@jeroenjanssens), @jeromecholewa, Janet Wesner (@jilmun), Jim Hester (@jimhester), JJ Chen (@jjchern), Jacek Kolacz (@jkolacz), Joanne Jang (@joannejang), @johannes4998, John Sears (@johnsears), @jonathanflint, Jon Calder (@jonmcalder), Jonathan Page (@jonpage), Jon Harmon (@jonthegeek), JooYoung Seo (@jooyoungseo), Justinas Petuchovas (@jpetuchovas), Jordan (@jrdnbradford), Jeffrey Arnold (@jrnold), Jose Roberto Ayala Solares (@jroberayalas), Joyce Robbins (@jtr13), @juandering, Julia Stewart Lowndes (@jules32), Sonja (@kaetschap), Kara Woo (@karawoo), Katrin Leinweber (@katrinleinweber), Karandeep Singh (@kdpsingh), Kevin Perese (@kevinxperese), Kevin Ferris (@kferris10), Kirill Sevastyanenko (@kirillseva), Jonathan Kitt (@KittJonathan), @koalabearski, Kirill MÃ¼ller (@krlmlr), RafaÅ‚ Kucharski (@kucharsky), Kevin Wright (@kwstat), Noah Landesberg (@landesbergn), Lawrence Wu (@lawwu), @lindbrook, Luke W Johnston (@lwjohnst86), Kara de la Marck (@MarckK), Kunal Marwaha (@marwahaha), Matan Hakim (@matanhakim), Matthias Liew (@MatthiasLiew), Matt Wittbrodt (@MattWittbrodt), Mauro Lepore (@maurolepore), Mark Beveridge (@mbeveridge), @mcewenkhundi, mcsnowface, PhD (@mcsnowface), Matt Herman (@mfherman), Michael Boerman (@michaelboerman), Mitsuo Shiota (@mitsuoxv), Matthew Hendrickson (@mjhendrickson), @MJMarshall, Misty Knight-Finley (@mkfin7), Mohammed Hamdy (@mmhamdy), Maxim Nazarov (@mnazarov), Maria Paula Caldas (@mpaulacaldas), Mustafa Ascha (@mustafaascha), Nelson Areal (@nareal), Nate Olson (@nate-d-olson), Nathanael (@nateaff), @nattalides, Ned Western (@NedJWestern), Nick Clark (@nickclark1000), @nickelas, Nirmal Patel (@nirmalpatel), Nischal Shrestha (@nischalshrestha), Nicholas Tierney (@njtierney), Jakub Nowosad (@Nowosad), Nick Pullen (@nstjhp), @olivier6088, Olivier Cailloux (@oliviercailloux), Robin Penfold (@p0bs), Pablo E. Garcia (@pabloedug), Paul Adamson (@padamson), Penelope Y (@penelopeysm), Peter Hurford (@peterhurford), Peter Baumgartner (@petzi53), Patrick Kennedy (@pkq), Pooya Taherkhani (@pooyataher), Y. Yu (@PursuitOfDataScience), Radu Grosu (@radugrosu), Ranae Dietzel (@Ranae), Ralph Straumann (@rastrau), Rayna M Harris (@raynamharris), @ReeceGoding, Robin Gertenbach (@rgertenbach), Jajo (@RIngyao), Riva Quiroga (@rivaquiroga), Richard Knight (@RJHKnight), Richard Zijdeman (@rlzijdeman), @robertchu03, Robin Kohrs (@RobinKohrs), Robin (@Robinlovelace), Emily Robinson (@robinsones), Rob Tenorio (@robtenorio), Rod Mazloomi (@RodAli), Rohan Alexander (@RohanAlexander), Romero Morais (@RomeroBarata), Albert Y. Kim (@rudeboybert), Saghir (@saghirb), Hojjat Salmasian (@salmasian), Jonas (@sauercrowd), Vebash Naidoo (@sciencificity), Seamus McKinsey (@seamus-mckinsey), @seanpwilliams, Luke Smith (@seasmith), Matthew Sedaghatfar (@sedaghatfar), Sebastian Kraus (@sekR4), Sam Firke (@sfirke), Shannon Ellis (@ShanEllis), @shoili, Christian Heinrich (@Shurakai), Sâ€™busiso Mkhondwane (@sibusiso16), SM Raiyyan (@sm-raiyyan), Jakob Krigovsky (@sonicdoe), Stephan Koenig (@stephan-koenig), Stephen Balogun (@stephenbalogun), Steven M. Mortimer (@StevenMMortimer), StÃ©phane Guillou (@stragu), Sulgi Kim (@sulgik), Sergiusz Bleja (@svenski), Tal Galili (@talgalili), Alec Fisher (@Taurenamo), Todd Gerarden (@tgerarden), Tom Godfrey (@thomasggodfrey), Tim Broderick (@timbroderick), Tim Waterhouse (@timwaterhouse), TJ Mahr (@tjmahr), Thomas Klebel (@tklebel), Tom Prior (@tomjamesprior), Terence Teo (@tteo), @twgardner2, Ulrik Lyngs (@ulyngs), Shinya Uryu (@uribo), Martin Van der Linden (@vanderlindenma), Walter Somerville (@waltersom), @werkstattcodes, Will Beasley (@wibeasley), Yihui Xie (@yihui), Yiming (Paul) Li (@yimingli), @yingxingwu, Hiroaki Yutani (@yutannihilation), Yu Yu Aung (@yuyu-aung), Zach Bogart (@zachbogart), @zeal626, Zeki Akyol (@zekiakyol).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#colophon",
    "href": "intro.html#colophon",
    "title": "Introduction",
    "section": "Colophon",
    "text": "Colophon\nAn online version of this book is available at https://r4ds.hadley.nz. It will continue to evolve in between reprints of the physical book. The source of the book is available at https://github.com/hadley/r4ds. The book is powered by Quarto, which makes it easy to write books that combine text and executable code.\næœ¬ä¹¦çš„åœ¨çº¿ç‰ˆæœ¬å¯åœ¨ https://r4ds.hadley.nz æŸ¥çœ‹ã€‚ åœ¨å®ä½“ä¹¦å†ç‰ˆä¹‹é—´ï¼Œå®ƒä¼šä¸æ–­æ¼”è¿›ã€‚ æœ¬ä¹¦çš„æºä»£ç å¯åœ¨ https://github.com/hadley/r4ds æ‰¾åˆ°ã€‚ æœ¬ä¹¦ç”± Quarto é©±åŠ¨ï¼Œå®ƒä½¿å¾—ç¼–å†™ç»“åˆæ–‡æœ¬å’Œå¯æ‰§è¡Œä»£ç çš„ä¹¦ç±å˜å¾—å®¹æ˜“ã€‚",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "Introduction",
    "section": "",
    "text": "If youâ€™d like a comprehensive overview of all of RStudioâ€™s features, see the RStudio User Guide at https://docs.posit.co/ide/user.â†©ï¸",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "whole-game.html",
    "href": "whole-game.html",
    "title": "Whole game",
    "section": "",
    "text": "Our goal in this part of the book is to give you a rapid overview of the main tools of data science: importing, tidying, transforming, and visualizing data, as shown in FigureÂ 1. We want to show you the â€œwhole gameâ€ of data science giving you just enough of all the major pieces so that you can tackle real, if simple, datasets. The later parts of the book will hit each of these topics in more depth, increasing the range of data science challenges that you can tackle.  åœ¨æœ¬ä¹¦è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¿«é€Ÿæ¦‚è§ˆæ•°æ®ç§‘å­¦çš„ä¸»è¦å·¥å…·ï¼šå¯¼å…¥ (importing)ã€æ•´æ´åŒ– (tidying)ã€è½¬æ¢ (transforming) å’Œ å¯è§†åŒ– (visualizing)ï¼Œå¦‚ FigureÂ 1 æ‰€ç¤ºã€‚ æˆ‘ä»¬å¸Œæœ›å‘ä½ å±•ç¤ºæ•°æ®ç§‘å­¦çš„ â€œå®Œæ•´å…¨å±€ (whole game)â€ï¼Œè®©ä½ å¯¹æ‰€æœ‰å…³é”®ç¯èŠ‚éƒ½æœ‰è¶³å¤Ÿè®¤è¯†ï¼Œä»¥ä¾¿èƒ½å¤Ÿå¤„ç†çœŸæ­£ä½†ç›¸å¯¹ç®€å•çš„æ•°æ®é›†ã€‚ åç»­ç« èŠ‚å°†æ›´æ·±å…¥åœ°æ¢è®¨è¿™äº›ä¸»é¢˜ï¼Œé€æ­¥æå‡ä½ å¯åº”å¯¹çš„æ•°æ®ç§‘å­¦æŒ‘æˆ˜çš„å¹¿åº¦å’Œæ·±åº¦ã€‚\n\n\n\n\n\n\n\nFigureÂ 1: In this section of the book, youâ€™ll learn how to import, tidy, transform, and visualize data.\n\n\n\n\nFour chapters focus on the tools of data science:  ä»¥ä¸‹å››ä¸ªç« èŠ‚é›†ä¸­ä»‹ç»æ•°æ®ç§‘å­¦çš„æ ¸å¿ƒå·¥å…·ï¼š\n\nVisualization is a great place to start with R programming, because the payoff is so clear: you get to make elegant and informative plots that help you understand data. In 1Â  Data visualization youâ€™ll dive into visualization, learning the basic structure of a ggplot2 plot, and powerful techniques for turning data into plots.  ä»¥å¯è§†åŒ–å…¥é—¨ R ç¼–ç¨‹æ˜¯ç»ä½³é€‰æ‹©ï¼Œå› ä¸ºå®ƒçš„å›æŠ¥ååˆ†ç›´è§‚ï¼šä½ å¯ä»¥ç»˜åˆ¶ä¼˜é›…è€Œä¿¡æ¯ä¸°å¯Œçš„å›¾å½¢æ¥ç†è§£æ•°æ®ã€‚ åœ¨ 1Â  Data visualization ä¸­ï¼Œä½ å°†æ·±å…¥å­¦ä¹ å¯è§†åŒ–ï¼ŒæŒæ¡ ggplot2 å›¾å½¢çš„åŸºæœ¬ç»“æ„ï¼Œä»¥åŠå°†æ•°æ®è½¬åŒ–ä¸ºå›¾å½¢çš„å¼ºå¤§æŠ€å·§ã€‚\nVisualization alone is typically not enough, so in 3Â  Data transformation, youâ€™ll learn the key verbs that allow you to select important variables, filter out key observations, create new variables, and compute summaries.  å•é å¯è§†åŒ–é€šå¸¸ä¸è¶³ä»¥å®Œæˆåˆ†æä»»åŠ¡ï¼Œå› æ­¤åœ¨ 3Â  Data transformation ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸€ç»„å…³é”® â€œåŠ¨è¯ (verbs)â€ï¼šé€‰æ‹©é‡è¦å˜é‡ã€ç­›é€‰å…³é”®è§‚æµ‹ã€åˆ›å»ºæ–°å˜é‡å¹¶ç”Ÿæˆæ±‡æ€»ç»“æœã€‚\nIn 5Â  Data tidying, youâ€™ll learn about tidy data, a consistent way of storing your data that makes transformation, visualization, and modelling easier. Youâ€™ll learn the underlying principles, and how to get your data into a tidy form.  åœ¨ 5Â  Data tidying ä¸­ï¼Œä½ å°†äº†è§£ â€œæ•´æ´æ•°æ® (tidy data)â€ çš„æ¦‚å¿µï¼Œè¿™æ˜¯ä¸€ç§ä¸€è‡´çš„å­˜å‚¨æ–¹å¼ï¼Œå¯è®©åç»­è½¬æ¢ã€å¯è§†åŒ–ä¸å»ºæ¨¡å·¥ä½œæ›´è½»æ¾ã€‚ ä½ å°†å­¦ä¹ å…¶æ ¸å¿ƒåŸåˆ™ï¼Œä»¥åŠå¦‚ä½•å°†æ•°æ®æ•´ç†æˆæ•´æ´æ ¼å¼ã€‚\nBefore you can transform and visualize your data, you need to first get your data into R. In 7Â  Data import youâ€™ll learn the basics of getting .csv files into R.  åœ¨è½¬æ¢å’Œå¯è§†åŒ–æ•°æ®ä¹‹å‰ï¼Œä½ éœ€è¦å…ˆå°†æ•°æ®å¯¼å…¥ Rã€‚ 7Â  Data import å°†æ•™ä½ æŠŠ .csv æ–‡ä»¶è¯»å…¥ R çš„åŸºç¡€æ–¹æ³•ã€‚\n\nNestled among these chapters are four other chapters that focus on your R workflow. In 2Â  Workflow: basics, 4Â  Workflow: code style, and 6Â  Workflow: scripts and projects youâ€™ll learn good workflow practices for writing and organizing your R code. These will set you up for success in the long run, as theyâ€™ll give you the tools to stay organized when you tackle real projects. Finally, 8Â  Workflow: getting help will teach you how to get help and keep learning.  é™¤äº†ä¸Šè¿°å†…å®¹ï¼Œæœ¬éƒ¨åˆ†è¿˜ç©¿æ’äº†å››ä¸ªä¸“æ³¨äº R å·¥ä½œæµçš„ç« èŠ‚ã€‚ åœ¨ 2Â  Workflow: basicsã€4Â  Workflow: code style ä»¥åŠ 6Â  Workflow: scripts and projects ä¸­ï¼Œä½ å°†å­¦ä¹ æ’°å†™å¹¶ç»„ç»‡ R ä»£ç çš„è‰¯å¥½å·¥ä½œæµå®è·µã€‚ è¿™äº›æŠ€èƒ½å°†åœ¨é•¿æœŸé¡¹ç›®ä¸­åŠ©ä½ ä¿æŒæ¡ç†ä¸é«˜æ•ˆã€‚ æœ€åï¼Œ8Â  Workflow: getting help å°†æŒ‡å¯¼ä½ å¦‚ä½•å¯»æ±‚å¸®åŠ©å¹¶æŒç»­å­¦ä¹ ã€‚",
    "crumbs": [
      "Whole game"
    ]
  },
  {
    "objectID": "data-visualize.html",
    "href": "data-visualize.html",
    "title": "1Â  Data visualization",
    "section": "",
    "text": "1.1 Introduction\nR has several systems for making graphs, but ggplot2 is one of the most elegant and most versatile. ggplot2 implements the grammar of graphics, a coherent system for describing and building graphs. With ggplot2, you can do more and faster by learning one system and applying it in many places.\nR æœ‰å¤šä¸ªç”¨äºåˆ¶ä½œå›¾å½¢çš„ç³»ç»Ÿï¼Œä½† ggplot2 æ˜¯å…¶ä¸­æœ€ä¼˜é›…ã€åŠŸèƒ½æœ€å…¨é¢çš„ä¹‹ä¸€ã€‚ggplot2 å®ç°äº†å›¾å½¢è¯­æ³• (grammar of graphics)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæè¿°å’Œæ„å»ºå›¾å½¢çš„è¿è´¯ç³»ç»Ÿã€‚é€šè¿‡å­¦ä¹  ggplot2ï¼Œä½ å¯ä»¥åœ¨è®¸å¤šåœ°æ–¹åº”ç”¨è¿™ä¸€ç³»ç»Ÿï¼Œä»è€Œæ›´å¿«ã€æ›´å¥½åœ°å®Œæˆå·¥ä½œã€‚\nThis chapter will teach you how to visualize your data using ggplot2. We will start by creating a simple scatterplot and use that to introduce aesthetic mappings and geometric objects â€“ the fundamental building blocks of ggplot2. We will then walk you through visualizing distributions of single variables as well as visualizing relationships between two or more variables. Weâ€™ll finish off with saving your plots and troubleshooting tips.\næœ¬ç« å°†æ•™ä½ å¦‚ä½•ä½¿ç”¨ ggplot2 æ¥å¯è§†åŒ–ä½ çš„æ•°æ®ã€‚æˆ‘ä»¬å°†ä»åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•£ç‚¹å›¾å¼€å§‹ï¼Œå¹¶ä»¥æ­¤ä»‹ç»ç¾å­¦æ˜ å°„ (aesthetic mappings) å’Œå‡ ä½•å¯¹è±¡ (geometric objects)â€”â€”å®ƒä»¬æ˜¯ ggplot2 çš„åŸºæœ¬æ„å»ºæ¨¡å—ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å¼•å¯¼ä½ å­¦ä¹ å¦‚ä½•å¯è§†åŒ–å•ä¸ªå˜é‡çš„åˆ†å¸ƒä»¥åŠä¸¤ä¸ªæˆ–å¤šä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»ã€‚æœ€åï¼Œæˆ‘ä»¬ä¼šä»‹ç»å¦‚ä½•ä¿å­˜ä½ çš„å›¾å½¢ä»¥åŠä¸€äº›æ•…éšœæ’é™¤æŠ€å·§ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#introduction",
    "href": "data-visualize.html#introduction",
    "title": "1Â  Data visualization",
    "section": "",
    "text": "â€œThe simple graph has brought more information to the data analystâ€™s mind than any other device.â€ â€” John Tukey\nâ€œç®€å•çš„å›¾å½¢ç»™æ•°æ®åˆ†æå¸ˆå¸¦æ¥çš„ä¿¡æ¯æ¯”ä»»ä½•å…¶ä»–è®¾å¤‡éƒ½å¤šã€‚â€ â€” çº¦ç¿°Â·å›¾åŸº (John Tukey)\n\n\n\n\n1.1.1 Prerequisites\nThis chapter focuses on ggplot2, one of the core packages in the tidyverse. To access the datasets, help pages, and functions used in this chapter, load the tidyverse by running:\næœ¬ç« é‡ç‚¹ä»‹ç» ggplot2ï¼Œå®ƒæ˜¯ tidyverse ä¸­çš„æ ¸å¿ƒåŒ…ä¹‹ä¸€ã€‚è¦è®¿é—®æœ¬ç« ä¸­ä½¿ç”¨çš„æ•°æ®é›†ã€å¸®åŠ©é¡µé¢å’Œå‡½æ•°ï¼Œè¯·é€šè¿‡è¿è¡Œä»¥ä¸‹ä»£ç åŠ è½½ tidyverseï¼š\n\nlibrary(tidyverse)\n#&gt; â”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\n#&gt; âœ” dplyr     1.1.4     âœ” readr     2.1.5\n#&gt; âœ” forcats   1.0.0     âœ” stringr   1.5.1\n#&gt; âœ” ggplot2   3.5.2     âœ” tibble    3.3.0\n#&gt; âœ” lubridate 1.9.4     âœ” tidyr     1.3.1\n#&gt; âœ” purrr     1.0.4     \n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\n#&gt; âœ– dplyr::filter() masks stats::filter()\n#&gt; âœ– dplyr::lag()    masks stats::lag()\n#&gt; â„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nThat one line of code loads the core tidyverse; the packages that you will use in almost every data analysis. It also tells you which functions from the tidyverse conflict with functions in base R (or from other packages you might have loaded)1.\nè¿™ä¸€è¡Œä»£ç åŠ è½½äº† tidyverse çš„æ ¸å¿ƒåŒ…ï¼›è¿™äº›åŒ…å‡ ä¹åœ¨æ¯æ¬¡æ•°æ®åˆ†æä¸­éƒ½ä¼šç”¨åˆ°ã€‚å®ƒè¿˜ä¼šå‘Šè¯‰ä½  tidyverse ä¸­çš„å“ªäº›å‡½æ•°ä¸åŸºç¡€ Rï¼ˆæˆ–å…¶ä»–ä½ å¯èƒ½å·²åŠ è½½çš„åŒ…ï¼‰ä¸­çš„å‡½æ•°å­˜åœ¨å†²çª1ã€‚\nIf you run this code and get the error message there is no package called 'tidyverse', youâ€™ll need to first install it, then run library() once again.\nå¦‚æœä½ è¿è¡Œæ­¤ä»£ç å¹¶æ”¶åˆ°é”™è¯¯æ¶ˆæ¯ there is no package called 'tidyverse'ï¼Œä½ éœ€è¦å…ˆå®‰è£…å®ƒï¼Œç„¶åå†è¿è¡Œä¸€æ¬¡ library()ã€‚\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nYou only need to install a package once, but you need to load it every time you start a new session.\nä½ åªéœ€è¦å®‰è£…ä¸€ä¸ªåŒ…ä¸€æ¬¡ï¼Œä½†æ¯æ¬¡å¼€å§‹æ–°ä¼šè¯æ—¶éƒ½éœ€è¦åŠ è½½å®ƒã€‚\nIn addition to tidyverse, we will also use the palmerpenguins package, which includes the penguins dataset containing body measurements for penguins on three islands in the Palmer Archipelago, and the ggthemes package, which offers a colorblind safe color palette.\né™¤äº† tidyverseï¼Œæˆ‘ä»¬è¿˜å°†ä½¿ç”¨ palmerpenguins åŒ…ï¼Œå…¶ä¸­åŒ…å«äº† penguins æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«å¸•é»˜ç¾¤å²›ä¸‰ä¸ªå²›å±¿ä¸Šä¼é¹…çš„èº«ä½“æµ‹é‡æ•°æ®ï¼›æˆ‘ä»¬è¿˜ä¼šç”¨åˆ° ggthemes åŒ…ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªè‰²ç›²å®‰å…¨çš„è°ƒè‰²æ¿ã€‚\n\nlibrary(palmerpenguins)\n#&gt; \n#&gt; Attaching package: 'palmerpenguins'\n#&gt; The following objects are masked from 'package:datasets':\n#&gt; \n#&gt;     penguins, penguins_raw\nlibrary(ggthemes)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#first-steps",
    "href": "data-visualize.html#first-steps",
    "title": "1Â  Data visualization",
    "section": "\n1.2 First steps",
    "text": "1.2 First steps\nDo penguins with longer flippers weigh more or less than penguins with shorter flippers? You probably already have an answer, but try to make your answer precise. What does the relationship between flipper length and body mass look like? Is it positive? Negative? Linear? Nonlinear? Does the relationship vary by the species of the penguin? How about by the island where the penguin lives? Letâ€™s create visualizations that we can use to answer these questions.\né³çŠ¶è‚¢è¾ƒé•¿çš„ä¼é¹…æ¯”é³çŠ¶è‚¢è¾ƒçŸ­çš„ä¼é¹…é‡è¿˜æ˜¯è½»ï¼Ÿä½ å¯èƒ½å·²ç»æœ‰äº†ç­”æ¡ˆï¼Œä½†è¯·å°è¯•è®©ä½ çš„ç­”æ¡ˆæ›´ç²¾ç¡®ã€‚é³çŠ¶è‚¢é•¿åº¦å’Œä½“é‡ä¹‹é—´çš„å…³ç³»æ˜¯æ€æ ·çš„ï¼Ÿæ˜¯æ­£ç›¸å…³ï¼Ÿè´Ÿç›¸å…³ï¼Ÿçº¿æ€§çš„ï¼Ÿéçº¿æ€§çš„ï¼Ÿè¿™ç§å…³ç³»æ˜¯å¦å› ä¼é¹…çš„ç§ç±»è€Œå¼‚ï¼Ÿåˆæ˜¯å¦å› ä¼é¹…å±…ä½çš„å²›å±¿è€Œå¼‚ï¼Ÿè®©æˆ‘ä»¬åˆ›å»ºå¯è§†åŒ–å›¾è¡¨æ¥å›ç­”è¿™äº›é—®é¢˜ã€‚\n\n1.2.1 The penguins data frame\nYou can test your answers to those questions with the penguins data frame found in palmerpenguins (a.k.a. palmerpenguins::penguins). A data frame is a rectangular collection of variables (in the columns) and observations (in the rows). penguins contains 344 observations collected and made available by Dr.Â Kristen Gorman and the Palmer Station, Antarctica LTER2.\nä½ å¯ä»¥ä½¿ç”¨ palmerpenguins åŒ…ä¸­çš„ penguins æ•°æ®æ¡†ï¼ˆä¹Ÿå†™ä½œ palmerpenguins::penguinsï¼‰æ¥æ£€éªŒä½ å¯¹è¿™äº›é—®é¢˜çš„å›ç­”ã€‚æ•°æ®æ¡†æ˜¯ä¸€ä¸ªçŸ©å½¢é›†åˆï¼ŒåŒ…å«å˜é‡ï¼ˆåœ¨åˆ—ä¸­ï¼‰å’Œè§‚æµ‹å€¼ï¼ˆåœ¨è¡Œä¸­ï¼‰ã€‚penguins æ•°æ®é›†åŒ…å«äº† 344 æ¡è§‚æµ‹æ•°æ®ï¼Œç”± Kristen Gorman åšå£«å’Œå—æå¸•é»˜ç«™é•¿æœŸç”Ÿæ€ç ”ç©¶é¡¹ç›®ï¼ˆLTERï¼‰æ”¶é›†å¹¶æä¾›2ã€‚\nTo make the discussion easier, letâ€™s define some terms:\nä¸ºäº†è®©è®¨è®ºæ›´å®¹æ˜“ï¼Œæˆ‘ä»¬æ¥å®šä¹‰ä¸€äº›æœ¯è¯­ï¼š\n- A variable is a quantity, quality, or property that you can measure.å˜é‡ (variable) æ˜¯ä½ å¯ä»¥æµ‹é‡çš„æ•°é‡ã€è´¨é‡æˆ–å±æ€§ã€‚\n- A value is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.å€¼ (value) æ˜¯ä½ åœ¨æµ‹é‡æ—¶ä¸€ä¸ªå˜é‡çš„çŠ¶æ€ã€‚ä¸€ä¸ªå˜é‡çš„å€¼å¯èƒ½åœ¨ä¸åŒæ¬¡æµ‹é‡ä¸­å‘ç”Ÿå˜åŒ–ã€‚\n- An observation is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. Weâ€™ll sometimes refer to an observation as a data point.è§‚æµ‹ (observation) æ˜¯åœ¨ç›¸ä¼¼æ¡ä»¶ä¸‹è¿›è¡Œçš„ä¸€ç»„æµ‹é‡ï¼ˆé€šå¸¸ä½ ä¼šåœ¨åŒä¸€æ—¶é—´å¯¹åŒä¸€å¯¹è±¡è¿›è¡Œä¸€æ¬¡è§‚æµ‹ä¸­çš„æ‰€æœ‰æµ‹é‡ï¼‰ã€‚ä¸€æ¬¡è§‚æµ‹ä¼šåŒ…å«å‡ ä¸ªå€¼ï¼Œæ¯ä¸ªå€¼éƒ½ä¸ä¸€ä¸ªä¸åŒçš„å˜é‡ç›¸å…³è”ã€‚æˆ‘ä»¬æœ‰æ—¶ä¹Ÿå°†ä¸€æ¬¡è§‚æµ‹ç§°ä¸ºä¸€ä¸ªæ•°æ®ç‚¹ã€‚\n- Tabular data is a set of values, each associated with a variable and an observation. Tabular data is tidy if each value is placed in its own â€œcellâ€, each variable in its own column, and each observation in its own row.è¡¨æ ¼æ•°æ® (Tabular data) æ˜¯ä¸€ç»„å€¼ï¼Œæ¯ä¸ªå€¼éƒ½ä¸ä¸€ä¸ªå˜é‡å’Œä¸€æ¬¡è§‚æµ‹ç›¸å…³è”ã€‚å¦‚æœæ¯ä¸ªå€¼éƒ½æ”¾åœ¨è‡ªå·±çš„â€œå•å…ƒæ ¼â€ä¸­ï¼Œæ¯ä¸ªå˜é‡åœ¨è‡ªå·±çš„åˆ—ä¸­ï¼Œæ¯ä¸ªè§‚æµ‹åœ¨è‡ªå·±çš„è¡Œä¸­ï¼Œé‚£ä¹ˆè¿™ä¸ªè¡¨æ ¼æ•°æ®å°±æ˜¯æ•´æ´çš„ã€‚\nIn this context, a variable refers to an attribute of all the penguins, and an observation refers to all the attributes of a single penguin.\nåœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œä¸€ä¸ªå˜é‡æŒ‡çš„æ˜¯æ‰€æœ‰ä¼é¹…çš„ä¸€ä¸ªå±æ€§ï¼Œè€Œä¸€ä¸ªè§‚æµ‹æŒ‡çš„æ˜¯å•åªä¼é¹…çš„æ‰€æœ‰å±æ€§ã€‚\nType the name of the data frame in the console and R will print a preview of its contents. Note that it says tibble on top of this preview. In the tidyverse, we use special data frames called tibbles that you will learn more about soon.\nåœ¨æ§åˆ¶å°ä¸­è¾“å…¥æ•°æ®æ¡†çš„åç§°ï¼ŒR å°†ä¼šæ‰“å°å…¶å†…å®¹çš„é¢„è§ˆã€‚æ³¨æ„ï¼Œåœ¨è¿™ä¸ªé¢„è§ˆçš„é¡¶éƒ¨æ˜¾ç¤ºäº† tibbleã€‚åœ¨ tidyverse ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç§ç‰¹æ®Šçš„æ•°æ®æ¡†ï¼Œç§°ä¸º tibblesï¼Œä½ å¾ˆå¿«å°±ä¼šå­¦åˆ°æ›´å¤šå…³äºå®ƒçš„çŸ¥è¯†ã€‚\n\npenguins\n#&gt; # A tibble: 344 Ã— 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # â„¹ 338 more rows\n#&gt; # â„¹ 3 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt;\n\nThis data frame contains 8 columns. For an alternative view, where you can see all variables and the first few observations of each variable, use glimpse(). Or, if youâ€™re in RStudio, run View(penguins) to open an interactive data viewer.\nè¯¥æ•°æ®æ¡†åŒ…å« 8 åˆ—ã€‚è‹¥è¦æŸ¥çœ‹å¦ä¸€ç§è§†å›¾ï¼Œå³å¯ä»¥çœ‹åˆ°æ‰€æœ‰å˜é‡ä»¥åŠæ¯ä¸ªå˜é‡çš„å‰å‡ ä¸ªè§‚æµ‹å€¼ï¼Œè¯·ä½¿ç”¨ glimpse()ã€‚æˆ–è€…ï¼Œå¦‚æœä½ åœ¨ RStudio ä¸­ï¼Œè¿è¡Œ View(penguins) å¯ä»¥æ‰“å¼€ä¸€ä¸ªäº¤äº’å¼æ•°æ®æŸ¥çœ‹å™¨ã€‚\n\nglimpse(penguins)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Aâ€¦\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgeâ€¦\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.â€¦\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.â€¦\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, â€¦\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 347â€¦\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, mâ€¦\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2â€¦\n\nAmong the variables in penguins are:penguins æ•°æ®æ¡†ä¸­çš„å˜é‡åŒ…æ‹¬ï¼š\n\nspecies: a penguinâ€™s species (Adelie, Chinstrap, or Gentoo).species: ä¼é¹…çš„ç§ç±»ï¼ˆé˜¿å¾·åˆ©ã€å¸½å¸¦æˆ–é‡‘å›¾ï¼‰ã€‚\nflipper_length_mm: length of a penguinâ€™s flipper, in millimeters.flipper_length_mm: ä¼é¹…é³çŠ¶è‚¢çš„é•¿åº¦ï¼Œå•ä½ä¸ºæ¯«ç±³ã€‚\nbody_mass_g: body mass of a penguin, in grams.body_mass_g: ä¼é¹…çš„ä½“é‡ï¼Œå•ä½ä¸ºå…‹ã€‚\n\nTo learn more about penguins, open its help page by running ?penguins.\nè¦äº†è§£æ›´å¤šå…³äº penguins çš„ä¿¡æ¯ï¼Œè¿è¡Œ ?penguins æ¥æ‰“å¼€å®ƒçš„å¸®åŠ©é¡µé¢ã€‚\n\n1.2.2 Ultimate goal\nOur ultimate goal in this chapter is to recreate the following visualization displaying the relationship between flipper lengths and body masses of these penguins, taking into consideration the species of the penguin.\næˆ‘ä»¬åœ¨æœ¬ç« çš„æœ€ç»ˆç›®æ ‡æ˜¯é‡æ–°åˆ›å»ºä»¥ä¸‹å¯è§†åŒ–å›¾è¡¨ï¼Œè¯¥å›¾è¡¨å±•ç¤ºäº†è¿™äº›ä¼é¹…çš„é³çŠ¶è‚¢é•¿åº¦å’Œä½“é‡ä¹‹é—´çš„å…³ç³»ï¼ŒåŒæ—¶è€ƒè™‘äº†ä¼é¹…çš„ç§ç±»ã€‚\n\n\n\n\n\n\n\n\n\n1.2.3 Creating a ggplot\nLetâ€™s recreate this plot step-by-step.\nè®©æˆ‘ä»¬ä¸€æ­¥æ­¥åœ°é‡æ–°åˆ›å»ºè¿™ä¸ªå›¾ã€‚\nWith ggplot2, you begin a plot with the function ggplot(), defining a plot object that you then add layers to. The first argument of ggplot() is the dataset to use in the graph and so ggplot(data = penguins) creates an empty graph that is primed to display the penguins data, but since we havenâ€™t told it how to visualize it yet, for now itâ€™s empty. This is not a very exciting plot, but you can think of it like an empty canvas youâ€™ll paint the remaining layers of your plot onto.\nä½¿ç”¨ ggplot2 æ—¶ï¼Œä½ é€šè¿‡ ggplot() å‡½æ•°å¼€å§‹ä¸€ä¸ªç»˜å›¾ï¼Œå®šä¹‰ä¸€ä¸ªç»˜å›¾å¯¹è±¡ï¼Œç„¶åå‘å…¶æ·»åŠ å›¾å±‚ (layers)ã€‚ggplot() çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¦åœ¨å›¾ä¸­ä½¿ç”¨çš„æ•°æ®é›†ï¼Œå› æ­¤ ggplot(data = penguins) ä¼šåˆ›å»ºä¸€ä¸ªå‡†å¤‡å¥½æ˜¾ç¤º penguins æ•°æ®çš„ç©ºå›¾ï¼Œä½†ç”±äºæˆ‘ä»¬è¿˜æ²¡æœ‰å‘Šè¯‰å®ƒå¦‚ä½•å¯è§†åŒ–è¿™äº›æ•°æ®ï¼Œæ‰€ä»¥ç›®å‰å®ƒè¿˜æ˜¯ç©ºçš„ã€‚è¿™è™½ç„¶ä¸æ˜¯ä¸€ä¸ªå¾ˆæ¿€åŠ¨äººå¿ƒçš„å›¾ï¼Œä½†ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€å—ç©ºç™½çš„ç”»å¸ƒï¼Œä½ å°†åœ¨è¿™ä¸Šé¢ç»˜åˆ¶å›¾çš„å…¶ä½™å›¾å±‚ã€‚\n\nggplot(data = penguins)\n\n\n\n\n\n\n\nNext, we need to tell ggplot() how the information from our data will be visually represented. The mapping argument of the ggplot() function defines how variables in your dataset are mapped to visual properties (aesthetics) of your plot. The mapping argument is always defined in the aes() function, and the x and y arguments of aes() specify which variables to map to the x and y axes. For now, we will only map flipper length to the x aesthetic and body mass to the y aesthetic. ggplot2 looks for the mapped variables in the data argument, in this case, penguins.\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å‘Šè¯‰ ggplot() å¦‚ä½•å°†æˆ‘ä»¬æ•°æ®ä¸­çš„ä¿¡æ¯è¿›è¡Œå¯è§†åŒ–è¡¨ç¤ºã€‚ggplot() å‡½æ•°çš„ mapping å‚æ•°å®šä¹‰äº†ä½ æ•°æ®é›†ä¸­çš„å˜é‡å¦‚ä½•æ˜ å°„åˆ°å›¾çš„è§†è§‰å±æ€§ï¼ˆç¾å­¦ (aesthetics)ï¼‰ä¸Šã€‚mapping å‚æ•°æ€»æ˜¯åœ¨ aes() å‡½æ•°ä¸­å®šä¹‰ï¼Œè€Œ aes() çš„ x å’Œ y å‚æ•°æŒ‡å®šäº†å°†å“ªäº›å˜é‡æ˜ å°„åˆ° x è½´å’Œ y è½´ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬åªå°†é³çŠ¶è‚¢é•¿åº¦æ˜ å°„åˆ° x ç¾å­¦ï¼Œå°†ä½“é‡æ˜ å°„åˆ° y ç¾å­¦ã€‚ggplot2 ä¼šåœ¨ data å‚æ•°ï¼ˆåœ¨è¿™é‡Œæ˜¯ penguinsï¼‰ä¸­å¯»æ‰¾è¢«æ˜ å°„çš„å˜é‡ã€‚\nThe following plot shows the result of adding these mappings.\nä¸‹é¢çš„å›¾è¡¨å±•ç¤ºäº†æ·»åŠ è¿™äº›æ˜ å°„åçš„ç»“æœã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n)\n\n\n\n\n\n\n\nOur empty canvas now has more structure â€“ itâ€™s clear where flipper lengths will be displayed (on the x-axis) and where body masses will be displayed (on the y-axis). But the penguins themselves are not yet on the plot. This is because we have not yet articulated, in our code, how to represent the observations from our data frame on our plot.\næˆ‘ä»¬ç©ºç™½çš„ç”»å¸ƒç°åœ¨æœ‰äº†æ›´å¤šçš„ç»“æ„â€”â€”å¾ˆæ¸…æ¥šé³çŠ¶è‚¢é•¿åº¦å°†æ˜¾ç¤ºåœ¨å“ªé‡Œï¼ˆx è½´ä¸Šï¼‰ï¼Œä½“é‡å°†æ˜¾ç¤ºåœ¨å“ªé‡Œï¼ˆy è½´ä¸Šï¼‰ã€‚ä½†æ˜¯ä¼é¹…æœ¬èº«è¿˜æ²¡æœ‰å‡ºç°åœ¨å›¾ä¸Šã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬è¿˜æ²¡æœ‰åœ¨ä»£ç ä¸­æ˜ç¡®è¯´æ˜å¦‚ä½•å°†æˆ‘ä»¬æ•°æ®æ¡†ä¸­çš„è§‚æµ‹å€¼åœ¨å›¾ä¸Šè¡¨ç¤ºå‡ºæ¥ã€‚\nTo do so, we need to define a geom: the geometrical object that a plot uses to represent data. These geometric objects are made available in ggplot2 with functions that start with geom_. People often describe plots by the type of geom that the plot uses. For example, bar charts use bar geoms (geom_bar()), line charts use line geoms (geom_line()), boxplots use boxplot geoms (geom_boxplot()), scatterplots use point geoms (geom_point()), and so on.\nä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ª å‡ ä½•å¯¹è±¡ (geom)ï¼šå³å›¾ç”¨æ¥è¡¨ç¤ºæ•°æ®çš„å‡ ä½•å¯¹è±¡ã€‚è¿™äº›å‡ ä½•å¯¹è±¡åœ¨ ggplot2 ä¸­é€šè¿‡ä»¥ geom_ å¼€å¤´çš„å‡½æ•°æä¾›ã€‚äººä»¬é€šå¸¸ç”¨å›¾æ‰€ä½¿ç”¨çš„å‡ ä½•å¯¹è±¡ç±»å‹æ¥æè¿°å›¾ã€‚ä¾‹å¦‚ï¼Œæ¡å½¢å›¾ä½¿ç”¨æ¡å½¢å‡ ä½•å¯¹è±¡ (geom_bar())ï¼ŒæŠ˜çº¿å›¾ä½¿ç”¨çº¿å½¢å‡ ä½•å¯¹è±¡ (geom_line())ï¼Œç®±çº¿å›¾ä½¿ç”¨ç®±çº¿å›¾å‡ ä½•å¯¹è±¡ (geom_boxplot())ï¼Œæ•£ç‚¹å›¾ä½¿ç”¨ç‚¹å‡ ä½•å¯¹è±¡ (geom_point()) ç­‰ç­‰ã€‚\nThe function geom_point() adds a layer of points to your plot, which creates a scatterplot. ggplot2 comes with many geom functions that each adds a different type of layer to a plot. Youâ€™ll learn a whole bunch of geoms throughout the book, particularly in Chapter 9.\nå‡½æ•° geom_point() ä¼šåœ¨ä½ çš„å›¾ä¸Šæ·»åŠ ä¸€ä¸ªç‚¹å›¾å±‚ï¼Œä»è€Œåˆ›å»ºä¸€ä¸ªæ•£ç‚¹å›¾ã€‚ggplot2 æä¾›äº†è®¸å¤šå‡ ä½•å‡½æ•°ï¼Œæ¯ä¸ªå‡½æ•°éƒ½ä¼šç»™å›¾æ·»åŠ ä¸åŒç±»å‹çš„å›¾å±‚ã€‚ä½ å°†åœ¨æœ¬ä¹¦ä¸­å­¦ä¹ åˆ°è®¸å¤šå‡ ä½•å¯¹è±¡ï¼Œç‰¹åˆ«æ˜¯åœ¨ Chapter 9 ä¸­ã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\nNow we have something that looks like what we might think of as a â€œscatterplotâ€. It doesnâ€™t yet match our â€œultimate goalâ€ plot, but using this plot we can start answering the question that motivated our exploration: â€œWhat does the relationship between flipper length and body mass look like?â€ The relationship appears to be positive (as flipper length increases, so does body mass), fairly linear (the points are clustered around a line instead of a curve), and moderately strong (there isnâ€™t too much scatter around such a line). Penguins with longer flippers are generally larger in terms of their body mass.\nç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªçœ‹èµ·æ¥åƒæ˜¯æˆ‘ä»¬æ‰€è®¤ä¸ºçš„â€œæ•£ç‚¹å›¾â€çš„ä¸œè¥¿ã€‚å®ƒè¿˜ä¸å®Œå…¨ç¬¦åˆæˆ‘ä»¬â€œæœ€ç»ˆç›®æ ‡â€çš„å›¾ï¼Œä½†é€šè¿‡è¿™å¼ å›¾ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å›ç­”æ¿€å‘æˆ‘ä»¬æ¢ç´¢çš„é—®é¢˜ï¼šâ€œé³çŠ¶è‚¢é•¿åº¦å’Œä½“é‡ä¹‹é—´çš„å…³ç³»æ˜¯æ€æ ·çš„ï¼Ÿâ€ è¿™ç§å…³ç³»çœ‹èµ·æ¥æ˜¯æ­£ç›¸å…³çš„ï¼ˆéšç€é³çŠ¶è‚¢é•¿åº¦çš„å¢åŠ ï¼Œä½“é‡ä¹Ÿå¢åŠ ï¼‰ï¼Œç›¸å½“çº¿æ€§çš„ï¼ˆæ•°æ®ç‚¹èšé›†åœ¨ä¸€æ¡ç›´çº¿å‘¨å›´è€Œä¸æ˜¯ä¸€æ¡æ›²çº¿ï¼‰ï¼Œå¹¶ä¸”å¼ºåº¦é€‚ä¸­ï¼ˆå›´ç»•è¿™æ¡çº¿çš„æ•£ç‚¹ä¸å¤šï¼‰ã€‚é³çŠ¶è‚¢è¾ƒé•¿çš„ä¼é¹…é€šå¸¸ä½“é‡ä¹Ÿè¾ƒé‡ã€‚\nBefore we add more layers to this plot, letâ€™s pause for a moment and review the warning message we got:\nåœ¨ä¸ºè¿™å¼ å›¾æ·»åŠ æ›´å¤šå›¾å±‚ä¹‹å‰ï¼Œè®©æˆ‘ä»¬æš‚åœä¸€ä¸‹ï¼Œå›é¡¾ä¸€ä¸‹æˆ‘ä»¬æ”¶åˆ°çš„è­¦å‘Šä¿¡æ¯ï¼š\n\nRemoved 2 rows containing missing values (geom_point()).\n\n&gt; å·²ç§»é™¤ 2 ä¸ªåŒ…å«ç¼ºå¤±å€¼çš„è¡Œ (geom_point()).\nWeâ€™re seeing this message because there are two penguins in our dataset with missing body mass and/or flipper length values and ggplot2 has no way of representing them on the plot without both of these values. Like R, ggplot2 subscribes to the philosophy that missing values should never silently go missing. This type of warning is probably one of the most common types of warnings you will see when working with real data â€“ missing values are a very common issue and youâ€™ll learn more about them throughout the book, particularly in Chapter 18. For the remaining plots in this chapter we will suppress this warning so itâ€™s not printed alongside every single plot we make.\næˆ‘ä»¬çœ‹åˆ°è¿™æ¡æ¶ˆæ¯æ˜¯å› ä¸ºæˆ‘ä»¬çš„æ•°æ®é›†ä¸­æœ‰ä¸¤åªä¼é¹…çš„ä½“é‡å’Œ/æˆ–é³çŠ¶è‚¢é•¿åº¦å€¼ç¼ºå¤±ï¼Œè€Œ ggplot2 åœ¨æ²¡æœ‰è¿™ä¸¤ä¸ªå€¼çš„æƒ…å†µä¸‹æ— æ³•åœ¨å›¾ä¸Šè¡¨ç¤ºå®ƒä»¬ã€‚å’Œ R ä¸€æ ·ï¼Œggplot2 ä¹Ÿéµå¾ªè¿™æ ·çš„ç†å¿µï¼šç¼ºå¤±å€¼ä¸åº”è¯¥æ‚„æ— å£°æ¯åœ°æ¶ˆå¤±ã€‚è¿™ç§ç±»å‹çš„è­¦å‘Šå¯èƒ½æ˜¯ä½ åœ¨å¤„ç†çœŸå®æ•°æ®æ—¶æœ€å¸¸çœ‹åˆ°çš„è­¦å‘Šä¹‹ä¸€â€”â€”ç¼ºå¤±å€¼æ˜¯ä¸€ä¸ªéå¸¸æ™®éçš„é—®é¢˜ï¼Œä½ å°†åœ¨æœ¬ä¹¦ä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨ Chapter 18 ä¸­å­¦åˆ°æ›´å¤šç›¸å…³çŸ¥è¯†ã€‚å¯¹äºæœ¬ç« ä¸­ä½™ä¸‹çš„å›¾ï¼Œæˆ‘ä»¬å°†æŠ‘åˆ¶æ­¤è­¦å‘Šï¼Œè¿™æ ·å®ƒå°±ä¸ä¼šåœ¨æˆ‘ä»¬åˆ¶ä½œçš„æ¯ä¸€å¼ å›¾æ—è¾¹éƒ½æ‰“å°å‡ºæ¥ã€‚\n\n1.2.4 Adding aesthetics and layers\nScatterplots are useful for displaying the relationship between two numerical variables, but itâ€™s always a good idea to be skeptical of any apparent relationship between two variables and ask if there may be other variables that explain or change the nature of this apparent relationship. For example, does the relationship between flipper length and body mass differ by species? Letâ€™s incorporate species into our plot and see if this reveals any additional insights into the apparent relationship between these variables.\næ•£ç‚¹å›¾å¯¹äºå±•ç¤ºä¸¤ä¸ªæ•°å€¼å˜é‡ä¹‹é—´çš„å…³ç³»å¾ˆæœ‰ç”¨ï¼Œä½†å¯¹ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„ä»»ä½•æ˜æ˜¾å…³ç³»æŒæ€€ç–‘æ€åº¦æ€»æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå¹¶ä¸”åº”è¯¥æ¢ç©¶æ˜¯å¦è¿˜æœ‰å…¶ä»–å˜é‡å¯ä»¥è§£é‡Šæˆ–æ”¹å˜è¿™ç§æ˜æ˜¾å…³ç³»çš„æ€§è´¨ã€‚ä¾‹å¦‚ï¼Œé³çŠ¶è‚¢é•¿åº¦å’Œä½“é‡ä¹‹é—´çš„å…³ç³»æ˜¯å¦å› ç‰©ç§è€Œå¼‚ï¼Ÿè®©æˆ‘ä»¬å°†ç‰©ç§çº³å…¥æˆ‘ä»¬çš„å›¾ä¸­ï¼Œçœ‹çœ‹è¿™æ˜¯å¦èƒ½æ­ç¤ºå…³äºè¿™äº›å˜é‡ä¹‹é—´æ˜æ˜¾å…³ç³»çš„æ›´å¤šè§è§£ã€‚\nTo achieve this, will we need to modify the aesthetic or the geom? If you guessed â€œin the aesthetic mapping, inside of aes()â€, youâ€™re already getting the hang of creating data visualizations with ggplot2! And if not, donâ€™t worry. Throughout the book you will make many more ggplots and have many more opportunities to check your intuition as you make them.\nä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹ç¾å­¦è¿˜æ˜¯å‡ ä½•å¯¹è±¡ï¼Ÿå¦‚æœä½ çŒœçš„æ˜¯â€œåœ¨ç¾å­¦æ˜ å°„ä¸­ï¼Œå³ aes() å†…éƒ¨â€ï¼Œé‚£ä¹ˆä½ å·²ç»å¼€å§‹æŒæ¡ç”¨ ggplot2 åˆ›å»ºæ•°æ®å¯è§†åŒ–çš„çªé—¨äº†ï¼å¦‚æœæ²¡çŒœå¯¹ï¼Œä¹Ÿåˆ«æ‹…å¿ƒã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œä½ å°†åˆ¶ä½œæ›´å¤šçš„ ggplot å›¾ï¼Œå¹¶åœ¨åˆ¶ä½œè¿‡ç¨‹ä¸­æœ‰æ›´å¤šæœºä¼šæ¥æ£€éªŒä½ çš„ç›´è§‰ã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point()\n\n\n\n\n\n\n\nWhen a categorical variable is mapped to an aesthetic, ggplot2 will automatically assign a unique value of the aesthetic (here a unique color) to each unique level of the variable (each of the three species), a process known as scaling. ggplot2 will also add a legend that explains which values correspond to which levels.\nå½“ä¸€ä¸ªåˆ†ç±»å˜é‡è¢«æ˜ å°„åˆ°ä¸€ä¸ªç¾å­¦ä¸Šæ—¶ï¼Œggplot2 ä¼šè‡ªåŠ¨ä¸ºè¯¥å˜é‡çš„æ¯ä¸ªå”¯ä¸€æ°´å¹³ï¼ˆè¿™é‡Œæ˜¯ä¸‰ä¸ªç‰©ç§ä¸­çš„æ¯ä¸€ä¸ªï¼‰åˆ†é…ä¸€ä¸ªè¯¥ç¾å­¦çš„å”¯ä¸€å€¼ï¼ˆè¿™é‡Œæ˜¯å”¯ä¸€çš„é¢œè‰²ï¼‰ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºæ ‡åº¦å˜æ¢ (scaling)ã€‚ggplot2 è¿˜ä¼šæ·»åŠ ä¸€ä¸ªå›¾ä¾‹ï¼Œè§£é‡Šå“ªäº›å€¼å¯¹åº”å“ªäº›æ°´å¹³ã€‚\nNow letâ€™s add one more layer: a smooth curve displaying the relationship between body mass and flipper length. Before you proceed, refer back to the code above, and think about how we can add this to our existing plot.\nç°åœ¨æˆ‘ä»¬å†åŠ ä¸€ä¸ªå›¾å±‚ï¼šä¸€æ¡å¹³æ»‘æ›²çº¿ï¼Œç”¨äºæ˜¾ç¤ºä½“é‡å’Œé³çŠ¶è‚¢é•¿åº¦ä¹‹é—´çš„å…³ç³»ã€‚åœ¨ç»§ç»­ä¹‹å‰ï¼Œè¯·å›é¡¾ä¸Šé¢çš„ä»£ç ï¼Œå¹¶æ€è€ƒæˆ‘ä»¬å¦‚ä½•å°†è¿™ä¸ªå›¾å±‚æ·»åŠ åˆ°ç°æœ‰çš„å›¾ä¸­ã€‚\nSince this is a new geometric object representing our data, we will add a new geom as a layer on top of our point geom: geom_smooth(). And we will specify that we want to draw the line of best fit based on a linear model with method = \"lm\".\nç”±äºè¿™æ˜¯ä¸€ä¸ªä»£è¡¨æˆ‘ä»¬æ•°æ®çš„æ–°çš„å‡ ä½•å¯¹è±¡ï¼Œæˆ‘ä»¬å°†åœ¨ç‚¹å‡ ä½•å¯¹è±¡ä¹‹ä¸Šæ·»åŠ ä¸€ä¸ªæ–°çš„å‡ ä½•å¯¹è±¡å›¾å±‚ï¼šgeom_smooth()ã€‚å¹¶ä¸”æˆ‘ä»¬å°†æŒ‡å®šæˆ‘ä»¬å¸Œæœ›åŸºäºä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼ˆlinear modelï¼‰æ¥ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿ï¼Œå³è®¾ç½® method = \"lm\"ã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nWe have successfully added lines, but this plot doesnâ€™t look like the plot from Section 1.2.2, which only has one line for the entire dataset as opposed to separate lines for each of the penguin species.\næˆ‘ä»¬æˆåŠŸåœ°æ·»åŠ äº†çº¿ï¼Œä½†è¿™å¼ å›¾çœ‹èµ·æ¥ä¸åƒ Section 1.2.2 ä¸­çš„é‚£å¼ å›¾ï¼Œé‚£å¼ å›¾åªæœ‰ä¸€æ¡è´¯ç©¿æ•´ä¸ªæ•°æ®é›†çš„çº¿ï¼Œè€Œä¸æ˜¯ä¸ºæ¯ç§ä¼é¹…éƒ½ç”»ä¸€æ¡å•ç‹¬çš„çº¿ã€‚\nWhen aesthetic mappings are defined in ggplot(), at the global level, theyâ€™re passed down to each of the subsequent geom layers of the plot. However, each geom function in ggplot2 can also take a mapping argument, which allows for aesthetic mappings at the local level that are added to those inherited from the global level. Since we want points to be colored based on species but donâ€™t want the lines to be separated out for them, we should specify color = species for geom_point() only.\nå½“ç¾å­¦æ˜ å°„åœ¨ ggplot() ä¸­å®šä¹‰æ—¶ï¼Œå³åœ¨å…¨å±€å±‚é¢ï¼Œå®ƒä»¬ä¼šè¢«ä¼ é€’ç»™å›¾ä¸­åç»­çš„æ¯ä¸ªå‡ ä½•å¯¹è±¡å›¾å±‚ã€‚ç„¶è€Œï¼Œggplot2 ä¸­çš„æ¯ä¸ªå‡ ä½•å‡½æ•°ä¹Ÿå¯ä»¥æ¥å—ä¸€ä¸ª mapping å‚æ•°ï¼Œè¿™å…è®¸åœ¨å±€éƒ¨å±‚é¢è¿›è¡Œç¾å­¦æ˜ å°„ï¼Œè¿™äº›æ˜ å°„ä¼šæ·»åŠ åˆ°ä»å…¨å±€å±‚é¢ç»§æ‰¿çš„æ˜ å°„ä¹‹ä¸Šã€‚å› ä¸ºæˆ‘ä»¬å¸Œæœ›ç‚¹æ ¹æ®ç‰©ç§ç€è‰²ï¼Œä½†ä¸å¸Œæœ›çº¿ä¹Ÿå› æ­¤åˆ†å¼€ï¼Œæ‰€ä»¥æˆ‘ä»¬åº”è¯¥åªä¸º geom_point() æŒ‡å®š color = speciesã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nVoila! We have something that looks very much like our ultimate goal, though itâ€™s not yet perfect. We still need to use different shapes for each species of penguins and improve labels.\nç§ï¼æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªéå¸¸æ¥è¿‘æˆ‘ä»¬æœ€ç»ˆç›®æ ‡çš„å›¾ï¼Œå°½ç®¡è¿˜ä¸å®Œç¾ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¸ºæ¯ç§ä¼é¹…ä½¿ç”¨ä¸åŒçš„å½¢çŠ¶ï¼Œå¹¶æ”¹è¿›æ ‡ç­¾ã€‚\nItâ€™s generally not a good idea to represent information using only colors on a plot, as people perceive colors differently due to color blindness or other color vision differences. Therefore, in addition to color, we can also map species to the shape aesthetic.\né€šå¸¸æ¥è¯´ï¼Œåœ¨å›¾ä¸Šä»…ç”¨é¢œè‰²æ¥è¡¨ç¤ºä¿¡æ¯ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå› ä¸ºç”±äºè‰²ç›²æˆ–å…¶ä»–è‰²è§‰å·®å¼‚ï¼Œäººä»¬å¯¹é¢œè‰²çš„æ„ŸçŸ¥æ˜¯ä¸åŒçš„ã€‚å› æ­¤ï¼Œé™¤äº†é¢œè‰²ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°† species æ˜ å°„åˆ° shape ç¾å­¦ä¸Šã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nNote that the legend is automatically updated to reflect the different shapes of the points as well.\nè¯·æ³¨æ„ï¼Œå›¾ä¾‹ä¹Ÿä¼šè‡ªåŠ¨æ›´æ–°ï¼Œä»¥åæ˜ ç‚¹çš„ä¸åŒå½¢çŠ¶ã€‚\nAnd finally, we can improve the labels of our plot using the labs() function in a new layer. Some of the arguments to labs() might be self explanatory: title adds a title and subtitle adds a subtitle to the plot. Other arguments match the aesthetic mappings, x is the x-axis label, y is the y-axis label, and color and shape define the label for the legend. In addition, we can improve the color palette to be colorblind safe with the scale_color_colorblind() function from the ggthemes package.\næœ€åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨ä¸€ä¸ªæ–°å›¾å±‚ä¸­ä½¿ç”¨ labs() å‡½æ•°æ¥æ”¹è¿›æˆ‘ä»¬å›¾çš„æ ‡ç­¾ã€‚labs() çš„ä¸€äº›å‚æ•°å¯èƒ½æ˜¯ä¸è¨€è‡ªæ˜çš„ï¼štitle ä¸ºå›¾æ·»åŠ ä¸€ä¸ªæ ‡é¢˜ï¼Œsubtitle æ·»åŠ ä¸€ä¸ªå‰¯æ ‡é¢˜ã€‚å…¶ä»–å‚æ•°ä¸ç¾å­¦æ˜ å°„ç›¸å¯¹åº”ï¼Œx æ˜¯ x è½´çš„æ ‡ç­¾ï¼Œy æ˜¯ y è½´çš„æ ‡ç­¾ï¼Œè€Œ color å’Œ shape å®šä¹‰äº†å›¾ä¾‹çš„æ ‡ç­¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ ggthemes åŒ…ä¸­çš„ scale_color_colorblind() å‡½æ•°æ¥æ”¹è¿›è°ƒè‰²æ¿ï¼Œä½¿å…¶å¯¹è‰²ç›²å‹å¥½ã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Body mass and flipper length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Flipper length (mm)\", y = \"Body mass (g)\",\n    color = \"Species\", shape = \"Species\"\n  ) +\n  scale_color_colorblind()\n\n\n\n\n\n\n\nWe finally have a plot that perfectly matches our â€œultimate goalâ€!\næˆ‘ä»¬ç»ˆäºå¾—åˆ°äº†ä¸€ä¸ªä¸æˆ‘ä»¬çš„â€œæœ€ç»ˆç›®æ ‡â€å®Œå…¨åŒ¹é…çš„å›¾ï¼\n\n1.2.5 Exercises\n\nHow many rows are in penguins? How many columns?penguins æ•°æ®æ¡†ä¸­æœ‰å¤šå°‘è¡Œï¼Ÿå¤šå°‘åˆ—ï¼Ÿ\nWhat does the bill_depth_mm variable in the penguins data frame describe? Read the help for ?penguins to find out.penguins æ•°æ®æ¡†ä¸­çš„ bill_depth_mm å˜é‡æè¿°äº†ä»€ä¹ˆï¼Ÿé˜…è¯» ?penguins çš„å¸®åŠ©æ–‡æ¡£æ¥æ‰¾å‡ºç­”æ¡ˆã€‚\nMake a scatterplot of bill_depth_mm vs.Â bill_length_mm. That is, make a scatterplot with bill_depth_mm on the y-axis and bill_length_mm on the x-axis. Describe the relationship between these two variables.\nåˆ¶ä½œä¸€ä¸ª bill_depth_mm å¯¹ bill_length_mm çš„æ•£ç‚¹å›¾ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåˆ¶ä½œä¸€ä¸ªä»¥ bill_depth_mm ä¸º y è½´ï¼Œbill_length_mm ä¸º x è½´çš„æ•£ç‚¹å›¾ã€‚æè¿°è¿™ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»ã€‚\nWhat happens if you make a scatterplot of species vs.Â bill_depth_mm? What might be a better choice of geom?\nå¦‚æœä½ åˆ¶ä½œä¸€ä¸ª species å¯¹ bill_depth_mm çš„æ•£ç‚¹å›¾ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿä»€ä¹ˆå¯èƒ½æ˜¯æ›´å¥½çš„å‡ ä½•å¯¹è±¡é€‰æ‹©ï¼Ÿ\n\nWhy does the following give an error and how would you fix it?\nä¸ºä»€ä¹ˆä¸‹é¢çš„ä»£ç ä¼šæŠ¥é”™ï¼Ÿä½ å°†å¦‚ä½•ä¿®å¤å®ƒï¼Ÿ\n\nggplot(data = penguins) +\n  geom_point()\n\n\nWhat does the na.rm argument do in geom_point()? What is the default value of the argument? Create a scatterplot where you successfully use this argument set to TRUE.\ngeom_point()ä¸­çš„na.rmå‚æ•°æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿè¯¥å‚æ•°çš„é»˜è®¤å€¼æ˜¯ä»€ä¹ˆï¼Ÿåˆ›å»ºä¸€ä¸ªæ•£ç‚¹å›¾ï¼Œåœ¨å…¶ä¸­æˆåŠŸåœ°å°†æ­¤å‚æ•°è®¾ç½®ä¸ºTRUE`ã€‚\nAdd the following caption to the plot you made in the previous exercise: â€œData come from the palmerpenguins package.â€ Hint: Take a look at the documentation for labs().\nåœ¨ä½ ä¸Šä¸€ä¸ªç»ƒä¹ ä¸­åˆ¶ä½œçš„å›¾ä¸Šæ·»åŠ ä»¥ä¸‹æ ‡é¢˜ï¼šâ€œæ•°æ®æ¥è‡ª palmerpenguins åŒ…ã€‚â€ æç¤ºï¼šæŸ¥çœ‹ labs() çš„æ–‡æ¡£ã€‚\n\nRecreate the following visualization. What aesthetic should bill_depth_mm be mapped to? And should it be mapped at the global level or at the geom level?\né‡æ–°åˆ›å»ºä»¥ä¸‹å¯è§†åŒ–å›¾ã€‚bill_depth_mm åº”è¯¥æ˜ å°„åˆ°å“ªä¸ªç¾å­¦ä¸Šï¼Ÿå®ƒåº”è¯¥åœ¨å…¨å±€å±‚é¢è¿˜æ˜¯åœ¨å‡ ä½•å¯¹è±¡å±‚é¢è¿›è¡Œæ˜ å°„ï¼Ÿ\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n    geom_point(aes(color = bill_depth_mm)) +\n    geom_smooth()\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n#&gt; Warning: Removed 2 rows containing non-finite outside the scale range\n#&gt; (`stat_smooth()`).\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n\n\nRun this code in your head and predict what the output will look like. Then, run the code in R and check your predictions.\nåœ¨è„‘æµ·ä¸­è¿è¡Œè¿™æ®µä»£ç ï¼Œå¹¶é¢„æµ‹è¾“å‡ºä¼šæ˜¯ä»€ä¹ˆæ ·å­ã€‚ç„¶åï¼Œåœ¨ R ä¸­è¿è¡Œä»£ç å¹¶æ£€æŸ¥ä½ çš„é¢„æµ‹ã€‚\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = island)\n) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\nWill these two graphs look different? Why/why not? è¿™ä¸¤å¼ å›¾çœ‹èµ·æ¥ä¼šæœ‰æ‰€ä¸åŒå—ï¼Ÿä¸ºä»€ä¹ˆ/ä¸ºä»€ä¹ˆä¸ï¼Ÿ\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper\\_length\\_mm, y = body\\_mass\\_g)\n) +\n  geom\\_point() +\n  geom\\_smooth()\n\nggplot() +\n  geom\\_point(\n    data = penguins,\n    mapping = aes(x = flipper\\_length\\_mm, y = body\\_mass\\_g)\n  ) +\n  geom\\_smooth(\n    data = penguins,\n    mapping = aes(x = flipper\\_length\\_mm, y = body\\_mass\\_g)\n  )\n```\n:::",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggplot2-calls",
    "href": "data-visualize.html#sec-ggplot2-calls",
    "title": "1Â  Data visualization",
    "section": "\n1.3 ggplot2 calls",
    "text": "1.3 ggplot2 calls\nAs we move on from these introductory sections, weâ€™ll transition to a more concise expression of ggplot2 code. So far weâ€™ve been very explicit, which is helpful when you are learning:\néšç€æˆ‘ä»¬ä»è¿™äº›ä»‹ç»æ€§ç« èŠ‚ç»§ç»­å‰è¿›ï¼Œæˆ‘ä»¬å°†è½¬å‘ä¸€ç§æ›´ç®€æ´çš„ ggplot2 ä»£ç è¡¨è¾¾æ–¹å¼ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´éå¸¸æ˜ç¡®ï¼Œè¿™åœ¨å­¦ä¹ æ—¶å¾ˆæœ‰å¸®åŠ©ï¼š\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n\nTypically, the first one or two arguments to a function are so important that you should know them by heart. The first two arguments to ggplot() are data and mapping, in the remainder of the book, we wonâ€™t supply those names. That saves typing, and, by reducing the amount of extra text, makes it easier to see whatâ€™s different between plots. Thatâ€™s a really important programming concern that weâ€™ll come back to in Chapter 25.\né€šå¸¸ï¼Œå‡½æ•°çš„å‰ä¸€ä¸¤ä¸ªå‚æ•°éå¸¸é‡è¦ï¼Œä½ åº”è¯¥ç†Ÿè®°äºå¿ƒã€‚ggplot() çš„å‰ä¸¤ä¸ªå‚æ•°æ˜¯ data å’Œ mappingï¼Œåœ¨æœ¬ä¹¦çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä¸å†æä¾›è¿™äº›åç§°ã€‚è¿™æ ·å¯ä»¥èŠ‚çœæ‰“å­—æ—¶é—´ï¼Œå¹¶ä¸”é€šè¿‡å‡å°‘é¢å¤–çš„æ–‡æœ¬é‡ï¼Œæ›´å®¹æ˜“çœ‹å‡ºå›¾ä¸å›¾ä¹‹é—´çš„åŒºåˆ«ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„ç¼–ç¨‹è€ƒé‡ï¼Œæˆ‘ä»¬å°†åœ¨ Chapter 25 ä¸­å†æ¬¡è®¨è®ºã€‚\nRewriting the previous plot more concisely yields:\næ›´ç®€æ´åœ°é‡å†™ä¹‹å‰çš„å›¾ä¼šå¾—åˆ°ï¼š\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()\n\nIn the future, youâ€™ll also learn about the pipe, |&gt;, which will allow you to create that plot with:\nå°†æ¥ï¼Œä½ è¿˜ä¼šå­¦åˆ°ç®¡é“ç¬¦ |&gt;ï¼Œå®ƒå°†å…è®¸ä½ ç”¨ä»¥ä¸‹æ–¹å¼åˆ›å»ºè¯¥å›¾ï¼š\n\npenguins |&gt; \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#visualizing-distributions",
    "href": "data-visualize.html#visualizing-distributions",
    "title": "1Â  Data visualization",
    "section": "\n1.4 Visualizing distributions",
    "text": "1.4 Visualizing distributions\nHow you visualize the distribution of a variable depends on the type of variable: categorical or numerical.\nå¦‚ä½•å¯è§†åŒ–ä¸€ä¸ªå˜é‡çš„åˆ†å¸ƒï¼Œå–å†³äºè¯¥å˜é‡çš„ç±»å‹ï¼šæ˜¯åˆ†ç±»å˜é‡è¿˜æ˜¯æ•°å€¼å˜é‡ã€‚\n\n1.4.1 A categorical variable\nA variable is categorical if it can only take one of a small set of values. To examine the distribution of a categorical variable, you can use a bar chart. The height of the bars displays how many observations occurred with each x value.\nå¦‚æœä¸€ä¸ªå˜é‡åªèƒ½å–ä¸€å°ç»„å€¼ä¸­çš„ä¸€ä¸ªï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯åˆ†ç±» (categorical) å˜é‡ã€‚è¦æ£€æŸ¥åˆ†ç±»å˜é‡çš„åˆ†å¸ƒï¼Œä½ å¯ä»¥ä½¿ç”¨æ¡å½¢å›¾ã€‚æ¡å½¢çš„é«˜åº¦æ˜¾ç¤ºäº†æ¯ä¸ª x å€¼å‡ºç°äº†å¤šå°‘æ¬¡è§‚æµ‹ã€‚\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\n\n\n\nIn bar plots of categorical variables with non-ordered levels, like the penguin species above, itâ€™s often preferable to reorder the bars based on their frequencies. Doing so requires transforming the variable to a factor (how R handles categorical data) and then reordering the levels of that factor.\nåœ¨å¤„ç†å…·æœ‰æ— åºæ°´å¹³çš„åˆ†ç±»å˜é‡çš„æ¡å½¢å›¾æ—¶ï¼Œæ¯”å¦‚ä¸Šé¢çš„ä¼é¹… speciesï¼Œé€šå¸¸æœ€å¥½æ ¹æ®å®ƒä»¬çš„é¢‘ç‡å¯¹æ¡å½¢è¿›è¡Œé‡æ–°æ’åºã€‚è¿™æ ·åšéœ€è¦å°†å˜é‡è½¬æ¢ä¸ºå› å­ï¼ˆR å¤„ç†åˆ†ç±»æ•°æ®çš„æ–¹å¼ï¼‰ï¼Œç„¶åé‡æ–°æ’åˆ—è¯¥å› å­çš„æ°´å¹³ã€‚\n\nggplot(penguins, aes(x = fct_infreq(species))) +\n  geom_bar()\n\n\n\n\n\n\n\nYou will learn more about factors and functions for dealing with factors (like fct_infreq() shown above) in Chapter 16.\nä½ å°†åœ¨ Chapter 16 ä¸­å­¦ä¹ æ›´å¤šå…³äºå› å­ä»¥åŠå¤„ç†å› å­çš„å‡½æ•°ï¼ˆå¦‚ä¸Šé¢å±•ç¤ºçš„ fct_infreq()ï¼‰çš„çŸ¥è¯†ã€‚\n\n1.4.2 A numerical variable\nA variable is numerical (or quantitative) if it can take on a wide range of numerical values, and it is sensible to add, subtract, or take averages with those values. Numerical variables can be continuous or discrete.\nå¦‚æœä¸€ä¸ªå˜é‡å¯ä»¥å–å¹¿æ³›çš„æ•°å€¼ï¼Œå¹¶ä¸”å¯¹è¿™äº›å€¼è¿›è¡ŒåŠ ã€å‡æˆ–æ±‚å¹³å‡æ˜¯æœ‰æ„ä¹‰çš„ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯æ•°å€¼ (numerical)ï¼ˆæˆ–å®šé‡ï¼‰å˜é‡ã€‚æ•°å€¼å˜é‡å¯ä»¥æ˜¯è¿ç»­çš„æˆ–ç¦»æ•£çš„ã€‚\nOne commonly used visualization for distributions of continuous variables is a histogram.\nä¸€ç§å¸¸ç”¨äºå¯è§†åŒ–è¿ç»­å˜é‡åˆ†å¸ƒçš„å›¾æ˜¯ç›´æ–¹å›¾ã€‚\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 200)\n\n\n\n\n\n\n\nA histogram divides the x-axis into equally spaced bins and then uses the height of a bar to display the number of observations that fall in each bin. In the graph above, the tallest bar shows that 39 observations have a body_mass_g value between 3,500 and 3,700 grams, which are the left and right edges of the bar.\nç›´æ–¹å›¾å°† x è½´åˆ’åˆ†ä¸ºç­‰å®½çš„åŒºé—´ï¼ˆbinsï¼‰ï¼Œç„¶åç”¨æ¡å½¢çš„é«˜åº¦æ¥æ˜¾ç¤ºè½å…¥æ¯ä¸ªåŒºé—´çš„è§‚æµ‹æ•°é‡ã€‚åœ¨ä¸Šå›¾ä¸­ï¼Œæœ€é«˜çš„æ¡å½¢æ˜¾ç¤ºæœ‰ 39 ä¸ªè§‚æµ‹çš„ body_mass_g å€¼åœ¨ 3,500 åˆ° 3,700 å…‹ä¹‹é—´ï¼Œè¿™åˆ†åˆ«æ˜¯è¯¥æ¡å½¢çš„å·¦å³è¾¹ç•Œã€‚\nYou can set the width of the intervals in a histogram with the binwidth argument, which is measured in the units of the x variable. You should always explore a variety of binwidths when working with histograms, as different binwidths can reveal different patterns. In the plots below a binwidth of 20 is too narrow, resulting in too many bars, making it difficult to determine the shape of the distribution. Similarly, a binwidth of 2,000 is too high, resulting in all data being binned into only three bars, and also making it difficult to determine the shape of the distribution. A binwidth of 200 provides a sensible balance.\nä½ å¯ä»¥ä½¿ç”¨ binwidth å‚æ•°æ¥è®¾ç½®ç›´æ–¹å›¾ä¸­åŒºé—´çš„å®½åº¦ï¼Œè¯¥å®½åº¦ä»¥ x å˜é‡çš„å•ä½æ¥è¡¡é‡ã€‚åœ¨ä½¿ç”¨ç›´æ–¹å›¾æ—¶ï¼Œä½ åº”è¯¥æ€»æ˜¯å°è¯•ä¸åŒçš„åŒºé—´å®½åº¦ï¼Œå› ä¸ºä¸åŒçš„å®½åº¦å¯èƒ½ä¼šæ­ç¤ºå‡ºä¸åŒçš„æ¨¡å¼ã€‚åœ¨ä¸‹é¢çš„å›¾ä¸­ï¼Œ20 çš„åŒºé—´å®½åº¦å¤ªçª„ï¼Œå¯¼è‡´æ¡å½¢è¿‡å¤šï¼Œéš¾ä»¥ç¡®å®šåˆ†å¸ƒçš„å½¢çŠ¶ã€‚åŒæ ·ï¼Œ2000 çš„åŒºé—´å®½åº¦å¤ªé«˜ï¼Œå¯¼è‡´æ‰€æœ‰æ•°æ®åªè¢«åˆ†åˆ°ä¸‰ä¸ªæ¡å½¢ä¸­ï¼Œä¹Ÿä½¿å¾—ç¡®å®šåˆ†å¸ƒçš„å½¢çŠ¶å˜å¾—å›°éš¾ã€‚200 çš„åŒºé—´å®½åº¦æä¾›äº†ä¸€ä¸ªåˆç†çš„å¹³è¡¡ã€‚\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 20)\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 2000)\n\n\n\n\n\n\n\n\n\n\nAn alternative visualization for distributions of numerical variables is a density plot. A density plot is a smoothed-out version of a histogram and a practical alternative, particularly for continuous data that comes from an underlying smooth distribution. We wonâ€™t go into how geom_density() estimates the density (you can read more about that in the function documentation), but letâ€™s explain how the density curve is drawn with an analogy. Imagine a histogram made out of wooden blocks. Then, imagine that you drop a cooked spaghetti string over it. The shape the spaghetti will take draped over blocks can be thought of as the shape of the density curve. It shows fewer details than a histogram but can make it easier to quickly glean the shape of the distribution, particularly with respect to modes and skewness.\næ•°å€¼å˜é‡åˆ†å¸ƒçš„å¦ä¸€ç§å¯è§†åŒ–æ–¹æ³•æ˜¯å¯†åº¦å›¾ã€‚å¯†åº¦å›¾æ˜¯ç›´æ–¹å›¾çš„å¹³æ»‘ç‰ˆæœ¬ï¼Œæ˜¯ä¸€ç§å®ç”¨çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå°¤å…¶é€‚ç”¨äºæ¥è‡ªåº•å±‚å¹³æ»‘åˆ†å¸ƒçš„è¿ç»­æ•°æ®ã€‚æˆ‘ä»¬ä¸ä¼šæ·±å…¥æ¢è®¨ geom_density() å¦‚ä½•ä¼°è®¡å¯†åº¦ï¼ˆä½ å¯ä»¥åœ¨å‡½æ•°æ–‡æ¡£ä¸­äº†è§£æ›´å¤šä¿¡æ¯ï¼‰ï¼Œä½†è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç±»æ¯”æ¥è§£é‡Šå¯†åº¦æ›²çº¿æ˜¯å¦‚ä½•ç»˜åˆ¶çš„ã€‚æƒ³è±¡ä¸€ä¸ªç”±æœ¨å—ç»„æˆçš„ç›´æ–¹å›¾ã€‚ç„¶åï¼Œæƒ³è±¡ä½ æŠŠä¸€æ ¹ç…®ç†Ÿçš„æ„å¤§åˆ©é¢æ¡æ‰”åœ¨å®ƒä¸Šé¢ã€‚æ„å¤§åˆ©é¢æ¡æ­åœ¨æœ¨å—ä¸Šå½¢æˆçš„å½¢çŠ¶å¯ä»¥è¢«çœ‹ä½œæ˜¯å¯†åº¦æ›²çº¿çš„å½¢çŠ¶ã€‚å®ƒæ¯”ç›´æ–¹å›¾æ˜¾ç¤ºçš„ç»†èŠ‚å°‘ï¼Œä½†å¯ä»¥æ›´å®¹æ˜“åœ°å¿«é€Ÿäº†è§£åˆ†å¸ƒçš„å½¢çŠ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼—æ•°å’Œååº¦æ–¹é¢ã€‚\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_density()\n#&gt; Warning: Removed 2 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\n\n1.4.3 Exercises\n\nMake a bar plot of species of penguins, where you assign species to the y aesthetic. How is this plot different?\nåˆ¶ä½œä¸€ä¸ª penguins ä¸­ species çš„æ¡å½¢å›¾ï¼Œå…¶ä¸­ä½ å°† species èµ‹ç»™ y ç¾å­¦ã€‚è¿™ä¸ªå›¾æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ\n\nHow are the following two plots different? Which aesthetic, color or fill, is more useful for changing the color of bars?\nä¸‹é¢è¿™ä¸¤ä¸ªå›¾æœ‰ä»€ä¹ˆä¸åŒï¼Ÿå“ªä¸ªç¾å­¦ï¼Œcolor è¿˜æ˜¯ fillï¼Œå¯¹äºæ”¹å˜æ¡å½¢çš„é¢œè‰²æ›´æœ‰ç”¨ï¼Ÿ\n\nggplot(penguins, aes(x = species)) +\n  geom\\_bar(color = \"red\")\n\nggplot(penguins, aes(x = species)) +\n  geom\\_bar(fill = \"red\")\n\n\nWhat does the bins argument in geom_histogram() do?geom_histogram() ä¸­çš„ bins å‚æ•°æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ\nMake a histogram of the carat variable in the diamonds dataset that is available when you load the tidyverse package. Experiment with different binwidths. What binwidth reveals the most interesting patterns?\nåˆ¶ä½œä¸€ä¸ª diamonds æ•°æ®é›†ä¸­ carat å˜é‡çš„ç›´æ–¹å›¾ï¼Œè¯¥æ•°æ®é›†åœ¨åŠ è½½ tidyverse åŒ…æ—¶å¯ç”¨ã€‚å°è¯•ä¸åŒçš„åŒºé—´å®½åº¦ã€‚å“ªä¸ªåŒºé—´å®½åº¦æ­ç¤ºäº†æœ€æœ‰è¶£çš„æ¨¡å¼ï¼Ÿ",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#visualizing-relationships",
    "href": "data-visualize.html#visualizing-relationships",
    "title": "1Â  Data visualization",
    "section": "\n1.5 Visualizing relationships",
    "text": "1.5 Visualizing relationships\nTo visualize a relationship we need to have at least two variables mapped to aesthetics of a plot. In the following sections you will learn about commonly used plots for visualizing relationships between two or more variables and the geoms used for creating them.\nè¦å¯è§†åŒ–ä¸€ä¸ªå…³ç³»ï¼Œæˆ‘ä»¬éœ€è¦å°†è‡³å°‘ä¸¤ä¸ªå˜é‡æ˜ å°„åˆ°å›¾çš„ç¾å­¦ä¸Šã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œä½ å°†å­¦ä¹ åˆ°å¸¸ç”¨äºå¯è§†åŒ–ä¸¤ä¸ªæˆ–å¤šä¸ªå˜é‡ä¹‹é—´å…³ç³»çš„å›¾ï¼Œä»¥åŠç”¨äºåˆ›å»ºå®ƒä»¬çš„å‡ ä½•å¯¹è±¡ã€‚\n\n1.5.1 A numerical and a categorical variable\nTo visualize the relationship between a numerical and a categorical variable we can use side-by-side box plots. A boxplot is a type of visual shorthand for measures of position (percentiles) that describe a distribution. It is also useful for identifying potential outliers. As shown in FigureÂ 1.1, each boxplot consists of:\nä¸ºäº†å¯è§†åŒ–æ•°å€¼å˜é‡å’Œåˆ†ç±»å˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¹¶æ’çš„ç®±çº¿å›¾ã€‚ç®±çº¿å›¾ (boxplot) æ˜¯ä¸€ç§æè¿°åˆ†å¸ƒä½ç½®åº¦é‡ï¼ˆç™¾åˆ†ä½æ•°ï¼‰çš„è§†è§‰ç®€å†™ã€‚å®ƒå¯¹äºè¯†åˆ«æ½œåœ¨çš„å¼‚å¸¸å€¼ä¹Ÿå¾ˆæœ‰ç”¨ã€‚å¦‚ FigureÂ 1.1 æ‰€ç¤ºï¼Œæ¯ä¸ªç®±çº¿å›¾éƒ½ç”±ä»¥ä¸‹å‡ éƒ¨åˆ†ç»„æˆï¼š\n- A box that indicates the range of the middle half of the data, a distance known as the interquartile range (IQR), stretching from the 25th percentile of the distribution to the 75th percentile. In the middle of the box is a line that displays the median, i.e.Â 50th percentile, of the distribution. These three lines give you a sense of the spread of the distribution and whether or not the distribution is symmetric about the median or skewed to one side.\n\nä¸€ä¸ªç®±ä½“ï¼Œè¡¨ç¤ºæ•°æ®ä¸­é—´ä¸€åŠçš„èŒƒå›´ï¼Œè¿™ä¸ªè·ç¦»è¢«ç§°ä¸ºå››åˆ†ä½è· (IQR)ï¼Œä»åˆ†å¸ƒçš„ç¬¬ 25 ç™¾åˆ†ä½æ•°å»¶ä¼¸åˆ°ç¬¬ 75 ç™¾åˆ†ä½æ•°ã€‚ç®±ä½“ä¸­é—´æœ‰ä¸€æ¡çº¿ï¼Œæ˜¾ç¤ºåˆ†å¸ƒçš„ä¸­ä½æ•°ï¼Œå³ç¬¬ 50 ç™¾åˆ†ä½æ•°ã€‚è¿™ä¸‰æ¡çº¿è®©ä½ äº†è§£åˆ†å¸ƒçš„ç¦»æ•£ç¨‹åº¦ä»¥åŠåˆ†å¸ƒæ˜¯å¦å…³äºä¸­ä½æ•°å¯¹ç§°æˆ–åå‘ä¸€ä¾§ã€‚\n\n- Visual points that display observations that fall more than 1.5 times the IQR from either edge of the box. These outlying points are unusual so are plotted individually.\n\næ˜¾ç¤ºç¦»ç®±ä½“ä»»ä¸€è¾¹ç¼˜è¶…è¿‡ 1.5 å€ IQR çš„è§‚æµ‹å€¼çš„è§†è§‰ç‚¹ã€‚è¿™äº›ç¦»ç¾¤ç‚¹æ˜¯ä¸å¯»å¸¸çš„ï¼Œæ‰€ä»¥è¢«å•ç‹¬ç»˜åˆ¶å‡ºæ¥ã€‚\n\n- A line (or whisker) that extends from each end of the box and goes to the farthest non-outlier point in the distribution.\n\nä»ç®±ä½“ä¸¤ç«¯å»¶ä¼¸å‡ºçš„çº¿ï¼ˆæˆ–é¡»ï¼‰ï¼Œä¸€ç›´å»¶ä¼¸åˆ°åˆ†å¸ƒä¸­æœ€è¿œçš„éç¦»ç¾¤ç‚¹ã€‚\n\n\n\n\n\n\n\n\nFigureÂ 1.1: Diagram depicting how a boxplot is created. æç»˜ç®±çº¿å›¾å¦‚ä½•åˆ›å»ºçš„å›¾ç¤ºã€‚\n\n\n\n\nLetâ€™s take a look at the distribution of body mass by species using geom_boxplot():\nè®©æˆ‘ä»¬ä½¿ç”¨ geom_boxplot() æ¥æŸ¥çœ‹æŒ‰ç‰©ç§åˆ†çš„ä½“é‡åˆ†å¸ƒï¼š\n\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nAlternatively, we can make density plots with geom_density().\næˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ geom_density() åˆ¶ä½œå¯†åº¦å›¾ã€‚\n\nggplot(penguins, aes(x = body_mass_g, color = species)) +\n  geom_density(linewidth = 0.75)\n\n\n\n\n\n\n\nWeâ€™ve also customized the thickness of the lines using the linewidth argument in order to make them stand out a bit more against the background.\næˆ‘ä»¬è¿˜ä½¿ç”¨äº† linewidth å‚æ•°è‡ªå®šä¹‰äº†çº¿æ¡çš„ç²—ç»†ï¼Œä»¥ä¾¿å®ƒä»¬åœ¨èƒŒæ™¯ä¸­æ›´åŠ çªå‡ºã€‚\nAdditionally, we can map species to both color and fill aesthetics and use the alpha aesthetic to add transparency to the filled density curves. This aesthetic takes values between 0 (completely transparent) and 1 (completely opaque). In the following plot itâ€™s set to 0.5.\næ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥å°† species åŒæ—¶æ˜ å°„åˆ° color å’Œ fill ç¾å­¦ï¼Œå¹¶ä½¿ç”¨ alpha ç¾å­¦ä¸ºå¡«å……çš„å¯†åº¦æ›²çº¿æ·»åŠ é€æ˜åº¦ã€‚è¿™ä¸ªç¾å­¦çš„å€¼ä»‹äº 0ï¼ˆå®Œå…¨é€æ˜ï¼‰å’Œ 1ï¼ˆå®Œå…¨ä¸é€æ˜ï¼‰ä¹‹é—´ã€‚åœ¨ä¸‹é¢çš„å›¾ä¸­ï¼Œå®ƒè¢«è®¾ç½®ä¸º 0.5ã€‚\n\nggplot(penguins, aes(x = body_mass_g, color = species, fill = species)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nNote the terminology we have used here:\næ³¨æ„æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨çš„æœ¯è¯­ï¼š\n- We map variables to aesthetics if we want the visual attribute represented by that aesthetic to vary based on the values of that variable. - Otherwise, we set the value of an aesthetic.\n\nå¦‚æœæˆ‘ä»¬å¸Œæœ›ç”±æŸä¸ªç¾å­¦ä»£è¡¨çš„è§†è§‰å±æ€§æ ¹æ®æŸä¸ªå˜é‡çš„å€¼è€Œå˜åŒ–ï¼Œæˆ‘ä»¬å°±å°†å˜é‡æ˜ å°„åˆ°è¯¥ç¾å­¦ã€‚\nå¦åˆ™ï¼Œæˆ‘ä»¬å°±è®¾ç½®æŸä¸ªç¾å­¦çš„å€¼ã€‚\n\n1.5.2 Two categorical variables\nWe can use stacked bar plots to visualize the relationship between two categorical variables. For example, the following two stacked bar plots both display the relationship between island and species, or specifically, visualizing the distribution of species within each island.\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨å †å æ¡å½¢å›¾æ¥å¯è§†åŒ–ä¸¤ä¸ªåˆ†ç±»å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹ä¸¤ä¸ªå †å æ¡å½¢å›¾éƒ½æ˜¾ç¤ºäº† island å’Œ species ä¹‹é—´çš„å…³ç³»ï¼Œæˆ–è€…å…·ä½“æ¥è¯´ï¼Œå¯è§†åŒ–äº†æ¯ä¸ªå²›å±¿å†… species çš„åˆ†å¸ƒã€‚\nThe first plot shows the frequencies of each species of penguins on each island. The plot of frequencies shows that there are equal numbers of Adelies on each island. But we donâ€™t have a good sense of the percentage balance within each island.\nç¬¬ä¸€å¼ å›¾æ˜¾ç¤ºäº†æ¯ä¸ªå²›å±¿ä¸Šæ¯ç§ä¼é¹…çš„é¢‘ç‡ã€‚é¢‘ç‡å›¾æ˜¾ç¤ºï¼Œæ¯ä¸ªå²›å±¿ä¸Šçš„é˜¿å¾·åˆ©ä¼é¹…æ•°é‡ç›¸ç­‰ã€‚ä½†æˆ‘ä»¬æ— æ³•å¾ˆå¥½åœ°äº†è§£æ¯ä¸ªå²›å±¿å†…éƒ¨çš„ç™¾åˆ†æ¯”å¹³è¡¡ã€‚\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar()\n\n\n\n\n\n\n\nThe second plot, a relative frequency plot created by setting position = \"fill\" in the geom, is more useful for comparing species distributions across islands since itâ€™s not affected by the unequal numbers of penguins across the islands. Using this plot we can see that Gentoo penguins all live on Biscoe island and make up roughly 75% of the penguins on that island, Chinstrap all live on Dream island and make up roughly 50% of the penguins on that island, and Adelie live on all three islands and make up all of the penguins on Torgersen.\nç¬¬äºŒå¼ å›¾æ˜¯ä¸€ä¸ªç›¸å¯¹é¢‘ç‡å›¾ï¼Œé€šè¿‡åœ¨å‡ ä½•å¯¹è±¡ä¸­è®¾ç½® position = \"fill\" åˆ›å»ºï¼Œå®ƒåœ¨æ¯”è¾ƒä¸åŒå²›å±¿é—´çš„ç‰©ç§åˆ†å¸ƒæ—¶æ›´æœ‰ç”¨ï¼Œå› ä¸ºå®ƒä¸å—å„å²›å±¿ä¼é¹…æ•°é‡ä¸ç­‰çš„å½±å“ã€‚é€šè¿‡è¿™å¼ å›¾æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œé‡‘å›¾ä¼é¹…éƒ½ç”Ÿæ´»åœ¨æ¯”æ–¯ç§‘å²›ï¼Œçº¦å è¯¥å²›ä¼é¹…æ€»æ•°çš„ 75%ï¼›å¸½å¸¦ä¼é¹…éƒ½ç”Ÿæ´»åœ¨æ¢¦å¹»å²›ï¼Œçº¦å è¯¥å²›ä¼é¹…æ€»æ•°çš„ 50%ï¼›è€Œé˜¿å¾·åˆ©ä¼é¹…ç”Ÿæ´»åœ¨æ‰€æœ‰ä¸‰ä¸ªå²›å±¿ä¸Šï¼Œå¹¶ä¸”å äº†æ‰˜å°”æ£®å²›ä¸Šæ‰€æœ‰ä¼é¹…ã€‚\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nIn creating these bar charts, we map the variable that will be separated into bars to the x aesthetic, and the variable that will change the colors inside the bars to the fill aesthetic.\nåœ¨åˆ›å»ºè¿™äº›æ¡å½¢å›¾æ—¶ï¼Œæˆ‘ä»¬å°†è¦è¢«åˆ†æˆæ¡å½¢çš„å˜é‡æ˜ å°„åˆ° x ç¾å­¦ï¼Œå°†è¦æ”¹å˜æ¡å½¢å†…éƒ¨é¢œè‰²çš„å˜é‡æ˜ å°„åˆ° fill ç¾å­¦ã€‚\n\n1.5.3 Two numerical variables\nSo far youâ€™ve learned about scatterplots (created with geom_point()) and smooth curves (created with geom_smooth()) for visualizing the relationship between two numerical variables. A scatterplot is probably the most commonly used plot for visualizing the relationship between two numerical variables.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»å­¦ä¹ äº†ç”¨äºå¯è§†åŒ–ä¸¤ä¸ªæ•°å€¼å˜é‡ä¹‹é—´å…³ç³»çš„æ•£ç‚¹å›¾ï¼ˆç”¨ geom_point() åˆ›å»ºï¼‰å’Œå¹³æ»‘æ›²çº¿ï¼ˆç”¨ geom_smooth() åˆ›å»ºï¼‰ã€‚æ•£ç‚¹å›¾å¯èƒ½æ˜¯å¯è§†åŒ–ä¸¤ä¸ªæ•°å€¼å˜é‡ä¹‹é—´å…³ç³»æœ€å¸¸ç”¨çš„å›¾ã€‚\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\n\n\n\n\n\n\n1.5.4 Three or more variables\nAs we saw in Section 1.2.4, we can incorporate more variables into a plot by mapping them to additional aesthetics. For example, in the following scatterplot the colors of points represent species and the shapes of points represent islands.\næ­£å¦‚æˆ‘ä»¬åœ¨ Section 1.2.4 ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ›´å¤šå˜é‡æ˜ å°„åˆ°å…¶ä»–ç¾å­¦ä¸Šï¼Œå°†å®ƒä»¬èå…¥åˆ°å›¾ä¸­ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„æ•£ç‚¹å›¾ä¸­ï¼Œç‚¹çš„é¢œè‰²ä»£è¡¨ç‰©ç§ï¼Œç‚¹çš„å½¢çŠ¶ä»£è¡¨å²›å±¿ã€‚\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = island))\n\n\n\n\n\n\n\nHowever adding too many aesthetic mappings to a plot makes it cluttered and difficult to make sense of. Another way, which is particularly useful for categorical variables, is to split your plot into facets, subplots that each display one subset of the data.\nç„¶è€Œï¼Œå‘å›¾ä¸­æ·»åŠ å¤ªå¤šçš„ç¾å­¦æ˜ å°„ä¼šä½¿å…¶å˜å¾—æ‚ä¹±æ— ç« ï¼Œéš¾ä»¥ç†è§£ã€‚å¦ä¸€ç§æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹åˆ†ç±»å˜é‡å¾ˆæœ‰ç”¨ï¼Œå°±æ˜¯å°†ä½ çš„å›¾åˆ†å‰²æˆåˆ†é¢ (facets)ï¼Œå³æ¯ä¸ªå­å›¾æ˜¾ç¤ºæ•°æ®çš„ä¸€ä¸ªå­é›†ã€‚\nTo facet your plot by a single variable, use facet_wrap(). The first argument of facet_wrap() is a formula3, which you create with ~ followed by a variable name. The variable that you pass to facet_wrap() should be categorical.\nè¦æŒ‰å•ä¸ªå˜é‡å¯¹å›¾è¿›è¡Œåˆ†é¢ï¼Œè¯·ä½¿ç”¨ facet_wrap()ã€‚facet_wrap() çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ä¸€ä¸ªå…¬å¼3ï¼Œä½ é€šè¿‡ ~ åè·Ÿä¸€ä¸ªå˜é‡åæ¥åˆ›å»ºå®ƒã€‚ä¼ é€’ç»™ facet_wrap() çš„å˜é‡åº”è¯¥æ˜¯åˆ†ç±»å˜é‡ã€‚\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species)) +\n  facet_wrap(~island)\n\n\n\n\n\n\n\nYou will learn about many other geoms for visualizing distributions of variables and relationships between them in Chapter 9.\nä½ å°†åœ¨ Chapter 9 ä¸­å­¦ä¹ åˆ°è®¸å¤šå…¶ä»–ç”¨äºå¯è§†åŒ–å˜é‡åˆ†å¸ƒå’Œå®ƒä»¬ä¹‹é—´å…³ç³»çš„å‡ ä½•å¯¹è±¡ã€‚\n\n1.5.5 Exercises\n\nThe mpg data frame that is bundled with the ggplot2 package contains 234 observations collected by the US Environmental Protection Agency on 38 car models. Which variables in mpg are categorical? Which variables are numerical? (Hint: Type ?mpg to read the documentation for the dataset.) How can you see this information when you run mpg?\nggplot2 è½¯ä»¶åŒ…ä¸­åŒ…å«çš„ mpg æ•°æ®æ¡† (data frame) å«æœ‰ 234 æ¡è§‚æµ‹æ•°æ®ï¼Œè¿™äº›æ•°æ®ç”±ç¾å›½ç¯å¢ƒä¿æŠ¤ç½²æ”¶é›†ï¼Œæ¶µç›–äº† 38 ç§è½¦å‹ã€‚ mpg ä¸­çš„å“ªäº›å˜é‡æ˜¯åˆ†ç±» (categorical) å˜é‡ï¼Ÿ å“ªäº›å˜é‡æ˜¯æ•°å€¼ (numerical) å˜é‡ï¼Ÿ (æç¤ºï¼šè¾“å…¥ ?mpg æ¥é˜…è¯»è¯¥æ•°æ®é›†çš„æ–‡æ¡£ã€‚) å½“ä½ è¿è¡Œ mpg æ—¶ï¼Œå¦‚ä½•çœ‹åˆ°è¿™äº›ä¿¡æ¯ï¼Ÿ\nMake a scatterplot of hwy vs.Â displ using the mpg data frame. Next, map a third, numerical variable to color, then size, then both color and size, then shape. How do these aesthetics behave differently for categorical vs.Â numerical variables?\nä½¿ç”¨ mpg æ•°æ®æ¡† (data frame) åˆ›å»ºä¸€ä¸ª hwy ä¸ displ çš„æ•£ç‚¹å›¾ (scatterplot)ã€‚ æ¥ä¸‹æ¥ï¼Œå°†ç¬¬ä¸‰ä¸ªæ•°å€¼ (numerical) å˜é‡æ˜ å°„ (map) åˆ° colorï¼Œç„¶åæ˜¯ sizeï¼Œç„¶åæ˜¯ color å’Œ sizeï¼Œæœ€åæ˜¯ shapeã€‚ å¯¹äºåˆ†ç±» (categorical) å˜é‡å’Œæ•°å€¼ (numerical) å˜é‡ï¼Œè¿™äº›å›¾å½¢å±æ€§ (aesthetics) çš„è¡Œä¸ºæœ‰ä½•ä¸åŒï¼Ÿ\nIn the scatterplot of hwy vs.Â displ, what happens if you map a third variable to linewidth?\nåœ¨ hwy ä¸ displ çš„æ•£ç‚¹å›¾ (scatterplot) ä¸­ï¼Œå¦‚æœå°†ç¬¬ä¸‰ä¸ªå˜é‡æ˜ å°„ (map) åˆ° linewidth ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\nWhat happens if you map the same variable to multiple aesthetics?\nå¦‚æœå°†åŒä¸€ä¸ªå˜é‡æ˜ å°„ (map) åˆ°å¤šä¸ªå›¾å½¢å±æ€§ (aesthetics) ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\nMake a scatterplot of bill_depth_mm vs.Â bill_length_mm and color the points by species. What does adding coloring by species reveal about the relationship between these two variables? What about faceting by species?\nåˆ›å»ºä¸€ä¸ª bill_depth_mm ä¸ bill_length_mm çš„æ•£ç‚¹å›¾ (scatterplot)ï¼Œå¹¶æŒ‰ species ä¸ºç‚¹ç€è‰²ã€‚ æŒ‰ç‰©ç§ (species) ç€è‰²æ­ç¤ºäº†è¿™ä¸¤ä¸ªå˜é‡ä¹‹é—´å…³ç³»çš„å“ªäº›ä¿¡æ¯ï¼Ÿ æŒ‰ species åˆ†é¢ (faceting) å‘¢ï¼Ÿ\n\nWhy does the following yield two separate legends? How would you fix it to combine the two legends?\nä¸ºä»€ä¹ˆä»¥ä¸‹ä»£ç ä¼šäº§ç”Ÿä¸¤ä¸ªç‹¬ç«‹çš„å›¾ä¾‹ (legends)ï¼Ÿ ä½ å°†å¦‚ä½•ä¿®æ”¹å®ƒä»¥åˆå¹¶è¿™ä¸¤ä¸ªå›¾ä¾‹ (legends)ï¼Ÿ\n\nggplot(\n  data = penguins,\n  mapping = aes(\n    x = bill_length_mm, y = bill_depth_mm, \n    color = species, shape = species\n  )\n) +\n  geom_point() +\n  labs(color = \"Species\")\n\n\n\nCreate the two following stacked bar plots. Which question can you answer with the first one? Which question can you answer with the second one?\nåˆ›å»ºä»¥ä¸‹ä¸¤ä¸ªå †å æ¡å½¢å›¾ (stacked bar plots)ã€‚ ä½ å¯ä»¥ç”¨ç¬¬ä¸€ä¸ªå›¾å›ç­”ä»€ä¹ˆé—®é¢˜ï¼Ÿ ä½ å¯ä»¥ç”¨ç¬¬äºŒä¸ªå›¾å›ç­”ä»€ä¹ˆé—®é¢˜ï¼Ÿ\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\")\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar(position = \"fill\")",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggsave",
    "href": "data-visualize.html#sec-ggsave",
    "title": "1Â  Data visualization",
    "section": "\n1.6 Saving your plots",
    "text": "1.6 Saving your plots\nOnce youâ€™ve made a plot, you might want to get it out of R by saving it as an image that you can use elsewhere. Thatâ€™s the job of ggsave(), which will save the plot most recently created to disk:\nä¸€æ—¦ä½ åˆ¶ä½œäº†å›¾ï¼Œä½ å¯èƒ½å¸Œæœ›å°†å…¶ä» R ä¸­å¯¼å‡ºï¼Œä¿å­˜ä¸ºå¯åœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨çš„å›¾åƒã€‚è¿™æ˜¯ ggsave() çš„å·¥ä½œï¼Œå®ƒä¼šå°†æœ€è¿‘åˆ›å»ºçš„å›¾ä¿å­˜åˆ°ç£ç›˜ï¼š\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\nggsave(filename = \"penguin-plot.png\")\n\nThis will save your plot to your working directory, a concept youâ€™ll learn more about in Chapter 6.\nè¿™ä¼šå°†ä½ çš„å›¾ä¿å­˜åˆ°ä½ çš„å·¥ä½œç›®å½•ï¼Œå…³äºè¿™ä¸ªæ¦‚å¿µä½ å°†åœ¨ Chapter 6 ä¸­å­¦åˆ°æ›´å¤šã€‚\nIf you donâ€™t specify the width and height they will be taken from the dimensions of the current plotting device. For reproducible code, youâ€™ll want to specify them. You can learn more about ggsave() in the documentation.\nå¦‚æœä½ ä¸æŒ‡å®š width å’Œ heightï¼Œå®ƒä»¬å°†å–è‡ªå½“å‰ç»˜å›¾è®¾å¤‡çš„å°ºå¯¸ã€‚ä¸ºäº†ä»£ç çš„å¯å¤ç°æ€§ï¼Œä½ ä¼šå¸Œæœ›æŒ‡å®šå®ƒä»¬ã€‚ä½ å¯ä»¥åœ¨æ–‡æ¡£ä¸­äº†è§£æ›´å¤šå…³äº ggsave() çš„ä¿¡æ¯ã€‚\nGenerally, however, we recommend that you assemble your final reports using Quarto, a reproducible authoring system that allows you to interleave your code and your prose and automatically include your plots in your write-ups. You will learn more about Quarto in Chapter 28.\nç„¶è€Œï¼Œé€šå¸¸æˆ‘ä»¬å»ºè®®ä½ ä½¿ç”¨ Quarto æ¥ç»„ç»‡ä½ çš„æœ€ç»ˆæŠ¥å‘Šï¼Œè¿™æ˜¯ä¸€ä¸ªå¯å¤ç°çš„åˆ›ä½œç³»ç»Ÿï¼Œå®ƒå…è®¸ä½ å°†ä»£ç å’Œæ–‡å­—äº¤ç»‡åœ¨ä¸€èµ·ï¼Œå¹¶è‡ªåŠ¨å°†ä½ çš„å›¾åŒ…å«åœ¨ä½ çš„æŠ¥å‘Šä¸­ã€‚ä½ å°†åœ¨ Chapter 28 ä¸­å­¦ä¹ æ›´å¤šå…³äº Quarto çš„ä¿¡æ¯ã€‚\n\n1.6.1 Exercises\n\n\nRun the following lines of code. Which of the two plots is saved as mpg-plot.png? Why?\nè¿è¡Œä»¥ä¸‹ä»£ç è¡Œã€‚å“ªå¼ å›¾è¢«ä¿å­˜ä¸º mpg-plot.pngï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n\nggplot(mpg, aes(x = class)) +\n  geom_bar()\nggplot(mpg, aes(x = cty, y = hwy)) +\n  geom_point()\nggsave(\"mpg-plot.png\")\n\n\nWhat do you need to change in the code above to save the plot as a PDF instead of a PNG? How could you find out what types of image files would work in ggsave()?\nä½ éœ€è¦å¦‚ä½•æ›´æ”¹ä¸Šé¢çš„ä»£ç ï¼Œæ‰èƒ½å°†å›¾ä¿å­˜ä¸º PDF è€Œä¸æ˜¯ PNGï¼Ÿä½ å¦‚ä½•æ‰¾å‡º ggsave() æ”¯æŒå“ªäº›ç±»å‹çš„å›¾åƒæ–‡ä»¶ï¼Ÿ",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#common-problems",
    "href": "data-visualize.html#common-problems",
    "title": "1Â  Data visualization",
    "section": "\n1.7 Common problems",
    "text": "1.7 Common problems\nAs you start to run R code, youâ€™re likely to run into problems. Donâ€™t worry â€” it happens to everyone. We have all been writing R code for years, but every day we still write code that doesnâ€™t work on the first try!\nå½“ä½ å¼€å§‹è¿è¡Œ R ä»£ç æ—¶ï¼Œä½ å¾ˆå¯èƒ½ä¼šé‡åˆ°é—®é¢˜ã€‚åˆ«æ‹…å¿ƒâ€”â€”è¿™å‘ç”Ÿåœ¨æ¯ä¸ªäººèº«ä¸Šã€‚æˆ‘ä»¬éƒ½å†™äº†å¤šå¹´çš„ R ä»£ç ï¼Œä½†æ¯å¤©æˆ‘ä»¬ä»ç„¶ä¼šå†™å‡ºç¬¬ä¸€æ¬¡å°è¯•å°±ä¸èƒ½å·¥ä½œçš„ä»£ç ï¼\nStart by carefully comparing the code that youâ€™re running to the code in the book. R is extremely picky, and a misplaced character can make all the difference. Make sure that every ( is matched with a ) and every \" is paired with another \". Sometimes youâ€™ll run the code and nothing happens. Check the left-hand of your console: if itâ€™s a +, it means that R doesnâ€™t think youâ€™ve typed a complete expression and itâ€™s waiting for you to finish it. In this case, itâ€™s usually easy to start from scratch again by pressing ESCAPE to abort processing the current command.\né¦–å…ˆï¼Œä»”ç»†æ¯”è¾ƒä½ æ­£åœ¨è¿è¡Œçš„ä»£ç å’Œä¹¦ä¸­çš„ä»£ç ã€‚R éå¸¸æŒ‘å‰”ï¼Œä¸€ä¸ªæ”¾é”™ä½ç½®çš„å­—ç¬¦éƒ½å¯èƒ½å¯¼è‡´å¤©å£¤ä¹‹åˆ«ã€‚ç¡®ä¿æ¯ä¸ª ( éƒ½ä¸ä¸€ä¸ª ) åŒ¹é…ï¼Œæ¯ä¸ª \" éƒ½ä¸å¦ä¸€ä¸ª \" é…å¯¹ã€‚æœ‰æ—¶ä½ è¿è¡Œä»£ç åä»€ä¹ˆä¹Ÿæ²¡å‘ç”Ÿã€‚æ£€æŸ¥ä½ çš„æ§åˆ¶å°å·¦ä¾§ï¼šå¦‚æœå®ƒæ˜¯ä¸€ä¸ª +ï¼Œè¿™æ„å‘³ç€ R è®¤ä¸ºä½ è¿˜æ²¡æœ‰è¾“å…¥ä¸€ä¸ªå®Œæ•´çš„è¡¨è¾¾å¼ï¼Œæ­£åœ¨ç­‰å¾…ä½ å®Œæˆå®ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šå¸¸å¾ˆå®¹æ˜“é€šè¿‡æŒ‰ ESCAPE é”®ä¸­æ­¢å½“å‰å‘½ä»¤çš„å¤„ç†ï¼Œç„¶åä»å¤´å¼€å§‹ã€‚\nOne common problem when creating ggplot2 graphics is to put the + in the wrong place: it has to come at the end of the line, not the start. In other words, make sure you havenâ€™t accidentally written code like this:\nåœ¨åˆ›å»º ggplot2 å›¾å½¢æ—¶ï¼Œä¸€ä¸ªå¸¸è§çš„é—®é¢˜æ˜¯æŠŠ + æ”¾åœ¨äº†é”™è¯¯çš„ä½ç½®ï¼šå®ƒå¿…é¡»æ”¾åœ¨è¡Œçš„æœ«å°¾ï¼Œè€Œä¸æ˜¯å¼€å¤´ã€‚æ¢å¥è¯è¯´ï¼Œç¡®ä¿ä½ æ²¡æœ‰æ„å¤–åœ°å†™å‡ºåƒä¸‹é¢è¿™æ ·çš„ä»£ç ï¼š\n\nggplot(data = mpg) \n+ geom_point(mapping = aes(x = displ, y = hwy))\n\nIf youâ€™re still stuck, try the help. You can get help about any R function by running ?function_name in the console, or highlighting the function name and pressing F1 in RStudio. Donâ€™t worry if the help doesnâ€™t seem that helpful - instead skip down to the examples and look for code that matches what youâ€™re trying to do.\nå¦‚æœä½ ä»ç„¶å¡ä½äº†ï¼Œè¯•è¯•å¸®åŠ©ã€‚ä½ å¯ä»¥é€šè¿‡åœ¨æ§åˆ¶å°è¿è¡Œ ?function_name æ¥è·å–ä»»ä½• R å‡½æ•°çš„å¸®åŠ©ï¼Œæˆ–è€…åœ¨ RStudio ä¸­é«˜äº®å‡½æ•°åå¹¶æŒ‰ F1ã€‚å¦‚æœå¸®åŠ©çœ‹èµ·æ¥ä¸é‚£ä¹ˆæœ‰ç”¨ï¼Œåˆ«æ‹…å¿ƒâ€”â€”ç›´æ¥è·³åˆ°ç¤ºä¾‹éƒ¨åˆ†ï¼Œå¯»æ‰¾ä¸ä½ æ­£åœ¨å°è¯•åšçš„äº‹æƒ…ç›¸åŒ¹é…çš„ä»£ç ã€‚\nIf that doesnâ€™t help, carefully read the error message. Sometimes the answer will be buried there! But when youâ€™re new to R, even if the answer is in the error message, you might not yet know how to understand it. Another great tool is Google: try googling the error message, as itâ€™s likely someone else has had the same problem, and has gotten help online.\nå¦‚æœé‚£ä¹Ÿå¸®ä¸äº†ä½ ï¼Œä»”ç»†é˜…è¯»é”™è¯¯ä¿¡æ¯ã€‚æœ‰æ—¶ç­”æ¡ˆå°±è—åœ¨é‚£é‡Œï¼ä½†æ˜¯å½“ä½ åˆšæ¥è§¦ R æ—¶ï¼Œå³ä½¿ç­”æ¡ˆå°±åœ¨é”™è¯¯ä¿¡æ¯ä¸­ï¼Œä½ å¯èƒ½è¿˜ä¸çŸ¥é“å¦‚ä½•ç†è§£å®ƒã€‚å¦ä¸€ä¸ªå¾ˆæ£’çš„å·¥å…·æ˜¯è°·æ­Œï¼šå°è¯•ç”¨è°·æ­Œæœç´¢é”™è¯¯ä¿¡æ¯ï¼Œå› ä¸ºå¾ˆå¯èƒ½å…¶ä»–äººä¹Ÿé‡åˆ°è¿‡åŒæ ·çš„é—®é¢˜ï¼Œå¹¶ä¸”åœ¨ç½‘ä¸Šå¾—åˆ°äº†å¸®åŠ©ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#summary",
    "href": "data-visualize.html#summary",
    "title": "1Â  Data visualization",
    "section": "\n1.8 Summary",
    "text": "1.8 Summary\nIn this chapter, youâ€™ve learned the basics of data visualization with ggplot2. We started with the basic idea that underpins ggplot2: a visualization is a mapping from variables in your data to aesthetic properties like position, color, size and shape. You then learned about increasing the complexity and improving the presentation of your plots layer-by-layer. You also learned about commonly used plots for visualizing the distribution of a single variable as well as for visualizing relationships between two or more variables, by leveraging additional aesthetic mappings and/or splitting your plot into small multiples using faceting.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†ä½¿ç”¨ ggplot2 è¿›è¡Œæ•°æ®å¯è§†åŒ–çš„åŸºç¡€çŸ¥è¯†ã€‚æˆ‘ä»¬ä»æ”¯æ’‘ ggplot2 çš„åŸºæœ¬æ€æƒ³å¼€å§‹ï¼šå¯è§†åŒ–æ˜¯å°†æ•°æ®ä¸­çš„å˜é‡æ˜ å°„åˆ°è¯¸å¦‚ä½ç½®ã€é¢œè‰²ã€å¤§å°å’Œå½¢çŠ¶ç­‰ç¾å­¦å±æ€§çš„è¿‡ç¨‹ã€‚ç„¶åä½ å­¦ä¹ äº†å¦‚ä½•é€å±‚å¢åŠ å›¾çš„å¤æ‚æ€§å¹¶æ”¹å–„å…¶å‘ˆç°æ•ˆæœã€‚ä½ è¿˜å­¦ä¹ äº†å¸¸ç”¨äºå¯è§†åŒ–å•ä¸ªå˜é‡åˆ†å¸ƒä»¥åŠå¯è§†åŒ–ä¸¤ä¸ªæˆ–å¤šä¸ªå˜é‡ä¹‹é—´å…³ç³»çš„å›¾ï¼Œè¿™æ˜¯é€šè¿‡åˆ©ç”¨é¢å¤–çš„ç¾å­¦æ˜ å°„å’Œ/æˆ–ä½¿ç”¨åˆ†é¢å°†å›¾åˆ†å‰²æˆå°å€æ•°å›¾æ¥å®ç°çš„ã€‚\nWeâ€™ll use visualizations again and again throughout this book, introducing new techniques as we need them as well as do a deeper dive into creating visualizations with ggplot2 in Chapter 9 through Chapter 11.\nåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬å°†åå¤ä½¿ç”¨å¯è§†åŒ–ï¼Œåœ¨éœ€è¦æ—¶å¼•å…¥æ–°æŠ€æœ¯ï¼Œå¹¶åœ¨ Chapter 9 åˆ° Chapter 11 ä¸­æ›´æ·±å…¥åœ°æ¢è®¨ä½¿ç”¨ ggplot2 åˆ›å»ºå¯è§†åŒ–ã€‚\nWith the basics of visualization under your belt, in the next chapter weâ€™re going to switch gears a little and give you some practical workflow advice. We intersperse workflow advice with data science tools throughout this part of the book because itâ€™ll help you stay organized as you write increasing amounts of R code.\næŒæ¡äº†å¯è§†åŒ–çš„åŸºç¡€çŸ¥è¯†åï¼Œåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç¨å¾®è½¬æ¢ä¸€ä¸‹æ€è·¯ï¼Œç»™ä½ ä¸€äº›å®ç”¨çš„å·¥ä½œæµç¨‹å»ºè®®ã€‚åœ¨æœ¬ä¹¦çš„è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å·¥ä½œæµç¨‹å»ºè®®ä¸æ•°æ®ç§‘å­¦å·¥å…·ç©¿æ’åœ¨ä¸€èµ·ï¼Œå› ä¸ºè¿™å°†åœ¨ä½ ç¼–å†™è¶Šæ¥è¶Šå¤šçš„ R ä»£ç æ—¶å¸®åŠ©ä½ ä¿æŒæ¡ç†æ¸…æ™°ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#footnotes",
    "href": "data-visualize.html#footnotes",
    "title": "1Â  Data visualization",
    "section": "",
    "text": "You can eliminate that message and force conflict resolution to happen on demand by using the conflicted package, which becomes more important as you load more packages. You can learn more about conflicted at https://conflicted.r-lib.org.â†©ï¸\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.â†©ï¸\nHere â€œformulaâ€ is the name of the thing created by ~, not a synonym for â€œequationâ€.â†©ï¸",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Data visualization</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html",
    "href": "workflow-basics.html",
    "title": "2Â  Workflow: basics",
    "section": "",
    "text": "2.1 Coding basics\nYou now have some experience running R code. We didnâ€™t give you many details, but youâ€™ve obviously figured out the basics, or you wouldâ€™ve thrown this book away in frustration! Frustration is natural when you start programming in R because it is such a stickler for punctuation, and even one character out of place can cause it to complain. But while you should expect to be a little frustrated, take comfort in that this experience is typical and temporary: it happens to everyone, and the only way to get over it is to keep trying.\nä½ ç°åœ¨å·²ç»æœ‰äº†ä¸€äº›è¿è¡Œ R ä»£ç çš„ç»éªŒã€‚æˆ‘ä»¬æ²¡æœ‰æä¾›å¤ªå¤šç»†èŠ‚ï¼Œä½†ä½ æ˜¾ç„¶å·²ç»æŒæ¡äº†åŸºç¡€çŸ¥è¯†ï¼Œå¦åˆ™ä½ å¯èƒ½æ—©å°±æ²®ä¸§åœ°æ‰”æ‰è¿™æœ¬ä¹¦äº†ï¼å½“ä½ å¼€å§‹ç”¨ R ç¼–ç¨‹æ—¶ï¼Œæ„Ÿåˆ°æ²®ä¸§æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºå®ƒå¯¹æ ‡ç‚¹ç¬¦å·è¦æ±‚éå¸¸ä¸¥æ ¼ï¼Œå“ªæ€•åªæœ‰ä¸€ä¸ªå­—ç¬¦æ”¾é”™ä½ç½® (misplaced) ä¹Ÿä¼šå¯¼è‡´å®ƒæŠ¥é”™ã€‚ä½†æ˜¯ï¼Œå°½ç®¡ä½ åº”è¯¥é¢„æ–™åˆ°ä¼šæœ‰äº›æ²®ä¸§ï¼Œä½†è¯·æ”¾å¿ƒï¼Œè¿™ç§ç»å†æ˜¯å…¸å‹ä¸”æš‚æ—¶çš„ï¼šæ¯ä¸ªäººéƒ½ä¼šé‡åˆ°ï¼Œè€Œå…‹æœå®ƒçš„å”¯ä¸€æ–¹æ³•å°±æ˜¯ä¸æ–­å°è¯•ã€‚\nBefore we go any further, letâ€™s ensure youâ€™ve got a solid foundation in running R code and that you know some of the most helpful RStudio features.\nåœ¨æˆ‘ä»¬ç»§ç»­æ·±å…¥ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç¡®ä¿ä½ åœ¨è¿è¡Œ R ä»£ç æ–¹é¢æœ‰åšå®çš„åŸºç¡€ï¼Œå¹¶ä¸”äº†è§£ä¸€äº› RStudio æœ€æœ‰ç”¨çš„åŠŸèƒ½ã€‚\nLetâ€™s review some basics weâ€™ve omitted so far in the interest of getting you plotting as quickly as possible. You can use R to do basic math calculations:\nè®©æˆ‘ä»¬å›é¡¾ä¸€äº›ä¸ºäº†è®©ä½ å°½å¿«å¼€å§‹ç»˜å›¾è€Œçœç•¥çš„åŸºç¡€çŸ¥è¯†ã€‚ä½ å¯ä»¥ä½¿ç”¨ R è¿›è¡ŒåŸºæœ¬çš„æ•°å­¦è®¡ç®—ï¼š\n1 / 200 * 30\n#&gt; [1] 0.15\n(59 + 73 + 2) / 3\n#&gt; [1] 44.66667\nsin(pi / 2)\n#&gt; [1] 1\nYou can create new objects with the assignment operator &lt;-:\nä½ å¯ä»¥ä½¿ç”¨èµ‹å€¼è¿ç®—ç¬¦ &lt;- åˆ›å»ºæ–°å¯¹è±¡ï¼š\nx &lt;- 3 * 4\nNote that the value of x is not printed, itâ€™s just stored. If you want to view the value, type x in the console.\næ³¨æ„ï¼Œx çš„å€¼å¹¶ä¸ä¼šè¢«æ‰“å°å‡ºæ¥ï¼Œå®ƒåªæ˜¯è¢«å‚¨å­˜èµ·æ¥äº†ã€‚å¦‚æœä½ æƒ³æŸ¥çœ‹å®ƒçš„å€¼ï¼Œå¯ä»¥åœ¨æ§åˆ¶å° (console) ä¸­è¾“å…¥ xã€‚\nYou can combine multiple elements into a vector with c():\nä½ å¯ä»¥ä½¿ç”¨ c() å‡½æ•°å°†å¤šä¸ªå…ƒç´  combine (ç»„åˆ) æˆä¸€ä¸ªå‘é‡ (vector)ï¼š\nprimes &lt;- c(2, 3, 5, 7, 11, 13)\nAnd basic arithmetic on vectors is applied to every element of the vector:\nå¯¹å‘é‡è¿›è¡Œçš„åŸºæœ¬ç®—æœ¯è¿ç®—ä¼šåº”ç”¨äºå‘é‡çš„æ¯ä¸ªå…ƒç´ ï¼š\nprimes * 2\n#&gt; [1]  4  6 10 14 22 26\nprimes - 1\n#&gt; [1]  1  2  4  6 10 12\nAll R statements where you create objects, assignment statements, have the same form:\næ‰€æœ‰åˆ›å»ºå¯¹è±¡çš„ R è¯­å¥ï¼Œå³èµ‹å€¼ (assignment) è¯­å¥ï¼Œéƒ½å…·æœ‰ç›¸åŒçš„å½¢å¼ï¼š\nobject_name &lt;- value\nWhen reading that code, say â€œobject name gets valueâ€ in your head.\nåœ¨é˜…è¯»è¿™æ®µä»£ç æ—¶ï¼Œä½ å¯ä»¥åœ¨è„‘æµ·ä¸­é»˜å¿µâ€œå¯¹è±¡åå¾—åˆ°å€¼â€ã€‚\nYou will make lots of assignments, and &lt;- is a pain to type. You can save time with RStudioâ€™s keyboard shortcut: Alt + - (the minus sign). Notice that RStudio automatically surrounds &lt;- with spaces, which is a good code formatting practice. Code can be miserable to read on a good day, so giveyoureyesabreak and use spaces.\nä½ ä¼šè¿›è¡Œå¤§é‡çš„èµ‹å€¼æ“ä½œï¼Œè€Œæ‰‹åŠ¨è¾“å…¥ &lt;- ä¼šå¾ˆéº»çƒ¦ã€‚ä½ å¯ä»¥ä½¿ç”¨ RStudio çš„é”®ç›˜å¿«æ·é”®æ¥èŠ‚çœæ—¶é—´ï¼šAlt + - (å‡å·)ã€‚è¯·æ³¨æ„ï¼ŒRStudio ä¼šè‡ªåŠ¨åœ¨ &lt;- ä¸¤ä¾§æ·»åŠ ç©ºæ ¼ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä»£ç æ ¼å¼åŒ–ä¹ æƒ¯ã€‚å³ä½¿åœ¨çŠ¶æ€å¥½çš„æ—¶å€™ï¼Œé˜…è¯»ä»£ç ä¹Ÿå¯èƒ½æ˜¯ä¸€ä»¶ç—›è‹¦çš„äº‹æƒ…ï¼Œæ‰€ä»¥è¯·å–„å¾…ä½ çš„çœ¼ç›ï¼Œå¤šä½¿ç”¨ç©ºæ ¼ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#comments",
    "href": "workflow-basics.html#comments",
    "title": "2Â  Workflow: basics",
    "section": "\n2.2 Comments",
    "text": "2.2 Comments\nR will ignore any text after # for that line. This allows you to write comments, text that is ignored by R but read by other humans. Weâ€™ll sometimes include comments in examples explaining whatâ€™s happening with the code.\nR ä¼šå¿½ç•¥è¯¥è¡Œ # ä¹‹åçš„æ‰€æœ‰æ–‡æœ¬ã€‚è¿™å…è®¸ä½ ç¼–å†™æ³¨é‡Š (comments)ï¼Œå³è¢« R å¿½ç•¥ä½†ä¾›äººç±»é˜…è¯»çš„æ–‡æœ¬ã€‚æˆ‘ä»¬æœ‰æ—¶ä¼šåœ¨ç¤ºä¾‹ä¸­åŠ å…¥æ³¨é‡Šæ¥è§£é‡Šä»£ç çš„åŠŸèƒ½ã€‚\nComments can be helpful for briefly describing what the following code does.\næ³¨é‡Šæœ‰åŠ©äºç®€è¦æè¿°åç»­ä»£ç çš„åŠŸèƒ½ã€‚\n\n# create vector of primes\nprimes &lt;- c(2, 3, 5, 7, 11, 13)\n\n# multiply primes by 2\nprimes * 2\n#&gt; [1]  4  6 10 14 22 26\n\nWith short pieces of code like this, leaving a comment for every single line of code might not be necessary. But as the code youâ€™re writing gets more complex, comments can save you (and your collaborators) a lot of time figuring out what was done in the code.\nå¯¹äºåƒè¿™æ ·ç®€çŸ­çš„ä»£ç ç‰‡æ®µï¼Œå¯èƒ½æ²¡æœ‰å¿…è¦ä¸ºæ¯ä¸€è¡Œä»£ç éƒ½å†™æ³¨é‡Šã€‚ä½†æ˜¯ï¼Œå½“ä½ ç¼–å†™çš„ä»£ç å˜å¾—è¶Šæ¥è¶Šå¤æ‚æ—¶ï¼Œæ³¨é‡Šå¯ä»¥ä¸ºä½ ï¼ˆå’Œä½ çš„åˆä½œè€…ï¼‰èŠ‚çœå¤§é‡æ—¶é—´æ¥ç†è§£ä»£ç çš„åŠŸèƒ½ã€‚\nUse comments to explain the why of your code, not the how or the what. The what and how of your code are always possible to figure out, even if it might be tedious, by carefully reading it. If you describe every step in the comments, and then change the code, you will have to remember to update the comments as well or it will be confusing when you return to your code in the future.\nä½¿ç”¨æ³¨é‡Šæ¥è§£é‡Šä½ ä»£ç çš„åŸå›  (why)ï¼Œè€Œä¸æ˜¯æ–¹å¼ (how) æˆ–å†…å®¹ (what)ã€‚é€šè¿‡ä»”ç»†é˜…è¯»ä»£ç ï¼Œæ€»æ˜¯å¯ä»¥ææ¸…æ¥šä»£ç çš„å†…å®¹å’Œæ–¹å¼ï¼Œå°½ç®¡è¿™å¯èƒ½å¾ˆä¹å‘³ã€‚å¦‚æœä½ åœ¨æ³¨é‡Šä¸­æè¿°äº†æ¯ä¸€æ­¥ï¼Œç„¶ååœ¨ä¿®æ”¹ä»£ç åï¼Œä½ å¿…é¡»è®°å¾—åŒæ—¶æ›´æ–°æ³¨é‡Šï¼Œå¦åˆ™å°†æ¥ä½ å†å›å¤´çœ‹ä»£ç æ—¶ä¼šæ„Ÿåˆ°å›°æƒ‘ã€‚\nFiguring out why something was done is much more difficult, if not impossible. For example, geom_smooth() has an argument called span, which controls the smoothness of the curve, with larger values yielding a smoother curve. Suppose you decide to change the value of span from its default of 0.75 to 0.9: itâ€™s easy for a future reader to understand what is happening, but unless you note your thinking in a comment, no one will understand why you changed the default.\nææ¸…æ¥šåšæŸä»¶äº‹çš„åŸå› è¦å›°éš¾å¾—å¤šï¼Œç”šè‡³æ˜¯ä¸å¯èƒ½çš„ã€‚ä¾‹å¦‚ï¼Œgeom_smooth() æœ‰ä¸€ä¸ªåä¸º span çš„å‚æ•°ï¼Œå®ƒæ§åˆ¶æ›²çº¿çš„å¹³æ»‘åº¦ï¼Œå€¼è¶Šå¤§æ›²çº¿è¶Šå¹³æ»‘ã€‚å‡è®¾ä½ å†³å®šå°† span çš„å€¼ä»é»˜è®¤çš„ 0.75 æ›´æ”¹ä¸º 0.9ï¼šæœªæ¥çš„è¯»è€…å¾ˆå®¹æ˜“ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä½†é™¤éä½ åœ¨æ³¨é‡Šä¸­è®°å½•ä¸‹ä½ çš„æƒ³æ³•ï¼Œå¦åˆ™æ²¡äººä¼šæ˜ç™½ä½ ä¸ºä»€ä¹ˆè¦æ›´æ”¹é»˜è®¤å€¼ã€‚\nFor data analysis code, use comments to explain your overall plan of attack and record important insights as you encounter them. Thereâ€™s no way to re-capture this knowledge from the code itself.\nå¯¹äºæ•°æ®åˆ†æä»£ç ï¼Œä½¿ç”¨æ³¨é‡Šæ¥è§£é‡Šä½ çš„æ•´ä½“åˆ†æè®¡åˆ’ï¼Œå¹¶è®°å½•ä½ é‡åˆ°çš„é‡è¦è§è§£ã€‚è¿™äº›ä¿¡æ¯æ˜¯æ— æ³•å•ä»ä»£ç æœ¬èº«é‡æ–°è·å–çš„ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#sec-whats-in-a-name",
    "href": "workflow-basics.html#sec-whats-in-a-name",
    "title": "2Â  Workflow: basics",
    "section": "\n2.3 Whatâ€™s in a name?",
    "text": "2.3 Whatâ€™s in a name?\nObject names must start with a letter and can only contain letters, numbers, _, and .. You want your object names to be descriptive, so youâ€™ll need to adopt a convention for multiple words. We recommend snake_case, where you separate lowercase words with _.\nå¯¹è±¡åç§°å¿…é¡»ä»¥å­—æ¯å¼€å¤´ï¼Œå¹¶ä¸”åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€_ å’Œ .ã€‚ä½ å¸Œæœ›ä½ çš„å¯¹è±¡åç§°å…·æœ‰æè¿°æ€§ï¼Œæ‰€ä»¥ä½ éœ€è¦ä¸ºå¤šä¸ªå•è¯çš„å‘½åé‡‡çº³ä¸€ç§çº¦å®šã€‚æˆ‘ä»¬æ¨èä½¿ç”¨è›‡å½¢å‘½åæ³• (snake_case)ï¼Œå³ç”¨ _ åˆ†éš”å°å†™å•è¯ã€‚\n\ni_use_snake_case\notherPeopleUseCamelCase\nsome.people.use.periods\nAnd_aFew.People_RENOUNCEconvention\n\nWeâ€™ll return to names again when we discuss code style in Chapter 4.\næˆ‘ä»¬å°†åœ¨ Chapter 4 ä¸­è®¨è®ºä»£ç é£æ ¼æ—¶å†æ¬¡å›åˆ°å‘½åçš„è¯é¢˜ã€‚\nYou can inspect an object by typing its name:\nä½ å¯ä»¥é€šè¿‡è¾“å…¥å¯¹è±¡åç§°æ¥æŸ¥çœ‹å®ƒï¼š\n\nx\n#&gt; [1] 12\n\nMake another assignment:\nå†è¿›è¡Œä¸€æ¬¡èµ‹å€¼ï¼š\n\nthis_is_a_really_long_name &lt;- 2.5\n\nTo inspect this object, try out RStudioâ€™s completion facility: type â€œthisâ€, press TAB, add characters until you have a unique prefix, then press return.\nè¦æŸ¥çœ‹è¿™ä¸ªå¯¹è±¡ï¼Œå¯ä»¥è¯•è¯• RStudio çš„è‡ªåŠ¨è¡¥å…¨åŠŸèƒ½ï¼šè¾“å…¥ â€œthisâ€ï¼ŒæŒ‰ TAB é”®ï¼Œç»§ç»­æ·»åŠ å­—ç¬¦ç›´åˆ°å‰ç¼€å”¯ä¸€ï¼Œç„¶åæŒ‰å›è½¦é”®ã€‚\nLetâ€™s assume you made a mistake, and that the value of this_is_a_really_long_name should be 3.5, not 2.5. You can use another keyboard shortcut to help you fix it. For example, you can press â†‘ to bring the last command you typed and edit it. Or, type â€œthisâ€ then press Cmd/Ctrl + â†‘ to list all the commands youâ€™ve typed that start with those letters. Use the arrow keys to navigate, then press enter to retype the command. Change 2.5 to 3.5 and rerun.\nå‡è®¾ä½ çŠ¯äº†ä¸€ä¸ªé”™è¯¯ï¼Œthis_is_a_really_long_name çš„å€¼åº”è¯¥æ˜¯ 3.5ï¼Œè€Œä¸æ˜¯ 2.5ã€‚ä½ å¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ªé”®ç›˜å¿«æ·é”®æ¥å¸®åŠ©ä½ ä¿®æ­£å®ƒã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥æŒ‰ â†‘ é”®è°ƒå‡ºä½ è¾“å…¥çš„ä¸Šä¸€æ¡å‘½ä»¤å¹¶è¿›è¡Œç¼–è¾‘ã€‚æˆ–è€…ï¼Œè¾“å…¥ â€œthisâ€ï¼Œç„¶åæŒ‰ Cmd/Ctrl + â†‘ æ¥åˆ—å‡ºæ‰€æœ‰ä»¥è¿™äº›å­—æ¯å¼€å¤´çš„å‘½ä»¤ã€‚ä½¿ç”¨ç®­å¤´é”®å¯¼èˆªï¼Œç„¶åæŒ‰å›è½¦é”®é‡æ–°è¾“å…¥è¯¥å‘½ä»¤ã€‚å°† 2.5 æ”¹ä¸º 3.5 å¹¶é‡æ–°è¿è¡Œã€‚\nMake yet another assignment:\nå†è¿›è¡Œä¸€æ¬¡èµ‹å€¼ï¼š\n\nr_rocks &lt;- 2^3\n\nLetâ€™s try to inspect it:\nè®©æˆ‘ä»¬è¯•ç€æŸ¥çœ‹å®ƒï¼š\n\nr_rock\n#&gt; Error: object 'r_rock' not found\nR_rocks\n#&gt; Error: object 'R_rocks' not found\n\nThis illustrates the implied contract between you and R: R will do the tedious computations for you, but in exchange, you must be completely precise in your instructions. If not, youâ€™re likely to get an error that says the object youâ€™re looking for was not found. Typos matter; R canâ€™t read your mind and say, â€œoh, they probably meant r_rocks when they typed r_rockâ€. Case matters; similarly, R canâ€™t read your mind and say, â€œoh, they probably meant r_rocks when they typed R_rocksâ€.\nè¿™è¯´æ˜äº†ä½ å’Œ R ä¹‹é—´çš„ä¸€ä¸ªéšå«å¥‘çº¦ï¼šR ä¼šä¸ºä½ å®Œæˆç¹ççš„è®¡ç®—ï¼Œä½†ä½œä¸ºäº¤æ¢ï¼Œä½ å¿…é¡»ç»™å‡ºå®Œå…¨ç²¾ç¡®çš„æŒ‡ä»¤ã€‚å¦åˆ™ï¼Œä½ å¾ˆå¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªé”™è¯¯ï¼Œæç¤ºæ‰¾ä¸åˆ°ä½ æƒ³è¦çš„å¯¹è±¡ã€‚æ‹¼å†™é”™è¯¯å¾ˆé‡è¦ï¼›R æ— æ³•è¯»æ‡‚ä½ çš„å¿ƒæ€ï¼Œç„¶åè¯´ï¼šâ€œå“¦ï¼Œä»–ä»¬è¾“å…¥ r_rock æ—¶å¯èƒ½æŒ‡çš„æ˜¯ r_rocksâ€ã€‚å¤§å°å†™ä¹Ÿå¾ˆé‡è¦ï¼›åŒæ ·ï¼ŒR ä¹Ÿæ— æ³•è¯»æ‡‚ä½ çš„å¿ƒæ€ï¼Œç„¶åè¯´ï¼šâ€œå“¦ï¼Œä»–ä»¬è¾“å…¥ R_rocks æ—¶å¯èƒ½æŒ‡çš„æ˜¯ r_rocksâ€ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#calling-functions",
    "href": "workflow-basics.html#calling-functions",
    "title": "2Â  Workflow: basics",
    "section": "\n2.4 Calling functions",
    "text": "2.4 Calling functions\nR has a large collection of built-in functions that are called like this:\nR æœ‰å¤§é‡å†…ç½®å‡½æ•°ï¼Œè°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š\n\nfunction_name(argument1 = value1, argument2 = value2, ...)\n\nLetâ€™s try using seq(), which makes regular sequences of numbers, and while weâ€™re at it, learn more helpful features of RStudio. Type se and hit TAB. A popup shows you possible completions. Specify seq() by typing more (a q) to disambiguate or by using â†‘/â†“ arrows to select. Notice the floating tooltip that pops up, reminding you of the functionâ€™s arguments and purpose. If you want more help, press F1 to get all the details in the help tab in the lower right pane.\nè®©æˆ‘ä»¬è¯•è¯• seq() å‡½æ•°ï¼Œå®ƒå¯ä»¥ç”Ÿæˆè§„åˆ™çš„æ•°å­—åºåˆ— (sequences)ï¼ŒåŒæ—¶æˆ‘ä»¬ä¹Ÿå¯ä»¥å­¦ä¹ æ›´å¤š RStudio çš„å®ç”¨åŠŸèƒ½ã€‚è¾“å…¥ se ç„¶åæŒ‰ TAB é”®ã€‚ä¸€ä¸ªå¼¹å‡ºçª—å£ä¼šæ˜¾ç¤ºå¯èƒ½çš„è¡¥å…¨é€‰é¡¹ã€‚é€šè¿‡è¾“å…¥æ›´å¤šå­—ç¬¦ï¼ˆä¸€ä¸ª qï¼‰æ¥æ¶ˆé™¤æ­§ä¹‰ï¼Œæˆ–ä½¿ç”¨ â†‘/â†“ ç®­å¤´æ¥é€‰æ‹© seq()ã€‚æ³¨æ„å¼¹å‡ºçš„æµ®åŠ¨æç¤ºæ¡†ï¼Œå®ƒä¼šæé†’ä½ è¯¥å‡½æ•°çš„å‚æ•°å’Œç”¨é€”ã€‚å¦‚æœä½ éœ€è¦æ›´å¤šå¸®åŠ©ï¼Œå¯ä»¥æŒ‰ F1 é”®ï¼Œåœ¨å³ä¸‹è§’çš„å¸®åŠ© (help) æ ‡ç­¾é¡µä¸­è·å–æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ã€‚\nWhen youâ€™ve selected the function you want, press TAB again. RStudio will add matching opening (() and closing ()) parentheses for you. Type the name of the first argument, from, and set it equal to 1. Then, type the name of the second argument, to, and set it equal to 10. Finally, hit return.\nå½“ä½ é€‰å®šæƒ³è¦çš„å‡½æ•°åï¼Œå†æ¬¡æŒ‰ TAB é”®ã€‚RStudio ä¼šä¸ºä½ æ·»åŠ åŒ¹é…çš„å¼€æ‹¬å· ( å’Œé—­æ‹¬å· )ã€‚è¾“å…¥ç¬¬ä¸€ä¸ªå‚æ•°çš„åç§° fromï¼Œå¹¶å°†å…¶è®¾ç½®ä¸º 1ã€‚ç„¶åï¼Œè¾“å…¥ç¬¬äºŒä¸ªå‚æ•°çš„åç§° toï¼Œå¹¶å°†å…¶è®¾ç½®ä¸º 10ã€‚æœ€åï¼ŒæŒ‰å›è½¦é”®ã€‚\n\nseq(from = 1, to = 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nWe often omit the names of the first several arguments in function calls, so we can rewrite this as follows:\nåœ¨å‡½æ•°è°ƒç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸çœç•¥å‰å‡ ä¸ªå‚æ•°çš„åç§°ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åƒä¸‹é¢è¿™æ ·é‡å†™ï¼š\n\nseq(1, 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nType the following code and notice that RStudio provides similar assistance with the paired quotation marks:\nè¾“å…¥ä»¥ä¸‹ä»£ç ï¼Œä½ ä¼šå‘ç° RStudio å¯¹æˆå¯¹çš„å¼•å·ä¹Ÿæä¾›äº†ç±»ä¼¼çš„è¾…åŠ©åŠŸèƒ½ï¼š\n\nx &lt;- \"hello world\"\n\nQuotation marks and parentheses must always come in a pair. RStudio does its best to help you, but itâ€™s still possible to mess up and end up with a mismatch. If this happens, R will show you the continuation character â€œ+â€:\nå¼•å·å’Œæ‹¬å·å¿…é¡»æ€»æ˜¯æˆå¯¹å‡ºç°ã€‚RStudio ä¼šå°½åŠ›å¸®åŠ©ä½ ï¼Œä½†ä»ç„¶æœ‰å¯èƒ½å‡ºé”™ï¼Œå¯¼è‡´æ‹¬å·æˆ–å¼•å·ä¸åŒ¹é…ã€‚å¦‚æœå‘ç”Ÿè¿™ç§æƒ…å†µï¼ŒR ä¼šæ˜¾ç¤ºä¸€ä¸ªç»­è¡Œç¬¦ +ï¼š\n&gt; x &lt;- \"hello\n+\nThe + tells you that R is waiting for more input; it doesnâ€™t think youâ€™re done yet. Usually, this means youâ€™ve forgotten either a \" or a ). Either add the missing pair, or press ESCAPE to abort the expression and try again.\nè¿™ä¸ª + å‘Šè¯‰ä½  R æ­£åœ¨ç­‰å¾…æ›´å¤šè¾“å…¥ï¼›å®ƒè®¤ä¸ºä½ è¿˜æ²¡æœ‰å®Œæˆè¾“å…¥ã€‚é€šå¸¸ï¼Œè¿™æ„å‘³ç€ä½ å¿˜è®°äº†è¾“å…¥ä¸€ä¸ª \" æˆ– )ã€‚ä½ å¯ä»¥è¡¥ä¸Šç¼ºå¤±çš„ç¬¦å·ï¼Œæˆ–è€…æŒ‰ ESCAPE é”®ä¸­æ­¢è¡¨è¾¾å¼å¹¶é‡è¯•ã€‚\nNote that the environment tab in the upper right pane displays all of the objects that youâ€™ve created:\næ³¨æ„ï¼Œå³ä¸Šè§’çª—æ ¼ä¸­çš„ç¯å¢ƒ (environment) æ ‡ç­¾é¡µä¼šæ˜¾ç¤ºä½ åˆ›å»ºçš„æ‰€æœ‰å¯¹è±¡ï¼š",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#exercises",
    "href": "workflow-basics.html#exercises",
    "title": "2Â  Workflow: basics",
    "section": "\n2.5 Exercises",
    "text": "2.5 Exercises",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#exercises-1",
    "href": "workflow-basics.html#exercises-1",
    "title": "2Â  Workflow: basics",
    "section": "\n2.6 Exercises",
    "text": "2.6 Exercises\n\n\nWhy does this code not work?\n\nmy_variable &lt;- 10\nmy_varÄ±able\n#&gt; Error: object 'my_varÄ±able' not found\n\nLook carefully! (This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.)\n\n\nTweak each of the following R commands so that they run correctly:\n\nlibary(todyverse)\n\nggplot(dTA = mpg) + \n  geom_point(maping = aes(x = displ y = hwy)) +\n  geom_smooth(method = \"lm)\n\n\nPress Option + Shift + K / Alt + Shift + K. What happens? How can you get to the same place using the menus?\n\nLetâ€™s revisit an exercise from the Section 1.6. Run the following lines of code. Which of the two plots is saved as mpg-plot.png? Why?\n\nmy_bar_plot &lt;- ggplot(mpg, aes(x = class)) +\n  geom_bar()\nmy_scatter_plot &lt;- ggplot(mpg, aes(x = cty, y = hwy)) +\n  geom_point()\nggsave(filename = \"mpg-plot.png\", plot = my_bar_plot)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#summary",
    "href": "workflow-basics.html#summary",
    "title": "2Â  Workflow: basics",
    "section": "\n2.7 Summary",
    "text": "2.7 Summary\nNow that youâ€™ve learned a little more about how R code works, and some tips to help you understand your code when you come back to it in the future. In the next chapter, weâ€™ll continue your data science journey by teaching you about dplyr, the tidyverse package that helps you transform data, whether itâ€™s selecting important variables, filtering down to rows of interest, or computing summary statistics.\nç°åœ¨ä½ å·²ç»å¯¹ R ä»£ç çš„å·¥ä½œåŸç†æœ‰äº†æ›´å¤šäº†è§£ï¼Œä¹ŸæŒæ¡äº†ä¸€äº›æŠ€å·§ï¼Œå¯ä»¥å¸®åŠ©ä½ åœ¨æœªæ¥å›é¡¾ä»£ç æ—¶æ›´å¥½åœ°ç†è§£å®ƒã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­ä½ çš„æ•°æ®ç§‘å­¦ä¹‹æ—…ï¼Œæ•™ä½ å…³äº dplyr çš„çŸ¥è¯†ï¼Œå®ƒæ˜¯ tidyverse ä¸­çš„ä¸€ä¸ªåŒ…ï¼Œå¯ä»¥å¸®åŠ©ä½ è½¬æ¢æ•°æ®ï¼Œæ— è®ºæ˜¯é€‰æ‹©é‡è¦å˜é‡ã€ç­›é€‰æ„Ÿå…´è¶£çš„è¡Œï¼Œè¿˜æ˜¯è®¡ç®—æ±‡æ€»ç»Ÿè®¡æ•°æ®ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Workflow: basics</span>"
    ]
  },
  {
    "objectID": "data-transform.html",
    "href": "data-transform.html",
    "title": "3Â  Data transformation",
    "section": "",
    "text": "3.1 Introduction\nVisualization is an important tool for generating insight, but itâ€™s rare that you get the data in exactly the right form you need to make the graph you want.\nå¯è§†åŒ–æ˜¯äº§ç”Ÿæ´å¯ŸåŠ›çš„é‡è¦å·¥å…·ï¼Œä½†ä½ å¾ˆå°‘èƒ½ä»¥ä½ éœ€è¦çš„ç¡®åˆ‡å½¢å¼è·å¾—æ•°æ®æ¥åˆ¶ä½œä½ æƒ³è¦çš„å›¾è¡¨ã€‚\nOften youâ€™ll need to create some new variables or summaries to answer your questions with your data, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with.\né€šå¸¸ï¼Œä½ éœ€è¦åˆ›å»ºä¸€äº›æ–°çš„å˜é‡æˆ–æ‘˜è¦æ¥ç”¨ä½ çš„æ•°æ®å›ç­”ä½ çš„é—®é¢˜ï¼Œæˆ–è€…ä½ å¯èƒ½åªæ˜¯æƒ³é‡å‘½åå˜é‡æˆ–é‡æ–°æ’åºè§‚æµ‹å€¼ï¼Œä»¥ä½¿æ•°æ®æ›´å®¹æ˜“å¤„ç†ã€‚\nYouâ€™ll learn how to do all that (and more!) in this chapter, which will introduce you to data transformation using the dplyr package and a new dataset on flights that departed from New York City in 2013.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•åšåˆ°æ‰€æœ‰è¿™äº› (ä»¥åŠæ›´å¤šï¼)ï¼Œæœ¬ç« å°†å‘ä½ ä»‹ç»å¦‚ä½•ä½¿ç”¨ dplyr åŒ…å’Œä¸€ä¸ªå…³äº 2013 å¹´ä»çº½çº¦å¸‚èµ·é£çš„èˆªç­çš„æ–°æ•°æ®é›†æ¥è¿›è¡Œæ•°æ®è½¬æ¢ã€‚\nThe goal of this chapter is to give you an overview of all the key tools for transforming a data frame.\næœ¬ç« çš„ç›®æ ‡æ˜¯è®©ä½ å¯¹è½¬æ¢æ•°æ®æ¡† (data frame) çš„æ‰€æœ‰å…³é”®å·¥å…·æœ‰ä¸€ä¸ªæ¦‚è§ˆã€‚\nWeâ€™ll start with functions that operate on rows and then columns of a data frame, then circle back to talk more about the pipe, an important tool that you use to combine verbs.\næˆ‘ä»¬å°†ä»æ“ä½œæ•°æ®æ¡†çš„è¡Œå’Œåˆ—çš„å‡½æ•°å¼€å§‹ï¼Œç„¶åå›è¿‡å¤´æ¥æ›´å¤šåœ°è®¨è®ºç®¡é“ (pipe)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨æ¥ç»„åˆåŠ¨è¯ (verb) çš„é‡è¦å·¥å…·ã€‚\nWe will then introduce the ability to work with groups.\nç„¶åæˆ‘ä»¬å°†ä»‹ç»å¤„ç†åˆ†ç»„çš„èƒ½åŠ›ã€‚\nWe will end the chapter with a case study that showcases these functions in action.\næˆ‘ä»¬å°†ä»¥ä¸€ä¸ªæ¡ˆä¾‹ç ”ç©¶æ¥ç»“æŸæœ¬ç« ï¼Œå±•ç¤ºè¿™äº›å‡½æ•°çš„å®é™…åº”ç”¨ã€‚\nIn later chapters, weâ€™ll return to the functions in more detail as we start to dig into specific types of data (e.g., numbers, strings, dates).\nåœ¨åé¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°å›é¡¾è¿™äº›å‡½æ•°ï¼Œå› ä¸ºæˆ‘ä»¬å°†å¼€å§‹æ·±å…¥ç ”ç©¶ç‰¹å®šç±»å‹çš„æ•°æ® (ä¾‹å¦‚ï¼Œæ•°å­—ã€å­—ç¬¦ä¸²ã€æ—¥æœŸ)ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#introduction",
    "href": "data-transform.html#introduction",
    "title": "3Â  Data transformation",
    "section": "",
    "text": "3.1.1 Prerequisites\nIn this chapter, weâ€™ll focus on the dplyr package, another core member of the tidyverse.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç» dplyr åŒ…ï¼Œå®ƒæ˜¯ tidyverse çš„å¦ä¸€ä¸ªæ ¸å¿ƒæˆå‘˜ã€‚\nWeâ€™ll illustrate the key ideas using data from the nycflights13 package and use ggplot2 to help us understand the data.\næˆ‘ä»¬å°†ä½¿ç”¨ nycflights13 åŒ…ä¸­çš„æ•°æ®æ¥è¯´æ˜å…³é”®æ€æƒ³ï¼Œå¹¶ä½¿ç”¨ ggplot2 æ¥å¸®åŠ©æˆ‘ä»¬ç†è§£æ•°æ®ã€‚\n\nlibrary(nycflights13)\nlibrary(tidyverse)\n#&gt; â”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\n#&gt; âœ” dplyr     1.1.4     âœ” readr     2.1.5\n#&gt; âœ” forcats   1.0.0     âœ” stringr   1.5.1\n#&gt; âœ” ggplot2   3.5.2     âœ” tibble    3.3.0\n#&gt; âœ” lubridate 1.9.4     âœ” tidyr     1.3.1\n#&gt; âœ” purrr     1.0.4     \n#&gt; â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\n#&gt; âœ– dplyr::filter() masks stats::filter()\n#&gt; âœ– dplyr::lag()    masks stats::lag()\n#&gt; â„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nTake careful note of the conflicts message thatâ€™s printed when you load the tidyverse.\nè¯·ä»”ç»†æ³¨æ„åŠ è½½ tidyverse æ—¶æ‰“å°çš„å†²çªæ¶ˆæ¯ã€‚\nIt tells you that dplyr overwrites some functions in base R.\nå®ƒå‘Šè¯‰ä½  dplyr è¦†ç›–äº†åŸºç¡€ R ä¸­çš„ä¸€äº›å‡½æ•°ã€‚\nIf you want to use the base version of these functions after loading dplyr, youâ€™ll need to use their full names: stats::filter() and stats::lag().\nå¦‚æœåœ¨åŠ è½½ dplyr åæƒ³ä½¿ç”¨è¿™äº›å‡½æ•°çš„åŸºç¡€ç‰ˆæœ¬ï¼Œä½ éœ€è¦ä½¿ç”¨å®ƒä»¬çš„å…¨åï¼šstats::filter() å’Œ stats::lag()ã€‚\nSo far, weâ€™ve mostly ignored which package a function comes from because it doesnâ€™t usually matter.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¤§å¤šå¿½ç•¥äº†å‡½æ•°æ¥è‡ªå“ªä¸ªåŒ…ï¼Œå› ä¸ºå®ƒé€šå¸¸ä¸é‡è¦ã€‚\nHowever, knowing the package can help you find help and find related functions, so when we need to be precise about which package a function comes from, weâ€™ll use the same syntax as R: packagename::functionname().\nç„¶è€Œï¼ŒçŸ¥é“åŒ…å¯ä»¥å¸®åŠ©ä½ æ‰¾åˆ°å¸®åŠ©å’Œç›¸å…³çš„å‡½æ•°ï¼Œæ‰€ä»¥å½“æˆ‘ä»¬éœ€â€‹â€‹è¦ç²¾ç¡®åœ°æŒ‡å‡ºå‡½æ•°æ¥è‡ªå“ªä¸ªåŒ…æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸ R ç›¸åŒçš„è¯­æ³•ï¼špackagename::functionname()ã€‚\n\n3.1.2 nycflights13\nTo explore the basic dplyr verbs, we will use nycflights13::flights.\nä¸ºäº†æ¢ç´¢åŸºæœ¬çš„ dplyr åŠ¨è¯ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ nycflights13::flightsã€‚\nThis dataset contains all 336,776 flights that departed from New York City in 2013.\nè¿™ä¸ªæ•°æ®é›†åŒ…å«äº† 2013 å¹´ä»çº½çº¦å¸‚å‡ºå‘çš„æ‰€æœ‰ 336,776 ä¸ªèˆªç­ã€‚\nThe data comes from the US Bureau of Transportation Statistics and is documented in ?flights.\næ•°æ®æ¥è‡ªç¾å›½äº¤é€šç»Ÿè®¡å±€ï¼Œå¹¶åœ¨ ?flights ä¸­æœ‰æ–‡æ¡£è®°å½•ã€‚\n\nflights\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nflights is a tibble, a special type of data frame used by the tidyverse to avoid some common gotchas.flights æ˜¯ä¸€ä¸ª tibbleï¼Œè¿™æ˜¯ tidyverse ä½¿ç”¨çš„ä¸€ç§ç‰¹æ®Šç±»å‹çš„æ•°æ®æ¡†ï¼Œä»¥é¿å…ä¸€äº›å¸¸è§çš„é™·é˜±ã€‚\nThe most important difference between tibbles and data frames is the way tibbles print; they are designed for large datasets, so they only show the first few rows and only the columns that fit on one screen.\ntibble å’Œæ•°æ®æ¡†ä¹‹é—´æœ€é‡è¦çš„åŒºåˆ«åœ¨äº tibble çš„æ‰“å°æ–¹å¼ï¼›å®ƒä»¬ä¸“ä¸ºå¤§å‹æ•°æ®é›†è®¾è®¡ï¼Œå› æ­¤åªæ˜¾ç¤ºå‰å‡ è¡Œå’Œèƒ½åœ¨ä¸€å±å†…æ˜¾ç¤ºçš„åˆ—ã€‚\nThere are a few options to see everything.\næœ‰å‡ ä¸ªé€‰é¡¹å¯ä»¥æŸ¥çœ‹æ‰€æœ‰å†…å®¹ã€‚\nIf youâ€™re using RStudio, the most convenient is probably View(flights), which opens an interactive, scrollable, and filterable view.\nå¦‚æœä½ æ­£åœ¨ä½¿ç”¨ RStudioï¼Œæœ€æ–¹ä¾¿çš„å¯èƒ½æ˜¯ View(flights)ï¼Œå®ƒä¼šæ‰“å¼€ä¸€ä¸ªäº¤äº’å¼çš„ã€å¯æ»šåŠ¨çš„å’Œå¯ç­›é€‰çš„è§†å›¾ã€‚\nOtherwise you can use print(flights, width = Inf) to show all columns, or use glimpse():\nå¦åˆ™ï¼Œä½ å¯ä»¥ä½¿ç”¨ print(flights, width = Inf) æ¥æ˜¾ç¤ºæ‰€æœ‰åˆ—ï¼Œæˆ–è€…ä½¿ç”¨ glimpse()ï¼š\n\nglimpse(flights)\n#&gt; Rows: 336,776\n#&gt; Columns: 19\n#&gt; $ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013â€¦\n#&gt; $ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦\n#&gt; $ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦\n#&gt; $ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 55â€¦\n#&gt; $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 60â€¦\n#&gt; $ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2,â€¦\n#&gt; $ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 8â€¦\n#&gt; $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 8â€¦\n#&gt; $ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7,â€¦\n#&gt; $ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\"â€¦\n#&gt; $ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301â€¦\n#&gt; $ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"Nâ€¦\n#&gt; $ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGâ€¦\n#&gt; $ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAâ€¦\n#&gt; $ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149â€¦\n#&gt; $ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 73â€¦\n#&gt; $ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6â€¦\n#&gt; $ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59â€¦\n#&gt; $ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-0â€¦\n\nIn both views, the variable names are followed by abbreviations that tell you the type of each variable: &lt;int&gt; is short for integer, &lt;dbl&gt; is short for double (aka real numbers), &lt;chr&gt; for character (aka strings), and &lt;dttm&gt; for date-time.\nåœ¨è¿™ä¸¤ç§è§†å›¾ä¸­ï¼Œå˜é‡ååé¢éƒ½è·Ÿç€ç¼©å†™ï¼Œå‘Šè¯‰ä½ æ¯ä¸ªå˜é‡çš„ç±»å‹ï¼š&lt;int&gt; æ˜¯æ•´æ•° (integer) çš„ç¼©å†™ï¼Œ&lt;dbl&gt; æ˜¯åŒç²¾åº¦æµ®ç‚¹æ•° (double) (ä¹Ÿç§°ä¸ºå®æ•°) çš„ç¼©å†™ï¼Œ&lt;chr&gt; æ˜¯å­—ç¬¦ (character) (ä¹Ÿç§°ä¸ºå­—ç¬¦ä¸²) çš„ç¼©å†™ï¼Œè€Œ &lt;dttm&gt; æ˜¯æ—¥æœŸæ—¶é—´ (date-time) çš„ç¼©å†™ã€‚\nThese are important because the operations you can perform on a column depend heavily on its â€œtype.â€\nè¿™äº›éƒ½å¾ˆé‡è¦ï¼Œå› ä¸ºä½ å¯ä»¥å¯¹ä¸€åˆ—æ‰§è¡Œçš„æ“ä½œåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºå®ƒçš„â€œç±»å‹â€ã€‚\n\n3.1.3 dplyr basics\nYouâ€™re about to learn the primary dplyr verbs (functions), which will allow you to solve the vast majority of your data manipulation challenges.\nä½ å³å°†å­¦ä¹ ä¸»è¦çš„ dplyr åŠ¨è¯ (å‡½æ•°)ï¼Œå®ƒä»¬å°†ä½¿ä½ èƒ½å¤Ÿè§£å†³ç»å¤§å¤šæ•°çš„æ•°æ®æ“ä½œæŒ‘æˆ˜ã€‚\nBut before we discuss their individual differences, itâ€™s worth stating what they have in common:\nä½†åœ¨æˆ‘ä»¬è®¨è®ºå®ƒä»¬çš„ä¸ªä½“å·®å¼‚ä¹‹å‰ï¼Œæœ‰å¿…è¦è¯´æ˜å®ƒä»¬çš„å…±åŒç‚¹ï¼š\n\nThe first argument is always a data frame.\nç¬¬ä¸€ä¸ªå‚æ•°æ€»æ˜¯ä¸€ä¸ªæ•°æ®æ¡†ã€‚\nThe subsequent arguments typically describe which columns to operate on using the variable names (without quotes).\nåç»­çš„å‚æ•°é€šå¸¸ä½¿ç”¨å˜é‡å (ä¸å¸¦å¼•å·) æ¥æè¿°è¦æ“ä½œçš„åˆ—ã€‚\nThe output is always a new data frame.\nè¾“å‡ºæ€»æ˜¯ä¸€ä¸ªæ–°çš„æ•°æ®æ¡†ã€‚\n\nBecause each verb does one thing well, solving complex problems will usually require combining multiple verbs, and weâ€™ll do so with the pipe, |&gt;.\nå› ä¸ºæ¯ä¸ªåŠ¨è¯éƒ½èƒ½å¾ˆå¥½åœ°å®Œæˆä¸€ä»¶äº‹ï¼Œæ‰€ä»¥è§£å†³å¤æ‚é—®é¢˜é€šå¸¸éœ€è¦ç»„åˆå¤šä¸ªåŠ¨è¯ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç®¡é“ |&gt; æ¥å®ç°è¿™ä¸€ç‚¹ã€‚\nWeâ€™ll discuss the pipe more in Section 3.4, but in brief, the pipe takes the thing on its left and passes it along to the function on its right so that x |&gt; f(y) is equivalent to f(x, y), and x |&gt; f(y) |&gt; g(z) is equivalent to g(f(x, y), z).\næˆ‘ä»¬å°†åœ¨ Section 3.4 ä¸­æ›´è¯¦ç»†åœ°è®¨è®ºç®¡é“ï¼Œä½†ç®€è€Œè¨€ä¹‹ï¼Œç®¡é“å°†å…¶å·¦è¾¹çš„ä¸œè¥¿ä¼ é€’ç»™å…¶å³è¾¹çš„å‡½æ•°ï¼Œå› æ­¤ x |&gt; f(y) ç­‰åŒäº f(x, y)ï¼Œè€Œ x |&gt; f(y) |&gt; g(z) ç­‰åŒäº g(f(x, y), z)ã€‚\nThe easiest way to pronounce the pipe is â€œthenâ€.\nç®¡é“æœ€ç®€å•çš„å‘éŸ³æ˜¯â€œç„¶åâ€ (then)ã€‚\nThat makes it possible to get a sense of the following code even though you havenâ€™t yet learned the details:\nè¿™ä½¿å¾—å³ä½¿ä½ è¿˜æ²¡æœ‰å­¦ä¹ ç»†èŠ‚ï¼Œä¹Ÿèƒ½ç†è§£ä»¥ä¸‹ä»£ç çš„å«ä¹‰ï¼š\n\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\ndplyrâ€™s verbs are organized into four groups based on what they operate on: rows, columns, groups, or tables.\ndplyr çš„åŠ¨è¯æ ¹æ®å®ƒä»¬æ“ä½œçš„å¯¹è±¡åˆ†ä¸ºå››ç»„ï¼šè¡Œã€åˆ—ã€ç»„ æˆ– è¡¨ã€‚\nIn the following sections, youâ€™ll learn the most important verbs for rows, columns, and groups.\nåœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼Œä½ å°†å­¦ä¹ é’ˆå¯¹è¡Œã€åˆ—å’Œç»„çš„æœ€é‡è¦çš„åŠ¨è¯ã€‚\nThen, weâ€™ll return to the join verbs that work on tables in Chapter 19.\nç„¶åï¼Œæˆ‘ä»¬å°†åœ¨ Chapter 19 ä¸­å›åˆ°å¤„ç†è¡¨çš„è¿æ¥åŠ¨è¯ã€‚\nLetâ€™s dive in!\nè®©æˆ‘ä»¬å¼€å§‹å§ï¼",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#rows",
    "href": "data-transform.html#rows",
    "title": "3Â  Data transformation",
    "section": "\n3.2 Rows",
    "text": "3.2 Rows\nThe most important verbs that operate on rows of a dataset are filter(), which changes which rows are present without changing their order, and arrange(), which changes the order of the rows without changing which are present.\næ“ä½œæ•°æ®é›†è¡Œçš„æœ€é‡è¦çš„åŠ¨è¯æ˜¯ filter()ï¼Œå®ƒåœ¨ä¸æ”¹å˜è¡Œé¡ºåºçš„æƒ…å†µä¸‹æ”¹å˜å­˜åœ¨çš„è¡Œï¼›ä»¥åŠ arrange()ï¼Œå®ƒåœ¨ä¸æ”¹å˜å­˜åœ¨çš„è¡Œçš„æƒ…å†µä¸‹æ”¹å˜è¡Œçš„é¡ºåºã€‚\nBoth functions only affect the rows, and the columns are left unchanged.\nè¿™ä¸¤ä¸ªå‡½æ•°éƒ½åªå½±å“è¡Œï¼Œåˆ—ä¿æŒä¸å˜ã€‚\nWeâ€™ll also discuss distinct() which finds rows with unique values.\næˆ‘ä»¬è¿˜å°†è®¨è®º distinct()ï¼Œå®ƒèƒ½æ‰¾åˆ°å…·æœ‰å”¯ä¸€å€¼çš„è¡Œã€‚\nUnlike arrange() and filter() it can also optionally modify the columns.\nä¸ arrange() å’Œ filter() ä¸åŒï¼Œå®ƒè¿˜å¯ä»¥é€‰æ‹©æ€§åœ°ä¿®æ”¹åˆ—ã€‚\n\n3.2.1 filter()\n\nfilter() allows you to keep rows based on the values of the columns1.filter() å…è®¸ä½ æ ¹æ®åˆ—çš„å€¼ä¿ç•™è¡Œ1ã€‚\nThe first argument is the data frame.\nç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ•°æ®æ¡†ã€‚\nThe second and subsequent arguments are the conditions that must be true to keep the row.\nç¬¬äºŒä¸ªåŠåç»­å‚æ•°æ˜¯å¿…é¡»ä¸ºçœŸæ‰èƒ½ä¿ç•™è¯¥è¡Œçš„æ¡ä»¶ã€‚\nFor example, we could find all flights that departed more than 120 minutes (two hours) late:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°æ‰€æœ‰æ™šç‚¹è¶…è¿‡ 120 åˆ†é’Ÿ (ä¸¤å°æ—¶) çš„èˆªç­ï¼š\n\nflights |&gt; \n  filter(dep_delay &gt; 120)\n#&gt; # A tibble: 9,723 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      848           1835       853     1001           1950\n#&gt; 2  2013     1     1      957            733       144     1056            853\n#&gt; 3  2013     1     1     1114            900       134     1447           1222\n#&gt; 4  2013     1     1     1540           1338       122     2020           1825\n#&gt; 5  2013     1     1     1815           1325       290     2120           1542\n#&gt; 6  2013     1     1     1842           1422       260     1958           1535\n#&gt; # â„¹ 9,717 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nAs well as &gt; (greater than), you can use &gt;= (greater than or equal to), &lt; (less than), &lt;= (less than or equal to), == (equal to), and != (not equal to).\né™¤äº† &gt; (å¤§äº)ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨ &gt;= (å¤§äºæˆ–ç­‰äº)ã€&lt; (å°äº)ã€&lt;= (å°äºæˆ–ç­‰äº)ã€== (ç­‰äº) å’Œ != (ä¸ç­‰äº)ã€‚\nYou can also combine conditions with & or , to indicate â€œandâ€ (check for both conditions) or with | to indicate â€œorâ€ (check for either condition):\nä½ è¿˜å¯ä»¥ä½¿ç”¨ & æˆ– , æ¥ç»„åˆæ¡ä»¶ï¼Œè¡¨ç¤ºâ€œä¸â€ (æ£€æŸ¥ä¸¤ä¸ªæ¡ä»¶)ï¼Œæˆ–ä½¿ç”¨ | è¡¨ç¤ºâ€œæˆ–â€ (æ£€æŸ¥ä»»ä¸€æ¡ä»¶)ï¼š\n\n# Flights that departed on January 1\nflights |&gt; \n  filter(month == 1 & day == 1)\n#&gt; # A tibble: 842 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 836 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\n# Flights that departed in January or February\nflights |&gt; \n  filter(month == 1 | month == 2)\n#&gt; # A tibble: 51,955 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 51,949 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nThereâ€™s a useful shortcut when youâ€™re combining | and ==: %in%.\nå½“ä½ ç»„åˆ | å’Œ == æ—¶ï¼Œæœ‰ä¸€ä¸ªæœ‰ç”¨çš„å¿«æ·æ–¹å¼ï¼š%in%ã€‚\nIt keeps rows where the variable equals one of the values on the right:\nå®ƒä¼šä¿ç•™å˜é‡ç­‰äºå³ä¾§å€¼ä¹‹ä¸€çš„è¡Œï¼š\n\n# A shorter way to select flights that departed in January or February\nflights |&gt; \n  filter(month %in% c(1, 2))\n#&gt; # A tibble: 51,955 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 51,949 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nWeâ€™ll come back to these comparisons and logical operators in more detail in Chapter 12.\næˆ‘ä»¬å°†åœ¨ Chapter 12 ä¸­æ›´è¯¦ç»†åœ°å›é¡¾è¿™äº›æ¯”è¾ƒå’Œé€»è¾‘è¿ç®—ç¬¦ã€‚\nWhen you run filter() dplyr executes the filtering operation, creating a new data frame, and then prints it.\nå½“ä½ è¿è¡Œ filter() æ—¶ï¼Œdplyr ä¼šæ‰§è¡Œç­›é€‰æ“ä½œï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®æ¡†ï¼Œç„¶åæ‰“å°å®ƒã€‚\nIt doesnâ€™t modify the existing flights dataset because dplyr functions never modify their inputs.\nå®ƒä¸ä¼šä¿®æ”¹ç°æœ‰çš„ flights æ•°æ®é›†ï¼Œå› ä¸º dplyr å‡½æ•°ä»ä¸ä¿®æ”¹å®ƒä»¬çš„è¾“å…¥ã€‚\nTo save the result, you need to use the assignment operator, &lt;-:\nè¦ä¿å­˜ç»“æœï¼Œä½ éœ€è¦ä½¿ç”¨èµ‹å€¼è¿ç®—ç¬¦ &lt;-ï¼š\n\njan1 &lt;- flights |&gt; \n  filter(month == 1 & day == 1)\n\n\n3.2.2 Common mistakes\nWhen youâ€™re starting out with R, the easiest mistake to make is to use = instead of == when testing for equality.\nå½“ä½ åˆšå¼€å§‹ä½¿ç”¨ R æ—¶ï¼Œæœ€å®¹æ˜“çŠ¯çš„é”™è¯¯æ˜¯åœ¨æµ‹è¯•ç›¸ç­‰æ€§æ—¶ä½¿ç”¨ = è€Œä¸æ˜¯ ==ã€‚\nfilter() will let you know when this happens:filter() ä¼šåœ¨è¿™ç§æƒ…å†µä¸‹é€šçŸ¥ä½ ï¼š\n\nflights |&gt; \n  filter(month = 1)\n#&gt; Error in `filter()`:\n#&gt; ! We detected a named input.\n#&gt; â„¹ This usually means that you've used `=` instead of `==`.\n#&gt; â„¹ Did you mean `month == 1`?\n\nAnother mistakes is you write â€œorâ€ statements like you would in English:\nå¦ä¸€ä¸ªé”™è¯¯æ˜¯ä½ åƒç”¨è‹±è¯­ä¸€æ ·å†™â€œæˆ–â€è¯­å¥ï¼š\n\nflights |&gt; \n  filter(month == 1 | 2)\n\nThis â€œworksâ€, in the sense that it doesnâ€™t throw an error, but it doesnâ€™t do what you want because | first checks the condition month == 1 and then checks the condition 2, which is not a sensible condition to check.\nè¿™â€œè¡Œå¾—é€šâ€ï¼Œå› ä¸ºå®ƒä¸ä¼šæŠ›å‡ºé”™è¯¯ï¼Œä½†å®ƒæ²¡æœ‰åšä½ æƒ³è¦çš„ï¼Œå› ä¸º | é¦–å…ˆæ£€æŸ¥æ¡ä»¶ month == 1ï¼Œç„¶åæ£€æŸ¥æ¡ä»¶ 2ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªåˆç†çš„æ£€æŸ¥æ¡ä»¶ã€‚\nWeâ€™ll learn more about whatâ€™s happening here and why in Section 12.3.2.\næˆ‘ä»¬å°†åœ¨ Section 12.3.2 ä¸­æ›´å¤šåœ°äº†è§£è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆä»¥åŠä¸ºä»€ä¹ˆä¼šè¿™æ ·ã€‚\n\n3.2.3 arrange()\n\narrange() changes the order of the rows based on the value of the columns.arrange() æ ¹æ®åˆ—çš„å€¼æ”¹å˜è¡Œçš„é¡ºåºã€‚\nIt takes a data frame and a set of column names (or more complicated expressions) to order by.\nå®ƒæ¥å—ä¸€ä¸ªæ•°æ®æ¡†å’Œä¸€ç»„åˆ—å (æˆ–æ›´å¤æ‚çš„è¡¨è¾¾å¼) ä½œä¸ºæ’åºä¾æ®ã€‚\nIf you provide more than one column name, each additional column will be used to break ties in the values of the preceding columns.\nå¦‚æœä½ æä¾›å¤šä¸ªåˆ—åï¼Œæ¯ä¸ªé¢å¤–çš„åˆ—å°†ç”¨äºæ‰“ç ´å‰é¢åˆ—å€¼ä¸­çš„å¹³å±€ã€‚\nFor example, the following code sorts by the departure time, which is spread over four columns.\nä¾‹å¦‚ï¼Œä»¥ä¸‹ä»£ç æŒ‰å‡ºå‘æ—¶é—´æ’åºï¼Œè¯¥æ—¶é—´åˆ†å¸ƒåœ¨å››åˆ—ä¸­ã€‚\nWe get the earliest years first, then within a year, the earliest months, etc.\næˆ‘ä»¬é¦–å…ˆå¾—åˆ°æœ€æ—©çš„å¹´ä»½ï¼Œç„¶ååœ¨ä¸€å¹´å†…ï¼Œå¾—åˆ°æœ€æ—©çš„æœˆä»½ï¼Œä¾æ­¤ç±»æ¨ã€‚\n\nflights |&gt; \n  arrange(year, month, day, dep_time)\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nYou can use desc() on a column inside of arrange() to re-order the data frame based on that column in descending (big-to-small) order.\nä½ å¯ä»¥åœ¨ arrange() å†…éƒ¨å¯¹åˆ—ä½¿ç”¨ desc()ï¼Œä»¥æŒ‰è¯¥åˆ—çš„é™åº (ä»å¤§åˆ°å°) é‡æ–°æ’åºæ•°æ®æ¡†ã€‚\nFor example, this code orders flights from most to least delayed:\nä¾‹å¦‚ï¼Œæ­¤ä»£ç å°†èˆªç­ä»æœ€æ™šç‚¹åˆ°æœ€å°‘æ™šç‚¹æ’åºï¼š\n\nflights |&gt; \n  arrange(desc(dep_delay))\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     9      641            900      1301     1242           1530\n#&gt; 2  2013     6    15     1432           1935      1137     1607           2120\n#&gt; 3  2013     1    10     1121           1635      1126     1239           1810\n#&gt; 4  2013     9    20     1139           1845      1014     1457           2210\n#&gt; 5  2013     7    22      845           1600      1005     1044           1815\n#&gt; 6  2013     4    10     1100           1900       960     1342           2211\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nNote that the number of rows has not changed â€“ weâ€™re only arranging the data, weâ€™re not filtering it.\nè¯·æ³¨æ„ï¼Œè¡Œæ•°æ²¡æœ‰æ”¹å˜â€”â€”æˆ‘ä»¬åªæ˜¯åœ¨æ’åˆ—æ•°æ®ï¼Œè€Œä¸æ˜¯ç­›é€‰æ•°æ®ã€‚\n\n3.2.4 distinct()\n\ndistinct() finds all the unique rows in a dataset, so technically, it primarily operates on the rows.distinct() åœ¨æ•°æ®é›†ä¸­æŸ¥æ‰¾æ‰€æœ‰å”¯ä¸€çš„è¡Œï¼Œå› æ­¤ä»æŠ€æœ¯ä¸Šè®²ï¼Œå®ƒä¸»è¦ä½œç”¨äºè¡Œã€‚\nMost of the time, however, youâ€™ll want the distinct combination of some variables, so you can also optionally supply column names:\nç„¶è€Œï¼Œå¤§å¤šæ•°æ—¶å€™ï¼Œä½ ä¼šæƒ³è¦ä¸€äº›å˜é‡çš„ç‹¬ç‰¹ç»„åˆï¼Œæ‰€ä»¥ä½ ä¹Ÿå¯ä»¥é€‰æ‹©æ€§åœ°æä¾›åˆ—åï¼š\n\n# Remove duplicate rows, if any\nflights |&gt; \n  distinct()\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\n# Find all unique origin and destination pairs\nflights |&gt; \n  distinct(origin, dest)\n#&gt; # A tibble: 224 Ã— 2\n#&gt;   origin dest \n#&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 EWR    IAH  \n#&gt; 2 LGA    IAH  \n#&gt; 3 JFK    MIA  \n#&gt; 4 JFK    BQN  \n#&gt; 5 LGA    ATL  \n#&gt; 6 EWR    ORD  \n#&gt; # â„¹ 218 more rows\n\nAlternatively, if you want to keep the other columns when filtering for unique rows, you can use the .keep_all = TRUE option.\næˆ–è€…ï¼Œå¦‚æœä½ æƒ³åœ¨ç­›é€‰å”¯ä¸€è¡Œæ—¶ä¿ç•™å…¶ä»–åˆ—ï¼Œå¯ä»¥ä½¿ç”¨ .keep_all = TRUE é€‰é¡¹ã€‚\n\nflights |&gt; \n  distinct(origin, dest, .keep_all = TRUE)\n#&gt; # A tibble: 224 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 218 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nItâ€™s not a coincidence that all of these distinct flights are on January 1: distinct() will find the first occurrence of a unique row in the dataset and discard the rest.\næ‰€æœ‰è¿™äº›ä¸åŒçš„èˆªç­éƒ½åœ¨ 1 æœˆ 1 æ—¥å¹¶éå·§åˆï¼šdistinct() ä¼šæ‰¾åˆ°æ•°æ®é›†ä¸­å”¯ä¸€è¡Œçš„ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œå¹¶ä¸¢å¼ƒå…¶ä½™çš„ã€‚\nIf you want to find the number of occurrences instead, youâ€™re better off swapping distinct() for count().\nå¦‚æœä½ æƒ³æŸ¥æ‰¾å‡ºç°æ¬¡æ•°ï¼Œæœ€å¥½å°† distinct() æ¢æˆ count()ã€‚\nWith the sort = TRUE argument, you can arrange them in descending order of the number of occurrences.\nä½¿ç”¨ sort = TRUE å‚æ•°ï¼Œä½ å¯ä»¥æŒ‰å‡ºç°æ¬¡æ•°çš„é™åºæ’åˆ—å®ƒä»¬ã€‚\nYouâ€™ll learn more about count in Section 13.3.\nä½ å°†åœ¨ Section 13.3 ä¸­å­¦åˆ°æ›´å¤šå…³äº count() çš„çŸ¥è¯†ã€‚\n\nflights |&gt;\n  count(origin, dest, sort = TRUE)\n#&gt; # A tibble: 224 Ã— 3\n#&gt;   origin dest      n\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 JFK    LAX   11262\n#&gt; 2 LGA    ATL   10263\n#&gt; 3 LGA    ORD    8857\n#&gt; 4 JFK    SFO    8204\n#&gt; 5 LGA    CLT    6168\n#&gt; 6 EWR    ORD    6100\n#&gt; # â„¹ 218 more rows\n\n\n3.2.5 Exercises\n\n\nIn a single pipeline for each condition, find all flights that meet the condition:\n\nHad an arrival delay of two or more hours\nFlew to Houston (IAH or HOU)\nWere operated by United, American, or Delta\nDeparted in summer (July, August, and September)\nArrived more than two hours late but didnâ€™t leave late\nWere delayed by at least an hour, but made up over 30 minutes in flight\n\n\nSort flights to find the flights with the longest departure delays. Find the flights that left earliest in the morning.\nSort flights to find the fastest flights. (Hint: Try including a math calculation inside of your function.)\nWas there a flight on every day of 2013?\nWhich flights traveled the farthest distance? Which traveled the least distance?\nDoes it matter what order you used filter() and arrange() if youâ€™re using both? Why/why not? Think about the results and how much work the functions would have to do.",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#columns",
    "href": "data-transform.html#columns",
    "title": "3Â  Data transformation",
    "section": "\n3.3 Columns",
    "text": "3.3 Columns\nThere are four important verbs that affect the columns without changing the rows: mutate() creates new columns that are derived from the existing columns, select() changes which columns are present, rename() changes the names of the columns, and relocate() changes the positions of the columns.\næœ‰å››ä¸ªé‡è¦çš„åŠ¨è¯ä¼šå½±å“åˆ—è€Œä¸æ”¹å˜è¡Œï¼šmutate() ä»ç°æœ‰åˆ—æ´¾ç”Ÿå‡ºæ–°åˆ—ï¼Œselect() æ”¹å˜å­˜åœ¨çš„åˆ—ï¼Œrename() æ”¹å˜åˆ—çš„åç§°ï¼Œrelocate() æ”¹å˜åˆ—çš„ä½ç½®ã€‚\n\n3.3.1 mutate()\n\nThe job of mutate() is to add new columns that are calculated from the existing columns.mutate() çš„å·¥ä½œæ˜¯æ·»åŠ ä»ç°æœ‰åˆ—è®¡ç®—å‡ºçš„æ–°åˆ—ã€‚\nIn the transform chapters, youâ€™ll learn a large set of functions that you can use to manipulate different types of variables.\nåœ¨è½¬æ¢ç« èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å¤§é‡å¯ç”¨äºæ“ä½œä¸åŒç±»å‹å˜é‡çš„å‡½æ•°ã€‚\nFor now, weâ€™ll stick with basic algebra, which allows us to compute the gain, how much time a delayed flight made up in the air, and the speed in miles per hour:\nç°åœ¨ï¼Œæˆ‘ä»¬å°†åšæŒä½¿ç”¨åŸºæœ¬ä»£æ•°ï¼Œå®ƒå…è®¸æˆ‘ä»¬è®¡ç®— gain (å»¶è¯¯çš„èˆªç­åœ¨ç©ºä¸­å¼¥è¡¥äº†å¤šå°‘æ—¶é—´) å’Œ speed (ä»¥è‹±é‡Œ/å°æ—¶ä¸ºå•ä½)ï¼š\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60\n  )\n#&gt; # A tibble: 336,776 Ã— 21\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nBy default, mutate() adds new columns on the right-hand side of your dataset, which makes it difficult to see whatâ€™s happening here.\né»˜è®¤æƒ…å†µä¸‹ï¼Œmutate() ä¼šåœ¨æ•°æ®é›†çš„å³ä¾§æ·»åŠ æ–°åˆ—ï¼Œè¿™ä½¿å¾—å¾ˆéš¾çœ‹æ¸…è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆã€‚\nWe can use the .before argument to instead add the variables to the left-hand side2:\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨ .before å‚æ•°æ¥å°†å˜é‡æ·»åŠ åˆ°å·¦ä¾§2ï¼š\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60,\n    .before = 1\n  )\n#&gt; # A tibble: 336,776 Ã— 21\n#&gt;    gain speed  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    -9  370.  2013     1     1      517            515         2      830\n#&gt; 2   -16  374.  2013     1     1      533            529         4      850\n#&gt; 3   -31  408.  2013     1     1      542            540         2      923\n#&gt; 4    17  517.  2013     1     1      544            545        -1     1004\n#&gt; 5    19  394.  2013     1     1      554            600        -6      812\n#&gt; 6   -16  288.  2013     1     1      554            558        -4      740\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, â€¦\n\nThe . indicates that .before is an argument to the function, not the name of a third new variable we are creating.. è¡¨ç¤º .before æ˜¯å‡½æ•°çš„ä¸€ä¸ªå‚æ•°ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬æ­£åœ¨åˆ›å»ºçš„ç¬¬ä¸‰ä¸ªæ–°å˜é‡çš„åç§°ã€‚\nYou can also use .after to add after a variable, and in both .before and .after you can use the variable name instead of a position.\nä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ .after åœ¨å˜é‡ä¹‹åæ·»åŠ ï¼Œåœ¨ .before å’Œ .after ä¸­ï¼Œä½ éƒ½å¯ä»¥ä½¿ç”¨å˜é‡åè€Œä¸æ˜¯ä½ç½®ã€‚\nFor example, we could add the new variables after day:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ day ä¹‹åæ·»åŠ æ–°å˜é‡ï¼š\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60,\n    .after = day\n  )\n\nAlternatively, you can control which variables are kept with the .keep argument.\næˆ–è€…ï¼Œä½ å¯ä»¥ä½¿ç”¨ .keep å‚æ•°æ¥æ§åˆ¶ä¿ç•™å“ªäº›å˜é‡ã€‚\nA particularly useful argument is \"used\" which specifies that we only keep the columns that were involved or created in the mutate() step.\nä¸€ä¸ªç‰¹åˆ«æœ‰ç”¨çš„å‚æ•°æ˜¯ \"used\"ï¼Œå®ƒæŒ‡å®šæˆ‘ä»¬åªä¿ç•™åœ¨ mutate() æ­¥éª¤ä¸­æ¶‰åŠæˆ–åˆ›å»ºçš„åˆ—ã€‚\nFor example, the following output will contain only the variables dep_delay, arr_delay, air_time, gain, hours, and gain_per_hour.\nä¾‹å¦‚ï¼Œä»¥ä¸‹è¾“å‡ºå°†åªåŒ…å« dep_delayã€arr_delayã€air_timeã€gainã€hours å’Œ gain_per_hour å˜é‡ã€‚\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    hours = air_time / 60,\n    gain_per_hour = gain / hours,\n    .keep = \"used\"\n  )\n\nNote that since we havenâ€™t assigned the result of the above computation back to flights, the new variables gain, hours, and gain_per_hour will only be printed but will not be stored in a data frame.\nè¯·æ³¨æ„ï¼Œç”±äºæˆ‘ä»¬æ²¡æœ‰å°†ä¸Šè¿°è®¡ç®—çš„ç»“æœåˆ†é…å› flightsï¼Œæ–°å˜é‡ gainã€hours å’Œ gain_per_hour å°†åªè¢«æ‰“å°è€Œä¸ä¼šå­˜å‚¨åœ¨æ•°æ®æ¡†ä¸­ã€‚\nAnd if we want them to be available in a data frame for future use, we should think carefully about whether we want the result to be assigned back to flights, overwriting the original data frame with many more variables, or to a new object.\nå¦‚æœæˆ‘ä»¬å¸Œæœ›å®ƒä»¬åœ¨æ•°æ®æ¡†ä¸­å¯ä¾›å°†æ¥ä½¿ç”¨ï¼Œæˆ‘ä»¬åº”è¯¥ä»”ç»†è€ƒè™‘æ˜¯å¦è¦å°†ç»“æœåˆ†é…å› flights (ç”¨æ›´å¤šçš„å˜é‡è¦†ç›–åŸå§‹æ•°æ®æ¡†)ï¼Œè¿˜æ˜¯åˆ†é…ç»™ä¸€ä¸ªæ–°å¯¹è±¡ã€‚\nOften, the right answer is a new object that is named informatively to indicate its contents, e.g., delay_gain, but you might also have good reasons for overwriting flights.\né€šå¸¸ï¼Œæ­£ç¡®çš„ç­”æ¡ˆæ˜¯ä¸€ä¸ªæ–°å¯¹è±¡ï¼Œå…¶åç§°å…·æœ‰ä¿¡æ¯æ€§ï¼Œä»¥æŒ‡ç¤ºå…¶å†…å®¹ï¼Œä¾‹å¦‚ delay_gainï¼Œä½†ä½ ä¹Ÿå¯èƒ½æœ‰å……åˆ†çš„ç†ç”±è¦†ç›– flightsã€‚\n\n3.3.2 select()\n\nItâ€™s not uncommon to get datasets with hundreds or even thousands of variables.\nè·å¾—åŒ…å«æ•°ç™¾ç”šè‡³æ•°åƒä¸ªå˜é‡çš„æ•°æ®é›†å¹¶ä¸å°‘è§ã€‚\nIn this situation, the first challenge is often just focusing on the variables youâ€™re interested in.\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¬¬ä¸€ä¸ªæŒ‘æˆ˜é€šå¸¸åªæ˜¯å…³æ³¨ä½ æ„Ÿå…´è¶£çš„å˜é‡ã€‚\nselect() allows you to rapidly zoom in on a useful subset using operations based on the names of the variables:select() å…è®¸ä½ ä½¿ç”¨åŸºäºå˜é‡åç§°çš„æ“ä½œå¿«é€Ÿæ”¾å¤§åˆ°ä¸€ä¸ªæœ‰ç”¨çš„å­é›†ï¼š\n\n\nSelect columns by name:\næŒ‰åç§°é€‰æ‹©åˆ—ï¼š\n{r}     #| results: false     flights |&gt;        select(year, month, day)\n\n\nSelect all columns between year and day (inclusive):\né€‰æ‹©ä» year åˆ° day (å«) çš„æ‰€æœ‰åˆ—ï¼š\n{r}     #| results: false     flights |&gt;        select(year:day)\n\n\nSelect all columns except those from year to day (inclusive):\né€‰æ‹©é™¤äº†ä» year åˆ° day (å«) ä¹‹å¤–çš„æ‰€æœ‰åˆ—ï¼š\n{r}     #| results: false     flights |&gt;        select(!year:day)\nHistorically this operation was done with - instead of !, so youâ€™re likely to see that in the wild.\nå†å²ä¸Šï¼Œè¿™ä¸ªæ“ä½œæ˜¯ä½¿ç”¨ - è€Œä¸æ˜¯ ! å®Œæˆçš„ï¼Œæ‰€ä»¥ä½ å¾ˆå¯èƒ½åœ¨é‡å¤–çœ‹åˆ°å®ƒã€‚\nThese two operators serve the same purpose but with subtle differences in behavior.\nè¿™ä¸¤ä¸ªè¿ç®—ç¬¦çš„ç›®çš„ç›¸åŒï¼Œä½†åœ¨è¡Œä¸ºä¸Šæœ‰ç»†å¾®çš„å·®åˆ«ã€‚\nWe recommend using ! because it reads as â€œnotâ€ and combines well with & and |.\næˆ‘ä»¬å»ºè®®ä½¿ç”¨ !ï¼Œå› ä¸ºå®ƒè¯»ä½œâ€œéâ€ (not)ï¼Œå¹¶ä¸”èƒ½å¾ˆå¥½åœ°ä¸ & å’Œ | ç»“åˆã€‚\n\n\nSelect all columns that are characters:\né€‰æ‹©æ‰€æœ‰å­—ç¬¦ç±»å‹çš„åˆ—ï¼š\n{r}     #| results: false     flights |&gt;        select(where(is.character))\n\n\nThere are a number of helper functions you can use within select():\nåœ¨ select() ä¸­ä½ å¯ä»¥ä½¿ç”¨è®¸å¤šè¾…åŠ©å‡½æ•°ï¼š\n\nstarts_with(\"abc\"): matches names that begin with â€œabcâ€.\nåŒ¹é…ä»¥ â€œabcâ€ å¼€å¤´çš„åç§°ã€‚\nends_with(\"xyz\"): matches names that end with â€œxyzâ€.\nåŒ¹é…ä»¥ â€œxyzâ€ ç»“å°¾çš„åç§°ã€‚\ncontains(\"ijk\"): matches names that contain â€œijkâ€.\nåŒ¹é…åŒ…å« â€œijkâ€ çš„åç§°ã€‚\nnum_range(\"x\", 1:3): matches x1, x2 and x3.\nåŒ¹é… x1, x2 å’Œ x3ã€‚\n\nSee ?select for more details.\næŸ¥çœ‹ ?select è·å–æ›´å¤šç»†èŠ‚ã€‚\nOnce you know regular expressions (the topic of Chapter 15) youâ€™ll also be able to use matches() to select variables that match a pattern.\nä¸€æ—¦ä½ äº†è§£äº†æ­£åˆ™è¡¨è¾¾å¼ (regular expressions) (Chapter 15 çš„ä¸»é¢˜)ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨ matches() æ¥é€‰æ‹©åŒ¹é…æ¨¡å¼çš„å˜é‡ã€‚\nYou can rename variables as you select() them by using =.\nä½ å¯ä»¥åœ¨ select() æ—¶ä½¿ç”¨ = æ¥é‡å‘½åå˜é‡ã€‚\nThe new name appears on the left-hand side of the =, and the old variable appears on the right-hand side:\næ–°åç§°å‡ºç°åœ¨ = çš„å·¦ä¾§ï¼Œæ—§å˜é‡å‡ºç°åœ¨å³ä¾§ï¼š\n\nflights |&gt; \n  select(tail_num = tailnum)\n#&gt; # A tibble: 336,776 Ã— 1\n#&gt;   tail_num\n#&gt;   &lt;chr&gt;   \n#&gt; 1 N14228  \n#&gt; 2 N24211  \n#&gt; 3 N619AA  \n#&gt; 4 N804JB  \n#&gt; 5 N668DN  \n#&gt; 6 N39463  \n#&gt; # â„¹ 336,770 more rows\n\n\n3.3.3 rename()\n\nIf you want to keep all the existing variables and just want to rename a few, you can use rename() instead of select():\nå¦‚æœä½ æƒ³ä¿ç•™æ‰€æœ‰ç°æœ‰å˜é‡ï¼Œè€Œåªæƒ³é‡å‘½åå°‘æ•°å‡ ä¸ªï¼Œä½ å¯ä»¥ä½¿ç”¨ rename() ä»£æ›¿ select()ï¼š\n\nflights |&gt; \n  rename(tail_num = tailnum)\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nIf you have a bunch of inconsistently named columns and it would be painful to fix them all by hand, check out janitor::clean_names() which provides some useful automated cleaning.\nå¦‚æœä½ æœ‰ä¸€å †å‘½åä¸ä¸€è‡´çš„åˆ—ï¼Œå¹¶ä¸”æ‰‹åŠ¨ä¿®å¤å®ƒä»¬ä¼šå¾ˆç—›è‹¦ï¼Œå¯ä»¥çœ‹çœ‹ janitor::clean_names()ï¼Œå®ƒæä¾›äº†ä¸€äº›æœ‰ç”¨çš„è‡ªåŠ¨æ¸…ç†åŠŸèƒ½ã€‚\n\n3.3.4 relocate()\n\nUse relocate() to move variables around.\nä½¿ç”¨ relocate() æ¥ç§»åŠ¨å˜é‡ã€‚\nYou might want to collect related variables together or move important variables to the front.\nä½ å¯èƒ½æƒ³å°†ç›¸å…³çš„å˜é‡æ”¶é›†åœ¨ä¸€èµ·ï¼Œæˆ–è€…å°†é‡è¦çš„å˜é‡ç§»åˆ°å‰é¢ã€‚\nBy default relocate() moves variables to the front:\né»˜è®¤æƒ…å†µä¸‹ï¼Œrelocate() å°†å˜é‡ç§»åŠ¨åˆ°æœ€å‰é¢ï¼š\n\nflights |&gt; \n  relocate(time_hour, air_time)\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;   time_hour           air_time  year month   day dep_time sched_dep_time\n#&gt;   &lt;dttm&gt;                 &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n#&gt; 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n#&gt; 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n#&gt; 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n#&gt; 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n#&gt; 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 12 more variables: dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, â€¦\n\nYou can also specify where to put them using the .before and .after arguments, just like in mutate():\nä½ ä¹Ÿå¯ä»¥åƒåœ¨ mutate() ä¸­ä¸€æ ·ï¼Œä½¿ç”¨ .before å’Œ .after å‚æ•°æ¥æŒ‡å®šå°†å®ƒä»¬æ”¾åœ¨å“ªé‡Œï¼š\n\nflights |&gt; \n  relocate(year:dep_time, .after = time_hour)\nflights |&gt; \n  relocate(starts_with(\"arr\"), .before = dep_time)\n\n\n3.3.5 Exercises\n\nCompare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?\nBrainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.\nWhat happens if you specify the name of the same variable multiple times in a select() call?\n\nWhat does the any_of() function do? Why might it be helpful in conjunction with this vector?\n\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\n\n\nDoes the result of running the following code surprise you? How do the select helpers deal with upper and lower case by default? How can you change that default?\n\nflights |&gt; select(contains(\"TIME\"))\n\n\nRename air_time to air_time_min to indicate units of measurement and move it to the beginning of the data frame.\n\nWhy doesnâ€™t the following work, and what does the error mean?\n\nflights |&gt; \n  select(tailnum) |&gt; \n  arrange(arr_delay)\n#&gt; Error in `arrange()`:\n#&gt; â„¹ In argument: `..1 = arr_delay`.\n#&gt; Caused by error:\n#&gt; ! object 'arr_delay' not found",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-the-pipe",
    "href": "data-transform.html#sec-the-pipe",
    "title": "3Â  Data transformation",
    "section": "\n3.4 The pipe",
    "text": "3.4 The pipe\nWeâ€™ve shown you simple examples of the pipe above, but its real power arises when you start to combine multiple verbs.\næˆ‘ä»¬åœ¨ä¸Šé¢å‘ä½ å±•ç¤ºäº†ç®¡é“çš„ç®€å•ç¤ºä¾‹ï¼Œä½†å®ƒçœŸæ­£çš„å¨åŠ›åœ¨äºå½“ä½ å¼€å§‹ç»„åˆå¤šä¸ªåŠ¨è¯æ—¶ã€‚\nFor example, imagine that you wanted to find the fastest flights to Houstonâ€™s IAH airport: you need to combine filter(), mutate(), select(), and arrange():\nä¾‹å¦‚ï¼Œå‡è®¾ä½ æƒ³æ‰¾åˆ°é£å¾€ä¼‘æ–¯é¡¿ IAH æœºåœºçš„æœ€å¿«èˆªç­ï¼šä½ éœ€è¦ç»„åˆ filter()ã€mutate()ã€select() å’Œ arrange()ï¼š\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  mutate(speed = distance / air_time * 60) |&gt; \n  select(year:day, dep_time, carrier, flight, speed) |&gt; \n  arrange(desc(speed))\n#&gt; # A tibble: 7,198 Ã— 7\n#&gt;    year month   day dep_time carrier flight speed\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n#&gt; 1  2013     7     9      707 UA         226  522.\n#&gt; 2  2013     8    27     1850 UA        1128  521.\n#&gt; 3  2013     8    28      902 UA        1711  519.\n#&gt; 4  2013     8    28     2122 UA        1022  519.\n#&gt; 5  2013     6    11     1628 UA        1178  515.\n#&gt; 6  2013     8    27     1017 UA         333  515.\n#&gt; # â„¹ 7,192 more rows\n\nEven though this pipeline has four steps, itâ€™s easy to skim because the verbs come at the start of each line: start with the flights data, then filter, then mutate, then select, then arrange.\nå°½ç®¡è¿™ä¸ªç®¡é“æœ‰å››ä¸ªæ­¥éª¤ï¼Œä½†å®ƒå¾ˆå®¹æ˜“æµè§ˆï¼Œå› ä¸ºåŠ¨è¯éƒ½å‡ºç°åœ¨æ¯è¡Œçš„å¼€å¤´ï¼šä» flights æ•°æ®å¼€å§‹ï¼Œç„¶åç­›é€‰ï¼Œç„¶åè½¬æ¢ï¼Œç„¶åé€‰æ‹©ï¼Œç„¶åæ’åˆ—ã€‚\nWhat would happen if we didnâ€™t have the pipe?\nå¦‚æœæˆ‘ä»¬æ²¡æœ‰ç®¡é“ä¼šæ€ä¹ˆæ ·ï¼Ÿ\nWe could nest each function call inside the previous call:\næˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªå‡½æ•°è°ƒç”¨åµŒå¥—åœ¨å‰ä¸€ä¸ªè°ƒç”¨ä¸­ï¼š\n\narrange(\n  select(\n    mutate(\n      filter(\n        flights, \n        dest == \"IAH\"\n      ),\n      speed = distance / air_time * 60\n    ),\n    year:day, dep_time, carrier, flight, speed\n  ),\n  desc(speed)\n)\n\nOr we could use a bunch of intermediate objects:\næˆ–è€…æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€å †ä¸­é—´å¯¹è±¡ï¼š\n\nflights1 &lt;- filter(flights, dest == \"IAH\")\nflights2 &lt;- mutate(flights1, speed = distance / air_time * 60)\nflights3 &lt;- select(flights2, year:day, dep_time, carrier, flight, speed)\narrange(flights3, desc(speed))\n\nWhile both forms have their time and place, the pipe generally produces data analysis code that is easier to write and read.\nè™½ç„¶è¿™ä¸¤ç§å½¢å¼éƒ½æœ‰å…¶é€‚ç”¨çš„æ—¶æœºå’Œåœºåˆï¼Œä½†ç®¡é“é€šå¸¸èƒ½ç”Ÿæˆæ›´æ˜“äºç¼–å†™å’Œé˜…è¯»çš„æ•°æ®åˆ†æä»£ç ã€‚\nTo add the pipe to your code, we recommend using the built-in keyboard shortcut Ctrl/Cmd + Shift + M.\nè¦å°†ç®¡é“æ·»åŠ åˆ°ä½ çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨å†…ç½®çš„é”®ç›˜å¿«æ·é”® Ctrl/Cmd + Shift + Mã€‚\nYouâ€™ll need to make one change to your RStudio options to use |&gt; instead of %&gt;% as shown in FigureÂ 3.1; more on %&gt;% shortly.\nä½ éœ€è¦å¯¹ RStudio é€‰é¡¹è¿›è¡Œä¸€é¡¹æ›´æ”¹ï¼Œä»¥ä½¿ç”¨ |&gt; è€Œä¸æ˜¯ %&gt;%ï¼Œå¦‚ FigureÂ 3.1 æ‰€ç¤ºï¼›ç¨åå°†è¯¦ç»†ä»‹ç» %&gt;%ã€‚\n\n\n\n\n\n\n\nFigureÂ 3.1: To insert |&gt;, make sure the â€œUse native pipe operatorâ€ option is checked.  è¦æ’å…¥ |&gt;ï¼Œè¯·ç¡®ä¿é€‰ä¸­â€œä½¿ç”¨åŸç”Ÿç®¡é“è¿ç®—ç¬¦â€ (Use native pipe operator) é€‰é¡¹ã€‚\n\n\n\n\n\n\n\n\n\n\nmagrittr\n\n\n\nIf youâ€™ve been using the tidyverse for a while, you might be familiar with the %&gt;% pipe provided by the magrittr package.\nå¦‚æœä½ å·²ç»ä½¿ç”¨ tidyverse ä¸€æ®µæ—¶é—´äº†ï¼Œä½ å¯èƒ½ç†Ÿæ‚‰ magrittr åŒ…æä¾›çš„ %&gt;% ç®¡é“ã€‚\nThe magrittr package is included in the core tidyverse, so you can use %&gt;% whenever you load the tidyverse:\nmagrittr åŒ…åŒ…å«åœ¨ tidyverse æ ¸å¿ƒä¸­ï¼Œå› æ­¤æ¯å½“ä½ åŠ è½½ tidyverse æ—¶éƒ½å¯ä»¥ä½¿ç”¨ %&gt;%ï¼š\n\nlibrary(tidyverse)\n\nmtcars %&gt;% \n  group_by(cyl) %&gt;%\n  summarize(n = n())\n\nFor simple cases, |&gt; and %&gt;% behave identically.\nåœ¨ç®€å•çš„æƒ…å†µä¸‹ï¼Œ|&gt; å’Œ %&gt;% çš„è¡Œä¸ºå®Œå…¨ç›¸åŒã€‚\nSo why do we recommend the base pipe?\né‚£ä¹ˆæˆ‘ä»¬ä¸ºä»€ä¹ˆæ¨èåŸºç¡€ç®¡é“å‘¢ï¼Ÿ\nFirstly, because itâ€™s part of base R, itâ€™s always available for you to use, even when youâ€™re not using the tidyverse.\né¦–å…ˆï¼Œå› ä¸ºå®ƒæ˜¯åŸºç¡€ R çš„ä¸€éƒ¨åˆ†ï¼Œæ‰€ä»¥å³ä½¿ä½ ä¸ä½¿ç”¨ tidyverseï¼Œå®ƒä¹Ÿå§‹ç»ˆå¯ç”¨ã€‚\nSecondly, |&gt; is quite a bit simpler than %&gt;%: in the time between the invention of %&gt;% in 2014 and the inclusion of |&gt; in R 4.1.0 in 2021, we gained a better understanding of the pipe.\nå…¶æ¬¡ï¼Œ|&gt; æ¯” %&gt;% ç®€å•å¾—å¤šï¼šåœ¨ 2014 å¹´ %&gt;% å‘æ˜å’Œ 2021 å¹´ R 4.1.0 åŒ…å« |&gt; ä¹‹é—´çš„æ—¶é—´é‡Œï¼Œæˆ‘ä»¬å¯¹ç®¡é“æœ‰äº†æ›´å¥½çš„ç†è§£ã€‚\nThis allowed the base implementation to jettison infrequently used and less important features.\nè¿™ä½¿å¾—åŸºç¡€å®ç°å¯ä»¥æ‘’å¼ƒä¸å¸¸ç”¨å’Œä¸å¤ªé‡è¦çš„åŠŸèƒ½ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#groups",
    "href": "data-transform.html#groups",
    "title": "3Â  Data transformation",
    "section": "\n3.5 Groups",
    "text": "3.5 Groups\nSo far youâ€™ve learned about functions that work with rows and columns.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»å­¦ä¹ äº†å¤„ç†è¡Œå’Œåˆ—çš„å‡½æ•°ã€‚\ndplyr gets even more powerful when you add in the ability to work with groups.\nå½“ä½ åŠ å…¥å¤„ç†åˆ†ç»„çš„èƒ½åŠ›æ—¶ï¼Œdplyr ä¼šå˜å¾—æ›´åŠ å¼ºå¤§ã€‚\nIn this section, weâ€™ll focus on the most important functions: group_by(), summarize(), and the slice family of functions.\nåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»æœ€é‡è¦çš„å‡½æ•°ï¼šgroup_by()ã€summarize() å’Œ slice ç³»åˆ—å‡½æ•°ã€‚\n\n3.5.1 group_by()\n\nUse group_by() to divide your dataset into groups meaningful for your analysis:\nä½¿ç”¨ group_by() å°†ä½ çš„æ•°æ®é›†åˆ’åˆ†ä¸ºå¯¹ä½ çš„åˆ†ææœ‰æ„ä¹‰çš„ç»„ï¼š\n\nflights |&gt; \n  group_by(month)\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt; # Groups:   month [12]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\ngroup_by() doesnâ€™t change the data but, if you look closely at the output, youâ€™ll notice that the output indicates that it is â€œgrouped byâ€ month (Groups: month [12]).group_by() ä¸ä¼šæ”¹å˜æ•°æ®ï¼Œä½†æ˜¯ï¼Œå¦‚æœä½ ä»”ç»†è§‚å¯Ÿè¾“å‡ºï¼Œä½ ä¼šæ³¨æ„åˆ°è¾“å‡ºè¡¨æ˜å®ƒå·²æŒ‰æœˆä»½â€œåˆ†ç»„â€ (Groups: month [12])ã€‚\nThis means subsequent operations will now work â€œby monthâ€.\nè¿™æ„å‘³ç€åç»­æ“ä½œç°åœ¨å°†â€œæŒ‰æœˆâ€å·¥ä½œã€‚\ngroup_by() adds this grouped feature (referred to as class) to the data frame, which changes the behavior of the subsequent verbs applied to the data.group_by() å°†æ­¤åˆ†ç»„ç‰¹å¾ (ç§°ä¸ºç±») æ·»åŠ åˆ°æ•°æ®æ¡†ä¸­ï¼Œè¿™ä¼šæ”¹å˜åº”ç”¨äºæ•°æ®çš„åç»­åŠ¨è¯çš„è¡Œä¸ºã€‚\n\n3.5.2 summarize()\n\nThe most important grouped operation is a summary, which, if being used to calculate a single summary statistic, reduces the data frame to have a single row for each group.\næœ€é‡è¦çš„åˆ†ç»„æ“ä½œæ˜¯æ‘˜è¦ï¼Œå¦‚æœç”¨äºè®¡ç®—å•ä¸ªæ‘˜è¦ç»Ÿè®¡é‡ï¼Œå®ƒä¼šå°†æ•°æ®æ¡†å‡å°‘ä¸ºæ¯ä¸ªç»„åªæœ‰ä¸€è¡Œã€‚\nIn dplyr, this operation is performed by summarize()3, as shown by the following example, which computes the average departure delay by month:\nåœ¨ dplyr ä¸­ï¼Œæ­¤æ“ä½œç”± summarize()3 æ‰§è¡Œï¼Œå¦‚ä¸‹ä¾‹æ‰€ç¤ºï¼Œè¯¥ç¤ºä¾‹è®¡ç®—æŒ‰æœˆå¹³å‡å‡ºå‘å»¶è¯¯ï¼š\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay)\n  )\n#&gt; # A tibble: 12 Ã— 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1        NA\n#&gt; 2     2        NA\n#&gt; 3     3        NA\n#&gt; 4     4        NA\n#&gt; 5     5        NA\n#&gt; 6     6        NA\n#&gt; # â„¹ 6 more rows\n\nUh-oh!\nå™¢ï¼\nSomething has gone wrong, and all of our results are NAs (pronounced â€œN-Aâ€), Râ€™s symbol for missing value.\nå‡ºé—®é¢˜äº†ï¼Œæˆ‘ä»¬æ‰€æœ‰çš„ç»“æœéƒ½æ˜¯ NA (è¯»ä½œâ€œN-Aâ€)ï¼Œè¿™æ˜¯ R ä¸­è¡¨ç¤ºç¼ºå¤±å€¼çš„ç¬¦å·ã€‚\nThis happened because some of the observed flights had missing data in the delay column, and so when we calculated the mean including those values, we got an NA result.\nå‘ç”Ÿè¿™ç§æƒ…å†µæ˜¯å› ä¸ºä¸€äº›è§‚å¯Ÿåˆ°çš„èˆªç­åœ¨å»¶è¯¯åˆ—ä¸­æœ‰ç¼ºå¤±æ•°æ®ï¼Œå› æ­¤å½“æˆ‘ä»¬è®¡ç®—åŒ…æ‹¬è¿™äº›å€¼çš„å¹³å‡å€¼æ—¶ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ª NA ç»“æœã€‚\nWeâ€™ll come back to discuss missing values in detail in Chapter 18, but for now, weâ€™ll tell the mean() function to ignore all missing values by setting the argument na.rm to TRUE:\næˆ‘ä»¬å°†åœ¨ Chapter 18 ä¸­è¯¦ç»†è®¨è®ºç¼ºå¤±å€¼ï¼Œä½†ç°åœ¨ï¼Œæˆ‘ä»¬å°†é€šè¿‡å°†å‚æ•° na.rm è®¾ç½®ä¸º TRUE æ¥å‘Šè¯‰ mean() å‡½æ•°å¿½ç•¥æ‰€æœ‰ç¼ºå¤±å€¼ï¼š\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 12 Ã— 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1      10.0\n#&gt; 2     2      10.8\n#&gt; 3     3      13.2\n#&gt; 4     4      13.9\n#&gt; 5     5      13.0\n#&gt; 6     6      20.8\n#&gt; # â„¹ 6 more rows\n\nYou can create any number of summaries in a single call to summarize().\nä½ å¯ä»¥åœ¨ä¸€æ¬¡ summarize() è°ƒç”¨ä¸­åˆ›å»ºä»»æ„æ•°é‡çš„æ‘˜è¦ã€‚\nYouâ€™ll learn various useful summaries in the upcoming chapters, but one very useful summary is n(), which returns the number of rows in each group:\nä½ å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­å­¦åˆ°å„ç§æœ‰ç”¨çš„æ‘˜è¦ï¼Œä½†ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„æ‘˜è¦æ˜¯ n()ï¼Œå®ƒè¿”å›æ¯ä¸ªç»„ä¸­çš„è¡Œæ•°ï¼š\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    n = n()\n  )\n#&gt; # A tibble: 12 Ã— 3\n#&gt;   month avg_delay     n\n#&gt;   &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1     1      10.0 27004\n#&gt; 2     2      10.8 24951\n#&gt; 3     3      13.2 28834\n#&gt; 4     4      13.9 28330\n#&gt; 5     5      13.0 28796\n#&gt; 6     6      20.8 28243\n#&gt; # â„¹ 6 more rows\n\nMeans and counts can get you a surprisingly long way in data science!\nå‡å€¼å’Œè®¡æ•°å¯ä»¥è®©ä½ åœ¨æ•°æ®ç§‘å­¦é¢†åŸŸèµ°å¾—å¾ˆè¿œï¼\n\n3.5.3 The slice_ functions\nThere are five handy functions that allow you to extract specific rows within each group:\næœ‰äº”ä¸ªæ–¹ä¾¿çš„å‡½æ•°ï¼Œå¯ä»¥è®©ä½ æå–æ¯ä¸ªç»„ä¸­çš„ç‰¹å®šè¡Œï¼š\n\ndf |&gt; slice_head(n = 1) takes the first row from each group.\nä»æ¯ä¸ªç»„ä¸­å–ç¬¬ä¸€è¡Œã€‚\ndf |&gt; slice_tail(n = 1) takes the last row in each group.\nä»æ¯ä¸ªç»„ä¸­å–æœ€åä¸€è¡Œã€‚\ndf |&gt; slice_min(x, n = 1) takes the row with the smallest value of column x.\nå– x åˆ—å€¼æœ€å°çš„è¡Œã€‚\ndf |&gt; slice_max(x, n = 1) takes the row with the largest value of column x.\nå– x åˆ—å€¼æœ€å¤§çš„è¡Œã€‚\ndf |&gt; slice_sample(n = 1) takes one random row.\nå–ä¸€ä¸ªéšæœºè¡Œã€‚\n\nYou can vary n to select more than one row, or instead of n =, you can use prop = 0.1 to select (e.g.) 10% of the rows in each group.\nä½ å¯ä»¥æ”¹å˜ n æ¥é€‰æ‹©å¤šäºä¸€è¡Œï¼Œæˆ–è€…ç”¨ prop = 0.1 æ¥ä»£æ›¿ n =ï¼Œä»¥é€‰æ‹© (ä¾‹å¦‚) æ¯ä¸ªç»„ä¸­ 10% çš„è¡Œã€‚\nFor example, the following code finds the flights that are most delayed upon arrival at each destination:\nä¾‹å¦‚ï¼Œä»¥ä¸‹ä»£ç æŸ¥æ‰¾åœ¨æ¯ä¸ªç›®çš„åœ°åˆ°è¾¾æ—¶å»¶è¯¯æœ€ä¸¥é‡çš„èˆªç­ï¼š\n\nflights |&gt; \n  group_by(dest) |&gt; \n  slice_max(arr_delay, n = 1) |&gt;\n  relocate(dest)\n#&gt; # A tibble: 108 Ã— 19\n#&gt; # Groups:   dest [105]\n#&gt;   dest   year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 ABQ    2013     7    22     2145           2007        98      132\n#&gt; 2 ACK    2013     7    23     1139            800       219     1250\n#&gt; 3 ALB    2013     1    25      123           2000       323      229\n#&gt; 4 ANC    2013     8    17     1740           1625        75     2042\n#&gt; 5 ATL    2013     7    22     2257            759       898      121\n#&gt; 6 AUS    2013     7    10     2056           1505       351     2347\n#&gt; # â„¹ 102 more rows\n#&gt; # â„¹ 11 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, â€¦\n\nNote that there are 105 destinations but we get 108 rows here.\nè¯·æ³¨æ„ï¼Œè¿™é‡Œæœ‰ 105 ä¸ªç›®çš„åœ°ï¼Œä½†æˆ‘ä»¬å¾—åˆ°äº† 108 è¡Œã€‚\nWhatâ€™s up?\næ€ä¹ˆå›äº‹ï¼Ÿ\nslice_min() and slice_max() keep tied values so n = 1 means give us all rows with the highest value.slice_min() å’Œ slice_max() ä¼šä¿ç•™å¹¶åˆ—å€¼ï¼Œæ‰€ä»¥ n = 1 æ„å‘³ç€ç»™æˆ‘ä»¬æ‰€æœ‰å…·æœ‰æœ€é«˜å€¼çš„è¡Œã€‚\nIf you want exactly one row per group you can set with_ties = FALSE.\nå¦‚æœä½ æƒ³æ¯ä¸ªç»„åªä¿ç•™ä¸€è¡Œï¼Œä½ å¯ä»¥è®¾ç½® with_ties = FALSEã€‚\nThis is similar to computing the max delay with summarize(), but you get the whole corresponding row (or rows if thereâ€™s a tie) instead of the single summary statistic.\nè¿™ç±»ä¼¼äºç”¨ summarize() è®¡ç®—æœ€å¤§å»¶è¿Ÿï¼Œä½†ä½ ä¼šå¾—åˆ°æ•´ä¸ªå¯¹åº”çš„è¡Œ (å¦‚æœæœ‰å¹¶åˆ—ï¼Œåˆ™ä¸ºå¤šè¡Œ)ï¼Œè€Œä¸æ˜¯å•ä¸ªæ‘˜è¦ç»Ÿè®¡é‡ã€‚\n\n3.5.4 Grouping by multiple variables\nYou can create groups using more than one variable.\nä½ å¯ä»¥ä½¿ç”¨å¤šä¸ªå˜é‡åˆ›å»ºåˆ†ç»„ã€‚\nFor example, we could make a group for each date.\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªæ—¥æœŸåˆ›å»ºä¸€ä¸ªåˆ†ç»„ã€‚\n\ndaily &lt;- flights |&gt;  \n  group_by(year, month, day)\ndaily\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nWhen you summarize a tibble grouped by more than one variable, each summary peels off the last group.\nå½“ä½ å¯¹æŒ‰å¤šä¸ªå˜é‡åˆ†ç»„çš„ tibble è¿›è¡Œæ±‡æ€»æ—¶ï¼Œæ¯ä¸ªæ±‡æ€»éƒ½ä¼šå‰¥ç¦»æœ€åä¸€ä¸ªåˆ†ç»„ã€‚\nIn hindsight, this wasnâ€™t a great way to make this function work, but itâ€™s difficult to change without breaking existing code.\näº‹åçœ‹æ¥ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªè®©è¿™ä¸ªå‡½æ•°å·¥ä½œçš„å¥½æ–¹æ³•ï¼Œä½†å¾ˆéš¾åœ¨ä¸ç ´åç°æœ‰ä»£ç çš„æƒ…å†µä¸‹è¿›è¡Œæ›´æ”¹ã€‚\nTo make it obvious whatâ€™s happening, dplyr displays a message that tells you how you can change this behavior:\nä¸ºäº†æ¸…æ¥šåœ°è¯´æ˜å‘ç”Ÿäº†ä»€ä¹ˆï¼Œdplyr ä¼šæ˜¾ç¤ºä¸€æ¡æ¶ˆæ¯ï¼Œå‘Šè¯‰ä½ å¦‚ä½•æ”¹å˜è¿™ç§è¡Œä¸ºï¼š\n\ndaily_flights &lt;- daily |&gt; \n  summarize(n = n())\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n\nIf youâ€™re happy with this behavior, you can explicitly request it in order to suppress the message:\nå¦‚æœä½ å¯¹è¿™ç§è¡Œä¸ºæ„Ÿåˆ°æ»¡æ„ï¼Œå¯ä»¥æ˜ç¡®è¯·æ±‚å®ƒä»¥æŠ‘åˆ¶æ¶ˆæ¯ï¼š\n\ndaily_flights &lt;- daily |&gt; \n  summarize(\n    n = n(), \n    .groups = \"drop_last\"\n  )\n\nAlternatively, change the default behavior by setting a different value, e.g., \"drop\" to drop all grouping or \"keep\" to preserve the same groups.\næˆ–è€…ï¼Œé€šè¿‡è®¾ç½®ä¸åŒçš„å€¼æ¥æ›´æ”¹é»˜è®¤è¡Œä¸ºï¼Œä¾‹å¦‚ï¼Œ\"drop\" ç”¨äºåˆ é™¤æ‰€æœ‰åˆ†ç»„ï¼Œ\"keep\" ç”¨äºä¿ç•™ç›¸åŒçš„åˆ†ç»„ã€‚\n\n3.5.5 Ungrouping\nYou might also want to remove grouping from a data frame without using summarize().\nä½ å¯èƒ½è¿˜æƒ³åœ¨ä¸ä½¿ç”¨ summarize() çš„æƒ…å†µä¸‹ä»æ•°æ®æ¡†ä¸­åˆ é™¤åˆ†ç»„ã€‚\nYou can do this with ungroup().\nä½ å¯ä»¥ä½¿ç”¨ ungroup() æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚\n\ndaily |&gt; \n  ungroup()\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nNow letâ€™s see what happens when you summarize an ungrouped data frame.\nç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å½“ä½ æ±‡æ€»ä¸€ä¸ªæœªåˆ†ç»„çš„æ•°æ®æ¡†æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚\n\ndaily |&gt; \n  ungroup() |&gt;\n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n  )\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   avg_delay flights\n#&gt;       &lt;dbl&gt;   &lt;int&gt;\n#&gt; 1      12.6  336776\n\nYou get a single row back because dplyr treats all the rows in an ungrouped data frame as belonging to one group.\nä½ åªä¼šå¾—åˆ°ä¸€è¡Œï¼Œå› ä¸º dplyr å°†æœªåˆ†ç»„æ•°æ®æ¡†ä¸­çš„æ‰€æœ‰è¡Œéƒ½è§†ä¸ºå±äºä¸€ä¸ªç»„ã€‚\n\n3.5.6 .by\n\ndplyr 1.1.0 includes a new, experimental, syntax for per-operation grouping, the .by argument.\ndplyr 1.1.0 åŒ…å«äº†ä¸€ä¸ªæ–°çš„ã€å®éªŒæ€§çš„ã€ç”¨äºæŒ‰æ“ä½œåˆ†ç»„çš„è¯­æ³•ï¼Œå³ .by å‚æ•°ã€‚\ngroup_by() and ungroup() arenâ€™t going away, but you can now also use the .by argument to group within a single operation:group_by() å’Œ ungroup() ä¸ä¼šæ¶ˆå¤±ï¼Œä½†ä½ ç°åœ¨ä¹Ÿå¯ä»¥ä½¿ç”¨ .by å‚æ•°åœ¨å•ä¸ªæ“ä½œå†…è¿›è¡Œåˆ†ç»„ï¼š\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = month\n  )\n\nOr if you want to group by multiple variables:\næˆ–è€…å¦‚æœä½ æƒ³æŒ‰å¤šä¸ªå˜é‡åˆ†ç»„ï¼š\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = c(origin, dest)\n  )\n\n.by works with all verbs and has the advantage that you donâ€™t need to use the .groups argument to suppress the grouping message or ungroup() when youâ€™re done..by é€‚ç”¨äºæ‰€æœ‰åŠ¨è¯ï¼Œå…¶ä¼˜ç‚¹æ˜¯å½“ä½ å®Œæˆæ“ä½œåï¼Œæ— éœ€ä½¿ç”¨ .groups å‚æ•°æ¥æŠ‘åˆ¶åˆ†ç»„æ¶ˆæ¯æˆ–ä½¿ç”¨ ungroup()ã€‚\nWe didnâ€™t focus on this syntax in this chapter because it was very new when we wrote the book.\næˆ‘ä»¬åœ¨æœ¬ç« ä¸­æ²¡æœ‰é‡ç‚¹ä»‹ç»è¿™ç§è¯­æ³•ï¼Œå› ä¸ºåœ¨æˆ‘ä»¬å†™ä¹¦æ—¶å®ƒè¿˜æ˜¯éå¸¸æ–°çš„ã€‚\nWe did want to mention it because we think it has a lot of promise and itâ€™s likely to be quite popular.\næˆ‘ä»¬ç¡®å®æƒ³æä¸€ä¸‹å®ƒï¼Œå› ä¸ºæˆ‘ä»¬è®¤ä¸ºå®ƒæœ‰å¾ˆå¤§çš„æ½œåŠ›ï¼Œè€Œä¸”å¾ˆå¯èƒ½ä¼šéå¸¸æµè¡Œã€‚\nYou can learn more about it in the dplyr 1.1.0 blog post.\nä½ å¯ä»¥åœ¨ dplyr 1.1.0 åšå®¢æ–‡ç«  ä¸­äº†è§£æ›´å¤šç›¸å…³ä¿¡æ¯ã€‚\n\n3.5.7 Exercises\n\nWhich carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs.Â bad carriers? Why/why not? (Hint: think about flights |&gt; group_by(carrier, dest) |&gt; summarize(n()))\nFind the flights that are most delayed upon departure from each destination.\nHow do delays vary over the course of the day? Illustrate your answer with a plot.\nWhat happens if you supply a negative n to slice_min() and friends?\nExplain what count() does in terms of the dplyr verbs you just learned. What does the sort argument to count() do?\n\nSuppose we have the following tiny data frame:\n\ndf &lt;- tibble(\n  x = 1:5,\n  y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\n  z = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what group_by() does.\n\ndf |&gt;\n  group_by(y)\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what arrange() does. Also, comment on how itâ€™s different from the group_by() in part (a).\n\ndf |&gt;\n  arrange(y)\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does.\n\ndf |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does. Then, comment on what the message says.\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does. How is the output different from the one in part (d)?\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\n\n\nWrite down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  mutate(mean_x = mean(x))",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-sample-size",
    "href": "data-transform.html#sec-sample-size",
    "title": "3Â  Data transformation",
    "section": "\n3.6 Case study: aggregates and sample size",
    "text": "3.6 Case study: aggregates and sample size\nWhenever you do any aggregation, itâ€™s always a good idea to include a count (n()).\næ¯å½“ä½ è¿›è¡Œä»»ä½•èšåˆæ—¶ï¼ŒåŒ…å«ä¸€ä¸ªè®¡æ•° (n()) æ€»æ˜¯å¥½ä¸»æ„ã€‚\nThat way, you can ensure that youâ€™re not drawing conclusions based on very small amounts of data.\nè¿™æ ·ï¼Œä½ å¯ä»¥ç¡®ä¿ä½ ä¸æ˜¯åŸºäºéå¸¸å°‘é‡çš„æ•°æ®å¾—å‡ºç»“è®ºã€‚\nWeâ€™ll demonstrate this with some baseball data from the Lahman package.\næˆ‘ä»¬å°†ä½¿ç”¨ Lahman åŒ…ä¸­çš„ä¸€äº›æ£’çƒæ•°æ®æ¥æ¼”ç¤ºè¿™ä¸€ç‚¹ã€‚\nSpecifically, we will compare what proportion of times a player gets a hit (H) vs.Â the number of times they try to put the ball in play (AB):\nå…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¯”è¾ƒçƒå‘˜å‡»ä¸­çƒçš„æ¬¡æ•° (H) ä¸ä»–ä»¬å°è¯•å°†çƒå‡»å…¥åœºå†…çš„æ¬¡æ•° (AB) çš„æ¯”ä¾‹ï¼š\n\nbatters &lt;- Lahman::Batting |&gt; \n  group_by(playerID) |&gt; \n  summarize(\n    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),\n    n = sum(AB, na.rm = TRUE)\n  )\nbatters\n#&gt; # A tibble: 20,730 Ã— 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 aardsda01      0          4\n#&gt; 2 aaronha01      0.305  12364\n#&gt; 3 aaronto01      0.229    944\n#&gt; 4 aasedo01       0          5\n#&gt; 5 abadan01       0.0952    21\n#&gt; 6 abadfe01       0.111      9\n#&gt; # â„¹ 20,724 more rows\n\nWhen we plot the skill of the batter (measured by the batting average, performance) against the number of opportunities to hit the ball (measured by times at bat, n), you see two patterns:\nå½“æˆ‘ä»¬å°†å‡»çƒæ‰‹çš„æŠ€æœ¯ (ç”¨å‡»çƒç‡ performance è¡¡é‡) ä¸å‡»çƒæœºä¼šæ•° (ç”¨å‡»çƒæ¬¡æ•° n è¡¡é‡) ç»˜åˆ¶æˆå›¾æ—¶ï¼Œä½ ä¼šçœ‹åˆ°ä¸¤ç§æ¨¡å¼ï¼š\n\n\nThe variation in performance is larger among players with fewer at-bats.\nå‡»çƒæ¬¡æ•°è¾ƒå°‘çš„çƒå‘˜çš„ performance å˜åŒ–æ›´å¤§ã€‚\nThe shape of this plot is very characteristic: whenever you plot a mean (or other summary statistics) vs.Â group size, youâ€™ll see that the variation decreases as the sample size increases4.\nè¿™å¼ å›¾çš„å½¢çŠ¶éå¸¸æœ‰ç‰¹ç‚¹ï¼šæ¯å½“ä½ ç»˜åˆ¶å‡å€¼ (æˆ–å…¶ä»–æ‘˜è¦ç»Ÿè®¡é‡) ä¸ç»„å¤§å°çš„å…³ç³»å›¾æ—¶ï¼Œä½ éƒ½ä¼šçœ‹åˆ°éšç€æ ·æœ¬é‡çš„å¢åŠ ï¼Œå˜å¼‚ä¼šå‡å°4ã€‚\n\nThereâ€™s a positive correlation between skill (performance) and opportunities to hit the ball (n) because teams want to give their best batters the most opportunities to hit the ball.\næŠ€æœ¯ (performance) ä¸å‡»çƒæœºä¼š (n) ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼Œå› ä¸ºçƒé˜Ÿå¸Œæœ›ç»™ä»–ä»¬æœ€å¥½çš„å‡»çƒæ‰‹æœ€å¤šçš„å‡»çƒæœºä¼šã€‚\n\n\nbatters |&gt; \n  filter(n &gt; 100) |&gt; \n  ggplot(aes(x = n, y = performance)) +\n  geom_point(alpha = 1 / 10) + \n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\nNote the handy pattern for combining ggplot2 and dplyr.\næ³¨æ„ç»“åˆ ggplot2 å’Œ dplyr çš„ä¾¿æ·æ¨¡å¼ã€‚\nYou just have to remember to switch from |&gt;, for dataset processing, to + for adding layers to your plot.\nä½ åªéœ€è¦è®°ä½ä»ç”¨äºæ•°æ®é›†å¤„ç†çš„ |&gt; åˆ‡æ¢åˆ°ç”¨äºå‘ç»˜å›¾æ·»åŠ å›¾å±‚çš„ +ã€‚\nThis also has important implications for ranking.\nè¿™å¯¹æ’åä¹Ÿæœ‰é‡è¦å½±å“ã€‚\nIf you naively sort on desc(performance), the people with the best batting averages are clearly the ones who tried to put the ball in play very few times and happened to get a hit, theyâ€™re not necessarily the most skilled players:\nå¦‚æœä½ å¤©çœŸåœ°æŒ‰ desc(performance) æ’åºï¼Œé‚£ä¹ˆå‡»çƒç‡æœ€é«˜çš„äººæ˜¾ç„¶æ˜¯é‚£äº›å°è¯•å°†çƒå‡»å…¥åœºå†…æ¬¡æ•°å¾ˆå°‘ä½†ç¢°å·§å‡»ä¸­äº†çš„äººï¼Œä»–ä»¬ä¸ä¸€å®šæ˜¯æœ€æœ‰æŠ€æœ¯çš„çƒå‘˜ï¼š\n\nbatters |&gt; \n  arrange(desc(performance))\n#&gt; # A tibble: 20,730 Ã— 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 abramge01           1     1\n#&gt; 2 alberan01           1     1\n#&gt; 3 banisje01           1     1\n#&gt; 4 bartocl01           1     1\n#&gt; 5 bassdo01            1     1\n#&gt; 6 birasst01           1     2\n#&gt; # â„¹ 20,724 more rows\n\nYou can find a good explanation of this problem and how to overcome it at http://varianceexplained.org/r/empirical_bayes_baseball/ and https://www.evanmiller.org/how-not-to-sort-by-average-rating.html.\nä½ å¯ä»¥åœ¨ http://varianceexplained.org/r/empirical_bayes_baseball/ å’Œ https://www.evanmiller.org/how-not-to-sort-by-average-rating.html æ‰¾åˆ°å¯¹è¿™ä¸ªé—®é¢˜ä»¥åŠå¦‚ä½•å…‹æœå®ƒçš„å¾ˆå¥½è§£é‡Šã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#summary",
    "href": "data-transform.html#summary",
    "title": "3Â  Data transformation",
    "section": "\n3.7 Summary",
    "text": "3.7 Summary\nIn this chapter, youâ€™ve learned the tools that dplyr provides for working with data frames.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº† dplyr ä¸ºå¤„ç†æ•°æ®æ¡†æä¾›çš„å·¥å…·ã€‚\nThe tools are roughly grouped into three categories: those that manipulate the rows (like filter() and arrange()), those that manipulate the columns (like select() and mutate()) and those that manipulate groups (like group_by() and summarize()).\nè¿™äº›å·¥å…·å¤§è‡´åˆ†ä¸ºä¸‰ç±»ï¼šæ“ä½œè¡Œçš„å·¥å…· (å¦‚ filter() å’Œ arrange())ã€æ“ä½œåˆ—çš„å·¥å…· (å¦‚ select() å’Œ mutate()) ä»¥åŠæ“ä½œç»„çš„å·¥å…· (å¦‚ group_by() å’Œ summarize())ã€‚\nIn this chapter, weâ€™ve focused on these â€œwhole data frameâ€ tools, but you havenâ€™t yet learned much about what you can do with the individual variable.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹ä»‹ç»äº†è¿™äº›â€œæ•´ä¸ªæ•°æ®æ¡†â€çš„å·¥å…·ï¼Œä½†ä½ è¿˜æ²¡æœ‰å­¦åˆ°å¤ªå¤šå…³äºå¦‚ä½•å¤„ç†å•ä¸ªå˜é‡çš„çŸ¥è¯†ã€‚\nWeâ€™ll return to that in the Transform part of the book, where each chapter provides tools for a specific type of variable.\næˆ‘ä»¬å°†åœ¨æœ¬ä¹¦çš„â€œè½¬æ¢â€éƒ¨åˆ†å›åˆ°è¿™ä¸ªé—®é¢˜ï¼Œå…¶ä¸­æ¯ä¸€ç« éƒ½ä¸ºç‰¹å®šç±»å‹çš„å˜é‡æä¾›äº†å·¥å…·ã€‚\nIn the next chapter, weâ€™ll pivot back to workflow to discuss the importance of code style and keeping your code well organized to make it easy for you and others to read and understand.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†è½¬å›å·¥ä½œæµç¨‹ï¼Œè®¨è®ºä»£ç é£æ ¼çš„é‡è¦æ€§ä»¥åŠä¿æŒä»£ç äº•äº•æœ‰æ¡ï¼Œä»¥ä¾¿ä½ å’Œå…¶ä»–äººæ˜“äºé˜…è¯»å’Œç†è§£ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#footnotes",
    "href": "data-transform.html#footnotes",
    "title": "3Â  Data transformation",
    "section": "",
    "text": "Later, youâ€™ll learn about the slice_*() family, which allows you to choose rows based on their positions.â†©ï¸\nRemember that in RStudio, the easiest way to see a dataset with many columns is View().â†©ï¸\nOr summarise(), if you prefer British English.â†©ï¸\n*cough* the law of large numbers *cough*.â†©ï¸",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "workflow-style.html",
    "href": "workflow-style.html",
    "title": "4Â  Workflow: code style",
    "section": "",
    "text": "4.1 Names\nGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread. Even as a very new programmer, itâ€™s a good idea to work on your code style. Using a consistent style makes it easier for others (including future-you!) to read your work and is particularly important if you need to get help from someone else. This chapter will introduce the most important points of the tidyverse style guide, which is used throughout this book.\nè‰¯å¥½çš„ç¼–ç é£æ ¼å°±åƒæ­£ç¡®çš„æ ‡ç‚¹ç¬¦å·ï¼šæ²¡æœ‰å®ƒä¹Ÿèƒ½è¡Œï¼Œä½†å®ƒç¡®å®èƒ½è®©äº‹æƒ…æ›´å®¹æ˜“é˜…è¯»ã€‚å³ä½¿ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹æ–°æ‰‹ï¼Œå…»æˆè‰¯å¥½çš„ä»£ç é£æ ¼ä¹Ÿæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚ä½¿ç”¨ä¸€è‡´çš„é£æ ¼å¯ä»¥è®©ä»–äººï¼ˆåŒ…æ‹¬æœªæ¥çš„ä½ ï¼ï¼‰æ›´å®¹æ˜“é˜…è¯»ä½ çš„ä½œå“ï¼Œåœ¨ä½ éœ€è¦ä»–äººå¸®åŠ©æ—¶å°¤å…¶é‡è¦ã€‚æœ¬ç« å°†ä»‹ç» tidyverse é£æ ¼æŒ‡å— ä¸­æœ€é‡è¦çš„å‡ ç‚¹ï¼Œæœ¬ä¹¦é€šç¯‡éƒ½ä½¿ç”¨äº†è¯¥æŒ‡å—ã€‚\nStyling your code will feel a bit tedious to start with, but if you practice it, it will soon become second nature. Additionally, there are some great tools to quickly restyle existing code, like the styler package by Lorenz Walthert. Once youâ€™ve installed it with install.packages(\"styler\"), an easy way to use it is via RStudioâ€™s command palette. The command palette lets you use any built-in RStudio command and many addins provided by packages. Open the palette by pressing Cmd/Ctrl + Shift + P, then type â€œstylerâ€ to see all the shortcuts offered by styler. FigureÂ 4.1 shows the results.\nä¸€å¼€å§‹ï¼Œä½ å¯èƒ½ä¼šè§‰å¾—ä»£ç é£æ ¼åŒ–æœ‰ç‚¹ä¹å‘³ï¼Œä½†å¦‚æœä½ å‹¤åŠ ç»ƒä¹ ï¼Œå®ƒå¾ˆå¿«å°±ä¼šæˆä¸ºä½ çš„ç¬¬äºŒå¤©æ€§ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€äº›å¾ˆæ£’çš„å·¥å…·å¯ä»¥å¿«é€Ÿé‡å¡‘ç°æœ‰ä»£ç çš„é£æ ¼ï¼Œæ¯”å¦‚ Lorenz Walthert å¼€å‘çš„ styler åŒ…ã€‚é€šè¿‡ install.packages(\"styler\") å®‰è£…åï¼Œä¸€ä¸ªç®€ä¾¿çš„ä½¿ç”¨æ–¹æ³•æ˜¯é€šè¿‡ RStudio çš„ å‘½ä»¤é¢æ¿ (command palette)ã€‚å‘½ä»¤é¢æ¿è®©ä½ èƒ½ä½¿ç”¨ä»»ä½• RStudio å†…ç½®å‘½ä»¤ä»¥åŠåŒ…æä¾›çš„è®¸å¤šæ’ä»¶ã€‚æŒ‰ Cmd/Ctrl + Shift + P æ‰“å¼€é¢æ¿ï¼Œç„¶åè¾“å…¥ â€œstylerâ€ å°±å¯ä»¥çœ‹åˆ° styler æä¾›çš„æ‰€æœ‰å¿«æ·æ–¹å¼ã€‚FigureÂ 4.1 å±•ç¤ºäº†ç»“æœã€‚\nWeâ€™ll use the tidyverse and nycflights13 packages for code examples in this chapter.\nåœ¨æœ¬ç« çš„ä»£ç ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ tidyverse å’Œ nycflights13 åŒ…ã€‚\nWe talked briefly about names in Section 2.3. Remember that variable names (those created by &lt;- and those created by mutate()) should use only lowercase letters, numbers, and _. Use _ to separate words within a name.\næˆ‘ä»¬åœ¨ Section 2.3 ä¸­ç®€è¦è®¨è®ºäº†å‘½åã€‚è¯·è®°ä½ï¼Œå˜é‡åï¼ˆç”± &lt;- åˆ›å»ºçš„å’Œç”± mutate() åˆ›å»ºçš„ï¼‰åº”ä»…ä½¿ç”¨å°å†™å­—æ¯ã€æ•°å­—å’Œ _ã€‚ä½¿ç”¨ _ æ¥åˆ†éš”åç§°ä¸­çš„å•è¯ã€‚\n# Strive for:\nshort_flights &lt;- flights |&gt; filter(air_time &lt; 60)\n\n# Avoid:\nSHORTFLIGHTS &lt;- flights |&gt; filter(air_time &lt; 60)\nAs a general rule of thumb, itâ€™s better to prefer long, descriptive names that are easy to understand rather than concise names that are fast to type. Short names save relatively little time when writing code (especially since autocomplete will help you finish typing them), but it can be time-consuming when you come back to old code and are forced to puzzle out a cryptic abbreviation.\næ ¹æ®ç»éªŒï¼Œæœ€å¥½é€‰æ‹©æ˜“äºç†è§£çš„é•¿æè¿°æ€§åç§°ï¼Œè€Œä¸æ˜¯è¾“å…¥å¿«çš„ç®€æ´åç§°ã€‚çŸ­åç§°åœ¨ç¼–å†™ä»£ç æ—¶èŠ‚çœçš„æ—¶é—´ç›¸å¯¹è¾ƒå°‘ï¼ˆç‰¹åˆ«æ˜¯å› ä¸ºè‡ªåŠ¨è¡¥å…¨ä¼šå¸®ä½ å®Œæˆè¾“å…¥ï¼‰ï¼Œä½†å½“ä½ å›å¤´çœ‹æ—§ä»£ç å¹¶è¢«è¿«ç¢ç£¨ä¸€ä¸ªç¥ç§˜çš„ç¼©å†™æ—¶ï¼Œå¯èƒ½ä¼šéå¸¸è€—æ—¶ã€‚\nIf you have a bunch of names for related things, do your best to be consistent. Itâ€™s easy for inconsistencies to arise when you forget a previous convention, so donâ€™t feel bad if you have to go back and rename things. In general, if you have a bunch of variables that are a variation on a theme, youâ€™re better off giving them a common prefix rather than a common suffix because autocomplete works best on the start of a variable.\nå¦‚æœä½ æœ‰ä¸€å †ç›¸å…³äº‹ç‰©çš„åç§°ï¼Œè¯·å°½é‡ä¿æŒä¸€è‡´ã€‚å½“ä½ å¿˜è®°ä¹‹å‰çš„çº¦å®šè€Œå¯¼è‡´ä¸ä¸€è‡´æ—¶ï¼Œè¿™æ˜¯å¾ˆå®¹æ˜“å‘ç”Ÿçš„ï¼Œæ‰€ä»¥å¦‚æœä½ éœ€è¦å›å»é‡å‘½åï¼Œä¹Ÿä¸å¿…æ„Ÿåˆ°éš¾è¿‡ã€‚æ€»çš„æ¥è¯´ï¼Œå¦‚æœä½ æœ‰ä¸€ç»„ä¸»é¢˜ç›¸è¿‘çš„å˜é‡ï¼Œæœ€å¥½ç»™å®ƒä»¬ä¸€ä¸ªå…±åŒçš„å‰ç¼€è€Œä¸æ˜¯åç¼€ï¼Œå› ä¸ºè‡ªåŠ¨è¡¥å…¨åœ¨å˜é‡å¼€å¤´æ•ˆæœæœ€å¥½ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#spaces",
    "href": "workflow-style.html#spaces",
    "title": "4Â  Workflow: code style",
    "section": "\n4.2 Spaces",
    "text": "4.2 Spaces\nPut spaces on either side of mathematical operators apart from ^ (i.e.Â +, -, ==, &lt;, â€¦), and around the assignment operator (&lt;-).\nåœ¨æ•°å­¦è¿ç®—ç¬¦ï¼ˆé™¤äº† ^ï¼Œå³ +ã€-ã€==ã€&lt; ç­‰ï¼‰çš„ä¸¤ä¾§ä»¥åŠèµ‹å€¼è¿ç®—ç¬¦ (&lt;-) çš„å‘¨å›´åŠ ä¸Šç©ºæ ¼ã€‚\n\n# Strive for\nz &lt;- (a + b)^2 / d\n\n# Avoid\nz&lt;-( a + b ) ^ 2/d\n\nDonâ€™t put spaces inside or outside parentheses for regular function calls. Always put a space after a comma, just like in standard English.\nåœ¨å¸¸è§„å‡½æ•°è°ƒç”¨çš„æ‹¬å·å†…å¤–ä¸è¦åŠ ç©ºæ ¼ã€‚åœ¨é€—å·åé¢ä¸€å®šè¦åŠ ä¸€ä¸ªç©ºæ ¼ï¼Œå°±åƒæ ‡å‡†è‹±è¯­ä¸€æ ·ã€‚\n\n# Strive for\nmean(x, na.rm = TRUE)\n\n# Avoid\nmean (x ,na.rm=TRUE)\n\nItâ€™s OK to add extra spaces if it improves alignment. For example, if youâ€™re creating multiple variables in mutate(), you might want to add spaces so that all the = line up.1 This makes it easier to skim the code.\nå¦‚æœèƒ½æ”¹å–„å¯¹é½ï¼Œå¯ä»¥æ·»åŠ é¢å¤–çš„ç©ºæ ¼ã€‚ä¾‹å¦‚ï¼Œå½“ä½ åœ¨ mutate() ä¸­åˆ›å»ºå¤šä¸ªå˜é‡æ—¶ï¼Œä½ å¯èƒ½æƒ³æ·»åŠ ç©ºæ ¼ä»¥ä½¿æ‰€æœ‰çš„ = å¯¹é½ã€‚1 è¿™èƒ½è®©ä»£ç æ›´å®¹æ˜“æµè§ˆã€‚\n\nflights |&gt; \n  mutate(\n    speed      = distance / air_time,\n    dep_hour   = dep_time %/% 100,\n    dep_minute = dep_time %%  100\n  )",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#sec-pipes",
    "href": "workflow-style.html#sec-pipes",
    "title": "4Â  Workflow: code style",
    "section": "\n4.3 Pipes",
    "text": "4.3 Pipes\n|&gt; should always have a space before it and should typically be the last thing on a line. This makes it easier to add new steps, rearrange existing steps, modify elements within a step, and get a 10,000 ft view by skimming the verbs on the left-hand side.|&gt; å‰é¢åº”è¯¥æ€»æœ‰ä¸€ä¸ªç©ºæ ¼ï¼Œå¹¶ä¸”é€šå¸¸åº”è¯¥æ˜¯ä¸€è¡Œçš„æœ€åä¸€ä¸ªå…ƒç´ ã€‚è¿™ä½¿å¾—æ·»åŠ æ–°æ­¥éª¤ã€é‡æ–°æ’åˆ—ç°æœ‰æ­¥éª¤ã€ä¿®æ”¹æ­¥éª¤ä¸­çš„å…ƒç´ ä»¥åŠé€šè¿‡æµè§ˆå·¦ä¾§çš„åŠ¨è¯æ¥è·å¾—å®è§‚è§†è§’å˜å¾—æ›´åŠ å®¹æ˜“ã€‚\n\n# Strive for \nflights |&gt;  \n  filter(!is.na(arr_delay), !is.na(tailnum)) |&gt; \n  count(dest)\n\n# Avoid\nflights|&gt;filter(!is.na(arr_delay), !is.na(tailnum))|&gt;count(dest)\n\nIf the function youâ€™re piping into has named arguments (like mutate() or summarize()), put each argument on a new line. If the function doesnâ€™t have named arguments (like select() or filter()), keep everything on one line unless it doesnâ€™t fit, in which case you should put each argument on its own line.\nå¦‚æœä½ æ­£åœ¨ç®¡é“è¿æ¥çš„å‡½æ•°æœ‰å‘½åå‚æ•°ï¼ˆå¦‚ mutate() æˆ– summarize()ï¼‰ï¼Œè¯·å°†æ¯ä¸ªå‚æ•°æ”¾åœ¨æ–°çš„ä¸€è¡Œã€‚å¦‚æœå‡½æ•°æ²¡æœ‰å‘½åå‚æ•°ï¼ˆå¦‚ select() æˆ– filter()ï¼‰ï¼Œåˆ™å°†æ‰€æœ‰å†…å®¹ä¿æŒåœ¨ä¸€è¡Œï¼Œé™¤éä¸€è¡Œå†™ä¸ä¸‹ï¼Œè¿™ç§æƒ…å†µä¸‹ä½ åº”è¯¥å°†æ¯ä¸ªå‚æ•°æ”¾åœ¨å•ç‹¬çš„ä¸€è¡Œã€‚\n\n# Strive for\nflights |&gt;  \n  group_by(tailnum) |&gt; \n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\n# Avoid\nflights |&gt;\n  group_by(\n    tailnum\n  ) |&gt; \n  summarize(delay = mean(arr_delay, na.rm = TRUE), n = n())\n\nAfter the first step of the pipeline, indent each line by two spaces. RStudio will automatically put the spaces in for you after a line break following a |&gt; . If youâ€™re putting each argument on its own line, indent by an extra two spaces. Make sure ) is on its own line, and un-indented to match the horizontal position of the function name.\nåœ¨ç®¡é“çš„ç¬¬ä¸€æ­¥ä¹‹åï¼Œæ¯è¡Œç¼©è¿›ä¸¤ä¸ªç©ºæ ¼ã€‚åœ¨ |&gt; åé¢æ¢è¡Œæ—¶ï¼ŒRStudio ä¼šè‡ªåŠ¨ä¸ºä½ æ·»åŠ ç©ºæ ¼ã€‚å¦‚æœä½ å°†æ¯ä¸ªå‚æ•°æ”¾åœ¨å•ç‹¬çš„ä¸€è¡Œï¼Œåˆ™é¢å¤–ç¼©è¿›ä¸¤ä¸ªç©ºæ ¼ã€‚ç¡®ä¿ ) å•ç‹¬å ä¸€è¡Œï¼Œå¹¶ä¸”ä¸ç¼©è¿›ï¼Œä»¥ä¸å‡½æ•°åçš„æ°´å¹³ä½ç½®å¯¹é½ã€‚\n\n# Strive for \nflights |&gt;  \n  group_by(tailnum) |&gt; \n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\n# Avoid\nflights|&gt;\n  group_by(tailnum) |&gt; \n  summarize(\n             delay = mean(arr_delay, na.rm = TRUE), \n             n = n()\n           )\n\n# Avoid\nflights|&gt;\n  group_by(tailnum) |&gt; \n  summarize(\n  delay = mean(arr_delay, na.rm = TRUE), \n  n = n()\n  )\n\nItâ€™s OK to shirk some of these rules if your pipeline fits easily on one line. But in our collective experience, itâ€™s common for short snippets to grow longer, so youâ€™ll usually save time in the long run by starting with all the vertical space you need.\nå¦‚æœä½ çš„ç®¡é“å¯ä»¥è½»æ¾åœ°æ”¾åœ¨ä¸€è¡Œä¸Šï¼Œå¯ä»¥ä¸éµå®ˆè¿™äº›è§„åˆ™ã€‚ä½†æ ¹æ®æˆ‘ä»¬çš„é›†ä½“ç»éªŒï¼ŒçŸ­ä»£ç ç‰‡æ®µé€šå¸¸ä¼šå˜å¾—è¶Šæ¥è¶Šé•¿ï¼Œæ‰€ä»¥ä»ä¸€å¼€å§‹å°±ä½¿ç”¨æ‰€éœ€çš„å‚ç›´ç©ºé—´ï¼Œä»é•¿è¿œæ¥çœ‹é€šå¸¸ä¼šèŠ‚çœæ—¶é—´ã€‚\n\n# This fits compactly on one line\ndf |&gt; mutate(y = x + 1)\n\n# While this takes up 4x as many lines, it's easily extended to \n# more variables and more steps in the future\ndf |&gt; \n  mutate(\n    y = x + 1\n  )\n\nFinally, be wary of writing very long pipes, say longer than 10-15 lines. Try to break them up into smaller sub-tasks, giving each task an informative name. The names will help cue the reader into whatâ€™s happening and makes it easier to check that intermediate results are as expected. Whenever you can give something an informative name, you should give it an informative name, for example when you fundamentally change the structure of the data, e.g., after pivoting or summarizing. Donâ€™t expect to get it right the first time! This means breaking up long pipelines if there are intermediate states that can get good names.\næœ€åï¼Œè¦è­¦æƒ•ç¼–å†™è¿‡é•¿çš„ç®¡é“ï¼Œæ¯”å¦‚è¶…è¿‡ 10-15 è¡Œã€‚è¯•ç€å°†å®ƒä»¬åˆ†è§£æˆæ›´å°çš„å­ä»»åŠ¡ï¼Œå¹¶ç»™æ¯ä¸ªä»»åŠ¡ä¸€ä¸ªä¿¡æ¯ä¸°å¯Œçš„åç§°ã€‚è¿™äº›åç§°å°†æœ‰åŠ©äºæç¤ºè¯»è€…æ­£åœ¨å‘ç”Ÿä»€ä¹ˆï¼Œå¹¶ä½¿å…¶æ›´å®¹æ˜“æ£€æŸ¥ä¸­é—´ç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸã€‚åªè¦ä½ èƒ½ç»™æŸä¸ªä¸œè¥¿ä¸€ä¸ªä¿¡æ¯ä¸°å¯Œçš„åç§°ï¼Œä½ å°±åº”è¯¥è¿™æ ·åšï¼Œä¾‹å¦‚ï¼Œå½“ä½ ä»æ ¹æœ¬ä¸Šæ”¹å˜æ•°æ®ç»“æ„æ—¶ï¼ˆä¾‹å¦‚ï¼Œåœ¨æ•°æ®é€è§†æˆ–æ±‡æ€»ä¹‹åï¼‰ã€‚ä¸è¦æœŸæœ›ç¬¬ä¸€æ¬¡å°±åšå¯¹ï¼è¿™æ„å‘³ç€å¦‚æœå­˜åœ¨å¯ä»¥è·å¾—å¥½åç§°çš„ä¸­é—´çŠ¶æ€ï¼Œå°±åº”è¯¥æ‹†åˆ†é•¿ç®¡é“ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#ggplot2",
    "href": "workflow-style.html#ggplot2",
    "title": "4Â  Workflow: code style",
    "section": "\n4.4 ggplot2",
    "text": "4.4 ggplot2\nThe same basic rules that apply to the pipe also apply to ggplot2; just treat + the same way as |&gt;.\né€‚ç”¨äºç®¡é“çš„åŸºæœ¬è§„åˆ™åŒæ ·é€‚ç”¨äº ggplot2ï¼›åªéœ€å°† + è§†ä¸º |&gt; å³å¯ã€‚\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE)\n  ) |&gt; \n  ggplot(aes(x = month, y = delay)) +\n  geom_point() + \n  geom_line()\n\nAgain, if you canâ€™t fit all of the arguments to a function on to a single line, put each argument on its own line:\nåŒæ ·ï¼Œå¦‚æœä¸€ä¸ªå‡½æ•°çš„æ‰€æœ‰å‚æ•°æ— æ³•æ”¾åœ¨ä¸€è¡Œå†…ï¼Œå°±å°†æ¯ä¸ªå‚æ•°å•ç‹¬æ”¾åœ¨ä¸€è¡Œï¼š\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(\n    distance = mean(distance),\n    speed = mean(distance / air_time, na.rm = TRUE)\n  ) |&gt; \n  ggplot(aes(x = distance, y = speed)) +\n  geom_smooth(\n    method = \"loess\",\n    span = 0.5,\n    se = FALSE, \n    color = \"white\", \n    linewidth = 4\n  ) +\n  geom_point()\n\nWatch for the transition from |&gt; to +. We wish this transition wasnâ€™t necessary, but unfortunately, ggplot2 was written before the pipe was discovered.\næ³¨æ„ä» |&gt; åˆ° + çš„è½¬æ¢ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ç§è½¬æ¢æ˜¯ä¸å¿…è¦çš„ï¼Œä½†é—æ†¾çš„æ˜¯ï¼Œggplot2 æ˜¯åœ¨ç®¡é“è¢«å‘ç°ä¹‹å‰ç¼–å†™çš„ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#sectioning-comments",
    "href": "workflow-style.html#sectioning-comments",
    "title": "4Â  Workflow: code style",
    "section": "\n4.5 Sectioning comments",
    "text": "4.5 Sectioning comments\nAs your scripts get longer, you can use sectioning comments to break up your file into manageable pieces:\nå½“ä½ çš„è„šæœ¬è¶Šæ¥è¶Šé•¿æ—¶ï¼Œä½ å¯ä»¥ä½¿ç”¨ åˆ†èŠ‚ æ³¨é‡Šå°†æ–‡ä»¶åˆ†è§£æˆæ˜“äºç®¡ç†çš„éƒ¨åˆ†ï¼š\n\n# Load data --------------------------------------\n\n# Plot data --------------------------------------\n\nRStudio provides a keyboard shortcut to create these headers (Cmd/Ctrl + Shift + R), and will display them in the code navigation drop-down at the bottom-left of the editor, as shown in FigureÂ 4.2.\nRStudio æä¾›äº†åˆ›å»ºè¿™äº›æ ‡é¢˜çš„é”®ç›˜å¿«æ·é”® (Cmd/Ctrl + Shift + R)ï¼Œå¹¶ä¼šåœ¨ç¼–è¾‘å™¨å·¦ä¸‹è§’çš„ä»£ç å¯¼èˆªä¸‹æ‹‰èœå•ä¸­æ˜¾ç¤ºå®ƒä»¬ï¼Œå¦‚ FigureÂ 4.2 æ‰€ç¤ºã€‚\n\n\n\n\n\n\n\nFigureÂ 4.2: After adding sectioning comments to your script, you can easily navigate to them using the code navigation tool in the bottom-left of the script editor.",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#exercises",
    "href": "workflow-style.html#exercises",
    "title": "4Â  Workflow: code style",
    "section": "\n4.6 Exercises",
    "text": "4.6 Exercises\n\n\nRestyle the following pipelines following the guidelines above.\n\nflights|&gt;filter(dest==\"IAH\")|&gt;group_by(year,month,day)|&gt;summarize(n=n(),\ndelay=mean(arr_delay,na.rm=TRUE))|&gt;filter(n&gt;10)\n\nflights|&gt;filter(carrier==\"UA\",dest%in%c(\"IAH\",\"HOU\"),sched_dep_time&gt;\n0900,sched_arr_time&lt;2000)|&gt;group_by(flight)|&gt;summarize(delay=mean(\narr_delay,na.rm=TRUE),cancelled=sum(is.na(arr_delay)),n=n())|&gt;filter(n&gt;10)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#summary",
    "href": "workflow-style.html#summary",
    "title": "4Â  Workflow: code style",
    "section": "\n4.7 Summary",
    "text": "4.7 Summary\nIn this chapter, youâ€™ve learned the most important principles of code style. These may feel like a set of arbitrary rules to start with (because they are!) but over time, as you write more code, and share code with more people, youâ€™ll see how important a consistent style is. And donâ€™t forget about the styler package: itâ€™s a great way to quickly improve the quality of poorly styled code.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†ä»£ç é£æ ¼æœ€é‡è¦çš„åŸåˆ™ã€‚ä¸€å¼€å§‹ï¼Œè¿™äº›å¯èƒ½æ„Ÿè§‰åƒæ˜¯ä¸€å¥—æ­¦æ–­çš„è§„åˆ™ï¼ˆå› ä¸ºå®ƒä»¬ç¡®å®æ˜¯ï¼ï¼‰ï¼Œä½†éšç€æ—¶é—´çš„æ¨ç§»ï¼Œå½“ä½ ç¼–å†™æ›´å¤šä»£ç ï¼Œå¹¶ä¸æ›´å¤šäººå…±äº«ä»£ç æ—¶ï¼Œä½ ä¼šçœ‹åˆ°ä¸€è‡´çš„é£æ ¼æ˜¯å¤šä¹ˆé‡è¦ã€‚åˆ«å¿˜äº† styler åŒ…ï¼šå®ƒæ˜¯ä¸€ä¸ªå¿«é€Ÿæé«˜å·®é£æ ¼ä»£ç è´¨é‡çš„å¥½æ–¹æ³•ã€‚\nIn the next chapter, we switch back to data science tools, learning about tidy data. Tidy data is a consistent way of organizing your data frames that is used throughout the tidyverse. This consistency makes your life easier because once you have tidy data, it just works with the vast majority of tidyverse functions. Of course, life is never easy, and most datasets you encounter in the wild will not already be tidy. So weâ€™ll also teach you how to use the tidyr package to tidy your untidy data.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†å›åˆ°æ•°æ®ç§‘å­¦å·¥å…·ï¼Œå­¦ä¹ æ•´æ´æ•°æ® (tidy data)ã€‚æ•´æ´æ•°æ®æ˜¯ç»„ç»‡æ•°æ®æ¡†çš„ä¸€ç§ä¸€è‡´æ–¹å¼ï¼Œåœ¨æ•´ä¸ª tidyverse ä¸­éƒ½åœ¨ä½¿ç”¨ã€‚è¿™ç§ä¸€è‡´æ€§ä½¿ä½ çš„å·¥ä½œæ›´è½»æ¾ï¼Œå› ä¸ºä¸€æ—¦ä½ æ‹¥æœ‰äº†æ•´æ´æ•°æ®ï¼Œå®ƒå°±èƒ½ä¸ç»å¤§å¤šæ•° tidyverse å‡½æ•°ååŒå·¥ä½œã€‚å½“ç„¶ï¼Œç”Ÿæ´»ä»ä¸è½»æ¾ï¼Œä½ åœ¨é‡å¤–é‡åˆ°çš„å¤§å¤šæ•°æ•°æ®é›†éƒ½ä¸ä¼šæ˜¯æ•´æ´çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿˜å°†æ•™ä½ å¦‚ä½•ä½¿ç”¨ tidyr åŒ…æ¥æ•´ç†ä½ çš„éæ•´æ´æ•°æ®ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#footnotes",
    "href": "workflow-style.html#footnotes",
    "title": "4Â  Workflow: code style",
    "section": "",
    "text": "Since dep_time is in HMM or HHMM format, we use integer division (%/%) to get hour and remainder (also known as modulo, %%) to get minute.â†©ï¸",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Workflow: code style</span>"
    ]
  },
  {
    "objectID": "data-tidy.html",
    "href": "data-tidy.html",
    "title": "5Â  Data tidying",
    "section": "",
    "text": "5.1 Introduction\nIn this chapter, you will learn a consistent way to organize your data in R using a system called tidy data. Getting your data into this format requires some work up front, but that work pays off in the long term. Once you have tidy data and the tidy tools provided by packages in the tidyverse, you will spend much less time munging data from one representation to another, allowing you to spend more time on the data questions you care about.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸€ç§åœ¨ R ä¸­ç»„ç»‡æ•°æ®çš„ä¸€è‡´æ€§æ–¹æ³•ï¼Œè¿™ä¸ªç³»ç»Ÿè¢«ç§°ä¸ºæ•´æ´æ•°æ® (tidy data)ã€‚ å°†æ•°æ®æ•´ç†æˆè¿™ç§æ ¼å¼éœ€è¦ä¸€äº›å‰æœŸå·¥ä½œï¼Œä½†ä»é•¿è¿œæ¥çœ‹ï¼Œè¿™äº›å·¥ä½œæ˜¯å€¼å¾—çš„ã€‚ ä¸€æ—¦ä½ æ‹¥æœ‰äº†æ•´æ´çš„æ•°æ®ä»¥åŠ tidyverse ä¸­å„ä¸ªåŒ…æä¾›çš„æ•´æ´å·¥å…·ï¼Œä½ å°†èŠ±è´¹æ›´å°‘çš„æ—¶é—´åœ¨ä¸åŒæ•°æ®è¡¨ç¤ºå½¢å¼ä¹‹é—´è¿›è¡Œè½¬æ¢ï¼Œä»è€Œå¯ä»¥æŠ•å…¥æ›´å¤šæ—¶é—´æ¥å…³æ³¨ä½ æ‰€å…³å¿ƒçš„æ•°æ®é—®é¢˜ã€‚\nIn this chapter, youâ€™ll first learn the definition of tidy data and see it applied to a simple toy dataset. Then weâ€™ll dive into the primary tool youâ€™ll use for tidying data: pivoting. Pivoting allows you to change the form of your data without changing any of the values.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†é¦–å…ˆå­¦ä¹ æ•´æ´æ•°æ®çš„å®šä¹‰ï¼Œå¹¶çœ‹åˆ°å®ƒå¦‚ä½•åº”ç”¨äºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹æ•°æ®é›†ã€‚ ç„¶åï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ç”¨äºæ•´ç†æ•°æ®çš„ä¸»è¦å·¥å…·ï¼šé€è§† (pivoting)ã€‚ é€è§†å…è®¸ä½ åœ¨ä¸æ”¹å˜ä»»ä½•å€¼çš„æƒ…å†µä¸‹æ”¹å˜æ•°æ®çš„å½¢æ€ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#introduction",
    "href": "data-tidy.html#introduction",
    "title": "5Â  Data tidying",
    "section": "",
    "text": "â€œHappy families are all alike; every unhappy family is unhappy in its own way.â€\nâ€” Leo Tolstoy\nâ€œå¹¸ç¦çš„å®¶åº­éƒ½æ˜¯ç›¸ä¼¼çš„ï¼›ä¸å¹¸çš„å®¶åº­å„æœ‰å„çš„ä¸å¹¸ã€‚â€\nâ€” åˆ—å¤«Â·æ‰˜å°”æ–¯æ³°\n\n\nâ€œTidy datasets are all alike, but every messy dataset is messy in its own way.â€\nâ€” Hadley Wickham\nâ€œæ•´æ´çš„æ•°æ®é›†éƒ½æ˜¯ç›¸ä¼¼çš„ï¼Œä½†æ¯ä¸ªå‡Œä¹±çš„æ•°æ®é›†å„æœ‰å„çš„å‡Œä¹±ä¹‹å¤„ã€‚â€\nâ€” Hadley Wickham\n\n\n\n\n5.1.1 Prerequisites\nIn this chapter, weâ€™ll focus on tidyr, a package that provides a bunch of tools to help tidy up your messy datasets. tidyr is a member of the core tidyverse.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç» tidyrï¼Œè¿™ä¸ªåŒ…æä¾›äº†ä¸€ç³»åˆ—å·¥å…·æ¥å¸®åŠ©ä½ æ•´ç†å‡Œä¹±çš„æ•°æ®é›†ã€‚ tidyr æ˜¯æ ¸å¿ƒ tidyverse çš„æˆå‘˜ä¹‹ä¸€ã€‚\n\nlibrary(tidyverse)\n\nFrom this chapter on, weâ€™ll suppress the loading message from library(tidyverse).\nä»æœ¬ç« å¼€å§‹ï¼Œæˆ‘ä»¬å°†æŠ‘åˆ¶ library(tidyverse) çš„åŠ è½½æ¶ˆæ¯ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-tidy-data",
    "href": "data-tidy.html#sec-tidy-data",
    "title": "5Â  Data tidying",
    "section": "\n5.2 Tidy data",
    "text": "5.2 Tidy data\nYou can represent the same underlying data in multiple ways. The example below shows the same data organized in three different ways. Each dataset shows the same values of four variables: country, year, population, and number of documented cases of TB (tuberculosis), but each dataset organizes the values in a different way.\nä½ å¯ä»¥ç”¨å¤šç§æ–¹å¼è¡¨ç¤ºç›¸åŒçš„åŸºç¡€æ•°æ®ã€‚ ä¸‹é¢çš„ç¤ºä¾‹å±•ç¤ºäº†ä»¥ä¸‰ç§ä¸åŒæ–¹å¼ç»„ç»‡çš„ç›¸åŒæ•°æ®ã€‚ æ¯ä¸ªæ•°æ®é›†éƒ½æ˜¾ç¤ºäº†å››ä¸ªå˜é‡çš„ç›¸åŒå€¼ï¼šcountry (å›½å®¶)ã€year (å¹´ä»½)ã€population (äººå£) å’Œè®°å½•åœ¨æ¡ˆçš„ cases (ç»“æ ¸ç—…ç—…ä¾‹æ•°)ï¼Œä½†æ¯ä¸ªæ•°æ®é›†ä»¥ä¸åŒçš„æ–¹å¼ç»„ç»‡è¿™äº›å€¼ã€‚\n\ntable1\n#&gt; # A tibble: 6 Ã— 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\ntable2\n#&gt; # A tibble: 12 Ã— 4\n#&gt;   country      year type           count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999 cases            745\n#&gt; 2 Afghanistan  1999 population  19987071\n#&gt; 3 Afghanistan  2000 cases           2666\n#&gt; 4 Afghanistan  2000 population  20595360\n#&gt; 5 Brazil       1999 cases          37737\n#&gt; 6 Brazil       1999 population 172006362\n#&gt; # â„¹ 6 more rows\n\ntable3\n#&gt; # A tibble: 6 Ã— 3\n#&gt;   country      year rate             \n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n#&gt; 1 Afghanistan  1999 745/19987071     \n#&gt; 2 Afghanistan  2000 2666/20595360    \n#&gt; 3 Brazil       1999 37737/172006362  \n#&gt; 4 Brazil       2000 80488/174504898  \n#&gt; 5 China        1999 212258/1272915272\n#&gt; 6 China        2000 213766/1280428583\n\nThese are all representations of the same underlying data, but they are not equally easy to use. One of them, table1, will be much easier to work with inside the tidyverse because itâ€™s tidy.\nè¿™äº›éƒ½æ˜¯ç›¸åŒåŸºç¡€æ•°æ®çš„ä¸åŒè¡¨ç¤ºå½¢å¼ï¼Œä½†å®ƒä»¬çš„ä½¿ç”¨ä¾¿åˆ©æ€§å¹¶ä¸ç›¸åŒã€‚ å…¶ä¸­ä¹‹ä¸€ï¼Œtable1ï¼Œåœ¨ tidyverse ä¸­ä½¿ç”¨èµ·æ¥ä¼šå®¹æ˜“å¾—å¤šï¼Œå› ä¸ºå®ƒæ˜¯æ•´æ´çš„ã€‚\nThere are three interrelated rules that make a dataset tidy:\næœ‰ä¸‰æ¡ç›¸äº’å…³è”çš„è§„åˆ™å¯ä»¥ä½¿æ•°æ®é›†å˜å¾—æ•´æ´ï¼š\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value.\næ¯ä¸ªå˜é‡æ˜¯ä¸€åˆ—ï¼›æ¯åˆ—æ˜¯ä¸€ä¸ªå˜é‡ã€‚\næ¯ä¸ªè§‚æµ‹æ˜¯ä¸€è¡Œï¼›æ¯è¡Œæ˜¯ä¸€ä¸ªè§‚æµ‹ã€‚\næ¯ä¸ªå€¼æ˜¯ä¸€ä¸ªå•å…ƒæ ¼ï¼›æ¯ä¸ªå•å…ƒæ ¼æ˜¯ä¸€ä¸ªå€¼ã€‚\n\nFigureÂ 5.1 shows the rules visually.FigureÂ 5.1 ç›´è§‚åœ°å±•ç¤ºäº†è¿™äº›è§„åˆ™ã€‚\n\n\n\n\n\n\n\nFigureÂ 5.1: The following three rules make a dataset tidy: variables are columns, observations are rows, and values are cells.\n\n\n\n\nWhy ensure that your data is tidy? There are two main advantages:\nä¸ºä»€ä¹ˆè¦ç¡®ä¿ä½ çš„æ•°æ®æ˜¯æ•´æ´çš„ï¼Ÿ ä¸»è¦æœ‰ä¸¤ä¸ªä¼˜ç‚¹ï¼š\n\nThereâ€™s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, itâ€™s easier to learn the tools that work with it because they have an underlying uniformity.\nThereâ€™s a specific advantage to placing variables in columns because it allows Râ€™s vectorized nature to shine. As you learned in Section 3.3.1 and Section 3.5.2, most built-in R functions work with vectors of values. That makes transforming tidy data feel particularly natural.\né€‰æ‹©ä¸€ç§ä¸€è‡´çš„æ•°æ®å­˜å‚¨æ–¹å¼å…·æœ‰æ™®éçš„ä¼˜åŠ¿ã€‚ å¦‚æœä½ æœ‰ä¸€ä¸ªä¸€è‡´çš„æ•°æ®ç»“æ„ï¼Œå­¦ä¹ ä¸ä¹‹é…åˆçš„å·¥å…·ä¼šæ›´å®¹æ˜“ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å†…åœ¨çš„ä¸€è‡´æ€§ã€‚\nå°†å˜é‡æ”¾åœ¨åˆ—ä¸­æœ‰ä¸€ä¸ªç‰¹å®šçš„ä¼˜åŠ¿ï¼Œå› ä¸ºè¿™èƒ½è®© R çš„å‘é‡åŒ–ç‰¹æ€§å¤§æ”¾å¼‚å½©ã€‚ æ­£å¦‚ä½ åœ¨ Section 3.3.1 å’Œ Section 3.5.2 ä¸­å­¦åˆ°çš„ï¼Œå¤§å¤šæ•°å†…ç½®çš„ R å‡½æ•°éƒ½å¤„ç†å€¼çš„å‘é‡ã€‚ è¿™ä½¿å¾—è½¬æ¢æ•´æ´çš„æ•°æ®æ„Ÿè§‰ç‰¹åˆ«è‡ªç„¶ã€‚\n\ndplyr, ggplot2, and all the other packages in the tidyverse are designed to work with tidy data. Here are a few small examples showing how you might work with table1.\ndplyrã€ggplot2 ä»¥åŠ tidyverse ä¸­çš„æ‰€æœ‰å…¶ä»–åŒ…éƒ½æ˜¯ä¸ºå¤„ç†æ•´æ´æ•°æ®è€Œè®¾è®¡çš„ã€‚ è¿™é‡Œæœ‰å‡ ä¸ªå°ä¾‹å­ï¼Œå±•ç¤ºäº†ä½ å¦‚ä½•ä½¿ç”¨ table1ã€‚\n\n# Compute rate per 10,000\ntable1 |&gt;\n  mutate(rate = cases / population * 10000)\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   country      year  cases population  rate\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071 0.373\n#&gt; 2 Afghanistan  2000   2666   20595360 1.29 \n#&gt; 3 Brazil       1999  37737  172006362 2.19 \n#&gt; 4 Brazil       2000  80488  174504898 4.61 \n#&gt; 5 China        1999 212258 1272915272 1.67 \n#&gt; 6 China        2000 213766 1280428583 1.67\n\n# Compute total cases per year\ntable1 |&gt; \n  group_by(year) |&gt; \n  summarize(total_cases = sum(cases))\n#&gt; # A tibble: 2 Ã— 2\n#&gt;    year total_cases\n#&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1  1999      250740\n#&gt; 2  2000      296920\n\n# Visualize changes over time\nggplot(table1, aes(x = year, y = cases)) +\n  geom_line(aes(group = country), color = \"grey50\") +\n  geom_point(aes(color = country, shape = country)) +\n  scale_x_continuous(breaks = c(1999, 2000)) # x-axis breaks at 1999 and 2000\n\n\n\n\n\n\n\n\n5.2.1 Exercises\n\nFor each of the sample tables, describe what each observation and each column represents.\n\nSketch out the process youâ€™d use to calculate the rate for table2 and table3. You will need to perform four operations:\n\nExtract the number of TB cases per country per year.\nExtract the matching population per country per year.\nDivide cases by population, and multiply by 10000.\nStore back in the appropriate place.\n\nYou havenâ€™t yet learned all the functions youâ€™d need to actually perform these operations, but you should still be able to think through the transformations youâ€™d need.",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-pivoting",
    "href": "data-tidy.html#sec-pivoting",
    "title": "5Â  Data tidying",
    "section": "\n5.3 Lengthening data",
    "text": "5.3 Lengthening data\nThe principles of tidy data might seem so obvious that you wonder if youâ€™ll ever encounter a dataset that isnâ€™t tidy. Unfortunately, however, most real data is untidy. There are two main reasons:\næ•´æ´æ•°æ®çš„åŸåˆ™å¯èƒ½çœ‹èµ·æ¥å¦‚æ­¤æ˜¾è€Œæ˜“è§ï¼Œä»¥è‡³äºä½ å¯èƒ½ä¼šæ€€ç–‘æ˜¯å¦ä¼šé‡åˆ°ä¸æ•´æ´çš„æ•°æ®é›†ã€‚ ç„¶è€Œï¼Œä¸å¹¸çš„æ˜¯ï¼Œå¤§å¤šæ•°çœŸå®æ•°æ®éƒ½æ˜¯ä¸æ•´æ´çš„ã€‚ ä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼š\n\nData is often organized to facilitate some goal other than analysis. For example, itâ€™s common for data to be structured to make data entry, not analysis, easy. æ•°æ®çš„ç»„ç»‡æ–¹å¼é€šå¸¸æ˜¯ä¸ºäº†ä¿ƒè¿›é™¤åˆ†æä¹‹å¤–çš„å…¶ä»–ç›®æ ‡ã€‚ ä¾‹å¦‚ï¼Œä¸ºäº†æ–¹ä¾¿æ•°æ®å½•å…¥è€Œéåˆ†æè€Œæ„å»ºæ•°æ®ç»“æ„æ˜¯å¾ˆå¸¸è§çš„ã€‚\nMost people arenâ€™t familiar with the principles of tidy data, and itâ€™s hard to derive them yourself unless you spend a lot of time working with data.\nå¤§å¤šæ•°äººå¹¶ä¸ç†Ÿæ‚‰æ•´æ´æ•°æ®çš„åŸåˆ™ï¼Œé™¤éä½ èŠ±å¤§é‡æ—¶é—´å¤„ç†æ•°æ®ï¼Œå¦åˆ™å¾ˆéš¾è‡ªå·±æ¨å¯¼å‡ºè¿™äº›åŸåˆ™ã€‚\n\nThis means that most real analyses will require at least a little tidying. Youâ€™ll begin by figuring out what the underlying variables and observations are. Sometimes this is easy; other times youâ€™ll need to consult with the people who originally generated the data. Next, youâ€™ll pivot your data into a tidy form, with variables in the columns and observations in the rows.\nè¿™æ„å‘³ç€å¤§å¤šæ•°å®é™…åˆ†æè‡³å°‘éœ€è¦ä¸€äº›æ•´ç†å·¥ä½œã€‚ ä½ å°†é¦–å…ˆå¼„æ¸…æ¥šæ½œåœ¨çš„å˜é‡å’Œè§‚æµ‹å€¼æ˜¯ä»€ä¹ˆã€‚ æœ‰æ—¶è¿™å¾ˆç®€å•ï¼›å…¶ä»–æ—¶å€™ä½ å¯èƒ½éœ€è¦å’¨è¯¢æœ€åˆç”Ÿæˆæ•°æ®çš„äººã€‚ æ¥ä¸‹æ¥ï¼Œä½ å°†é€è§† (pivot) ä½ çš„æ•°æ®ï¼Œä½¿å…¶æˆä¸ºå˜é‡åœ¨åˆ—ã€è§‚æµ‹åœ¨è¡Œçš„æ•´æ´å½¢å¼ã€‚\ntidyr provides two functions for pivoting data: pivot_longer() and pivot_wider(). Weâ€™ll first start with pivot_longer() because itâ€™s the most common case. Letâ€™s dive into some examples.\ntidyr æä¾›äº†ä¸¤ä¸ªç”¨äºæ•°æ®é€è§†çš„å‡½æ•°ï¼špivot_longer() å’Œ pivot_wider()ã€‚ æˆ‘ä»¬å°†é¦–å…ˆä» pivot_longer() å¼€å§‹ï¼Œå› ä¸ºè¿™æ˜¯æœ€å¸¸è§çš„æƒ…å†µã€‚ è®©æˆ‘ä»¬æ¥çœ‹ä¸€äº›ä¾‹å­ã€‚\n\n5.3.1 Data in column names\nThe billboard dataset records the billboard rank of songs in the year 2000:billboard æ•°æ®é›†è®°å½•äº† 2000 å¹´æ­Œæ›²çš„ billboard æ’è¡Œæ¦œæ’åï¼š\n\nbillboard\n#&gt; # A tibble: 317 Ã— 79\n#&gt;   artist       track               date.entered   wk1   wk2   wk3   wk4   wk5\n#&gt;   &lt;chr&gt;        &lt;chr&gt;               &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac        Baby Don't Cry (Keâ€¦ 2000-02-26      87    82    72    77    87\n#&gt; 2 2Ge+her      The Hardest Part Oâ€¦ 2000-09-02      91    87    92    NA    NA\n#&gt; 3 3 Doors Down Kryptonite          2000-04-08      81    70    68    67    66\n#&gt; 4 3 Doors Down Loser               2000-10-21      76    76    72    69    67\n#&gt; 5 504 Boyz     Wobble Wobble       2000-04-15      57    34    25    17    17\n#&gt; 6 98^0         Give Me Just One Nâ€¦ 2000-08-19      51    39    34    26    26\n#&gt; # â„¹ 311 more rows\n#&gt; # â„¹ 71 more variables: wk6 &lt;dbl&gt;, wk7 &lt;dbl&gt;, wk8 &lt;dbl&gt;, wk9 &lt;dbl&gt;, â€¦\n\nIn this dataset, each observation is a song. The first three columns (artist, track and date.entered) are variables that describe the song. Then we have 76 columns (wk1-wk76) that describe the rank of the song in each week1. Here, the column names are one variable (the week) and the cell values are another (the rank).\nåœ¨è¿™ä¸ªæ•°æ®é›†ä¸­ï¼Œæ¯ä¸ªè§‚æµ‹æ˜¯ä¸€é¦–æ­Œæ›²ã€‚ å‰ä¸‰åˆ—ï¼ˆartistã€track å’Œ date.enteredï¼‰æ˜¯æè¿°æ­Œæ›²çš„å˜é‡ã€‚ ç„¶åæˆ‘ä»¬æœ‰ 76 åˆ—ï¼ˆwk1 åˆ° wk76ï¼‰ï¼Œæè¿°äº†æ­Œæ›²åœ¨æ¯å‘¨çš„æ’å1ã€‚ åœ¨è¿™é‡Œï¼Œåˆ—åæ˜¯ä¸€ä¸ªå˜é‡ï¼ˆweekï¼‰ï¼Œè€Œå•å…ƒæ ¼çš„å€¼æ˜¯å¦ä¸€ä¸ªå˜é‡ï¼ˆrankï¼‰ã€‚\nTo tidy this data, weâ€™ll use pivot_longer():\nä¸ºäº†æ•´ç†è¿™ä¸ªæ•°æ®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ pivot_longer()ï¼š\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\"\n  )\n#&gt; # A tibble: 24,092 Ã— 5\n#&gt;    artist track                   date.entered week   rank\n#&gt;    &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt;  1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt;  2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt;  3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt;  4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt;  5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt;  6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt;  7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n#&gt;  8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n#&gt;  9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n#&gt; 10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n#&gt; # â„¹ 24,082 more rows\n\nAfter the data, there are three key arguments:\nåœ¨æ•°æ®ä¹‹åï¼Œæœ‰ä¸‰ä¸ªå…³é”®å‚æ•°ï¼š\n\ncols specifies which columns need to be pivoted, i.e.Â which columns arenâ€™t variables. This argument uses the same syntax as select() so here we could use !c(artist, track, date.entered) or starts_with(\"wk\").cols æŒ‡å®šå“ªäº›åˆ—éœ€è¦è¿›è¡Œé€è§†ï¼Œå³å“ªäº›åˆ—ä¸æ˜¯å˜é‡ã€‚æ­¤å‚æ•°ä½¿ç”¨ä¸ select() ç›¸åŒçš„è¯­æ³•ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å¯ä»¥ç”¨ !c(artist, track, date.entered) æˆ– starts_with(\"wk\")ã€‚\nnames_to names the variable stored in the column names, we named that variable week. names_to ä¸ºå­˜å‚¨åœ¨åˆ—åä¸­çš„å˜é‡å‘½åï¼Œæˆ‘ä»¬å°†å…¶å‘½åä¸º weekã€‚\nvalues_to names the variable stored in the cell values, we named that variable rank.values_to ä¸ºå­˜å‚¨åœ¨å•å…ƒæ ¼å€¼ä¸­çš„å˜é‡å‘½åï¼Œæˆ‘ä»¬å°†å…¶å‘½åä¸º rankã€‚\n\nNote that in the code \"week\" and \"rank\" are quoted because those are new variables weâ€™re creating, they donâ€™t yet exist in the data when we run the pivot_longer() call.\nè¯·æ³¨æ„ï¼Œåœ¨ä»£ç ä¸­ \"week\" å’Œ \"rank\" æ˜¯å¸¦å¼•å·çš„ï¼Œå› ä¸ºå®ƒä»¬æ˜¯æˆ‘ä»¬æ­£åœ¨åˆ›å»ºçš„æ–°å˜é‡ï¼Œåœ¨æˆ‘ä»¬è¿è¡Œ pivot_longer() è°ƒç”¨æ—¶ï¼Œå®ƒä»¬è¿˜ä¸å­˜åœ¨äºæ•°æ®ä¸­ã€‚\nNow letâ€™s turn our attention to the resulting, longer data frame. What happens if a song is in the top 100 for less than 76 weeks? Take 2 Pacâ€™s â€œBaby Donâ€™t Cryâ€, for example. The above output suggests that it was only in the top 100 for 7 weeks, and all the remaining weeks are filled in with missing values. These NAs donâ€™t really represent unknown observations; they were forced to exist by the structure of the dataset2, so we can ask pivot_longer() to get rid of them by setting values_drop_na = TRUE:\nç°åœ¨è®©æˆ‘ä»¬æŠŠæ³¨æ„åŠ›è½¬å‘ç”Ÿæˆçš„æ›´é•¿çš„æ•°æ®æ¡†ã€‚ å¦‚æœä¸€é¦–æ­Œè¿›å…¥å‰ 100 åçš„æ—¶é—´å°‘äº 76 å‘¨ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ ä»¥ 2 Pac çš„ â€œBaby Donâ€™t Cryâ€ ä¸ºä¾‹ã€‚ ä¸Šé¢çš„è¾“å‡ºè¡¨æ˜å®ƒåªåœ¨å‰ 100 åä¸­å¾…äº† 7 å‘¨ï¼Œè€Œæ‰€æœ‰å‰©ä½™çš„å‘¨æ•°éƒ½è¢«å¡«å……äº†ç¼ºå¤±å€¼ã€‚ è¿™äº› NA å¹¶ä¸çœŸæ­£ä»£è¡¨æœªçŸ¥çš„è§‚æµ‹å€¼ï¼›å®ƒä»¬æ˜¯ç”±äºæ•°æ®é›†çš„ç»“æ„è€Œè¢«å¼ºåˆ¶å­˜åœ¨çš„2ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾ç½® values_drop_na = TRUE æ¥è®© pivot_longer() ç§»é™¤å®ƒä»¬ï¼š\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  )\n#&gt; # A tibble: 5,307 Ã— 5\n#&gt;   artist track                   date.entered week   rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt; # â„¹ 5,301 more rows\n\nThe number of rows is now much lower, indicating that many rows with NAs were dropped.\nç°åœ¨è¡Œæ•°å¤§å¤§å‡å°‘äº†ï¼Œè¿™è¡¨æ˜è®¸å¤šå¸¦æœ‰ NA çš„è¡Œè¢«åˆ é™¤äº†ã€‚\nYou might also wonder what happens if a song is in the top 100 for more than 76 weeks? We canâ€™t tell from this data, but you might guess that additional columns wk77, wk78, â€¦ would be added to the dataset.\nä½ å¯èƒ½è¿˜ä¼šæƒ³ï¼Œå¦‚æœä¸€é¦–æ­Œåœ¨å‰ 100 åä¸­åœç•™è¶…è¿‡ 76 å‘¨ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ æˆ‘ä»¬æ— æ³•ä»è¿™ä¸ªæ•°æ®ä¸­å¾—çŸ¥ï¼Œä½†ä½ å¯èƒ½ä¼šçŒœæµ‹æ•°æ®é›†ä¸­ä¼šæ·»åŠ é¢å¤–çš„åˆ— wk77ã€wk78 ç­‰ã€‚\nThis data is now tidy, but we could make future computation a bit easier by converting values of week from character strings to numbers using mutate() and readr::parse_number(). parse_number() is a handy function that will extract the first number from a string, ignoring all other text.\nè¿™ä¸ªæ•°æ®ç°åœ¨æ˜¯æ•´æ´çš„ï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ mutate() å’Œ readr::parse_number() å°† week çš„å€¼ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å­—ï¼Œæ¥ä½¿æœªæ¥çš„è®¡ç®—æ›´å®¹æ˜“ä¸€äº›ã€‚ parse_number() æ˜¯ä¸€ä¸ªæ–¹ä¾¿çš„å‡½æ•°ï¼Œå®ƒä¼šä»å­—ç¬¦ä¸²ä¸­æå–ç¬¬ä¸€ä¸ªæ•°å­—ï¼Œå¹¶å¿½ç•¥æ‰€æœ‰å…¶ä»–æ–‡æœ¬ã€‚\n\nbillboard_longer &lt;- billboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  ) |&gt; \n  mutate(\n    week = parse_number(week)\n  )\nbillboard_longer\n#&gt; # A tibble: 5,307 Ã— 5\n#&gt;   artist track                   date.entered  week  rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26       1    87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26       2    82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26       3    72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26       4    77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26       5    87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26       6    94\n#&gt; # â„¹ 5,301 more rows\n\nNow that we have all the week numbers in one variable and all the rank values in another, weâ€™re in a good position to visualize how song ranks vary over time. The code is shown below and the result is in FigureÂ 5.2. We can see that very few songs stay in the top 100 for more than 20 weeks.\nç°åœ¨æˆ‘ä»¬æŠŠæ‰€æœ‰çš„å‘¨æ•°æ”¾åœ¨ä¸€ä¸ªå˜é‡ä¸­ï¼Œæ‰€æœ‰çš„æ’åå€¼æ”¾åœ¨å¦ä¸€ä¸ªå˜é‡ä¸­ï¼Œè¿™ä¸ºæˆ‘ä»¬å¯è§†åŒ–æ­Œæ›²æ’åéšæ—¶é—´å˜åŒ–çš„æƒ…å†µåˆ›é€ äº†è‰¯å¥½æ¡ä»¶ã€‚ ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼Œç»“æœè§ FigureÂ 5.2ã€‚ æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¾ˆå°‘æœ‰æ­Œæ›²èƒ½åœç•™åœ¨å‰ 100 åè¶…è¿‡ 20 å‘¨ã€‚\n\nbillboard_longer |&gt; \n  ggplot(aes(x = week, y = rank, group = track)) + \n  geom_line(alpha = 0.25) + \n  scale_y_reverse()\n\n\n\n\n\n\nFigureÂ 5.2: A line plot showing how the rank of a song changes over time.\n\n\n\n\n\n5.3.2 How does pivoting work?\nNow that youâ€™ve seen how we can use pivoting to reshape our data, letâ€™s take a little time to gain some intuition about what pivoting does to the data. Letâ€™s start with a very simple dataset to make it easier to see whatâ€™s happening. Suppose we have three patients with ids A, B, and C, and we take two blood pressure measurements on each patient. Weâ€™ll create the data with tribble(), a handy function for constructing small tibbles by hand:\næ—¢ç„¶ä½ å·²ç»çœ‹åˆ°äº†å¦‚ä½•ä½¿ç”¨é€è§†æ¥é‡å¡‘æ•°æ®ï¼Œè®©æˆ‘ä»¬èŠ±ç‚¹æ—¶é—´æ¥ç›´è§‚åœ°äº†è§£ä¸€ä¸‹é€è§†å¯¹æ•°æ®çš„ä½œç”¨ã€‚ è®©æˆ‘ä»¬ä»ä¸€ä¸ªéå¸¸ç®€å•çš„æ•°æ®é›†å¼€å§‹ï¼Œä»¥ä¾¿æ›´å®¹æ˜“åœ°çœ‹æ¸…å‘ç”Ÿäº†ä»€ä¹ˆã€‚ å‡è®¾æˆ‘ä»¬æœ‰ä¸‰ä¸ªç—…äººï¼Œä»–ä»¬çš„ id åˆ†åˆ«æ˜¯ Aã€B å’Œ Cï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªç—…äººè¿›è¡Œäº†ä¸¤æ¬¡è¡€å‹æµ‹é‡ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ tribble() åˆ›å»ºæ•°æ®ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–¹ä¾¿æ‰‹åŠ¨æ„å»ºå°å‹ tibble çš„å‡½æ•°ï¼š\n\ndf &lt;- tribble(\n  ~id,  ~bp1, ~bp2,\n   \"A\",  100,  120,\n   \"B\",  140,  115,\n   \"C\",  120,  125\n)\n\nWe want our new dataset to have three variables: id (already exists), measurement (the column names), and value (the cell values). To achieve this, we need to pivot df longer:\næˆ‘ä»¬å¸Œæœ›æ–°æ•°æ®é›†æœ‰ä¸‰ä¸ªå˜é‡ï¼šidï¼ˆå·²å­˜åœ¨ï¼‰ã€measurementï¼ˆåˆ—åï¼‰å’Œ valueï¼ˆå•å…ƒæ ¼å€¼ï¼‰ã€‚ ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦å°† df é€è§†å¾—æ›´é•¿ï¼š\n\ndf |&gt; \n  pivot_longer(\n    cols = bp1:bp2,\n    names_to = \"measurement\",\n    values_to = \"value\"\n  )\n#&gt; # A tibble: 6 Ã— 3\n#&gt;   id    measurement value\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 A     bp1           100\n#&gt; 2 A     bp2           120\n#&gt; 3 B     bp1           140\n#&gt; 4 B     bp2           115\n#&gt; 5 C     bp1           120\n#&gt; 6 C     bp2           125\n\nHow does the reshaping work? Itâ€™s easier to see if we think about it column by column. As shown in FigureÂ 5.3, the values in a column that was already a variable in the original dataset (id) need to be repeated, once for each column that is pivoted.\né‡å¡‘æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ å¦‚æœæˆ‘ä»¬é€åˆ—æ€è€ƒï¼Œä¼šæ›´å®¹æ˜“ç†è§£ã€‚ å¦‚ FigureÂ 5.3 æ‰€ç¤ºï¼ŒåŸå§‹æ•°æ®é›†ä¸­å·²ç»æ˜¯å˜é‡çš„åˆ—ï¼ˆidï¼‰ä¸­çš„å€¼éœ€è¦é‡å¤ï¼Œæ¯ä¸ªè¢«é€è§†çš„åˆ—é‡å¤ä¸€æ¬¡ã€‚\n\n\n\n\n\n\n\nFigureÂ 5.3: Columns that are already variables need to be repeated, once for each column that is pivoted.\n\n\n\n\nThe column names become values in a new variable, whose name is defined by names_to, as shown in FigureÂ 5.4. They need to be repeated once for each row in the original dataset.\nåˆ—åæˆä¸ºä¸€ä¸ªæ–°å˜é‡ä¸­çš„å€¼ï¼Œè¯¥æ–°å˜é‡çš„åç§°ç”± names_to å®šä¹‰ï¼Œå¦‚ FigureÂ 5.4 æ‰€ç¤ºã€‚ å®ƒä»¬éœ€è¦ä¸ºåŸå§‹æ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œé‡å¤ä¸€æ¬¡ã€‚\n\n\n\n\n\n\n\nFigureÂ 5.4: The column names of pivoted columns become values in a new column. The values need to be repeated once for each row of the original dataset.\n\n\n\n\nThe cell values also become values in a new variable, with a name defined by values_to. They are unwound row by row. FigureÂ 5.5 illustrates the process.\nå•å…ƒæ ¼çš„å€¼ä¹Ÿæˆä¸ºä¸€ä¸ªæ–°å˜é‡ä¸­çš„å€¼ï¼Œå…¶åç§°ç”± values_to å®šä¹‰ã€‚ å®ƒä»¬æ˜¯é€è¡Œå±•å¼€çš„ã€‚ FigureÂ 5.5 è¯´æ˜äº†è¿™ä¸ªè¿‡ç¨‹ã€‚\n\n\n\n\n\n\n\nFigureÂ 5.5: The number of values is preserved (not repeated), but unwound row-by-row.\n\n\n\n\n\n5.3.3 Many variables in column names\nA more challenging situation occurs when you have multiple pieces of information crammed into the column names, and you would like to store these in separate new variables. For example, take the who2 dataset, the source of table1 and friends that you saw above:\nä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„æƒ…å†µæ˜¯ï¼Œå½“ä½ æœ‰å¤šæ¡ä¿¡æ¯æŒ¤åœ¨åˆ—åä¸­ï¼Œè€Œä½ å¸Œæœ›å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸åŒçš„æ–°å˜é‡ä¸­æ—¶ã€‚ ä¾‹å¦‚ï¼Œä»¥ who2 æ•°æ®é›†ä¸ºä¾‹ï¼Œè¿™æ˜¯ä½ ä¹‹å‰çœ‹åˆ°çš„ table1 åŠç›¸å…³è¡¨æ ¼çš„æ¥æºï¼š\n\nwho2\n#&gt; # A tibble: 7,240 Ã— 58\n#&gt;   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980       NA        NA        NA        NA        NA\n#&gt; 2 Afghanistan  1981       NA        NA        NA        NA        NA\n#&gt; 3 Afghanistan  1982       NA        NA        NA        NA        NA\n#&gt; 4 Afghanistan  1983       NA        NA        NA        NA        NA\n#&gt; 5 Afghanistan  1984       NA        NA        NA        NA        NA\n#&gt; 6 Afghanistan  1985       NA        NA        NA        NA        NA\n#&gt; # â„¹ 7,234 more rows\n#&gt; # â„¹ 51 more variables: sp_m_5564 &lt;dbl&gt;, sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, â€¦\n\nThis dataset, collected by the World Health Organisation, records information about tuberculosis diagnoses. There are two columns that are already variables and are easy to interpret: country and year. They are followed by 56 columns like sp_m_014, ep_m_4554, and rel_m_3544. If you stare at these columns for long enough, youâ€™ll notice thereâ€™s a pattern. Each column name is made up of three pieces separated by _. The first piece, sp/rel/ep, describes the method used for the diagnosis, the second piece, m/f is the gender (coded as a binary variable in this dataset), and the third piece, 014/1524/2534/3544/4554/5564/65 is the age range (014 represents 0-14, for example).\nè¿™ä¸ªç”±ä¸–ç•Œå«ç”Ÿç»„ç»‡æ”¶é›†çš„æ•°æ®é›†è®°å½•äº†å…³äºç»“æ ¸ç—…è¯Šæ–­çš„ä¿¡æ¯ã€‚ æœ‰ä¸¤åˆ—å·²ç»æ˜¯å˜é‡ä¸”æ˜“äºè§£é‡Šï¼šcountry å’Œ yearã€‚ ç´§éšå…¶åçš„æ˜¯ 56 ä¸ªç±»ä¼¼ sp_m_014ã€ep_m_4554 å’Œ rel_m_3544 çš„åˆ—ã€‚ å¦‚æœä½ ç›¯ç€è¿™äº›åˆ—è¶³å¤Ÿé•¿çš„æ—¶é—´ï¼Œä½ ä¼šæ³¨æ„åˆ°ä¸€ä¸ªæ¨¡å¼ã€‚ æ¯ä¸ªåˆ—åç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼Œç”¨ _ åˆ†éš”ã€‚ ç¬¬ä¸€éƒ¨åˆ† sp/rel/ep æè¿°äº†è¯Šæ–­æ–¹æ³•ï¼Œç¬¬äºŒéƒ¨åˆ† m/f æ˜¯ genderï¼ˆæ€§åˆ«ï¼Œåœ¨æ­¤æ•°æ®é›†ä¸­ç¼–ç ä¸ºäºŒå…ƒå˜é‡ï¼‰ï¼Œç¬¬ä¸‰éƒ¨åˆ† 014/1524/2534/3544/4554/5564/65 æ˜¯ ageï¼ˆå¹´é¾„ï¼‰èŒƒå›´ï¼ˆä¾‹å¦‚ï¼Œ014 ä»£è¡¨ 0-14 å²ï¼‰ã€‚\nSo in this case we have six pieces of information recorded in who2: the country and the year (already columns); the method of diagnosis, the gender category, and the age range category (contained in the other column names); and the count of patients in that category (cell values). To organize these six pieces of information in six separate columns, we use pivot_longer() with a vector of column names for names_to and instructors for splitting the original variable names into pieces for names_sep as well as a column name for values_to:\nå› æ­¤ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åœ¨ who2 ä¸­è®°å½•äº†å…­æ¡ä¿¡æ¯ï¼šå›½å®¶å’Œå¹´ä»½ï¼ˆå·²æ˜¯åˆ—ï¼‰ï¼›è¯Šæ–­æ–¹æ³•ã€æ€§åˆ«ç±»åˆ«å’Œå¹´é¾„èŒƒå›´ç±»åˆ«ï¼ˆåŒ…å«åœ¨å…¶ä»–åˆ—åä¸­ï¼‰ï¼›ä»¥åŠè¯¥ç±»åˆ«ä¸­çš„æ‚£è€…è®¡æ•°ï¼ˆå•å…ƒæ ¼å€¼ï¼‰ã€‚ ä¸ºäº†å°†è¿™å…­æ¡ä¿¡æ¯ç»„ç»‡åœ¨å…­ä¸ªç‹¬ç«‹çš„åˆ—ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ pivot_longer()ï¼Œä¸º names_to æä¾›ä¸€ä¸ªåˆ—åå‘é‡ï¼Œä¸º names_sep æä¾›å°†åŸå§‹å˜é‡åæ‹†åˆ†æˆç‰‡æ®µçš„æŒ‡ä»¤ï¼Œå¹¶ä¸º values_to æä¾›ä¸€ä¸ªåˆ—åï¼š\n\nwho2 |&gt; \n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"), \n    names_sep = \"_\",\n    values_to = \"count\"\n  )\n#&gt; # A tibble: 405,440 Ã— 6\n#&gt;   country      year diagnosis gender age   count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980 sp        m      014      NA\n#&gt; 2 Afghanistan  1980 sp        m      1524     NA\n#&gt; 3 Afghanistan  1980 sp        m      2534     NA\n#&gt; 4 Afghanistan  1980 sp        m      3544     NA\n#&gt; 5 Afghanistan  1980 sp        m      4554     NA\n#&gt; 6 Afghanistan  1980 sp        m      5564     NA\n#&gt; # â„¹ 405,434 more rows\n\nAn alternative to names_sep is names_pattern, which you can use to extract variables from more complicated naming scenarios, once youâ€™ve learned about regular expressions in Chapter 15.names_sep çš„ä¸€ä¸ªæ›¿ä»£æ–¹æ¡ˆæ˜¯ names_patternï¼Œåœ¨ä½ å­¦ä¹ äº† Chapter 15 ä¸­çš„æ­£åˆ™è¡¨è¾¾å¼åï¼Œå¯ä»¥ç”¨å®ƒä»æ›´å¤æ‚çš„å‘½ååœºæ™¯ä¸­æå–å˜é‡ã€‚\nConceptually, this is only a minor variation on the simpler case youâ€™ve already seen. FigureÂ 5.6 shows the basic idea: now, instead of the column names pivoting into a single column, they pivot into multiple columns. You can imagine this happening in two steps (first pivoting and then separating) but under the hood it happens in a single step because thatâ€™s faster.\nä»æ¦‚å¿µä¸Šè®²ï¼Œè¿™åªæ˜¯ä½ å·²ç»çœ‹è¿‡çš„ç®€å•æƒ…å†µçš„ä¸€ä¸ªå¾®å°å˜ä½“ã€‚ FigureÂ 5.6 å±•ç¤ºäº†åŸºæœ¬æ€æƒ³ï¼šç°åœ¨ï¼Œåˆ—åä¸æ˜¯é€è§†åˆ°å•ä¸ªåˆ—ä¸­ï¼Œè€Œæ˜¯é€è§†åˆ°å¤šä¸ªåˆ—ä¸­ã€‚ ä½ å¯ä»¥æƒ³è±¡è¿™åˆ†ä¸¤æ­¥å‘ç”Ÿï¼ˆå…ˆé€è§†å†åˆ†ç¦»ï¼‰ï¼Œä½†åœ¨åº•å±‚å®ƒæ˜¯ä¸€æ­¥å®Œæˆçš„ï¼Œå› ä¸ºè¿™æ ·æ›´å¿«ã€‚\n\n\n\n\n\n\n\nFigureÂ 5.6: Pivoting columns with multiple pieces of information in the names means that each column name now fills in values in multiple output columns.\n\n\n\n\n\n5.3.4 Data and variable names in the column headers\nThe next step up in complexity is when the column names include a mix of variable values and variable names. For example, take the household dataset:\nä¸‹ä¸€ä¸ªå¤æ‚ç¨‹åº¦çš„æå‡æ˜¯å½“åˆ—åä¸­æ··åˆäº†å˜é‡å€¼å’Œå˜é‡åã€‚ ä¾‹å¦‚ï¼Œä»¥ household æ•°æ®é›†ä¸ºä¾‹ï¼š\n\nhousehold\n#&gt; # A tibble: 5 Ã— 5\n#&gt;   family dob_child1 dob_child2 name_child1 name_child2\n#&gt;    &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      \n#&gt; 1      1 1998-11-26 2000-01-29 Susan       Jose       \n#&gt; 2      2 1996-06-22 NA         Mark        &lt;NA&gt;       \n#&gt; 3      3 2002-07-11 2004-04-05 Sam         Seth       \n#&gt; 4      4 2004-10-10 2009-08-27 Craig       Khai       \n#&gt; 5      5 2000-12-05 2005-02-28 Parker      Gracie\n\nThis dataset contains data about five families, with the names and dates of birth of up to two children. The new challenge in this dataset is that the column names contain the names of two variables (dob, name) and the values of another (child, with values 1 or 2). To solve this problem we again need to supply a vector to names_to but this time we use the special \".value\" sentinel; this isnâ€™t the name of a variable but a unique value that tells pivot_longer() to do something different. This overrides the usual values_to argument to use the first component of the pivoted column name as a variable name in the output.\nè¯¥æ•°æ®é›†åŒ…å«äº”ä¸ªå®¶åº­çš„æ•°æ®ï¼Œå…¶ä¸­åŒ…å«æœ€å¤šä¸¤ä¸ªå­©å­çš„å§“åå’Œå‡ºç”Ÿæ—¥æœŸã€‚ è¿™ä¸ªæ•°æ®é›†ä¸­çš„æ–°æŒ‘æˆ˜æ˜¯ï¼Œåˆ—ååŒ…å«äº†ä¸¤ä¸ªå˜é‡çš„åç§°ï¼ˆdobã€nameï¼‰å’Œå¦ä¸€ä¸ªå˜é‡çš„å€¼ï¼ˆchildï¼Œå€¼ä¸º 1 æˆ– 2ï¼‰ã€‚ è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å†æ¬¡éœ€è¦å‘ names_to æä¾›ä¸€ä¸ªå‘é‡ï¼Œä½†è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨ç‰¹æ®Šçš„ \".value\" æ ‡è®°ï¼›è¿™ä¸æ˜¯ä¸€ä¸ªå˜é‡åï¼Œè€Œæ˜¯ä¸€ä¸ªç‰¹æ®Šçš„å€¼ï¼Œå‘Šè¯‰ pivot_longer() åšä¸€äº›ä¸åŒçš„äº‹æƒ…ã€‚ è¿™ä¼šè¦†ç›–é€šå¸¸çš„ values_to å‚æ•°ï¼Œè½¬è€Œä½¿ç”¨è¢«é€è§†åˆ—åçš„ç¬¬ä¸€ä¸ªç»„æˆéƒ¨åˆ†ä½œä¸ºè¾“å‡ºä¸­çš„å˜é‡åã€‚\n\nhousehold |&gt; \n  pivot_longer(\n    cols = !family, \n    names_to = c(\".value\", \"child\"), \n    names_sep = \"_\", \n    values_drop_na = TRUE\n  )\n#&gt; # A tibble: 9 Ã— 4\n#&gt;   family child  dob        name \n#&gt;    &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;\n#&gt; 1      1 child1 1998-11-26 Susan\n#&gt; 2      1 child2 2000-01-29 Jose \n#&gt; 3      2 child1 1996-06-22 Mark \n#&gt; 4      3 child1 2002-07-11 Sam  \n#&gt; 5      3 child2 2004-04-05 Seth \n#&gt; 6      4 child1 2004-10-10 Craig\n#&gt; # â„¹ 3 more rows\n\nWe again use values_drop_na = TRUE, since the shape of the input forces the creation of explicit missing variables (e.g., for families with only one child).\næˆ‘ä»¬å†æ¬¡ä½¿ç”¨ values_drop_na = TRUEï¼Œå› ä¸ºè¾“å…¥çš„å½¢çŠ¶å¼ºåˆ¶åˆ›å»ºäº†æ˜¾å¼çš„ç¼ºå¤±å˜é‡ï¼ˆä¾‹å¦‚ï¼Œå¯¹äºåªæœ‰ä¸€ä¸ªå­©å­çš„å®¶åº­ï¼‰ã€‚\nFigureÂ 5.7 illustrates the basic idea with a simpler example. When you use \".value\" in names_to, the column names in the input contribute to both values and variable names in the output.FigureÂ 5.7 ç”¨ä¸€ä¸ªæ›´ç®€å•çš„ä¾‹å­é˜è¿°äº†åŸºæœ¬æ€æƒ³ã€‚ å½“ä½ åœ¨ names_to ä¸­ä½¿ç”¨ \".value\" æ—¶ï¼Œè¾“å…¥ä¸­çš„åˆ—ååŒæ—¶è´¡çŒ®äºè¾“å‡ºä¸­çš„å€¼å’Œå˜é‡åã€‚\n\n\n\n\n\n\n\nFigureÂ 5.7: Pivoting with names_to = c(\".value\", \"num\") splits the column names into two components: the first part determines the output column name (x or y), and the second part determines the value of the num column.",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#widening-data",
    "href": "data-tidy.html#widening-data",
    "title": "5Â  Data tidying",
    "section": "\n5.4 Widening data",
    "text": "5.4 Widening data\nSo far weâ€™ve used pivot_longer() to solve the common class of problems where values have ended up in column names. Next weâ€™ll pivot (HA HA) to pivot_wider(), which makes datasets wider by increasing columns and reducing rows and helps when one observation is spread across multiple rows. This seems to arise less commonly in the wild, but it does seem to crop up a lot when dealing with governmental data.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»ä½¿ç”¨ pivot_longer() è§£å†³äº†å€¼æœ€ç»ˆå‡ºç°åœ¨åˆ—åä¸­çš„ä¸€ç±»å¸¸è§é—®é¢˜ã€‚ æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è½¬å‘ï¼ˆå“ˆå“ˆï¼Œä¸€è¯­åŒå…³ï¼‰pivot_wider()ï¼Œå®ƒé€šè¿‡å¢åŠ åˆ—æ•°å’Œå‡å°‘è¡Œæ•°ä½¿æ•°æ®é›†å˜å®½ï¼Œå¹¶åœ¨ä¸€ä¸ªè§‚æµ‹åˆ†å¸ƒåœ¨å¤šè¡Œæ—¶æä¾›å¸®åŠ©ã€‚ è¿™ç§æƒ…å†µåœ¨ç°å®ä¸–ç•Œä¸­ä¼¼ä¹ä¸é‚£ä¹ˆå¸¸è§ï¼Œä½†åœ¨å¤„ç†æ”¿åºœæ•°æ®æ—¶å´ç»å¸¸å‡ºç°ã€‚\nWeâ€™ll start by looking at cms_patient_experience, a dataset from the Centers of Medicare and Medicaid services that collects data about patient experiences:\næˆ‘ä»¬å°†ä» cms_patient_experience æ•°æ®é›†å¼€å§‹ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¥è‡ªåŒ»ç–—ä¿é™©å’ŒåŒ»ç–—è¡¥åŠ©æœåŠ¡ä¸­å¿ƒ (Centers of Medicare and Medicaid services) çš„æ•°æ®é›†ï¼Œæ”¶é›†äº†å…³äºæ‚£è€…ä½“éªŒçš„æ•°æ®ï¼š\n\ncms_patient_experience\n#&gt; # A tibble: 500 Ã— 5\n#&gt;   org_pac_id org_nm                     measure_cd   measure_title   prf_rate\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                      &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_1  CAHPS for MIPSâ€¦       63\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_2  CAHPS for MIPSâ€¦       87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_3  CAHPS for MIPSâ€¦       86\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_5  CAHPS for MIPSâ€¦       57\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_8  CAHPS for MIPSâ€¦       85\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_12 CAHPS for MIPSâ€¦       24\n#&gt; # â„¹ 494 more rows\n\nThe core unit being studied is an organization, but each organization is spread across six rows, with one row for each measurement taken in the survey organization. We can see the complete set of values for measure_cd and measure_title by using distinct():\nç ”ç©¶çš„æ ¸å¿ƒå•ä½æ˜¯ä¸€ä¸ªç»„ç»‡ï¼Œä½†æ¯ä¸ªç»„ç»‡çš„æ•°æ®åˆ†å¸ƒåœ¨å…­è¡Œä¸­ï¼Œæ¯ä¸€è¡Œå¯¹åº”äºè¯¥è°ƒæŸ¥ç»„ç»‡è¿›è¡Œçš„ä¸€é¡¹æµ‹é‡ã€‚ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ distinct() æŸ¥çœ‹ measure_cd å’Œ measure_title çš„å®Œæ•´å€¼é›†åˆï¼š\n\ncms_patient_experience |&gt; \n  distinct(measure_cd, measure_title)\n#&gt; # A tibble: 6 Ã— 2\n#&gt;   measure_cd   measure_title                                                 \n#&gt;   &lt;chr&gt;        &lt;chr&gt;                                                         \n#&gt; 1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and Inâ€¦\n#&gt; 2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate            \n#&gt; 3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider              \n#&gt; 4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education            \n#&gt; 5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff        \n#&gt; 6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources\n\nNeither of these columns will make particularly great variable names: measure_cd doesnâ€™t hint at the meaning of the variable and measure_title is a long sentence containing spaces. Weâ€™ll use measure_cd as the source for our new column names for now, but in a real analysis you might want to create your own variable names that are both short and meaningful.\nè¿™ä¸¤åˆ—éƒ½ä¸èƒ½æˆä¸ºç‰¹åˆ«å¥½çš„å˜é‡åï¼šmeasure_cd æ²¡æœ‰æš—ç¤ºå˜é‡çš„å«ä¹‰ï¼Œè€Œ measure_title æ˜¯ä¸€ä¸ªåŒ…å«ç©ºæ ¼çš„é•¿å¥å­ã€‚ æˆ‘ä»¬æš‚æ—¶ä½¿ç”¨ measure_cd ä½œä¸ºæ–°åˆ—åçš„æ¥æºï¼Œä½†åœ¨å®é™…åˆ†æä¸­ï¼Œä½ å¯èƒ½å¸Œæœ›åˆ›å»ºæ—¢ç®€çŸ­åˆæœ‰æ„ä¹‰çš„è‡ªå·±çš„å˜é‡åã€‚\npivot_wider() has the opposite interface to pivot_longer(): instead of choosing new column names, we need to provide the existing columns that define the values (values_from) and the column name (names_from):pivot_wider() çš„æ¥å£ä¸ pivot_longer() ç›¸åï¼šæˆ‘ä»¬ä¸æ˜¯é€‰æ‹©æ–°çš„åˆ—åï¼Œè€Œæ˜¯éœ€è¦æä¾›å®šä¹‰å€¼çš„ç°æœ‰åˆ— (values_from) å’Œå®šä¹‰åˆ—åçš„åˆ— (names_from)ï¼š\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n#&gt; # A tibble: 500 Ã— 9\n#&gt;   org_pac_id org_nm                   measure_title   CAHPS_GRP_1 CAHPS_GRP_2\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                    &lt;chr&gt;                 &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP â€¦ CAHPS for MIPSâ€¦          63          NA\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP â€¦ CAHPS for MIPSâ€¦          NA          87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP â€¦ CAHPS for MIPSâ€¦          NA          NA\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP â€¦ CAHPS for MIPSâ€¦          NA          NA\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP â€¦ CAHPS for MIPSâ€¦          NA          NA\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP â€¦ CAHPS for MIPSâ€¦          NA          NA\n#&gt; # â„¹ 494 more rows\n#&gt; # â„¹ 4 more variables: CAHPS_GRP_3 &lt;dbl&gt;, CAHPS_GRP_5 &lt;dbl&gt;, â€¦\n\nThe output doesnâ€™t look quite right; we still seem to have multiple rows for each organization. Thatâ€™s because, we also need to tell pivot_wider() which column or columns have values that uniquely identify each row; in this case those are the variables starting with \"org\":\nè¾“å‡ºçœ‹èµ·æ¥ä¸å¤ªå¯¹ï¼›æˆ‘ä»¬ä¼¼ä¹æ¯ä¸ªç»„ç»‡ä»ç„¶æœ‰å¤šè¡Œã€‚ è¿™æ˜¯å› ä¸ºï¼Œæˆ‘ä»¬è¿˜éœ€è¦å‘Šè¯‰ pivot_wider() å“ªä¸ªæˆ–å“ªäº›åˆ—çš„å€¼å¯ä»¥å”¯ä¸€æ ‡è¯†æ¯ä¸€è¡Œï¼›åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™äº›æ˜¯ä»¥ \"org\" å¼€å¤´çš„å˜é‡ï¼š\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    id_cols = starts_with(\"org\"),\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n#&gt; # A tibble: 95 Ã— 8\n#&gt;   org_pac_id org_nm           CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAâ€¦          63          87          86          57\n#&gt; 2 0446162697 ASSOCIATION OF â€¦          59          85          83          63\n#&gt; 3 0547164295 BEAVER MEDICAL â€¦          49          NA          75          44\n#&gt; 4 0749333730 CAPE PHYSICIANSâ€¦          67          84          85          65\n#&gt; 5 0840104360 ALLIANCE PHYSICâ€¦          66          87          87          64\n#&gt; 6 0840109864 REX HOSPITAL INC          73          87          84          67\n#&gt; # â„¹ 89 more rows\n#&gt; # â„¹ 2 more variables: CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\nThis gives us the output that weâ€™re looking for.\nè¿™å°±å¾—åˆ°äº†æˆ‘ä»¬æƒ³è¦çš„ç»“æœã€‚\n\n5.4.1 How does pivot_wider() work?\nTo understand how pivot_wider() works, letâ€™s again start with a very simple dataset. This time we have two patients with ids A and B, we have three blood pressure measurements on patient A and two on patient B:\nä¸ºäº†ç†è§£ pivot_wider() çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬å†æ¬¡ä»ä¸€ä¸ªéå¸¸ç®€å•çš„æ•°æ®é›†å¼€å§‹ã€‚ è¿™æ¬¡æˆ‘ä»¬æœ‰ä¸¤ä¸ªç—…äººï¼ŒID åˆ†åˆ«ä¸º A å’Œ Bï¼Œæˆ‘ä»¬å¯¹ç—…äºº A è¿›è¡Œäº†ä¸‰æ¬¡è¡€å‹æµ‹é‡ï¼Œå¯¹ç—…äºº B è¿›è¡Œäº†ä¸¤æ¬¡ï¼š\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"B\",        \"bp1\",    140,\n  \"B\",        \"bp2\",    115, \n  \"A\",        \"bp2\",    120,\n  \"A\",        \"bp3\",    105\n)\n\nWeâ€™ll take the values from the value column and the names from the measurement column:\næˆ‘ä»¬å°†ä» value åˆ—ä¸­è·å–å€¼ï¼Œä» measurement åˆ—ä¸­è·å–åç§°ï¼š\n\ndf |&gt; \n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n#&gt; # A tibble: 2 Ã— 4\n#&gt;   id      bp1   bp2   bp3\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A       100   120   105\n#&gt; 2 B       140   115    NA\n\nTo begin the process pivot_wider() needs to first figure out what will go in the rows and columns. The new column names will be the unique values of measurement.\nè¦å¼€å§‹è¿™ä¸ªè¿‡ç¨‹ï¼Œpivot_wider() é¦–å…ˆéœ€è¦ç¡®å®šè¡Œå’Œåˆ—çš„å†…å®¹ã€‚ æ–°çš„åˆ—åå°†æ˜¯ measurement çš„å”¯ä¸€å€¼ã€‚\n\ndf |&gt; \n  distinct(measurement) |&gt; \n  pull()\n#&gt; [1] \"bp1\" \"bp2\" \"bp3\"\n\nBy default, the rows in the output are determined by all the variables that arenâ€™t going into the new names or values. These are called the id_cols. Here there is only one column, but in general there can be any number.\né»˜è®¤æƒ…å†µä¸‹ï¼Œè¾“å‡ºä¸­çš„è¡Œç”±æ‰€æœ‰ä¸ç”¨äºæ–°åç§°æˆ–å€¼çš„å˜é‡å†³å®šã€‚ è¿™äº›è¢«ç§°ä¸º id_colsã€‚ è¿™é‡Œåªæœ‰ä¸€ä¸ªåˆ—ï¼Œä½†é€šå¸¸å¯ä»¥æœ‰ä»»æ„æ•°é‡çš„åˆ—ã€‚\n\ndf |&gt; \n  select(-measurement, -value) |&gt; \n  distinct()\n#&gt; # A tibble: 2 Ã— 1\n#&gt;   id   \n#&gt;   &lt;chr&gt;\n#&gt; 1 A    \n#&gt; 2 B\n\npivot_wider() then combines these results to generate an empty data frame:\nç„¶åï¼Œpivot_wider() ç»“åˆè¿™äº›ç»“æœç”Ÿæˆä¸€ä¸ªç©ºçš„æ•°æ®æ¡†ï¼š\n\ndf |&gt; \n  select(-measurement, -value) |&gt; \n  distinct() |&gt; \n  mutate(x = NA, y = NA, z = NA)\n#&gt; # A tibble: 2 Ã— 4\n#&gt;   id    x     y     z    \n#&gt;   &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 A     NA    NA    NA   \n#&gt; 2 B     NA    NA    NA\n\nIt then fills in all the missing values using the data in the input. In this case, not every cell in the output has a corresponding value in the input as thereâ€™s no third blood pressure measurement for patient B, so that cell remains missing. Weâ€™ll come back to this idea that pivot_wider() can â€œmakeâ€ missing values in Chapter 18.\nç„¶åï¼Œå®ƒä½¿ç”¨è¾“å…¥ä¸­çš„æ•°æ®å¡«å……æ‰€æœ‰ç¼ºå¤±å€¼ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¾“å‡ºä¸­çš„å¹¶éæ¯ä¸ªå•å…ƒæ ¼åœ¨è¾“å…¥ä¸­éƒ½æœ‰å¯¹åº”çš„å€¼ï¼Œå› ä¸ºç—…äºº B æ²¡æœ‰ç¬¬ä¸‰æ¬¡è¡€å‹æµ‹é‡å€¼ï¼Œæ‰€ä»¥è¯¥å•å…ƒæ ¼ä¿æŒç¼ºå¤±çŠ¶æ€ã€‚ æˆ‘ä»¬å°†åœ¨ Chapter 18 ä¸­å†æ¬¡è®¨è®º pivot_wider() å¯ä»¥â€œåˆ¶é€ â€ç¼ºå¤±å€¼çš„è¿™ä¸ªæ¦‚å¿µã€‚\nYou might also wonder what happens if there are multiple rows in the input that correspond to one cell in the output. The example below has two rows that correspond to id â€œAâ€ and measurement â€œbp1â€:\nä½ å¯èƒ½è¿˜ä¼šæƒ³ï¼Œå¦‚æœè¾“å…¥ä¸­æœ‰å¤šä¸ªè¡Œå¯¹åº”äºè¾“å‡ºä¸­çš„ä¸€ä¸ªå•å…ƒæ ¼ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆã€‚ ä¸‹é¢çš„ä¾‹å­ä¸­æœ‰ä¸¤è¡Œå¯¹åº” id â€œAâ€ å’Œ measurement â€œbp1â€ï¼š\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"A\",        \"bp1\",    102,\n  \"A\",        \"bp2\",    120,\n  \"B\",        \"bp1\",    140, \n  \"B\",        \"bp2\",    115\n)\n\nIf we attempt to pivot this we get an output that contains list-columns, which youâ€™ll learn more about in Chapter 23:\nå¦‚æœæˆ‘ä»¬å°è¯•å¯¹æ­¤è¿›è¡Œé€è§†ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ªåŒ…å«åˆ—è¡¨åˆ—ï¼ˆlist-columnsï¼‰çš„è¾“å‡ºï¼Œä½ å°†åœ¨ Chapter 23 ä¸­å­¦åˆ°æ›´å¤šç›¸å…³å†…å®¹ï¼š\n\ndf |&gt;\n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n#&gt; Warning: Values from `value` are not uniquely identified; output will contain\n#&gt; list-cols.\n#&gt; â€¢ Use `values_fn = list` to suppress this warning.\n#&gt; â€¢ Use `values_fn = {summary_fun}` to summarise duplicates.\n#&gt; â€¢ Use the following dplyr code to identify duplicates.\n#&gt;   {data} |&gt;\n#&gt;   dplyr::summarise(n = dplyr::n(), .by = c(id, measurement)) |&gt;\n#&gt;   dplyr::filter(n &gt; 1L)\n#&gt; # A tibble: 2 Ã— 3\n#&gt;   id    bp1       bp2      \n#&gt;   &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n#&gt; 2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\nSince you donâ€™t know how to work with this sort of data yet, youâ€™ll want to follow the hint in the warning to figure out where the problem is:\nç”±äºä½ è¿˜ä¸çŸ¥é“å¦‚ä½•å¤„ç†è¿™ç±»æ•°æ®ï¼Œä½ å¯èƒ½éœ€è¦éµå¾ªè­¦å‘Šä¸­çš„æç¤ºæ¥æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ï¼š\n\ndf |&gt; \n  group_by(id, measurement) |&gt; \n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   id    measurement     n\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 A     bp1             2\n\nItâ€™s then up to you to figure out whatâ€™s gone wrong with your data and either repair the underlying damage or use your grouping and summarizing skills to ensure that each combination of row and column values only has a single row.\næ¥ä¸‹æ¥å°±ç”±ä½ æ¥æ‰¾å‡ºæ•°æ®ä¸­å‡ºäº†ä»€ä¹ˆé—®é¢˜ï¼Œè¦ä¹ˆä¿®å¤æ½œåœ¨çš„æŸåï¼Œè¦ä¹ˆåˆ©ç”¨ä½ çš„åˆ†ç»„å’Œæ±‡æ€»æŠ€èƒ½ï¼Œç¡®ä¿è¡Œå’Œåˆ—å€¼çš„æ¯ä¸ªç»„åˆåªæœ‰ä¸€ä¸ªå•è¡Œã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#summary",
    "href": "data-tidy.html#summary",
    "title": "5Â  Data tidying",
    "section": "\n5.5 Summary",
    "text": "5.5 Summary\nIn this chapter you learned about tidy data: data that has variables in columns and observations in rows. Tidy data makes working in the tidyverse easier, because itâ€™s a consistent structure understood by most functions, the main challenge is transforming the data from whatever structure you receive it in to a tidy format. To that end, you learned about pivot_longer() and pivot_wider() which allow you to tidy up many untidy datasets. The examples we presented here are a selection of those from vignette(\"pivot\", package = \"tidyr\"), so if you encounter a problem that this chapter doesnâ€™t help you with, that vignette is a good place to try next.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†æ•´æ´æ•°æ®ï¼šå³å˜é‡åœ¨åˆ—ã€è§‚æµ‹åœ¨è¡Œçš„æ•°æ®ã€‚ æ•´æ´æ•°æ®ä½¿å¾—åœ¨ tidyverse ä¸­å·¥ä½œæ›´åŠ å®¹æ˜“ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªè¢«å¤§å¤šæ•°å‡½æ•°æ‰€ç†è§£çš„ä¸€è‡´æ€§ç»“æ„ï¼Œä¸»è¦çš„æŒ‘æˆ˜åœ¨äºå°†ä½ æ”¶åˆ°çš„ä»»ä½•ç»“æ„çš„æ•°æ®è½¬æ¢ä¸ºæ•´æ´æ ¼å¼ã€‚ ä¸ºæ­¤ï¼Œä½ å­¦ä¹ äº† pivot_longer() å’Œ pivot_wider()ï¼Œå®ƒä»¬å¯ä»¥è®©ä½ æ•´ç†è®¸å¤šä¸æ•´æ´çš„æ•°æ®é›†ã€‚ æˆ‘ä»¬åœ¨è¿™é‡Œå±•ç¤ºçš„ä¾‹å­é€‰è‡ª vignette(\"pivot\", package = \"tidyr\")ï¼Œæ‰€ä»¥å¦‚æœä½ é‡åˆ°æœ¬ç« æ— æ³•è§£å†³çš„é—®é¢˜ï¼Œé‚£ç¯‡å°å“æ–‡æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¸‹ä¸€æ­¥å°è¯•ã€‚\nAnother challenge is that, for a given dataset, it can be impossible to label the longer or the wider version as the â€œtidyâ€ one. This is partly a reflection of our definition of tidy data, where we said tidy data has one variable in each column, but we didnâ€™t actually define what a variable is (and itâ€™s surprisingly hard to do so). Itâ€™s totally fine to be pragmatic and to say a variable is whatever makes your analysis easiest. So if youâ€™re stuck figuring out how to do some computation, consider switching up the organisation of your data; donâ€™t be afraid to untidy, transform, and re-tidy as needed!\nå¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ï¼Œå¯¹äºç»™å®šçš„æ•°æ®é›†ï¼Œå¯èƒ½æ— æ³•å°†é•¿æ ¼å¼æˆ–å®½æ ¼å¼ç‰ˆæœ¬æ ‡è®°ä¸ºâ€œæ•´æ´â€çš„ç‰ˆæœ¬ã€‚ è¿™éƒ¨åˆ†åæ˜ äº†æˆ‘ä»¬å¯¹æ•´æ´æ•°æ®çš„å®šä¹‰ï¼Œæˆ‘ä»¬è¯´æ•´æ´æ•°æ®æ¯åˆ—æœ‰ä¸€ä¸ªå˜é‡ï¼Œä½†æˆ‘ä»¬å®é™…ä¸Šæ²¡æœ‰å®šä¹‰ä»€ä¹ˆæ˜¯å˜é‡ï¼ˆè€Œä¸”ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œè¿™å¾ˆéš¾åšåˆ°ï¼‰ã€‚ é‡‡å–åŠ¡å®çš„æ€åº¦æ˜¯å®Œå…¨å¯ä»¥çš„ï¼Œå¯ä»¥è¯´å˜é‡å°±æ˜¯ä»»ä½•ä½¿ä½ çš„åˆ†ææœ€å®¹æ˜“çš„ä¸œè¥¿ã€‚ æ‰€ä»¥ï¼Œå¦‚æœä½ åœ¨è®¡ç®—ä¸Šé‡åˆ°å›°éš¾ï¼Œå¯ä»¥è€ƒè™‘æ”¹å˜æ•°æ®çš„ç»„ç»‡æ–¹å¼ï¼›ä¸è¦å®³æ€•æŒ‰éœ€è¿›è¡Œéæ•´æ´åŒ–ã€è½¬æ¢å’Œé‡æ–°æ•´ç†ï¼\nIf you enjoyed this chapter and want to learn more about the underlying theory, you can learn more about the history and theoretical underpinnings in the Tidy Data paper published in the Journal of Statistical Software.\nå¦‚æœä½ å–œæ¬¢è¿™ä¸€ç« å¹¶æƒ³äº†è§£æ›´å¤šå…³äºå…¶èƒŒåç†è®ºçš„çŸ¥è¯†ï¼Œä½ å¯ä»¥åœ¨å‘è¡¨äºã€Šç»Ÿè®¡è½¯ä»¶æ‚å¿—ã€‹(Journal of Statistical Software) çš„ Tidy Data è®ºæ–‡ä¸­äº†è§£æ›´å¤šå…³äºå…¶å†å²å’Œç†è®ºåŸºç¡€çš„å†…å®¹ã€‚\nNow that youâ€™re writing a substantial amount of R code, itâ€™s time to learn more about organizing your code into files and directories. In the next chapter, youâ€™ll learn all about the advantages of scripts and projects, and some of the many tools that they provide to make your life easier.\nç°åœ¨ä½ å·²ç»ç¼–å†™äº†å¤§é‡çš„ R ä»£ç ï¼Œæ˜¯æ—¶å€™å­¦ä¹ æ›´å¤šå…³äºå°†ä»£ç ç»„ç»‡åˆ°æ–‡ä»¶å’Œç›®å½•ä¸­çš„çŸ¥è¯†äº†ã€‚ åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œä½ å°†å­¦ä¹ è„šæœ¬å’Œé¡¹ç›®çš„æ‰€æœ‰ä¼˜ç‚¹ï¼Œä»¥åŠå®ƒä»¬ä¸ºä½¿ä½ çš„ç”Ÿæ´»æ›´è½»æ¾è€Œæä¾›çš„è®¸å¤šå·¥å…·ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#footnotes",
    "href": "data-tidy.html#footnotes",
    "title": "5Â  Data tidying",
    "section": "",
    "text": "The song will be included as long as it was in the top 100 at some point in 2000, and is tracked for up to 72 weeks after it appears.â†©ï¸\nWeâ€™ll come back to this idea in Chapter 18.â†©ï¸",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html",
    "href": "workflow-scripts.html",
    "title": "6Â  Workflow: scripts and projects",
    "section": "",
    "text": "6.1 Scripts\nThis chapter will introduce you to two essential tools for organizing your code: scripts and projects.\næœ¬ç« å°†å‘ä½ ä»‹ç»ä¸¤ä¸ªç»„ç»‡ä»£ç çš„åŸºæœ¬å·¥å…·ï¼šè„šæœ¬å’Œé¡¹ç›®ã€‚\nSo far, you have used the console to run code. Thatâ€™s a great place to start, but youâ€™ll find it gets cramped pretty quickly as you create more complex ggplot2 graphics and longer dplyr pipelines. To give yourself more room to work, use the script editor. Open it up by clicking the File menu, selecting New File, then R script, or using the keyboard shortcut Cmd/Ctrl + Shift + N. Now youâ€™ll see four panes, as in FigureÂ 6.1. The script editor is a great place to experiment with your code. When you want to change something, you donâ€™t have to re-type the whole thing, you can just edit the script and re-run it. And once you have written code that works and does what you want, you can save it as a script file to easily return to later.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ ä¸€ç›´åœ¨ä½¿ç”¨æ§åˆ¶å° (console) è¿è¡Œä»£ç ã€‚ è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œä½†å½“ä½ åˆ›å»ºæ›´å¤æ‚çš„ ggplot2 å›¾å½¢å’Œæ›´é•¿çš„ dplyr ç®¡é“æ—¶ï¼Œä½ ä¼šå‘ç°å®ƒå¾ˆå¿«å°±ä¼šå˜å¾—æ‹¥æŒ¤ä¸å ªã€‚ ä¸ºäº†ç»™è‡ªå·±æ›´å¤šçš„å·¥ä½œç©ºé—´ï¼Œè¯·ä½¿ç”¨è„šæœ¬ç¼–è¾‘å™¨ã€‚ é€šè¿‡ç‚¹å‡»æ–‡ä»¶èœå•ï¼Œé€‰æ‹©æ–°å»ºæ–‡ä»¶ï¼Œç„¶åé€‰æ‹© R è„šæœ¬æ¥æ‰“å¼€å®ƒï¼Œæˆ–è€…ä½¿ç”¨é”®ç›˜å¿«æ·é”® Cmd/Ctrl + Shift + Nã€‚ ç°åœ¨ä½ ä¼šçœ‹åˆ°å››ä¸ªçª—æ ¼ï¼Œå¦‚ FigureÂ 6.1 æ‰€ç¤ºã€‚ è„šæœ¬ç¼–è¾‘å™¨æ˜¯è¯•éªŒä»£ç çš„ç»ä½³åœºæ‰€ã€‚ å½“ä½ æƒ³æ”¹å˜æŸäº›ä¸œè¥¿æ—¶ï¼Œä½ ä¸å¿…é‡æ–°è¾“å…¥å…¨éƒ¨å†…å®¹ï¼Œåªéœ€ç¼–è¾‘è„šæœ¬å¹¶é‡æ–°è¿è¡Œå³å¯ã€‚ è€Œä¸”ï¼Œä¸€æ—¦ä½ ç¼–å†™äº†èƒ½æ­£å¸¸å·¥ä½œå¹¶å®ç°ä½ æƒ³è¦çš„åŠŸèƒ½çš„ä»£ç ï¼Œä½ å¯ä»¥å°†å…¶ä¿å­˜ä¸ºè„šæœ¬æ–‡ä»¶ï¼Œä»¥ä¾¿æ—¥åè½»æ¾è¿”å›ã€‚\nFigureÂ 6.1: Opening the script editor adds a new pane at the top-left of the IDE.",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Workflow: scripts and projects</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#scripts",
    "href": "workflow-scripts.html#scripts",
    "title": "6Â  Workflow: scripts and projects",
    "section": "",
    "text": "6.1.1 Running code\nThe script editor is an excellent place for building complex ggplot2 plots or long sequences of dplyr manipulations. The key to using the script editor effectively is to memorize one of the most important keyboard shortcuts: Cmd/Ctrl + Enter. This executes the current R expression in the console. For example, take the code below.\nè„šæœ¬ç¼–è¾‘å™¨æ˜¯æ„å»ºå¤æ‚ ggplot2 å›¾æˆ–é•¿åºåˆ— dplyr æ“ä½œçš„ç»ä½³åœºæ‰€ã€‚ æœ‰æ•ˆä½¿ç”¨è„šæœ¬ç¼–è¾‘å™¨çš„å…³é”®æ˜¯è®°ä½ä¸€ä¸ªæœ€é‡è¦çš„é”®ç›˜å¿«æ·é”®ï¼šCmd/Ctrl + Enterã€‚ è¿™ä¼šåœ¨æ§åˆ¶å°ä¸­æ‰§è¡Œå½“å‰çš„ R è¡¨è¾¾å¼ã€‚ ä¾‹å¦‚ï¼Œçœ‹ä¸‹é¢çš„ä»£ç ã€‚\n\nlibrary(dplyr)\nlibrary(nycflights13)\n\nnot_cancelled &lt;- flights |&gt; \n  filter(!is.na(dep_delay)â–ˆ, !is.na(arr_delay))\n\nnot_cancelled |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(mean = mean(dep_delay))\n\nIf your cursor is at â–ˆ, pressing Cmd/Ctrl + Enter will run the complete command that generates not_cancelled. It will also move the cursor to the following statement (beginning with not_cancelled |&gt;). That makes it easy to step through your complete script by repeatedly pressing Cmd/Ctrl + Enter.\nå¦‚æœä½ çš„å…‰æ ‡åœ¨ â–ˆ å¤„ï¼ŒæŒ‰ä¸‹ Cmd/Ctrl + Enter å°†è¿è¡Œç”Ÿæˆ not_cancelled çš„å®Œæ•´å‘½ä»¤ã€‚ å®ƒè¿˜ä¼šå°†å…‰æ ‡ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªè¯­å¥ï¼ˆä»¥ not_cancelled |&gt; å¼€å¤´ï¼‰ã€‚ è¿™æ ·ï¼Œé€šè¿‡é‡å¤æŒ‰ Cmd/Ctrl + Enterï¼Œä½ å°±å¯ä»¥è½»æ¾åœ°é€æ­¥æ‰§è¡Œæ•´ä¸ªè„šæœ¬ã€‚\nInstead of running your code expression-by-expression, you can also execute the complete script in one step with Cmd/Ctrl + Shift + S. Doing this regularly is a great way to ensure that youâ€™ve captured all the important parts of your code in the script.\né™¤äº†é€ä¸ªè¡¨è¾¾å¼è¿è¡Œä»£ç ï¼Œä½ è¿˜å¯ä»¥é€šè¿‡ Cmd/Ctrl + Shift + S ä¸€æ­¥æ‰§è¡Œæ•´ä¸ªè„šæœ¬ã€‚ å®šæœŸè¿™æ ·åšæ˜¯ç¡®ä¿ä½ å·²å°†æ‰€æœ‰é‡è¦ä»£ç éƒ¨åˆ†ä¿å­˜åœ¨è„šæœ¬ä¸­çš„å¥½æ–¹æ³•ã€‚\nWe recommend you always start your script with the packages you need. That way, if you share your code with others, they can easily see which packages they need to install. Note, however, that you should never include install.packages() in a script you share. Itâ€™s inconsiderate to hand off a script that will change something on their computer if theyâ€™re not being careful!\næˆ‘ä»¬å»ºè®®ä½ å§‹ç»ˆåœ¨è„šæœ¬çš„å¼€å¤´å£°æ˜æ‰€éœ€çš„åŒ…ã€‚ è¿™æ ·ï¼Œå¦‚æœä½ ä¸ä»–äººå…±äº«ä»£ç ï¼Œä»–ä»¬å¯ä»¥è½»æ¾çœ‹åˆ°éœ€è¦å®‰è£…å“ªäº›åŒ…ã€‚ ä½†æ˜¯è¯·æ³¨æ„ï¼Œä½ æ°¸è¿œä¸åº”è¯¥åœ¨ä½ åˆ†äº«çš„è„šæœ¬ä¸­åŒ…å« install.packages()ã€‚ å¦‚æœåˆ«äººä¸å°å¿ƒï¼Œä½ çš„è„šæœ¬å¯èƒ½ä¼šåœ¨ä»–ä»¬çš„è®¡ç®—æœºä¸Šåšå‡ºæ›´æ”¹ï¼Œé€’äº¤è¿™æ ·çš„è„šæœ¬æ˜¯ä¸ä½“è´´çš„è¡Œä¸ºï¼\nWhen working through future chapters, we highly recommend starting in the script editor and practicing your keyboard shortcuts. Over time, sending code to the console in this way will become so natural that you wonâ€™t even think about it.\nåœ¨å­¦ä¹ åç»­ç« èŠ‚æ—¶ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ ä»è„šæœ¬ç¼–è¾‘å™¨å¼€å§‹ï¼Œå¹¶ç»ƒä¹ ä½ çš„é”®ç›˜å¿«æ·é”®ã€‚ éšç€æ—¶é—´çš„æ¨ç§»ï¼Œä»¥è¿™ç§æ–¹å¼å‘æ§åˆ¶å°å‘é€ä»£ç å°†å˜å¾—å¦‚æ­¤è‡ªç„¶ï¼Œä»¥è‡³äºä½ ç”šè‡³ä¸ä¼šå»æƒ³å®ƒã€‚\n\n6.1.2 RStudio diagnostics\nIn the script editor, RStudio will highlight syntax errors with a red squiggly line and a cross in the sidebar:\nåœ¨è„šæœ¬ç¼–è¾‘å™¨ä¸­ï¼ŒRStudio ä¼šç”¨çº¢è‰²æ³¢æµªçº¿å’Œä¾§è¾¹æ ä¸­çš„å‰å·æ¥é«˜äº®æ˜¾ç¤ºè¯­æ³•é”™è¯¯ï¼š\n\n\n\n\n\n\n\n\nHover over the cross to see what the problem is:\nå°†é¼ æ ‡æ‚¬åœåœ¨å‰å·ä¸ŠæŸ¥çœ‹é—®é¢˜æ‰€åœ¨ï¼š\n\n\n\n\n\n\n\n\nRStudio will also let you know about potential problems:\nRStudio ä¹Ÿä¼šè®©ä½ çŸ¥é“æ½œåœ¨çš„é—®é¢˜ï¼š\n\n\n\n\n\n\n\n\n\n6.1.3 Saving and naming\nRStudio automatically saves the contents of the script editor when you quit, and automatically reloads it when you re-open. Nevertheless, itâ€™s a good idea to avoid Untitled1, Untitled2, Untitled3, and so on and instead save your scripts and to give them informative names.\nå½“ä½ é€€å‡º RStudio æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨ä¿å­˜è„šæœ¬ç¼–è¾‘å™¨çš„å†…å®¹ï¼Œå¹¶åœ¨ä½ é‡æ–°æ‰“å¼€æ—¶è‡ªåŠ¨é‡æ–°åŠ è½½ã€‚ å°½ç®¡å¦‚æ­¤ï¼Œæœ€å¥½è¿˜æ˜¯é¿å…ä½¿ç”¨ Untitled1ã€Untitled2ã€Untitled3 ç­‰åç§°ï¼Œè€Œæ˜¯ä¿å­˜ä½ çš„è„šæœ¬å¹¶ç»™å®ƒä»¬èµ·ä¸€äº›ä¿¡æ¯ä¸°å¯Œçš„åå­—ã€‚\nIt might be tempting to name your files code.R or myscript.R, but you should think a bit harder before choosing a name for your file. Three important principles for file naming are as follows:\nä½ å¯èƒ½ä¼šæƒ³æŠŠä½ çš„æ–‡ä»¶å‘½åä¸º code.R æˆ– myscript.Rï¼Œä½†åœ¨é€‰æ‹©æ–‡ä»¶åä¹‹å‰ï¼Œä½ åº”è¯¥å†å¤šæƒ³ä¸€æƒ³ã€‚ æ–‡ä»¶å‘½åçš„ä¸‰ä¸ªé‡è¦åŸåˆ™å¦‚ä¸‹ï¼š\n\nFile names should be machine readable: avoid spaces, symbols, and special characters. Donâ€™t rely on case sensitivity to distinguish files.\næ–‡ä»¶ååº”ä¾¿äºæœºå™¨è¯»å–ï¼šé¿å…ä½¿ç”¨ç©ºæ ¼ã€ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦ã€‚ä¸è¦ä¾èµ–å¤§å°å†™åŒºåˆ†æ–‡ä»¶ã€‚\nFile names should be human readable: use file names to describe whatâ€™s in the file.\næ–‡ä»¶ååº”ä¾¿äºäººç±»é˜…è¯»ï¼šç”¨æ–‡ä»¶åæè¿°æ–‡ä»¶å†…å®¹ã€‚\nFile names should play well with default ordering: start file names with numbers so that alphabetical sorting puts them in the order they get used.\næ–‡ä»¶ååº”ä¾¿äºé»˜è®¤æ’åºï¼šç”¨æ•°å­—å¼€å¤´ï¼Œè¿™æ ·æŒ‰å­—æ¯æ’åºæ—¶æ–‡ä»¶ä¼šæŒ‰ä½¿ç”¨é¡ºåºæ’åˆ—ã€‚\n\nFor example, suppose you have the following files in a project folder.\nä¾‹å¦‚ï¼Œå‡è®¾ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹ä¸­æœ‰ä»¥ä¸‹æ–‡ä»¶ã€‚\nalternative model.R\ncode for exploratory analysis.r\nfinalreport.qmd\nFinalReport.qmd\nfig 1.png\nFigure_02.png\nmodel_first_try.R\nrun-first.r\ntemp.txt\nThere are a variety of problems here: itâ€™s hard to find which file to run first, file names contain spaces, there are two files with the same name but different capitalization (finalreport vs.Â FinalReport1), and some names donâ€™t describe their contents (run-first and temp).\nè¿™é‡Œå­˜åœ¨å„ç§é—®é¢˜ï¼šå¾ˆéš¾æ‰¾åˆ°é¦–å…ˆè¦è¿è¡Œå“ªä¸ªæ–‡ä»¶ï¼Œæ–‡ä»¶ååŒ…å«ç©ºæ ¼ï¼Œæœ‰ä¸¤ä¸ªåç§°ç›¸åŒä½†å¤§å°å†™ä¸åŒçš„æ–‡ä»¶ï¼ˆfinalreport vs.Â FinalReport1ï¼‰ï¼Œè€Œä¸”æœ‰äº›åç§°æ²¡æœ‰æè¿°å…¶å†…å®¹ï¼ˆrun-first å’Œ tempï¼‰ã€‚\nHereâ€™s a better way of naming and organizing the same set of files:\nè¿™é‡Œæœ‰ä¸€ç§æ›´å¥½çš„å‘½åå’Œç»„ç»‡åŒä¸€ç»„æ–‡ä»¶çš„æ–¹å¼ï¼š\n01-load-data.R\n02-exploratory-analysis.R\n03-model-approach-1.R\n04-model-approach-2.R\nfig-01.png\nfig-02.png\nreport-2022-03-20.qmd\nreport-2022-04-02.qmd\nreport-draft-notes.txt\nNumbering the key scripts makes it obvious in which order to run them and a consistent naming scheme makes it easier to see what varies. Additionally, the figures are labelled similarly, the reports are distinguished by dates included in the file names, and temp is renamed to report-draft-notes to better describe its contents. If you have a lot of files in a directory, taking organization one step further and placing different types of files (scripts, figures, etc.) in different directories is recommended.\nå¯¹å…³é”®è„šæœ¬è¿›è¡Œç¼–å·å¯ä»¥æ¸…æ¥šåœ°è¡¨æ˜è¿è¡Œå®ƒä»¬çš„é¡ºåºï¼Œè€Œä¸€è‡´çš„å‘½åæ–¹æ¡ˆä¹Ÿæ›´å®¹æ˜“çœ‹å‡ºä¸åŒä¹‹å¤„ã€‚ æ­¤å¤–ï¼Œå›¾å½¢çš„æ ‡ç­¾ä¹Ÿç±»ä¼¼ï¼ŒæŠ¥å‘Šé€šè¿‡æ–‡ä»¶åä¸­åŒ…å«çš„æ—¥æœŸæ¥åŒºåˆ†ï¼Œtemp è¢«é‡å‘½åä¸º report-draft-notes ä»¥æ›´å¥½åœ°æè¿°å…¶å†…å®¹ã€‚ å¦‚æœä¸€ä¸ªç›®å½•ä¸­æœ‰å¾ˆå¤šæ–‡ä»¶ï¼Œå»ºè®®å°†ç»„ç»‡å·¥ä½œæ›´è¿›ä¸€æ­¥ï¼Œå°†ä¸åŒç±»å‹çš„æ–‡ä»¶ï¼ˆè„šæœ¬ã€å›¾å½¢ç­‰ï¼‰æ”¾åœ¨ä¸åŒçš„ç›®å½•ä¸­ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Workflow: scripts and projects</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#projects",
    "href": "workflow-scripts.html#projects",
    "title": "6Â  Workflow: scripts and projects",
    "section": "\n6.2 Projects",
    "text": "6.2 Projects\nOne day, you will need to quit R, go do something else, and return to your analysis later. One day, you will be working on multiple analyses simultaneously and you want to keep them separate. One day, you will need to bring data from the outside world into R and send numerical results and figures from R back out into the world.\næ€»æœ‰ä¸€å¤©ï¼Œä½ éœ€è¦é€€å‡º Rï¼Œå»åšåˆ«çš„äº‹æƒ…ï¼Œç„¶åå†å›åˆ°ä½ çš„åˆ†æä¸­ã€‚ æ€»æœ‰ä¸€å¤©ï¼Œä½ ä¼šåŒæ—¶è¿›è¡Œå¤šä¸ªåˆ†æï¼Œå¹¶ä¸”ä½ å¸Œæœ›å°†å®ƒä»¬åˆ†å¼€ã€‚ æ€»æœ‰ä¸€å¤©ï¼Œä½ éœ€è¦å°†å¤–éƒ¨ä¸–ç•Œçš„æ•°æ®å¯¼å…¥ Rï¼Œå¹¶å°†æ•°å€¼ç»“æœå’Œå›¾è¡¨ä» R å¯¼å‡ºåˆ°å¤–éƒ¨ä¸–ç•Œã€‚\nTo handle these real life situations, you need to make two decisions:\nä¸ºäº†å¤„ç†è¿™äº›ç°å®ç”Ÿæ´»ä¸­çš„æƒ…å†µï¼Œä½ éœ€è¦åšå‡ºä¸¤ä¸ªå†³å®šï¼š\n\nWhat is the source of truth? What will you save as your lasting record of what happened?\näº‹å®æ¥æºæ˜¯ä»€ä¹ˆï¼Ÿ ä½ ä¼šä¿å­˜ä»€ä¹ˆä½œä¸ºä½ æ‰€åšäº‹æƒ…çš„æ°¸ä¹…è®°å½•ï¼Ÿ\nWhere does your analysis live?\nä½ çš„åˆ†æå­˜æ”¾åœ¨å“ªé‡Œï¼Ÿ\n\n\n6.2.1 What is the source of truth?\nAs a beginner, itâ€™s okay to rely on your current Environment to contain all the objects you have created throughout your analysis. However, to make it easier to work on larger projects or collaborate with others, your source of truth should be the R scripts. With your R scripts (and your data files), you can recreate the environment. With only your environment, itâ€™s much harder to recreate your R scripts: youâ€™ll either have to retype a lot of code from memory (inevitably making mistakes along the way) or youâ€™ll have to carefully mine your R history.\nä½œä¸ºåˆå­¦è€…ï¼Œä¾èµ–ä½ å½“å‰çš„ç¯å¢ƒ (Environment) æ¥åŒ…å«ä½ åœ¨æ•´ä¸ªåˆ†æè¿‡ç¨‹ä¸­åˆ›å»ºçš„æ‰€æœ‰å¯¹è±¡æ˜¯å¯ä»¥çš„ã€‚ ç„¶è€Œï¼Œä¸ºäº†æ›´å®¹æ˜“åœ°å¤„ç†å¤§å‹é¡¹ç›®æˆ–ä¸ä»–äººåä½œï¼Œä½ çš„äº‹å®æ¥æºåº”è¯¥æ˜¯ R è„šæœ¬ã€‚ æœ‰äº†ä½ çš„ R è„šæœ¬ï¼ˆå’Œä½ çš„æ•°æ®æ–‡ä»¶ï¼‰ï¼Œä½ å°±å¯ä»¥é‡ç°ç¯å¢ƒã€‚ å¦‚æœåªæœ‰ä½ çš„ç¯å¢ƒï¼Œè¦é‡ç°ä½ çš„ R è„šæœ¬å°±å›°éš¾å¾—å¤šï¼šä½ è¦ä¹ˆå¿…é¡»å‡­è®°å¿†é‡æ–°è¾“å…¥å¤§é‡ä»£ç ï¼ˆè¿™ä¸å¯é¿å…åœ°ä¼šå‡ºé”™ï¼‰ï¼Œè¦ä¹ˆå°±å¾—ä»”ç»†æŒ–æ˜ä½ çš„ R å†å²è®°å½•ã€‚\nTo help keep your R scripts as the source of truth for your analysis, we highly recommend that you instruct RStudio not to preserve your workspace between sessions. You can do this either by running usethis::use_blank_slate()2 or by mimicking the options shown in FigureÂ 6.2. This will cause you some short-term pain, because now when you restart RStudio, it will no longer remember the code that you ran last time nor will the objects you created or the datasets you read be available to use. But this short-term pain saves you long-term agony because it forces you to capture all important procedures in your code. Thereâ€™s nothing worse than discovering three months after the fact that youâ€™ve only stored the results of an important calculation in your environment, not the calculation itself in your code.\nä¸ºäº†å¸®åŠ©ä¿æŒä½ çš„ R è„šæœ¬ä½œä¸ºä½ åˆ†æçš„äº‹å®æ¥æºï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ æŒ‡ç¤º RStudio åœ¨ä¼šè¯ä¹‹é—´ä¸è¦ä¿å­˜ä½ çš„å·¥ä½œåŒºã€‚ ä½ å¯ä»¥é€šè¿‡è¿è¡Œ usethis::use_blank_slate()1 æˆ–æ¨¡ä»¿ FigureÂ 6.2 ä¸­æ˜¾ç¤ºçš„é€‰é¡¹æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚è¿™ä¼šç»™ä½ å¸¦æ¥ä¸€äº›çŸ­æœŸçš„ç—›è‹¦ï¼Œå› ä¸ºç°åœ¨å½“ä½ é‡æ–°å¯åŠ¨ RStudio æ—¶ï¼Œå®ƒå°†ä¸å†è®°å¾—ä½ ä¸Šæ¬¡è¿è¡Œçš„ä»£ç ï¼Œä½ åˆ›å»ºçš„å¯¹è±¡æˆ–è¯»å–çš„æ•°æ®é›†ä¹Ÿæ— æ³•ä½¿ç”¨ã€‚ ä½†è¿™ç§çŸ­æœŸçš„ç—›è‹¦å¯ä»¥ä¸ºä½ çœå»é•¿æœŸçš„æŠ˜ç£¨ï¼Œå› ä¸ºå®ƒè¿«ä½¿ä½ å°†æ‰€æœ‰é‡è¦çš„è¿‡ç¨‹éƒ½è®°å½•åœ¨ä½ çš„ä»£ç ä¸­ã€‚ æ²¡æœ‰ä»€ä¹ˆæ¯”åœ¨ä¸‰ä¸ªæœˆåå‘ç°ä½ åªåœ¨ç¯å¢ƒä¸­å­˜å‚¨äº†é‡è¦è®¡ç®—çš„ç»“æœï¼Œè€Œæ²¡æœ‰åœ¨ä»£ç ä¸­å­˜å‚¨è®¡ç®—æœ¬èº«æ›´ç³Ÿç³•çš„äº†ã€‚\n\n\n\n\n\n\n\nFigureÂ 6.2: Copy these options in your RStudio options to always start your RStudio session with a clean slate.\n\n\n\n\nThere is a great pair of keyboard shortcuts that will work together to make sure youâ€™ve captured the important parts of your code in the editor:\næœ‰ä¸€å¯¹å¾ˆæ£’çš„é”®ç›˜å¿«æ·é”®å¯ä»¥ååŒå·¥ä½œï¼Œç¡®ä¿ä½ å·²ç»å°†ä»£ç çš„é‡è¦éƒ¨åˆ†ä¿å­˜åœ¨ç¼–è¾‘å™¨ä¸­ï¼š\n\nPress Cmd/Ctrl + Shift + 0/F10 to restart R.\næŒ‰ä¸‹ Cmd/Ctrl + Shift + 0/F10 é‡å¯ Rã€‚\nPress Cmd/Ctrl + Shift + S to re-run the current script.\næŒ‰ä¸‹ Cmd/Ctrl + Shift + S é‡æ–°è¿è¡Œå½“å‰è„šæœ¬ã€‚\n\nWe collectively use this pattern hundreds of times a week.\næˆ‘ä»¬æ¯å‘¨ä¼šé›†ä½“ä½¿ç”¨è¿™ä¸ªæ¨¡å¼æ•°ç™¾æ¬¡ã€‚\nAlternatively, if you donâ€™t use keyboard shortcuts, you can go to Session &gt; Restart R and then highlight and re-run your current script.\næˆ–è€…ï¼Œå¦‚æœä½ ä¸ä½¿ç”¨é”®ç›˜å¿«æ·é”®ï¼Œä½ å¯ä»¥è½¬åˆ° Session &gt; Restart Rï¼Œç„¶åé«˜äº®å¹¶é‡æ–°è¿è¡Œä½ å½“å‰çš„è„šæœ¬ã€‚\n\n\n\n\n\n\nRStudio server\n\n\n\nIf youâ€™re using RStudio server, your R session is never restarted by default. When you close your RStudio server tab, it might feel like youâ€™re closing R, but the server actually keeps it running in the background. The next time you return, youâ€™ll be in exactly the same place you left. This makes it even more important to regularly restart R so that youâ€™re starting with a clean slate.\nå¦‚æœä½ æ­£åœ¨ä½¿ç”¨ RStudio æœåŠ¡å™¨ï¼Œä½ çš„ R ä¼šè¯é»˜è®¤æƒ…å†µä¸‹æ°¸è¿œä¸ä¼šé‡å¯ã€‚ å½“ä½ å…³é—­ RStudio æœåŠ¡å™¨çš„æ ‡ç­¾é¡µæ—¶ï¼Œå¯èƒ½æ„Ÿè§‰åƒæ˜¯å…³é—­äº† Rï¼Œä½†æœåŠ¡å™¨å®é™…ä¸Šåœ¨åå°ä¿æŒå®ƒè¿è¡Œã€‚ ä¸‹æ¬¡ä½ å›æ¥æ—¶ï¼Œä½ å°†æ­£å¥½åœ¨ä½ ç¦»å¼€çš„åœ°æ–¹ã€‚ è¿™ä½¿å¾—å®šæœŸé‡å¯ R ä»¥ä¾¿ä»ä¸€ä¸ªå¹²å‡€çš„çŠ¶æ€å¼€å§‹å˜å¾—æ›´åŠ é‡è¦ã€‚\n\n\n\n6.2.2 Where does your analysis live?\nR has a powerful notion of the working directory. This is where R looks for files that you ask it to load, and where it will put any files that you ask it to save. RStudio shows your current working directory at the top of the console:\nR æœ‰ä¸€ä¸ªå¼ºå¤§çš„æ¦‚å¿µï¼Œå«åšå·¥ä½œç›®å½• (working directory)ã€‚ è¿™æ˜¯ R å¯»æ‰¾ä½ è¦æ±‚å®ƒåŠ è½½çš„æ–‡ä»¶çš„ä½ç½®ï¼Œä¹Ÿæ˜¯å®ƒå­˜æ”¾ä½ è¦æ±‚å®ƒä¿å­˜çš„ä»»ä½•æ–‡ä»¶çš„ä½ç½®ã€‚ RStudio åœ¨æ§åˆ¶å°çš„é¡¶éƒ¨æ˜¾ç¤ºä½ å½“å‰çš„å·¥ä½œç›®å½•ï¼š\n\n\n\n\n\n\n\n\nAnd you can print this out in R code by running getwd():\nä½ ä¹Ÿå¯ä»¥åœ¨ R ä»£ç ä¸­é€šè¿‡è¿è¡Œ getwd() æ¥æ‰“å°å‡ºè¿™ä¸ªè·¯å¾„ï¼š\n\ngetwd()\n#&gt; [1] \"/Users/hadley/Documents/r4ds\"\n\nIn this R session, the current working directory (think of it as â€œhomeâ€) is in hadleyâ€™s Documents folder, in a subfolder called r4ds. This code will return a different result when you run it, because your computer has a different directory structure than Hadleyâ€™s!\nåœ¨è¿™ä¸ª R ä¼šè¯ä¸­ï¼Œå½“å‰çš„å·¥ä½œç›®å½•ï¼ˆå¯ä»¥æŠŠå®ƒæƒ³è±¡æˆâ€œå®¶â€ï¼‰åœ¨ hadley çš„ Documents æ–‡ä»¶å¤¹ä¸‹çš„ä¸€ä¸ªåä¸º r4ds çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚ å½“ä½ è¿è¡Œè¿™æ®µä»£ç æ—¶ï¼Œä¼šè¿”å›ä¸€ä¸ªä¸åŒçš„ç»“æœï¼Œå› ä¸ºä½ çš„è®¡ç®—æœºç›®å½•ç»“æ„ä¸ Hadley çš„ä¸åŒï¼\nAs a beginning R user, itâ€™s OK to let your working directory be your home directory, documents directory, or any other weird directory on your computer. But youâ€™re more than a handful of chapters into this book, and youâ€™re no longer a beginner. Very soon now you should evolve to organizing your projects into directories and, when working on a project, set Râ€™s working directory to the associated directory.\nä½œä¸º R çš„åˆå­¦è€…ï¼Œè®©ä½ çš„å·¥ä½œç›®å½•æ˜¯ä½ çš„ä¸»ç›®å½•ã€æ–‡æ¡£ç›®å½•æˆ–ä½ ç”µè„‘ä¸Šçš„ä»»ä½•å…¶ä»–å¥‡æ€ªç›®å½•éƒ½æ˜¯å¯ä»¥çš„ã€‚ ä½†ä½ å·²ç»è¯»äº†è¿™æœ¬ä¹¦å¥½å‡ ç« äº†ï¼Œä½ ä¸å†æ˜¯åˆå­¦è€…äº†ã€‚ å¾ˆå¿«ä½ å°±åº”è¯¥è¿›åŒ–åˆ°å°†ä½ çš„é¡¹ç›®ç»„ç»‡åˆ°ç›®å½•ä¸­ï¼Œå¹¶ä¸”åœ¨å¤„ç†ä¸€ä¸ªé¡¹ç›®æ—¶ï¼Œå°† R çš„å·¥ä½œç›®å½•è®¾ç½®ä¸ºç›¸å…³çš„ç›®å½•ã€‚\nYou can set the working directory from within R but we do not recommend it:\nä½ å¯ä»¥åœ¨ R å†…éƒ¨è®¾ç½®å·¥ä½œç›®å½•ï¼Œä½†æˆ‘ä»¬ä¸æ¨èè¿™æ ·åšï¼š\n\nsetwd(\"/path/to/my/CoolProject\")\n\nThereâ€™s a better way; a way that also puts you on the path to managing your R work like an expert. That way is the RStudio project.\næœ‰æ›´å¥½çš„æ–¹æ³•ï¼›ä¸€ç§èƒ½è®©ä½ åƒä¸“å®¶ä¸€æ ·ç®¡ç†ä½ çš„ R å·¥ä½œçš„é€”å¾„ã€‚ é‚£å°±æ˜¯ RStudio é¡¹ç›® (project)ã€‚\n\n6.2.3 RStudio projects\nKeeping all the files associated with a given project (input data, R scripts, analytical results, and figures) together in one directory is such a wise and common practice that RStudio has built-in support for this via projects. Letâ€™s make a project for you to use while youâ€™re working through the rest of this book. Click File &gt; New Project, then follow the steps shown in FigureÂ 6.3.\nå°†ä¸ç‰¹å®šé¡¹ç›®ç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆè¾“å…¥æ•°æ®ã€R è„šæœ¬ã€åˆ†æç»“æœå’Œå›¾è¡¨ï¼‰éƒ½æ”¾åœ¨ä¸€ä¸ªç›®å½•ä¸­æ˜¯ä¸€ç§éå¸¸æ˜æ™ºå’Œæ™®éçš„åšæ³•ï¼ŒRStudio é€šè¿‡é¡¹ç›®ä¸ºè¿™ç§åšæ³•æä¾›äº†å†…ç½®æ”¯æŒã€‚ è®©æˆ‘ä»¬ä¸ºä½ åˆ›å»ºä¸€ä¸ªé¡¹ç›®ï¼Œä»¥ä¾¿ä½ åœ¨å­¦ä¹ æœ¬ä¹¦å…¶ä½™éƒ¨åˆ†æ—¶ä½¿ç”¨ã€‚ ç‚¹å‡» File &gt; New Projectï¼Œç„¶åæŒ‰ç…§ FigureÂ 6.3 ä¸­æ˜¾ç¤ºçš„æ­¥éª¤æ“ä½œã€‚\n\n\n\n\n\n\n\nFigureÂ 6.3: To create new project: (top) first click New Directory, then (middle) click New Project, then (bottom) fill in the directory (project) name, choose a good subdirectory for its home and click Create Project.\n\n\n\n\nCall your project r4ds and think carefully about which subdirectory you put the project in. If you donâ€™t store it somewhere sensible, it will be hard to find it in the future!\nå°†ä½ çš„é¡¹ç›®å‘½åä¸º r4dsï¼Œå¹¶ä»”ç»†è€ƒè™‘å°†é¡¹ç›®æ”¾åœ¨å“ªä¸ªå­ç›®å½•ä¸­ã€‚ å¦‚æœä½ ä¸æŠŠå®ƒå­˜æ”¾åœ¨ä¸€ä¸ªåˆç†çš„åœ°æ–¹ï¼Œå°†æ¥ä¼šå¾ˆéš¾æ‰¾åˆ°å®ƒï¼\nOnce this process is complete, youâ€™ll get a new RStudio project just for this book. Check that the â€œhomeâ€ of your project is the current working directory:\nä¸€æ—¦è¿™ä¸ªè¿‡ç¨‹å®Œæˆï¼Œä½ å°†ä¸ºè¿™æœ¬ä¹¦å¾—åˆ°ä¸€ä¸ªæ–°çš„ RStudio é¡¹ç›®ã€‚ æ£€æŸ¥ä¸€ä¸‹ä½ é¡¹ç›®çš„â€œå®¶â€æ˜¯å¦æ˜¯å½“å‰çš„å·¥ä½œç›®å½•ï¼š\n\ngetwd()\n#&gt; [1] /Users/hadley/Documents/r4ds\n\nNow enter the following commands in the script editor, and save the file, calling it â€œdiamonds.Râ€. Then, create a new folder called â€œdataâ€. You can do this by clicking on the â€œNew Folderâ€ button in the Files pane in RStudio. Finally, run the complete script which will save a PNG and CSV file into your project directory. Donâ€™t worry about the details, youâ€™ll learn them later in the book.\nç°åœ¨åœ¨è„šæœ¬ç¼–è¾‘å™¨ä¸­è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼Œå¹¶ä¿å­˜æ–‡ä»¶ï¼Œå‘½åä¸ºâ€œdiamonds.Râ€ã€‚ ç„¶åï¼Œåˆ›å»ºä¸€ä¸ªåä¸ºâ€œdataâ€çš„æ–°æ–‡ä»¶å¤¹ã€‚ ä½ å¯ä»¥é€šè¿‡ç‚¹å‡» RStudio æ–‡ä»¶çª—æ ¼ä¸­çš„â€œNew Folderâ€æŒ‰é’®æ¥å®Œæˆæ­¤æ“ä½œã€‚ æœ€åï¼Œè¿è¡Œæ•´ä¸ªè„šæœ¬ï¼Œè¿™ä¼šå°†ä¸€ä¸ª PNG å’Œä¸€ä¸ª CSV æ–‡ä»¶ä¿å­˜åˆ°ä½ çš„é¡¹ç›®ç›®å½•ä¸­ã€‚ åˆ«æ‹…å¿ƒç»†èŠ‚ï¼Œä½ å°†åœ¨ä¹¦çš„åé¢å­¦ä¹ å®ƒä»¬ã€‚\n\nlibrary(tidyverse)\n\nggplot(diamonds, aes(x = carat, y = price)) + \n  geom_hex()\nggsave(\"diamonds.png\")\n\nwrite_csv(diamonds, \"data/diamonds.csv\")\n\nQuit RStudio. Inspect the folder associated with your project â€” notice the .Rproj file. Double-click that file to re-open the project. Notice you get back to where you left off: itâ€™s the same working directory and command history, and all the files you were working on are still open. Because you followed our instructions above, you will, however, have a completely fresh environment, guaranteeing that youâ€™re starting with a clean slate.\né€€å‡º RStudioã€‚ æ£€æŸ¥ä¸ä½ çš„é¡¹ç›®å…³è”çš„æ–‡ä»¶å¤¹â€”â€”æ³¨æ„é‚£ä¸ª .Rproj æ–‡ä»¶ã€‚ åŒå‡»è¯¥æ–‡ä»¶ä»¥é‡æ–°æ‰“å¼€é¡¹ç›®ã€‚ ä½ ä¼šå‘ç°ä½ å›åˆ°äº†ç¦»å¼€æ—¶çš„åœ°æ–¹ï¼šå·¥ä½œç›®å½•å’Œå‘½ä»¤å†å²è®°å½•éƒ½ç›¸åŒï¼Œä½ æ­£åœ¨å¤„ç†çš„æ‰€æœ‰æ–‡ä»¶ä»ç„¶æ˜¯æ‰“å¼€çš„ã€‚ ç„¶è€Œï¼Œå› ä¸ºä½ éµå¾ªäº†æˆ‘ä»¬ä¸Šé¢çš„æŒ‡ç¤ºï¼Œä½ å°†æ‹¥æœ‰ä¸€ä¸ªå…¨æ–°çš„ç¯å¢ƒï¼Œä¿è¯ä½ æ˜¯ä»ä¸€ä¸ªå¹²å‡€çš„çŠ¶æ€å¼€å§‹ã€‚\nIn your favorite OS-specific way, search your computer for diamonds.png and you will find the PNG (no surprise) but also the script that created it (diamonds.R). This is a huge win! One day, you will want to remake a figure or just understand where it came from. If you rigorously save figures to files with R code and never with the mouse or the clipboard, you will be able to reproduce old work with ease!\nç”¨ä½ å–œæ¬¢çš„ç‰¹å®šäºæ“ä½œç³»ç»Ÿçš„æ–¹å¼ï¼Œåœ¨ä½ çš„ç”µè„‘ä¸Šæœç´¢ diamonds.pngï¼Œä½ ä¼šæ‰¾åˆ°è¿™ä¸ª PNG æ–‡ä»¶ï¼ˆä¸å¥‡æ€ªï¼‰ï¼Œä½†åŒæ—¶ä¹Ÿä¼šæ‰¾åˆ°åˆ›å»ºå®ƒçš„è„šæœ¬ (diamonds.R)ã€‚ è¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„èƒœåˆ©ï¼ æ€»æœ‰ä¸€å¤©ï¼Œä½ ä¼šæƒ³è¦é‡åšä¸€ä¸ªå›¾è¡¨ï¼Œæˆ–è€…åªæ˜¯æƒ³äº†è§£å®ƒæ˜¯æ€ä¹ˆæ¥çš„ã€‚ å¦‚æœä½ ä¸¥æ ¼åœ°ç”¨ R ä»£ç å°†å›¾è¡¨ä¿å­˜åˆ°æ–‡ä»¶ï¼Œè€Œä¸æ˜¯ç”¨é¼ æ ‡æˆ–å‰ªè´´æ¿ï¼Œä½ å°†èƒ½å¤Ÿè½»æ¾åœ°é‡ç°æ—§çš„å·¥ä½œï¼\n\n6.2.4 Relative and absolute paths\nOnce youâ€™re inside a project, you should only ever use relative paths not absolute paths. Whatâ€™s the difference? A relative path is relative to the working directory, i.e.Â the projectâ€™s home. When Hadley wrote data/diamonds.csv above it was a shortcut for /Users/hadley/Documents/r4ds/data/diamonds.csv. But importantly, if Mine ran this code on her computer, it would point to /Users/Mine/Documents/r4ds/data/diamonds.csv. This is why relative paths are important: theyâ€™ll work regardless of where the R project folder ends up.\nä¸€æ—¦ä½ è¿›å…¥ä¸€ä¸ªé¡¹ç›®ä¸­ï¼Œä½ åº”è¯¥åªä½¿ç”¨ç›¸å¯¹è·¯å¾„ (relative paths)ï¼Œè€Œä¸æ˜¯ç»å¯¹è·¯å¾„ (absolute paths)ã€‚ æœ‰ä»€ä¹ˆåŒºåˆ«å‘¢ï¼Ÿ ç›¸å¯¹è·¯å¾„æ˜¯ç›¸å¯¹äºå·¥ä½œç›®å½•çš„ï¼Œä¹Ÿå°±æ˜¯é¡¹ç›®çš„ä¸»ç›®å½•ã€‚ å½“ Hadley åœ¨ä¸Šé¢å†™ data/diamonds.csv æ—¶ï¼Œå®ƒæ˜¯ /Users/hadley/Documents/r4ds/data/diamonds.csv çš„ä¸€ä¸ªå¿«æ·æ–¹å¼ã€‚ ä½†é‡è¦çš„æ˜¯ï¼Œå¦‚æœ Mine åœ¨å¥¹çš„ç”µè„‘ä¸Šè¿è¡Œè¿™æ®µä»£ç ï¼Œå®ƒå°†æŒ‡å‘ /Users/Mine/Documents/r4ds/data/diamonds.csvã€‚ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆç›¸å¯¹è·¯å¾„å¾ˆé‡è¦ï¼šæ— è®º R é¡¹ç›®æ–‡ä»¶å¤¹æœ€ç»ˆåœ¨å“ªé‡Œï¼Œå®ƒä»¬éƒ½èƒ½å·¥ä½œã€‚\nAbsolute paths point to the same place regardless of your working directory. They look a little different depending on your operating system. On Windows they start with a drive letter (e.g., C:) or two backslashes (e.g., \\\\servername) and on Mac/Linux they start with a slash â€œ/â€ (e.g., /users/hadley). You should never use absolute paths in your scripts, because they hinder sharing: no one else will have exactly the same directory configuration as you.\næ— è®ºä½ çš„å·¥ä½œç›®å½•æ˜¯ä»€ä¹ˆï¼Œç»å¯¹è·¯å¾„éƒ½æŒ‡å‘åŒä¸€ä¸ªåœ°æ–¹ã€‚ å®ƒä»¬æ ¹æ®ä½ çš„æ“ä½œç³»ç»Ÿçœ‹èµ·æ¥æœ‰äº›ä¸åŒã€‚ åœ¨ Windows ä¸Šï¼Œå®ƒä»¬ä»¥é©±åŠ¨å™¨å·ï¼ˆä¾‹å¦‚ C:ï¼‰æˆ–ä¸¤ä¸ªåæ–œæ ï¼ˆä¾‹å¦‚ \\\\servernameï¼‰å¼€å¤´ï¼Œè€Œåœ¨ Mac/Linux ä¸Šï¼Œå®ƒä»¬ä»¥æ–œæ â€œ/â€å¼€å¤´ï¼ˆä¾‹å¦‚ /users/hadleyï¼‰ã€‚ ä½ æ°¸è¿œä¸åº”è¯¥åœ¨ä½ çš„è„šæœ¬ä¸­ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œå› ä¸ºå®ƒä»¬ä¼šå¦¨ç¢å…±äº«ï¼šæ²¡æœ‰å…¶ä»–äººä¼šæ‹¥æœ‰ä¸ä½ å®Œå…¨ç›¸åŒçš„ç›®å½•é…ç½®ã€‚\nThereâ€™s another important difference between operating systems: how you separate the components of the path. Mac and Linux uses slashes (e.g., data/diamonds.csv) and Windows uses backslashes (e.g., data\\diamonds.csv). R can work with either type (no matter what platform youâ€™re currently using), but unfortunately, backslashes mean something special to R, and to get a single backslash in the path, you need to type two backslashes! That makes life frustrating, so we recommend always using the Linux/Mac style with forward slashes.\næ“ä½œç³»ç»Ÿä¹‹é—´è¿˜æœ‰å¦ä¸€ä¸ªé‡è¦çš„åŒºåˆ«ï¼šä½ å¦‚ä½•åˆ†éš”è·¯å¾„çš„ç»„æˆéƒ¨åˆ†ã€‚ Mac å’Œ Linux ä½¿ç”¨æ­£æ–œæ ï¼ˆä¾‹å¦‚ data/diamonds.csvï¼‰ï¼Œè€Œ Windows ä½¿ç”¨åæ–œæ ï¼ˆä¾‹å¦‚ data\\diamonds.csvï¼‰ã€‚ R å¯ä»¥å¤„ç†è¿™ä¸¤ç§ç±»å‹ï¼ˆæ— è®ºä½ å½“å‰ä½¿ç”¨çš„æ˜¯å“ªä¸ªå¹³å°ï¼‰ï¼Œä½†ä¸å¹¸çš„æ˜¯ï¼Œåæ–œæ å¯¹ R æ¥è¯´æœ‰ç‰¹æ®Šå«ä¹‰ï¼Œè¦åœ¨è·¯å¾„ä¸­å¾—åˆ°ä¸€ä¸ªåæ–œæ ï¼Œä½ éœ€è¦è¾“å…¥ä¸¤ä¸ªåæ–œæ ï¼ è¿™è®©ç”Ÿæ´»å˜å¾—ä»¤äººæ²®ä¸§ï¼Œæ‰€ä»¥æˆ‘ä»¬å»ºè®®å§‹ç»ˆä½¿ç”¨ Linux/Mac é£æ ¼çš„æ­£æ–œæ ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Workflow: scripts and projects</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#exercises",
    "href": "workflow-scripts.html#exercises",
    "title": "6Â  Workflow: scripts and projects",
    "section": "\n6.3 Exercises",
    "text": "6.3 Exercises\n\nGo to the RStudio Tips Twitter account, https://twitter.com/rstudiotips and find one tip that looks interesting. Practice using it!\nWhat other common mistakes will RStudio diagnostics report? Read https://support.posit.co/hc/en-us/articles/205753617-Code-Diagnostics to find out.",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Workflow: scripts and projects</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#summary",
    "href": "workflow-scripts.html#summary",
    "title": "6Â  Workflow: scripts and projects",
    "section": "\n6.4 Summary",
    "text": "6.4 Summary\nIn this chapter, youâ€™ve learned how to organize your R code in scripts (files) and projects (directories). Much like code style, this may feel like busywork at first. But as you accumulate more code across multiple projects, youâ€™ll learn to appreciate how a little up front organisation can save you a bunch of time down the road.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•åœ¨è„šæœ¬ï¼ˆæ–‡ä»¶ï¼‰å’Œé¡¹ç›®ï¼ˆç›®å½•ï¼‰ä¸­ç»„ç»‡ä½ çš„ R ä»£ç ã€‚ å°±åƒä»£ç é£æ ¼ä¸€æ ·ï¼Œè¿™èµ·åˆå¯èƒ½æ„Ÿè§‰åƒæ˜¯çç¢çš„å·¥ä½œã€‚ ä½†éšç€ä½ åœ¨å¤šä¸ªé¡¹ç›®ä¸­ç§¯ç´¯äº†è¶Šæ¥è¶Šå¤šçš„ä»£ç ï¼Œä½ ä¼šé€æ¸ä½“ä¼šåˆ°ï¼Œä¸€ç‚¹ç‚¹å‰æœŸçš„ç»„ç»‡å·¥ä½œèƒ½åœ¨æœªæ¥ä¸ºä½ èŠ‚çœå¤§é‡æ—¶é—´ã€‚\nIn summary, scripts and projects give you a solid workflow that will serve you well in the future:\næ€»è€Œè¨€ä¹‹ï¼Œè„šæœ¬å’Œé¡¹ç›®ä¸ºä½ æä¾›äº†ä¸€ä¸ªåšå®çš„å·¥ä½œæµç¨‹ï¼Œè¿™å°†åœ¨æœªæ¥å¯¹ä½ å¤§æœ‰è£¨ç›Šï¼š\n\nCreate one RStudio project for each data analysis project.\nä¸ºæ¯ä¸ªæ•°æ®åˆ†æé¡¹ç›®åˆ›å»ºä¸€ä¸ª RStudio é¡¹ç›®ã€‚\nSave your scripts (with informative names) in the project, edit them, run them in bits or as a whole. Restart R frequently to make sure youâ€™ve captured everything in your scripts.\nåœ¨é¡¹ç›®ä¸­ä¿å­˜ä½ çš„è„šæœ¬ï¼ˆå¹¶ä½¿ç”¨ä¿¡æ¯ä¸°å¯Œçš„åç§°ï¼‰ï¼Œç¼–è¾‘å®ƒä»¬ï¼Œåˆ†æ®µæˆ–æ•´ä½“è¿è¡Œå®ƒä»¬ã€‚é¢‘ç¹é‡å¯ R ä»¥ç¡®ä¿ä½ å·²å°†æ‰€æœ‰å†…å®¹éƒ½è®°å½•åœ¨è„šæœ¬ä¸­ã€‚\nOnly ever use relative paths, not absolute paths.\nåªä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä¸ä½¿ç”¨ç»å¯¹è·¯å¾„ã€‚\n\nThen everything you need is in one place and cleanly separated from all the other projects that you are working on.\nç„¶åï¼Œä½ éœ€è¦çš„ä¸€åˆ‡éƒ½åœ¨ä¸€ä¸ªåœ°æ–¹ï¼Œå¹¶ä¸ä½ æ­£åœ¨è¿›è¡Œçš„æ‰€æœ‰å…¶ä»–é¡¹ç›®æ¸…æ™°åœ°åˆ†ç¦»å¼€æ¥ã€‚\nSo far, weâ€™ve worked with datasets bundled inside of R packages. This makes it easier to get some practice on pre-prepared data, but obviously your data wonâ€™t be available in this way. So in the next chapter, youâ€™re going to learn how load data from disk into your R session using the readr package.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´ä½¿ç”¨ R åŒ…ä¸­æ†ç»‘çš„æ•°æ®é›†ã€‚ è¿™ä½¿å¾—åœ¨é¢„å…ˆå‡†å¤‡å¥½çš„æ•°æ®ä¸Šè¿›è¡Œç»ƒä¹ å˜å¾—æ›´å®¹æ˜“ï¼Œä½†æ˜¾ç„¶ä½ çš„æ•°æ®ä¸ä¼šä»¥è¿™ç§æ–¹å¼æä¾›ã€‚ å› æ­¤ï¼Œåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ readr åŒ…å°†æ•°æ®ä»ç£ç›˜åŠ è½½åˆ°ä½ çš„ R ä¼šè¯ä¸­ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Workflow: scripts and projects</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#footnotes",
    "href": "workflow-scripts.html#footnotes",
    "title": "6Â  Workflow: scripts and projects",
    "section": "",
    "text": "Not to mention that youâ€™re tempting fate by using â€œfinalâ€ in the name ğŸ˜† The comic Piled Higher and Deeper has a fun strip on this.â†©ï¸\nIf you donâ€™t have usethis installed, you can install it with install.packages(\"usethis\").â†©ï¸",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Workflow: scripts and projects</span>"
    ]
  },
  {
    "objectID": "data-import.html",
    "href": "data-import.html",
    "title": "7Â  Data import",
    "section": "",
    "text": "7.1 Introduction\nWorking with data provided by R packages is a great way to learn data science tools, but you want to apply what youâ€™ve learned to your own data at some point.\nä½¿ç”¨ R åŒ…ä¸­æä¾›çš„æ•°æ®æ˜¯å­¦ä¹ æ•°æ®ç§‘å­¦å·¥å…·çš„å¥½æ–¹æ³•ï¼Œä½†åœ¨æŸäº›æ—¶å€™ï¼Œä½ ä¼šå¸Œæœ›å°†æ‰€å­¦çŸ¥è¯†åº”ç”¨åˆ°è‡ªå·±çš„æ•°æ®ä¸Šã€‚\nIn this chapter, youâ€™ll learn the basics of reading data files into R.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ å°†æ•°æ®æ–‡ä»¶è¯»å…¥ R çš„åŸºç¡€çŸ¥è¯†ã€‚\nSpecifically, this chapter will focus on reading plain-text rectangular files.\nå…·ä½“æ¥è¯´ï¼Œæœ¬ç« å°†é‡ç‚¹ä»‹ç»å¦‚ä½•è¯»å–çº¯æ–‡æœ¬çŸ©å½¢æ–‡ä»¶ã€‚\nWeâ€™ll start with practical advice for handling features like column names, types, and missing data.\næˆ‘ä»¬å°†ä»å¤„ç†åˆ—åã€ç±»å‹å’Œç¼ºå¤±æ•°æ®ç­‰ç‰¹æ€§çš„å®ç”¨å»ºè®®å¼€å§‹ã€‚\nYou will then learn about reading data from multiple files at once and writing data from R to a file.\nç„¶åï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä¸€æ¬¡æ€§ä»å¤šä¸ªæ–‡ä»¶ä¸­è¯»å–æ•°æ®ï¼Œä»¥åŠå¦‚ä½•å°†æ•°æ®ä» R å†™å…¥æ–‡ä»¶ã€‚\nFinally, youâ€™ll learn how to handcraft data frames in R.\næœ€åï¼Œä½ å°†å­¦ä¹ å¦‚ä½•åœ¨ R ä¸­æ‰‹åŠ¨åˆ›å»ºæ•°æ®æ¡†ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#introduction",
    "href": "data-import.html#introduction",
    "title": "7Â  Data import",
    "section": "",
    "text": "7.1.1 Prerequisites\nIn this chapter, youâ€™ll learn how to load flat files in R with the readr package, which is part of the core tidyverse.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ readr åŒ…åœ¨ R ä¸­åŠ è½½å¹³é¢æ–‡ä»¶ï¼Œè¯¥åŒ…æ˜¯æ ¸å¿ƒ tidyverse çš„ä¸€éƒ¨åˆ†ã€‚\n\nlibrary(tidyverse)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#reading-data-from-a-file",
    "href": "data-import.html#reading-data-from-a-file",
    "title": "7Â  Data import",
    "section": "\n7.2 Reading data from a file",
    "text": "7.2 Reading data from a file\nTo begin, weâ€™ll focus on the most common rectangular data file type: CSV, which is short for comma-separated values.\né¦–å…ˆï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨æœ€å¸¸è§çš„çŸ©å½¢æ•°æ®æ–‡ä»¶ç±»å‹ï¼šCSVï¼Œå³é€—å·åˆ†éš”å€¼ (comma-separated values) çš„ç¼©å†™ã€‚\nHere is what a simple CSV file looks like.\nä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ CSV æ–‡ä»¶çš„æ ·å­ã€‚\nThe first row, commonly called the header row, gives the column names, and the following six rows provide the data.\nç¬¬ä¸€è¡Œï¼Œé€šå¸¸ç§°ä¸ºæ ‡é¢˜è¡Œ (header row)ï¼Œç»™å‡ºäº†åˆ—åï¼Œæ¥ä¸‹æ¥çš„å…­è¡Œæä¾›äº†æ•°æ®ã€‚\nThe columns are separated, aka delimited, by commas.\nåˆ—ä¹‹é—´ç”±é€—å·åˆ†éš”ï¼Œä¹Ÿç§°ä¸ºå®šç•Œ (delimited)ã€‚\n\nStudent ID,Full Name,favourite.food,mealPlan,AGE\n1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4\n2,Barclay Lynn,French fries,Lunch only,5\n3,Jayendra Lyne,N/A,Breakfast and lunch,7\n4,Leon Rossini,Anchovies,Lunch only,\n5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five\n6,GÃ¼venÃ§ Attila,Ice cream,Lunch only,6\n\nTableÂ 7.1 shows a representation of the same data as a table.TableÂ 7.1 ä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºäº†ç›¸åŒçš„æ•°æ®ã€‚\n\n\n\nTableÂ 7.1: Data from the students.csv file as a table.\n\n\n\n\n\n\n\n\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\n\n1\nSunil Huffmann\nStrawberry yoghurt\nLunch only\n4\n\n\n2\nBarclay Lynn\nFrench fries\nLunch only\n5\n\n\n3\nJayendra Lyne\nN/A\nBreakfast and lunch\n7\n\n\n4\nLeon Rossini\nAnchovies\nLunch only\nNA\n\n\n5\nChidiegwu Dunkel\nPizza\nBreakfast and lunch\nfive\n\n\n6\nGÃ¼venÃ§ Attila\nIce cream\nLunch only\n6\n\n\n\n\n\n\n\n\nWe can read this file into R using read_csv().\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨ read_csv() å°†è¿™ä¸ªæ–‡ä»¶è¯»å…¥ Rã€‚\nThe first argument is the most important: the path to the file.\nç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æœ€é‡è¦çš„ï¼šæ–‡ä»¶çš„è·¯å¾„ã€‚\nYou can think about the path as the address of the file: the file is called students.csv and it lives in the data folder.\nä½ å¯ä»¥å°†è·¯å¾„çœ‹ä½œæ˜¯æ–‡ä»¶çš„åœ°å€ï¼šæ–‡ä»¶åä¸º students.csvï¼Œå®ƒä½äº data æ–‡ä»¶å¤¹ä¸­ã€‚\n\nstudents &lt;- read_csv(\"data/students.csv\")\n#&gt; Rows: 6 Columns: 5\n#&gt; â”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#&gt; Delimiter: \",\"\n#&gt; chr (4): Full Name, favourite.food, mealPlan, AGE\n#&gt; dbl (1): Student ID\n#&gt; \n#&gt; â„¹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; â„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nThe code above will work if you have the students.csv file in a data folder in your project.\nå¦‚æœä½ çš„é¡¹ç›®ä¸­æœ‰ä¸€ä¸ª data æ–‡ä»¶å¤¹ï¼Œå¹¶ä¸”å…¶ä¸­åŒ…å« students.csv æ–‡ä»¶ï¼Œé‚£ä¹ˆä¸Šé¢çš„ä»£ç å°†ä¼šæ­£å¸¸å·¥ä½œã€‚\nYou can download the students.csv file from https://pos.it/r4ds-students-csv or you can read it directly from that URL with:\nä½ å¯ä»¥ä» https://pos.it/r4ds-students-csv ä¸‹è½½ students.csv æ–‡ä»¶ï¼Œæˆ–è€…ä½¿ç”¨ä»¥ä¸‹ä»£ç ç›´æ¥ä»è¯¥ URL è¯»å–ï¼š\n\nstudents &lt;- read_csv(\"https://pos.it/r4ds-students-csv\")\n\nWhen you run read_csv(), it prints out a message telling you the number of rows and columns of data, the delimiter that was used, and the column specifications (names of columns organized by the type of data the column contains).\nå½“ä½ è¿è¡Œ read_csv() æ—¶ï¼Œå®ƒä¼šæ‰“å°å‡ºä¸€æ¡æ¶ˆæ¯ï¼Œå‘Šè¯‰ä½ æ•°æ®çš„è¡Œæ•°å’Œåˆ—æ•°ã€ä½¿ç”¨çš„åˆ†éš”ç¬¦ä»¥åŠåˆ—çš„è§„æ ¼ (column specifications)ï¼ˆæŒ‰åˆ—æ‰€å«æ•°æ®ç±»å‹ç»„ç»‡çš„åˆ—åï¼‰ã€‚\nIt also prints out some information about retrieving the full column specification and how to quiet this message.\nå®ƒè¿˜ä¼šæ‰“å°ä¸€äº›å…³äºæ£€ç´¢å®Œæ•´åˆ—è§„æ ¼ä»¥åŠå¦‚ä½•é™é»˜æ­¤æ¶ˆæ¯çš„ä¿¡æ¯ã€‚\nThis message is an integral part of readr, and weâ€™ll return to it in Section 7.3.\nè¿™æ¡æ¶ˆæ¯æ˜¯ readr ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†åœ¨ Section 7.3 ä¸­å†æ¬¡è®¨è®ºå®ƒã€‚\n\n7.2.1 Practical advice\nOnce you read data in, the first step usually involves transforming it in some way to make it easier to work with in the rest of your analysis.\nä¸€æ—¦ä½ è¯»å…¥æ•°æ®ï¼Œç¬¬ä¸€æ­¥é€šå¸¸æ˜¯å°†å…¶ä»¥æŸç§æ–¹å¼è¿›è¡Œè½¬æ¢ï¼Œä½¿å…¶åœ¨åç»­åˆ†æä¸­æ›´æ˜“äºä½¿ç”¨ã€‚\nLetâ€™s take another look at the students data with that in mind.\nè®©æˆ‘ä»¬å¸¦ç€è¿™ä¸ªæƒ³æ³•å†çœ‹ä¸€ä¸‹ students æ•°æ®ã€‚\n\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nIn the favourite.food column, there are a bunch of food items, and then the character string N/A, which should have been a real NA that R will recognize as â€œnot availableâ€.\nåœ¨ favourite.food åˆ—ä¸­ï¼Œæœ‰ä¸€å †é£Ÿç‰©æ¡ç›®ï¼Œç„¶åæ˜¯å­—ç¬¦ä¸² N/Aï¼Œå®ƒæœ¬åº”æ˜¯ä¸€ä¸ªçœŸæ­£çš„ NAï¼ŒR ä¼šå°†å…¶è¯†åˆ«ä¸ºâ€œä¸å¯ç”¨â€(not available)ã€‚\nThis is something we can address using the na argument.\nè¿™æ˜¯æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ na å‚æ•°æ¥è§£å†³çš„é—®é¢˜ã€‚\nBy default, read_csv() only recognizes empty strings (\"\") in this dataset as NAs, and we want it to also recognize the character string \"N/A\".\né»˜è®¤æƒ…å†µä¸‹ï¼Œread_csv() åœ¨è¿™ä¸ªæ•°æ®é›†ä¸­åªå°†ç©ºå­—ç¬¦ä¸² (\"\") è¯†åˆ«ä¸º NAï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒä¹Ÿèƒ½è¯†åˆ«å­—ç¬¦ä¸² \"N/A\"ã€‚\n\nstudents &lt;- read_csv(\"data/students.csv\", na = c(\"N/A\", \"\"))\n\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nYou might also notice that the Student ID and Full Name columns are surrounded by backticks.\nä½ å¯èƒ½è¿˜ä¼šæ³¨æ„åˆ° Student ID å’Œ Full Name åˆ—è¢«åå¼•å·åŒ…å›´ã€‚\nThatâ€™s because they contain spaces, breaking Râ€™s usual rules for variable names; theyâ€™re non-syntactic names.\nè¿™æ˜¯å› ä¸ºå®ƒä»¬åŒ…å«ç©ºæ ¼ï¼Œç ´åäº† R é€šå¸¸çš„å˜é‡å‘½åè§„åˆ™ï¼›å®ƒä»¬æ˜¯éè¯­æ³•åç§° (non-syntactic names)ã€‚\nTo refer to these variables, you need to surround them with backticks, `:\nè¦å¼•ç”¨è¿™äº›å˜é‡ï¼Œä½ éœ€è¦ç”¨åå¼•å· ` å°†å®ƒä»¬æ‹¬èµ·æ¥ï¼š\n\nstudents |&gt; \n  rename(\n    student_id = `Student ID`,\n    full_name = `Full Name`\n  )\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite.food     mealPlan            AGE  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nAn alternative approach is to use janitor::clean_names() to use some heuristics to turn them all into snake case at once1.\nå¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ janitor::clean_names()ï¼Œå®ƒä¼šè¿ç”¨ä¸€äº›å¯å‘å¼æ–¹æ³•å°†æ‰€æœ‰åˆ—åä¸€æ¬¡æ€§è½¬æ¢ä¸ºè›‡å½¢å‘½åæ³• (snake case)1ã€‚\n\nstudents |&gt; janitor::clean_names()\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nAnother common task after reading in data is to consider variable types.\nè¯»å…¥æ•°æ®åçš„å¦ä¸€ä¸ªå¸¸è§ä»»åŠ¡æ˜¯è€ƒè™‘å˜é‡ç±»å‹ã€‚\nFor example, meal_plan is a categorical variable with a known set of possible values, which in R should be represented as a factor:\nä¾‹å¦‚ï¼Œmeal_plan æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡ï¼Œå…¶å¯èƒ½å€¼çš„é›†åˆæ˜¯å·²çŸ¥çš„ï¼Œåœ¨ R ä¸­åº”è¯¥è¡¨ç¤ºä¸ºä¸€ä¸ªå› å­ (factor)ï¼š\n\nstudents |&gt;\n  janitor::clean_names() |&gt;\n  mutate(meal_plan = factor(meal_plan))\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nNote that the values in the meal_plan variable have stayed the same, but the type of variable denoted underneath the variable name has changed from character (&lt;chr&gt;) to factor (&lt;fct&gt;).\nè¯·æ³¨æ„ï¼Œmeal_plan å˜é‡ä¸­çš„å€¼ä¿æŒä¸å˜ï¼Œä½†å˜é‡åä¸‹æ–¹è¡¨ç¤ºçš„å˜é‡ç±»å‹å·²ä»å­—ç¬¦ (&lt;chr&gt;) å˜ä¸ºäº†å› å­ (&lt;fct&gt;)ã€‚\nYouâ€™ll learn more about factors in Chapter 16.\nä½ å°†åœ¨ Chapter 16 ä¸­å­¦åˆ°æ›´å¤šå…³äºå› å­çš„çŸ¥è¯†ã€‚\nBefore you analyze these data, youâ€™ll probably want to fix the age column.\nåœ¨åˆ†æè¿™äº›æ•°æ®ä¹‹å‰ï¼Œä½ å¯èƒ½éœ€è¦ä¿®æ­£ age åˆ—ã€‚\nCurrently, age is a character variable because one of the observations is typed out as five instead of a numeric 5.\nç›®å‰ï¼Œage æ˜¯ä¸€ä¸ªå­—ç¬¦å˜é‡ï¼Œå› ä¸ºå…¶ä¸­ä¸€ä¸ªè§‚æµ‹å€¼è¢«è¾“å…¥ä¸º five è€Œä¸æ˜¯æ•°å­— 5ã€‚\nWe discuss the details of fixing this issue in Chapter 20.\næˆ‘ä»¬å°†åœ¨ Chapter 20 ä¸­è®¨è®ºä¿®å¤è¿™ä¸ªé—®é¢˜çš„ç»†èŠ‚ã€‚\n\nstudents &lt;- students |&gt;\n  janitor::clean_names() |&gt;\n  mutate(\n    meal_plan = factor(meal_plan),\n    age = parse_number(if_else(age == \"five\", \"5\", age))\n  )\n\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only              6\n\nA new function here is if_else(), which has three arguments.\nè¿™é‡Œæœ‰ä¸€ä¸ªæ–°å‡½æ•° if_else()ï¼Œå®ƒæœ‰ä¸‰ä¸ªå‚æ•°ã€‚\nThe first argument test should be a logical vector.\nç¬¬ä¸€ä¸ªå‚æ•° test åº”è¯¥æ˜¯ä¸€ä¸ªé€»è¾‘å‘é‡ã€‚\nThe result will contain the value of the second argument, yes, when test is TRUE, and the value of the third argument, no, when it is FALSE.\nå½“ test ä¸º TRUE æ—¶ï¼Œç»“æœå°†åŒ…å«ç¬¬äºŒä¸ªå‚æ•° yes çš„å€¼ï¼›å½“ test ä¸º FALSE æ—¶ï¼Œç»“æœå°†åŒ…å«ç¬¬ä¸‰ä¸ªå‚æ•° no çš„å€¼ã€‚\nHere weâ€™re saying if age is the character string \"five\", make it \"5\", and if not leave it as age.\nè¿™é‡Œæˆ‘ä»¬æ˜¯è¯´ï¼Œå¦‚æœ age æ˜¯å­—ç¬¦ä¸² \"five\"ï¼Œå°±æŠŠå®ƒå˜æˆ \"5\"ï¼Œå¦åˆ™ä¿æŒ age ä¸å˜ã€‚\nYou will learn more about if_else() and logical vectors in Chapter 12.\nä½ å°†åœ¨ Chapter 12 ä¸­å­¦ä¹ æ›´å¤šå…³äº if_else() å’Œé€»è¾‘å‘é‡çš„çŸ¥è¯†ã€‚\n\n7.2.2 Other arguments\nThere are a couple of other important arguments that we need to mention, and theyâ€™ll be easier to demonstrate if we first show you a handy trick: read_csv() can read text strings that youâ€™ve created and formatted like a CSV file:\nè¿˜æœ‰å‡ ä¸ªå…¶ä»–é‡è¦çš„å‚æ•°éœ€è¦æˆ‘ä»¬æåŠï¼Œå¦‚æœæˆ‘ä»¬å…ˆå‘ä½ å±•ç¤ºä¸€ä¸ªæ–¹ä¾¿çš„æŠ€å·§ï¼Œå®ƒä»¬ä¼šæ›´å®¹æ˜“æ¼”ç¤ºï¼šread_csv() å¯ä»¥è¯»å–ä½ åˆ›å»ºå¹¶æ ¼å¼åŒ–ä¸º CSV æ–‡ä»¶å½¢å¼çš„æ–‡æœ¬å­—ç¬¦ä¸²ï¼š\n\nread_csv(\n  \"a,b,c\n  1,2,3\n  4,5,6\"\n)\n#&gt; # A tibble: 2 Ã— 3\n#&gt;       a     b     c\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\nUsually, read_csv() uses the first line of the data for the column names, which is a very common convention.\né€šå¸¸ï¼Œread_csv() ä½¿ç”¨æ•°æ®çš„ç¬¬ä¸€è¡Œä½œä¸ºåˆ—åï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸æ™®éçš„æƒ¯ä¾‹ã€‚\nBut itâ€™s not uncommon for a few lines of metadata to be included at the top of the file.\nä½†æ˜¯åœ¨æ–‡ä»¶é¡¶éƒ¨åŒ…å«å‡ è¡Œå…ƒæ•°æ®çš„æƒ…å†µä¹Ÿå¹¶ä¸å°‘è§ã€‚\nYou can use skip = n to skip the first n lines or use comment = \"#\" to drop all lines that start with (e.g.) #:\nä½ å¯ä»¥ä½¿ç”¨ skip = n æ¥è·³è¿‡å‰ n è¡Œï¼Œæˆ–è€…ä½¿ç”¨ comment = \"#\" æ¥åˆ é™¤æ‰€æœ‰ä»¥ï¼ˆä¾‹å¦‚ï¼‰# å¼€å¤´çš„è¡Œï¼š\n\nread_csv(\n  \"The first line of metadata\n  The second line of metadata\n  x,y,z\n  1,2,3\",\n  skip = 2\n)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\nread_csv(\n  \"# A comment I want to skip\n  x,y,z\n  1,2,3\",\n  comment = \"#\"\n)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\nIn other cases, the data might not have column names.\nåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œæ•°æ®å¯èƒ½æ²¡æœ‰åˆ—åã€‚\nYou can use col_names = FALSE to tell read_csv() not to treat the first row as headings and instead label them sequentially from X1 to Xn:\nä½ å¯ä»¥ä½¿ç”¨ col_names = FALSE æ¥å‘Šè¯‰ read_csv() ä¸è¦å°†ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜ï¼Œè€Œæ˜¯å°†å®ƒä»¬ä» X1 åˆ° Xn é¡ºåºæ ‡è®°ï¼š\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = FALSE\n)\n#&gt; # A tibble: 2 Ã— 3\n#&gt;      X1    X2    X3\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\nAlternatively, you can pass col_names a character vector which will be used as the column names:\næˆ–è€…ï¼Œä½ å¯ä»¥ç»™ col_names ä¼ é€’ä¸€ä¸ªå­—ç¬¦å‘é‡ï¼Œå®ƒå°†è¢«ç”¨ä½œåˆ—åï¼š\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = c(\"x\", \"y\", \"z\")\n)\n#&gt; # A tibble: 2 Ã— 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\nThese arguments are all you need to know to read the majority of CSV files that youâ€™ll encounter in practice.\nè¿™äº›å‚æ•°å°±æ˜¯ä½ åœ¨å®è·µä¸­è¯»å–ç»å¤§å¤šæ•° CSV æ–‡ä»¶æ‰€éœ€è¦çŸ¥é“çš„å…¨éƒ¨å†…å®¹ã€‚\n(For the rest, youâ€™ll need to carefully inspect your .csv file and read the documentation for read_csv()â€™s many other arguments.)\nï¼ˆå¯¹äºå…¶ä½™æƒ…å†µï¼Œä½ éœ€è¦ä»”ç»†æ£€æŸ¥ä½ çš„ .csv æ–‡ä»¶ï¼Œå¹¶é˜…è¯» read_csv() è®¸å¤šå…¶ä»–å‚æ•°çš„æ–‡æ¡£ã€‚ï¼‰\n\n7.2.3 Other file types\nOnce youâ€™ve mastered read_csv(), using readrâ€™s other functions is straightforward; itâ€™s just a matter of knowing which function to reach for:\nä¸€æ—¦ä½ æŒæ¡äº† read_csv()ï¼Œä½¿ç”¨ readr çš„å…¶ä»–å‡½æ•°å°±å˜å¾—å¾ˆç®€å•äº†ï¼›å…³é”®åœ¨äºçŸ¥é“è¯¥ä½¿ç”¨å“ªä¸ªå‡½æ•°ï¼š\n\nread_csv2() reads semicolon-separated files. These use ; instead of , to separate fields and are common in countries that use , as the decimal marker.read_csv2() è¯»å–ä»¥åˆ†å·åˆ†éš”çš„æ–‡ä»¶ã€‚è¿™äº›æ–‡ä»¶ä½¿ç”¨ ; è€Œä¸æ˜¯ , æ¥åˆ†éš”å­—æ®µï¼Œåœ¨é‚£äº›ä½¿ç”¨ , ä½œä¸ºå°æ•°ç‚¹çš„å›½å®¶å¾ˆå¸¸è§ã€‚\nread_tsv() reads tab-delimited files.read_tsv() è¯»å–åˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡ä»¶ã€‚\nread_delim() reads in files with any delimiter, attempting to automatically guess the delimiter if you donâ€™t specify it.read_delim() è¯»å–ä»»ä½•åˆ†éš”ç¬¦çš„æ–‡ä»¶ï¼Œå¦‚æœä½ ä¸æŒ‡å®šåˆ†éš”ç¬¦ï¼Œå®ƒä¼šå°è¯•è‡ªåŠ¨çŒœæµ‹ã€‚\nread_fwf() reads fixed-width files. You can specify fields by their widths with fwf_widths() or by their positions with fwf_positions().read_fwf() è¯»å–å›ºå®šå®½åº¦æ–‡ä»¶ã€‚ä½ å¯ä»¥ä½¿ç”¨ fwf_widths() æŒ‰å®½åº¦æŒ‡å®šå­—æ®µï¼Œæˆ–ä½¿ç”¨ fwf_positions() æŒ‰ä½ç½®æŒ‡å®šã€‚\nread_table() reads a common variation of fixed-width files where columns are separated by white space.read_table() è¯»å–å›ºå®šå®½åº¦æ–‡ä»¶çš„ä¸€ç§å¸¸è§å˜ä½“ï¼Œå…¶ä¸­åˆ—ç”±ç©ºç™½åˆ†éš”ã€‚\nread_log() reads Apache-style log files.read_log() è¯»å– Apache é£æ ¼çš„æ—¥å¿—æ–‡ä»¶ã€‚\n\n7.2.4 Exercises\n\nWhat function would you use to read a file where fields were separated with â€œ|â€?\nApart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common?\nWhat are the most important arguments to read_fwf()?\n\nSometimes strings in a CSV file contain commas. To prevent them from causing problems, they need to be surrounded by a quoting character, like \" or '. By default, read_csv() assumes that the quoting character will be \". To read the following text into a data frame, what argument to read_csv() do you need to specify?\n\n\"x,y\\n1,'a,b'\"\n\n\n\nIdentify what is wrong with each of the following inline CSV files. What happens when you run the code?\n\nread_csv(\"a,b\\n1,2,3\\n4,5,6\")\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\nread_csv(\"a,b\\n\\\"1\")\nread_csv(\"a,b\\n1,2\\na,b\")\nread_csv(\"a;b\\n1;3\")\n\n\n\nPractice referring to non-syntactic names in the following data frame by:\n\nExtracting the variable called 1.\nPlotting a scatterplot of 1 vs.Â 2.\nCreating a new column called 3, which is 2 divided by 1.\nRenaming the columns to one, two, and three.\n\n\nannoying &lt;- tibble(\n  `1` = 1:10,\n  `2` = `1` * 2 + rnorm(length(`1`))\n)",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-col-types",
    "href": "data-import.html#sec-col-types",
    "title": "7Â  Data import",
    "section": "\n7.3 Controlling column types",
    "text": "7.3 Controlling column types\nA CSV file doesnâ€™t contain any information about the type of each variable (i.e.Â whether itâ€™s a logical, number, string, etc.), so readr will try to guess the type.\nCSV æ–‡ä»¶ä¸åŒ…å«ä»»ä½•å…³äºæ¯ä¸ªå˜é‡ç±»å‹çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå®ƒæ˜¯ä¸€ä¸ªé€»è¾‘å€¼ã€æ•°å­—ã€å­—ç¬¦ä¸²ç­‰ï¼‰ï¼Œæ‰€ä»¥ readr ä¼šå°è¯•çŒœæµ‹å…¶ç±»å‹ã€‚\nThis section describes how the guessing process works, how to resolve some common problems that cause it to fail, and, if needed, how to supply the column types yourself.\næœ¬èŠ‚æè¿°äº†çŒœæµ‹è¿‡ç¨‹æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå¦‚ä½•è§£å†³ä¸€äº›å¯¼è‡´å®ƒå¤±è´¥çš„å¸¸è§é—®é¢˜ï¼Œä»¥åŠåœ¨éœ€è¦æ—¶å¦‚ä½•è‡ªå·±æä¾›åˆ—ç±»å‹ã€‚\nFinally, weâ€™ll mention a few general strategies that are useful if readr is failing catastrophically and you need to get more insight into the structure of your file.\næœ€åï¼Œæˆ‘ä»¬å°†æåŠä¸€äº›é€šç”¨çš„ç­–ç•¥ï¼Œå¦‚æœ readr å‘ç”Ÿç¾éš¾æ€§æ•…éšœï¼Œè€Œä½ éœ€è¦æ›´æ·±å…¥åœ°äº†è§£æ–‡ä»¶ç»“æ„ï¼Œè¿™äº›ç­–ç•¥ä¼šå¾ˆæœ‰ç”¨ã€‚\n\n7.3.1 Guessing types\nreadr uses a heuristic to figure out the column types.\nreadr ä½¿ç”¨ä¸€ç§å¯å‘å¼æ–¹æ³• (heuristic) æ¥ç¡®å®šåˆ—ç±»å‹ã€‚\nFor each column, it pulls the values of 1,0002 rows spaced evenly from the first row to the last, ignoring missing values.\nå¯¹äºæ¯ä¸€åˆ—ï¼Œå®ƒä¼šä»ç¬¬ä¸€è¡Œåˆ°æœ€åä¸€è¡Œå‡åŒ€åœ°æŠ½å– 1000 è¡Œ 2 çš„å€¼ï¼Œå¹¶å¿½ç•¥ç¼ºå¤±å€¼ã€‚\nIt then works through the following questions:\nç„¶åå®ƒä¼šæŒ‰é¡ºåºè€ƒè™‘ä»¥ä¸‹é—®é¢˜ï¼š\n\nDoes it contain only F, T, FALSE, or TRUE (ignoring case)? If so, itâ€™s a logical.\nå®ƒæ˜¯å¦åªåŒ…å« Fã€Tã€FALSE æˆ– TRUEï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰ï¼Ÿå¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå®ƒæ˜¯ä¸€ä¸ªé€»è¾‘å€¼ã€‚\nDoes it contain only numbers (e.g., 1, -4.5, 5e6, Inf)? If so, itâ€™s a number.\nå®ƒæ˜¯å¦åªåŒ…å«æ•°å­—ï¼ˆä¾‹å¦‚ 1, -4.5, 5e6, Infï¼‰ï¼Ÿå¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå®ƒæ˜¯ä¸€ä¸ªæ•°å­—ã€‚\nDoes it match the ISO8601 standard? If so, itâ€™s a date or date-time. (Weâ€™ll return to date-times in more detail in Section 17.2).\nå®ƒæ˜¯å¦ç¬¦åˆ ISO8601 æ ‡å‡†ï¼Ÿå¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå®ƒæ˜¯ä¸€ä¸ªæ—¥æœŸæˆ–æ—¥æœŸæ—¶é—´ã€‚ï¼ˆæˆ‘ä»¬å°†åœ¨ Section 17.2 ä¸­æ›´è¯¦ç»†åœ°å›åˆ°æ—¥æœŸæ—¶é—´ã€‚ï¼‰\nOtherwise, it must be a string.\nå¦åˆ™ï¼Œå®ƒå¿…é¡»æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚\n\nYou can see that behavior in action in this simple example:\nä½ å¯ä»¥åœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­çœ‹åˆ°è¿™ç§è¡Œä¸ºï¼š\n\nread_csv(\"\n  logical,numeric,date,string\n  TRUE,1,2021-01-15,abc\n  false,4.5,2021-02-15,def\n  T,Inf,2021-02-16,ghi\n\")\n#&gt; # A tibble: 3 Ã— 4\n#&gt;   logical numeric date       string\n#&gt;   &lt;lgl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt; \n#&gt; 1 TRUE        1   2021-01-15 abc   \n#&gt; 2 FALSE       4.5 2021-02-15 def   \n#&gt; 3 TRUE      Inf   2021-02-16 ghi\n\nThis heuristic works well if you have a clean dataset, but in real life, youâ€™ll encounter a selection of weird and beautiful failures.\nå¦‚æœä½ æœ‰ä¸€ä¸ªå¹²å‡€çš„æ•°æ®é›†ï¼Œè¿™ç§å¯å‘å¼æ–¹æ³•ä¼šå·¥ä½œå¾—å¾ˆå¥½ï¼Œä½†åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œä½ ä¼šé‡åˆ°å„ç§å¥‡æ€ªè€Œç¾å¦™çš„å¤±è´¥æƒ…å†µã€‚\n\n7.3.2 Missing values, column types, and problems\nThe most common way column detection fails is that a column contains unexpected values, and you get a character column instead of a more specific type.\nåˆ—æ£€æµ‹å¤±è´¥æœ€å¸¸è§çš„æ–¹å¼æ˜¯åˆ—ä¸­åŒ…å«æ„å¤–å€¼ï¼Œå¯¼è‡´ä½ å¾—åˆ°ä¸€ä¸ªå­—ç¬¦åˆ—è€Œä¸æ˜¯æ›´å…·ä½“çš„ç±»å‹ã€‚\nOne of the most common causes for this is a missing value, recorded using something other than the NA that readr expects.\nå…¶ä¸­ä¸€ä¸ªæœ€å¸¸è§çš„åŸå› æ˜¯ç¼ºå¤±å€¼ï¼Œå®ƒä½¿ç”¨äº† readr æœŸæœ›çš„ NA ä¹‹å¤–çš„å…¶å®ƒæ–¹å¼è¿›è¡Œè®°å½•ã€‚\nTake this simple 1 column CSV file as an example:\nä»¥è¿™ä¸ªç®€å•çš„å•åˆ— CSV æ–‡ä»¶ä¸ºä¾‹ï¼š\n\nsimple_csv &lt;- \"\n  x\n  10\n  .\n  20\n  30\"\n\nIf we read it without any additional arguments, x becomes a character column:\nå¦‚æœæˆ‘ä»¬ä¸å¸¦ä»»ä½•é™„åŠ å‚æ•°è¯»å–å®ƒï¼Œx ä¼šå˜æˆä¸€ä¸ªå­—ç¬¦åˆ—ï¼š\n\nread_csv(simple_csv)\n#&gt; # A tibble: 4 Ã— 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 10   \n#&gt; 2 .    \n#&gt; 3 20   \n#&gt; 4 30\n\nIn this very small case, you can easily see the missing value ..\nåœ¨è¿™ä¸ªéå¸¸å°çš„æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å¾ˆå®¹æ˜“åœ°çœ‹åˆ°ç¼ºå¤±å€¼ .ã€‚\nBut what happens if you have thousands of rows with only a few missing values represented by .s sprinkled among them?\nä½†æ˜¯ï¼Œå¦‚æœä½ æœ‰æˆåƒä¸Šä¸‡è¡Œæ•°æ®ï¼Œå…¶ä¸­åªæ•£å¸ƒç€å°‘æ•°ç”¨ . è¡¨ç¤ºçš„ç¼ºå¤±å€¼ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ\nOne approach is to tell readr that x is a numeric column, and then see where it fails.\nä¸€ç§æ–¹æ³•æ˜¯å‘Šè¯‰ readr x æ˜¯ä¸€ä¸ªæ•°å€¼åˆ—ï¼Œç„¶åçœ‹å®ƒåœ¨å“ªé‡Œå¤±è´¥ã€‚\nYou can do that with the col_types argument, which takes a named list where the names match the column names in the CSV file:\nä½ å¯ä»¥é€šè¿‡ col_types å‚æ•°æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œå®ƒæ¥å—ä¸€ä¸ªå‘½ååˆ—è¡¨ï¼Œå…¶ä¸­åç§°ä¸ CSV æ–‡ä»¶ä¸­çš„åˆ—ååŒ¹é…ï¼š\n\ndf &lt;- read_csv(\n  simple_csv, \n  col_types = list(x = col_double())\n)\n#&gt; Warning: One or more parsing issues, call `problems()` on your data frame for\n#&gt; details, e.g.:\n#&gt;   dat &lt;- vroom(...)\n#&gt;   problems(dat)\n\nNow read_csv() reports that there was a problem, and tells us we can find out more with problems():\nç°åœ¨ read_csv() æŠ¥å‘Šè¯´æœ‰é—®é¢˜ï¼Œå¹¶å‘Šè¯‰æˆ‘ä»¬å¯ä»¥ç”¨ problems() äº†è§£æ›´å¤šä¿¡æ¯ï¼š\n\nproblems(df)\n#&gt; # A tibble: 1 Ã— 5\n#&gt;     row   col expected actual file                                           \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;                                          \n#&gt; 1     3     1 a double .      C:/Users/14913/AppData/Local/Temp/Rtmp2j43zp/fâ€¦\n\nThis tells us that there was a problem in row 3, col 1 where readr expected a double but got a ..\nè¿™å‘Šè¯‰æˆ‘ä»¬åœ¨ç¬¬ 3 è¡Œç¬¬ 1 åˆ—å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œreadr æœŸæœ›ä¸€ä¸ªåŒç²¾åº¦æµ®ç‚¹æ•° (double)ï¼Œä½†å¾—åˆ°äº†ä¸€ä¸ª .ã€‚\nThat suggests this dataset uses . for missing values.\nè¿™è¡¨æ˜è¯¥æ•°æ®é›†ä½¿ç”¨ . è¡¨ç¤ºç¼ºå¤±å€¼ã€‚\nSo then we set na = \".\", the automatic guessing succeeds, giving us the numeric column that we want:\næ‰€ä»¥æˆ‘ä»¬è®¾ç½® na = \".\"ï¼Œè‡ªåŠ¨çŒœæµ‹æˆåŠŸäº†ï¼Œç»™äº†æˆ‘ä»¬æƒ³è¦çš„æ•°å€¼åˆ—ï¼š\n\nread_csv(simple_csv, na = \".\")\n#&gt; # A tibble: 4 Ã— 1\n#&gt;       x\n#&gt;   &lt;dbl&gt;\n#&gt; 1    10\n#&gt; 2    NA\n#&gt; 3    20\n#&gt; 4    30\n\n\n7.3.3 Column types\nreadr provides a total of nine column types for you to use:\nreadr å…±æä¾›äº†ä¹ç§åˆ—ç±»å‹ä¾›ä½ ä½¿ç”¨ï¼š\n\ncol_logical() and col_double() read logicals and real numbers. Theyâ€™re relatively rarely needed (except as above), since readr will usually guess them for you.col_logical() å’Œ col_double() è¯»å–é€»è¾‘å€¼å’Œå®æ•°ã€‚å®ƒä»¬ç›¸å¯¹è¾ƒå°‘éœ€è¦ï¼ˆé™¤éåƒä¸Šé¢é‚£æ ·ï¼‰ï¼Œå› ä¸º readr é€šå¸¸ä¼šä¸ºä½ çŒœå‡ºå®ƒä»¬ã€‚\ncol_integer() reads integers. We seldom distinguish integers and doubles in this book because theyâ€™re functionally equivalent, but reading integers explicitly can occasionally be useful because they occupy half the memory of doubles.col_integer() è¯»å–æ•´æ•°ã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬å¾ˆå°‘åŒºåˆ†æ•´æ•°å’ŒåŒç²¾åº¦æµ®ç‚¹æ•°ï¼Œå› ä¸ºå®ƒä»¬åœ¨åŠŸèƒ½ä¸Šæ˜¯ç­‰æ•ˆçš„ï¼Œä½†æ˜ç¡®è¯»å–ä¸ºæ•´æ•°æœ‰æ—¶å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒä»¬åªå ç”¨åŒç²¾åº¦æµ®ç‚¹æ•°ä¸€åŠçš„å†…å­˜ã€‚\ncol_character() reads strings. This can be useful to specify explicitly when you have a column that is a numeric identifier, i.e., long series of digits that identifies an object but doesnâ€™t make sense to apply mathematical operations to. Examples include phone numbers, social security numbers, credit card numbers, etc.col_character() è¯»å–å­—ç¬¦ä¸²ã€‚å½“ä½ æœ‰ä¸€ä¸ªä½œä¸ºæ•°å­—æ ‡è¯†ç¬¦çš„åˆ—æ—¶ï¼Œæ˜ç¡®æŒ‡å®šå®ƒä¼šå¾ˆæœ‰ç”¨ï¼Œå³ï¼Œä¸€é•¿ä¸²æ ‡è¯†å¯¹è±¡çš„æ•°å­—ï¼Œä½†å¯¹å…¶åº”ç”¨æ•°å­¦è¿ç®—æ²¡æœ‰æ„ä¹‰ã€‚ä¾‹å¦‚ç”µè¯å·ç ã€ç¤¾ä¼šå®‰å…¨å·ç ã€ä¿¡ç”¨å¡å·ç­‰ã€‚\ncol_factor(), col_date(), and col_datetime() create factors, dates, and date-times respectively; youâ€™ll learn more about those when we get to those data types in Chapter 16 and Chapter 17.col_factor(), col_date() å’Œ col_datetime() åˆ†åˆ«åˆ›å»ºå› å­ã€æ—¥æœŸå’Œæ—¥æœŸæ—¶é—´ï¼›å½“æˆ‘ä»¬åœ¨ Chapter 16 å’Œ Chapter 17 ä¸­è®²åˆ°è¿™äº›æ•°æ®ç±»å‹æ—¶ï¼Œä½ å°†å­¦åˆ°æ›´å¤šç›¸å…³çŸ¥è¯†ã€‚\ncol_number() is a permissive numeric parser that will ignore non-numeric components, and is particularly useful for currencies. Youâ€™ll learn more about it in Chapter 13.col_number() æ˜¯ä¸€ä¸ªå®½å®¹çš„æ•°å­—è§£æå™¨ï¼Œå®ƒä¼šå¿½ç•¥éæ•°å­—éƒ¨åˆ†ï¼Œå¯¹äºè´§å¸ç‰¹åˆ«æœ‰ç”¨ã€‚ä½ å°†åœ¨ Chapter 13 ä¸­å­¦åˆ°æ›´å¤šç›¸å…³çŸ¥è¯†ã€‚\ncol_skip() skips a column so itâ€™s not included in the result, which can be useful for speeding up reading the data if you have a large CSV file and you only want to use some of the columns.col_skip() ä¼šè·³è¿‡ä¸€åˆ—ï¼Œä½¿å…¶ä¸åŒ…å«åœ¨ç»“æœä¸­ï¼Œè¿™åœ¨å¤„ç†å¤§å‹ CSV æ–‡ä»¶ä¸”ä½ åªæƒ³ä½¿ç”¨éƒ¨åˆ†åˆ—æ—¶ï¼Œå¯ä»¥åŠ å¿«æ•°æ®è¯»å–é€Ÿåº¦ã€‚\n\nItâ€™s also possible to override the default column by switching from list() to cols() and specifying .default:\nä¹Ÿå¯ä»¥é€šè¿‡ä» list() åˆ‡æ¢åˆ° cols() å¹¶æŒ‡å®š .default æ¥è¦†ç›–é»˜è®¤çš„åˆ—ç±»å‹ï¼š\n\nanother_csv &lt;- \"\nx,y,z\n1,2,3\"\n\nread_csv(\n  another_csv, \n  col_types = cols(.default = col_character())\n)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     2     3\n\nAnother useful helper is cols_only() which will read in only the columns you specify:\nå¦ä¸€ä¸ªæœ‰ç”¨çš„è¾…åŠ©å‡½æ•°æ˜¯ cols_only()ï¼Œå®ƒå°†åªè¯»å…¥ä½ æŒ‡å®šçš„åˆ—ï¼š\n\nread_csv(\n  another_csv,\n  col_types = cols_only(x = col_character())\n)\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-readr-directory",
    "href": "data-import.html#sec-readr-directory",
    "title": "7Â  Data import",
    "section": "\n7.4 Reading data from multiple files",
    "text": "7.4 Reading data from multiple files\nSometimes your data is split across multiple files instead of being contained in a single file.\næœ‰æ—¶ä½ çš„æ•°æ®åˆ†æ•£åœ¨å¤šä¸ªæ–‡ä»¶ä¸­ï¼Œè€Œä¸æ˜¯åŒ…å«åœ¨å•ä¸ªæ–‡ä»¶ä¸­ã€‚\nFor example, you might have sales data for multiple months, with each monthâ€™s data in a separate file: 01-sales.csv for January, 02-sales.csv for February, and 03-sales.csv for March.\nä¾‹å¦‚ï¼Œä½ å¯èƒ½æœ‰å¤šå€‹æœˆçš„éŠ·å”®æ•¸æ“šï¼Œæ¯å€‹æœˆçš„æ•¸æ“šéƒ½å­˜æ”¾åœ¨ä¸€å€‹å–®ç¨çš„æ–‡ä»¶ä¸­ï¼šä¸€æœˆæ˜¯ 01-sales.csvï¼ŒäºŒæœˆæ˜¯ 02-sales.csvï¼Œä¸‰æœˆæ˜¯ 03-sales.csvã€‚\nWith read_csv() you can read these data in at once and stack them on top of each other in a single data frame.\nä½¿ç”¨ read_csv()ï¼Œä½ å¯ä»¥ä¸€æ¬¡æ€§è¯»å–è¿™äº›æ•°æ®ï¼Œå¹¶å°†å®ƒä»¬å †å åœ¨ä¸€ä¸ªæ•°æ®æ¡†ä¸­ã€‚\n\nsales_files &lt;- c(\"data/01-sales.csv\", \"data/02-sales.csv\", \"data/03-sales.csv\")\nread_csv(sales_files, id = \"file\")\n#&gt; # A tibble: 19 Ã— 6\n#&gt;   file              month    year brand  item     n\n#&gt;   &lt;chr&gt;             &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 data/01-sales.csv January  2019     1  1234     3\n#&gt; 2 data/01-sales.csv January  2019     1  8721     9\n#&gt; 3 data/01-sales.csv January  2019     1  1822     2\n#&gt; 4 data/01-sales.csv January  2019     2  3333     1\n#&gt; 5 data/01-sales.csv January  2019     2  2156     9\n#&gt; 6 data/01-sales.csv January  2019     2  3987     6\n#&gt; # â„¹ 13 more rows\n\nOnce again, the code above will work if you have the CSV files in a data folder in your project.\nåŒæ ·ï¼Œå¦‚æœä½ çš„é¡¹ç›®ä¸­æœ‰ä¸€ä¸ª data æ–‡ä»¶å¤¹ï¼Œå¹¶ä¸”å…¶ä¸­åŒ…å«è¿™äº› CSV æ–‡ä»¶ï¼Œé‚£ä¹ˆä¸Šé¢çš„ä»£ç å°†ä¼šæ­£å¸¸å·¥ä½œã€‚\nYou can download these files from https://pos.it/r4ds-01-sales, https://pos.it/r4ds-02-sales, and https://pos.it/r4ds-03-sales or you can read them directly with:\nä½ å¯ä»¥ä» https://pos.it/r4ds-01-salesã€https://pos.it/r4ds-02-sales å’Œ https://pos.it/r4ds-03-sales ä¸‹è½½è¿™äº›æ–‡ä»¶ï¼Œæˆ–è€…ä½¿ç”¨ä»¥ä¸‹ä»£ç ç›´æ¥è¯»å–å®ƒä»¬ï¼š\n\nsales_files &lt;- c(\n  \"https://pos.it/r4ds-01-sales\",\n  \"https://pos.it/r4ds-02-sales\",\n  \"https://pos.it/r4ds-03-sales\"\n)\nread_csv(sales_files, id = \"file\")\n\nThe id argument adds a new column called file to the resulting data frame that identifies the file the data come from.id å‚æ•°ä¼šå‘ç»“æœæ•°æ®æ¡†ä¸­æ·»åŠ ä¸€ä¸ªåä¸º file çš„æ–°åˆ—ï¼Œç”¨äºæ ‡è¯†æ•°æ®æ¥è‡ªå“ªä¸ªæ–‡ä»¶ã€‚\nThis is especially helpful in circumstances where the files youâ€™re reading in do not have an identifying column that can help you trace the observations back to their original sources.\nå½“ ä½ è¯»å…¥çš„æ–‡ä»¶ä¸­æ²¡æœ‰ä¸€ä¸ªå¯ç”¨äºå°†è§‚æµ‹å€¼è¿½æº¯åˆ°å…¶åŸå§‹æ¥æºçš„æ ‡è¯†åˆ—æ—¶ï¼Œè¿™å°¤å…¶æœ‰ç”¨ã€‚\nIf you have many files you want to read in, it can get cumbersome to write out their names as a list.\nå¦‚æœä½ æœ‰è®¸å¤šæ–‡ä»¶è¦è¯»å…¥ï¼Œå°†å®ƒä»¬çš„åå­—å†™æˆä¸€ä¸ªåˆ—è¡¨å¯èƒ½ä¼šå¾ˆéº»çƒ¦ã€‚\nInstead, you can use the base list.files() function to find the files for you by matching a pattern in the file names.\nç›¸åï¼Œä½ å¯ä»¥ä½¿ç”¨åŸºç¡€å‡½æ•° list.files()ï¼Œé€šè¿‡åŒ¹é…æ–‡ä»¶åä¸­çš„æ¨¡å¼æ¥ä¸ºä½ æŸ¥æ‰¾æ–‡ä»¶ã€‚\nYouâ€™ll learn more about these patterns in Chapter 15.\nä½ å°†åœ¨ Chapter 15 ä¸­å­¦åˆ°æ›´å¤šå…³äºè¿™äº›æ¨¡å¼çš„çŸ¥è¯†ã€‚\n\nsales_files &lt;- list.files(\"data\", pattern = \"sales\\\\.csv$\", full.names = TRUE)\nsales_files\n#&gt; [1] \"data/01-sales.csv\" \"data/02-sales.csv\" \"data/03-sales.csv\"",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-writing-to-a-file",
    "href": "data-import.html#sec-writing-to-a-file",
    "title": "7Â  Data import",
    "section": "\n7.5 Writing to a file",
    "text": "7.5 Writing to a file\nreadr also comes with two useful functions for writing data back to disk: write_csv() and write_tsv().\nreadr è¿˜é™„å¸¦äº†ä¸¤ä¸ªç”¨äºå°†æ•°æ®å†™å›ç£ç›˜çš„æœ‰ç”¨å‡½æ•°ï¼šwrite_csv() å’Œ write_tsv()ã€‚\nThe most important arguments to these functions are x (the data frame to save) and file (the location to save it).\nè¿™äº›å‡½æ•°æœ€é‡è¦çš„å‚æ•°æ˜¯ xï¼ˆè¦ä¿å­˜çš„æ•°æ®æ¡†ï¼‰å’Œ fileï¼ˆä¿å­˜å®ƒçš„ä½ç½®ï¼‰ã€‚\nYou can also specify how missing values are written with na, and if you want to append to an existing file.\nä½ è¿˜å¯ä»¥ç”¨ na æŒ‡å®šç¼ºå¤±å€¼çš„å†™å…¥æ–¹å¼ï¼Œä»¥åŠæ˜¯å¦è¦ appendï¼ˆè¿½åŠ ï¼‰åˆ°ç°æœ‰æ–‡ä»¶ä¸­ã€‚\n\nwrite_csv(students, \"students.csv\")\n\nNow letâ€™s read that csv file back in.\nç°åœ¨è®©æˆ‘ä»¬æŠŠé‚£ä¸ª csv æ–‡ä»¶å†è¯»å›æ¥ã€‚\nNote that the variable type information that you just set up is lost when you save to CSV because youâ€™re starting over with reading from a plain text file again:\nè¯·æ³¨æ„ï¼Œå½“ä½ ä¿å­˜ä¸º CSV æ ¼å¼æ—¶ï¼Œåˆšåˆšè®¾ç½®çš„å˜é‡ç±»å‹ä¿¡æ¯ä¼šä¸¢å¤±ï¼Œå› ä¸ºä½ åˆä»çº¯æ–‡æœ¬æ–‡ä»¶é‡æ–°å¼€å§‹è¯»å–äº†ï¼š\n\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only              6\nwrite_csv(students, \"students-2.csv\")\nread_csv(\"students-2.csv\")\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only              6\n\nThis makes CSVs a little unreliable for caching interim resultsâ€”you need to recreate the column specification every time you load in.\nè¿™ä½¿å¾— CSV å¯¹äºç¼“å­˜ä¸­é—´ç»“æœæœ‰äº›ä¸å¯é â€”â€”æ¯æ¬¡åŠ è½½æ—¶ä½ éƒ½éœ€è¦é‡æ–°åˆ›å»ºåˆ—çš„è§„æ ¼ã€‚\nThere are two main alternatives:\næœ‰ä¸¤ä¸ªä¸»è¦çš„æ›¿ä»£æ–¹æ¡ˆï¼š\n\n\nwrite_rds() and read_rds() are uniform wrappers around the base functions readRDS() and saveRDS(). These store data in Râ€™s custom binary format called RDS. This means that when you reload the object, you are loading the exact same R object that you stored.write_rds() å’Œ read_rds() æ˜¯å¯¹åŸºç¡€å‡½æ•° readRDS() å’Œ saveRDS() çš„ç»Ÿä¸€å°è£…ã€‚å®ƒä»¬ä»¥ R çš„è‡ªå®šä¹‰äºŒè¿›åˆ¶æ ¼å¼ï¼ˆç§°ä¸º RDSï¼‰å­˜å‚¨æ•°æ®ã€‚è¿™æ„å‘³ç€å½“ä½ é‡æ–°åŠ è½½å¯¹è±¡æ—¶ï¼Œä½ åŠ è½½çš„æ˜¯ä¸ä½ å­˜å‚¨çš„å®Œå…¨ç›¸åŒçš„ R å¯¹è±¡ã€‚\n\nwrite_rds(students, \"students.rds\")\nread_rds(\"students.rds\")\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only              6\n\n\n\nThe arrow package allows you to read and write parquet files, a fast binary file format that can be shared across programming languages. Weâ€™ll return to arrow in more depth in Chapter 22.\narrow åŒ…å…è®¸ä½ è¯»å†™ parquet æ–‡ä»¶ï¼Œè¿™æ˜¯ä¸€ç§å¿«é€Ÿçš„äºŒè¿›åˆ¶æ–‡ä»¶æ ¼å¼ï¼Œå¯ä»¥åœ¨ä¸åŒç¼–ç¨‹è¯­è¨€ä¹‹é—´å…±äº«ã€‚æˆ‘ä»¬å°†åœ¨ Chapter 22 ä¸­æ›´æ·±å…¥åœ°æ¢è®¨ arrowã€‚\n\nlibrary(arrow)\nwrite_parquet(students, \"students.parquet\")\nread_parquet(\"students.parquet\")\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name          favourite_food     meal_plan               age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt;              &lt;fct&gt;                 &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann     Strawberry yoghurt Lunch only                4\n#&gt; 2          2 Barclay Lynn       French fries       Lunch only                5\n#&gt; 3          3 Jayendra Lyne      NA                 Breakfast and lunch       7\n#&gt; 4          4 Leon Rossini       Anchovies          Lunch only               NA\n#&gt; 5          5 Chidiegwu Dunkel   Pizza              Breakfast and lunch       5\n#&gt; 6          6 GÃ¼venÃ§ Attila      Ice cream          Lunch only                6\n\n\n\nParquet tends to be much faster than RDS and is usable outside of R, but does require the arrow package.\nParquet æ ¼å¼é€šå¸¸æ¯” RDS å¿«å¾—å¤šï¼Œå¹¶ä¸”å¯ä»¥åœ¨ R ä¹‹å¤–ä½¿ç”¨ï¼Œä½†éœ€è¦ arrow åŒ…ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#data-entry",
    "href": "data-import.html#data-entry",
    "title": "7Â  Data import",
    "section": "\n7.6 Data entry",
    "text": "7.6 Data entry\nSometimes youâ€™ll need to assemble a tibble â€œby handâ€ doing a little data entry in your R script.\næœ‰æ—¶ä½ éœ€è¦åœ¨ R è„šæœ¬ä¸­é€šè¿‡å°‘é‡çš„æ•°æ®å½•å…¥æ¥â€œæ‰‹åŠ¨â€ç»„å»ºä¸€ä¸ª tibbleã€‚\nThere are two useful functions to help you do this which differ in whether you layout the tibble by columns or by rows.\næœ‰ä¸¤ä¸ªæœ‰ç”¨çš„å‡½æ•°å¯ä»¥å¸®åŠ©ä½ åšåˆ°è¿™ä¸€ç‚¹ï¼Œå®ƒä»¬çš„åŒºåˆ«åœ¨äºä½ æ˜¯æŒ‰åˆ—è¿˜æ˜¯æŒ‰è¡Œæ¥å¸ƒå±€ tibbleã€‚\ntibble() works by column:tibble() æŒ‰åˆ—å·¥ä½œï¼š\n\ntibble(\n  x = c(1, 2, 5), \n  y = c(\"h\", \"m\", \"g\"),\n  z = c(0.08, 0.83, 0.60)\n)\n#&gt; # A tibble: 3 Ã— 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6\n\nLaying out the data by column can make it hard to see how the rows are related, so an alternative is tribble(), short for transposed tibble, which lets you lay out your data row by row.\næŒ‰åˆ—å¸ƒå±€æ•°æ®å¯èƒ½å¾ˆéš¾çœ‹æ¸…è¡Œä¸è¡Œä¹‹é—´çš„å…³ç³»ï¼Œæ‰€ä»¥ä¸€ä¸ªæ›¿ä»£æ–¹æ¡ˆæ˜¯ tribble()ï¼Œå³è½¬ç½® tibble (transposed tibble) çš„ç¼©å†™ï¼Œå®ƒè®©ä½ èƒ½å¤Ÿé€è¡Œå¸ƒå±€æ•°æ®ã€‚\ntribble() is customized for data entry in code: column headings start with ~ and entries are separated by commas.tribble() æ˜¯ä¸ºåœ¨ä»£ç ä¸­è¿›è¡Œæ•°æ®å½•å…¥è€Œå®šåˆ¶çš„ï¼šåˆ—æ ‡é¢˜ä»¥ ~ å¼€å¤´ï¼Œæ¡ç›®ä¹‹é—´ç”¨é€—å·åˆ†éš”ã€‚\nThis makes it possible to lay out small amounts of data in an easy to read form:\nè¿™ä½¿å¾—ä»¥æ˜“äºé˜…è¯»çš„å½¢å¼å¸ƒç½®å°‘é‡æ•°æ®æˆä¸ºå¯èƒ½ï¼š\n\ntribble(\n  ~x, ~y, ~z,\n  1, \"h\", 0.08,\n  2, \"m\", 0.83,\n  5, \"g\", 0.60\n)\n#&gt; # A tibble: 3 Ã— 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#summary",
    "href": "data-import.html#summary",
    "title": "7Â  Data import",
    "section": "\n7.7 Summary",
    "text": "7.7 Summary\nIn this chapter, youâ€™ve learned how to load CSV files with read_csv() and to do your own data entry with tibble() and tribble().\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¼šäº†å¦‚ä½•ä½¿ç”¨ read_csv() åŠ è½½ CSV æ–‡ä»¶ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ tibble() å’Œ tribble() è¿›è¡Œè‡ªå·±çš„æ•°æ®å½•å…¥ã€‚\nYouâ€™ve learned how csv files work, some of the problems you might encounter, and how to overcome them.\nä½ å·²ç»äº†è§£äº† csv æ–‡ä»¶çš„å·¥ä½œåŸç†ï¼Œå¯èƒ½ä¼šé‡åˆ°çš„ä¸€äº›é—®é¢˜ï¼Œä»¥åŠå¦‚ä½•å…‹æœå®ƒä»¬ã€‚\nWeâ€™ll come to data import a few times in this book: Chapter 20 from Excel and Google Sheets, Chapter 21 will show you how to load data from databases, Chapter 22 from parquet files, Chapter 23 from JSON, and Chapter 24 from websites.\nåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¼šå¤šæ¬¡æ¶‰åŠæ•°æ®å¯¼å…¥ï¼šChapter 20 ä»‹ç»ä» Excel å’Œ Google Sheets å¯¼å…¥ï¼ŒChapter 21 å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä»æ•°æ®åº“åŠ è½½æ•°æ®ï¼ŒChapter 22 ä» parquet æ–‡ä»¶å¯¼å…¥ï¼ŒChapter 23 ä» JSON å¯¼å…¥ï¼Œä»¥åŠ Chapter 24 ä»ç½‘ç«™å¯¼å…¥ã€‚\nWeâ€™re just about at the end of this section of the book, but thereâ€™s one important last topic to cover: how to get help.\næˆ‘ä»¬å³å°†ç»“æŸæœ¬ä¹¦çš„è¿™ä¸€éƒ¨åˆ†ï¼Œä½†è¿˜æœ‰ä¸€ä¸ªé‡è¦çš„æœ€åä¸»é¢˜éœ€è¦æ¶µç›–ï¼šå¦‚ä½•è·å–å¸®åŠ©ã€‚\nSo in the next chapter, youâ€™ll learn some good places to look for help, how to create a reprex to maximize your chances of getting good help, and some general advice on keeping up with the world of R.\nå› æ­¤ï¼Œåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œä½ å°†å­¦åˆ°ä¸€äº›å¯»æ±‚å¸®åŠ©çš„å¥½åœ°æ–¹ï¼Œå¦‚ä½•åˆ›å»ºä¸€ä¸ªå¯å¤ç°çš„ä¾‹å­ (reprex) æ¥æœ€å¤§åŒ–ä½ è·å¾—æœ‰æ•ˆå¸®åŠ©çš„æœºä¼šï¼Œä»¥åŠä¸€äº›å…³äºè·Ÿä¸Š R ä¸–ç•Œå‘å±•æ­¥ä¼çš„é€šç”¨å»ºè®®ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#footnotes",
    "href": "data-import.html#footnotes",
    "title": "7Â  Data import",
    "section": "",
    "text": "The janitor package is not part of the tidyverse, but it offers handy functions for data cleaning and works well within data pipelines that use |&gt;.â†©ï¸\nYou can override the default of 1000 with the guess_max argument.â†©ï¸",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "workflow-help.html",
    "href": "workflow-help.html",
    "title": "8Â  Workflow: getting help",
    "section": "",
    "text": "8.1 Google is your friend\nThis book is not an island; there is no single resource that will allow you to master R. As you begin to apply the techniques described in this book to your own data, you will soon find questions that we do not answer. This section describes a few tips on how to get help and to help you keep learning.\næœ¬ä¹¦ä¸æ˜¯ä¸€åº§å­¤å²›ï¼›æ²¡æœ‰ä»»ä½•å•ä¸€èµ„æºèƒ½è®©ä½ ç²¾é€š Rã€‚ å½“ä½ å¼€å§‹å°†æœ¬ä¹¦ä¸­æè¿°çš„æŠ€æœ¯åº”ç”¨äºä½ è‡ªå·±çš„æ•°æ®æ—¶ï¼Œä½ å¾ˆå¿«å°±ä¼šå‘ç°æˆ‘ä»¬æ²¡æœ‰å›ç­”çš„é—®é¢˜ã€‚ æœ¬èŠ‚å°†ä»‹ç»ä¸€äº›è·å–å¸®åŠ©ä»¥åŠå¸®åŠ©ä½ æŒç»­å­¦ä¹ çš„æŠ€å·§ã€‚\nIf you get stuck, start with Google. Typically adding â€œRâ€ to a query is enough to restrict it to relevant results: if the search isnâ€™t useful, it often means that there arenâ€™t any R-specific results available. Additionally, adding package names like â€œtidyverseâ€ or â€œggplot2â€ will help narrow down the results to code that will feel more familiar to you as well, e.g., â€œhow to make a boxplot in Râ€ vs.Â â€œhow to make a boxplot in R with ggplot2â€. Google is particularly useful for error messages. If you get an error message and you have no idea what it means, try googling it! Chances are that someone else has been confused by it in the past, and there will be help somewhere on the web. (If the error message isnâ€™t in English, run Sys.setenv(LANGUAGE = \"en\") and re-run the code; youâ€™re more likely to find help for English error messages.)\nå¦‚æœä½ é‡åˆ°å›°éš¾ï¼Œä» Google å¼€å§‹ã€‚ é€šå¸¸ï¼Œåœ¨æŸ¥è¯¢ä¸­æ·»åŠ  â€œRâ€ å°±è¶³ä»¥å°†å…¶é™åˆ¶åœ¨ç›¸å…³çš„ç»“æœä¸­ï¼šå¦‚æœæœç´¢ç»“æœä¸ç†æƒ³ï¼Œè¿™é€šå¸¸æ„å‘³ç€æ²¡æœ‰ R ç‰¹å®šçš„ç»“æœå¯ç”¨ã€‚ æ­¤å¤–ï¼Œæ·»åŠ åƒ â€œtidyverseâ€ æˆ– â€œggplot2â€ è¿™æ ·çš„åŒ…åä¹Ÿä¼šå¸®åŠ©ä½ å°†ç»“æœç¼©å°åˆ°ä½ æ›´ç†Ÿæ‚‰çš„ä»£ç ï¼Œä¾‹å¦‚ï¼Œâ€œhow to make a boxplot in Râ€ å¯¹æ¯” â€œhow to make a boxplot in R with ggplot2â€ã€‚ Google å¯¹äºé”™è¯¯ä¿¡æ¯å°¤å…¶æœ‰ç”¨ã€‚ å¦‚æœä½ æ”¶åˆ°ä¸€æ¡é”™è¯¯ä¿¡æ¯ï¼Œå¹¶ä¸”ä¸çŸ¥é“å®ƒæ˜¯ä»€ä¹ˆæ„æ€ï¼Œè¯•è¯•ç”¨ Google æœç´¢å®ƒï¼ å¾ˆå¯èƒ½è¿‡å»æœ‰å…¶ä»–äººä¹Ÿå¯¹æ­¤æ„Ÿåˆ°å›°æƒ‘ï¼Œç½‘ä¸ŠæŸä¸ªåœ°æ–¹ä¼šæœ‰å¸®åŠ©ã€‚ ï¼ˆå¦‚æœé”™è¯¯ä¿¡æ¯ä¸æ˜¯è‹±æ–‡çš„ï¼Œè¿è¡Œ Sys.setenv(LANGUAGE = \"en\") å¹¶é‡æ–°è¿è¡Œä»£ç ï¼›ä½ æ›´æœ‰å¯èƒ½æ‰¾åˆ°è‹±æ–‡é”™è¯¯ä¿¡æ¯çš„å¸®åŠ©ã€‚ï¼‰\nIf Google doesnâ€™t help, try Stack Overflow. Start by spending a little time searching for an existing answer, including [R], to restrict your search to questions and answers that use R.\nå¦‚æœ Google å¸®ä¸äº†ä½ ï¼Œè¯•è¯• Stack Overflowã€‚ é¦–å…ˆèŠ±ç‚¹æ—¶é—´æœç´¢ç°æœ‰çš„ç­”æ¡ˆï¼Œè®°å¾—åŠ ä¸Š [R]ï¼Œå°†ä½ çš„æœç´¢é™åˆ¶åœ¨ä½¿ç”¨ R çš„é—®é¢˜å’Œç­”æ¡ˆä¸Šã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Workflow: getting help</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#making-a-reprex",
    "href": "workflow-help.html#making-a-reprex",
    "title": "8Â  Workflow: getting help",
    "section": "\n8.2 Making a reprex",
    "text": "8.2 Making a reprex\nIf your googling doesnâ€™t find anything useful, itâ€™s a really good idea to prepare a reprex, short for minimal reproducible example. A good reprex makes it easier for other people to help you, and often youâ€™ll figure out the problem yourself in the course of making it. There are two parts to creating a reprex:\nå¦‚æœä½ çš„ Google æœç´¢æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰ç”¨çš„ä¸œè¥¿ï¼Œé‚£ä¹ˆå‡†å¤‡ä¸€ä¸ª reprex (æœ€å°å¯å¤ç°ç¤ºä¾‹çš„ç¼©å†™) æ˜¯ä¸ªéå¸¸å¥½çš„ä¸»æ„ã€‚ ä¸€ä¸ªå¥½çš„ reprex èƒ½è®©å…¶ä»–äººæ›´å®¹æ˜“å¸®åŠ©ä½ ï¼Œè€Œä¸”é€šå¸¸åœ¨åˆ¶ä½œ reprex çš„è¿‡ç¨‹ä¸­ä½ å°±èƒ½è‡ªå·±æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ã€‚ åˆ›å»º reprex æœ‰ä¸¤ä¸ªéƒ¨åˆ†ï¼š\n\nFirst, you need to make your code reproducible. This means that you need to capture everything, i.e.Â include any library() calls and create all necessary objects. The easiest way to make sure youâ€™ve done this is using the reprex package.\né¦–å…ˆï¼Œä½ éœ€è¦è®©ä½ çš„ä»£ç å¯å¤ç°ã€‚ è¿™æ„å‘³ç€ä½ éœ€è¦æ•è·æ‰€æœ‰ä¸œè¥¿ï¼Œå³åŒ…å«ä»»ä½• library() è°ƒç”¨å¹¶åˆ›å»ºæ‰€æœ‰å¿…è¦çš„å¯¹è±¡ã€‚ ç¡®ä¿åšåˆ°è¿™ä¸€ç‚¹æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ reprex åŒ…ã€‚\nSecond, you need to make it minimal. Strip away everything that is not directly related to your problem. This usually involves creating a much smaller and simpler R object than the one youâ€™re facing in real life or even using built-in data.\nå…¶æ¬¡ï¼Œä½ éœ€è¦è®©å®ƒæœ€å°åŒ–ã€‚ å‰”é™¤æ‰€æœ‰ä¸ä½ çš„é—®é¢˜ä¸ç›´æ¥ç›¸å…³çš„ä¸œè¥¿ã€‚ è¿™é€šå¸¸æ¶‰åŠåˆ›å»ºä¸€ä¸ªæ¯”ä½ ç°å®ç”Ÿæ´»ä¸­é¢ä¸´çš„ R å¯¹è±¡å°å¾—å¤šã€ç®€å•å¾—å¤šçš„å¯¹è±¡ï¼Œç”šè‡³ä½¿ç”¨å†…ç½®æ•°æ®ã€‚\n\nThat sounds like a lot of work! And it can be, but it has a great payoff:\nè¿™å¬èµ·æ¥å·¥ä½œé‡å¾ˆå¤§ï¼ äº‹å®å¯èƒ½å¦‚æ­¤ï¼Œä½†å®ƒæœ‰å·¨å¤§çš„å›æŠ¥ï¼š\n\n80% of the time, creating an excellent reprex reveals the source of your problem. Itâ€™s amazing how often the process of writing up a self-contained and minimal example allows you to answer your own question.\n80% çš„æƒ…å†µä¸‹ï¼Œåˆ›å»ºä¸€ä¸ªå‡ºè‰²çš„ reprex ä¼šæ­ç¤ºä½ é—®é¢˜çš„æ ¹æºã€‚ ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œç¼–å†™ä¸€ä¸ªç‹¬ç«‹çš„æœ€å°ç¤ºä¾‹çš„è¿‡ç¨‹å¸¸å¸¸èƒ½è®©ä½ è‡ªå·±å›ç­”è‡ªå·±çš„é—®é¢˜ã€‚\nThe other 20% of the time, you will have captured the essence of your problem in a way that is easy for others to play with. This substantially improves your chances of getting help!\nå¦å¤– 20% çš„æƒ…å†µä¸‹ï¼Œä½ å°†ä»¥ä¸€ç§ä¾¿äºä»–äººæ“ä½œçš„æ–¹å¼æŠ“ä½äº†é—®é¢˜çš„æœ¬è´¨ã€‚ è¿™å¤§å¤§æé«˜äº†ä½ è·å¾—å¸®åŠ©çš„æœºä¼šï¼\n\nWhen creating a reprex by hand, itâ€™s easy to accidentally miss something, meaning your code canâ€™t be run on someone elseâ€™s computer. Avoid this problem by using the reprex package, which is installed as part of the tidyverse. Letâ€™s say you copy this code onto your clipboard (or, on RStudio Server or Cloud, select it):\nå½“æ‰‹åŠ¨åˆ›å»º reprex æ—¶ï¼Œå¾ˆå®¹æ˜“ä¸å°å¿ƒæ¼æ‰æŸäº›ä¸œè¥¿ï¼Œè¿™æ„å‘³ç€ä½ çš„ä»£ç æ— æ³•åœ¨åˆ«äººçš„ç”µè„‘ä¸Šè¿è¡Œã€‚ é€šè¿‡ä½¿ç”¨ reprex åŒ…å¯ä»¥é¿å…è¿™ä¸ªé—®é¢˜ï¼Œè¯¥åŒ…æ˜¯ä½œä¸º tidyverse çš„ä¸€éƒ¨åˆ†å®‰è£…çš„ã€‚ å‡è®¾ä½ å°†è¿™æ®µä»£ç å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼ˆæˆ–è€…ï¼Œåœ¨ RStudio Server æˆ– Cloud ä¸Šï¼Œé€‰ä¸­å®ƒï¼‰ï¼š\n\ny &lt;- 1:4\nmean(y)\n\nThen call reprex(), where the default output is formatted for GitHub:\nç„¶åè°ƒç”¨ reprex()ï¼Œå…¶é»˜è®¤è¾“å‡ºæ ¼å¼æ˜¯ä¸º GitHub å‡†å¤‡çš„ï¼š\nreprex::reprex()\nA nicely rendered HTML preview will display in RStudioâ€™s Viewer (if youâ€™re in RStudio) or your default browser otherwise. The reprex is automatically copied to your clipboard (on RStudio Server or Cloud, you will need to copy this yourself):\nä¸€ä¸ªæ¸²æŸ“ç²¾ç¾çš„ HTML é¢„è§ˆå°†æ˜¾ç¤ºåœ¨ RStudio çš„ Viewer çª—æ ¼ä¸­ï¼ˆå¦‚æœä½ åœ¨ RStudio ä¸­ï¼‰æˆ–è€…ä½ çš„é»˜è®¤æµè§ˆå™¨ä¸­ã€‚ reprex ä¼šè‡ªåŠ¨å¤åˆ¶åˆ°ä½ çš„å‰ªè´´æ¿ï¼ˆåœ¨ RStudio Server æˆ– Cloud ä¸Šï¼Œä½ éœ€è¦è‡ªå·±å¤åˆ¶ï¼‰ï¼š\n``` r\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n```\nThis text is formatted in a special way, called Markdown, which can be pasted to sites like StackOverflow or Github and they will automatically render it to look like code. Hereâ€™s what that Markdown would look like rendered on GitHub:\nè¿™æ®µæ–‡æœ¬ä»¥ä¸€ç§ç‰¹æ®Šçš„æ–¹å¼æ ¼å¼åŒ–ï¼Œç§°ä¸º Markdownï¼Œå¯ä»¥ç²˜è´´åˆ°åƒ StackOverflow æˆ– Github è¿™æ ·çš„ç½‘ç«™ä¸Šï¼Œå®ƒä»¬ä¼šè‡ªåŠ¨å°†å…¶æ¸²æŸ“æˆä»£ç çš„æ ·å­ã€‚ ä»¥ä¸‹æ˜¯è¯¥ Markdown åœ¨ GitHub ä¸Šæ¸²æŸ“åçš„æ ·å­ï¼š\n\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n\nAnyone else can copy, paste, and run this immediately.\nä»»ä½•å…¶ä»–äººéƒ½å¯ä»¥ç«‹å³å¤åˆ¶ã€ç²˜è´´å¹¶è¿è¡Œè¿™æ®µä»£ç ã€‚\nThere are three things you need to include to make your example reproducible: required packages, data, and code.\nè¦ä½¿ä½ çš„ç¤ºä¾‹å¯å¤ç°ï¼Œä½ éœ€è¦åŒ…å«ä¸‰æ ·ä¸œè¥¿ï¼šæ‰€éœ€çš„åŒ…ã€æ•°æ®å’Œä»£ç ã€‚\n\nPackages should be loaded at the top of the script so itâ€™s easy to see which ones the example needs. This is a good time to check that youâ€™re using the latest version of each package; you may have discovered a bug thatâ€™s been fixed since you installed or last updated the package. For packages in the tidyverse, the easiest way to check is to run tidyverse_update().åŒ… (Packages) åº”è¯¥åœ¨è„šæœ¬çš„é¡¶éƒ¨åŠ è½½ï¼Œè¿™æ ·å¯ä»¥å¾ˆå®¹æ˜“åœ°çœ‹åˆ°ç¤ºä¾‹éœ€è¦å“ªäº›åŒ…ã€‚ è¿™æ˜¯ä¸€ä¸ªæ£€æŸ¥ä½ æ˜¯å¦æ­£åœ¨ä½¿ç”¨æ¯ä¸ªåŒ…æœ€æ–°ç‰ˆæœ¬çš„å¥½æ—¶æœºï¼›ä½ å¯èƒ½å‘ç°äº†ä¸€ä¸ªåœ¨ä½ å®‰è£…æˆ–ä¸Šæ¬¡æ›´æ–°åŒ…ä¹‹åå·²ç»è¢«ä¿®å¤çš„ bugã€‚ å¯¹äº tidyverse ä¸­çš„åŒ…ï¼Œæœ€ç®€å•çš„æ£€æŸ¥æ–¹æ³•æ˜¯è¿è¡Œ tidyverse_update()ã€‚\n\nThe easiest way to include data is to use dput() to generate the R code needed to recreate it. For example, to recreate the mtcars dataset in R, perform the following steps:\nåŒ…å« æ•°æ® (data) æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ dput() ç”Ÿæˆé‡ç°æ•°æ®æ‰€éœ€çš„ R ä»£ç ã€‚ ä¾‹å¦‚ï¼Œè¦åœ¨ R ä¸­é‡ç° mtcars æ•°æ®é›†ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š\n\nRun dput(mtcars) in R\nCopy the output\nIn reprex, type mtcars &lt;-, then paste.\n\nTry to use the smallest subset of your data that still reveals the problem.\nå°½é‡ä½¿ç”¨ä»èƒ½æ­ç¤ºé—®é¢˜çš„æœ€å°æ•°æ®å­é›†ã€‚\n\n\nSpend a little bit of time ensuring that your code is easy for others to read:\nèŠ±ä¸€ç‚¹æ—¶é—´ç¡®ä¿ä½ çš„ ä»£ç  (code) ä¾¿äºä»–äººé˜…è¯»ï¼š\n\nMake sure youâ€™ve used spaces and your variable names are concise yet informative.\nç¡®ä¿ä½ ä½¿ç”¨äº†ç©ºæ ¼ï¼Œå¹¶ä¸”ä½ çš„å˜é‡åç®€æ´è€Œä¿¡æ¯ä¸°å¯Œã€‚\nUse comments to indicate where your problem lies.\nä½¿ç”¨æ³¨é‡Šæ¥æŒ‡å‡ºä½ çš„é—®é¢˜æ‰€åœ¨ã€‚\nDo your best to remove everything that is not related to the problem.\nå°½åŠ›åˆ é™¤æ‰€æœ‰ä¸é—®é¢˜æ— å…³çš„å†…å®¹ã€‚\n\nThe shorter your code is, the easier it is to understand and the easier it is to fix.\nä½ çš„ä»£ç è¶ŠçŸ­ï¼Œå°±è¶Šå®¹æ˜“ç†è§£ï¼Œä¹Ÿè¶Šå®¹æ˜“ä¿®å¤ã€‚\n\n\nFinish by checking that you have actually made a reproducible example by starting a fresh R session and copying and pasting your script.\næœ€åï¼Œé€šè¿‡å¯åŠ¨ä¸€ä¸ªæ–°çš„ R ä¼šè¯å¹¶å¤åˆ¶ç²˜è´´ä½ çš„è„šæœ¬ï¼Œæ¥æ£€æŸ¥ä½ æ˜¯å¦ç¡®å®åˆ›å»ºäº†ä¸€ä¸ªå¯å¤ç°çš„ç¤ºä¾‹ã€‚\nCreating reprexes is not trivial, and it will take some practice to learn to create good, truly minimal reprexes. However, learning to ask questions that include the code, and investing the time to make it reproducible will continue to pay off as you learn and master R.\nåˆ›å»º reprex å¹¶éæ˜“äº‹ï¼Œéœ€è¦ä¸€äº›ç»ƒä¹ æ‰èƒ½å­¦ä¼šåˆ›å»ºå¥½çš„ã€çœŸæ­£æœ€å°åŒ–çš„ reprexã€‚ ç„¶è€Œï¼Œå­¦ä¼šæå‡ºåŒ…å«ä»£ç çš„é—®é¢˜ï¼Œå¹¶æŠ•å…¥æ—¶é—´ä½¿å…¶å¯å¤ç°ï¼Œå°†åœ¨ä½ å­¦ä¹ å’ŒæŒæ¡ R çš„è¿‡ç¨‹ä¸­æŒç»­å¸¦æ¥å›æŠ¥ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Workflow: getting help</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#investing-in-yourself",
    "href": "workflow-help.html#investing-in-yourself",
    "title": "8Â  Workflow: getting help",
    "section": "\n8.3 Investing in yourself",
    "text": "8.3 Investing in yourself\nYou should also spend some time preparing yourself to solve problems before they occur. Investing a little time in learning R each day will pay off handsomely in the long run. One way is to follow what the tidyverse team is doing on the tidyverse blog. To keep up with the R community more broadly, we recommend reading R Weekly: itâ€™s a community effort to aggregate the most interesting news in the R community each week.\nä½ ä¹Ÿåº”è¯¥èŠ±ä¸€äº›æ—¶é—´ä¸ºè‡ªå·±åšå¥½å‡†å¤‡ï¼Œä»¥ä¾¿åœ¨é—®é¢˜å‘ç”Ÿå‰å°±èƒ½è§£å†³å®ƒä»¬ã€‚ æ¯å¤©æŠ•å…¥ä¸€ç‚¹æ—¶é—´å­¦ä¹  Rï¼Œä»é•¿è¿œæ¥çœ‹å°†è·å¾—ä¸°åšçš„å›æŠ¥ã€‚ ä¸€ç§æ–¹æ³•æ˜¯åœ¨ tidyverse åšå®¢ ä¸Šå…³æ³¨ tidyverse å›¢é˜Ÿçš„åŠ¨æ€ã€‚ ä¸ºäº†æ›´å¹¿æ³›åœ°äº†è§£ R ç¤¾åŒºçš„åŠ¨æ€ï¼Œæˆ‘ä»¬æ¨èé˜…è¯» R Weeklyï¼šè¿™æ˜¯ä¸€ä¸ªç¤¾åŒºé¡¹ç›®ï¼Œæ¯å‘¨æ±‡æ€» R ç¤¾åŒºæœ€æœ‰è¶£çš„æ–°é—»ã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Workflow: getting help</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#summary",
    "href": "workflow-help.html#summary",
    "title": "8Â  Workflow: getting help",
    "section": "\n8.4 Summary",
    "text": "8.4 Summary\nThis chapter concludes the Whole Game part of the book. Youâ€™ve now seen the most important parts of the data science process: visualization, transformation, tidying and importing. Now youâ€™ve got a holistic view of the whole process, and we start to get into the details of small pieces.\næœ¬ç« ç»“æŸäº†æœ¬ä¹¦çš„â€œå…¨å±€æ¦‚è§ˆâ€éƒ¨åˆ†ã€‚ ä½ ç°åœ¨å·²ç»çœ‹åˆ°äº†æ•°æ®ç§‘å­¦æµç¨‹ä¸­æœ€é‡è¦çš„éƒ¨åˆ†ï¼šå¯è§†åŒ–ã€è½¬æ¢ã€æ•´ç†å’Œå¯¼å…¥ã€‚ ç°åœ¨ä½ å¯¹æ•´ä¸ªæµç¨‹æœ‰äº†å…¨é¢çš„äº†è§£ï¼Œæˆ‘ä»¬å°†å¼€å§‹æ·±å…¥æ¢è®¨å„ä¸ªå°éƒ¨åˆ†çš„ç»†èŠ‚ã€‚\nThe next part of the book, Visualize, does a deeper dive into the grammar of graphics and creating data visualizations with ggplot2, showcases how to use the tools youâ€™ve learned so far to conduct exploratory data analysis, and introduces good practices for creating plots for communication.\næœ¬ä¹¦çš„ä¸‹ä¸€éƒ¨åˆ†â€œå¯è§†åŒ–â€ï¼Œå°†æ›´æ·±å…¥åœ°æ¢è®¨å›¾å½¢è¯­æ³•å’Œä½¿ç”¨ ggplot2 åˆ›å»ºæ•°æ®å¯è§†åŒ–ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨ä½ ç›®å‰å­¦åˆ°çš„å·¥å…·è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æï¼Œå¹¶ä»‹ç»åˆ›å»ºç”¨äºäº¤æµçš„å›¾è¡¨çš„è‰¯å¥½å®è·µã€‚",
    "crumbs": [
      "Whole game",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Workflow: getting help</span>"
    ]
  },
  {
    "objectID": "visualize.html",
    "href": "visualize.html",
    "title": "Visualize",
    "section": "",
    "text": "After reading the first part of the book, you understand (at least superficially) the most important tools for doing data science. Now itâ€™s time to start diving into the details. In this part of the book, youâ€™ll learn about visualizing data in further depth.\nè¯»å®Œæœ¬ä¹¦çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œä½ å·²ç»ï¼ˆè‡³å°‘è¡¨é¢ä¸Šï¼‰äº†è§£äº†æ•°æ®ç§‘å­¦ä¸­æœ€é‡è¦çš„å·¥å…·ã€‚ ç°åœ¨æ˜¯æ—¶å€™å¼€å§‹æ·±å…¥ç»†èŠ‚äº†ã€‚ åœ¨æœ¬ä¹¦çš„è¿™ä¸€éƒ¨åˆ†ï¼Œä½ å°†æ›´æ·±å…¥åœ°å­¦ä¹ æ•°æ®å¯è§†åŒ–ã€‚\n\n\n\n\n\n\n\nFigureÂ 1: Data visualization is often the first step in data exploration.  æ•°æ®å¯è§†åŒ–é€šå¸¸æ˜¯æ•°æ®æ¢ç´¢çš„ç¬¬ä¸€æ­¥ã€‚\n\n\n\n\nEach chapter addresses one to a few aspects of creating a data visualization.\næ¯ä¸€ç« éƒ½ä¼šè®¨è®ºåˆ›å»ºæ•°æ®å¯è§†åŒ–çš„ä¸€åˆ°å‡ ä¸ªæ–¹é¢ã€‚\n\nIn 9Â  Layers you will learn about the layered grammar of graphics.\nåœ¨ 9Â  Layers ä¸­ï¼Œä½ å°†å­¦ä¹ åˆ†å±‚å›¾å½¢è¯­æ³•ã€‚\nIn 10Â  Exploratory data analysis, youâ€™ll combine visualization with your curiosity and skepticism to ask and answer interesting questions about data.\nåœ¨ 10Â  Exploratory data analysis ä¸­ï¼Œä½ å°†æŠŠå¯è§†åŒ–ä¸ä½ çš„å¥½å¥‡å¿ƒå’Œæ€€ç–‘ç²¾ç¥ç»“åˆèµ·æ¥ï¼Œå¯¹æ•°æ®æå‡ºå¹¶å›ç­”æœ‰è¶£çš„é—®é¢˜ã€‚\nFinally, in 11Â  Communication you will learn how to take your exploratory graphics, elevate them, and turn them into expository graphics, graphics that help the newcomer to your analysis understand whatâ€™s going on as quickly and easily as possible.\næœ€åï¼Œåœ¨ 11Â  Communication ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å°†ä½ çš„æ¢ç´¢æ€§å›¾å½¢è¿›è¡Œå‡åï¼Œå°†å®ƒä»¬è½¬å˜ä¸ºè§£é‡Šæ€§å›¾å½¢ï¼Œå³èƒ½å¸®åŠ©åˆæ¬¡æ¥è§¦ä½ åˆ†æçš„äººå°½å¯èƒ½å¿«é€Ÿã€è½»æ¾åœ°ç†è§£åˆ†æå†…å®¹çš„å›¾å½¢ã€‚\n\nThese three chapters get you started in the world of visualization, but there is much more to learn. The absolute best place to learn more is the ggplot2 book: ggplot2: Elegant graphics for data analysis. It goes into much more depth about the underlying theory, and has many more examples of how to combine the individual pieces to solve practical problems. Another great resource is the ggplot2 extensions gallery https://exts.ggplot2.tidyverse.org/gallery/. This site lists many of the packages that extend ggplot2 with new geoms and scales. Itâ€™s a great place to start if youâ€™re trying to do something that seems hard with ggplot2.\nè¿™ä¸‰ç« ä¸ºä½ å¼€å¯äº†å¯è§†åŒ–ä¸–ç•Œçš„å¤§é—¨ï¼Œä½†è¿˜æœ‰å¾ˆå¤šä¸œè¥¿éœ€è¦å­¦ä¹ ã€‚ å­¦ä¹ æ›´å¤šçŸ¥è¯†çš„æœ€ä½³å»å¤„æ˜¯ ggplot2 çš„ä¹¦ç±ï¼šggplot2: Elegant graphics for data analysisã€‚ å®ƒæ›´æ·±å…¥åœ°æ¢è®¨äº†åº•å±‚ç†è®ºï¼Œå¹¶æä¾›äº†æ›´å¤šå…³äºå¦‚ä½•ç»„åˆå„ä¸ªéƒ¨åˆ†æ¥è§£å†³å®é™…é—®é¢˜çš„ä¾‹å­ã€‚ å¦ä¸€ä¸ªå¾ˆæ£’çš„èµ„æºæ˜¯ ggplot2 æ‰©å±•åŒ…çš„å±•å»Š https://exts.ggplot2.tidyverse.org/gallery/ã€‚ è¿™ä¸ªç½‘ç«™åˆ—å‡ºäº†è®¸å¤šç”¨æ–°çš„å‡ ä½•å¯¹è±¡ (geoms) å’Œæ ‡åº¦ (scales) æ‰©å±• ggplot2 çš„åŒ…ã€‚ å¦‚æœä½ æƒ³ç”¨ ggplot2 åšä¸€äº›çœ‹èµ·æ¥å¾ˆå›°éš¾çš„äº‹æƒ…ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚",
    "crumbs": [
      "Visualize"
    ]
  },
  {
    "objectID": "layers.html",
    "href": "layers.html",
    "title": "9Â  Layers",
    "section": "",
    "text": "9.1 Introduction\nIn Chapter 1, you learned much more than just how to make scatterplots, bar charts, and boxplots. You learned a foundation that you can use to make any type of plot with ggplot2.\nåœ¨ Chapter 1 ä¸­ï¼Œä½ å­¦åˆ°çš„è¿œä¸æ­¢å¦‚ä½•åˆ¶ä½œæ•£ç‚¹å›¾ã€æ¡å½¢å›¾å’Œç®±çº¿å›¾ã€‚ä½ å­¦åˆ°äº†ä¸€ä¸ªå¯ä»¥ç”¨ ggplot2 åˆ¶ä½œä»»ä½•ç±»å‹å›¾è¡¨çš„åŸºç¡€ã€‚\nIn this chapter, youâ€™ll expand on that foundation as you learn about the layered grammar of graphics. Weâ€™ll start with a deeper dive into aesthetic mappings, geometric objects, and facets. Then, you will learn about statistical transformations ggplot2 makes under the hood when creating a plot. These transformations are used to calculate new values to plot, such as the heights of bars in a bar plot or medians in a box plot. You will also learn about position adjustments, which modify how geoms are displayed in your plots. Finally, weâ€™ll briefly introduce coordinate systems.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†é€šè¿‡å­¦ä¹ åˆ†å±‚å›¾å½¢è¯­æ³•æ¥æ‰©å±•è¿™ä¸€åŸºç¡€ã€‚æˆ‘ä»¬å°†ä»æ·±å…¥æ¢è®¨ç¾å­¦æ˜ å°„ (aesthetic mappings)ã€å‡ ä½•å¯¹è±¡ (geometric objects) å’Œåˆ†é¢ (facets) å¼€å§‹ã€‚ç„¶åï¼Œä½ å°†å­¦ä¹  ggplot2 åœ¨åˆ›å»ºå›¾è¡¨æ—¶åœ¨åº•å±‚è¿›è¡Œçš„ç»Ÿè®¡å˜æ¢ (statistical transformations)ã€‚è¿™äº›å˜æ¢ç”¨äºè®¡ç®—è¦ç»˜åˆ¶çš„æ–°å€¼ï¼Œä¾‹å¦‚æ¡å½¢å›¾ä¸­æ¡å½¢çš„é«˜åº¦æˆ–ç®±çº¿å›¾ä¸­çš„ä¸­ä½æ•°ã€‚ä½ è¿˜å°†å­¦ä¹ ä½ç½®è°ƒæ•´ (position adjustments)ï¼Œå®ƒå¯ä»¥ä¿®æ”¹å‡ ä½•å¯¹è±¡åœ¨å›¾è¡¨ä¸­çš„æ˜¾ç¤ºæ–¹å¼ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ç®€è¦ä»‹ç»åæ ‡ç³» (coordinate systems)ã€‚\nWe will not cover every single function and option for each of these layers, but we will walk you through the most important and commonly used functionality provided by ggplot2 as well as introduce you to packages that extend ggplot2.\næˆ‘ä»¬ä¸ä¼šæ¶µç›–è¿™äº›å›¾å±‚ä¸­çš„æ¯ä¸€ä¸ªå‡½æ•°å’Œé€‰é¡¹ï¼Œä½†æˆ‘ä»¬ä¼šå¼•å¯¼ä½ äº†è§£ ggplot2 æä¾›çš„æœ€é‡è¦å’Œæœ€å¸¸ç”¨çš„åŠŸèƒ½ï¼Œå¹¶å‘ä½ ä»‹ç»æ‰©å±• ggplot2 çš„åŒ…ã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#introduction",
    "href": "layers.html#introduction",
    "title": "9Â  Layers",
    "section": "",
    "text": "9.1.1 Prerequisites\nThis chapter focuses on ggplot2. To access the datasets, help pages, and functions used in this chapter, load the tidyverse by running this code:\næœ¬ç« é‡ç‚¹ä»‹ç» ggplot2ã€‚è¦è®¿é—®æœ¬ç« ä¸­ä½¿ç”¨çš„æ•°æ®é›†ã€å¸®åŠ©é¡µé¢å’Œå‡½æ•°ï¼Œè¯·è¿è¡Œä»¥ä¸‹ä»£ç åŠ è½½ tidyverseï¼š\n\nlibrary(tidyverse)",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#aesthetic-mappings",
    "href": "layers.html#aesthetic-mappings",
    "title": "9Â  Layers",
    "section": "\n9.2 Aesthetic mappings",
    "text": "9.2 Aesthetic mappings\n\nâ€œThe greatest value of a picture is when it forces us to notice what we never expected to see.â€ â€” John Tukey\nâ€œä¸€å›¾èƒœåƒè¨€ï¼Œå°¤å…¶æ˜¯åœ¨å®ƒè¿«ä½¿æˆ‘ä»¬æ³¨æ„åˆ°æˆ‘ä»¬ä»æœªé¢„æ–™åˆ°çš„äº‹ç‰©æ—¶ã€‚â€ â€” çº¦ç¿°Â·å›¾åŸº (John Tukey)\n\nRemember that the mpg data frame bundled with the ggplot2 package contains 234 observations on 38 car models.\nè¯·è®°ä½ï¼Œggplot2 åŒ…ä¸­é™„å¸¦çš„ mpg æ•°æ®æ¡†åŒ…å« 234 æ¡å…³äº 38 ç§è½¦å‹çš„è§‚æµ‹æ•°æ®ã€‚\n\nmpg\n#&gt; # A tibble: 234 Ã— 11\n#&gt;   manufacturer model displ  year   cyl trans      drv     cty   hwy fl   \n#&gt;   &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n#&gt; 1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p    \n#&gt; 2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p    \n#&gt; 3 audi         a4      2    2008     4 manual(m6) f        20    31 p    \n#&gt; 4 audi         a4      2    2008     4 auto(av)   f        21    30 p    \n#&gt; 5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p    \n#&gt; 6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p    \n#&gt; # â„¹ 228 more rows\n#&gt; # â„¹ 1 more variable: class &lt;chr&gt;\n\nAmong the variables in mpg are:mpg æ•°æ®é›†ä¸­çš„å˜é‡åŒ…æ‹¬ï¼š\n\ndispl: A carâ€™s engine size, in liters. A numerical variable.displï¼šæ±½è½¦çš„å‘åŠ¨æœºå°ºå¯¸ï¼Œå•ä½ä¸ºå‡ã€‚\nè¿™æ˜¯ä¸€ä¸ªæ•°å€¼å˜é‡ã€‚\nhwy: A carâ€™s fuel efficiency on the highway, in miles per gallon (mpg). A car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distance. A numerical variable.hwyï¼šæ±½è½¦åœ¨é«˜é€Ÿå…¬è·¯ä¸Šçš„ç‡ƒæ²¹æ•ˆç‡ï¼Œå•ä½ä¸ºè‹±é‡Œ/åŠ ä»‘ (mpg)ã€‚\nå½“è¡Œé©¶ç›¸åŒè·ç¦»æ—¶ï¼Œç‡ƒæ²¹æ•ˆç‡ä½çš„æ±½è½¦æ¯”ç‡ƒæ²¹æ•ˆç‡é«˜çš„æ±½è½¦æ¶ˆè€—æ›´å¤šçš„ç‡ƒæ–™ã€‚\nè¿™æ˜¯ä¸€ä¸ªæ•°å€¼å˜é‡ã€‚\nclass: Type of car. A categorical variable.classï¼šæ±½è½¦ç±»å‹ã€‚\nè¿™æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡ã€‚\n\nLetâ€™s start by visualizing the relationship between displ and hwy for various classes of cars. We can do this with a scatterplot where the numerical variables are mapped to the x and y aesthetics and the categorical variable is mapped to an aesthetic like color or shape.\nè®©æˆ‘ä»¬ä»å¯è§†åŒ–ä¸åŒ class ç±»å‹æ±½è½¦çš„ displ å’Œ hwy ä¹‹é—´çš„å…³ç³»å¼€å§‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ•£ç‚¹å›¾æ¥å®ç°ï¼Œå…¶ä¸­æ•°å€¼å˜é‡æ˜ å°„åˆ° x å’Œ y ç¾å­¦å±æ€§ï¼Œè€Œåˆ†ç±»å˜é‡æ˜ å°„åˆ°åƒ color æˆ– shape è¿™æ ·çš„ç¾å­¦å±æ€§ã€‚\n# Left\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point()\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, shape = class)) +\n  geom_point()\n#&gt; Warning: The shape palette can deal with a maximum of 6 discrete values because more\n#&gt; than 6 becomes difficult to discriminate\n#&gt; â„¹ you have requested 7 values. Consider specifying shapes manually if you\n#&gt;   need that many of them.\n#&gt; Warning: Removed 62 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nWhen class is mapped to shape, we get two warnings:\nå½“ class æ˜ å°„åˆ° shape æ—¶ï¼Œæˆ‘ä»¬ä¼šæ”¶åˆ°ä¸¤ä¸ªè­¦å‘Šï¼š\n\n1: The shape palette can deal with a maximum of 6 discrete values because more than 6 becomes difficult to discriminate; you have 7. Consider specifying shapes manually if you must have them.\nå½¢çŠ¶è°ƒè‰²æ¿æœ€å¤šåªèƒ½å¤„ç† 6 ä¸ªç¦»æ•£å€¼ï¼Œå› ä¸ºè¶…è¿‡ 6 ä¸ªå°±å¾ˆéš¾åŒºåˆ†äº†ï¼›è€Œä½ æœ‰ 7 ä¸ªã€‚å¦‚æœå¿…é¡»ä½¿ç”¨å®ƒä»¬ï¼Œè¯·è€ƒè™‘æ‰‹åŠ¨æŒ‡å®šå½¢çŠ¶ã€‚\n2: Removed 62 rows containing missing values (geom_point()).\nç§»é™¤äº† 62 è¡ŒåŒ…å«ç¼ºå¤±å€¼çš„æ•°æ® (geom_point())ã€‚\n\nSince ggplot2 will only use six shapes at a time, by default, additional groups will go unplotted when you use the shape aesthetic. The second warning is related â€“ there are 62 SUVs in the dataset and theyâ€™re not plotted.\nç”±äº ggplot2 é»˜è®¤ä¸€æ¬¡åªä½¿ç”¨å…­ç§å½¢çŠ¶ï¼Œå› æ­¤å½“ä½ ä½¿ç”¨å½¢çŠ¶ç¾å­¦æ—¶ï¼Œé¢å¤–çš„åˆ†ç»„å°†ä¸ä¼šè¢«ç»˜åˆ¶å‡ºæ¥ã€‚ç¬¬äºŒä¸ªè­¦å‘Šä¸æ­¤ç›¸å…³â€”â€”æ•°æ®é›†ä¸­æœ‰ 62 è¾† SUV æ²¡æœ‰è¢«ç»˜åˆ¶ã€‚\nSimilarly, we can map class to size or alpha aesthetics as well, which control the size and the transparency of the points, respectively.\nåŒæ ·ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å°† class æ˜ å°„åˆ° size æˆ– alpha ç¾å­¦ï¼Œå®ƒä»¬åˆ†åˆ«æ§åˆ¶ç‚¹çš„å¤§å°å’Œé€æ˜åº¦ã€‚\n# Left\nggplot(mpg, aes(x = displ, y = hwy, size = class)) +\n  geom_point()\n#&gt; Warning: Using size for a discrete variable is not advised.\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, alpha = class)) +\n  geom_point()\n#&gt; Warning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\nBoth of these produce warnings as well:\nè¿™ä¸¤è€…ä¹Ÿéƒ½ä¼šäº§ç”Ÿè­¦å‘Šï¼š\n\nUsing alpha for a discrete variable is not advised. ä¸å»ºè®®å¯¹ç¦»æ•£å˜é‡ä½¿ç”¨ alphaã€‚\n\nMapping an unordered discrete (categorical) variable (class) to an ordered aesthetic (size or alpha) is generally not a good idea because it implies a ranking that does not in fact exist.\nå°†ä¸€ä¸ªæ— åºçš„ç¦»æ•£ï¼ˆåˆ†ç±»ï¼‰å˜é‡ï¼ˆclassï¼‰æ˜ å°„åˆ°ä¸€ä¸ªæœ‰åºçš„ç¾å­¦å±æ€§ï¼ˆsize æˆ– alphaï¼‰é€šå¸¸ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå› ä¸ºå®ƒæš—ç¤ºäº†ä¸€ä¸ªå®é™…ä¸Šä¸å­˜åœ¨çš„æ’åºã€‚\nOnce you map an aesthetic, ggplot2 takes care of the rest. It selects a reasonable scale to use with the aesthetic, and it constructs a legend that explains the mapping between levels and values. For x and y aesthetics, ggplot2 does not create a legend, but it creates an axis line with tick marks and a label. The axis line provides the same information as a legend; it explains the mapping between locations and values.\nä¸€æ—¦ä½ æ˜ å°„äº†ä¸€ä¸ªç¾å­¦å±æ€§ï¼Œggplot2 ä¼šå¤„ç†å‰©ä¸‹çš„äº‹æƒ…ã€‚å®ƒä¼šé€‰æ‹©ä¸€ä¸ªåˆç†çš„æ ‡åº¦ä¸è¯¥ç¾å­¦å±æ€§ä¸€èµ·ä½¿ç”¨ï¼Œå¹¶æ„å»ºä¸€ä¸ªå›¾ä¾‹æ¥è§£é‡Šçº§åˆ«å’Œå€¼ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚å¯¹äº x å’Œ y ç¾å­¦å±æ€§ï¼Œggplot2 ä¸ä¼šåˆ›å»ºå›¾ä¾‹ï¼Œä½†ä¼šåˆ›å»ºå¸¦æœ‰åˆ»åº¦çº¿å’Œæ ‡ç­¾çš„åæ ‡è½´ã€‚åæ ‡è½´çº¿æä¾›äº†ä¸å›¾ä¾‹ç›¸åŒçš„ä¿¡æ¯ï¼›å®ƒè§£é‡Šäº†ä½ç½®å’Œå€¼ä¹‹é—´çš„æ˜ å°„ã€‚\nYou can also set the visual properties of your geom manually as an argument of your geom function (outside of aes()) instead of relying on a variable mapping to determine the appearance. For example, we can make all of the points in our plot blue:\nä½ ä¹Ÿå¯ä»¥åœ¨å‡ ä½•å¯¹è±¡å‡½æ•°ä¸­æ‰‹åŠ¨è®¾ç½®å…¶è§†è§‰å±æ€§ä½œä¸ºå‚æ•°ï¼ˆåœ¨ aes() ä¹‹å¤–ï¼‰ï¼Œè€Œä¸æ˜¯ä¾èµ–å˜é‡æ˜ å°„æ¥å†³å®šå¤–è§‚ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°†å›¾ä¸­çš„æ‰€æœ‰ç‚¹éƒ½è®¾ç½®ä¸ºè“è‰²ï¼š\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(color = \"blue\")\n\n\n\n\n\n\n\nHere, the color doesnâ€™t convey information about a variable, but only changes the appearance of the plot. Youâ€™ll need to pick a value that makes sense for that aesthetic:\nåœ¨è¿™é‡Œï¼Œé¢œè‰²å¹¶ä¸ä¼ è¾¾å…³äºå˜é‡çš„ä¿¡æ¯ï¼Œè€Œåªæ˜¯æ”¹å˜äº†å›¾è¡¨çš„å¤–è§‚ã€‚ä½ éœ€è¦ä¸ºè¯¥ç¾å­¦é€‰æ‹©ä¸€ä¸ªæœ‰æ„ä¹‰çš„å€¼ï¼š\n\nThe name of a color as a character string, e.g., color = \"blue\"\nä½œä¸ºå­—ç¬¦â€‹â€‹ä¸²çš„é¢œè‰²åç§°ï¼Œä¾‹å¦‚ color = \"blue\"\nThe size of a point in mm, e.g., size = 1 ä»¥æ¯«ç±³ä¸ºå•ä½çš„ç‚¹çš„å¤§å°ï¼Œä¾‹å¦‚ size = 1\nThe shape of a point as a number, e.g, shape = 1, as shown in FigureÂ 9.1.\nç‚¹çš„å½¢çŠ¶ï¼Œä»¥æ•°å­—è¡¨ç¤ºï¼Œä¾‹å¦‚ shape = 1ï¼Œå¦‚ FigureÂ 9.1 æ‰€ç¤ºã€‚\n\n\n\n\n\n\n\n\nFigureÂ 9.1: R has 26 built-in shapes that are identified by numbers. There are some seeming duplicates: for example, 0, 15, and 22 are all squares. The difference comes from the interaction of the color and fill aesthetics. The hollow shapes (0â€“14) have a border determined by color; the solid shapes (15â€“20) are filled with color; the filled shapes (21â€“25) have a border of color and are filled with fill. Shapes are arranged to keep similar shapes next to each other.\n\n\n\nR æœ‰ 26 ç§å†…ç½®å½¢çŠ¶ï¼Œç”¨æ•°å­—æ ‡è¯†ã€‚æœ‰äº›å½¢çŠ¶çœ‹èµ·æ¥é‡å¤äº†ï¼šä¾‹å¦‚ï¼Œ0ã€15 å’Œ 22 éƒ½æ˜¯æ­£æ–¹å½¢ã€‚åŒºåˆ«åœ¨äº color å’Œ fill ç¾å­¦çš„äº¤äº’ä½œç”¨ã€‚ç©ºå¿ƒå½¢çŠ¶ (0â€“14) çš„è¾¹æ¡†ç”± color å†³å®šï¼›å®å¿ƒå½¢çŠ¶ (15â€“20) ç”± color å¡«å……ï¼›å¡«å……å½¢çŠ¶ (21â€“25) çš„è¾¹æ¡†æ˜¯ colorï¼Œå¡«å……æ˜¯ fillã€‚å½¢çŠ¶çš„æ’åˆ—æ˜¯ä¸ºäº†è®©ç›¸ä¼¼çš„å½¢çŠ¶å½¼æ­¤ç›¸é‚»ã€‚\nSo far we have discussed aesthetics that we can map or set in a scatterplot, when using a point geom. You can learn more about all possible aesthetic mappings in the aesthetic specifications vignette at https://ggplot2.tidyverse.org/articles/ggplot2-specs.html.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»è®¨è®ºäº†åœ¨ä½¿ç”¨ç‚¹å‡ ä½•å¯¹è±¡æ—¶ï¼Œå¯ä»¥åœ¨æ•£ç‚¹å›¾ä¸­æ˜ å°„æˆ–è®¾ç½®çš„ç¾å­¦ã€‚ä½ å¯ä»¥åœ¨ç¾å­¦è§„èŒƒå°å“æ–‡ https://ggplot2.tidyverse.org/articles/ggplot2-specs.html ä¸­äº†è§£æ›´å¤šå…³äºæ‰€æœ‰å¯èƒ½çš„ç¾å­¦æ˜ å°„ã€‚\nThe specific aesthetics you can use for a plot depend on the geom you use to represent the data. In the next section we dive deeper into geoms.\nä½ å¯ä»¥ç”¨äºç»˜å›¾çš„ç‰¹å®šç¾å­¦å–å†³äºä½ ç”¨æ¥è¡¨ç¤ºæ•°æ®çš„å‡ ä½•å¯¹è±¡ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ›´æ·±å…¥åœ°æ¢è®¨å‡ ä½•å¯¹è±¡ã€‚\n\n9.2.1 Exercises\n\nCreate a scatterplot of hwy vs.Â displ where the points are pink filled in triangles.\n\nWhy did the following code not result in a plot with blue points?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = \"blue\"))\n\n\nWhat does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point)\nWhat happens if you map an aesthetic to something other than a variable name, like aes(color = displ &lt; 5)? Note, youâ€™ll also need to specify x and y.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#sec-geometric-objects",
    "href": "layers.html#sec-geometric-objects",
    "title": "9Â  Layers",
    "section": "\n9.3 Geometric objects",
    "text": "9.3 Geometric objects\nHow are these two plots similar?\nè¿™ä¸¤å¹…å›¾æœ‰ä½•ç›¸ä¼¼ä¹‹å¤„ï¼Ÿ\n\n\n\n\n\n\n\n\n\n\nBoth plots contain the same x variable, the same y variable, and both describe the same data. But the plots are not identical. Each plot uses a different geometric object, geom, to represent the data. The plot on the left uses the point geom, and the plot on the right uses the smooth geom, a smooth line fitted to the data.\nä¸¤å¼ å›¾éƒ½åŒ…å«ç›¸åŒçš„ x å˜é‡ï¼Œç›¸åŒçš„ y å˜é‡ï¼Œå¹¶ä¸”éƒ½æè¿°äº†ç›¸åŒçš„æ•°æ®ã€‚ä½†è¿™ä¸¤å¼ å›¾å¹¶ä¸å®Œå…¨ç›¸åŒã€‚æ¯å¼ å›¾éƒ½ä½¿ç”¨ä¸åŒçš„å‡ ä½•å¯¹è±¡ï¼ˆgeomï¼‰æ¥è¡¨ç¤ºæ•°æ®ã€‚å·¦è¾¹çš„å›¾ä½¿ç”¨äº†ç‚¹å‡ ä½•å¯¹è±¡ï¼ˆpoint geomï¼‰ï¼Œå³è¾¹çš„å›¾ä½¿ç”¨äº†å¹³æ»‘å‡ ä½•å¯¹è±¡ï¼ˆsmooth geomï¼‰ï¼Œå³ä¸€æ¡æ‹Ÿåˆæ•°æ®çš„å¹³æ»‘æ›²çº¿ã€‚\nTo change the geom in your plot, change the geom function that you add to ggplot(). For instance, to make the plots above, you can use the following code:\nè¦æ›´æ”¹ç»˜å›¾ä¸­çš„å‡ ä½•å¯¹è±¡ï¼Œè¯·æ›´æ”¹æ·»åŠ åˆ° ggplot() çš„å‡ ä½•å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œè¦åˆ¶ä½œä¸Šé¢çš„å›¾ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_smooth()\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nEvery geom function in ggplot2 takes a mapping argument, either defined locally in the geom layer or globally in the ggplot() layer. However, not every aesthetic works with every geom. You could set the shape of a point, but you couldnâ€™t set the â€œshapeâ€ of a line. If you try, ggplot2 will silently ignore that aesthetic mapping. On the other hand, you could set the linetype of a line. geom_smooth() will draw a different line, with a different linetype, for each unique value of the variable that you map to linetype.\nggplot2 ä¸­çš„æ¯ä¸ªå‡ ä½•å‡½æ•°éƒ½æ¥å—ä¸€ä¸ª mapping å‚æ•°ï¼Œè¯¥å‚æ•°å¯ä»¥åœ¨å‡ ä½•å±‚ä¸­å±€éƒ¨å®šä¹‰ï¼Œä¹Ÿå¯ä»¥åœ¨ ggplot() å±‚ä¸­å…¨å±€å®šä¹‰ã€‚ç„¶è€Œï¼Œå¹¶éæ¯ä¸ªç¾å­¦éƒ½é€‚ç”¨äºæ¯ä¸ªå‡ ä½•å¯¹è±¡ã€‚ä½ å¯ä»¥è®¾ç½®ç‚¹çš„å½¢çŠ¶ï¼Œä½†ä¸èƒ½è®¾ç½®çº¿çš„â€œå½¢çŠ¶â€ã€‚å¦‚æœä½ å°è¯•è¿™æ ·åšï¼Œggplot2 ä¼šé»˜é»˜åœ°å¿½ç•¥è¯¥ç¾å­¦æ˜ å°„ã€‚å¦ä¸€æ–¹é¢ï¼Œä½ å¯ä»¥è®¾ç½®çº¿çš„çº¿å‹ã€‚geom_smooth() ä¼šä¸ºæ˜ å°„åˆ°çº¿å‹çš„å˜é‡çš„æ¯ä¸ªå”¯ä¸€å€¼ç»˜åˆ¶ä¸€æ¡ä¸åŒçš„çº¿ï¼Œå¹¶å…·æœ‰ä¸åŒçš„çº¿å‹ã€‚\n# Left\nggplot(mpg, aes(x = displ, y = hwy, shape = drv)) + \n  geom_smooth()\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, linetype = drv)) + \n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\nHere, geom_smooth() separates the cars into three lines based on their drv value, which describes a carâ€™s drive train. One line describes all of the points that have a 4 value, one line describes all of the points that have an f value, and one line describes all of the points that have an r value. Here, 4 stands for four-wheel drive, f for front-wheel drive, and r for rear-wheel drive.\nåœ¨è¿™é‡Œï¼Œgeom_smooth() æ ¹æ®æ±½è½¦çš„ drv å€¼ï¼ˆæè¿°æ±½è½¦çš„é©±åŠ¨ç³»ç»Ÿï¼‰å°†æ±½è½¦åˆ†ä¸ºä¸‰æ¡çº¿ã€‚ä¸€æ¡çº¿æè¿°æ‰€æœ‰ drv å€¼ä¸º 4 çš„ç‚¹ï¼Œä¸€æ¡çº¿æè¿°æ‰€æœ‰å€¼ä¸º f çš„ç‚¹ï¼Œå¦ä¸€æ¡çº¿æè¿°æ‰€æœ‰å€¼ä¸º r çš„ç‚¹ã€‚è¿™é‡Œï¼Œ4 ä»£è¡¨å››è½®é©±åŠ¨ (four-wheel drive)ï¼Œf ä»£è¡¨å‰è½®é©±åŠ¨ (front-wheel drive)ï¼Œr ä»£è¡¨åè½®é©±åŠ¨ (rear-wheel drive)ã€‚\nIf this sounds strange, we can make it clearer by overlaying the lines on top of the raw data and then coloring everything according to drv.\nå¦‚æœè¿™å¬èµ·æ¥æœ‰äº›å¥‡æ€ªï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†çº¿æ¡å åŠ åœ¨åŸå§‹æ•°æ®ä¹‹ä¸Šï¼Œç„¶åæ ¹æ® drv å¯¹æ‰€æœ‰å†…å®¹è¿›è¡Œç€è‰²ï¼Œä½¿å…¶æ›´åŠ æ¸…æ™°ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) + \n  geom_point() +\n  geom_smooth(aes(linetype = drv))\n\n\n\n\n\n\n\nNotice that this plot contains two geoms in the same graph.\næ³¨æ„ï¼Œæ­¤å›¾åœ¨åŒä¸€å¼ å›¾è¡¨ä¸­åŒ…å«äº†ä¸¤ç§å‡ ä½•å¯¹è±¡ã€‚\nMany geoms, like geom_smooth(), use a single geometric object to display multiple rows of data. For these geoms, you can set the group aesthetic to a categorical variable to draw multiple objects. ggplot2 will draw a separate object for each unique value of the grouping variable. In practice, ggplot2 will automatically group the data for these geoms whenever you map an aesthetic to a discrete variable (as in the linetype example). It is convenient to rely on this feature because the group aesthetic by itself does not add a legend or distinguishing features to the geoms.\nè®¸å¤šå‡ ä½•å¯¹è±¡ï¼ˆgeomsï¼‰ï¼Œå¦‚ geom_smooth()ï¼Œä½¿ç”¨å•ä¸ªå‡ ä½•å¯¹è±¡æ¥æ˜¾ç¤ºå¤šè¡Œæ•°æ®ã€‚å¯¹äºè¿™äº›å‡ ä½•å¯¹è±¡ï¼Œæ‚¨å¯ä»¥å°† group ç¾å­¦è®¾ç½®ä¸ºåˆ†ç±»å˜é‡ä»¥ç»˜åˆ¶å¤šä¸ªå¯¹è±¡ã€‚ggplot2 å°†ä¸ºåˆ†ç»„å˜é‡çš„æ¯ä¸ªå”¯ä¸€å€¼ç»˜åˆ¶ä¸€ä¸ªå•ç‹¬çš„å¯¹è±¡ã€‚åœ¨å®è·µä¸­ï¼Œåªè¦æ‚¨å°†ç¾å­¦æ˜ å°„åˆ°ç¦»æ•£å˜é‡ï¼ˆå¦‚ linetype ç¤ºä¾‹ä¸­ï¼‰ï¼Œggplot2 å°±ä¼šè‡ªåŠ¨ä¸ºè¿™äº›å‡ ä½•å¯¹è±¡åˆ†ç»„æ•°æ®ã€‚ä¾èµ–æ­¤åŠŸèƒ½å¾ˆæ–¹ä¾¿ï¼Œå› ä¸º group ç¾å­¦æœ¬èº«ä¸ä¼šä¸ºå‡ ä½•å¯¹è±¡æ·»åŠ å›¾ä¾‹æˆ–åŒºåˆ†ç‰¹å¾ã€‚\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth()\n\n# Middle\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(group = drv))\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you place mappings in a geom function, ggplot2 will treat them as local mappings for the layer. It will use these mappings to extend or overwrite the global mappings for that layer only. This makes it possible to display different aesthetics in different layers.\nå¦‚æœä½ å°†æ˜ å°„æ”¾ç½®åœ¨ geom å‡½æ•°ä¸­ï¼Œggplot2 ä¼šå°†å®ƒä»¬è§†ä¸ºè¯¥å›¾å±‚çš„å±€éƒ¨æ˜ å°„ã€‚å®ƒå°†ä½¿ç”¨è¿™äº›æ˜ å°„æ¥æ‰©å±•æˆ–è¦†ç›–ä»…è¯¥å›¾å±‚çš„å…¨å±€æ˜ å°„ã€‚è¿™ä½¿å¾—åœ¨ä¸åŒå›¾å±‚ä¸­æ˜¾ç¤ºä¸åŒçš„ç¾å­¦æˆä¸ºå¯èƒ½ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(aes(color = class)) + \n  geom_smooth()\n\n\n\n\n\n\n\nYou can use the same idea to specify different data for each layer. Here, we use red points as well as open circles to highlight two-seater cars. The local data argument in geom_point() overrides the global data argument in ggplot() for that layer only.\næ‚¨å¯ä»¥ä½¿ç”¨ç›¸åŒçš„æ€è·¯ä¸ºæ¯ä¸ªå›¾å±‚æŒ‡å®šä¸åŒçš„ dataã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨çº¢ç‚¹å’Œç©ºå¿ƒåœ†æ¥çªå‡ºæ˜¾ç¤ºåŒåº§æ±½è½¦ã€‚geom_point() ä¸­çš„å±€éƒ¨æ•°æ®å‚æ•°ä»…è¦†ç›– ggplot() ä¸­è¯¥å›¾å±‚çš„å…¨å±€æ•°æ®å‚æ•°ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    color = \"red\"\n  ) +\n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    shape = \"circle open\", size = 3, color = \"red\"\n  )\n\n\n\n\n\n\n\nGeoms are the fundamental building blocks of ggplot2. You can completely transform the look of your plot by changing its geom, and different geoms can reveal different features of your data. For example, the histogram and density plot below reveal that the distribution of highway mileage is bimodal and right skewed while the boxplot reveals two potential outliers.\nGeoms æ˜¯ ggplot2 çš„åŸºæœ¬æ„å»ºå—ã€‚æ‚¨å¯ä»¥é€šè¿‡æ›´æ”¹å…¶ geom æ¥å®Œå…¨æ”¹å˜ç»˜å›¾çš„å¤–è§‚ï¼Œä¸åŒçš„ geoms å¯ä»¥æ­ç¤ºæ‚¨æ•°æ®çš„ä¸åŒç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„ç›´æ–¹å›¾å’Œå¯†åº¦å›¾æ˜¾ç¤ºé«˜é€Ÿå…¬è·¯é‡Œç¨‹çš„åˆ†å¸ƒæ˜¯åŒå³°å’Œå³åçš„ï¼Œè€Œç®±çº¿å›¾åˆ™æ­ç¤ºäº†ä¸¤ä¸ªæ½œåœ¨çš„å¼‚å¸¸å€¼ã€‚\n# Left\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram(binwidth = 2)\n\n# Middle\nggplot(mpg, aes(x = hwy)) +\n  geom_density()\n\n# Right\nggplot(mpg, aes(x = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2 provides more than 40 geoms but these donâ€™t cover all possible plots one could make. If you need a different geom, we recommend looking into extension packages first to see if someone else has already implemented it (see https://exts.ggplot2.tidyverse.org/gallery/ for a sampling). For example, the ggridges package (https://wilkelab.org/ggridges) is useful for making ridgeline plots, which can be useful for visualizing the density of a numerical variable for different levels of a categorical variable. In the following plot not only did we use a new geom (geom_density_ridges()), but we have also mapped the same variable to multiple aesthetics (drv to y, fill, and color) as well as set an aesthetic (alpha = 0.5) to make the density curves transparent.\nggplot2 æä¾›äº† 40 å¤šç§å‡ ä½•å¯¹è±¡ï¼Œä½†è¿™äº›å¹¶ä¸èƒ½æ¶µç›–æ‰€æœ‰å¯èƒ½åˆ¶ä½œçš„å›¾è¡¨ã€‚å¦‚æœæ‚¨éœ€è¦ä¸€ç§ä¸åŒçš„å‡ ä½•å¯¹è±¡ï¼Œæˆ‘ä»¬å»ºè®®é¦–å…ˆæŸ¥çœ‹æ‰©å±•åŒ…ï¼Œçœ‹æ˜¯å¦æœ‰äººå·²ç»å®ç°äº†å®ƒï¼ˆå‚è§ https://exts.ggplot2.tidyverse.org/gallery/ ä»¥è·å–ç¤ºä¾‹ï¼‰ã€‚ä¾‹å¦‚ï¼Œggridges åŒ…ï¼ˆhttps://wilkelab.org/ggridgesï¼‰å¯¹äºåˆ¶ä½œå±±è„Šçº¿å›¾éå¸¸æœ‰ç”¨ï¼Œè¿™å¯¹äºå¯è§†åŒ–ä¸€ä¸ªæ•°å€¼å˜é‡åœ¨ä¸åŒåˆ†ç±»å˜é‡æ°´å¹³ä¸‹çš„å¯†åº¦éå¸¸æœ‰ç”¨ã€‚åœ¨ä¸‹é¢çš„å›¾è¡¨ä¸­ï¼Œæˆ‘ä»¬ä¸ä»…ä½¿ç”¨äº†ä¸€ä¸ªæ–°çš„å‡ ä½•å¯¹è±¡ï¼ˆgeom_density_ridges()ï¼‰ï¼Œè¿˜å°†åŒä¸€ä¸ªå˜é‡æ˜ å°„åˆ°äº†å¤šä¸ªç¾å­¦å±æ€§ï¼ˆå°† drv æ˜ å°„åˆ° yã€fill å’Œ colorï¼‰ï¼Œå¹¶ä¸”è®¾ç½®äº†ä¸€ä¸ªç¾å­¦å±æ€§ï¼ˆalpha = 0.5ï¼‰æ¥ä½¿å¯†åº¦æ›²çº¿é€æ˜ã€‚\n\nlibrary(ggridges)\n\nggplot(mpg, aes(x = hwy, y = drv, fill = drv, color = drv)) +\n  geom_density_ridges(alpha = 0.5, show.legend = FALSE)\n#&gt; Picking joint bandwidth of 1.28\n\n\n\n\n\n\n\nThe best place to get a comprehensive overview of all of the geoms ggplot2 offers, as well as all functions in the package, is the reference page: https://ggplot2.tidyverse.org/reference. To learn more about any single geom, use the help (e.g., ?geom_smooth).\nè¦å…¨é¢äº†è§£ ggplot2 æä¾›çš„æ‰€æœ‰å‡ ä½•å¯¹è±¡ä»¥åŠåŒ…ä¸­çš„æ‰€æœ‰å‡½æ•°ï¼Œæœ€å¥½çš„åœ°æ–¹æ˜¯å‚è€ƒé¡µé¢ï¼šhttps://ggplot2.tidyverse.org/referenceã€‚è¦äº†è§£ä»»ä½•å•ä¸ªå‡ ä½•å¯¹è±¡ï¼Œè¯·ä½¿ç”¨å¸®åŠ©ï¼ˆä¾‹å¦‚ï¼Œ?geom_smoothï¼‰ã€‚\n\n9.3.1 Exercises\n\nWhat geom would you use to draw a line chart? A boxplot? A histogram? An area chart?\n\nEarlier in this chapter we used show.legend without explaining it:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\nWhat does show.legend = FALSE do here? What happens if you remove it? Why do you think we used it earlier?\n\nWhat does the se argument to geom_smooth() do?\n\nRecreate the R code necessary to generate the following graphs. Note that wherever a categorical variable is used in the plot, itâ€™s drv.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#facets",
    "href": "layers.html#facets",
    "title": "9Â  Layers",
    "section": "\n9.4 Facets",
    "text": "9.4 Facets\nIn Chapter 1 you learned about faceting with facet_wrap(), which splits a plot into subplots that each display one subset of the data based on a categorical variable.\nåœ¨ Chapter 1 ä¸­ï¼Œä½ å­¦ä¹ äº†ä½¿ç”¨ facet_wrap() è¿›è¡Œåˆ†é¢ï¼Œè¯¥å‡½æ•°æ ¹æ®ä¸€ä¸ªåˆ†ç±»å˜é‡å°†å›¾è¡¨åˆ†å‰²æˆå¤šä¸ªå­å›¾ï¼Œæ¯ä¸ªå­å›¾æ˜¾ç¤ºæ•°æ®çš„ä¸€ä¸ªå­é›†ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_wrap(~cyl)\n\n\n\n\n\n\n\nTo facet your plot with the combination of two variables, switch from facet_wrap() to facet_grid(). The first argument of facet_grid() is also a formula, but now itâ€™s a double sided formula: rows ~ cols.\nè¦ä½¿ç”¨ä¸¤ä¸ªå˜é‡çš„ç»„åˆå¯¹å›¾è¡¨è¿›è¡Œåˆ†é¢ï¼Œè¯·ä» facet_wrap() åˆ‡æ¢åˆ° facet_grid()ã€‚facet_grid() çš„ç¬¬ä¸€ä¸ªå‚æ•°ä¹Ÿæ˜¯ä¸€ä¸ªå…¬å¼ï¼Œä½†ç°åœ¨å®ƒæ˜¯ä¸€ä¸ªåŒè¾¹å…¬å¼ï¼šrows ~ colsã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl)\n\n\n\n\n\n\n\nBy default each of the facets share the same scale and range for x and y axes. This is useful when you want to compare data across facets but it can be limiting when you want to visualize the relationship within each facet better. Setting the scales argument in a faceting function to \"free_x\" will allow for different scales of x-axis across columns, \"free_y\" will allow for different scales on y-axis across rows, and \"free\" will allow both.\né»˜è®¤æƒ…å†µä¸‹ï¼Œæ¯ä¸ªåˆ†é¢å…±äº«ç›¸åŒçš„ x è½´å’Œ y è½´åˆ»åº¦åŠèŒƒå›´ã€‚å½“æ‚¨æƒ³åœ¨ä¸åŒåˆ†é¢ä¹‹é—´æ¯”è¾ƒæ•°æ®æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ï¼Œä½†å½“æ‚¨æƒ³æ›´å¥½åœ°å¯è§†åŒ–æ¯ä¸ªåˆ†é¢å†…éƒ¨çš„å…³ç³»æ—¶ï¼Œè¿™å¯èƒ½ä¼šæœ‰é™åˆ¶ã€‚åœ¨åˆ†é¢å‡½æ•°ä¸­å°† scales å‚æ•°è®¾ç½®ä¸º \"free_x\" å°†å…è®¸è·¨åˆ—ä½¿ç”¨ä¸åŒçš„ x è½´åˆ»åº¦ï¼Œ\"free_y\" å°†å…è®¸è·¨è¡Œä½¿ç”¨ä¸åŒçš„ y è½´åˆ»åº¦ï¼Œè€Œ \"free\" å°†åŒæ—¶å…è®¸ä¸¤è€…ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl, scales = \"free\")\n\n\n\n\n\n\n\n\n9.4.1 Exercises\n\nWhat happens if you facet on a continuous variable?\n\nWhat do the empty cells in the plot above with facet_grid(drv ~ cyl) mean? Run the following code. How do they relate to the resulting plot?\n\nggplot(mpg) + \n  geom_point(aes(x = drv, y = cyl))\n\n\n\nWhat plots does the following code make? What does . do?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)\n\n\n\nTake the first faceted plot in this section:\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ cyl, nrow = 2)\n\nWhat are the advantages to using faceting instead of the color aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset?\n\nRead ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesnâ€™t facet_grid() have nrow and ncol arguments?\n\nWhich of the following plots makes it easier to compare engine size (displ) across cars with different drive trains? What does this say about when to place a faceting variable across rows or columns?\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(drv ~ .)\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() +\n  facet_grid(. ~ drv)\n\n\n\nRecreate the following plot using facet_wrap() instead of facet_grid(). How do the positions of the facet labels change?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#statistical-transformations",
    "href": "layers.html#statistical-transformations",
    "title": "9Â  Layers",
    "section": "\n9.5 Statistical transformations",
    "text": "9.5 Statistical transformations\nConsider a basic bar chart, drawn with geom_bar() or geom_col(). The following chart displays the total number of diamonds in the diamonds dataset, grouped by cut. The diamonds dataset is in the ggplot2 package and contains information on ~54,000 diamonds, including the price, carat, color, clarity, and cut of each diamond. The chart shows that more diamonds are available with high quality cuts than with low quality cuts.\nè€ƒè™‘ä¸€ä¸ªç”¨ geom_bar() æˆ– geom_col() ç»˜åˆ¶çš„åŸºæœ¬æ¡å½¢å›¾ã€‚ä¸‹å›¾æ˜¾ç¤ºäº† diamonds æ•°æ®é›†ä¸­æŒ‰ cut åˆ†ç»„çš„é’»çŸ³æ€»æ•°ã€‚diamonds æ•°æ®é›†ä½äº ggplot2 åŒ…ä¸­ï¼ŒåŒ…å«çº¦ 54,000 é¢—é’»çŸ³çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¯é¢—é’»çŸ³çš„ priceã€caratã€colorã€clarity å’Œ cutã€‚è¯¥å›¾è¡¨æ˜¾ç¤ºï¼Œé«˜è´¨é‡åˆ‡å·¥çš„é’»çŸ³æ¯”ä½è´¨é‡åˆ‡å·¥çš„é’»çŸ³æ›´å¤šã€‚\n\nggplot(diamonds, aes(x = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\nOn the x-axis, the chart displays cut, a variable from diamonds. On the y-axis, it displays count, but count is not a variable in diamonds! Where does count come from? Many graphs, like scatterplots, plot the raw values of your dataset. Other graphs, like bar charts, calculate new values to plot:\nåœ¨ x è½´ä¸Šï¼Œå›¾è¡¨æ˜¾ç¤º cutï¼Œè¿™æ˜¯ diamonds æ•°æ®é›†ä¸­çš„ä¸€ä¸ªå˜é‡ã€‚åœ¨ y è½´ä¸Šï¼Œå®ƒæ˜¾ç¤ºè®¡æ•° (count)ï¼Œä½†è®¡æ•°å¹¶ä¸æ˜¯ diamonds æ•°æ®é›†ä¸­çš„å˜é‡ï¼è®¡æ•°ä»ä½•è€Œæ¥ï¼Ÿè®¸å¤šå›¾è¡¨ï¼Œå¦‚æ•£ç‚¹å›¾ï¼Œä¼šç»˜åˆ¶æ•°æ®é›†çš„åŸå§‹å€¼ã€‚è€Œå…¶ä»–å›¾è¡¨ï¼Œå¦‚æ¡å½¢å›¾ï¼Œåˆ™ä¼šè®¡ç®—æ–°çš„å€¼æ¥è¿›è¡Œç»˜åˆ¶ï¼š\n\nBar charts, histograms, and frequency polygons bin your data and then plot bin counts, the number of points that fall in each bin.\næ¡å½¢å›¾ã€ç›´æ–¹å›¾å’Œé¢‘ç‡å¤šè¾¹å½¢å°†æ‚¨çš„æ•°æ®åˆ†ç®±ï¼Œç„¶åç»˜åˆ¶æ¯ä¸ªç®±ä¸­çš„è®¡æ•°ï¼Œå³è½å…¥æ¯ä¸ªç®±ä¸­çš„ç‚¹çš„æ•°é‡ã€‚\nSmoothers fit a model to your data and then plot predictions from the model.\nå¹³æ»‘å™¨ (Smoothers) ä¼šå¯¹ä½ çš„æ•°æ®æ‹Ÿåˆä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åç»˜åˆ¶å‡ºæ¨¡å‹çš„é¢„æµ‹å€¼ã€‚\nBoxplots compute the five-number summary of the distribution and then display that summary as a specially formatted box.\nç®±çº¿å›¾è®¡ç®—åˆ†å¸ƒçš„äº”æ•°æ¦‚æ‹¬ï¼ˆfive-number summaryï¼‰ï¼Œç„¶åå°†è¯¥æ¦‚æ‹¬æ˜¾ç¤ºä¸ºç‰¹æ®Šæ ¼å¼çš„ç®±å½¢ã€‚\n\nThe algorithm used to calculate new values for a graph is called a stat, short for statistical transformation. FigureÂ 9.2 shows how this process works with geom_bar().\nç”¨äºä¸ºå›¾å½¢è®¡ç®—æ–°å€¼çš„ç®—æ³•ç§°ä¸º statï¼Œå³ç»Ÿè®¡å˜æ¢ (statistical transformation) çš„ç¼©å†™ã€‚FigureÂ 9.2 å±•ç¤ºäº†æ­¤è¿‡ç¨‹å¦‚ä½•ä¸ geom_bar() ä¸€èµ·å·¥ä½œã€‚\n\n\n\n\n\n\n\nFigureÂ 9.2: When creating a bar chart we first start with the raw data, then aggregate it to count the number of observations in each bar, and finally map those computed variables to plot aesthetics.\n\n\n\n\nåœ¨åˆ›å»ºæ¡å½¢å›¾æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆä»åŸå§‹æ•°æ®å¼€å§‹ï¼Œç„¶åå¯¹å…¶è¿›è¡Œèšåˆä»¥è®¡ç®—æ¯ä¸ªæ¡å½¢ä¸­çš„è§‚æµ‹æ•°é‡ï¼Œæœ€åå°†è¿™äº›è®¡ç®—å‡ºçš„å˜é‡æ˜ å°„åˆ°ç»˜å›¾ç¾å­¦ä¸Šã€‚\nYou can learn which stat a geom uses by inspecting the default value for the stat argument. For example, ?geom_bar shows that the default value for stat is â€œcountâ€, which means that geom_bar() uses stat_count(). stat_count() is documented on the same page as geom_bar(). If you scroll down, the section called â€œComputed variablesâ€ explains that it computes two new variables: count and prop.\nä½ å¯ä»¥é€šè¿‡æ£€æŸ¥ stat å‚æ•°çš„é»˜è®¤å€¼æ¥äº†è§£ä¸€ä¸ªå‡ ä½•å¯¹è±¡ï¼ˆgeomï¼‰ä½¿ç”¨äº†å“ªä¸ªç»Ÿè®¡å˜æ¢ï¼ˆstatï¼‰ã€‚ä¾‹å¦‚ï¼Œ?geom_bar æ˜¾ç¤º stat çš„é»˜è®¤å€¼æ˜¯ â€œcountâ€ï¼Œè¿™æ„å‘³ç€ geom_bar() ä½¿ç”¨äº† stat_count()ã€‚stat_count() å’Œ geom_bar() åœ¨åŒä¸€ä¸ªå¸®åŠ©é¡µé¢ä¸Šæœ‰æ–‡æ¡£è¯´æ˜ã€‚å¦‚æœä½ å‘ä¸‹æ»šåŠ¨ï¼Œåä¸ºâ€œè®¡ç®—å˜é‡â€çš„éƒ¨åˆ†ä¼šè§£é‡Šå®ƒè®¡ç®—äº†ä¸¤ä¸ªæ–°å˜é‡ï¼šcount å’Œ propã€‚\nEvery geom has a default stat; and every stat has a default geom. This means that you can typically use geoms without worrying about the underlying statistical transformation. However, there are three reasons why you might need to use a stat explicitly:\næ¯ä¸ª geom éƒ½æœ‰ä¸€ä¸ªé»˜è®¤çš„ statï¼›æ¯ä¸ª stat ä¹Ÿæœ‰ä¸€ä¸ªé»˜è®¤çš„ geomã€‚è¿™æ„å‘³ç€ä½ é€šå¸¸å¯ä»¥ä½¿ç”¨ geom è€Œä¸å¿…æ‹…å¿ƒåº•å±‚çš„ç»Ÿè®¡è½¬æ¢ã€‚ç„¶è€Œï¼Œæœ‰ä¸‰ä¸ªåŸå› å¯èƒ½è®©ä½ éœ€è¦æ˜ç¡®åœ°ä½¿ç”¨ statï¼š\n\n\nYou might want to override the default stat. In the code below, we change the stat of geom_bar() from count (the default) to identity. This lets us map the height of the bars to the raw values of a y variable.\nä½ å¯èƒ½æƒ³è¦è¦†ç›–é»˜è®¤çš„ç»Ÿè®¡å˜æ¢ã€‚åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å°† geom_bar() çš„ç»Ÿè®¡å˜æ¢ä» countï¼ˆé»˜è®¤å€¼ï¼‰æ›´æ”¹ä¸º identityã€‚è¿™ä½¿æˆ‘ä»¬å¯ä»¥å°†æ¡å½¢çš„é«˜åº¦æ˜ å°„åˆ° y å˜é‡çš„åŸå§‹å€¼ã€‚\n\ndiamonds |&gt;\n  count(cut) |&gt;\n  ggplot(aes(x = cut, y = n)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\nYou might want to override the default mapping from transformed variables to aesthetics. For example, you might want to display a bar chart of proportions, rather than counts:\nä½ å¯èƒ½æƒ³è¦è¦†ç›–ä»è½¬æ¢åå˜é‡åˆ°ç¾å­¦çš„é»˜è®¤æ˜ å°„ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½æƒ³æ˜¾ç¤ºä¸€ä¸ªæ¯”ä¾‹æ¡å½¢å›¾ï¼Œè€Œä¸æ˜¯è®¡æ•°æ¡å½¢å›¾ï¼š\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop), group = 1)) + \n  geom_bar()\n\n\n\n\n\n\n\nTo find the possible variables that can be computed by the stat, look for the section titled â€œcomputed variablesâ€ in the help for geom_bar().\nè¦æŸ¥æ‰¾å¯ç”±ç»Ÿè®¡å˜æ¢è®¡ç®—çš„å¯èƒ½å˜é‡ï¼Œè¯·åœ¨ geom_bar() çš„å¸®åŠ©æ–‡æ¡£ä¸­æŸ¥æ‰¾æ ‡é¢˜ä¸ºâ€œè®¡ç®—å˜é‡â€çš„éƒ¨åˆ†ã€‚\n\n\nYou might want to draw greater attention to the statistical transformation in your code. For example, you might use stat_summary(), which summarizes the y values for each unique x value, to draw attention to the summary that youâ€™re computing:\nä½ å¯èƒ½æƒ³åœ¨ä»£ç ä¸­æ›´åŠ çªå‡ºç»Ÿè®¡å˜æ¢ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥ä½¿ç”¨ stat_summary()ï¼Œå®ƒä¸ºæ¯ä¸ªå”¯ä¸€çš„ x å€¼æ±‡æ€» y å€¼ï¼Œä»¥çªå‡ºä½ æ­£åœ¨è®¡ç®—çš„æ‘˜è¦ï¼š\n\nggplot(diamonds) + \n  stat_summary(\n    aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )\n\n\n\n\n\n\n\n\n\nggplot2 provides more than 20 stats for you to use. Each stat is a function, so you can get help in the usual way, e.g., ?stat_bin.\nggplot2 æä¾›äº†è¶…è¿‡ 20 ç§ç»Ÿè®¡å˜æ¢ä¾›æ‚¨ä½¿ç”¨ã€‚æ¯ç§ç»Ÿè®¡å˜æ¢éƒ½æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå› æ­¤æ‚¨å¯ä»¥é€šè¿‡å¸¸è§„æ–¹å¼è·å–å¸®åŠ©ï¼Œä¾‹å¦‚ ?stat_binã€‚\n\n9.5.1 Exercises\n\nWhat is the default geom associated with stat_summary()? How could you rewrite the previous plot to use that geom function instead of the stat function?\nWhat does geom_col() do? How is it different from geom_bar()?\nMost geoms and stats come in pairs that are almost always used in concert. Make a list of all the pairs. What do they have in common? (Hint: Read through the documentation.)\nWhat variables does stat_smooth() compute? What arguments control its behavior?\n\nIn our proportion bar chart, we needed to set group = 1. Why? In other words, what is the problem with these two graphs?\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop))) + \n  geom_bar()\nggplot(diamonds, aes(x = cut, fill = color, y = after_stat(prop))) + \n  geom_bar()",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#position-adjustments",
    "href": "layers.html#position-adjustments",
    "title": "9Â  Layers",
    "section": "\n9.6 Position adjustments",
    "text": "9.6 Position adjustments\nThereâ€™s one more piece of magic associated with bar charts. You can color a bar chart using either the color aesthetic, or, more usefully, the fill aesthetic:\næ¡å½¢å›¾è¿˜æœ‰ä¸€ä¸ªç¥å¥‡ä¹‹å¤„ã€‚ä½ å¯ä»¥ä½¿ç”¨ color ç¾å­¦ï¼Œæˆ–è€…æ›´æœ‰ç”¨çš„ fill ç¾å­¦æ¥ä¸ºæ¡å½¢å›¾ä¸Šè‰²ï¼š\n# Left\nggplot(mpg, aes(x = drv, color = drv)) + \n  geom_bar()\n\n# Right\nggplot(mpg, aes(x = drv, fill = drv)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nNote what happens if you map the fill aesthetic to another variable, like class: the bars are automatically stacked. Each colored rectangle represents a combination of drv and class.\nè¯·æ³¨æ„ï¼Œå¦‚æœå°†å¡«å……ç¾å­¦æ˜ å°„åˆ°å¦ä¸€ä¸ªå˜é‡ï¼ˆå¦‚ classï¼‰ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼šæ¡å½¢ä¼šè‡ªåŠ¨å †å ã€‚æ¯ä¸ªå½©è‰²çŸ©å½¢ä»£è¡¨ drv å’Œ class çš„ç»„åˆã€‚\n\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar()\n\n\n\n\n\n\n\nThe stacking is performed automatically using the position adjustment specified by the position argument. If you donâ€™t want a stacked bar chart, you can use one of three other options: \"identity\", \"dodge\" or \"fill\".\nå †å æ˜¯é€šè¿‡ position å‚æ•°æŒ‡å®šçš„ ä½ç½®è°ƒæ•´ (position adjustment) è‡ªåŠ¨æ‰§è¡Œçš„ã€‚å¦‚æœä½ ä¸æƒ³è¦å †å æ¡å½¢å›¾ï¼Œå¯ä»¥ä½¿ç”¨å…¶ä»–ä¸‰ä¸ªé€‰é¡¹ä¹‹ä¸€ï¼š\"identity\"ã€\"dodge\" æˆ– \"fill\"ã€‚\n\n\nposition = \"identity\" will place each object exactly where it falls in the context of the graph. This is not very useful for bars, because it overlaps them. To see that overlapping we either need to make the bars slightly transparent by setting alpha to a small value, or completely transparent by setting fill = NA.\n# Left\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(alpha = 1/5, position = \"identity\")\n\n# Right\nggplot(mpg, aes(x = drv, color = class)) + \n  geom_bar(fill = NA, position = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\n\nposition = \"identity\" ä¼šå°†æ¯ä¸ªå¯¹è±¡ç²¾ç¡®åœ°æ”¾ç½®åœ¨å®ƒåœ¨å›¾è¡¨ä¸Šä¸‹æ–‡ä¸­çš„ä½ç½®ã€‚å¯¹äºæ¡å½¢å›¾æ¥è¯´ï¼Œè¿™ä¸å¤ªæœ‰ç”¨ï¼Œå› ä¸ºå®ƒä¼šä½¿å®ƒä»¬é‡å ã€‚ä¸ºäº†çœ‹åˆ°è¿™ç§é‡å ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡å°† alpha è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå°çš„å€¼æ¥ä½¿æ¡å½¢å›¾ç•¥å¾®é€æ˜ï¼Œæˆ–è€…é€šè¿‡è®¾ç½® fill = NA æ¥ä½¿å…¶å®Œå…¨é€æ˜ã€‚\nThe identity position adjustment is more useful for 2d geoms, like points, where it is the default.identity ä½ç½®è°ƒæ•´å¯¹äºäºŒç»´å‡ ä½•å¯¹è±¡ï¼ˆå¦‚ç‚¹ï¼‰æ›´æœ‰ç”¨ï¼Œå®ƒæ˜¯é»˜è®¤è®¾ç½®ã€‚\n\nposition = \"fill\" works like stacking, but makes each set of stacked bars the same height. This makes it easier to compare proportions across groups.\nposition = \"fill\" çš„ä½œç”¨ç±»ä¼¼äºå †å ï¼Œä½†ä¼šä½¿æ¯ç»„å †å çš„æ¡å½¢å›¾å…·æœ‰ç›¸åŒçš„é«˜åº¦ã€‚è¿™ä½¿å¾—è·¨ç»„æ¯”è¾ƒæ¯”ä¾‹å˜å¾—æ›´åŠ å®¹æ˜“ã€‚\n\nposition = \"dodge\" places overlapping objects directly beside one another. This makes it easier to compare individual values.\n# Left\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(position = \"fill\")\n\n# Right\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\nposition = \"dodge\" å°†é‡å çš„å¯¹è±¡ç›´æ¥å¹¶æ’æ”¾ç½®ã€‚è¿™ä½¿å¾—æ¯”è¾ƒå•ä¸ªå€¼å˜å¾—æ›´å®¹æ˜“ã€‚\n\nThereâ€™s one other type of adjustment thatâ€™s not useful for bar charts, but can be very useful for scatterplots. Recall our first scatterplot. Did you notice that the plot displays only 126 points, even though there are 234 observations in the dataset?\nè¿˜æœ‰ä¸€ç§è°ƒæ•´å¯¹æ¡å½¢å›¾æ²¡ä»€ä¹ˆç”¨ï¼Œä½†å¯¹æ•£ç‚¹å›¾å´éå¸¸æœ‰ç”¨ã€‚å›æƒ³ä¸€ä¸‹æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæ•£ç‚¹å›¾ã€‚ä½ æœ‰æ²¡æœ‰æ³¨æ„åˆ°ï¼Œå°½ç®¡æ•°æ®é›†ä¸­æœ‰ 234 ä¸ªè§‚æµ‹å€¼ï¼Œä½†è¯¥å›¾åªæ˜¾ç¤ºäº† 126 ä¸ªç‚¹ï¼Ÿ\n\n\n\n\n\n\n\n\nThe underlying values of hwy and displ are rounded so the points appear on a grid and many points overlap each other. This problem is known as overplotting. This arrangement makes it difficult to see the distribution of the data. Are the data points spread equally throughout the graph, or is there one special combination of hwy and displ that contains 109 values?hwy å’Œ displ çš„åŸºç¡€å€¼æ˜¯å››èˆäº”å…¥çš„ï¼Œæ‰€ä»¥ç‚¹å‡ºç°åœ¨ä¸€ä¸ªç½‘æ ¼ä¸Šï¼Œè®¸å¤šç‚¹ç›¸äº’é‡å ã€‚è¿™ä¸ªé—®é¢˜è¢«ç§°ä¸º è¿‡ç»˜ (overplotting)ã€‚è¿™ç§æ’åˆ—æ–¹å¼ä½¿å¾—å¾ˆéš¾çœ‹å‡ºæ•°æ®çš„åˆ†å¸ƒæƒ…å†µã€‚æ•°æ®ç‚¹æ˜¯å‡åŒ€åœ°åˆ†å¸ƒåœ¨æ•´ä¸ªå›¾è¡¨ä¸­ï¼Œè¿˜æ˜¯å­˜åœ¨ä¸€ä¸ªåŒ…å« 109 ä¸ªå€¼çš„ç‰¹æ®Š hwy å’Œ displ ç»„åˆï¼Ÿ\nYou can avoid this gridding by setting the position adjustment to â€œjitterâ€. position = \"jitter\" adds a small amount of random noise to each point. This spreads the points out because no two points are likely to receive the same amount of random noise.\næ‚¨å¯ä»¥é€šè¿‡å°†ä½ç½®è°ƒæ•´è®¾ç½®ä¸ºâ€œjitterâ€æ¥é¿å…è¿™ç§ç½‘æ ¼åŒ–ã€‚position = \"jitter\" ä¼šä¸ºæ¯ä¸ªç‚¹æ·»åŠ å°‘é‡éšæœºå™ªå£°ã€‚è¿™ä¼šå°†ç‚¹æ•£å¼€ï¼Œå› ä¸ºä¸å¤ªå¯èƒ½æœ‰ä¸¤ç‚¹ä¼šæ¥æ”¶åˆ°ç›¸åŒé‡çš„éšæœºå™ªå£°ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(position = \"jitter\")\n\n\n\n\n\n\n\nAdding randomness seems like a strange way to improve your plot, but while it makes your graph less accurate at small scales, it makes your graph more revealing at large scales. Because this is such a useful operation, ggplot2 comes with a shorthand for geom_point(position = \"jitter\"): geom_jitter().\nå¢åŠ éšæœºæ€§ä¼¼ä¹æ˜¯ä¸€ç§å¥‡æ€ªçš„æ”¹å–„å›¾è¡¨çš„æ–¹å¼ï¼Œä½†è™½ç„¶å®ƒåœ¨å°å°ºåº¦ä¸Šä½¿ä½ çš„å›¾è¡¨ä¸é‚£ä¹ˆç²¾ç¡®ï¼Œä½†åœ¨å¤§å°ºåº¦ä¸Šå´ä½¿ä½ çš„å›¾è¡¨æ›´å…·æ­ç¤ºæ€§ã€‚å› ä¸ºè¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„æ“ä½œï¼Œggplot2 ä¸º geom_point(position = \"jitter\") æä¾›äº†ä¸€ä¸ªç®€å†™ï¼šgeom_jitter()ã€‚\nTo learn more about a position adjustment, look up the help page associated with each adjustment: ?position_dodge, ?position_fill, ?position_identity, ?position_jitter, and ?position_stack.\nè¦äº†è§£æœ‰å…³ä½ç½®è°ƒæ•´çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥é˜…ä¸æ¯ä¸ªè°ƒæ•´ç›¸å…³çš„å¸®åŠ©é¡µé¢ï¼š?position_dodgeã€?position_fillã€?position_identityã€?position_jitter å’Œ ?position_stackã€‚\n\n9.6.1 Exercises\n\n\nWhat is the problem with the following plot? How could you improve it?\n\nggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point()\n\n\n\nWhat, if anything, is the difference between the two plots? Why?\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point()\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(position = \"identity\")\n\n\nWhat parameters to geom_jitter() control the amount of jittering?\nCompare and contrast geom_jitter() with geom_count().\nWhatâ€™s the default position adjustment for geom_boxplot()? Create a visualization of the mpg dataset that demonstrates it.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#coordinate-systems",
    "href": "layers.html#coordinate-systems",
    "title": "9Â  Layers",
    "section": "\n9.7 Coordinate systems",
    "text": "9.7 Coordinate systems\nCoordinate systems are probably the most complicated part of ggplot2. The default coordinate system is the Cartesian coordinate system where the x and y positions act independently to determine the location of each point. There are two other coordinate systems that are occasionally helpful.\nåæ ‡ç³»å¯èƒ½æ˜¯ ggplot2 ä¸­æœ€å¤æ‚çš„éƒ¨åˆ†ã€‚é»˜è®¤çš„åæ ‡ç³»æ˜¯ç¬›å¡å°”åæ ‡ç³»ï¼Œå…¶ä¸­ x å’Œ y çš„ä½ç½®ç‹¬ç«‹åœ°å†³å®šæ¯ä¸ªç‚¹çš„ä½ç½®ã€‚è¿˜æœ‰å¦å¤–ä¸¤ä¸ªå¶å°”æœ‰ç”¨çš„åæ ‡ç³»ã€‚\n\n\ncoord_quickmap() sets the aspect ratio correctly for geographic maps. This is very important if youâ€™re plotting spatial data with ggplot2. We donâ€™t have the space to discuss maps in this book, but you can learn more in the Maps chapter of ggplot2: Elegant graphics for data analysis.\nnz &lt;- map_data(\"nz\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\") +\n  coord_quickmap()\n\n\n\n\n\n\n\n\n\n\n\ncoord_quickmap() ä¸ºåœ°ç†åœ°å›¾æ­£ç¡®è®¾ç½®é•¿å®½æ¯”ã€‚å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨ ggplot2 ç»˜åˆ¶ç©ºé—´æ•°æ®ï¼Œè¿™ä¸€ç‚¹éå¸¸é‡è¦ã€‚æˆ‘ä»¬åœ¨è¿™æœ¬ä¹¦ä¸­æ²¡æœ‰ç¯‡å¹…è®¨è®ºåœ°å›¾ï¼Œä½†æ‚¨å¯ä»¥åœ¨ ggplot2: Elegant graphics for data analysis çš„åœ°å›¾ç« èŠ‚ä¸­äº†è§£æ›´å¤šä¿¡æ¯ã€‚\n\ncoord_polar() uses polar coordinates. Polar coordinates reveal an interesting connection between a bar chart and a Coxcomb chart.\nbar &lt;- ggplot(data = diamonds) + \n  geom_bar(\n    mapping = aes(x = clarity, fill = clarity), \n    show.legend = FALSE,\n    width = 1\n  ) + \n  theme(aspect.ratio = 1)\n\nbar + coord_flip()\nbar + coord_polar()\n\n\n\n\n\n\n\n\n\n\n\ncoord_polar() ä½¿ç”¨æåæ ‡ã€‚æåæ ‡æ­ç¤ºäº†æ¡å½¢å›¾å’Œå—ä¸æ ¼å°”ç«ç‘°å›¾ (Coxcomb chart) ä¹‹é—´ä¸€ä¸ªæœ‰è¶£çš„è”ç³»ã€‚\n\n\n9.7.1 Exercises\n\nTurn a stacked bar chart into a pie chart using coord_polar().\nWhatâ€™s the difference between coord_quickmap() and coord_map()?\n\nWhat does the following plot tell you about the relationship between city and highway mpg? Why is coord_fixed() important? What does geom_abline() do?\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +\n  geom_point() + \n  geom_abline() +\n  coord_fixed()",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#the-layered-grammar-of-graphics",
    "href": "layers.html#the-layered-grammar-of-graphics",
    "title": "9Â  Layers",
    "section": "\n9.8 The layered grammar of graphics",
    "text": "9.8 The layered grammar of graphics\nWe can expand on the graphing template you learned in Section 1.3 by adding position adjustments, stats, coordinate systems, and faceting:\næˆ‘ä»¬å¯ä»¥é€šè¿‡æ·»åŠ ä½ç½®è°ƒæ•´ã€ç»Ÿè®¡å˜æ¢ã€åæ ‡ç³»å’Œåˆ†é¢ï¼Œæ¥æ‰©å±•æ‚¨åœ¨ Section 1.3 ä¸­å­¦åˆ°çš„ç»˜å›¾æ¨¡æ¿ï¼š\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(\n     mapping = aes(&lt;MAPPINGS&gt;),\n     stat = &lt;STAT&gt;, \n     position = &lt;POSITION&gt;\n  ) +\n  &lt;COORDINATE_FUNCTION&gt; +\n  &lt;FACET_FUNCTION&gt;\nOur new template takes seven parameters, the bracketed words that appear in the template. In practice, you rarely need to supply all seven parameters to make a graph because ggplot2 will provide useful defaults for everything except the data, the mappings, and the geom function.\næˆ‘ä»¬çš„æ–°æ¨¡æ¿æœ‰ä¸ƒä¸ªå‚æ•°ï¼Œå³æ¨¡æ¿ä¸­å‡ºç°çš„æ–¹æ‹¬å·å†…çš„è¯ã€‚åœ¨å®è·µä¸­ï¼Œæ‚¨å¾ˆå°‘éœ€è¦æä¾›æ‰€æœ‰ä¸ƒä¸ªå‚æ•°æ¥åˆ¶ä½œå›¾è¡¨ï¼Œå› ä¸º ggplot2 ä¼šä¸ºé™¤äº†æ•°æ®ã€æ˜ å°„å’Œå‡ ä½•å‡½æ•°ä¹‹å¤–çš„æ‰€æœ‰å†…å®¹æä¾›æœ‰ç”¨çš„é»˜è®¤å€¼ã€‚\nThe seven parameters in the template compose the grammar of graphics, a formal system for building plots. The grammar of graphics is based on the insight that you can uniquely describe any plot as a combination of a dataset, a geom, a set of mappings, a stat, a position adjustment, a coordinate system, a faceting scheme, and a theme.\næ¨¡æ¿ä¸­çš„ä¸ƒä¸ªå‚æ•°æ„æˆäº†å›¾å½¢è¯­æ³•ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºç»˜å›¾çš„æ­£å¼ç³»ç»Ÿã€‚å›¾å½¢è¯­æ³•åŸºäºè¿™æ ·ä¸€ä¸ªæ´è§ï¼šä½ å¯ä»¥å°†ä»»ä½•ç»˜å›¾å”¯ä¸€åœ°æè¿°ä¸ºä¸€ä¸ªæ•°æ®é›†ã€ä¸€ä¸ªå‡ ä½•å¯¹è±¡ã€ä¸€ç»„æ˜ å°„ã€ä¸€ä¸ªç»Ÿè®¡å˜æ¢ã€ä¸€ä¸ªä½ç½®è°ƒæ•´ã€ä¸€ä¸ªåæ ‡ç³»ã€ä¸€ä¸ªåˆ†é¢æ–¹æ¡ˆå’Œä¸€ä¸ªä¸»é¢˜çš„ç»„åˆã€‚\nTo see how this works, consider how you could build a basic plot from scratch: you could start with a dataset and then transform it into the information that you want to display (with a stat). Next, you could choose a geometric object to represent each observation in the transformed data. You could then use the aesthetic properties of the geoms to represent variables in the data. You would map the values of each variable to the levels of an aesthetic. These steps are illustrated in FigureÂ 9.3. Youâ€™d then select a coordinate system to place the geoms into, using the location of the objects (which is itself an aesthetic property) to display the values of the x and y variables.\nä¸ºäº†ç†è§£è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå¯ä»¥è€ƒè™‘å¦‚ä½•ä»å¤´å¼€å§‹æ„å»ºä¸€ä¸ªåŸºæœ¬å›¾è¡¨ï¼šä½ å¯ä»¥ä»ä¸€ä¸ªæ•°æ®é›†å¼€å§‹ï¼Œç„¶åï¼ˆé€šè¿‡ä¸€ä¸ªç»Ÿè®¡å˜æ¢ statï¼‰å°†å…¶è½¬æ¢ä¸ºä½ æƒ³è¦æ˜¾ç¤ºçš„ä¿¡æ¯ã€‚æ¥ä¸‹æ¥ï¼Œä½ å¯ä»¥é€‰æ‹©ä¸€ä¸ªå‡ ä½•å¯¹è±¡æ¥è¡¨ç¤ºè½¬æ¢åæ•°æ®ä¸­çš„æ¯ä¸ªè§‚æµ‹å€¼ã€‚ç„¶åï¼Œä½ å¯ä»¥ä½¿ç”¨å‡ ä½•å¯¹è±¡çš„ç¾å­¦å±æ€§æ¥è¡¨ç¤ºæ•°æ®ä¸­çš„å˜é‡ã€‚ä½ ä¼šå°†æ¯ä¸ªå˜é‡çš„å€¼æ˜ å°„åˆ°ç¾å­¦çš„ä¸€ä¸ªå±‚æ¬¡ä¸Šã€‚è¿™äº›æ­¥éª¤åœ¨ FigureÂ 9.3 ä¸­æœ‰æ‰€è¯´æ˜ã€‚ç„¶åï¼Œä½ ä¼šé€‰æ‹©ä¸€ä¸ªåæ ‡ç³»æ¥æ”¾ç½®è¿™äº›å‡ ä½•å¯¹è±¡ï¼Œåˆ©ç”¨å¯¹è±¡çš„ä½ç½®ï¼ˆå…¶æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ªç¾å­¦å±æ€§ï¼‰æ¥æ˜¾ç¤º x å’Œ y å˜é‡çš„å€¼ã€‚\n\n\n\n\n\n\n\nFigureÂ 9.3: Steps for going from raw data to a table of frequencies to a bar plot where the heights of the bar represent the frequencies.\n\n\n\n\nä»åŸå§‹æ•°æ®åˆ°é¢‘ç‡è¡¨ï¼Œå†åˆ°æ¡å½¢å›¾çš„æ­¥éª¤ï¼Œå…¶ä¸­æ¡å½¢çš„é«˜åº¦ä»£è¡¨é¢‘ç‡ã€‚\nAt this point, you would have a complete graph, but you could further adjust the positions of the geoms within the coordinate system (a position adjustment) or split the graph into subplots (faceting). You could also extend the plot by adding one or more additional layers, where each additional layer uses a dataset, a geom, a set of mappings, a stat, and a position adjustment.\nè‡³æ­¤ï¼Œä½ å°†å¾—åˆ°ä¸€ä¸ªå®Œæ•´çš„å›¾å½¢ï¼Œä½†ä½ å¯ä»¥è¿›ä¸€æ­¥è°ƒæ•´åæ ‡ç³»å†…å‡ ä½•å¯¹è±¡çš„ä½ç½®ï¼ˆä½ç½®è°ƒæ•´ï¼‰ï¼Œæˆ–å°†å›¾å½¢åˆ†å‰²æˆå­å›¾ï¼ˆåˆ†é¢ï¼‰ã€‚ä½ è¿˜å¯ä»¥é€šè¿‡æ·»åŠ ä¸€ä¸ªæˆ–å¤šä¸ªé™„åŠ å›¾å±‚æ¥æ‰©å±•è¯¥å›¾ï¼Œå…¶ä¸­æ¯ä¸ªé™„åŠ å›¾å±‚éƒ½ä½¿ç”¨ä¸€ä¸ªæ•°æ®é›†ã€ä¸€ä¸ªå‡ ä½•å¯¹è±¡ã€ä¸€ç»„æ˜ å°„ã€ä¸€ä¸ªç»Ÿè®¡å˜æ¢å’Œä¸€ä¸ªä½ç½®è°ƒæ•´ã€‚\nYou could use this method to build any plot that you imagine. In other words, you can use the code template that youâ€™ve learned in this chapter to build hundreds of thousands of unique plots.\nä½ å¯ä»¥ç”¨è¿™ç§æ–¹æ³•æ„å»ºä½ æ‰€èƒ½æƒ³è±¡çš„ä»»ä½•å›¾è¡¨ã€‚æ¢å¥è¯è¯´ï¼Œä½ å¯ä»¥ä½¿ç”¨æœ¬ç« å­¦åˆ°çš„ä»£ç æ¨¡æ¿æ¥æ„å»ºæˆåƒä¸Šä¸‡ä¸ªç‹¬ç‰¹çš„å›¾è¡¨ã€‚\nIf youâ€™d like to learn more about the theoretical underpinnings of ggplot2, you might enjoy reading â€œThe Layered Grammar of Graphicsâ€, the scientific paper that describes the theory of ggplot2 in detail.\nå¦‚æœä½ æƒ³æ·±å…¥äº†è§£ ggplot2 çš„ç†è®ºåŸºç¡€ï¼Œä½ å¯èƒ½ä¼šå–œæ¬¢é˜…è¯»ã€Šåˆ†å±‚å›¾å½¢è¯­æ³•ã€‹ï¼Œè¿™ç¯‡ç§‘å­¦è®ºæ–‡è¯¦ç»†æè¿°äº† ggplot2 çš„ç†è®ºã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "layers.html#summary",
    "href": "layers.html#summary",
    "title": "9Â  Layers",
    "section": "\n9.9 Summary",
    "text": "9.9 Summary\nIn this chapter you learned about the layered grammar of graphics starting with aesthetics and geometries to build a simple plot, facets for splitting the plot into subsets, statistics for understanding how geoms are calculated, position adjustments for controlling the fine details of position when geoms might otherwise overlap, and coordinate systems which allow you to fundamentally change what x and y mean. One layer we have not yet touched on is theme, which we will introduce in Section 11.5.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†åˆ†å±‚å›¾å½¢è¯­æ³•ï¼Œä»ç¾å­¦å’Œå‡ ä½•å­¦å¼€å§‹æ„å»ºä¸€ä¸ªç®€å•çš„å›¾ï¼Œç”¨åˆ†é¢å°†å›¾åˆ†å‰²æˆå­é›†ï¼Œç”¨ç»Ÿè®¡æ¥ç†è§£å‡ ä½•å¯¹è±¡çš„è®¡ç®—æ–¹å¼ï¼Œç”¨ä½ç½®è°ƒæ•´æ¥æ§åˆ¶å‡ ä½•å¯¹è±¡å¯èƒ½é‡å æ—¶çš„ä½ç½®ç»†èŠ‚ï¼Œä»¥åŠç”¨åæ ‡ç³»æ¥ä»æ ¹æœ¬ä¸Šæ”¹å˜ x å’Œ y çš„å«ä¹‰ã€‚æˆ‘ä»¬å°šæœªæ¶‰åŠçš„ä¸€ä¸ªå›¾å±‚æ˜¯ä¸»é¢˜ï¼Œæˆ‘ä»¬å°†åœ¨ Section 11.5 ä¸­ä»‹ç»å®ƒã€‚\nTwo very useful resources for getting an overview of the complete ggplot2 functionality are the ggplot2 cheatsheet (which you can find at https://posit.co/resources/cheatsheets) and the ggplot2 package website (https://ggplot2.tidyverse.org).\nè¦æƒ³å…¨é¢äº†è§£ ggplot2 çš„åŠŸèƒ½ï¼Œæœ‰ä¸¤ä¸ªéå¸¸æœ‰ç”¨çš„èµ„æºï¼šggplot2 é€ŸæŸ¥è¡¨ï¼ˆä½ å¯ä»¥åœ¨ https://posit.co/resources/cheatsheets æ‰¾åˆ°ï¼‰å’Œ ggplot2 åŒ…çš„ç½‘ç«™ï¼ˆhttps://ggplot2.tidyverse.orgï¼‰ã€‚\nAn important lesson you should take from this chapter is that when you feel the need for a geom that is not provided by ggplot2, itâ€™s always a good idea to look into whether someone else has already solved your problem by creating a ggplot2 extension package that offers that geom.\nä½ åº”è¯¥ä»æœ¬ç« ä¸­å­¦åˆ°çš„ä¸€ä¸ªé‡è¦æ•™è®­æ˜¯ï¼Œå½“ä½ è§‰å¾—éœ€è¦ä¸€ä¸ª ggplot2 æœªæä¾›çš„å‡ ä½•å¯¹è±¡æ—¶ï¼Œæœ€å¥½å…ˆå»çœ‹çœ‹æ˜¯å¦å·²ç»æœ‰äººé€šè¿‡åˆ›å»ºæä¾›è¯¥å‡ ä½•å¯¹è±¡çš„ ggplot2 æ‰©å±•åŒ…è§£å†³äº†ä½ çš„é—®é¢˜ã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Layers</span>"
    ]
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "10Â  Exploratory data analysis",
    "section": "",
    "text": "10.1 Introduction\nThis chapter will show you how to use visualization and transformation to explore your data in a systematic way, a task that statisticians call exploratory data analysis, or EDA for short.\næœ¬ç« å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¯è§†åŒ–å’Œè½¬æ¢æ¥ç³»ç»Ÿåœ°æ¢ç´¢æ•°æ®ï¼Œç»Ÿè®¡å­¦å®¶ç§°ä¹‹ä¸ºæ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆexploratory data analysisï¼Œç®€ç§° EDAï¼‰ã€‚\nEDA is an iterative cycle. You:\nEDA æ˜¯ä¸€ä¸ªè¿­ä»£çš„è¿‡ç¨‹ã€‚ä½ éœ€è¦ï¼š\nEDA is not a formal process with a strict set of rules.\nEDA å¹¶éä¸€ä¸ªæœ‰ç€ä¸¥æ ¼è§„åˆ™çš„æ­£å¼æµç¨‹ã€‚\nMore than anything, EDA is a state of mind.\næ›´é‡è¦çš„æ˜¯ï¼ŒEDA æ˜¯ä¸€ç§æ€ç»´çŠ¶æ€ã€‚\nDuring the initial phases of EDA you should feel free to investigate every idea that occurs to you.\nåœ¨ EDA çš„åˆå§‹é˜¶æ®µï¼Œä½ åº”è¯¥è‡ªç”±åœ°å»æ¢ç©¶ä½ è„‘æµ·ä¸­å‡ºç°çš„æ¯ä¸€ä¸ªæƒ³æ³•ã€‚\nSome of these ideas will pan out, and some will be dead ends.\nå…¶ä¸­ä¸€äº›æƒ³æ³•ä¼šæˆåŠŸï¼Œè€Œå¦ä¸€äº›åˆ™ä¼šæ˜¯æ­»èƒ¡åŒã€‚\nAs your exploration continues, you will home in on a few particularly productive insights that youâ€™ll eventually write up and communicate to others.\néšç€ä½ æ¢ç´¢çš„æ·±å…¥ï¼Œä½ ä¼šé€æ¸èšç„¦äºä¸€äº›ç‰¹åˆ«å¯Œæœ‰æˆæ•ˆçš„è§è§£ï¼Œå¹¶æœ€ç»ˆå°†å®ƒä»¬æ•´ç†æˆæ–‡ï¼Œä¸ä»–äººäº¤æµã€‚\nEDA is an important part of any data analysis, even if the primary research questions are handed to you on a platter, because you always need to investigate the quality of your data.\nEDA æ˜¯ä»»ä½•æ•°æ®åˆ†æä¸­éƒ½è‡³å…³é‡è¦çš„ä¸€ç¯ï¼Œå³ä½¿ä¸»è¦çš„ç ”ç©¶é—®é¢˜å·²ç»ç°æˆåœ°æ‘†åœ¨ä½ é¢å‰ï¼Œå› ä¸ºä½ æ€»æ˜¯éœ€è¦è€ƒå¯Ÿæ•°æ®çš„è´¨é‡ã€‚\nData cleaning is just one application of EDA: you ask questions about whether your data meets your expectations or not.\næ•°æ®æ¸…æ´—åªæ˜¯ EDA çš„ä¸€ç§åº”ç”¨ï¼šä½ éœ€è¦æå‡ºé—®é¢˜ï¼Œåˆ¤æ–­ä½ çš„æ•°æ®æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚\nTo do data cleaning, youâ€™ll need to deploy all the tools of EDA: visualization, transformation, and modelling.\nè¦è¿›è¡Œæ•°æ®æ¸…æ´—ï¼Œä½ éœ€è¦è¿ç”¨ EDA çš„æ‰€æœ‰å·¥å…·ï¼šå¯è§†åŒ–ã€è½¬æ¢å’Œå»ºæ¨¡ã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "10Â  Exploratory data analysis",
    "section": "",
    "text": "Generate questions about your data.\nç”Ÿæˆå…³äºæ•°æ®çš„é—®é¢˜ã€‚\nSearch for answers by visualizing, transforming, and modelling your data.\né€šè¿‡å¯è§†åŒ–ã€è½¬æ¢å’Œå»ºæ¨¡æ¥å¯»æ‰¾ç­”æ¡ˆã€‚\nUse what you learn to refine your questions and/or generate new questions.\nåˆ©ç”¨ä½ æ‰€å­¦åˆ°çš„çŸ¥è¯†æ¥å®Œå–„ä½ çš„é—®é¢˜å’Œ/æˆ–ç”Ÿæˆæ–°çš„é—®é¢˜ã€‚\n\n\n\n\n\n\n\n\n\n\n10.1.1 Prerequisites\nIn this chapter weâ€™ll combine what youâ€™ve learned about dplyr and ggplot2 to interactively ask questions, answer them with data, and then ask new questions.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»“åˆä½ æ‰€å­¦çš„ dplyr å’Œ ggplot2 çŸ¥è¯†ï¼Œä»¥äº¤äº’æ–¹å¼æå‡ºé—®é¢˜ï¼Œç”¨æ•°æ®å›ç­”é—®é¢˜ï¼Œç„¶åå†æå‡ºæ–°çš„é—®é¢˜ã€‚\n\nlibrary(tidyverse)",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#questions",
    "href": "EDA.html#questions",
    "title": "10Â  Exploratory data analysis",
    "section": "\n10.2 Questions",
    "text": "10.2 Questions\n\nâ€œThere are no routine statistical questions, only questionable statistical routines.â€ â€” Sir David Cox\n\n&gt; â€œæ²¡æœ‰å¸¸è§„çš„ç»Ÿè®¡é—®é¢˜ï¼Œåªæœ‰å€¼å¾—æ€€ç–‘çš„ç»Ÿè®¡å¥—è·¯ã€‚â€ â€” David Cox çˆµå£«\n\nâ€œFar better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.â€ â€” John Tukey\n\n&gt; â€œå¯¹æ­£ç¡®é—®é¢˜ï¼ˆé€šå¸¸æ˜¯æ¨¡ç³Šçš„ï¼‰çš„è¿‘ä¼¼å›ç­”ï¼Œè¿œèƒœäºå¯¹é”™è¯¯é—®é¢˜ï¼ˆæ€»èƒ½ç²¾ç¡®åŒ–ï¼‰çš„ç²¾ç¡®å›ç­”ã€‚â€ â€” John Tukey\nYour goal during EDA is to develop an understanding of your data.\nä½ åœ¨ EDA æœŸé—´çš„ç›®æ ‡æ˜¯å»ºç«‹å¯¹æ•°æ®çš„ç†è§£ã€‚\nThe easiest way to do this is to use questions as tools to guide your investigation.\næœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨é—®é¢˜ä½œä¸ºå·¥å…·æ¥å¼•å¯¼ä½ çš„è°ƒæŸ¥ã€‚\nWhen you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make.\nå½“ä½ æå‡ºä¸€ä¸ªé—®é¢˜æ—¶ï¼Œè¿™ä¸ªé—®é¢˜ä¼šå°†ä½ çš„æ³¨æ„åŠ›é›†ä¸­åˆ°æ•°æ®é›†çš„ç‰¹å®šéƒ¨åˆ†ï¼Œå¹¶å¸®åŠ©ä½ å†³å®šåˆ¶ä½œå“ªäº›å›¾è¡¨ã€æ¨¡å‹æˆ–è¿›è¡Œå“ªäº›è½¬æ¢ã€‚\nEDA is fundamentally a creative process.\nEDA æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåˆ›é€ æ€§çš„è¿‡ç¨‹ã€‚\nAnd like most creative processes, the key to asking quality questions is to generate a large quantity of questions.\nå’Œå¤§å¤šæ•°åˆ›é€ æ€§è¿‡ç¨‹ä¸€æ ·ï¼Œæå‡º é«˜è´¨é‡ é—®é¢˜çš„å…³é”®åœ¨äºç”Ÿæˆ å¤§é‡ çš„é—®é¢˜ã€‚\nIt is difficult to ask revealing questions at the start of your analysis because you do not know what insights can be gleaned from your dataset.\nåœ¨åˆ†æä¹‹åˆå¾ˆéš¾æå‡ºæœ‰å¯å‘æ€§çš„é—®é¢˜ï¼Œå› ä¸ºä½ ä¸çŸ¥é“å¯ä»¥ä»æ•°æ®é›†ä¸­è·å¾—å“ªäº›è§è§£ã€‚\nOn the other hand, each new question that you ask will expose you to a new aspect of your data and increase your chance of making a discovery.\nå¦ä¸€æ–¹é¢ï¼Œä½ æ¯æå‡ºä¸€ä¸ªæ–°é—®é¢˜ï¼Œéƒ½ä¼šè®©ä½ æ¥è§¦åˆ°æ•°æ®çš„ä¸€ä¸ªæ–°æ–¹é¢ï¼Œå¹¶å¢åŠ ä½ åšå‡ºå‘ç°çš„æœºä¼šã€‚\nYou can quickly drill down into the most interesting parts of your dataâ€”and develop a set of thought-provoking questionsâ€”if you follow up each question with a new question based on what you find.\nå¦‚æœä½ åœ¨æ¯ä¸ªé—®é¢˜ä¹‹åéƒ½æ ¹æ®ä½ çš„å‘ç°æå‡ºä¸€ä¸ªæ–°é—®é¢˜ï¼Œä½ å°±å¯ä»¥è¿…é€Ÿæ·±å…¥åˆ°æ•°æ®æœ€æœ‰è¶£çš„éƒ¨åˆ†ï¼Œå¹¶å½¢æˆä¸€ç³»åˆ—å‘äººæ·±çœçš„é—®é¢˜ã€‚\nThere is no rule about which questions you should ask to guide your research.\nå…³äºåº”è¯¥æå‡ºå“ªäº›é—®é¢˜æ¥æŒ‡å¯¼ä½ çš„ç ”ç©¶ï¼Œå¹¶æ²¡æœ‰å›ºå®šçš„è§„åˆ™ã€‚\nHowever, two types of questions will always be useful for making discoveries within your data.\nç„¶è€Œï¼Œæœ‰ä¸¤ç±»é—®é¢˜å¯¹äºåœ¨æ•°æ®ä¸­è¿›è¡Œå‘ç°æ€»æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚\nYou can loosely word these questions as:\nä½ å¯ä»¥å°†è¿™äº›é—®é¢˜å¤§è‡´è¡¨è¿°ä¸ºï¼š\n\nWhat type of variation occurs within my variables?\næˆ‘çš„å˜é‡å†…éƒ¨å­˜åœ¨å“ªç§ç±»å‹çš„å˜å¼‚ï¼Ÿ\nWhat type of covariation occurs between my variables?\næˆ‘çš„å˜é‡ä¹‹é—´å­˜åœ¨å“ªç§ç±»å‹çš„åå˜ï¼Ÿ\n\nThe rest of this chapter will look at these two questions.\næœ¬ç« çš„å…¶ä½™éƒ¨åˆ†å°†æ¢è®¨è¿™ä¸¤ä¸ªé—®é¢˜ã€‚\nWeâ€™ll explain what variation and covariation are, and weâ€™ll show you several ways to answer each question.\næˆ‘ä»¬å°†è§£é‡Šä»€ä¹ˆæ˜¯å˜å¼‚å’Œåå˜ï¼Œå¹¶å‘ä½ å±•ç¤ºå‡ ç§å›ç­”æ¯ä¸ªé—®é¢˜çš„æ–¹æ³•ã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#variation",
    "href": "EDA.html#variation",
    "title": "10Â  Exploratory data analysis",
    "section": "\n10.3 Variation",
    "text": "10.3 Variation\nVariation is the tendency of the values of a variable to change from measurement to measurement.\n**å˜å¼‚ï¼ˆVariationï¼‰**æ˜¯æŒ‡ä¸€ä¸ªå˜é‡çš„å€¼åœ¨æ¯æ¬¡æµ‹é‡ä¹‹é—´å‘ç”Ÿå˜åŒ–çš„è¶‹åŠ¿ã€‚\nYou can see variation easily in real life; if you measure any continuous variable twice, you will get two different results.\nä½ åœ¨ç°å®ç”Ÿæ´»ä¸­å¾ˆå®¹æ˜“çœ‹åˆ°å˜å¼‚ï¼›å¦‚æœä½ å¯¹ä»»ä½•è¿ç»­å˜é‡è¿›è¡Œä¸¤æ¬¡æµ‹é‡ï¼Œä½ ä¼šå¾—åˆ°ä¸¤ä¸ªä¸åŒçš„ç»“æœã€‚\nThis is true even if you measure quantities that are constant, like the speed of light.\nå³ä½¿ä½ æµ‹é‡çš„æ˜¯åƒå…‰é€Ÿè¿™æ ·çš„æ’å®šé‡ï¼Œæƒ…å†µä¹Ÿæ˜¯å¦‚æ­¤ã€‚\nEach of your measurements will include a small amount of error that varies from measurement to measurement.\nä½ çš„æ¯æ¬¡æµ‹é‡éƒ½ä¼šåŒ…å«å°‘é‡çš„è¯¯å·®ï¼Œè¿™ä¸ªè¯¯å·®åœ¨æ¯æ¬¡æµ‹é‡ä¹‹é—´éƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚\nVariables can also vary if you measure across different subjects (e.g., the eye colors of different people) or at different times (e.g., the energy levels of an electron at different moments).\nå¦‚æœä½ æµ‹é‡ä¸åŒçš„ä¸»ä½“ï¼ˆä¾‹å¦‚ï¼Œä¸åŒäººçš„çœ¼ç›é¢œè‰²ï¼‰æˆ–åœ¨ä¸åŒçš„æ—¶é—´ï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªç”µå­åœ¨ä¸åŒæ—¶åˆ»çš„èƒ½çº§ï¼‰ï¼Œå˜é‡ä¹Ÿä¼šå‘ç”Ÿå˜åŒ–ã€‚\nEvery variable has its own pattern of variation, which can reveal interesting information about how it varies between measurements on the same observation as well as across observations.\næ¯ä¸ªå˜é‡éƒ½æœ‰å…¶è‡ªèº«çš„å˜å¼‚æ¨¡å¼ï¼Œè¿™å¯ä»¥æ­ç¤ºå…³äºå®ƒåœ¨åŒä¸€æ¬¡è§‚æµ‹çš„æµ‹é‡ä¹‹é—´ä»¥åŠä¸åŒè§‚æµ‹ä¹‹é—´å¦‚ä½•å˜åŒ–çš„æœ‰è¶£ä¿¡æ¯ã€‚\nThe best way to understand that pattern is to visualize the distribution of the variableâ€™s values, which youâ€™ve learned about in Chapter 1.\nç†è§£è¿™ç§æ¨¡å¼çš„æœ€ä½³æ–¹æ³•æ˜¯å¯è§†åŒ–å˜é‡å€¼çš„åˆ†å¸ƒï¼Œä½ å·²ç»åœ¨ Chapter 1 ä¸­å­¦ä¹ è¿‡ç›¸å…³å†…å®¹ã€‚\nWeâ€™ll start our exploration by visualizing the distribution of weights (carat) of ~54,000 diamonds from the diamonds dataset.\næˆ‘ä»¬å°†é€šè¿‡å¯è§†åŒ– diamonds æ•°æ®é›†ä¸­çº¦ 54,000 é¢—é’»çŸ³çš„é‡é‡ï¼ˆcaratï¼‰åˆ†å¸ƒæ¥å¼€å§‹æˆ‘ä»¬çš„æ¢ç´¢ã€‚\nSince carat is a numerical variable, we can use a histogram:\nç”±äº carat æ˜¯ä¸€ä¸ªæ•°å€¼å˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›´æ–¹å›¾ï¼š\n\nggplot(diamonds, aes(x = carat)) +\n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\nNow that you can visualize variation, what should you look for in your plots?\næ—¢ç„¶ä½ èƒ½å¤Ÿå¯è§†åŒ–å˜å¼‚ï¼Œé‚£ä¹ˆä½ åº”è¯¥åœ¨å›¾è¡¨ä¸­å¯»æ‰¾ä»€ä¹ˆå‘¢ï¼Ÿ\nAnd what type of follow-up questions should you ask?\nä½ åº”è¯¥æå‡ºä»€ä¹ˆæ ·çš„åç»­é—®é¢˜å‘¢ï¼Ÿ\nWeâ€™ve put together a list below of the most useful types of information that you will find in your graphs, along with some follow-up questions for each type of information.\næˆ‘ä»¬åœ¨ä¸‹é¢æ•´ç†äº†ä¸€ä¸ªåˆ—è¡¨ï¼Œåˆ—å‡ºäº†ä½ å¯ä»¥åœ¨å›¾è¡¨ä¸­æ‰¾åˆ°çš„æœ€æœ‰ç”¨çš„ä¿¡æ¯ç±»å‹ï¼Œä»¥åŠé’ˆå¯¹æ¯ç§ä¿¡æ¯ç±»å‹çš„ä¸€äº›åç»­é—®é¢˜ã€‚\nThe key to asking good follow-up questions will be to rely on your curiosity (What do you want to learn more about?) as well as your skepticism (How could this be misleading?).\næå‡ºå¥½çš„åç»­é—®é¢˜çš„å…³é”®åœ¨äºä¾èµ–ä½ çš„å¥½å¥‡å¿ƒï¼ˆä½ æƒ³äº†è§£æ›´å¤šå…³äºä»€ä¹ˆï¼Ÿï¼‰å’Œä½ çš„æ€€ç–‘ç²¾ç¥ï¼ˆè¿™æ€ä¹ˆå¯èƒ½ä¼šè¯¯å¯¼äººï¼Ÿï¼‰ã€‚\n\n10.3.1 Typical values\nIn both bar charts and histograms, tall bars show the common values of a variable, and shorter bars show less-common values.\nåœ¨æ¡å½¢å›¾å’Œç›´æ–¹å›¾ä¸­ï¼Œé«˜æ¡æ˜¾ç¤ºå˜é‡çš„å¸¸è§å€¼ï¼ŒçŸ­æ¡æ˜¾ç¤ºä¸é‚£ä¹ˆå¸¸è§çš„å€¼ã€‚\nPlaces that do not have bars reveal values that were not seen in your data.\næ²¡æœ‰æ¡å½¢çš„åœ°æ–¹æ­ç¤ºäº†ä½ çš„æ•°æ®ä¸­æœªæ›¾å‡ºç°çš„å€¼ã€‚\nTo turn this information into useful questions, look for anything unexpected:\nè¦å°†è¿™äº›ä¿¡æ¯è½¬åŒ–ä¸ºæœ‰ç”¨çš„é—®é¢˜ï¼Œè¯·å¯»æ‰¾ä»»ä½•æ„æƒ³ä¸åˆ°çš„åœ°æ–¹ï¼š\n\nWhich values are the most common? Why?\nå“ªäº›å€¼æœ€å¸¸è§ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\nWhich values are rare? Why? Does that match your expectations?\nå“ªäº›å€¼å¾ˆç½•è§ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿè¿™ç¬¦åˆä½ çš„é¢„æœŸå—ï¼Ÿ\nCan you see any unusual patterns? What might explain them?\nä½ èƒ½çœ‹åˆ°ä»»ä½•ä¸å¯»å¸¸çš„æ¨¡å¼å—ï¼Ÿå¯èƒ½çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ\n\nLetâ€™s take a look at the distribution of carat for smaller diamonds.\nè®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è¾ƒå°é’»çŸ³çš„ carat åˆ†å¸ƒã€‚\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt; 3)\n\nggplot(smaller, aes(x = carat)) +\n  geom_histogram(binwidth = 0.01)\n\n\n\n\n\n\n\nThis histogram suggests several interesting questions:\nè¿™ä¸ªç›´æ–¹å›¾å¼•å‡ºäº†å‡ ä¸ªæœ‰è¶£çš„é—®é¢˜ï¼š\n\nWhy are there more diamonds at whole carats and common fractions of carats?\nä¸ºä»€ä¹ˆåœ¨æ•´æ•°å…‹æ‹‰å’Œå¸¸è§çš„å…‹æ‹‰åˆ†æ•°å¤„æœ‰æ›´å¤šçš„é’»çŸ³ï¼Ÿ\nWhy are there more diamonds slightly to the right of each peak than there are slightly to the left of each peak?\nä¸ºä»€ä¹ˆæ¯ä¸ªå³°å€¼å³ä¾§çš„é’»çŸ³æ•°é‡æ¯”å·¦ä¾§çš„è¦å¤šï¼Ÿ\n\nVisualizations can also reveal clusters, which suggest that subgroups exist in your data.\nå¯è§†åŒ–è¿˜å¯ä»¥æ­ç¤ºèšç±»ï¼Œè¿™è¡¨æ˜ä½ çš„æ•°æ®ä¸­å­˜åœ¨å­ç¾¤ã€‚\nTo understand the subgroups, ask:\nè¦ç†è§£è¿™äº›å­ç¾¤ï¼Œå¯ä»¥é—®ï¼š\n\nHow are the observations within each subgroup similar to each other?\næ¯ä¸ªå­ç¾¤å†…çš„è§‚æµ‹å€¼å½¼æ­¤ä¹‹é—´æœ‰ä½•ç›¸ä¼¼ä¹‹å¤„ï¼Ÿ\nHow are the observations in separate clusters different from each other?\nä¸åŒèšç±»ä¸­çš„è§‚æµ‹å€¼å½¼æ­¤ä¹‹é—´æœ‰ä½•ä¸åŒä¹‹å¤„ï¼Ÿ\nHow can you explain or describe the clusters?\nä½ å¦‚ä½•è§£é‡Šæˆ–æè¿°è¿™äº›èšç±»ï¼Ÿ\nWhy might the appearance of clusters be misleading?\nä¸ºä»€ä¹ˆèšç±»çš„å‡ºç°å¯èƒ½ä¼šäº§ç”Ÿè¯¯å¯¼ï¼Ÿ\n\nSome of these questions can be answered with the data while some will require domain expertise about the data.\nå…¶ä¸­ä¸€äº›é—®é¢˜å¯ä»¥ç”¨æ•°æ®æ¥å›ç­”ï¼Œè€Œå¦ä¸€äº›åˆ™éœ€è¦å…³äºè¯¥æ•°æ®çš„é¢†åŸŸä¸“ä¸šçŸ¥è¯†ã€‚\nMany of them will prompt you to explore a relationship between variables, for example, to see if the values of one variable can explain the behavior of another variable.\nå…¶ä¸­è®¸å¤šé—®é¢˜ä¼šä¿ƒä½¿ä½ æ¢ç´¢å˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œä¾‹å¦‚ï¼Œçœ‹çœ‹ä¸€ä¸ªå˜é‡çš„å€¼æ˜¯å¦èƒ½è§£é‡Šå¦ä¸€ä¸ªå˜é‡çš„è¡Œä¸ºã€‚\nWeâ€™ll get to that shortly.\næˆ‘ä»¬å¾ˆå¿«å°±ä¼šè°ˆåˆ°è¿™ä¸€ç‚¹ã€‚\n\n10.3.2 Unusual values\nOutliers are observations that are unusual; data points that donâ€™t seem to fit the pattern.\nç¦»ç¾¤å€¼æ˜¯å¼‚å¸¸çš„è§‚æµ‹å€¼ï¼›å³é‚£äº›ä¼¼ä¹ä¸ç¬¦åˆæ¨¡å¼çš„æ•°æ®ç‚¹ã€‚\nSometimes outliers are data entry errors, sometimes they are simply values at the extremes that happened to be observed in this data collection, and other times they suggest important new discoveries.\næœ‰æ—¶ç¦»ç¾¤å€¼æ˜¯æ•°æ®å½•å…¥é”™è¯¯ï¼Œæœ‰æ—¶å®ƒä»¬ä»…ä»…æ˜¯åœ¨è¿™æ¬¡æ•°æ®æ”¶é›†ä¸­ç¢°å·§è§‚æµ‹åˆ°çš„æç«¯å€¼ï¼Œè€Œå…¶ä»–æ—¶å€™å®ƒä»¬åˆ™å¯èƒ½é¢„ç¤ºç€é‡è¦çš„æ–°å‘ç°ã€‚\nWhen you have a lot of data, outliers are sometimes difficult to see in a histogram.\nå½“ä½ æœ‰å¤§é‡æ•°æ®æ—¶ï¼Œç¦»ç¾¤å€¼æœ‰æ—¶åœ¨ç›´æ–¹å›¾ä¸­å¾ˆéš¾çœ‹å‡ºæ¥ã€‚\nFor example, take the distribution of the y variable from the diamonds dataset.\nä¾‹å¦‚ï¼Œä»¥é’»çŸ³æ•°æ®é›†ä¸­çš„ y å˜é‡åˆ†å¸ƒä¸ºä¾‹ã€‚\nThe only evidence of outliers is the unusually wide limits on the x-axis.\nç¦»ç¾¤å€¼çš„å”¯ä¸€è¯æ®æ˜¯ x è½´ä¸Šå¼‚å¸¸å®½çš„èŒƒå›´ã€‚\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\nThere are so many observations in the common bins that the rare bins are very short, making it very difficult to see them (although maybe if you stare intently at 0 youâ€™ll spot something).\nåœ¨å¸¸è§çš„ç®±ï¼ˆbinï¼‰ä¸­æœ‰å¦‚æ­¤å¤šçš„è§‚æµ‹å€¼ï¼Œä»¥è‡³äºç½•è§çš„ç®±éå¸¸çŸ­ï¼Œä½¿å¾—å®ƒä»¬å¾ˆéš¾è¢«çœ‹åˆ°ï¼ˆå°½ç®¡å¦‚æœä½ ä»”ç»†ç›¯ç€ 0 çš„ä½ç½®ï¼Œæˆ–è®¸èƒ½å‘ç°ç‚¹ä»€ä¹ˆï¼‰ã€‚\nTo make it easy to see the unusual values, we need to zoom to small values of the y-axis with coord_cartesian():\nä¸ºäº†æ›´å®¹æ˜“åœ°çœ‹åˆ°å¼‚å¸¸å€¼ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ coord_cartesian() æ¥æ”¾å¤§ y è½´çš„è¾ƒå°å€¼éƒ¨åˆ†ï¼š\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5) +\n  coord_cartesian(ylim = c(0, 50))\n\n\n\n\n\n\n\ncoord_cartesian() also has an xlim() argument for when you need to zoom into the x-axis.coord_cartesian() ä¹Ÿæœ‰ä¸€ä¸ª xlim() å‚æ•°ï¼Œç”¨äºå½“ä½ éœ€è¦æ”¾å¤§ x è½´æ—¶ã€‚\nggplot2 also has xlim() and ylim() functions that work slightly differently: they throw away the data outside the limits.\nggplot2 ä¹Ÿæœ‰ xlim() å’Œ ylim() å‡½æ•°ï¼Œå®ƒä»¬çš„å·¥ä½œæ–¹å¼ç•¥æœ‰ä¸åŒï¼šå®ƒä»¬ä¼šä¸¢å¼ƒè¶…å‡ºèŒƒå›´çš„æ•°æ®ã€‚\nThis allows us to see that there are three unusual values: 0, ~30, and ~60.\nè¿™è®©æˆ‘ä»¬èƒ½çœ‹åˆ°æœ‰ä¸‰ä¸ªå¼‚å¸¸å€¼ï¼š0ã€çº¦ 30 å’Œçº¦ 60ã€‚\nWe pluck them out with dplyr:\næˆ‘ä»¬ç”¨ dplyr æŠŠå®ƒä»¬æŒ‘é€‰å‡ºæ¥ï¼š\n\nunusual &lt;- diamonds |&gt; \n  filter(y &lt; 3 | y &gt; 20) |&gt; \n  select(price, x, y, z) |&gt;\n  arrange(y)\nunusual\n#&gt; # A tibble: 9 Ã— 4\n#&gt;   price     x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  5139  0      0    0   \n#&gt; 2  6381  0      0    0   \n#&gt; 3 12800  0      0    0   \n#&gt; 4 15686  0      0    0   \n#&gt; 5 18034  0      0    0   \n#&gt; 6  2130  0      0    0   \n#&gt; 7  2130  0      0    0   \n#&gt; 8  2075  5.15  31.8  5.12\n#&gt; 9 12210  8.09  58.9  8.06\n\nThe y variable measures one of the three dimensions of these diamonds, in mm.y å˜é‡ä»¥æ¯«ç±³ï¼ˆmmï¼‰ä¸ºå•ä½ï¼Œæµ‹é‡äº†è¿™äº›é’»çŸ³çš„ä¸‰ä¸ªç»´åº¦ä¹‹ä¸€ã€‚\nWe know that diamonds canâ€™t have a width of 0mm, so these values must be incorrect.\næˆ‘ä»¬çŸ¥é“é’»çŸ³çš„å®½åº¦ä¸å¯èƒ½æ˜¯ 0 æ¯«ç±³ï¼Œæ‰€ä»¥è¿™äº›å€¼è‚¯å®šæ˜¯é”™è¯¯çš„ã€‚\nBy doing EDA, we have discovered missing data that was coded as 0, which we never would have found by simply searching for NAs.\né€šè¿‡è¿›è¡Œ EDAï¼Œæˆ‘ä»¬å‘ç°äº†è¢«ç¼–ç ä¸º 0 çš„ç¼ºå¤±æ•°æ®ï¼Œè¿™æ˜¯æˆ‘ä»¬ä»…é€šè¿‡æœç´¢ NA æ°¸è¿œæ— æ³•å‘ç°çš„ã€‚\nGoing forward we might choose to re-code these values as NAs in order to prevent misleading calculations.\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šé€‰æ‹©å°†è¿™äº›å€¼é‡æ–°ç¼–ç ä¸º NAï¼Œä»¥é˜²æ­¢äº§ç”Ÿè¯¯å¯¼æ€§çš„è®¡ç®—ç»“æœã€‚\nWe might also suspect that measurements of 32mm and 59mm are implausible: those diamonds are over an inch long, but donâ€™t cost hundreds of thousands of dollars!\næˆ‘ä»¬å¯èƒ½è¿˜ä¼šæ€€ç–‘ 32 æ¯«ç±³å’Œ 59 æ¯«ç±³çš„æµ‹é‡å€¼æ˜¯ä¸å¯ä¿¡çš„ï¼šé‚£äº›é’»çŸ³è¶…è¿‡ä¸€è‹±å¯¸é•¿ï¼Œä½†ä»·æ ¼å´æ²¡æœ‰è¾¾åˆ°æ•°åä¸‡ç¾å…ƒï¼\nItâ€™s good practice to repeat your analysis with and without the outliers.\nä¸€ä¸ªå¥½çš„åšæ³•æ˜¯ï¼Œåœ¨åŒ…å«å’Œä¸åŒ…å«ç¦»ç¾¤å€¼çš„æƒ…å†µä¸‹é‡å¤ä½ çš„åˆ†æã€‚\nIf they have minimal effect on the results, and you canâ€™t figure out why theyâ€™re there, itâ€™s reasonable to omit them, and move on.\nå¦‚æœå®ƒä»¬å¯¹ç»“æœçš„å½±å“å¾®ä¹å…¶å¾®ï¼Œè€Œä¸”ä½ æ— æ³•æ‰¾å‡ºå®ƒä»¬å­˜åœ¨çš„åŸå› ï¼Œé‚£ä¹ˆçœç•¥å®ƒä»¬å¹¶ç»§ç»­åˆ†ææ˜¯åˆç†çš„ã€‚\nHowever, if they have a substantial effect on your results, you shouldnâ€™t drop them without justification.\nç„¶è€Œï¼Œå¦‚æœå®ƒä»¬å¯¹ä½ çš„ç»“æœæœ‰é‡å¤§å½±å“ï¼Œä½ å°±ä¸åº”è¯¥åœ¨æ²¡æœ‰æ­£å½“ç†ç”±çš„æƒ…å†µä¸‹ä¸¢å¼ƒå®ƒä»¬ã€‚\nYouâ€™ll need to figure out what caused them (e.g., a data entry error) and disclose that you removed them in your write-up.\nä½ éœ€è¦å¼„æ¸…æ¥šæ˜¯ä»€ä¹ˆå¯¼è‡´äº†å®ƒä»¬ï¼ˆä¾‹å¦‚ï¼Œæ•°æ®å½•å…¥é”™è¯¯ï¼‰ï¼Œå¹¶åœ¨ä½ çš„æŠ¥å‘Šä¸­æŠ«éœ²ä½ ç§»é™¤äº†å®ƒä»¬ã€‚\n\n10.3.3 Exercises\n\nExplore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.\nExplore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.)\nHow many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?\nCompare and contrast coord_cartesian() vs.Â xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#sec-unusual-values-eda",
    "href": "EDA.html#sec-unusual-values-eda",
    "title": "10Â  Exploratory data analysis",
    "section": "\n10.4 Unusual values",
    "text": "10.4 Unusual values\nIf youâ€™ve encountered unusual values in your dataset, and simply want to move on to the rest of your analysis, you have two options.\nå¦‚æœä½ åœ¨æ•°æ®é›†ä¸­é‡åˆ°äº†å¼‚å¸¸å€¼ï¼Œå¹¶ä¸”åªæƒ³ç»§ç»­è¿›è¡Œå…¶ä½™çš„åˆ†æï¼Œä½ æœ‰ä¸¤ä¸ªé€‰æ‹©ã€‚\n\n\nDrop the entire row with the strange values:\nåˆ é™¤åŒ…å«å¼‚å¸¸å€¼çš„æ•´è¡Œï¼š\n\ndiamonds2 &lt;- diamonds |&gt; \n  filter(between(y, 3, 20))\n\nWe donâ€™t recommend this option because one invalid value doesnâ€™t imply that all the other values for that observation are also invalid.\næˆ‘ä»¬ä¸æ¨èè¿™ä¸ªé€‰é¡¹ï¼Œå› ä¸ºä¸€ä¸ªæ— æ•ˆå€¼å¹¶ä¸æ„å‘³ç€è¯¥è§‚æµ‹çš„æ‰€æœ‰å…¶ä»–å€¼ä¹Ÿéƒ½æ— æ•ˆã€‚\nAdditionally, if you have low quality data, by the time that youâ€™ve applied this approach to every variable you might find that you donâ€™t have any data left!\næ­¤å¤–ï¼Œå¦‚æœä½ çš„æ•°æ®è´¨é‡å¾ˆä½ï¼Œå½“ä½ å¯¹æ¯ä¸ªå˜é‡éƒ½é‡‡ç”¨è¿™ç§æ–¹æ³•åï¼Œä½ å¯èƒ½ä¼šå‘ç°ä½ å·²ç»æ²¡æœ‰ä»»ä½•æ•°æ®äº†ï¼\n\n\nInstead, we recommend replacing the unusual values with missing values.\nç›¸åï¼Œæˆ‘ä»¬å»ºè®®ç”¨ç¼ºå¤±å€¼æ›¿æ¢å¼‚å¸¸å€¼ã€‚\nThe easiest way to do this is to use mutate() to replace the variable with a modified copy.\næœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ mutate() å°†å˜é‡æ›¿æ¢ä¸ºå…¶ä¿®æ”¹åçš„å‰¯æœ¬ã€‚\nYou can use the if_else() function to replace unusual values with NA:\nä½ å¯ä»¥ä½¿ç”¨ if_else() å‡½æ•°å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸º NAï¼š\n\ndiamonds2 &lt;- diamonds |&gt; \n  mutate(y = if_else(y &lt; 3 | y &gt; 20, NA, y))\n\n\n\nItâ€™s not obvious where you should plot missing values, so ggplot2 doesnâ€™t include them in the plot, but it does warn that theyâ€™ve been removed:\nç”±äºä¸æ¸…æ¥šåº”è¯¥åœ¨å“ªé‡Œç»˜åˆ¶ç¼ºå¤±å€¼ï¼Œggplot2 åœ¨ç»˜å›¾æ—¶ä¸ä¼šåŒ…å«å®ƒä»¬ï¼Œä½†ä¼šå‘å‡ºè­¦å‘Šï¼Œæç¤ºå®ƒä»¬å·²è¢«ç§»é™¤ï¼š\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point()\n#&gt; Warning: Removed 9 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\nTo suppress that warning, set na.rm = TRUE:\nè¦æŠ‘åˆ¶è¯¥è­¦å‘Šï¼Œè¯·è®¾ç½® na.rm = TRUEï¼š\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point(na.rm = TRUE)\n\nOther times you want to understand what makes observations with missing values different to observations with recorded values.\nå…¶ä»–æ—¶å€™ï¼Œä½ æƒ³è¦ç†è§£å…·æœ‰ç¼ºå¤±å€¼çš„è§‚æµ‹å€¼ä¸å…·æœ‰è®°å½•å€¼çš„è§‚æµ‹å€¼æœ‰ä½•ä¸åŒã€‚\nFor example, in nycflights13::flights1, missing values in the dep_time variable indicate that the flight was cancelled.\nä¾‹å¦‚ï¼Œåœ¨ nycflights13::flights1 ä¸­ï¼Œdep_time å˜é‡ä¸­çš„ç¼ºå¤±å€¼è¡¨ç¤ºèˆªç­è¢«å–æ¶ˆäº†ã€‚\nSo you might want to compare the scheduled departure times for cancelled and non-cancelled times.\nå› æ­¤ï¼Œä½ å¯èƒ½æƒ³æ¯”è¾ƒå·²å–æ¶ˆèˆªç­å’Œæœªå–æ¶ˆèˆªç­çš„è®¡åˆ’èµ·é£æ—¶é—´ã€‚\nYou can do this by making a new variable, using is.na() to check if dep_time is missing.\nä½ å¯ä»¥é€šè¿‡åˆ›å»ºä¸€ä¸ªæ–°å˜é‡æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä½¿ç”¨ is.na() æ¥æ£€æŸ¥ dep_time æ˜¯å¦ç¼ºå¤±ã€‚\n\nnycflights13::flights |&gt; \n  mutate(\n    cancelled = is.na(dep_time),\n    sched_hour = sched_dep_time %/% 100,\n    sched_min = sched_dep_time %% 100,\n    sched_dep_time = sched_hour + (sched_min / 60)\n  ) |&gt; \n  ggplot(aes(x = sched_dep_time)) + \n  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)\n\n\n\n\n\n\n\nHowever this plot isnâ€™t great because there are many more non-cancelled flights than cancelled flights.\nç„¶è€Œï¼Œè¿™å¼ å›¾å¹¶ä¸ç†æƒ³ï¼Œå› ä¸ºæœªå–æ¶ˆçš„èˆªç­æ•°é‡è¿œè¿œå¤šäºå·²å–æ¶ˆçš„èˆªç­ã€‚\nIn the next section weâ€™ll explore some techniques for improving this comparison.\nåœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸€äº›æ”¹è¿›è¿™ç§æ¯”è¾ƒçš„æŠ€å·§ã€‚\n\n10.4.1 Exercises\n\nWhat happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference in how missing values are handled in histograms and bar charts?\nWhat does na.rm = TRUE do in mean() and sum()?\nRecreate the frequency plot of scheduled_dep_time colored by whether the flight was cancelled or not. Also facet by the cancelled variable. Experiment with different values of the scales variable in the faceting function to mitigate the effect of more non-cancelled flights than cancelled flights.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#covariation",
    "href": "EDA.html#covariation",
    "title": "10Â  Exploratory data analysis",
    "section": "\n10.5 Covariation",
    "text": "10.5 Covariation\nIf variation describes the behavior within a variable, covariation describes the behavior between variables.\nå¦‚æœè¯´å˜å¼‚æè¿°çš„æ˜¯å•ä¸ªå˜é‡å†…éƒ¨çš„è¡Œä¸ºï¼Œé‚£ä¹ˆåå˜åˆ™æè¿°çš„æ˜¯å˜é‡ä¹‹é—´çš„è¡Œä¸ºã€‚\nCovariation is the tendency for the values of two or more variables to vary together in a related way.\n**åå˜ï¼ˆCovariationï¼‰**æ˜¯ä¸¤ä¸ªæˆ–å¤šä¸ªå˜é‡çš„å€¼ä»¥ç›¸å…³çš„æ–¹å¼ä¸€åŒå˜åŒ–çš„è¶‹åŠ¿ã€‚\nThe best way to spot covariation is to visualize the relationship between two or more variables.\nå‘ç°åå˜çš„æœ€å¥½æ–¹æ³•æ˜¯å¯è§†åŒ–ä¸¤ä¸ªæˆ–å¤šä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»ã€‚\n\n10.5.1 A categorical and a numerical variable\nFor example, letâ€™s explore how the price of a diamond varies with its quality (measured by cut) using geom_freqpoly():\nä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ geom_freqpoly() æ¥æ¢ç©¶é’»çŸ³ä»·æ ¼å¦‚ä½•éšå…¶è´¨é‡ï¼ˆä»¥ cut è¡¡é‡ï¼‰è€Œå˜åŒ–ï¼š\n\nggplot(diamonds, aes(x = price)) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\nNote that ggplot2 uses an ordered color scale for cut because itâ€™s defined as an ordered factor variable in the data.\nè¯·æ³¨æ„ï¼Œggplot2 å¯¹ cut ä½¿ç”¨äº†æœ‰åºé¢œè‰²æ ‡åº¦ï¼Œå› ä¸ºå®ƒåœ¨æ•°æ®ä¸­è¢«å®šä¹‰ä¸ºä¸€ä¸ªæœ‰åºå› å­å˜é‡ã€‚\nYouâ€™ll learn more about these in Section 16.6.\nä½ å°†åœ¨ Section 16.6 ç« èŠ‚ä¸­å­¦åˆ°æ›´å¤šå…³äºè¿™äº›çš„å†…å®¹ã€‚\nThe default appearance of geom_freqpoly() is not that useful here because the height, determined by the overall count, differs so much across cuts, making it hard to see the differences in the shapes of their distributions.\nåœ¨è¿™é‡Œï¼Œgeom_freqpoly() çš„é»˜è®¤å¤–è§‚å¹¶ä¸ååˆ†æœ‰ç”¨ï¼Œå› ä¸ºç”±æ€»è®¡æ•°å†³å®šçš„é«˜åº¦åœ¨ä¸åŒçš„ cutï¼ˆåˆ‡å·¥ï¼‰ä¹‹é—´å·®å¼‚å·¨å¤§ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬å¾ˆéš¾çœ‹å‡ºå®ƒä»¬åˆ†å¸ƒå½¢çŠ¶çš„å·®å¼‚ã€‚\nTo make the comparison easier we need to swap what is displayed on the y-axis.\nä¸ºäº†è®©æ¯”è¾ƒæ›´å®¹æ˜“ï¼Œæˆ‘ä»¬éœ€è¦æ›´æ¢ Y è½´ä¸Šæ˜¾ç¤ºçš„å†…å®¹ã€‚\nInstead of displaying count, weâ€™ll display the density, which is the count standardized so that the area under each frequency polygon is one.\næˆ‘ä»¬å°†ä¸å†æ˜¾ç¤ºè®¡æ•°ï¼Œè€Œæ˜¯æ˜¾ç¤ºå¯†åº¦ï¼Œå¯†åº¦æ˜¯ç»è¿‡æ ‡å‡†åŒ–çš„è®¡æ•°ï¼Œä½¿å¾—æ¯ä¸ªé¢‘ç‡å¤šè¾¹å½¢ä¸‹çš„é¢ç§¯ä¸ºä¸€ã€‚\n\nggplot(diamonds, aes(x = price, y = after_stat(density))) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\nNote that weâ€™re mapping the density to y, but since density is not a variable in the diamonds dataset, we need to first calculate it.\nè¯·æ³¨æ„ï¼Œæˆ‘ä»¬å°†å¯†åº¦æ˜ å°„åˆ° yï¼Œä½†ç”±äº density ä¸æ˜¯ diamonds æ•°æ®é›†ä¸­çš„å˜é‡ï¼Œæˆ‘ä»¬éœ€è¦å…ˆè®¡ç®—å®ƒã€‚\nWe use the after_stat() function to do so.\næˆ‘ä»¬ä½¿ç”¨ after_stat() å‡½æ•°æ¥å®Œæˆè¿™ä¸ªè®¡ç®—ã€‚\nThereâ€™s something rather surprising about this plot - it appears that fair diamonds (the lowest quality) have the highest average price!\nè¿™å¼ å›¾æœ‰äº›å‡ºäººæ„æ–™â€”â€”ä¼¼ä¹ â€œFairâ€ï¼ˆæœ€å·®è´¨é‡ï¼‰ç­‰çº§çš„é’»çŸ³å¹³å‡ä»·æ ¼æœ€é«˜ï¼\nBut maybe thatâ€™s because frequency polygons are a little hard to interpret - thereâ€™s a lot going on in this plot.\nä½†è¿™ä¹Ÿè®¸æ˜¯å› ä¸ºé¢‘ç‡å¤šè¾¹å½¢æœ‰ç‚¹éš¾ä»¥è§£è¯»â€”â€”è¿™å¼ å›¾ä¸­ä¿¡æ¯é‡å¤ªå¤§äº†ã€‚\nA visually simpler plot for exploring this relationship is using side-by-side boxplots.\nä¸€ä¸ªåœ¨è§†è§‰ä¸Šæ›´ç®€æ´ã€ç”¨äºæ¢ç´¢è¿™ç§å…³ç³»çš„å›¾æ˜¯å¹¶æ’ç®±çº¿å›¾ã€‚\n\nggplot(diamonds, aes(x = cut, y = price)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nWe see much less information about the distribution, but the boxplots are much more compact so we can more easily compare them (and fit more on one plot).\næˆ‘ä»¬çœ‹åˆ°çš„å…³äºåˆ†å¸ƒçš„ä¿¡æ¯å°‘äº†å¾ˆå¤šï¼Œä½†ç®±çº¿å›¾æ›´åŠ ç´§å‡‘ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æ›´å®¹æ˜“åœ°æ¯”è¾ƒå®ƒä»¬ï¼ˆå¹¶ä¸”å¯ä»¥åœ¨ä¸€å¼ å›¾ä¸Šå®¹çº³æ›´å¤šå†…å®¹ï¼‰ã€‚\nIt supports the counter-intuitive finding that better quality diamonds are typically cheaper!\nå®ƒæ”¯æŒäº†ä¸€ä¸ªä¸ç›´è§‰ç›¸æ‚–çš„å‘ç°ï¼šè´¨é‡æ›´å¥½çš„é’»çŸ³é€šå¸¸æ›´ä¾¿å®œï¼\nIn the exercises, youâ€™ll be challenged to figure out why.\nåœ¨ç»ƒä¹ ä¸­ï¼Œä½ å°†éœ€è¦æŒ‘æˆ˜å»å¼„æ¸…æ¥šä¸ºä»€ä¹ˆä¼šè¿™æ ·ã€‚\ncut is an ordered factor: fair is worse than good, which is worse than very good and so on.cut æ˜¯ä¸€ä¸ªæœ‰åºå› å­ï¼šfair æ¯” good å·®ï¼Œgood åˆæ¯” very good å·®ï¼Œä»¥æ­¤ç±»æ¨ã€‚\nMany categorical variables donâ€™t have such an intrinsic order, so you might want to reorder them to make a more informative display.\nè®¸å¤šåˆ†ç±»å˜é‡æ²¡æœ‰è¿™ç§å†…åœ¨çš„é¡ºåºï¼Œæ‰€ä»¥ä½ å¯èƒ½æƒ³è¦é‡æ–°æ’åºå®ƒä»¬ä»¥è·å¾—ä¿¡æ¯æ›´ä¸°å¯Œçš„å±•ç¤ºã€‚\nOne way to do that is with fct_reorder().\nä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ fct_reorder()ã€‚\nYouâ€™ll learn more about that function in Section 16.4, but we want to give you a quick preview here because itâ€™s so useful.\nä½ å°†åœ¨ Section 16.4 ä¸­å­¦åˆ°æ›´å¤šå…³äºè¯¥å‡½æ•°çš„å†…å®¹ï¼Œä½†æˆ‘ä»¬æƒ³åœ¨è¿™é‡Œç»™ä½ ä¸€ä¸ªå¿«é€Ÿé¢„è§ˆï¼Œå› ä¸ºå®ƒéå¸¸æœ‰ç”¨ã€‚\nFor example, take the class variable in the mpg dataset.\nä¾‹å¦‚ï¼Œä»¥ mpg æ•°æ®é›†ä¸­çš„ class å˜é‡ä¸ºä¾‹ã€‚\nYou might be interested to know how highway mileage varies across classes:\nä½ å¯èƒ½æƒ³çŸ¥é“ä¸åŒè½¦è¾†ç±»åˆ«çš„é«˜é€Ÿå…¬è·¯é‡Œç¨‹æ•°æœ‰ä½•ä¸åŒï¼š\n\nggplot(mpg, aes(x = class, y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nTo make the trend easier to see, we can reorder class based on the median value of hwy:\nä¸ºäº†ä½¿è¶‹åŠ¿æ›´æ˜“äºè§‚å¯Ÿï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ® hwy çš„ä¸­ä½æ•°å¯¹ class è¿›è¡Œé‡æ–°æ’åºï¼š\n\nggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nIf you have long variable names, geom_boxplot() will work better if you flip it 90Â°.\nå¦‚æœä½ çš„å˜é‡åå¾ˆé•¿ï¼Œå°† geom_boxplot() ç¿»è½¬ 90Â° ä¼šæœ‰æ›´å¥½çš„æ•ˆæœã€‚\nYou can do that by exchanging the x and y aesthetic mappings.\nä½ å¯ä»¥é€šè¿‡äº¤æ¢ x å’Œ y çš„ç¾å­¦æ˜ å°„æ¥å®ç°è¿™ä¸€ç‚¹ã€‚\n\nggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n10.5.1.1 Exercises\n\nUse what youâ€™ve learned to improve the visualization of the departure times of cancelled vs.Â non-cancelled flights.\nBased on EDA, what variable in the diamonds dataset appears to be most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?\nInstead of exchanging the x and y variables, add coord_flip() as a new layer to the vertical boxplot to create a horizontal one. How does this compare to exchanging the variables?\nOne problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of â€œoutlying valuesâ€. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs.Â cut. What do you learn? How do you interpret the plots?\nCreate a visualization of diamond prices vs.Â a categorical variable from the diamonds dataset using geom_violin(), then a faceted geom_histogram(), then a colored geom_freqpoly(), and then a colored geom_density(). Compare and contrast the four plots. What are the pros and cons of each method of visualizing the distribution of a numerical variable based on the levels of a categorical variable?\nIf you have a small dataset, itâ€™s sometimes useful to use geom_jitter() to avoid overplotting to more easily see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.\n\n10.5.2 Two categorical variables\nTo visualize the covariation between categorical variables, youâ€™ll need to count the number of observations for each combination of levels of these categorical variables.\nè¦å¯è§†åŒ–åˆ†ç±»å˜é‡ä¹‹é—´çš„åå˜ï¼Œä½ éœ€è¦è®¡ç®—è¿™äº›åˆ†ç±»å˜é‡å„æ°´å¹³ç»„åˆçš„è§‚æµ‹æ•°é‡ã€‚\nOne way to do that is to rely on the built-in geom_count():\nä¸€ç§æ–¹æ³•æ˜¯ä¾èµ–äºå†…ç½®çš„ geom_count() å‡½æ•°ï¼š\n\nggplot(diamonds, aes(x = cut, y = color)) +\n  geom_count()\n\n\n\n\n\n\n\nThe size of each circle in the plot displays how many observations occurred at each combination of values.\nå›¾ä¸­æ¯ä¸ªåœ†åœˆçš„å¤§å°æ˜¾ç¤ºäº†åœ¨æ¯ä¸ªå€¼ç»„åˆå¤„å‘ç”Ÿçš„è§‚æµ‹æ¬¡æ•°ã€‚\nCovariation will appear as a strong correlation between specific x values and specific y values.\nåå˜å°†è¡¨ç°ä¸ºç‰¹å®š x å€¼å’Œç‰¹å®š y å€¼ä¹‹é—´çš„å¼ºç›¸å…³æ€§ã€‚\nAnother approach for exploring the relationship between these variables is computing the counts with dplyr:\næ¢ç´¢è¿™äº›å˜é‡ä¹‹é—´å…³ç³»çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ dplyr è®¡ç®—è®¡æ•°ï¼š\n\ndiamonds |&gt; \n  count(color, cut)\n#&gt; # A tibble: 35 Ã— 3\n#&gt;   color cut           n\n#&gt;   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt;\n#&gt; 1 D     Fair        163\n#&gt; 2 D     Good        662\n#&gt; 3 D     Very Good  1513\n#&gt; 4 D     Premium    1603\n#&gt; 5 D     Ideal      2834\n#&gt; 6 E     Fair        224\n#&gt; # â„¹ 29 more rows\n\nThen visualize with geom_tile() and the fill aesthetic:\nç„¶åä½¿ç”¨ geom_tile() å’Œå¡«å……ç¾å­¦è¿›è¡Œå¯è§†åŒ–ï¼š\n\ndiamonds |&gt; \n  count(color, cut) |&gt;  \n  ggplot(aes(x = color, y = cut)) +\n  geom_tile(aes(fill = n))\n\n\n\n\n\n\n\nIf the categorical variables are unordered, you might want to use the seriation package to simultaneously reorder the rows and columns in order to more clearly reveal interesting patterns.\nå¦‚æœåˆ†ç±»å˜é‡æ˜¯æ— åºçš„ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨ seriation åŒ…æ¥åŒæ—¶å¯¹è¡Œå’Œåˆ—è¿›è¡Œé‡æ–°æ’åºï¼Œä»¥ä¾¿æ›´æ¸…æ™°åœ°æ­ç¤ºæœ‰è¶£çš„æ¨¡å¼ã€‚\nFor larger plots, you might want to try the heatmaply package, which creates interactive plots.\nå¯¹äºè¾ƒå¤§çš„å›¾è¡¨ï¼Œä½ å¯èƒ½æƒ³å°è¯• heatmaply åŒ…ï¼Œå®ƒå¯ä»¥åˆ›å»ºäº¤äº’å¼å›¾è¡¨ã€‚\n\n10.5.2.1 Exercises\n\nHow could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?\nWhat different data insights do you get with a segmented bar chart if color is mapped to the x aesthetic and cut is mapped to the fill aesthetic? Calculate the counts that fall into each of the segments.\nUse geom_tile() together with dplyr to explore how average flight departure delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?\n\n10.5.3 Two numerical variables\nYouâ€™ve already seen one great way to visualize the covariation between two numerical variables: draw a scatterplot with geom_point().\nä½ å·²ç»è§è¿‡ä¸€ç§å¯è§†åŒ–ä¸¤ä¸ªæ•°å€¼å˜é‡åå˜çš„å¥½æ–¹æ³•ï¼šç”¨ geom_point() ç»˜åˆ¶æ•£ç‚¹å›¾ã€‚\nYou can see covariation as a pattern in the points.\nä½ å¯ä»¥å°†åå˜çœ‹ä½œæ˜¯æ•°æ®ç‚¹ä¸­çš„ä¸€ç§æ¨¡å¼ã€‚\nFor example, you can see a positive relationship between the carat size and price of a diamond: diamonds with more carats have a higher price.\nä¾‹å¦‚ï¼Œä½ å¯ä»¥çœ‹åˆ°é’»çŸ³çš„å…‹æ‹‰å¤§å°å’Œä»·æ ¼ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼šå…‹æ‹‰æ•°è¶Šå¤§çš„é’»çŸ³ä»·æ ¼è¶Šé«˜ã€‚\nThe relationship is exponential.\nè¿™ç§å…³ç³»æ˜¯æŒ‡æ•°çº§çš„ã€‚\n\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_point()\n\n\n\n\n\n\n\n(In this section weâ€™ll use the smaller dataset to stay focused on the bulk of the diamonds that are smaller than 3 carats)\nï¼ˆåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ smaller æ•°æ®é›†ï¼Œä»¥ä¸“æ³¨äºå°äº 3 å…‹æ‹‰çš„å¤§éƒ¨åˆ†é’»çŸ³ï¼‰\nScatterplots become less useful as the size of your dataset grows, because points begin to overplot, and pile up into areas of uniform black, making it hard to judge differences in the density of the data across the 2-dimensional space as well as making it hard to spot the trend.\néšç€æ•°æ®é›†è§„æ¨¡çš„å¢é•¿ï¼Œæ•£ç‚¹å›¾çš„ç”¨å¤„ä¼šå‡å°ï¼Œå› ä¸ºæ•°æ®ç‚¹å¼€å§‹é‡å ç»˜å›¾ï¼ˆoverplotï¼‰ï¼Œå †ç§¯æˆä¸€ç‰‡çº¯é»‘çš„åŒºåŸŸï¼Œè¿™ä½¿å¾—åˆ¤æ–­æ•°æ®åœ¨äºŒç»´ç©ºé—´ä¸­çš„å¯†åº¦å·®å¼‚ä»¥åŠå‘ç°è¶‹åŠ¿éƒ½å˜å¾—å›°éš¾ã€‚\nYouâ€™ve already seen one way to fix the problem: using the alpha aesthetic to add transparency.\nä½ å·²ç»çœ‹åˆ°ä¸€ç§è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ï¼šä½¿ç”¨ alpha ç¾å­¦æ¥å¢åŠ é€æ˜åº¦ã€‚\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_point(alpha = 1 / 100)\n\n\n\n\n\n\n\nBut using transparency can be challenging for very large datasets.\nä½†æ˜¯å¯¹äºéå¸¸å¤§çš„æ•°æ®é›†ï¼Œä½¿ç”¨é€æ˜åº¦å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚\nAnother solution is to use bin.\nå¦ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨åˆ†ç®±ï¼ˆbinï¼‰ã€‚\nPreviously you used geom_histogram() and geom_freqpoly() to bin in one dimension.\nä¹‹å‰ä½ ä½¿ç”¨ geom_histogram() å’Œ geom_freqpoly() åœ¨ä¸€ç»´ç©ºé—´ä¸­è¿›è¡Œåˆ†ç®±ã€‚\nNow youâ€™ll learn how to use geom_bin2d() and geom_hex() to bin in two dimensions.\nç°åœ¨ä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ geom_bin2d() å’Œ geom_hex() åœ¨äºŒç»´ç©ºé—´ä¸­è¿›è¡Œåˆ†ç®±ã€‚\ngeom_bin2d() and geom_hex() divide the coordinate plane into 2d bins and then use a fill color to display how many points fall into each bin.geom_bin2d() å’Œ geom_hex() å°†åæ ‡å¹³é¢åˆ’åˆ†ä¸ºäºŒç»´çš„ç®±å­ï¼Œç„¶åä½¿ç”¨å¡«å……é¢œè‰²æ¥æ˜¾ç¤ºæ¯ä¸ªç®±å­ä¸­æœ‰å¤šå°‘ä¸ªæ•°æ®ç‚¹ã€‚\ngeom_bin2d() creates rectangular bins.geom_bin2d() åˆ›å»ºçŸ©å½¢ç®±ã€‚\ngeom_hex() creates hexagonal bins.geom_hex() åˆ›å»ºå…­è¾¹å½¢ç®±ã€‚\nYou will need to install the hexbin package to use geom_hex().\nä½ éœ€è¦å®‰è£… hexbin åŒ…æ‰èƒ½ä½¿ç”¨ geom_hex()ã€‚\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_bin2d()\n\n# install.packages(\"hexbin\")\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_hex()\n\n\n\n\n\n\n\n\n\n\nAnother option is to bin one continuous variable so it acts like a categorical variable.\nå¦ä¸€ç§é€‰æ‹©æ˜¯å¯¹ä¸€ä¸ªè¿ç»­å˜é‡è¿›è¡Œåˆ†ç®±ï¼Œä½¿å…¶è¡¨ç°å¾—åƒä¸€ä¸ªåˆ†ç±»å˜é‡ã€‚\nThen you can use one of the techniques for visualizing the combination of a categorical and a continuous variable that you learned about.\nç„¶åï¼Œä½ å¯ä»¥ä½¿ç”¨ä½ å­¦è¿‡çš„å¯è§†åŒ–åˆ†ç±»å˜é‡å’Œè¿ç»­å˜é‡ç»„åˆçš„æŠ€å·§ä¹‹ä¸€ã€‚\nFor example, you could bin carat and then for each group, display a boxplot:\nä¾‹å¦‚ï¼Œä½ å¯ä»¥å¯¹ carat è¿›è¡Œåˆ†ç®±ï¼Œç„¶åä¸ºæ¯ä¸ªç»„æ˜¾ç¤ºä¸€ä¸ªç®±çº¿å›¾ï¼š\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_width(carat, 0.1)))\n\n\n\n\n\n\n\ncut_width(x, width), as used above, divides x into bins of width width.\nå¦‚ä¸Šæ‰€ç¤ºï¼Œcut_width(x, width) å°† x åˆ†å‰²æˆå®½åº¦ä¸º width çš„åŒºé—´ã€‚\nBy default, boxplots look roughly the same (apart from number of outliers) regardless of how many observations there are, so itâ€™s difficult to tell that each boxplot summarizes a different number of points.\né»˜è®¤æƒ…å†µä¸‹ï¼Œæ— è®ºè§‚æµ‹æ•°é‡å¤šå°‘ï¼Œç®±çº¿å›¾çœ‹èµ·æ¥éƒ½å¤§è‡´ç›¸åŒï¼ˆé™¤äº†ç¦»ç¾¤ç‚¹çš„æ•°é‡ï¼‰ï¼Œå› æ­¤å¾ˆéš¾åˆ¤æ–­æ¯ä¸ªç®±çº¿å›¾æ‰€æ¦‚æ‹¬çš„æ•°æ®ç‚¹æ•°é‡æ˜¯ä¸åŒçš„ã€‚\nOne way to show that is to make the width of the boxplot proportional to the number of points with varwidth = TRUE.\nä¸€ç§æ˜¾ç¤ºè¿™ä¸€ç‚¹çš„æ–¹æ³•æ˜¯ï¼Œé€šè¿‡è®¾ç½® varwidth = TRUEï¼Œä½¿ç®±çº¿å›¾çš„å®½åº¦ä¸æ•°æ®ç‚¹çš„æ•°é‡æˆæ­£æ¯”ã€‚\n\n10.5.3.1 Exercises\n\nInstead of summarizing the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs.Â cut_number()? How does that impact a visualization of the 2d distribution of carat and price?\nVisualize the distribution of carat, partitioned by price.\nHow does the price distribution of very large diamonds compare to small diamonds? Is it as you expect, or does it surprise you?\nCombine two of the techniques youâ€™ve learned to visualize the combined distribution of cut, carat, and price.\n\nTwo dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the following plot have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately. Why is a scatterplot a better display than a binned plot for this case?\n\ndiamonds |&gt; \n  filter(x &gt;= 4) |&gt; \n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))\n\n\n\nInstead of creating boxes of equal width with cut_width(), we could create boxes that contain roughly equal number of points with cut_number(). What are the advantages and disadvantages of this approach?\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_number(carat, 20)))",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#patterns-and-models",
    "href": "EDA.html#patterns-and-models",
    "title": "10Â  Exploratory data analysis",
    "section": "\n10.6 Patterns and models",
    "text": "10.6 Patterns and models\nIf a systematic relationship exists between two variables it will appear as a pattern in the data.\nå¦‚æœä¸¤ä¸ªå˜é‡ä¹‹é—´å­˜åœ¨ç³»ç»Ÿæ€§å…³ç³»ï¼Œå®ƒå°†ä»¥æ¨¡å¼çš„å½¢å¼å‡ºç°åœ¨æ•°æ®ä¸­ã€‚\nIf you spot a pattern, ask yourself:\nå¦‚æœä½ å‘ç°ä¸€ä¸ªæ¨¡å¼ï¼Œé—®é—®è‡ªå·±ï¼š\n\nCould this pattern be due to coincidence (i.e.Â random chance)?\nè¿™ä¸ªæ¨¡å¼å¯èƒ½æ˜¯ç”±äºå·§åˆï¼ˆå³éšæœºæœºä¼šï¼‰å—ï¼Ÿ\nHow can you describe the relationship implied by the pattern?\nä½ å¦‚ä½•æè¿°è¿™ä¸ªæ¨¡å¼æ‰€æš—ç¤ºçš„å…³ç³»ï¼Ÿ\nHow strong is the relationship implied by the pattern?\nè¿™ä¸ªæ¨¡å¼æ‰€æš—ç¤ºçš„å…³ç³»æœ‰å¤šå¼ºï¼Ÿ\nWhat other variables might affect the relationship?\nè¿˜æœ‰å“ªäº›å…¶ä»–å˜é‡å¯èƒ½ä¼šå½±å“è¿™ç§å…³ç³»ï¼Ÿ\nDoes the relationship change if you look at individual subgroups of the data?\nå¦‚æœè§‚å¯Ÿæ•°æ®çš„å•ä¸ªå­ç¾¤ï¼Œè¿™ç§å…³ç³»ä¼šæ”¹å˜å—ï¼Ÿ\n\nPatterns in your data provide clues about relationships, i.e., they reveal covariation.\næ•°æ®ä¸­çš„æ¨¡å¼ä¸ºæˆ‘ä»¬æä¾›äº†å…³äºå…³ç³»çš„çº¿ç´¢ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬æ­ç¤ºäº†åå˜å…³ç³»ã€‚\nIf you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it.\nå¦‚æœä½ å°†å˜å¼‚è§†ä¸ºä¸€ç§äº§ç”Ÿä¸ç¡®å®šæ€§çš„ç°è±¡ï¼Œé‚£ä¹ˆåå˜å°±æ˜¯ä¸€ç§å‡å°‘ä¸ç¡®å®šæ€§çš„ç°è±¡ã€‚\nIf two variables covary, you can use the values of one variable to make better predictions about the values of the second.\nå¦‚æœä¸¤ä¸ªå˜é‡åå˜ï¼Œä½ å¯ä»¥åˆ©ç”¨ä¸€ä¸ªå˜é‡çš„å€¼æ¥æ›´å¥½åœ°é¢„æµ‹å¦ä¸€ä¸ªå˜é‡çš„å€¼ã€‚\nIf the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second.\nå¦‚æœåå˜æ˜¯ç”±å› æœå…³ç³»ï¼ˆä¸€ç§ç‰¹æ®Šæƒ…å†µï¼‰å¼•èµ·çš„ï¼Œé‚£ä¹ˆä½ å¯ä»¥åˆ©ç”¨ä¸€ä¸ªå˜é‡çš„å€¼æ¥æ§åˆ¶å¦ä¸€ä¸ªå˜é‡çš„å€¼ã€‚\nModels are a tool for extracting patterns out of data.\næ¨¡å‹æ˜¯ä»æ•°æ®ä¸­æå–æ¨¡å¼çš„å·¥å…·ã€‚\nFor example, consider the diamonds data.\nä¾‹å¦‚ï¼Œè€ƒè™‘é’»çŸ³æ•°æ®ã€‚\nItâ€™s hard to understand the relationship between cut and price, because cut and carat, and carat and price are tightly related.\nå¾ˆéš¾ç†è§£åˆ‡å·¥å’Œä»·æ ¼ä¹‹é—´çš„å…³ç³»ï¼Œå› ä¸ºåˆ‡å·¥å’Œå…‹æ‹‰ï¼Œä»¥åŠå…‹æ‹‰å’Œä»·æ ¼æ˜¯ç´§å¯†ç›¸å…³çš„ã€‚\nItâ€™s possible to use a model to remove the very strong relationship between price and carat so we can explore the subtleties that remain.\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹æ¥ç§»é™¤ä»·æ ¼å’Œå…‹æ‹‰ä¹‹é—´éå¸¸å¼ºçš„å…³ç³»ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥æ¢ç´¢å…¶ä¸­å‰©ä¸‹çš„ç»†å¾®ä¹‹å¤„ã€‚\nThe following code fits a model that predicts price from carat and then computes the residuals (the difference between the predicted value and the actual value).\nä»¥ä¸‹ä»£ç æ‹Ÿåˆäº†ä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ ¹æ® carat é¢„æµ‹ priceï¼Œç„¶åè®¡ç®—æ®‹å·®ï¼ˆé¢„æµ‹å€¼ä¸å®é™…å€¼ä¹‹é—´çš„å·®å¼‚ï¼‰ã€‚\nThe residuals give us a view of the price of the diamond, once the effect of carat has been removed.\næ®‹å·®è®©æˆ‘ä»¬èƒ½å¤Ÿçœ‹åˆ°åœ¨ç§»é™¤äº†å…‹æ‹‰æ•ˆåº”åé’»çŸ³çš„ä»·æ ¼æƒ…å†µã€‚\nNote that instead of using the raw values of price and carat, we log transform them first, and fit a model to the log-transformed values.\nè¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ price å’Œ carat çš„åŸå§‹å€¼ï¼Œè€Œæ˜¯å…ˆå¯¹å®ƒä»¬è¿›è¡Œå¯¹æ•°è½¬æ¢ï¼Œç„¶åå¯¹å¯¹æ•°è½¬æ¢åçš„å€¼æ‹Ÿåˆæ¨¡å‹ã€‚\nThen, we exponentiate the residuals to put them back in the scale of raw prices.\nç„¶åï¼Œæˆ‘ä»¬å¯¹æ®‹å·®è¿›è¡ŒæŒ‡æ•°åŒ–ï¼Œä»¥å°†å®ƒä»¬æ¢å¤åˆ°åŸå§‹ä»·æ ¼çš„å°ºåº¦ã€‚\n\nlibrary(tidymodels)\n\ndiamonds &lt;- diamonds |&gt;\n  mutate(\n    log_price = log(price),\n    log_carat = log(carat)\n  )\n\ndiamonds_fit &lt;- linear_reg() |&gt;\n  fit(log_price ~ log_carat, data = diamonds)\n\ndiamonds_aug &lt;- augment(diamonds_fit, new_data = diamonds) |&gt;\n  mutate(.resid = exp(.resid))\n\nggplot(diamonds_aug, aes(x = carat, y = .resid)) + \n  geom_point()\n\n\n\n\n\n\n\nOnce youâ€™ve removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price: relative to their size, better quality diamonds are more expensive.\nä¸€æ—¦ä½ ç§»é™¤äº†å…‹æ‹‰å’Œä»·æ ¼ä¹‹é—´çš„å¼ºç›¸å…³æ€§ï¼Œä½ å°±èƒ½åœ¨åˆ‡å·¥å’Œä»·æ ¼çš„å…³ç³»ä¸­çœ‹åˆ°ä½ æ‰€é¢„æœŸçš„ç»“æœï¼šç›¸å¯¹äºå®ƒä»¬çš„å¤§å°è€Œè¨€ï¼Œè´¨é‡æ›´å¥½çš„é’»çŸ³æ›´æ˜‚è´µã€‚\n\nggplot(diamonds_aug, aes(x = cut, y = .resid)) + \n  geom_boxplot()\n\n\n\n\n\n\n\nWeâ€™re not discussing modelling in this book because understanding what models are and how they work is easiest once you have tools of data wrangling and programming in hand.\næˆ‘ä»¬åœ¨è¿™æœ¬ä¹¦ä¸­ä¸è®¨è®ºå»ºæ¨¡ï¼Œå› ä¸ºä¸€æ—¦ä½ æŒæ¡äº†æ•°æ®æ•´ç†å’Œç¼–ç¨‹çš„å·¥å…·ï¼Œç†è§£æ¨¡å‹æ˜¯ä»€ä¹ˆä»¥åŠå®ƒä»¬å¦‚ä½•å·¥ä½œå°±ä¼šå˜å¾—æœ€å®¹æ˜“ã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#summary",
    "href": "EDA.html#summary",
    "title": "10Â  Exploratory data analysis",
    "section": "\n10.7 Summary",
    "text": "10.7 Summary\nIn this chapter youâ€™ve learned a variety of tools to help you understand the variation within your data.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†å„ç§å·¥å…·æ¥å¸®åŠ©ä½ ç†è§£æ•°æ®ä¸­çš„å˜å¼‚ã€‚\nYouâ€™ve seen techniques that work with a single variable at a time and with a pair of variables.\nä½ å·²ç»çœ‹åˆ°äº†å¤„ç†å•ä¸ªå˜é‡ä»¥åŠä¸€å¯¹å˜é‡çš„æŠ€å·§ã€‚\nThis might seem painfully restrictive if you have tens or hundreds of variables in your data, but theyâ€™re the foundation upon which all other techniques are built.\nå¦‚æœä½ çš„æ•°æ®ä¸­æœ‰æ•°åæˆ–æ•°ç™¾ä¸ªå˜é‡ï¼Œè¿™å¯èƒ½çœ‹èµ·æ¥é™åˆ¶æ€§å¾ˆå¼ºï¼Œä½†å®ƒä»¬æ˜¯æ‰€æœ‰å…¶ä»–æŠ€æœ¯æ„å»ºçš„åŸºç¡€ã€‚\nIn the next chapter, weâ€™ll focus on the tools we can use to communicate our results.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºå¯ä»¥ç”¨æ¥äº¤æµæˆ‘ä»¬ç»“æœçš„å·¥å…·ã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#footnotes",
    "href": "EDA.html#footnotes",
    "title": "10Â  Exploratory data analysis",
    "section": "",
    "text": "Remember that when we need to be explicit about where a function (or dataset) comes from, weâ€™ll use the special form package::function() or package::dataset.â†©ï¸",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "communication.html",
    "href": "communication.html",
    "title": "11Â  Communication",
    "section": "",
    "text": "11.1 Introduction\nIn Chapter 10, you learned how to use plots as tools for exploration. When you make exploratory plots, you knowâ€”even before lookingâ€”which variables the plot will display. You made each plot for a purpose, could quickly look at it, and then move on to the next plot. In the course of most analyses, youâ€™ll produce tens or hundreds of plots, most of which are immediately thrown away.\nåœ¨ Chapter 10 ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨å›¾å½¢ä½œä¸ºæ¢ç´¢çš„å·¥å…·ã€‚å½“ä½ åˆ¶ä½œæ¢ç´¢æ€§å›¾å½¢æ—¶ï¼Œä½ ç”šè‡³åœ¨çœ‹å›¾ä¹‹å‰å°±çŸ¥é“å®ƒå°†æ˜¾ç¤ºå“ªäº›å˜é‡ã€‚ä½ åˆ¶ä½œçš„æ¯ä¸ªå›¾å½¢éƒ½æœ‰å…¶ç›®çš„ï¼Œå¯ä»¥å¿«é€Ÿæµè§ˆä¸€ä¸‹ï¼Œç„¶åç»§ç»­åˆ¶ä½œä¸‹ä¸€ä¸ªã€‚åœ¨å¤§å¤šæ•°åˆ†æè¿‡ç¨‹ä¸­ï¼Œä½ ä¼šç”Ÿæˆæ•°åç”šè‡³æ•°ç™¾ä¸ªå›¾å½¢ï¼Œå…¶ä¸­å¤§éƒ¨åˆ†éƒ½ä¼šè¢«ç«‹å³ä¸¢å¼ƒã€‚\nNow that you understand your data, you need to communicate your understanding to others. Your audience will likely not share your background knowledge and will not be deeply invested in the data. To help others quickly build up a good mental model of the data, you will need to invest considerable effort in making your plots as self-explanatory as possible. In this chapter, youâ€™ll learn some of the tools that ggplot2 provides to do so.\nç°åœ¨ä½ å·²ç»ç†è§£äº†ä½ çš„æ•°æ®ï¼Œä½ éœ€è¦å°†ä½ çš„ç†è§£ä¼ è¾¾ç»™ä»–äººã€‚ä½ çš„å—ä¼—å¾ˆå¯èƒ½ä¸å…·å¤‡ä½ çš„èƒŒæ™¯çŸ¥è¯†ï¼Œä¹Ÿä¸ä¼šå¯¹æ•°æ®æŠ•å…¥å¤ªå¤šç²¾åŠ›ã€‚ä¸ºäº†å¸®åŠ©ä»–äººå¿«é€Ÿå»ºç«‹èµ·å¯¹æ•°æ®çš„è‰¯å¥½å¿ƒæ™ºæ¨¡å‹ï¼Œä½ éœ€è¦æŠ•å…¥å¤§é‡ç²¾åŠ›ä½¿ä½ çš„å›¾å½¢å°½å¯èƒ½åœ°ä¸è¨€è‡ªæ˜ã€‚åœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹  ggplot2 ä¸ºæ­¤æä¾›çš„ä¸€äº›å·¥å…·ã€‚\nThis chapter focuses on the tools you need to create good graphics. We assume that you know what you want, and just need to know how to do it. For that reason, we highly recommend pairing this chapter with a good general visualization book. We particularly like The Truthful Art, by Albert Cairo. It doesnâ€™t teach the mechanics of creating visualizations, but instead focuses on what you need to think about in order to create effective graphics.\næœ¬ç« é‡ç‚¹ä»‹ç»åˆ›å»ºä¼˜ç§€å›¾å½¢æ‰€éœ€çš„å·¥å…·ã€‚æˆ‘ä»¬å‡è®¾ä½ å·²ç»çŸ¥é“è‡ªå·±æƒ³è¦ä»€ä¹ˆï¼Œåªéœ€è¦çŸ¥é“å¦‚ä½•å®ç°å®ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®å°†æœ¬ç« ä¸ä¸€æœ¬ä¼˜ç§€çš„é€šç”¨å¯è§†åŒ–ä¹¦ç±ç»“åˆé˜…è¯»ã€‚æˆ‘ä»¬ç‰¹åˆ«æ¨è Albert Cairo çš„ The Truthful Artã€‚è¿™æœ¬ä¹¦ä¸æ•™ä½ åˆ›å»ºå¯è§†åŒ–çš„å…·ä½“æ“ä½œï¼Œè€Œæ˜¯ä¸“æ³¨äºä¸ºäº†åˆ›ä½œæœ‰æ•ˆçš„å›¾å½¢ä½ éœ€è¦æ€è€ƒäº›ä»€ä¹ˆã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#introduction",
    "href": "communication.html#introduction",
    "title": "11Â  Communication",
    "section": "",
    "text": "11.1.1 Prerequisites\nIn this chapter, weâ€™ll focus once again on ggplot2. Weâ€™ll also use a little dplyr for data manipulation, scales to override the default breaks, labels, transformations and palettes, and a few ggplot2 extension packages, including ggrepel (https://ggrepel.slowkow.com) by Kamil Slowikowski and patchwork (https://patchwork.data-imaginist.com) by Thomas Lin Pedersen. Donâ€™t forget that youâ€™ll need to install those packages with install.packages() if you donâ€™t already have them.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†å†æ¬¡èšç„¦äº ggplot2ã€‚æˆ‘ä»¬è¿˜ä¼šä½¿ç”¨ä¸€äº› dplyr è¿›è¡Œæ•°æ®æ“ä½œï¼Œä½¿ç”¨ scales åŒ…æ¥è¦†ç›–é»˜è®¤çš„åˆ»åº¦ã€æ ‡ç­¾ã€å˜æ¢å’Œè°ƒè‰²æ¿ï¼Œä»¥åŠä¸€äº› ggplot2 æ‰©å±•åŒ…ï¼ŒåŒ…æ‹¬ Kamil Slowikowski å¼€å‘çš„ ggrepel (https://ggrepel.slowkow.com) å’Œ Thomas Lin Pedersen å¼€å‘çš„ patchwork (https://patchwork.data-imaginist.com)ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£…è¿™äº›åŒ…ï¼Œåˆ«å¿˜äº†ç”¨ install.packages() æ¥å®‰è£…å®ƒä»¬ã€‚\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(patchwork)",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#labels",
    "href": "communication.html#labels",
    "title": "11Â  Communication",
    "section": "\n11.2 Labels",
    "text": "11.2 Labels\nThe easiest place to start when turning an exploratory graphic into an expository graphic is with good labels. You add labels with the labs() function.\nå°†æ¢ç´¢æ€§å›¾å½¢è½¬å˜ä¸ºè§£é‡Šæ€§å›¾å½¢ï¼Œæœ€ç®€å•çš„å…¥æ‰‹ç‚¹å°±æ˜¯æ·»åŠ è‰¯å¥½çš„æ ‡ç­¾ã€‚ä½ å¯ä»¥ä½¿ç”¨ labs() å‡½æ•°æ¥æ·»åŠ æ ‡ç­¾ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Engine displacement (L)\",\n    y = \"Highway fuel economy (mpg)\",\n    color = \"Car type\",\n    title = \"Fuel efficiency generally decreases with engine size\",\n    subtitle = \"Two seaters (sports cars) are an exception because of their light weight\",\n    caption = \"Data from fueleconomy.gov\"\n  )\n\n\n\n\n\n\n\nThe purpose of a plot title is to summarize the main finding. Avoid titles that just describe what the plot is, e.g., â€œA scatterplot of engine displacement vs.Â fuel economyâ€.\nå›¾å½¢æ ‡é¢˜çš„ç›®çš„æ˜¯æ€»ç»“ä¸»è¦å‘ç°ã€‚åº”é¿å…ä½¿ç”¨ä»…ä»…æè¿°å›¾å½¢å†…å®¹çš„æ ‡é¢˜ï¼Œä¾‹å¦‚â€œå‘åŠ¨æœºæ’é‡ä¸ç‡ƒæ²¹ç»æµæ€§çš„æ•£ç‚¹å›¾â€ã€‚\nIf you need to add more text, there are two other useful labels: subtitle adds additional detail in a smaller font beneath the title and caption adds text at the bottom right of the plot, often used to describe the source of the data. You can also use labs() to replace the axis and legend titles. Itâ€™s usually a good idea to replace short variable names with more detailed descriptions, and to include the units.\nå¦‚æœä½ éœ€è¦æ·»åŠ æ›´å¤šæ–‡å­—ï¼Œè¿˜æœ‰ä¸¤ä¸ªæœ‰ç”¨çš„æ ‡ç­¾ï¼šsubtitle (å‰¯æ ‡é¢˜) ä¼šåœ¨ä¸»æ ‡é¢˜ä¸‹æ–¹ä»¥è¾ƒå°å­—ä½“æ·»åŠ é¢å¤–ç»†èŠ‚ï¼Œè€Œ caption (è¯´æ˜æ–‡å­—) ä¼šåœ¨å›¾å½¢å³ä¸‹è§’æ·»åŠ æ–‡å­—ï¼Œé€šå¸¸ç”¨æ¥æè¿°æ•°æ®æ¥æºã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ labs() æ¥æ›¿æ¢åæ ‡è½´å’Œå›¾ä¾‹çš„æ ‡é¢˜ã€‚é€šå¸¸ï¼Œç”¨æ›´è¯¦ç»†çš„æè¿°æ›¿æ¢ç®€çŸ­çš„å˜é‡åï¼Œå¹¶åŒ…å«å•ä½ï¼Œæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚\nItâ€™s possible to use mathematical equations instead of text strings. Just switch \"\" out for quote() and read about the available options in ?plotmath:\nä½ ä¹Ÿå¯ä»¥ä½¿ç”¨æ•°å­¦å…¬å¼ä»£æ›¿æ–‡æœ¬å­—ç¬¦ä¸²ã€‚åªéœ€å°† \"\" æ¢æˆ quote()ï¼Œå¹¶åœ¨ ?plotmath ä¸­é˜…è¯»æœ‰å…³å¯ç”¨é€‰é¡¹çš„ä¿¡æ¯ï¼š\n\ndf &lt;- tibble(\n  x = 1:10,\n  y = cumsum(x^2)\n)\n\nggplot(df, aes(x, y)) +\n  geom_point() +\n  labs(\n    x = quote(x[i]),\n    y = quote(sum(x[i] ^ 2, i == 1, n))\n  )\n\n\n\n\n\n\n\n\n11.2.1 Exercises\n\nCreate one plot on the fuel economy data with customized title, subtitle, caption, x, y, and color labels.\n\nRecreate the following plot using the fuel economy data. Note that both the colors and shapes of points vary by type of drive train.\n\n\n\n\n\n\n\n\n\nTake an exploratory graphic that youâ€™ve created in the last month, and add informative titles to make it easier for others to understand.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#annotations",
    "href": "communication.html#annotations",
    "title": "11Â  Communication",
    "section": "\n11.3 Annotations",
    "text": "11.3 Annotations\nIn addition to labelling major components of your plot, itâ€™s often useful to label individual observations or groups of observations. The first tool you have at your disposal is geom_text(). geom_text() is similar to geom_point(), but it has an additional aesthetic: label. This makes it possible to add textual labels to your plots.\né™¤äº†ä¸ºå›¾å½¢çš„ä¸»è¦ç»„ä»¶æ·»åŠ æ ‡ç­¾å¤–ï¼Œä¸ºå•ä¸ªè§‚æµ‹æˆ–è§‚æµ‹ç»„æ·»åŠ æ ‡ç­¾ä¹Ÿå¸¸å¸¸å¾ˆæœ‰ç”¨ã€‚ä½ å¯ä»¥ä½¿ç”¨çš„ç¬¬ä¸€ä¸ªå·¥å…·æ˜¯ geom_text()ã€‚geom_text() ç±»ä¼¼äº geom_point()ï¼Œä½†å®ƒæœ‰ä¸€ä¸ªé¢å¤–çš„ç¾å­¦å±æ€§ï¼šlabelã€‚è¿™ä½¿å¾—ä½ å¯ä»¥åœ¨å›¾å½¢ä¸­æ·»åŠ æ–‡æœ¬æ ‡ç­¾ã€‚\nThere are two possible sources of labels. First, you might have a tibble that provides labels. In the following plot we pull out the cars with the highest engine size in each drive type and save their information as a new data frame called label_info.\næ ‡ç­¾æœ‰ä¸¤ä¸ªå¯èƒ½çš„æ¥æºã€‚é¦–å…ˆï¼Œä½ å¯èƒ½æœ‰ä¸€ä¸ªæä¾›æ ‡ç­¾çš„ tibbleã€‚åœ¨ä¸‹é¢çš„å›¾å½¢ä¸­ï¼Œæˆ‘ä»¬æå–äº†æ¯ç§é©±åŠ¨ç±»å‹ä¸­å‘åŠ¨æœºå°ºå¯¸æœ€å¤§çš„æ±½è½¦ï¼Œå¹¶å°†å…¶ä¿¡æ¯ä¿å­˜ä¸ºä¸€ä¸ªåä¸º label_info çš„æ–°æ•°æ®æ¡†ã€‚\n\nlabel_info &lt;- mpg |&gt;\n  group_by(drv) |&gt;\n  arrange(desc(displ)) |&gt;\n  slice_head(n = 1) |&gt;\n  mutate(\n    drive_type = case_when(\n      drv == \"f\" ~ \"front-wheel drive\",\n      drv == \"r\" ~ \"rear-wheel drive\",\n      drv == \"4\" ~ \"4-wheel drive\"\n    )\n  ) |&gt;\n  select(displ, hwy, drv, drive_type)\n\nlabel_info\n#&gt; # A tibble: 3 Ã— 4\n#&gt; # Groups:   drv [3]\n#&gt;   displ   hwy drv   drive_type       \n#&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;            \n#&gt; 1   6.5    17 4     4-wheel drive    \n#&gt; 2   5.3    25 f     front-wheel drive\n#&gt; 3   7      24 r     rear-wheel drive\n\nThen, we use this new data frame to directly label the three groups to replace the legend with labels placed directly on the plot. Using the fontface and size arguments we can customize the look of the text labels. Theyâ€™re larger than the rest of the text on the plot and bolded. (theme(legend.position = \"none\") turns all the legends off â€” weâ€™ll talk about it more shortly.)\nç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ–°çš„æ•°æ®æ¡†æ¥ç›´æ¥æ ‡è®°è¿™ä¸‰ä¸ªç»„ï¼Œç”¨ç›´æ¥æ”¾ç½®åœ¨å›¾ä¸Šçš„æ ‡ç­¾å–ä»£å›¾ä¾‹ã€‚é€šè¿‡ä½¿ç”¨ fontface å’Œ size å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå®šä¹‰æ–‡æœ¬æ ‡ç­¾çš„å¤–è§‚ã€‚å®ƒä»¬æ¯”å›¾ä¸Šå…¶ä»–æ–‡æœ¬æ›´å¤§å¹¶ä¸”åŠ ç²—äº†ã€‚(theme(legend.position = \"none\") ä¼šå…³é—­æ‰€æœ‰å›¾ä¾‹â€”â€”æˆ‘ä»¬ç¨åä¼šæ›´è¯¦ç»†åœ°è®¨è®ºå®ƒã€‚)\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_text(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, hjust = \"right\", vjust = \"bottom\"\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nNote the use of hjust (horizontal justification) and vjust (vertical justification) to control the alignment of the label.\næ³¨æ„ä½¿ç”¨ hjust (æ°´å¹³å¯¹é½) å’Œ vjust (å‚ç›´å¯¹é½) æ¥æ§åˆ¶æ ‡ç­¾çš„å¯¹é½æ–¹å¼ã€‚\nHowever the annotated plot we made above is hard to read because the labels overlap with each other, and with the points. We can use the geom_label_repel() function from the ggrepel package to address both of these issues. This useful package will automatically adjust labels so that they donâ€™t overlap:\nç„¶è€Œï¼Œæˆ‘ä»¬ä¸Šé¢åˆ¶ä½œçš„å¸¦æ³¨é‡Šçš„å›¾å¾ˆéš¾é˜…è¯»ï¼Œå› ä¸ºæ ‡ç­¾ä¹‹é—´ä»¥åŠæ ‡ç­¾ä¸æ•°æ®ç‚¹ä¹‹é—´å­˜åœ¨é‡å ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ ggrepel åŒ…ä¸­çš„ geom_label_repel() å‡½æ•°æ¥è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚è¿™ä¸ªæœ‰ç”¨çš„åŒ…ä¼šè‡ªåŠ¨è°ƒæ•´æ ‡ç­¾ï¼Œä½¿å…¶ä¸é‡å ï¼š\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_label_repel(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, nudge_y = 2\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nYou can also use the same idea to highlight certain points on a plot with geom_text_repel() from the ggrepel package. Note another handy technique used here: we added a second layer of large, hollow points to further highlight the labelled points.\nä½ ä¹Ÿå¯ä»¥ç”¨åŒæ ·çš„æ–¹æ³•ï¼Œä½¿ç”¨ ggrepel åŒ…ä¸­çš„ geom_text_repel() æ¥é«˜äº®å›¾ä¸Šçš„æŸäº›ç‚¹ã€‚æ³¨æ„è¿™é‡Œä½¿ç”¨çš„å¦ä¸€ä¸ªä¾¿æ·æŠ€å·§ï¼šæˆ‘ä»¬æ·»åŠ äº†ç¬¬äºŒå±‚å¤§çš„ç©ºå¿ƒç‚¹ï¼Œä»¥è¿›ä¸€æ­¥çªå‡ºæ˜¾ç¤ºè¢«æ ‡è®°çš„ç‚¹ã€‚\n\npotential_outliers &lt;- mpg |&gt;\n  filter(hwy &gt; 40 | (hwy &gt; 20 & displ &gt; 5))\n  \nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_text_repel(data = potential_outliers, aes(label = model)) +\n  geom_point(data = potential_outliers, color = \"red\") +\n  geom_point(\n    data = potential_outliers,\n    color = \"red\", size = 3, shape = \"circle open\"\n  )\n\n\n\n\n\n\n\nRemember, in addition to geom_text() and geom_label(), you have many other geoms in ggplot2 available to help annotate your plot. A couple ideas:\nè¯·è®°ä½ï¼Œé™¤äº† geom_text() å’Œ geom_label() ä¹‹å¤–ï¼Œggplot2 ä¸­è¿˜æœ‰è®¸å¤šå…¶ä»–å‡ ä½•å¯¹è±¡ (geom) å¯ä»¥å¸®åŠ©ä½ æ³¨é‡Šå›¾å½¢ã€‚æœ‰å‡ ä¸ªæƒ³æ³•ï¼š\n\nUse geom_hline() and geom_vline() to add reference lines. We often make them thick (linewidth = 2) and white (color = white), and draw them underneath the primary data layer. That makes them easy to see, without drawing attention away from the data.\næˆ‘ä»¬é€šå¸¸å°†å®ƒä»¬è®¾ç½®å¾—è¾ƒç²— (linewidth = 2) ä¸”ä¸ºç™½è‰² (color = white)ï¼Œå¹¶å°†å…¶ç»˜åˆ¶åœ¨ä¸»æ•°æ®å±‚çš„ä¸‹æ–¹ã€‚&lt;br&gt;è¿™æ ·æ—¢å®¹æ˜“çœ‹åˆ°ï¼Œåˆä¸ä¼šåˆ†æ•£å¯¹æ•°æ®çš„æ³¨æ„åŠ›ã€‚\nUse geom_rect() to draw a rectangle around points of interest. The boundaries of the rectangle are defined by aesthetics xmin, xmax, ymin, ymax. Alternatively, look into the ggforce package, specifically geom_mark_hull(), which allows you to annotate subsets of points with hulls.\nçŸ©å½¢çš„è¾¹ç•Œç”±ç¾å­¦å±æ€§ xminã€xmaxã€yminã€ymax å®šä¹‰ã€‚&lt;br&gt;æˆ–è€…ï¼Œå¯ä»¥ç ”ç©¶ä¸€ä¸‹ ggforce åŒ…ï¼Œç‰¹åˆ«æ˜¯ geom_mark_hull()ï¼Œå®ƒå…è®¸ä½ ç”¨å‡¸åŒ…æ¥æ³¨é‡Šç‚¹çš„å­é›†ã€‚\nUse geom_segment() with the arrow argument to draw attention to a point with an arrow. Use aesthetics x and y to define the starting location, and xend and yend to define the end location.\nä½¿ç”¨ç¾å­¦å±æ€§ x å’Œ y å®šä¹‰èµ·å§‹ä½ç½®ï¼Œxend å’Œ yend å®šä¹‰ç»“æŸä½ç½®ã€‚\n\nAnother handy function for adding annotations to plots is annotate(). As a rule of thumb, geoms are generally useful for highlighting a subset of the data while annotate() is useful for adding one or few annotation elements to a plot.\nå¦ä¸€ä¸ªä¸ºå›¾å½¢æ·»åŠ æ³¨é‡Šçš„ä¾¿æ·å‡½æ•°æ˜¯ annotate()ã€‚æ ¹æ®ç»éªŒï¼Œå‡ ä½•å¯¹è±¡ (geom) é€šå¸¸ç”¨äºé«˜äº®æ˜¾ç¤ºæ•°æ®çš„å­é›†ï¼Œè€Œ annotate() åˆ™é€‚ç”¨äºå‘å›¾å½¢ä¸­æ·»åŠ ä¸€ä¸ªæˆ–å‡ ä¸ªæ³¨é‡Šå…ƒç´ ã€‚\nTo demonstrate using annotate(), letâ€™s create some text to add to our plot. The text is a bit long, so weâ€™ll use stringr::str_wrap() to automatically add line breaks to it given the number of characters you want per line:\nä¸ºäº†æ¼”ç¤º annotate() çš„ç”¨æ³•ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€äº›æ–‡æœ¬æ·»åŠ åˆ°å›¾ä¸­ã€‚è¿™æ®µæ–‡æœ¬æœ‰ç‚¹é•¿ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨ stringr::str_wrap()ï¼Œæ ¹æ®ä½ å¸Œæœ›æ¯è¡Œæ˜¾ç¤ºçš„å­—ç¬¦æ•°æ¥è‡ªåŠ¨ä¸ºå…¶æ·»åŠ æ¢è¡Œç¬¦ï¼š\n\ntrend_text &lt;- \"Larger engine sizes tend to have lower fuel economy.\" |&gt;\n  str_wrap(width = 30)\ntrend_text\n#&gt; [1] \"Larger engine sizes tend to\\nhave lower fuel economy.\"\n\nThen, we add two layers of annotation: one with a label geom and the other with a segment geom. The x and y aesthetics in both define where the annotation should start, and the xend and yend aesthetics in the segment annotation define the end location of the segment. Note also that the segment is styled as an arrow.\nç„¶åï¼Œæˆ‘ä»¬æ·»åŠ ä¸¤å±‚æ³¨é‡Šï¼šä¸€å±‚æ˜¯æ ‡ç­¾å‡ ä½•å¯¹è±¡ï¼Œå¦ä¸€å±‚æ˜¯çº¿æ®µå‡ ä½•å¯¹è±¡ã€‚ä¸¤è€…ä¸­çš„ x å’Œ y ç¾å­¦å±æ€§å®šä¹‰äº†æ³¨é‡Šçš„èµ·å§‹ä½ç½®ï¼Œè€Œçº¿æ®µæ³¨é‡Šä¸­çš„ xend å’Œ yend ç¾å­¦å±æ€§å®šä¹‰äº†çº¿æ®µçš„ç»“æŸä½ç½®ã€‚è¿˜è¦æ³¨æ„ï¼Œè¯¥çº¿æ®µè¢«æ ·å¼åŒ–ä¸ºç®­å¤´ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  annotate(\n    geom = \"label\", x = 3.5, y = 38,\n    label = trend_text,\n    hjust = \"left\", color = \"red\"\n  ) +\n  annotate(\n    geom = \"segment\",\n    x = 3, y = 35, xend = 5, yend = 25, color = \"red\",\n    arrow = arrow(type = \"closed\")\n  )\n\n\n\n\n\n\n\nAnnotation is a powerful tool for communicating main takeaways and interesting features of your visualizations. The only limit is your imagination (and your patience with positioning annotations to be aesthetically pleasing)!\næ³¨é‡Šæ˜¯ä¼ è¾¾å¯è§†åŒ–ä¸»è¦ç»“è®ºå’Œæœ‰è¶£ç‰¹å¾çš„å¼ºå¤§å·¥å…·ã€‚å”¯ä¸€çš„é™åˆ¶æ˜¯ä½ çš„æƒ³è±¡åŠ›ï¼ˆä»¥åŠä½ ä¸ºç¾è§‚åœ°å®šä½æ³¨é‡Šè€Œä»˜å‡ºçš„è€å¿ƒï¼‰ï¼\n\n11.3.1 Exercises\n\nUse geom_text() with infinite positions to place text at the four corners of the plot.\nUse annotate() to add a point geom in the middle of your last plot without having to create a tibble. Customize the shape, size, or color of the point.\nHow do labels with geom_text() interact with faceting? How can you add a label to a single facet? How can you put a different label in each facet? (Hint: Think about the dataset that is being passed to geom_text().)\nWhat arguments to geom_label() control the appearance of the background box?\nWhat are the four arguments to arrow()? How do they work? Create a series of plots that demonstrate the most important options.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#scales",
    "href": "communication.html#scales",
    "title": "11Â  Communication",
    "section": "\n11.4 Scales",
    "text": "11.4 Scales\nThe third way you can make your plot better for communication is to adjust the scales. Scales control how the aesthetic mappings manifest visually.\nè®©ä½ çš„å›¾è¡¨æ›´æ˜“äºäº¤æµçš„ç¬¬ä¸‰ç§æ–¹æ³•æ˜¯è°ƒæ•´æ ‡åº¦ï¼ˆscalesï¼‰ã€‚æ ‡åº¦æ§åˆ¶ç€ç¾å­¦æ˜ å°„ï¼ˆaesthetic mappingsï¼‰åœ¨è§†è§‰ä¸Šçš„è¡¨ç°æ–¹å¼ã€‚\n\n11.4.1 Default scales\nNormally, ggplot2 automatically adds scales for you. For example, when you type:\né€šå¸¸æƒ…å†µä¸‹ï¼Œggplot2 ä¼šè‡ªåŠ¨ä¸ºä½ æ·»åŠ æ ‡åº¦ã€‚ä¾‹å¦‚ï¼Œå½“ä½ è¾“å…¥ï¼š\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nggplot2 automatically adds default scales behind the scenes:\nggplot2 ä¼šåœ¨åå°è‡ªåŠ¨æ·»åŠ é»˜è®¤çš„æ ‡åº¦ï¼š\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  scale_color_discrete()\n\nNote the naming scheme for scales: scale_ followed by the name of the aesthetic, then _, then the name of the scale. The default scales are named according to the type of variable they align with: continuous, discrete, datetime, or date. scale_x_continuous() puts the numeric values from displ on a continuous number line on the x-axis, scale_color_discrete() chooses colors for each of the class of car, etc. There are lots of non-default scales which youâ€™ll learn about below.\næ³¨æ„æ ‡åº¦çš„å‘½åæ–¹æ¡ˆï¼šscale_ åè·Ÿç¾å­¦å±æ€§çš„åç§°ï¼Œç„¶åæ˜¯ _ï¼Œå†åè·Ÿæ ‡åº¦çš„åç§°ã€‚é»˜è®¤æ ‡åº¦æ˜¯æ ¹æ®å®ƒä»¬æ‰€å¯¹åº”çš„å˜é‡ç±»å‹æ¥å‘½åçš„ï¼šè¿ç»­å‹ (continuous)ã€ç¦»æ•£å‹ (discrete)ã€æ—¥æœŸæ—¶é—´å‹ (datetime) æˆ–æ—¥æœŸå‹ (date)ã€‚scale_x_continuous() å°† displ çš„æ•°å€¼æ”¾åœ¨ x è½´çš„è¿ç»­æ•°è½´ä¸Šï¼Œscale_color_discrete() ä¸ºæ¯ç§æ±½è½¦ class é€‰æ‹©é¢œè‰²ï¼Œç­‰ç­‰ã€‚ä¸‹é¢ä½ å°†å­¦ä¹ åˆ°è®¸å¤šéé»˜è®¤çš„æ ‡åº¦ã€‚\nThe default scales have been carefully chosen to do a good job for a wide range of inputs. Nevertheless, you might want to override the defaults for two reasons:\né»˜è®¤æ ‡åº¦ç»è¿‡ç²¾å¿ƒæŒ‘é€‰ï¼Œèƒ½åœ¨å„ç§è¾“å…¥ä¸‹éƒ½è¡¨ç°è‰¯å¥½ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä½ å¯èƒ½å‡ºäºä¸¤ä¸ªåŸå› æƒ³è¦è¦†ç›–é»˜è®¤è®¾ç½®ï¼š\n\nYou might want to tweak some of the parameters of the default scale. This allows you to do things like change the breaks on the axes, or the key labels on the legend.\nè¿™å…è®¸ä½ åšä¸€äº›äº‹æƒ…ï¼Œæ¯”å¦‚æ›´æ”¹åæ ‡è½´ä¸Šçš„åˆ»åº¦ï¼Œæˆ–å›¾ä¾‹ä¸Šçš„é”®æ ‡ç­¾ã€‚\nYou might want to replace the scale altogether, and use a completely different algorithm. Often you can do better than the default because you know more about the data.\né€šå¸¸ä½ å¯ä»¥åšå¾—æ¯”é»˜è®¤æ›´å¥½ï¼Œå› ä¸ºä½ å¯¹æ•°æ®æœ‰æ›´å¤šçš„äº†è§£ã€‚\n\n11.4.2 Axis ticks and legend keys\nCollectively axes and legends are called guides. Axes are used for x and y aesthetics; legends are used for everything else.\nåæ ‡è½´å’Œå›¾ä¾‹ç»Ÿç§°ä¸ºå¼•å¯¼å…ƒç´  (guides)ã€‚åæ ‡è½´ç”¨äº x å’Œ y ç¾å­¦å±æ€§ï¼›å›¾ä¾‹ç”¨äºæ‰€æœ‰å…¶ä»–ç¾å­¦å±æ€§ã€‚\nThere are two primary arguments that affect the appearance of the ticks on the axes and the keys on the legend: breaks and labels. Breaks controls the position of the ticks, or the values associated with the keys. Labels controls the text label associated with each tick/key. The most common use of breaks is to override the default choice:\næœ‰ä¸¤ä¸ªä¸»è¦å‚æ•°ä¼šå½±å“åæ ‡è½´ä¸Šçš„åˆ»åº¦çº¿å’Œå›¾ä¾‹ä¸Šçš„é”®çš„å¤–è§‚ï¼šbreaks å’Œ labelsã€‚Breaks æ§åˆ¶åˆ»åº¦çº¿çš„ä½ç½®ï¼Œæˆ–ä¸é”®ç›¸å…³è”çš„å€¼ã€‚Labels æ§åˆ¶ä¸æ¯ä¸ªåˆ»åº¦çº¿/é”®ç›¸å…³è”çš„æ–‡æœ¬æ ‡ç­¾ã€‚breaks æœ€å¸¸è§çš„ç”¨é€”æ˜¯è¦†ç›–é»˜è®¤é€‰é¡¹ï¼š\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(15, 40, by = 5)) \n\n\n\n\n\n\n\nYou can use labels in the same way (a character vector the same length as breaks), but you can also set it to NULL to suppress the labels altogether. This can be useful for maps, or for publishing plots where you canâ€™t share the absolute numbers. You can also use breaks and labels to control the appearance of legends. For discrete scales for categorical variables, labels can be a named list of the existing level names and the desired labels for them.\nä½ å¯ä»¥ç”¨åŒæ ·çš„æ–¹å¼ä½¿ç”¨ labels (ä¸€ä¸ªä¸ breaks é•¿åº¦ç›¸åŒçš„å­—ç¬¦å‘é‡)ï¼Œä½†ä½ ä¹Ÿå¯ä»¥å°†å…¶è®¾ç½®ä¸º NULL æ¥å®Œå…¨æŠ‘åˆ¶æ ‡ç­¾ã€‚è¿™å¯¹äºåœ°å›¾æˆ–å‘å¸ƒé‚£äº›ä¸èƒ½åˆ†äº«ç»å¯¹æ•°å­—çš„å›¾è¡¨å¯èƒ½å¾ˆæœ‰ç”¨ã€‚ä½ è¿˜å¯ä»¥ä½¿ç”¨ breaks å’Œ labels æ¥æ§åˆ¶å›¾ä¾‹çš„å¤–è§‚ã€‚å¯¹äºåˆ†ç±»å˜é‡çš„ç¦»æ•£æ ‡åº¦ï¼Œlabels å¯ä»¥æ˜¯ä¸€ä¸ªå‘½ååˆ—è¡¨ï¼ŒåŒ…å«ç°æœ‰çš„æ°´å¹³åç§°å’Œå®ƒä»¬æœŸæœ›çš„æ ‡ç­¾ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_x_continuous(labels = NULL) +\n  scale_y_continuous(labels = NULL) +\n  scale_color_discrete(labels = c(\"4\" = \"4-wheel\", \"f\" = \"front\", \"r\" = \"rear\"))\n\n\n\n\n\n\n\nThe labels argument coupled with labelling functions from the scales package is also useful for formatting numbers as currency, percent, etc. The plot on the left shows default labelling with label_dollar(), which adds a dollar sign as well as a thousand separator comma. The plot on the right adds further customization by dividing dollar values by 1,000 and adding a suffix â€œKâ€ (for â€œthousandsâ€) as well as adding custom breaks. Note that breaks is in the original scale of the data.labels å‚æ•°ä¸ scales åŒ…ä¸­çš„æ ‡ç­¾å‡½æ•°ç›¸ç»“åˆï¼Œå¯¹äºæ ¼å¼åŒ–æ•°å­—ï¼ˆå¦‚è´§å¸ã€ç™¾åˆ†æ¯”ç­‰ï¼‰ä¹Ÿå¾ˆæœ‰ç”¨ã€‚å·¦å›¾å±•ç¤ºäº†ä½¿ç”¨ label_dollar() çš„é»˜è®¤æ ‡ç­¾ï¼Œå®ƒä¼šæ·»åŠ ç¾å…ƒç¬¦å·å’Œåƒä½åˆ†éš”é€—å·ã€‚å³å›¾é€šè¿‡å°†ç¾å…ƒå€¼é™¤ä»¥ 1000 å¹¶æ·»åŠ åç¼€â€œKâ€ï¼ˆä»£è¡¨â€œåƒâ€ï¼‰ï¼Œä»¥åŠæ·»åŠ è‡ªå®šä¹‰æ–­ç‚¹ï¼Œè¿›è¡Œäº†è¿›ä¸€æ­¥çš„å®šåˆ¶ã€‚æ³¨æ„ï¼Œbreaks æ˜¯åŸºäºåŸå§‹æ•°æ®çš„æ ‡åº¦ã€‚\n# Left\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(labels = label_dollar())\n\n# Right\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(\n    labels = label_dollar(scale = 1/1000, suffix = \"K\"), \n    breaks = seq(1000, 19000, by = 6000)\n  )\n\n\n\n\n\n\n\n\n\n\nAnother handy label function is label_percent():\nå¦ä¸€ä¸ªæ–¹ä¾¿çš„æ ‡ç­¾å‡½æ•°æ˜¯ label_percent()ï¼š\n\nggplot(diamonds, aes(x = cut, fill = clarity)) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(name = \"Percentage\", labels = label_percent())\n\n\n\n\n\n\n\nAnother use of breaks is when you have relatively few data points and want to highlight exactly where the observations occur. For example, take this plot that shows when each US president started and ended their term.breaks çš„å¦ä¸€ä¸ªç”¨é€”æ˜¯å½“ä½ æ•°æ®ç‚¹ç›¸å¯¹è¾ƒå°‘ï¼Œå¹¶å¸Œæœ›ç²¾ç¡®åœ°çªå‡ºæ˜¾ç¤ºè§‚æµ‹å€¼å‡ºç°çš„ä½ç½®æ—¶ã€‚ä¾‹å¦‚ï¼Œçœ‹ä¸‹é¢è¿™å¼ å›¾ï¼Œå®ƒæ˜¾ç¤ºäº†æ¯ä½ç¾å›½æ€»ç»Ÿä»»æœŸçš„èµ·æ­¢æ—¶é—´ã€‚\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_x_date(name = NULL, breaks = presidential$start, date_labels = \"'%y\")\n\n\n\n\n\n\n\nNote that for the breaks argument we pulled out the start variable as a vector with presidential$start because we canâ€™t do an aesthetic mapping for this argument. Also note that the specification of breaks and labels for date and datetime scales is a little different:\nè¯·æ³¨æ„ï¼Œå¯¹äº breaks å‚æ•°ï¼Œæˆ‘ä»¬ä½¿ç”¨ presidential$start å°† start å˜é‡æå–ä¸ºä¸€ä¸ªå‘é‡ï¼Œå› ä¸ºæˆ‘ä»¬ä¸èƒ½å¯¹è¿™ä¸ªå‚æ•°è¿›è¡Œç¾å­¦æ˜ å°„ã€‚å¦è¯·æ³¨æ„ï¼Œæ—¥æœŸå’Œæ—¥æœŸæ—¶é—´æ ‡åº¦çš„æ–­ç‚¹å’Œæ ‡ç­¾çš„è§„èŒƒç•¥æœ‰ä¸åŒï¼š\n\ndate_labels takes a format specification, in the same form as parse_datetime().date_labels æ¥å—ä¸€ä¸ªæ ¼å¼è§„èŒƒï¼Œå…¶å½¢å¼ä¸ parse_datetime() ç›¸åŒã€‚\ndate_breaks (not shown here), takes a string like â€œ2 daysâ€ or â€œ1 monthâ€.date_breaksï¼ˆæ­¤å¤„æœªæ˜¾ç¤ºï¼‰æ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå¦‚ â€œ2 daysâ€ æˆ– â€œ1 monthâ€ã€‚\n\n11.4.3 Legend layout\nYou will most often use breaks and labels to tweak the axes. While they both also work for legends, there are a few other techniques you are more likely to use.\nä½ æœ€å¸¸ä½¿ç”¨ breaks å’Œ labels æ¥è°ƒæ•´åæ ‡è½´ã€‚è™½ç„¶å®ƒä»¬ä¹Ÿé€‚ç”¨äºå›¾ä¾‹ï¼Œä½†ä½ æ›´å¯èƒ½ä½¿ç”¨ä¸€äº›å…¶ä»–çš„æŠ€å·§ã€‚\nTo control the overall position of the legend, you need to use a theme() setting. Weâ€™ll come back to themes at the end of the chapter, but in brief, they control the non-data parts of the plot. The theme setting legend.position controls where the legend is drawn:\nè¦æ§åˆ¶å›¾ä¾‹çš„æ•´ä½“ä½ç½®ï¼Œä½ éœ€è¦ä½¿ç”¨ theme() è®¾ç½®ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« æœ«å°¾å†è®¨è®ºä¸»é¢˜ (themes)ï¼Œä½†ç®€è€Œè¨€ä¹‹ï¼Œå®ƒä»¬æ§åˆ¶ç€å›¾è¡¨çš„éæ•°æ®éƒ¨åˆ†ã€‚ä¸»é¢˜è®¾ç½® legend.position æ§åˆ¶å›¾ä¾‹çš„ç»˜åˆ¶ä½ç½®ï¼š\nbase &lt;- ggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nbase + theme(legend.position = \"right\") # the default\nbase + theme(legend.position = \"left\")\nbase + \n  theme(legend.position = \"top\") +\n  guides(color = guide_legend(nrow = 3))\nbase + \n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf your plot is short and wide, place the legend at the top or bottom, and if itâ€™s tall and narrow, place the legend at the left or right. You can also use legend.position = \"none\" to suppress the display of the legend altogether.\nå¦‚æœä½ çš„å›¾å½¢åˆçŸ­åˆå®½ï¼Œå°±æŠŠå›¾ä¾‹æ”¾åœ¨é¡¶éƒ¨æˆ–åº•éƒ¨ï¼›å¦‚æœå®ƒåˆé«˜åˆçª„ï¼Œå°±æŠŠå›¾ä¾‹æ”¾åœ¨å·¦ä¾§æˆ–å³ä¾§ã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ legend.position = \"none\" æ¥å®Œå…¨æŠ‘åˆ¶å›¾ä¾‹çš„æ˜¾ç¤ºã€‚\nTo control the display of individual legends, use guides() along with guide_legend() or guide_colorbar(). The following example shows two important settings: controlling the number of rows the legend uses with nrow, and overriding one of the aesthetics to make the points bigger. This is particularly useful if you have used a low alpha to display many points on a plot.\nè¦æ§åˆ¶å•ä¸ªå›¾ä¾‹çš„æ˜¾ç¤ºï¼Œè¯·ä½¿ç”¨ guides() å‡½æ•°ï¼Œå¹¶é…åˆ guide_legend() æˆ– guide_colorbar()ã€‚ä¸‹é¢çš„ä¾‹å­å±•ç¤ºäº†ä¸¤ä¸ªé‡è¦çš„è®¾ç½®ï¼šä½¿ç”¨ nrow æ§åˆ¶å›¾ä¾‹ä½¿ç”¨çš„è¡Œæ•°ï¼Œä»¥åŠè¦†ç›–å…¶ä¸­ä¸€ä¸ªç¾å­¦å±æ€§ä»¥ä½¿ç‚¹å˜å¤§ã€‚å¦‚æœä½ åœ¨å›¾ä¸Šä½¿ç”¨äº†è¾ƒä½çš„ alpha å€¼æ¥æ˜¾ç¤ºè®¸å¤šç‚¹ï¼Œè¿™å°¤å…¶æœ‰ç”¨ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2, override.aes = list(size = 4)))\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nNote that the name of the argument in guides() matches the name of the aesthetic, just like in labs().\næ³¨æ„ï¼Œguides() ä¸­çš„å‚æ•°åç§°ä¸ç¾å­¦å±æ€§çš„åç§°ç›¸åŒ¹é…ï¼Œå°±åƒåœ¨ labs() ä¸­ä¸€æ ·ã€‚\n\n11.4.4 Replacing a scale\nInstead of just tweaking the details a little, you can instead replace the scale altogether. There are two types of scales youâ€™re mostly likely to want to switch out: continuous position scales and color scales. Fortunately, the same principles apply to all the other aesthetics, so once youâ€™ve mastered position and color, youâ€™ll be able to quickly pick up other scale replacements.\nä½ ä¸ä»…å¯ä»¥å¾®è°ƒç»†èŠ‚ï¼Œè¿˜å¯ä»¥å®Œå…¨æ›¿æ¢æ•´ä¸ªæ ‡åº¦ã€‚ä½ æœ€å¯èƒ½æƒ³è¦æ›´æ¢çš„ä¸¤ç§æ ‡åº¦æ˜¯ï¼šè¿ç»­ä½ç½®æ ‡åº¦å’Œé¢œè‰²æ ‡åº¦ã€‚å¹¸è¿çš„æ˜¯ï¼ŒåŒæ ·çš„åŸåˆ™ä¹Ÿé€‚ç”¨äºæ‰€æœ‰å…¶ä»–ç¾å­¦å±æ€§ï¼Œæ‰€ä»¥ä¸€æ—¦ä½ æŒæ¡äº†ä½ç½®å’Œé¢œè‰²ï¼Œä½ å°±èƒ½å¾ˆå¿«å­¦ä¼šå…¶ä»–æ ‡åº¦çš„æ›¿æ¢ã€‚\nItâ€™s very useful to plot transformations of your variable. For example, itâ€™s easier to see the precise relationship between carat and price if we log transform them:\nå¯¹ä½ çš„å˜é‡è¿›è¡Œå˜æ¢åç»˜å›¾éå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å¯¹ carat å’Œ price è¿›è¡Œå¯¹æ•°å˜æ¢ï¼Œå°±æ›´å®¹æ˜“çœ‹æ¸…å®ƒä»¬ä¹‹é—´çš„ç²¾ç¡®å…³ç³»ï¼š\n# Left\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d()\n\n# Right\nggplot(diamonds, aes(x = log10(carat), y = log10(price))) +\n  geom_bin2d()\n\n\n\n\n\n\n\n\n\n\nHowever, the disadvantage of this transformation is that the axes are now labelled with the transformed values, making it hard to interpret the plot. Instead of doing the transformation in the aesthetic mapping, we can instead do it with the scale. This is visually identical, except the axes are labelled on the original data scale.\nç„¶è€Œï¼Œè¿™ç§å˜æ¢çš„ç¼ºç‚¹æ˜¯åæ ‡è½´ç°åœ¨ç”¨å˜æ¢åçš„å€¼æ¥æ ‡è®°ï¼Œè¿™ä½¿å¾—å›¾è¡¨éš¾ä»¥è§£è¯»ã€‚æˆ‘ä»¬å¯ä»¥åœ¨æ ‡åº¦ä¸­è¿›è¡Œå˜æ¢ï¼Œè€Œä¸æ˜¯åœ¨ç¾å­¦æ˜ å°„ä¸­è¿›è¡Œã€‚è¿™æ ·åœ¨è§†è§‰ä¸Šæ˜¯ç›¸åŒçš„ï¼Œä½†åæ ‡è½´ä¼šä»¥åŸå§‹æ•°æ®æ ‡åº¦è¿›è¡Œæ ‡è®°ã€‚\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d() + \n  scale_x_log10() + \n  scale_y_log10()\n\n\n\n\n\n\n\nAnother scale that is frequently customized is color. The default categorical scale picks colors that are evenly spaced around the color wheel. Useful alternatives are the ColorBrewer scales which have been hand tuned to work better for people with common types of color blindness. The two plots below look similar, but there is enough difference in the shades of red and green that the dots on the right can be distinguished even by people with red-green color blindness.1\nå¦ä¸€ä¸ªç»å¸¸è¢«å®šåˆ¶çš„æ ‡åº¦æ˜¯é¢œè‰²ã€‚é»˜è®¤çš„åˆ†ç±»æ ‡åº¦ä¼šé€‰æ‹©åœ¨è‰²è½®ä¸Šå‡åŒ€åˆ†å¸ƒçš„é¢œè‰²ã€‚ä¸€äº›æœ‰ç”¨çš„æ›¿ä»£æ–¹æ¡ˆæ˜¯ ColorBrewer æ ‡åº¦ï¼Œè¿™äº›æ ‡åº¦ç»è¿‡æ‰‹å·¥è°ƒæ•´ï¼Œå¯¹æ‚£æœ‰å¸¸è§è‰²ç›²ç±»å‹çš„äººæ›´åŠ å‹å¥½ã€‚ä¸‹é¢çš„ä¸¤å¹…å›¾çœ‹èµ·æ¥ç›¸ä¼¼ï¼Œä½†çº¢è‰²å’Œç»¿è‰²çš„è‰²åº¦æœ‰è¶³å¤Ÿçš„å·®å¼‚ï¼Œå³ä½¿æ˜¯çº¢ç»¿è‰²ç›²çš„äººä¹Ÿèƒ½åŒºåˆ†å³å›¾ä¸­çš„ç‚¹ã€‚1\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv))\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\nDonâ€™t forget simpler techniques for improving accessibility. If there are just a few colors, you can add a redundant shape mapping. This will also help ensure your plot is interpretable in black and white.\nä¸è¦å¿˜è®°ä½¿ç”¨æ›´ç®€å•çš„æŠ€æœ¯æ¥æé«˜å¯è®¿é—®æ€§ã€‚å¦‚æœåªæœ‰å‡ ç§é¢œè‰²ï¼Œä½ å¯ä»¥æ·»åŠ ä¸€ä¸ªå†—ä½™çš„å½¢çŠ¶æ˜ å°„ã€‚è¿™ä¹Ÿæœ‰åŠ©äºç¡®ä¿ä½ çš„å›¾åœ¨é»‘ç™½æ¨¡å¼ä¸‹ä¹Ÿæ˜¯å¯ä»¥ç†è§£çš„ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv, shape = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\nThe ColorBrewer scales are documented online at https://colorbrewer2.org/ and made available in R via the RColorBrewer package, by Erich Neuwirth. FigureÂ 11.1 shows the complete list of all palettes. The sequential (top) and diverging (bottom) palettes are particularly useful if your categorical values are ordered, or have a â€œmiddleâ€. This often arises if youâ€™ve used cut() to make a continuous variable into a categorical variable.\nColorBrewer è‰²é˜¶çš„æ–‡æ¡£å¯ä»¥åœ¨çº¿æŸ¥çœ‹ï¼šhttps://colorbrewer2.org/ï¼Œå¹¶é€šè¿‡ Erich Neuwirth å¼€å‘çš„ RColorBrewer åŒ…åœ¨ R ä¸­ä½¿ç”¨ã€‚FigureÂ 11.1 å±•ç¤ºäº†æ‰€æœ‰è°ƒè‰²æ¿çš„å®Œæ•´åˆ—è¡¨ã€‚å¦‚æœä½ çš„åˆ†ç±»å€¼æ˜¯æœ‰åºçš„ï¼Œæˆ–è€…æœ‰ä¸€ä¸ªâ€œä¸­é—´å€¼â€ï¼Œé‚£ä¹ˆé¡ºåºï¼ˆé¡¶éƒ¨ï¼‰å’Œå‘æ•£ï¼ˆåº•éƒ¨ï¼‰è°ƒè‰²æ¿å°±ç‰¹åˆ«æœ‰ç”¨ã€‚è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿåœ¨ä½ ä½¿ç”¨ cut() å‡½æ•°å°†è¿ç»­å˜é‡è½¬æ¢ä¸ºåˆ†ç±»å˜é‡æ—¶ã€‚\n\n\n\n\n\n\n\nFigureÂ 11.1: All colorBrewer scales.\n\n\n\n\nWhen you have a predefined mapping between values and colors, use scale_color_manual(). For example, if we map presidential party to color, we want to use the standard mapping of red for Republicans and blue for Democrats. One approach for assigning these colors is using hex color codes:\nå½“ä½ æœ‰ä¸€ä¸ªé¢„å®šä¹‰çš„å€¼ä¸é¢œè‰²ä¹‹é—´çš„æ˜ å°„æ—¶ï¼Œè¯·ä½¿ç”¨ scale_color_manual()ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°†æ€»ç»Ÿçš„å…šæ´¾æ˜ å°„åˆ°é¢œè‰²ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨æ ‡å‡†çš„æ˜ å°„ï¼šå…±å’Œå…šä¸ºçº¢è‰²ï¼Œæ°‘ä¸»å…šä¸ºè“è‰²ã€‚åˆ†é…è¿™äº›é¢œè‰²çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨åå…­è¿›åˆ¶é¢œè‰²ä»£ç ï¼š\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id, color = party)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_color_manual(values = c(Republican = \"#E81B23\", Democratic = \"#00AEF3\"))\n\n\n\n\n\n\n\nFor continuous color, you can use the built-in scale_color_gradient() or scale_fill_gradient(). If you have a diverging scale, you can use scale_color_gradient2(). That allows you to give, for example, positive and negative values different colors. Thatâ€™s sometimes also useful if you want to distinguish points above or below the mean.\nå¯¹äºè¿ç»­é¢œè‰²ï¼Œä½ å¯ä»¥ä½¿ç”¨å†…ç½®çš„ scale_color_gradient() æˆ– scale_fill_gradient()ã€‚å¦‚æœä½ æœ‰ä¸€ä¸ªå‘æ•£å‹æ ‡åº¦ï¼Œä½ å¯ä»¥ä½¿ç”¨ scale_color_gradient2()ã€‚è¿™å…è®¸ä½ ï¼Œä¾‹å¦‚ï¼Œç»™æ­£å€¼å’Œè´Ÿå€¼èµ‹äºˆä¸åŒçš„é¢œè‰²ã€‚å¦‚æœä½ æƒ³åŒºåˆ†å¹³å‡å€¼ä»¥ä¸Šæˆ–ä»¥ä¸‹çš„ç‚¹ï¼Œè¿™æœ‰æ—¶ä¹Ÿå¾ˆæœ‰ç”¨ã€‚\nAnother option is to use the viridis color scales. The designers, Nathaniel Smith and StÃ©fan van der Walt, carefully tailored continuous color schemes that are perceptible to people with various forms of color blindness as well as perceptually uniform in both color and black and white. These scales are available as continuous (c), discrete (d), and binned (b) palettes in ggplot2.\nå¦ä¸€ä¸ªé€‰æ‹©æ˜¯ä½¿ç”¨ viridis é¢œè‰²æ ‡åº¦ã€‚å…¶è®¾è®¡è€… Nathaniel Smith å’Œ StÃ©fan van der Walt ç²¾å¿ƒè®¾è®¡äº†è¿ç»­çš„é¢œè‰²æ–¹æ¡ˆï¼Œè¿™äº›æ–¹æ¡ˆå¯¹äºå„ç§å½¢å¼çš„è‰²ç›²äººå£«æ¥è¯´éƒ½æ˜¯å¯æ„ŸçŸ¥çš„ï¼Œå¹¶ä¸”åœ¨å½©è‰²å’Œé»‘ç™½æ¨¡å¼ä¸‹éƒ½å…·æœ‰æ„ŸçŸ¥ä¸Šçš„å‡åŒ€æ€§ã€‚è¿™äº›æ ‡åº¦åœ¨ ggplot2 ä¸­ä»¥è¿ç»­ (c)ã€ç¦»æ•£ (d) å’Œåˆ†ç®± (b) è°ƒè‰²æ¿çš„å½¢å¼æä¾›ã€‚\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  labs(title = \"Default, continuous\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_c() +\n  labs(title = \"Viridis, continuous\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_b() +\n  labs(title = \"Viridis, binned\", x = NULL, y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that all color scales come in two varieties: scale_color_*() and scale_fill_*() for the color and fill aesthetics respectively (the color scales are available in both UK and US spellings).\nè¯·æ³¨æ„ï¼Œæ‰€æœ‰é¢œè‰²æ ‡åº¦éƒ½æœ‰ä¸¤ç§å˜ä½“ï¼šscale_color_*() å’Œ scale_fill_*()ï¼Œåˆ†åˆ«å¯¹åº” color å’Œ fill ç¾å­¦å±æ€§ï¼ˆé¢œè‰²æ ‡åº¦æä¾›è‹±å¼å’Œç¾å¼ä¸¤ç§æ‹¼å†™ï¼‰ã€‚\n\n11.4.5 Zooming\nThere are three ways to control the plot limits:\næœ‰ä¸‰ç§æ–¹æ³•å¯ä»¥æ§åˆ¶å›¾çš„ç•Œé™ï¼š\n\nAdjusting what data are plotted.\nè°ƒæ•´è¢«ç»˜åˆ¶çš„æ•°æ®ã€‚\nSetting the limits in each scale.\nåœ¨æ¯ä¸ªæ ‡åº¦ä¸­è®¾ç½®èŒƒå›´ï¼ˆlimitsï¼‰ã€‚\nSetting xlim and ylim in coord_cartesian().\nåœ¨ coord_cartesian() ä¸­è®¾ç½® xlim å’Œ ylimã€‚\n\nWeâ€™ll demonstrate these options in a series of plots. The plot on the left shows the relationship between engine size and fuel efficiency, colored by type of drive train. The plot on the right shows the same variables, but subsets the data that are plotted. Subsetting the data has affected the x and y scales as well as the smooth curve.\næˆ‘ä»¬å°†é€šè¿‡ä¸€ç³»åˆ—å›¾è¡¨æ¥æ¼”ç¤ºè¿™äº›é€‰é¡¹ã€‚å·¦è¾¹çš„å›¾è¡¨æ˜¾ç¤ºäº†å‘åŠ¨æœºå°ºå¯¸å’Œç‡ƒæ²¹æ•ˆç‡ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶æŒ‰é©±åŠ¨ç±»å‹ç€è‰²ã€‚å³è¾¹çš„å›¾è¡¨æ˜¾ç¤ºäº†ç›¸åŒçš„å˜é‡ï¼Œä½†å¯¹ç»˜åˆ¶çš„æ•°æ®è¿›è¡Œäº†å­é›†åŒ–ã€‚å¯¹æ•°æ®è¿›è¡Œå­é›†åŒ–å½±å“äº† x å’Œ y è½´çš„æ ‡åº¦ä»¥åŠå¹³æ»‘æ›²çº¿ã€‚\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n# Right\nmpg |&gt;\n  filter(displ &gt;= 5 & displ &lt;= 6 & hwy &gt;= 10 & hwy &lt;= 25) |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\nLetâ€™s compare these to the two plots below where the plot on the left sets the limits on individual scales and the plot on the right sets them in coord_cartesian(). We can see that reducing the limits is equivalent to subsetting the data. Therefore, to zoom in on a region of the plot, itâ€™s generally best to use coord_cartesian().\nè®©æˆ‘ä»¬å°†è¿™äº›ä¸ä¸‹é¢çš„ä¸¤å¼ å›¾è¿›è¡Œæ¯”è¾ƒï¼Œå…¶ä¸­å·¦è¾¹çš„å›¾åœ¨å•ä¸ªæ ‡åº¦ä¸Šè®¾ç½®äº† limitsï¼Œè€Œå³è¾¹çš„å›¾åœ¨ coord_cartesian() ä¸­è®¾ç½®äº†å®ƒä»¬ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç¼©å°é™åˆ¶ç­‰åŒäºå¯¹æ•°æ®è¿›è¡Œå­é›†åŒ–ã€‚å› æ­¤ï¼Œè¦æ”¾å¤§å›¾çš„æŸä¸ªåŒºåŸŸï¼Œé€šå¸¸æœ€å¥½ä½¿ç”¨ coord_cartesian()ã€‚\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  scale_x_continuous(limits = c(5, 6)) +\n  scale_y_continuous(limits = c(10, 25))\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  coord_cartesian(xlim = c(5, 6), ylim = c(10, 25))\n\n\n\n\n\n\n\n\n\n\nOn the other hand, setting the limits on individual scales is generally more useful if you want to expand the limits, e.g., to match scales across different plots. For example, if we extract two classes of cars and plot them separately, itâ€™s difficult to compare the plots because all three scales (the x-axis, the y-axis, and the color aesthetic) have different ranges.\nå¦ä¸€æ–¹é¢ï¼Œå¦‚æœä½ æƒ³æ‰©å¤§èŒƒå›´ï¼Œä¾‹å¦‚ï¼Œä¸ºäº†åœ¨ä¸åŒå›¾ä¹‹é—´åŒ¹é…æ ‡åº¦ï¼Œé‚£ä¹ˆåœ¨å•ä¸ªæ ‡åº¦ä¸Šè®¾ç½® limits é€šå¸¸æ›´æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æå–ä¸¤ç±»æ±½è½¦å¹¶åˆ†åˆ«ç»˜åˆ¶å®ƒä»¬ï¼Œé‚£ä¹ˆæ¯”è¾ƒè¿™äº›å›¾ä¼šå¾ˆå›°éš¾ï¼Œå› ä¸ºæ‰€æœ‰ä¸‰ä¸ªæ ‡åº¦ï¼ˆxè½´ã€yè½´å’Œé¢œè‰²ç¾å­¦ï¼‰éƒ½æœ‰ä¸åŒçš„èŒƒå›´ã€‚\nsuv &lt;- mpg |&gt; filter(class == \"suv\")\ncompact &lt;- mpg |&gt; filter(class == \"compact\")\n\n# Left\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n# Right\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nOne way to overcome this problem is to share scales across multiple plots, training the scales with the limits of the full data.\nå…‹æœè¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯åœ¨å¤šä¸ªå›¾ä¹‹é—´å…±äº«æ ‡åº¦ï¼Œä½¿ç”¨å®Œæ•´æ•°æ®çš„ limits æ¥â€œè®­ç»ƒâ€è¿™äº›æ ‡åº¦ã€‚\nx_scale &lt;- scale_x_continuous(limits = range(mpg$displ))\ny_scale &lt;- scale_y_continuous(limits = range(mpg$hwy))\ncol_scale &lt;- scale_color_discrete(limits = unique(mpg$drv))\n\n# Left\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n# Right\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n\n\n\n\n\n\n\n\n\nIn this particular case, you could have simply used faceting, but this technique is useful more generally, if for instance, you want to spread plots over multiple pages of a report.\nåœ¨è¿™ä¸ªç‰¹å®šçš„æ¡ˆä¾‹ä¸­ï¼Œä½ æœ¬å¯ä»¥ç®€å•åœ°ä½¿ç”¨åˆ†é¢ï¼Œä½†è¿™ç§æŠ€æœ¯åœ¨æ›´æ™®éçš„æƒ…å†µä¸‹ä¹Ÿå¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚ï¼Œå½“ä½ æƒ³å°†å›¾è¡¨åˆ†å¸ƒåœ¨æŠ¥å‘Šçš„å¤šä¸ªé¡µé¢ä¸Šæ—¶ã€‚\n\n11.4.6 Exercises\n\n\nWhy doesnâ€™t the following code override the default scale?\n\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  scale_color_gradient(low = \"white\", high = \"red\") +\n  coord_fixed()\n\n\nWhat is the first argument to every scale? How does it compare to labs()?\n\nChange the display of the presidential terms by:\n\nCombining the two variants that customize colors and x axis breaks.\nImproving the display of the y axis.\nLabelling each term with the name of the president.\nAdding informative plot labels.\nPlacing breaks every 4 years (this is trickier than it seems!).\n\n\n\nFirst, create the following plot. Then, modify the code using override.aes to make the legend easier to see.\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_point(aes(color = cut), alpha = 1/20)",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#sec-themes",
    "href": "communication.html#sec-themes",
    "title": "11Â  Communication",
    "section": "\n11.5 Themes",
    "text": "11.5 Themes\nFinally, you can customize the non-data elements of your plot with a theme:\næœ€åï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸»é¢˜ (theme) æ¥è‡ªå®šä¹‰å›¾å½¢ä¸­çš„éæ•°æ®å…ƒç´ ï¼š\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme_bw()\n\n\n\n\n\n\n\nggplot2 includes the eight themes shown in FigureÂ 11.2, with theme_gray() as the default.2 Many more are included in add-on packages like ggthemes (https://jrnold.github.io/ggthemes), by Jeffrey Arnold. You can also create your own themes, if you are trying to match a particular corporate or journal style.\nggplot2 åŒ…å«äº† FigureÂ 11.2 ä¸­æ˜¾ç¤ºçš„å…«ä¸ªä¸»é¢˜ï¼Œå…¶ä¸­ theme_gray() æ˜¯é»˜è®¤ä¸»é¢˜ã€‚2 è¿˜æœ‰æ›´å¤šä¸»é¢˜åŒ…å«åœ¨é™„åŠ åŒ…ä¸­ï¼Œä¾‹å¦‚ Jeffrey Arnold å¼€å‘çš„ ggthemes (https://jrnold.github.io/ggthemes)ã€‚å¦‚æœä½ æƒ³åŒ¹é…ç‰¹å®šçš„å…¬å¸æˆ–æœŸåˆŠé£æ ¼ï¼Œä¹Ÿå¯ä»¥åˆ›å»ºè‡ªå·±çš„ä¸»é¢˜ã€‚\n\n\n\n\n\n\n\nFigureÂ 11.2: The eight themes built-in to ggplot2.\n\n\n\n\nItâ€™s also possible to control individual components of each theme, like the size and color of the font used for the y axis. Weâ€™ve already seen that legend.position controls where the legend is drawn. There are many other aspects of the legend that can be customized with theme(). For example, in the plot below we change the direction of the legend as well as put a black border around it. Note that customization of the legend box and plot title elements of the theme are done with element_*() functions. These functions specify the styling of non-data components, e.g., the title text is bolded in the face argument of element_text() and the legend border color is defined in the color argument of element_rect(). The theme elements that control the position of the title and the caption are plot.title.position and plot.caption.position, respectively. In the following plot these are set to \"plot\" to indicate these elements are aligned to the entire plot area, instead of the plot panel (the default). A few other helpful theme() components are used to change the placement for format of the title and caption text.\nä¹Ÿå¯ä»¥æ§åˆ¶æ¯ä¸ªä¸»é¢˜çš„å•ä¸ªç»„ä»¶ï¼Œæ¯”å¦‚ y è½´ä½¿ç”¨çš„å­—ä½“å¤§å°å’Œé¢œè‰²ã€‚æˆ‘ä»¬å·²ç»çœ‹åˆ° legend.position æ§åˆ¶å›¾ä¾‹çš„ç»˜åˆ¶ä½ç½®ã€‚å›¾ä¾‹çš„è®¸å¤šå…¶ä»–æ–¹é¢ä¹Ÿå¯ä»¥ç”¨ theme() æ¥å®šåˆ¶ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„å›¾ä¸­ï¼Œæˆ‘ä»¬æ”¹å˜äº†å›¾ä¾‹çš„æ–¹å‘ï¼Œå¹¶ç»™å®ƒåŠ ä¸Šäº†é»‘è‰²çš„è¾¹æ¡†ã€‚æ³¨æ„ï¼Œå›¾ä¾‹æ¡†å’Œå›¾æ ‡é¢˜ç­‰ä¸»é¢˜å…ƒç´ çš„å®šåˆ¶æ˜¯é€šè¿‡ element_*() å‡½æ•°å®Œæˆçš„ã€‚è¿™äº›å‡½æ•°æŒ‡å®šäº†éæ•°æ®ç»„ä»¶çš„æ ·å¼ï¼Œä¾‹å¦‚ï¼Œæ ‡é¢˜æ–‡æœ¬åœ¨ element_text() çš„ face å‚æ•°ä¸­è¢«åŠ ç²—ï¼Œå›¾ä¾‹è¾¹æ¡†é¢œè‰²åœ¨ element_rect() çš„ color å‚æ•°ä¸­è¢«å®šä¹‰ã€‚æ§åˆ¶æ ‡é¢˜å’Œè¯´æ˜æ–‡å­—ä½ç½®çš„ä¸»é¢˜å…ƒç´ åˆ†åˆ«æ˜¯ plot.title.position å’Œ plot.caption.positionã€‚åœ¨ä¸‹é¢çš„å›¾ä¸­ï¼Œè¿™äº›è¢«è®¾ç½®ä¸º \"plot\"ï¼Œè¡¨ç¤ºè¿™äº›å…ƒç´ ä¸æ•´ä¸ªç»˜å›¾åŒºåŸŸå¯¹é½ï¼Œè€Œä¸æ˜¯ç»˜å›¾é¢æ¿ï¼ˆé»˜è®¤å€¼ï¼‰ã€‚è¿˜ä½¿ç”¨äº†ä¸€äº›å…¶ä»–æœ‰ç”¨çš„ theme() ç»„ä»¶æ¥æ›´æ”¹æ ‡é¢˜å’Œè¯´æ˜æ–‡å­—çš„ä½ç½®æ ¼å¼ã€‚\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  labs(\n    title = \"Larger engine sizes tend to have lower fuel economy\",\n    caption = \"Source: https://fueleconomy.gov.\"\n  ) +\n  theme(\n    legend.position = c(0.6, 0.7),\n    legend.direction = \"horizontal\",\n    legend.box.background = element_rect(color = \"black\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.title.position = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.caption = element_text(hjust = 0)\n  )\n#&gt; Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n#&gt; 3.5.0.\n#&gt; â„¹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\nFor an overview of all theme() components, see help with ?theme. The ggplot2 book is also a great place to go for the full details on theming.\nè¦äº†è§£æ‰€æœ‰ theme() ç»„ä»¶çš„æ¦‚è§ˆï¼Œè¯·æŸ¥çœ‹ ?theme çš„å¸®åŠ©æ–‡æ¡£ã€‚ggplot2 book ä¹Ÿæ˜¯ä¸€ä¸ªäº†è§£ä¸»é¢˜è®¾ç½®å…¨éƒ¨ç»†èŠ‚çš„å¥½å»å¤„ã€‚\n\n11.5.1 Exercises\n\nPick a theme offered by the ggthemes package and apply it to the last plot you made.\nMake the axis labels of your plot blue and bolded.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#layout",
    "href": "communication.html#layout",
    "title": "11Â  Communication",
    "section": "\n11.6 Layout",
    "text": "11.6 Layout\nSo far we talked about how to create and modify a single plot. What if you have multiple plots you want to lay out in a certain way? The patchwork package allows you to combine separate plots into the same graphic. We loaded this package earlier in the chapter.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•åˆ›å»ºå’Œä¿®æ”¹å•ä¸ªå›¾ã€‚ä½†å¦‚æœä½ æœ‰å¤šä¸ªå›¾ï¼Œå¹¶å¸Œæœ›ä»¥æŸç§ç‰¹å®šæ–¹å¼å¸ƒå±€å®ƒä»¬ï¼Œè¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿpatchwork åŒ…å…è®¸ä½ å°†å¤šä¸ªç‹¬ç«‹çš„å›¾ç»„åˆæˆä¸€ä¸ªå›¾å½¢ã€‚æˆ‘ä»¬åœ¨æœ¬ç« å‰é¢å·²ç»åŠ è½½äº†è¿™ä¸ªåŒ…ã€‚\nTo place two plots next to each other, you can simply add them to each other. Note that you first need to create the plots and save them as objects (in the following example theyâ€™re called p1 and p2). Then, you place them next to each other with +.\nè¦å°†ä¸¤ä¸ªå›¾å¹¶æ’æ”¾ç½®ï¼Œä½ åªéœ€å°†å®ƒä»¬ç›¸åŠ å³å¯ã€‚è¯·æ³¨æ„ï¼Œä½ é¦–å…ˆéœ€è¦åˆ›å»ºè¿™äº›å›¾å¹¶å°†å®ƒä»¬ä¿å­˜ä¸ºå¯¹è±¡ï¼ˆåœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œå®ƒä»¬è¢«ç§°ä¸º p1 å’Œ p2ï¼‰ã€‚ç„¶åï¼Œä½ ç”¨ + å°†å®ƒä»¬å¹¶æ’æ”¾ç½®ã€‚\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"Plot 2\")\np1 + p2\n\n\n\n\n\n\n\nItâ€™s important to note that in the above code chunk we did not use a new function from the patchwork package. Instead, the package added a new functionality to the + operator.\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ä¸Šé¢çš„ä»£ç å—ä¸­ï¼Œæˆ‘ä»¬å¹¶æœªä½¿ç”¨ patchwork åŒ…ä¸­çš„æ–°å‡½æ•°ã€‚ç›¸åï¼Œè¯¥åŒ…ä¸º + è¿ç®—ç¬¦æ·»åŠ äº†æ–°çš„åŠŸèƒ½ã€‚\nYou can also create complex plot layouts with patchwork. In the following, | places the p1 and p3 next to each other and / moves p2 to the next line.\nä½ è¿˜å¯ä»¥ä½¿ç”¨ patchwork åˆ›å»ºå¤æ‚çš„å›¾å½¢å¸ƒå±€ã€‚åœ¨ä¸‹æ–‡ä¸­ï¼Œ| å°† p1 å’Œ p3 å¹¶æ’æ”¾ç½®ï¼Œè€Œ / å°† p2 ç§»åˆ°ä¸‹ä¸€è¡Œã€‚\n\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 3\")\n(p1 | p3) / p2\n\n\n\n\n\n\n\nAdditionally, patchwork allows you to collect legends from multiple plots into one common legend, customize the placement of the legend as well as dimensions of the plots, and add a common title, subtitle, caption, etc. to your plots. Below we create 5 plots. We have turned off the legends on the box plots and the scatterplot and collected the legends for the density plots at the top of the plot with & theme(legend.position = \"top\"). Note the use of the & operator here instead of the usual +. This is because weâ€™re modifying the theme for the patchwork plot as opposed to the individual ggplots. The legend is placed on top, inside the guide_area(). Finally, we have also customized the heights of the various components of our patchwork â€“ the guide has a height of 1, the box plots 3, density plots 2, and the faceted scatterplot 4. Patchwork divides up the area you have allotted for your plot using this scale and places the components accordingly.\næ­¤å¤–ï¼Œpatchwork å…è®¸ä½ å°†å¤šä¸ªå›¾çš„å›¾ä¾‹æ”¶é›†åˆ°ä¸€ä¸ªå…¬å…±å›¾ä¾‹ä¸­ï¼Œè‡ªå®šä¹‰å›¾ä¾‹çš„ä½ç½®ä»¥åŠå›¾çš„å°ºå¯¸ï¼Œå¹¶ä¸ºä½ çš„å›¾æ·»åŠ å…¬å…±çš„æ ‡é¢˜ã€å‰¯æ ‡é¢˜ã€è¯´æ˜ç­‰ã€‚ä¸‹é¢æˆ‘ä»¬åˆ›å»º 5 ä¸ªå›¾ã€‚æˆ‘ä»¬å…³é—­äº†ç®±çº¿å›¾å’Œæ•£ç‚¹å›¾çš„å›¾ä¾‹ï¼Œå¹¶ä½¿ç”¨ & theme(legend.position = \"top\") å°†å¯†åº¦å›¾çš„å›¾ä¾‹æ”¶é›†åˆ°å›¾çš„é¡¶éƒ¨ã€‚æ³¨æ„è¿™é‡Œä½¿ç”¨äº† & æ“ä½œç¬¦è€Œä¸æ˜¯é€šå¸¸çš„ +ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬æ­£åœ¨ä¿®æ”¹ patchwork å›¾çš„ä¸»é¢˜ï¼Œè€Œä¸æ˜¯å•ä¸ª ggplotã€‚å›¾ä¾‹è¢«æ”¾ç½®åœ¨é¡¶éƒ¨ï¼Œåœ¨ guide_area() å†…éƒ¨ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜è‡ªå®šä¹‰äº† patchwork å„ä¸ªç»„ä»¶çš„é«˜åº¦â€”â€”å¼•å¯¼åŒºé«˜åº¦ä¸º 1ï¼Œç®±çº¿å›¾ä¸º 3ï¼Œå¯†åº¦å›¾ä¸º 2ï¼Œåˆ†é¢æ•£ç‚¹å›¾ä¸º 4ã€‚Patchwork ä½¿ç”¨è¿™ä¸ªæ¯”ä¾‹æ¥åˆ’åˆ†ä½ ä¸ºå›¾åˆ†é…çš„åŒºåŸŸï¼Œå¹¶ç›¸åº”åœ°æ”¾ç½®ç»„ä»¶ã€‚\n\np1 &lt;- ggplot(mpg, aes(x = drv, y = cty, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"Plot 1\")\n\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"Plot 2\")\n\np3 &lt;- ggplot(mpg, aes(x = cty, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"Plot 3\")\n\np4 &lt;- ggplot(mpg, aes(x = hwy, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"Plot 4\")\n\np5 &lt;- ggplot(mpg, aes(x = cty, y = hwy, color = drv)) + \n  geom_point(show.legend = FALSE) + \n  facet_wrap(~drv) +\n  labs(title = \"Plot 5\")\n\n(guide_area() / (p1 + p2) / (p3 + p4) / p5) +\n  plot_annotation(\n    title = \"City and highway mileage for cars with different drive trains\",\n    caption = \"Source: https://fueleconomy.gov.\"\n  ) +\n  plot_layout(\n    guides = \"collect\",\n    heights = c(1, 3, 2, 4)\n    ) &\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nIf youâ€™d like to learn more about combining and layout out multiple plots with patchwork, we recommend looking through the guides on the package website: https://patchwork.data-imaginist.com.\nå¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºä½¿ç”¨ patchwork ç»„åˆå’Œå¸ƒå±€å¤šä¸ªå›¾çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å»ºè®®ä½ æµè§ˆè¯¥åŒ…ç½‘ç«™ä¸Šçš„æŒ‡å—ï¼šhttps://patchwork.data-imaginist.comã€‚\n\n11.6.1 Exercises\n\n\nWhat happens if you omit the parentheses in the following plot layout. Can you explain why this happens?\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"Plot 2\")\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 3\")\n\n(p1 | p2) / p3\n\n\n\nUsing the three plots from the previous exercise, recreate the following patchwork.",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#summary",
    "href": "communication.html#summary",
    "title": "11Â  Communication",
    "section": "\n11.7 Summary",
    "text": "11.7 Summary\nIn this chapter youâ€™ve learned about adding plot labels such as title, subtitle, caption as well as modifying default axis labels, using annotation to add informational text to your plot or to highlight specific data points, customizing the axis scales, and changing the theme of your plot. Youâ€™ve also learned about combining multiple plots in a single graph using both simple and complex plot layouts.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†æ·»åŠ å›¾å½¢æ ‡ç­¾ï¼ˆå¦‚æ ‡é¢˜ã€å‰¯æ ‡é¢˜ã€è¯´æ˜æ–‡å­—ï¼‰ä»¥åŠä¿®æ”¹é»˜è®¤åæ ‡è½´æ ‡ç­¾ã€ä½¿ç”¨æ³¨é‡Šä¸ºå›¾å½¢æ·»åŠ ä¿¡æ¯æ€§æ–‡æœ¬æˆ–çªå‡ºæ˜¾ç¤ºç‰¹å®šæ•°æ®ç‚¹ã€è‡ªå®šä¹‰åæ ‡è½´æ ‡åº¦å’Œæ›´æ”¹å›¾å½¢ä¸»é¢˜ã€‚ä½ è¿˜å­¦ä¹ äº†ä½¿ç”¨ç®€å•å’Œå¤æ‚çš„å›¾å½¢å¸ƒå±€å°†å¤šä¸ªå›¾å½¢ç»„åˆæˆä¸€ä¸ªå›¾å½¢ã€‚\nWhile youâ€™ve so far learned about how to make many different types of plots and how to customize them using a variety of techniques, weâ€™ve barely scratched the surface of what you can create with ggplot2. If you want to get a comprehensive understanding of ggplot2, we recommend reading the book, ggplot2: Elegant Graphics for Data Analysis. Other useful resources are the R Graphics Cookbook by Winston Chang and Fundamentals of Data Visualization by Claus Wilke.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»å­¦ä¼šäº†å¦‚ä½•åˆ¶ä½œå¤šç§ä¸åŒç±»å‹çš„å›¾ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨å„ç§æŠ€æœ¯å¯¹å…¶è¿›è¡Œè‡ªå®šä¹‰ï¼Œä½†æˆ‘ä»¬å¯¹ ggplot2 èƒ½åˆ›å»ºçš„å†…å®¹è¿˜åªæ˜¯æµ…å°è¾„æ­¢ã€‚å¦‚æœä½ æƒ³å…¨é¢äº†è§£ ggplot2ï¼Œæˆ‘ä»¬æ¨èé˜…è¯» ggplot2: Elegant Graphics for Data Analysis è¿™æœ¬ä¹¦ã€‚å…¶ä»–æœ‰ç”¨çš„èµ„æºåŒ…æ‹¬ Winston Chang çš„ R Graphics Cookbook å’Œ Claus Wilke çš„ Fundamentals of Data Visualizationã€‚",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#footnotes",
    "href": "communication.html#footnotes",
    "title": "11Â  Communication",
    "section": "",
    "text": "You can use a tool like SimDaltonism to simulate color blindness to test these images.â†©ï¸\nMany people wonder why the default theme has a gray background. This was a deliberate choice because it puts the data forward while still making the grid lines visible. The white grid lines are visible (which is important because they significantly aid position judgments), but they have little visual impact and we can easily tune them out. The gray background gives the plot a similar typographic color to the text, ensuring that the graphics fit in with the flow of a document without jumping out with a bright white background. Finally, the gray background creates a continuous field of color which ensures that the plot is perceived as a single visual entity.â†©ï¸",
    "crumbs": [
      "Visualize",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "transform.html",
    "href": "transform.html",
    "title": "Transform",
    "section": "",
    "text": "The second part of the book was a deep dive into data visualization. In this part of the book, youâ€™ll learn about the most important types of variables that youâ€™ll encounter inside a data frame and learn the tools you can use to work with them.\næœ¬ä¹¦çš„ç¬¬äºŒéƒ¨åˆ†æ·±å…¥æ¢è®¨äº†æ•°æ®å¯è§†åŒ–ã€‚åœ¨æœ¬ä¹¦çš„è¿™ä¸€éƒ¨åˆ†ï¼Œä½ å°†å­¦ä¹ åˆ°åœ¨æ•°æ®æ¡† (data frame) ä¸­ä¼šé‡åˆ°çš„æœ€é‡è¦å˜é‡ç±»å‹ï¼Œä»¥åŠå¯ä»¥ç”¨æ¥å¤„ç†å®ƒä»¬çš„å·¥å…·ã€‚\n\n\n\n\n\n\n\nFigureÂ 1: The options for data transformation depend heavily on the type of data involved, the subject of this part of the book.\n\n\n\n\nYou can read these chapters as you need them; theyâ€™re designed to be largely standalone so that they can be read out of order.\nä½ å¯ä»¥æ ¹æ®éœ€è¦é˜…è¯»è¿™äº›ç« èŠ‚ï¼›å®ƒä»¬çš„è®¾è®¡åˆè¡·æ˜¯ä½¿å…¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¿æŒç‹¬ç«‹ï¼Œå› æ­¤å¯ä»¥ä¸æŒ‰é¡ºåºé˜…è¯»ã€‚\n\n12Â  Logical vectors teaches you about logical vectors. These are the simplest types of vectors, but are extremely powerful. Youâ€™ll learn how to create them with numeric comparisons, how to combine them with Boolean algebra, how to use them in summaries, and how to use them for conditional transformations. è¿™æ˜¯æœ€ç®€å•çš„å‘é‡ç±»å‹ï¼Œä½†åŠŸèƒ½æå…¶å¼ºå¤§ã€‚ä½ å°†å­¦ä¹ å¦‚ä½•é€šè¿‡æ•°å€¼æ¯”è¾ƒæ¥åˆ›å»ºå®ƒä»¬ï¼Œå¦‚ä½•ç”¨å¸ƒå°”ä»£æ•° (Boolean algebra) æ¥ç»„åˆå®ƒä»¬ï¼Œå¦‚ä½•åœ¨æ±‡æ€» (summaries) ä¸­ä½¿ç”¨å®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•å°†å®ƒä»¬ç”¨äºæ¡ä»¶è½¬æ¢ã€‚\n13Â  Numbers dives into tools for vectors of numbers, the powerhouse of data science. Youâ€™ll learn more about counting and a bunch of important transformation and summary functions. ä½ å°†å­¦ä¹ æ›´å¤šå…³äºè®¡æ•°ä»¥åŠä¸€ç³»åˆ—é‡è¦çš„è½¬æ¢å’Œæ±‡æ€»å‡½æ•°ã€‚\n14Â  Strings will give you the tools to work with strings: youâ€™ll slice them, youâ€™ll dice them, and youâ€™ll stick them back together again. This chapter mostly focuses on the stringr package, but youâ€™ll also learn some more tidyr functions devoted to extracting data from character strings. æœ¬ç« ä¸»è¦å…³æ³¨ stringr åŒ…ï¼Œä½†ä½ ä¹Ÿå°†å­¦ä¹ ä¸€äº› tidyr ä¸­ä¸“é—¨ç”¨äºä»å­—ç¬¦ä¸²ä¸­æå–æ•°æ®çš„å‡½æ•°ã€‚\n15Â  Regular expressions introduces you to regular expressions, a powerful tool for manipulating strings. This chapter will take you from thinking that a cat walked over your keyboard to reading and writing complex string patterns. æœ¬ç« å°†å¸¦ä½ ä»æ„Ÿè§‰åƒæ˜¯çŒ«èµ°è¿‡äº†ä½ çš„é”®ç›˜ï¼Œåˆ°èƒ½å¤Ÿè¯»æ‡‚å¹¶ç¼–å†™å¤æ‚çš„å­—ç¬¦ä¸²æ¨¡å¼ã€‚\n16Â  Factors introduces factors: the data type that R uses to store categorical data. You use a factor when variable has a fixed set of possible values, or when you want to use a non-alphabetical ordering of a string. å½“ä¸€ä¸ªå˜é‡æœ‰ä¸€ç»„å›ºå®šçš„å¯èƒ½å€¼ï¼Œæˆ–è€…å½“ä½ æƒ³å¯¹å­—ç¬¦ä¸²ä½¿ç”¨éå­—æ¯é¡ºåºæ’åºæ—¶ï¼Œä½ ä¼šä½¿ç”¨å› å­ã€‚\n17Â  Dates and times will give you the key tools for working with dates and date-times. Unfortunately, the more you learn about date-times, the more complicated they seem to get, but with the help of the lubridate package, youâ€™ll learn to how to overcome the most common challenges. ä¸å¹¸çš„æ˜¯ï¼Œä½ å¯¹æ—¥æœŸæ—¶é—´äº†è§£å¾—è¶Šå¤šï¼Œå®ƒä»¬ä¼¼ä¹å°±å˜å¾—è¶Šå¤æ‚ï¼Œä½†åœ¨ lubridate åŒ…çš„å¸®åŠ©ä¸‹ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•å…‹æœæœ€å¸¸è§çš„æŒ‘æˆ˜ã€‚\n18Â  Missing values discusses missing values in depth. Weâ€™ve discussed them a couple of times in isolation, but now itâ€™s time to discuss them holistically, helping you come to grips with the difference between implicit and explicit missing values, and how and why you might convert between them. æˆ‘ä»¬å·²ç»é›¶æ˜Ÿåœ°è®¨è®ºè¿‡å‡ æ¬¡ï¼Œä½†ç°åœ¨æ˜¯æ—¶å€™å…¨é¢åœ°è®¨è®ºå®ƒä»¬äº†ï¼Œå¸®åŠ©ä½ ç†è§£éšå¼ (implicit) å’Œæ˜¾å¼ (explicit) ç¼ºå¤±å€¼ä¹‹é—´çš„åŒºåˆ«ï¼Œä»¥åŠå¦‚ä½•ä»¥åŠä¸ºä½•åœ¨å®ƒä»¬ä¹‹é—´è¿›è¡Œè½¬æ¢ã€‚\n19Â  Joins finishes up this part of the book by giving you tools to join two (or more) data frames together. Learning about joins will force you to grapple with the idea of keys, and think about how you identify each row in a dataset. å­¦ä¹ è¿æ¥ (joins) å°†è¿«ä½¿ä½ æ·±å…¥ç†è§£é”® (keys) çš„æ¦‚å¿µï¼Œå¹¶æ€è€ƒå¦‚ä½•è¯†åˆ«æ•°æ®é›†ä¸­çš„æ¯ä¸€è¡Œã€‚",
    "crumbs": [
      "Transform"
    ]
  },
  {
    "objectID": "logicals.html",
    "href": "logicals.html",
    "title": "12Â  Logical vectors",
    "section": "",
    "text": "12.1 Introduction\nIn this chapter, youâ€™ll learn tools for working with logical vectors. Logical vectors are the simplest type of vector because each element can only be one of three possible values: TRUE, FALSE, and NA. Itâ€™s relatively rare to find logical vectors in your raw data, but youâ€™ll create and manipulate them in the course of almost every analysis.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ ä½¿ç”¨é€»è¾‘å‘é‡çš„å·¥å…·ã€‚é€»è¾‘å‘é‡æ˜¯æœ€ç®€å•çš„å‘é‡ç±»å‹ï¼Œå› ä¸ºæ¯ä¸ªå…ƒç´ åªèƒ½æ˜¯ä¸‰ä¸ªå¯èƒ½å€¼ä¹‹ä¸€ï¼šTRUEã€FALSE å’Œ NAã€‚åœ¨åŸå§‹æ•°æ®ä¸­ç›¸å¯¹è¾ƒå°‘è§åˆ°é€»è¾‘å‘é‡ï¼Œä½†ä½ å‡ ä¹åœ¨æ¯ä¸€æ¬¡åˆ†æè¿‡ç¨‹ä¸­éƒ½ä¼šåˆ›å»ºå’Œæ“ä½œå®ƒä»¬ã€‚\nWeâ€™ll begin by discussing the most common way of creating logical vectors: with numeric comparisons. Then youâ€™ll learn about how you can use Boolean algebra to combine different logical vectors, as well as some useful summaries. Weâ€™ll finish off with if_else() and case_when(), two useful functions for making conditional changes powered by logical vectors.\næˆ‘ä»¬å°†ä»è®¨è®ºåˆ›å»ºé€»è¾‘å‘é‡æœ€å¸¸è§çš„æ–¹æ³•å¼€å§‹ï¼šä½¿ç”¨æ•°å€¼æ¯”è¾ƒã€‚ç„¶åï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨å¸ƒå°”ä»£æ•°æ¥ç»„åˆä¸åŒçš„é€»è¾‘å‘é‡ï¼Œä»¥åŠä¸€äº›æœ‰ç”¨çš„æ±‡æ€»æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ä»‹ç» if_else() å’Œ case_when()ï¼Œè¿™æ˜¯ä¸¤ä¸ªç”±é€»è¾‘å‘é‡é©±åŠ¨ã€ç”¨äºè¿›è¡Œæ¡ä»¶æ€§å˜æ›´çš„æœ‰ç”¨å‡½æ•°ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "logicals.html#introduction",
    "href": "logicals.html#introduction",
    "title": "12Â  Logical vectors",
    "section": "",
    "text": "12.1.1 Prerequisites\nMost of the functions youâ€™ll learn about in this chapter are provided by base R, so we donâ€™t need the tidyverse, but weâ€™ll still load it so we can use mutate(), filter(), and friends to work with data frames. Weâ€™ll also continue to draw examples from the nycflights13::flights dataset.\næœ¬ç« ä½ å°†å­¦åˆ°çš„å¤§å¤šæ•°å‡½æ•°éƒ½ç”± R base æä¾›ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦ tidyverseï¼Œä½†æˆ‘ä»¬ä»ç„¶ä¼šåŠ è½½å®ƒï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ mutate()ã€filter() åŠå…¶ä»–ç›¸å…³å‡½æ•°æ¥å¤„ç†æ•°æ®æ¡†ã€‚æˆ‘ä»¬ä¹Ÿå°†ç»§ç»­ä½¿ç”¨ nycflights13::flights æ•°æ®é›†ä¸­çš„ä¾‹å­ã€‚\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\nHowever, as we start to cover more tools, there wonâ€™t always be a perfect real example. So weâ€™ll start making up some dummy data with c():\nç„¶è€Œï¼Œéšç€æˆ‘ä»¬å¼€å§‹ä»‹ç»æ›´å¤šçš„å·¥å…·ï¼Œå¹¶ä¸æ€»èƒ½æ‰¾åˆ°ä¸€ä¸ªå®Œç¾çš„çœŸå®æ¡ˆä¾‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å¼€å§‹ä½¿ç”¨ c() åˆ›å»ºä¸€äº›è™šæ‹Ÿæ•°æ®ï¼š\n\nx &lt;- c(1, 2, 3, 5, 7, 11, 13)\nx * 2\n#&gt; [1]  2  4  6 10 14 22 26\n\nThis makes it easier to explain individual functions at the cost of making it harder to see how it might apply to your data problems. Just remember that any manipulation we do to a free-floating vector, you can do to a variable inside a data frame with mutate() and friends.\nè¿™æ ·åšè™½ç„¶æ›´å®¹æ˜“è§£é‡Šå•ä¸ªå‡½æ•°ï¼Œä½†ä»£ä»·æ˜¯æ›´éš¾çœ‹å‡ºå®ƒå¦‚ä½•åº”ç”¨äºä½ çš„æ•°æ®é—®é¢˜ã€‚åªéœ€è®°ä½ï¼Œæˆ‘ä»¬å¯¹ä¸€ä¸ªç‹¬ç«‹å‘é‡æ‰€åšçš„ä»»ä½•æ“ä½œï¼Œä½ éƒ½å¯ä»¥é€šè¿‡ mutate() åŠç›¸å…³å‡½æ•°å¯¹æ•°æ®æ¡†å†…çš„å˜é‡è¿›è¡ŒåŒæ ·çš„æ“ä½œã€‚\n\ndf &lt;- tibble(x)\ndf |&gt; \n  mutate(y = x * 2)\n#&gt; # A tibble: 7 Ã— 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2\n#&gt; 2     2     4\n#&gt; 3     3     6\n#&gt; 4     5    10\n#&gt; 5     7    14\n#&gt; 6    11    22\n#&gt; # â„¹ 1 more row",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "logicals.html#comparisons",
    "href": "logicals.html#comparisons",
    "title": "12Â  Logical vectors",
    "section": "\n12.2 Comparisons",
    "text": "12.2 Comparisons\nA very common way to create a logical vector is via a numeric comparison with &lt;, &lt;=, &gt;, &gt;=, !=, and ==. So far, weâ€™ve mostly created logical variables transiently within filter() â€” they are computed, used, and then thrown away. For example, the following filter finds all daytime departures that arrive roughly on time:\nåˆ›å»ºé€»è¾‘å‘é‡çš„ä¸€ä¸ªéå¸¸å¸¸è§çš„æ–¹æ³•æ˜¯é€šè¿‡æ•°å€¼æ¯”è¾ƒï¼Œä½¿ç”¨ &lt;, &lt;=, &gt;, &gt;=, !=, å’Œ ==ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸»è¦æ˜¯åœ¨ filter() ä¸­ä¸´æ—¶åˆ›å»ºé€»è¾‘å˜é‡â€”â€”å®ƒä»¬è¢«è®¡ç®—ã€ä½¿ç”¨ï¼Œç„¶åè¢«ä¸¢å¼ƒã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„ç­›é€‰å™¨å¯ä»¥æ‰¾å‡ºæ‰€æœ‰åœ¨ç™½å¤©å‡ºå‘ä¸”å¤§è‡´å‡†æ—¶åˆ°è¾¾çš„èˆªç­ï¼š\n\nflights |&gt; \n  filter(dep_time &gt; 600 & dep_time &lt; 2000 & abs(arr_delay) &lt; 20)\n#&gt; # A tibble: 172,286 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      601            600         1      844            850\n#&gt; 2  2013     1     1      602            610        -8      812            820\n#&gt; 3  2013     1     1      602            605        -3      821            805\n#&gt; 4  2013     1     1      606            610        -4      858            910\n#&gt; 5  2013     1     1      606            610        -4      837            845\n#&gt; 6  2013     1     1      607            607         0      858            915\n#&gt; # â„¹ 172,280 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nItâ€™s useful to know that this is a shortcut and you can explicitly create the underlying logical variables with mutate():\näº†è§£è¿™æ˜¯ä¸€ç§å¿«æ·æ–¹å¼ä¼šå¾ˆæœ‰ç”¨ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ mutate() æ˜¾å¼åœ°åˆ›å»ºåº•å±‚çš„é€»è¾‘å˜é‡ï¼š\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 Ã— 4\n#&gt;   dep_time arr_delay daytime approx_ontime\n#&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;lgl&gt;   &lt;lgl&gt;        \n#&gt; 1      517        11 FALSE   TRUE         \n#&gt; 2      533        20 FALSE   FALSE        \n#&gt; 3      542        33 FALSE   FALSE        \n#&gt; 4      544       -18 FALSE   TRUE         \n#&gt; 5      554       -25 FALSE   FALSE        \n#&gt; 6      554        12 FALSE   TRUE         \n#&gt; # â„¹ 336,770 more rows\n\nThis is particularly useful for more complicated logic because naming the intermediate steps makes it easier to both read your code and check that each step has been computed correctly.\nè¿™å¯¹äºæ›´å¤æ‚çš„é€»è¾‘å°¤å…¶æœ‰ç”¨ï¼Œå› ä¸ºä¸ºä¸­é—´æ­¥éª¤å‘½åå¯ä»¥ä½¿ä½ çš„ä»£ç æ›´æ˜“äºé˜…è¯»ï¼Œä¹Ÿæ›´å®¹æ˜“æ£€æŸ¥æ¯ä¸€æ­¥æ˜¯å¦è®¡ç®—æ­£ç¡®ã€‚\nAll up, the initial filter is equivalent to:\næ€»è€Œè¨€ä¹‹ï¼Œæœ€åˆçš„ç­›é€‰å™¨ç­‰åŒäºï¼š\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n  ) |&gt; \n  filter(daytime & approx_ontime)\n\n\n12.2.1 Floating point comparison\nBeware of using == with numbers. For example, it looks like this vector contains the numbers 1 and 2:\næ³¨æ„ï¼Œå½“å¤„ç†æ•°å­—æ—¶è¦å°å¿ƒä½¿ç”¨ ==ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢è¿™ä¸ªå‘é‡çœ‹èµ·æ¥åŒ…å«äº†æ•°å­— 1 å’Œ 2ï¼š\n\nx &lt;- c(1 / 49 * 49, sqrt(2) ^ 2)\nx\n#&gt; [1] 1 2\n\nBut if you test them for equality, you get FALSE:\nä½†å¦‚æœä½ æµ‹è¯•å®ƒä»¬æ˜¯å¦ç›¸ç­‰ï¼Œä½ ä¼šå¾—åˆ° FALSEï¼š\n\nx == c(1, 2)\n#&gt; [1] FALSE FALSE\n\nWhatâ€™s going on? Computers store numbers with a fixed number of decimal places so thereâ€™s no way to exactly represent 1/49 or sqrt(2) and subsequent computations will be very slightly off. We can see the exact values by calling print() with the digits1 argument:\nè¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿè®¡ç®—æœºä»¥å›ºå®šçš„å°æ•°ä½æ•°å­˜å‚¨æ•°å­—ï¼Œå› æ­¤æ— æ³•ç²¾ç¡®è¡¨ç¤º 1/49 æˆ– sqrt(2)ï¼Œåç»­è®¡ç®—ä¼šæœ‰äº›å¾®åå·®ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨ print() å¹¶ä½¿ç”¨ digits1 å‚æ•°æ¥æŸ¥çœ‹ç¡®åˆ‡çš„å€¼ï¼š\n\nprint(x, digits = 16)\n#&gt; [1] 0.9999999999999999 2.0000000000000004\n\nYou can see why R defaults to rounding these numbers; they really are very close to what you expect.\nä½ å¯ä»¥çœ‹åˆ°ä¸ºä»€ä¹ˆ R é»˜è®¤ä¼šå››èˆäº”å…¥è¿™äº›æ•°å­—ï¼›å®ƒä»¬ç¡®å®éå¸¸æ¥è¿‘ä½ çš„é¢„æœŸã€‚\nNow that youâ€™ve seen why == is failing, what can you do about it? One option is to use dplyr::near() which ignores small differences:\næ—¢ç„¶ä½ å·²ç»çœ‹åˆ°äº† == å¤±è´¥çš„åŸå› ï¼Œé‚£ä½ è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿä¸€ä¸ªé€‰é¡¹æ˜¯ä½¿ç”¨ dplyr::near()ï¼Œå®ƒä¼šå¿½ç•¥å¾®å°çš„å·®å¼‚ï¼š\n\nnear(x, c(1, 2))\n#&gt; [1] TRUE TRUE\n\n\n12.2.2 Missing values\nMissing values represent the unknown so they are â€œcontagiousâ€: almost any operation involving an unknown value will also be unknown:\nç¼ºå¤±å€¼ä»£è¡¨æœªçŸ¥ï¼Œæ‰€ä»¥å®ƒä»¬æ˜¯â€œä¼šä¼ æŸ“çš„â€ï¼šå‡ ä¹ä»»ä½•æ¶‰åŠæœªçŸ¥å€¼çš„æ“ä½œç»“æœä¹Ÿå°†æ˜¯æœªçŸ¥çš„ï¼š\n\nNA &gt; 5\n#&gt; [1] NA\n10 == NA\n#&gt; [1] NA\n\nThe most confusing result is this one:\næœ€ä»¤äººå›°æƒ‘çš„ç»“æœæ˜¯è¿™ä¸ªï¼š\n\nNA == NA\n#&gt; [1] NA\n\nItâ€™s easiest to understand why this is true if we artificially supply a little more context:\nå¦‚æœæˆ‘ä»¬äººä¸ºåœ°æä¾›ä¸€äº›ä¸Šä¸‹æ–‡ï¼Œå°±æœ€å®¹æ˜“ç†è§£ä¸ºä»€ä¹ˆè¿™æ˜¯çœŸçš„ï¼š\n\n# We don't know how old Mary is\nage_mary &lt;- NA\n\n# We don't know how old John is\nage_john &lt;- NA\n\n# Are Mary and John the same age?\nage_mary == age_john\n#&gt; [1] NA\n# We don't know!\n\nSo if you want to find all flights where dep_time is missing, the following code doesnâ€™t work because dep_time == NA will yield NA for every single row, and filter() automatically drops missing values:\næ‰€ä»¥ï¼Œå¦‚æœä½ æƒ³æŸ¥æ‰¾æ‰€æœ‰ dep_time ç¼ºå¤±çš„èˆªç­ï¼Œä¸‹é¢çš„ä»£ç æ˜¯è¡Œä¸é€šçš„ï¼Œå› ä¸º dep_time == NA ä¼šå¯¹æ¯ä¸€è¡Œéƒ½äº§ç”Ÿ NAï¼Œè€Œ filter() ä¼šè‡ªåŠ¨ä¸¢å¼ƒç¼ºå¤±å€¼ï¼š\n\nflights |&gt; \n  filter(dep_time == NA)\n#&gt; # A tibble: 0 Ã— 19\n#&gt; # â„¹ 19 variables: year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;, dep_time &lt;int&gt;,\n#&gt; #   sched_dep_time &lt;int&gt;, dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, â€¦\n\nInstead weâ€™ll need a new tool: is.na().\nå› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ–°å·¥å…·ï¼šis.na()ã€‚\n\n12.2.3 is.na()\n\nis.na(x) works with any type of vector and returns TRUE for missing values and FALSE for everything else:is.na(x) é€‚ç”¨äºä»»ä½•ç±»å‹çš„å‘é‡ï¼Œå¯¹äºç¼ºå¤±å€¼è¿”å› TRUEï¼Œå¯¹äºå…¶ä»–æ‰€æœ‰å€¼è¿”å› FALSEï¼š\n\nis.na(c(TRUE, NA, FALSE))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(1, NA, 3))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(\"a\", NA, \"b\"))\n#&gt; [1] FALSE  TRUE FALSE\n\nWe can use is.na() to find all the rows with a missing dep_time:\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨ is.na() æ¥æŸ¥æ‰¾æ‰€æœ‰ dep_time ç¼ºå¤±çš„è¡Œï¼š\n\nflights |&gt; \n  filter(is.na(dep_time))\n#&gt; # A tibble: 8,255 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     2       NA           1540        NA       NA           1747\n#&gt; 6  2013     1     2       NA           1620        NA       NA           1746\n#&gt; # â„¹ 8,249 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nis.na() can also be useful in arrange(). arrange() usually puts all the missing values at the end but you can override this default by first sorting by is.na():is.na() åœ¨ arrange() ä¸­ä¹Ÿå¾ˆæœ‰ç”¨ã€‚arrange() é€šå¸¸ä¼šå°†æ‰€æœ‰ç¼ºå¤±å€¼æ”¾åœ¨æœ«å°¾ï¼Œä½†ä½ å¯ä»¥é€šè¿‡å…ˆæŒ‰ is.na() æ’åºæ¥è¦†ç›–è¿™ä¸ªé»˜è®¤è¡Œä¸ºï¼š\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(dep_time)\n#&gt; # A tibble: 842 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 836 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(desc(is.na(dep_time)), dep_time)\n#&gt; # A tibble: 842 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     1      517            515         2      830            819\n#&gt; 6  2013     1     1      533            529         4      850            830\n#&gt; # â„¹ 836 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nWeâ€™ll come back to cover missing values in more depth in Chapter 18.\næˆ‘ä»¬å°†åœ¨ Chapter 18 ä¸­æ›´æ·±å…¥åœ°è®¨è®ºç¼ºå¤±å€¼ã€‚\n\n12.2.4 Exercises\n\nHow does dplyr::near() work? Type near to see the source code. Is sqrt(2)^2 near 2?\nUse mutate(), is.na(), and count() together to describe how the missing values in dep_time, sched_dep_time and dep_delay are connected.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "logicals.html#boolean-algebra",
    "href": "logicals.html#boolean-algebra",
    "title": "12Â  Logical vectors",
    "section": "\n12.3 Boolean algebra",
    "text": "12.3 Boolean algebra\nOnce you have multiple logical vectors, you can combine them together using Boolean algebra. In R, & is â€œandâ€, | is â€œorâ€, ! is â€œnotâ€, and xor() is exclusive or2. For example, df |&gt; filter(!is.na(x)) finds all rows where x is not missing and df |&gt; filter(x &lt; -10 | x &gt; 0) finds all rows where x is smaller than -10 or bigger than 0. FigureÂ 12.1 shows the complete set of Boolean operations and how they work.\nä¸€æ—¦ä½ æœ‰äº†å¤šä¸ªé€»è¾‘å‘é‡ï¼Œå°±å¯ä»¥ä½¿ç”¨å¸ƒå°”ä»£æ•°å°†å®ƒä»¬ç»„åˆèµ·æ¥ã€‚åœ¨ R ä¸­ï¼Œ& æ˜¯â€œä¸â€ï¼Œ| æ˜¯â€œæˆ–â€ï¼Œ! æ˜¯â€œéâ€ï¼Œè€Œ xor() æ˜¯å¼‚æˆ–ï¼ˆexclusive orï¼‰1ã€‚ä¾‹å¦‚ï¼Œdf |&gt; filter(!is.na(x)) ä¼šæ‰¾åˆ°æ‰€æœ‰ x ä¸ç¼ºå¤±çš„è¡Œï¼Œè€Œ df |&gt; filter(x &lt; -10 | x &gt; 0) ä¼šæ‰¾åˆ°æ‰€æœ‰ x å°äº -10 æˆ–å¤§äº 0 çš„è¡Œã€‚FigureÂ 12.1 å±•ç¤ºäº†å®Œæ•´çš„å¸ƒå°”è¿ç®—é›†åŠå…¶å·¥ä½œåŸç†ã€‚\n\n\n\n\n\n\n\nFigureÂ 12.1: The complete set of Boolean operations. x is the left-hand circle, y is the right-hand circle, and the shaded regions show which parts each operator selects.\n\n\n\n\nAs well as & and |, R also has && and ||. Donâ€™t use them in dplyr functions! These are called short-circuiting operators and only ever return a single TRUE or FALSE. Theyâ€™re important for programming, not data science.\né™¤äº† & å’Œ |ï¼ŒR è¿˜æœ‰ && å’Œ ||ã€‚ä¸è¦åœ¨ dplyr å‡½æ•°ä¸­ä½¿ç”¨å®ƒä»¬ï¼è¿™äº›è¢«ç§°ä¸ºçŸ­è·¯è¿ç®—ç¬¦ï¼Œå®ƒä»¬åªè¿”å›å•ä¸ªçš„ TRUE æˆ– FALSEã€‚å®ƒä»¬å¯¹äºç¼–ç¨‹å¾ˆé‡è¦ï¼Œè€Œä¸æ˜¯æ•°æ®ç§‘å­¦ã€‚\n\n12.3.1 Missing values\nThe rules for missing values in Boolean algebra are a little tricky to explain because they seem inconsistent at first glance:\nå¸ƒå°”ä»£æ•°ä¸­å…³äºç¼ºå¤±å€¼çš„è§„åˆ™æœ‰ç‚¹éš¾ä»¥è§£é‡Šï¼Œå› ä¸ºå®ƒä»¬ä¹ä¸€çœ‹ä¼¼ä¹ä¸ä¸€è‡´ï¼š\n\ndf &lt;- tibble(x = c(TRUE, FALSE, NA))\n\ndf |&gt; \n  mutate(\n    and = x & NA,\n    or = x | NA\n  )\n#&gt; # A tibble: 3 Ã— 3\n#&gt;   x     and   or   \n#&gt;   &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 TRUE  NA    TRUE \n#&gt; 2 FALSE FALSE NA   \n#&gt; 3 NA    NA    NA\n\nTo understand whatâ€™s going on, think about NA | TRUE (NA or TRUE). A missing value in a logical vector means that the value could either be TRUE or FALSE. TRUE | TRUE and FALSE | TRUE are both TRUE because at least one of them is TRUE. NA | TRUE must also be TRUE because NA can either be TRUE or FALSE. However, NA | FALSE is NA because we donâ€™t know if NA is TRUE or FALSE. Similar reasoning applies for & considering that both conditions must be fulfilled. Therefore NA & TRUE is NA because NA can either be TRUE or FALSE and NA & FALSE is FALSE because at least one of the conditions is FALSE.\nè¦ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆï¼Œå¯ä»¥æ€è€ƒä¸€ä¸‹ NA | TRUEï¼ˆNA æˆ– TRUEï¼‰ã€‚é€»è¾‘å‘é‡ä¸­çš„ç¼ºå¤±å€¼æ„å‘³ç€è¯¥å€¼å¯èƒ½æ˜¯ TRUE æˆ– FALSEã€‚TRUE | TRUE å’Œ FALSE | TRUE éƒ½æ˜¯ TRUEï¼Œå› ä¸ºå…¶ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ˜¯ TRUEã€‚NA | TRUE ä¹Ÿå¿…é¡»æ˜¯ TRUEï¼Œå› ä¸º NA å¯èƒ½æ˜¯ TRUE æˆ– FALSEã€‚ç„¶è€Œï¼ŒNA | FALSE çš„ç»“æœæ˜¯ NAï¼Œå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“ NA æ˜¯ TRUE è¿˜æ˜¯ FALSEã€‚ç±»ä¼¼çš„æ¨ç†ä¹Ÿé€‚ç”¨äº &ï¼Œè€ƒè™‘åˆ°ä¸¤ä¸ªæ¡ä»¶éƒ½å¿…é¡»æ»¡è¶³ã€‚å› æ­¤ï¼ŒNA & TRUE çš„ç»“æœæ˜¯ NAï¼Œå› ä¸º NA å¯èƒ½æ˜¯ TRUE æˆ– FALSEï¼›è€Œ NA & FALSE çš„ç»“æœæ˜¯ FALSEï¼Œå› ä¸ºè‡³å°‘æœ‰ä¸€ä¸ªæ¡ä»¶æ˜¯ FALSEã€‚\n\n12.3.2 Order of operations\nNote that the order of operations doesnâ€™t work like English. Take the following code that finds all flights that departed in November or December:\næ³¨æ„ï¼Œè¿ç®—é¡ºåºä¸åƒè‹±è¯­é‚£æ ·ã€‚çœ‹ä¸‹é¢è¿™æ®µæŸ¥æ‰¾æ‰€æœ‰åœ¨ 11 æœˆæˆ– 12 æœˆèµ·é£çš„èˆªç­çš„ä»£ç ï¼š\n\nflights |&gt; \n  filter(month == 11 | month == 12)\n\nYou might be tempted to write it like youâ€™d say in English: â€œFind all flights that departed in November or December.â€:\nä½ å¯èƒ½ä¼šæƒ³å½“ç„¶åœ°åƒç”¨è‹±è¯­è¯´çš„é‚£æ ·å†™ï¼šâ€œæŸ¥æ‰¾æ‰€æœ‰åœ¨ 11 æœˆæˆ– 12 æœˆèµ·é£çš„èˆªç­ã€‚â€ï¼š\n\nflights |&gt; \n  filter(month == 11 | 12)\n#&gt; # A tibble: 336,776 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nThis code doesnâ€™t error but it also doesnâ€™t seem to have worked. Whatâ€™s going on? Here, R first evaluates month == 11 creating a logical vector, which we call nov. It computes nov | 12. When you use a number with a logical operator it converts everything apart from 0 to TRUE, so this is equivalent to nov | TRUE which will always be TRUE, so every row will be selected:\nè¿™æ®µä»£ç æ²¡æœ‰æŠ¥é”™ï¼Œä½†ä¼¼ä¹ä¹Ÿæ²¡æœ‰èµ·ä½œç”¨ã€‚è¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿåœ¨è¿™é‡Œï¼ŒR é¦–å…ˆè¯„ä¼° month == 11ï¼Œåˆ›å»ºäº†ä¸€ä¸ªæˆ‘ä»¬ç§°ä¹‹ä¸º nov çš„é€»è¾‘å‘é‡ã€‚ç„¶åå®ƒè®¡ç®— nov | 12ã€‚å½“ä½ å°†æ•°å­—ä¸é€»è¾‘è¿ç®—ç¬¦ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œé™¤äº† 0 ä¹‹å¤–çš„æ‰€æœ‰æ•°å­—éƒ½ä¼šè¢«è½¬æ¢ä¸º TRUEï¼Œæ‰€ä»¥è¿™ç­‰ä»·äº nov | TRUEï¼Œç»“æœå°†æ°¸è¿œæ˜¯ TRUEï¼Œå› æ­¤æ‰€æœ‰è¡Œéƒ½ä¼šè¢«é€‰ä¸­ï¼š\n\nflights |&gt; \n  mutate(\n    nov = month == 11,\n    final = nov | 12,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 Ã— 3\n#&gt;   month nov   final\n#&gt;   &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1     1 FALSE TRUE \n#&gt; 2     1 FALSE TRUE \n#&gt; 3     1 FALSE TRUE \n#&gt; 4     1 FALSE TRUE \n#&gt; 5     1 FALSE TRUE \n#&gt; 6     1 FALSE TRUE \n#&gt; # â„¹ 336,770 more rows\n\n\n12.3.3 %in%\n\nAn easy way to avoid the problem of getting your ==s and |s in the right order is to use %in%. x %in% y returns a logical vector the same length as x that is TRUE whenever a value in x is anywhere in y .\nä¸€ä¸ªé¿å… == å’Œ | æ’åºé—®é¢˜çš„ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨ %in%ã€‚x %in% y ä¼šè¿”å›ä¸€ä¸ªä¸ x é•¿åº¦ç›¸åŒçš„é€»è¾‘å‘é‡ï¼Œå½“ x ä¸­çš„å€¼å­˜åœ¨äº y ä¸­ä»»ä½•ä½ç½®æ—¶ï¼Œè¯¥å‘é‡å¯¹åº”å…ƒç´ ä¸º TRUEã€‚\n\n1:12 %in% c(1, 5, 11)\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\nletters[1:10] %in% c(\"a\", \"e\", \"i\", \"o\", \"u\")\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n\nSo to find all flights in November and December we could write:\næ‰€ä»¥è¦æŸ¥æ‰¾æ‰€æœ‰åœ¨åä¸€æœˆå’ŒåäºŒæœˆçš„èˆªç­ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·å†™ï¼š\n\nflights |&gt; \n  filter(month %in% c(11, 12))\n\nNote that %in% obeys different rules for NA to ==, as NA %in% NA is TRUE.\næ³¨æ„ï¼Œå¯¹äº NAï¼Œ%in% éµå¾ªä¸ == ä¸åŒçš„è§„åˆ™ï¼Œå› ä¸º NA %in% NA çš„ç»“æœæ˜¯ TRUEã€‚\n\nc(1, 2, NA) == NA\n#&gt; [1] NA NA NA\nc(1, 2, NA) %in% NA\n#&gt; [1] FALSE FALSE  TRUE\n\nThis can make for a useful shortcut:\nè¿™å¯ä»¥æˆä¸ºä¸€ä¸ªæœ‰ç”¨çš„å¿«æ·æ–¹å¼ï¼š\n\nflights |&gt; \n  filter(dep_time %in% c(NA, 0800))\n#&gt; # A tibble: 8,803 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      800            800         0     1022           1014\n#&gt; 2  2013     1     1      800            810       -10      949            955\n#&gt; 3  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 4  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 5  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 6  2013     1     1       NA            600        NA       NA            901\n#&gt; # â„¹ 8,797 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\n\n12.3.4 Exercises\n\nFind all flights where arr_delay is missing but dep_delay is not. Find all flights where neither arr_time nor sched_arr_time are missing, but arr_delay is.\nHow many flights have a missing dep_time? What other variables are missing in these rows? What might these rows represent?\nAssuming that a missing dep_time implies that a flight is cancelled, look at the number of cancelled flights per day. Is there a pattern? Is there a connection between the proportion of cancelled flights and the average delay of non-cancelled flights?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "logicals.html#sec-logical-summaries",
    "href": "logicals.html#sec-logical-summaries",
    "title": "12Â  Logical vectors",
    "section": "\n12.4 Summaries",
    "text": "12.4 Summaries\nThe following sections describe some useful techniques for summarizing logical vectors. As well as functions that only work specifically with logical vectors, you can also use functions that work with numeric vectors.\nä»¥ä¸‹å„èŠ‚ä»‹ç»äº†ä¸€äº›æ±‡æ€»é€»è¾‘å‘é‡çš„æœ‰ç”¨æŠ€å·§ã€‚é™¤äº†ä¸“é—¨å¤„ç†é€»è¾‘å‘é‡çš„å‡½æ•°å¤–ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨å¤„ç†æ•°å€¼å‘é‡çš„å‡½æ•°ã€‚\n\n12.4.1 Logical summaries\nThere are two main logical summaries: any() and all(). any(x) is the equivalent of |; itâ€™ll return TRUE if there are any TRUEâ€™s in x. all(x) is equivalent of &; itâ€™ll return TRUE only if all values of x are TRUEâ€™s. Like most summary functions, you can make the missing values go away with na.rm = TRUE.\næœ‰ä¸¤ä¸ªä¸»è¦çš„é€»è¾‘æ±‡æ€»å‡½æ•°ï¼šany() å’Œ all()ã€‚any(x) ç›¸å½“äº |ï¼›å¦‚æœ x ä¸­æœ‰ä»»ä½•ä¸€ä¸ª TRUEï¼Œå®ƒå°±ä¼šè¿”å› TRUEã€‚all(x) ç›¸å½“äº &ï¼›åªæœ‰å½“ x çš„æ‰€æœ‰å€¼éƒ½ä¸º TRUE æ—¶ï¼Œå®ƒæ‰ä¼šè¿”å› TRUEã€‚å’Œå¤§å¤šæ•°æ±‡æ€»å‡½æ•°ä¸€æ ·ï¼Œä½ å¯ä»¥é€šè¿‡ na.rm = TRUE æ¥ç§»é™¤ç¼ºå¤±å€¼ã€‚\nFor example, we could use all() and any() to find out if every flight was delayed on departure by at most an hour or if any flights were delayed on arrival by five hours or more. And using group_by() allows us to do that by day:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ all() å’Œ any() æ¥æŸ¥æ˜æ˜¯å¦æ¯æ¶èˆªç­çš„èµ·é£å»¶è¯¯éƒ½ä¸è¶…è¿‡ä¸€å°æ—¶ï¼Œæˆ–è€…æ˜¯å¦æœ‰ä»»ä½•èˆªç­çš„åˆ°è¾¾å»¶è¯¯è¾¾åˆ°äº”å°æ—¶æˆ–æ›´é•¿ã€‚å¹¶ä¸”ä½¿ç”¨ group_by() å…è®¸æˆ‘ä»¬æŒ‰å¤©æ¥åšè¿™ä¸ªåˆ†æï¼š\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    all_delayed = all(dep_delay &lt;= 60, na.rm = TRUE),\n    any_long_delay = any(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 Ã— 5\n#&gt;    year month   day all_delayed any_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;       &lt;lgl&gt;         \n#&gt; 1  2013     1     1 FALSE       TRUE          \n#&gt; 2  2013     1     2 FALSE       TRUE          \n#&gt; 3  2013     1     3 FALSE       FALSE         \n#&gt; 4  2013     1     4 FALSE       FALSE         \n#&gt; 5  2013     1     5 FALSE       TRUE          \n#&gt; 6  2013     1     6 FALSE       FALSE         \n#&gt; # â„¹ 359 more rows\n\nIn most cases, however, any() and all() are a little too crude, and it would be nice to be able to get a little more detail about how many values are TRUE or FALSE. That leads us to the numeric summaries.\nç„¶è€Œï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œany() å’Œ all() æœ‰ç‚¹è¿‡äºç²—ç•¥ï¼Œå¦‚æœèƒ½æ›´è¯¦ç»†åœ°äº†è§£æœ‰å¤šå°‘å€¼æ˜¯ TRUE æˆ– FALSE ä¼šæ›´å¥½ã€‚è¿™å°±å¼•å‡ºäº†æ•°å€¼æ±‡æ€»ã€‚\n\n12.4.2 Numeric summaries of logical vectors\nWhen you use a logical vector in a numeric context, TRUE becomes 1 and FALSE becomes 0. This makes sum() and mean() very useful with logical vectors because sum(x) gives the number of TRUEs and mean(x) gives the proportion of TRUEs (because mean() is just sum() divided by length()).\nå½“ä½ åœ¨æ•°å€¼ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨é€»è¾‘å‘é‡æ—¶ï¼ŒTRUE ä¼šå˜æˆ 1ï¼ŒFALSE ä¼šå˜æˆ 0ã€‚è¿™ä½¿å¾— sum() å’Œ mean() åœ¨å¤„ç†é€»è¾‘å‘é‡æ—¶éå¸¸æœ‰ç”¨ï¼Œå› ä¸º sum(x) ç»™å‡ºäº† TRUE çš„æ•°é‡ï¼Œè€Œ mean(x) ç»™å‡ºäº† TRUE çš„æ¯”ä¾‹ï¼ˆå› ä¸º mean() å°±æ˜¯ sum() é™¤ä»¥ length()ï¼‰ã€‚\nThat, for example, allows us to see the proportion of flights that were delayed on departure by at most an hour and the number of flights that were delayed on arrival by five hours or more:\nä¾‹å¦‚ï¼Œè¿™è®©æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹èµ·é£å»¶è¯¯æœ€å¤šä¸€å°æ—¶çš„èˆªç­æ¯”ä¾‹ï¼Œä»¥åŠåˆ°è¾¾å»¶è¯¯äº”å°æ—¶æˆ–ä»¥ä¸Šçš„èˆªç­æ•°é‡ï¼š\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    proportion_delayed = mean(dep_delay &lt;= 60, na.rm = TRUE),\n    count_long_delay = sum(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 Ã— 5\n#&gt;    year month   day proportion_delayed count_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;dbl&gt;            &lt;int&gt;\n#&gt; 1  2013     1     1              0.939                3\n#&gt; 2  2013     1     2              0.914                3\n#&gt; 3  2013     1     3              0.941                0\n#&gt; 4  2013     1     4              0.953                0\n#&gt; 5  2013     1     5              0.964                1\n#&gt; 6  2013     1     6              0.959                0\n#&gt; # â„¹ 359 more rows\n\n\n12.4.3 Logical subsetting\nThereâ€™s one final use for logical vectors in summaries: you can use a logical vector to filter a single variable to a subset of interest. This makes use of the base [ (pronounced subset) operator, which youâ€™ll learn more about in Section 27.2.\nåœ¨æ±‡æ€»ä¸­ï¼Œé€»è¾‘å‘é‡è¿˜æœ‰ä¸€ä¸ªæœ€ç»ˆç”¨é€”ï¼šä½ å¯ä»¥ä½¿ç”¨é€»è¾‘å‘é‡å°†å•ä¸ªå˜é‡ç­›é€‰åˆ°æ„Ÿå…´è¶£çš„å­é›†ã€‚è¿™åˆ©ç”¨äº† R base çš„ [ï¼ˆå‘éŸ³ä¸º subsetï¼‰è¿ç®—ç¬¦ï¼Œä½ å°†åœ¨ Section 27.2 ä¸­å­¦åˆ°æ›´å¤šç›¸å…³å†…å®¹ã€‚\nImagine we wanted to look at the average delay just for flights that were actually delayed. One way to do so would be to first filter the flights and then calculate the average delay:\nå‡è®¾æˆ‘ä»¬åªæƒ³çœ‹å®é™…å»¶è¯¯èˆªç­çš„å¹³å‡å»¶è¯¯æ—¶é—´ã€‚ä¸€ç§æ–¹æ³•æ˜¯å…ˆç­›é€‰å‡ºè¿™äº›èˆªç­ï¼Œç„¶åè®¡ç®—å¹³å‡å»¶è¯¯æ—¶é—´ï¼š\n\nflights |&gt; \n  filter(arr_delay &gt; 0) |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 Ã— 5\n#&gt;    year month   day behind     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5   461\n#&gt; 2  2013     1     2   32.0   535\n#&gt; 3  2013     1     3   27.7   460\n#&gt; 4  2013     1     4   28.3   297\n#&gt; 5  2013     1     5   22.6   238\n#&gt; 6  2013     1     6   24.4   381\n#&gt; # â„¹ 359 more rows\n\nThis works, but what if we wanted to also compute the average delay for flights that arrived early? Weâ€™d need to perform a separate filter step, and then figure out how to combine the two data frames together3. Instead you could use [ to perform an inline filtering: arr_delay[arr_delay &gt; 0] will yield only the positive arrival delays.\nè¿™æ ·åšæ˜¯å¯è¡Œçš„ï¼Œä½†å¦‚æœæˆ‘ä»¬è¿˜æƒ³è®¡ç®—ææ—©åˆ°è¾¾èˆªç­çš„å¹³å‡å»¶è¯¯æ—¶é—´å‘¢ï¼Ÿæˆ‘ä»¬å°±éœ€è¦æ‰§è¡Œä¸€ä¸ªå•ç‹¬çš„ç­›é€‰æ­¥éª¤ï¼Œç„¶åæƒ³åŠæ³•å°†ä¸¤ä¸ªæ•°æ®æ¡†åˆå¹¶åœ¨ä¸€èµ·3ã€‚ç›¸åï¼Œä½ å¯ä»¥ä½¿ç”¨ [ æ¥æ‰§è¡Œå†…è”ç­›é€‰ï¼šarr_delay[arr_delay &gt; 0] å°†åªäº§ç”Ÿæ­£çš„åˆ°è¾¾å»¶è¯¯æ—¶é—´ã€‚\nThis leads to:\nè¿™ä¼šå¾—åˆ°ï¼š\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay[arr_delay &gt; 0], na.rm = TRUE),\n    ahead = mean(arr_delay[arr_delay &lt; 0], na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 Ã— 6\n#&gt;    year month   day behind ahead     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5 -12.5   842\n#&gt; 2  2013     1     2   32.0 -14.3   943\n#&gt; 3  2013     1     3   27.7 -18.2   914\n#&gt; 4  2013     1     4   28.3 -17.0   915\n#&gt; 5  2013     1     5   22.6 -14.0   720\n#&gt; 6  2013     1     6   24.4 -13.6   832\n#&gt; # â„¹ 359 more rows\n\nAlso note the difference in the group size: in the first chunk n() gives the number of delayed flights per day; in the second, n() gives the total number of flights.\nåŒæ—¶æ³¨æ„ç»„å¤§å°çš„å·®å¼‚ï¼šåœ¨ç¬¬ä¸€ä¸ªä»£ç å—ä¸­ï¼Œn() ç»™å‡ºçš„æ˜¯æ¯å¤©å»¶è¯¯çš„èˆªç­æ•°é‡ï¼›åœ¨ç¬¬äºŒä¸ªä»£ç å—ä¸­ï¼Œn() ç»™å‡ºçš„æ˜¯æ€»èˆªç­æ•°é‡ã€‚\n\n12.4.4 Exercises\n\nWhat will sum(is.na(x)) tell you? How about mean(is.na(x))?\nWhat does prod() return when applied to a logical vector? What logical summary function is it equivalent to? What does min() return when applied to a logical vector? What logical summary function is it equivalent to? Read the documentation and perform a few experiments.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "logicals.html#conditional-transformations",
    "href": "logicals.html#conditional-transformations",
    "title": "12Â  Logical vectors",
    "section": "\n12.5 Conditional transformations",
    "text": "12.5 Conditional transformations\nOne of the most powerful features of logical vectors are their use for conditional transformations, i.e.Â doing one thing for condition x, and something different for condition y. There are two important tools for this: if_else() and case_when().\né€»è¾‘å‘é‡æœ€å¼ºå¤§çš„ç‰¹æ€§ä¹‹ä¸€æ˜¯å®ƒä»¬åœ¨æ¡ä»¶è½¬æ¢ä¸­çš„åº”ç”¨ï¼Œå³é’ˆå¯¹æ¡ä»¶ x åšä¸€ä»¶äº‹ï¼Œé’ˆå¯¹æ¡ä»¶ y åšå¦ä¸€ä»¶äº‹ã€‚æœ‰ä¸¤ä¸ªé‡è¦çš„å·¥å…·å¯ä»¥å®ç°è¿™ä¸€ç‚¹ï¼šif_else() å’Œ case_when()ã€‚\n\n12.5.1 if_else()\n\nIf you want to use one value when a condition is TRUE and another value when itâ€™s FALSE, you can use dplyr::if_else()4. Youâ€™ll always use the first three argument of if_else(). The first argument, condition, is a logical vector, the second, true, gives the output when the condition is true, and the third, false, gives the output if the condition is false.\nå¦‚æœä½ æƒ³åœ¨æ¡ä»¶ä¸º TRUE æ—¶ä½¿ç”¨ä¸€ä¸ªå€¼ï¼Œè€Œåœ¨æ¡ä»¶ä¸º FALSE æ—¶ä½¿ç”¨å¦ä¸€ä¸ªå€¼ï¼Œä½ å¯ä»¥ä½¿ç”¨ dplyr::if_else()4ã€‚ä½ æ€»æ˜¯ä¼šä½¿ç”¨ if_else() çš„å‰ä¸‰ä¸ªå‚æ•°ã€‚ç¬¬ä¸€ä¸ªå‚æ•° condition æ˜¯ä¸€ä¸ªé€»è¾‘å‘é‡ï¼Œç¬¬äºŒä¸ªå‚æ•° true ç»™å‡ºæ¡ä»¶ä¸ºçœŸæ—¶çš„è¾“å‡ºï¼Œç¬¬ä¸‰ä¸ªå‚æ•° false ç»™å‡ºæ¡ä»¶ä¸ºå‡æ—¶çš„è¾“å‡ºã€‚\nLetâ€™s begin with a simple example of labeling a numeric vector as either â€œ+veâ€ (positive) or â€œ-veâ€ (negative):\nè®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å¼€å§‹ï¼Œå°†ä¸€ä¸ªæ•°å€¼å‘é‡æ ‡è®°ä¸ºâ€œ+veâ€ï¼ˆæ­£æ•°ï¼‰æˆ–â€œ-veâ€ï¼ˆè´Ÿæ•°ï¼‰ï¼š\n\nx &lt;- c(-3:3, NA)\nif_else(x &gt; 0, \"+ve\", \"-ve\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" NA\n\nThereâ€™s an optional fourth argument, missing which will be used if the input is NA:\nè¿˜æœ‰ä¸€ä¸ªå¯é€‰çš„ç¬¬å››ä¸ªå‚æ•° missingï¼Œå½“è¾“å…¥ä¸º NA æ—¶ä¼šä½¿ç”¨è¿™ä¸ªå‚æ•°ï¼š\n\nif_else(x &gt; 0, \"+ve\", \"-ve\", \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nYou can also use vectors for the true and false arguments. For example, this allows us to create a minimal implementation of abs():\nä½ ä¹Ÿå¯ä»¥ä¸º true å’Œ false å‚æ•°ä½¿ç”¨å‘é‡ã€‚ä¾‹å¦‚ï¼Œè¿™å…è®¸æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª abs() çš„æœ€å°åŒ–å®ç°ï¼š\n\nif_else(x &lt; 0, -x, x)\n#&gt; [1]  3  2  1  0  1  2  3 NA\n\nSo far all the arguments have used the same vectors, but you can of course mix and match. For example, you could implement a simple version of coalesce() like this:\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ‰€æœ‰çš„å‚æ•°éƒ½ä½¿ç”¨äº†ç›¸åŒçš„å‘é‡ï¼Œä½†ä½ å½“ç„¶å¯ä»¥æ··åˆæ­é…ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥åƒè¿™æ ·å®ç°ä¸€ä¸ª coalesce() çš„ç®€å•ç‰ˆæœ¬ï¼š\n\nx1 &lt;- c(NA, 1, 2, NA)\ny1 &lt;- c(3, NA, 4, 6)\nif_else(is.na(x1), y1, x1)\n#&gt; [1] 3 1 2 6\n\nYou might have noticed a small infelicity in our labeling example above: zero is neither positive nor negative. We could resolve this by adding an additional if_else():\nä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°æˆ‘ä»¬ä¸Šé¢æ ‡ç­¾ç¤ºä¾‹ä¸­çš„ä¸€ä¸ªå°ç‘•ç–µï¼šé›¶æ—¢ä¸æ˜¯æ­£æ•°ä¹Ÿä¸æ˜¯è´Ÿæ•°ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ·»åŠ ä¸€ä¸ªé¢å¤–çš„ if_else() æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š\n\nif_else(x == 0, \"0\", if_else(x &lt; 0, \"-ve\", \"+ve\"), \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nThis is already a little hard to read, and you can imagine it would only get harder if you have more conditions. Instead, you can switch to dplyr::case_when().\nè¿™å·²ç»æœ‰ç‚¹éš¾è¯»äº†ï¼Œä½ å¯ä»¥æƒ³è±¡ï¼Œå¦‚æœä½ æœ‰æ›´å¤šçš„æ¡ä»¶ï¼Œæƒ…å†µåªä¼šå˜å¾—æ›´ç³Ÿã€‚å› æ­¤ï¼Œä½ å¯ä»¥è½¬è€Œä½¿ç”¨ dplyr::case_when()ã€‚\n\n12.5.2 case_when()\n\ndplyrâ€™s case_when() is inspired by SQLâ€™s CASE statement and provides a flexible way of performing different computations for different conditions. It has a special syntax that unfortunately looks like nothing else youâ€™ll use in the tidyverse. It takes pairs that look like condition ~ output. condition must be a logical vector; when itâ€™s TRUE, output will be used.\ndplyr çš„ case_when() å—åˆ° SQL çš„ CASE è¯­å¥çš„å¯å‘ï¼Œæä¾›äº†ä¸€ç§ä¸ºä¸åŒæ¡ä»¶æ‰§è¡Œä¸åŒè®¡ç®—çš„çµæ´»æ–¹å¼ã€‚å®ƒæœ‰ä¸€ç§ç‰¹æ®Šçš„è¯­æ³•ï¼Œä¸å¹¸çš„æ˜¯ï¼Œè¿™ä¸ä½ åœ¨ tidyverse ä¸­ä½¿ç”¨çš„å…¶ä»–ä»»ä½•ä¸œè¥¿éƒ½ä¸ä¸€æ ·ã€‚å®ƒæ¥å—å½¢å¦‚ condition ~ output çš„é…å¯¹ã€‚condition å¿…é¡»æ˜¯ä¸€ä¸ªé€»è¾‘å‘é‡ï¼›å½“å®ƒä¸º TRUE æ—¶ï¼Œå°†ä½¿ç”¨ outputã€‚\nThis means we could recreate our previous nested if_else() as follows:\nè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åƒä¸‹é¢è¿™æ ·é‡æ–°åˆ›å»ºæˆ‘ä»¬ä¹‹å‰çš„åµŒå¥— if_else()ï¼š\n\nx &lt;- c(-3:3, NA)\ncase_when(\n  x == 0   ~ \"0\",\n  x &lt; 0    ~ \"-ve\", \n  x &gt; 0    ~ \"+ve\",\n  is.na(x) ~ \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nThis is more code, but itâ€™s also more explicit.\nè¿™éœ€è¦æ›´å¤šçš„ä»£ç ï¼Œä½†å®ƒä¹Ÿæ›´æ˜ç¡®ã€‚\nTo explain how case_when() works, letâ€™s explore some simpler cases. If none of the cases match, the output gets an NA:\nä¸ºäº†è§£é‡Š case_when() çš„å·¥ä½œåŸç†ï¼Œè®©æˆ‘ä»¬æ¢è®¨ä¸€äº›æ›´ç®€å•çš„æƒ…å†µã€‚å¦‚æœæ²¡æœ‰ä¸€ä¸ªæ¡ä»¶åŒ¹é…ï¼Œè¾“å‡ºå°†å¾—åˆ°ä¸€ä¸ª NAï¼š\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" NA    \"+ve\" \"+ve\" \"+ve\" NA\n\nUse .default if you want to create a â€œdefaultâ€/catch all value:\nå¦‚æœä½ æƒ³åˆ›å»ºä¸€ä¸ªâ€œé»˜è®¤â€æˆ–â€œåŒ…ç½—ä¸‡è±¡â€çš„å€¼ï¼Œè¯·ä½¿ç”¨ .defaultï¼š\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\",\n  .default = \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"???\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nAnd note that if multiple conditions match, only the first will be used:\nå¹¶ä¸”è¯·æ³¨æ„ï¼Œå¦‚æœå¤šä¸ªæ¡ä»¶åŒ¹é…ï¼Œåªæœ‰ç¬¬ä¸€ä¸ªä¼šè¢«ä½¿ç”¨ï¼š\n\ncase_when(\n  x &gt; 0 ~ \"+ve\",\n  x &gt; 2 ~ \"big\"\n)\n#&gt; [1] NA    NA    NA    NA    \"+ve\" \"+ve\" \"+ve\" NA\n\nJust like with if_else() you can use variables on both sides of the ~ and you can mix and match variables as needed for your problem. For example, we could use case_when() to provide some human readable labels for the arrival delay:\nå°±åƒ if_else() ä¸€æ ·ï¼Œä½ å¯ä»¥åœ¨ ~ çš„ä¸¤è¾¹ä½¿ç”¨å˜é‡ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®ä½ çš„é—®é¢˜éœ€è¦æ··åˆå’ŒåŒ¹é…å˜é‡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ case_when() ä¸ºåˆ°è¾¾å»¶è¿Ÿæä¾›ä¸€äº›äººç±»å¯è¯»çš„æ ‡ç­¾ï¼š\n\nflights |&gt; \n  mutate(\n    status = case_when(\n      is.na(arr_delay)     ~ \"cancelled\",\n      arr_delay &lt; -30      ~ \"very early\",\n      arr_delay &lt; -15      ~ \"early\",\n      abs(arr_delay) &lt;= 15 ~ \"on time\",\n      arr_delay &lt; 60       ~ \"late\",\n      arr_delay &lt; Inf      ~ \"very late\",\n    ),\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 Ã— 2\n#&gt;   arr_delay status \n#&gt;       &lt;dbl&gt; &lt;chr&gt;  \n#&gt; 1        11 on time\n#&gt; 2        20 late   \n#&gt; 3        33 late   \n#&gt; 4       -18 early  \n#&gt; 5       -25 early  \n#&gt; 6        12 on time\n#&gt; # â„¹ 336,770 more rows\n\nBe wary when writing this sort of complex case_when() statement; my first two attempts used a mix of &lt; and &gt; and I kept accidentally creating overlapping conditions.\nåœ¨ç¼–å†™è¿™ç±»å¤æ‚çš„ case_when() è¯­å¥æ—¶è¦å°å¿ƒï¼›æˆ‘æœ€åˆçš„ä¸¤æ¬¡å°è¯•æ··åˆä½¿ç”¨äº† &lt; å’Œ &gt;ï¼Œç»“æœä¸å°å¿ƒåˆ›å»ºäº†é‡å çš„æ¡ä»¶ã€‚\n\n12.5.3 Compatible types\nNote that both if_else() and case_when() require compatible types in the output. If theyâ€™re not compatible, youâ€™ll see errors like this:\nè¯·æ³¨æ„ï¼Œif_else() å’Œ case_when() éƒ½è¦æ±‚è¾“å‡ºä¸­çš„ç±»å‹æ˜¯å…¼å®¹çš„ã€‚å¦‚æœå®ƒä»¬ä¸å…¼å®¹ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„é”™è¯¯ï¼š\n\nif_else(TRUE, \"a\", 1)\n#&gt; Error in `if_else()`:\n#&gt; ! Can't combine `true` &lt;character&gt; and `false` &lt;double&gt;.\n\ncase_when(\n  x &lt; -1 ~ TRUE,  \n  x &gt; 0  ~ now()\n)\n#&gt; Error in `case_when()`:\n#&gt; ! Can't combine `..1 (right)` &lt;logical&gt; and `..2 (right)` &lt;datetime&lt;local&gt;&gt;.\n\nOverall, relatively few types are compatible, because automatically converting one type of vector to another is a common source of errors. Here are the most important cases that are compatible:\næ€»çš„æ¥è¯´ï¼Œç›¸å¯¹è¾ƒå°‘çš„ç±»å‹æ˜¯å…¼å®¹çš„ï¼Œå› ä¸ºè‡ªåŠ¨å°†ä¸€ç§ç±»å‹çš„å‘é‡è½¬æ¢ä¸ºå¦ä¸€ç§ç±»å‹æ˜¯é”™è¯¯çš„å¸¸è§æ¥æºã€‚ä»¥ä¸‹æ˜¯å…¼å®¹çš„æœ€é‡è¦æƒ…å†µï¼š\n\nNumeric and logical vectors are compatible, as we discussed in Section 12.4.2.\næ•°å€¼å‘é‡å’Œé€»è¾‘å‘é‡æ˜¯å…¼å®¹çš„ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ Section 12.4.2 ä¸­è®¨è®ºçš„é‚£æ ·ã€‚\nStrings and factors (Chapter 16) are compatible, because you can think of a factor as a string with a restricted set of values.\nå­—ç¬¦ä¸²å’Œå› å­ï¼ˆChapter 16ï¼‰æ˜¯å…¼å®¹çš„ï¼Œå› ä¸ºä½ å¯ä»¥æŠŠå› å­çœ‹ä½œæ˜¯ä¸€ç»„å—é™åˆ¶çš„å­—ç¬¦ä¸²ã€‚\nDates and date-times, which weâ€™ll discuss in Chapter 17, are compatible because you can think of a date as a special case of date-time.\næ—¥æœŸå’Œæ—¥æœŸæ—¶é—´ï¼ˆæˆ‘ä»¬å°†åœ¨ Chapter 17 ä¸­è®¨è®ºï¼‰æ˜¯å…¼å®¹çš„ï¼Œå› ä¸ºä½ å¯ä»¥æŠŠæ—¥æœŸçœ‹ä½œæ˜¯æ—¥æœŸæ—¶é—´çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µã€‚\nNA, which is technically a logical vector, is compatible with everything because every vector has some way of representing a missing value.NAï¼Œä¸¥æ ¼æ¥è¯´æ˜¯ä¸€ä¸ªé€»è¾‘å‘é‡ï¼Œå®ƒä¸æ‰€æœ‰ç±»å‹éƒ½å…¼å®¹ï¼Œå› ä¸ºæ¯ä¸ªå‘é‡éƒ½æœ‰è¡¨ç¤ºç¼ºå¤±å€¼çš„æ–¹å¼ã€‚\n\nWe donâ€™t expect you to memorize these rules, but they should become second nature over time because they are applied consistently throughout the tidyverse.\næˆ‘ä»¬ä¸æœŸæœ›ä½ è®°ä½è¿™äº›è§„åˆ™ï¼Œä½†éšç€æ—¶é—´çš„æ¨ç§»ï¼Œå®ƒä»¬åº”è¯¥ä¼šæˆä¸ºä½ çš„ç¬¬äºŒå¤©æ€§ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ•´ä¸ª tidyverse ä¸­éƒ½æ˜¯ä¸€è‡´åº”ç”¨çš„ã€‚\n\n12.5.4 Exercises\n\nA number is even if itâ€™s divisible by two, which in R you can find out with x %% 2 == 0. Use this fact and if_else() to determine whether each number between 0 and 20 is even or odd.\nGiven a vector of days like x &lt;- c(\"Monday\", \"Saturday\", \"Wednesday\"), use an if_else() statement to label them as weekends or weekdays.\nUse if_else() to compute the absolute value of a numeric vector called x.\nWrite a case_when() statement that uses the month and day columns from flights to label a selection of important US holidays (e.g., New Years Day, 4th of July, Thanksgiving, and Christmas). First create a logical column that is either TRUE or FALSE, and then create a character column that either gives the name of the holiday or is NA.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "logicals.html#summary",
    "href": "logicals.html#summary",
    "title": "12Â  Logical vectors",
    "section": "\n12.6 Summary",
    "text": "12.6 Summary\nThe definition of a logical vector is simple because each value must be either TRUE, FALSE, or NA. But logical vectors provide a huge amount of power. In this chapter, you learned how to create logical vectors with &gt;, &lt;, &lt;=, &gt;=, ==, !=, and is.na(), how to combine them with !, &, and |, and how to summarize them with any(), all(), sum(), and mean(). You also learned the powerful if_else() and case_when() functions that allow you to return values depending on the value of a logical vector.\né€»è¾‘å‘é‡çš„å®šä¹‰å¾ˆç®€å•ï¼Œå› ä¸ºæ¯ä¸ªå€¼å¿…é¡»æ˜¯ TRUEã€FALSE æˆ– NA ä¹‹ä¸€ã€‚ä½†é€»è¾‘å‘é‡æä¾›äº†å·¨å¤§çš„èƒ½åŠ›ã€‚åœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ &gt;ã€&lt;ã€&lt;=ã€&gt;=ã€==ã€!= å’Œ is.na() åˆ›å»ºé€»è¾‘å‘é‡ï¼Œå¦‚ä½•ä½¿ç”¨ !ã€& å’Œ | ç»„åˆå®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ any()ã€all()ã€sum() å’Œ mean() å¯¹å®ƒä»¬è¿›è¡Œæ±‡æ€»ã€‚ä½ è¿˜å­¦ä¹ äº†å¼ºå¤§çš„ if_else() å’Œ case_when() å‡½æ•°ï¼Œå®ƒä»¬å…è®¸ä½ æ ¹æ®é€»è¾‘å‘é‡çš„å€¼è¿”å›ä¸åŒçš„å€¼ã€‚\nWeâ€™ll see logical vectors again and again in the following chapters. For example in Chapter 14 youâ€™ll learn about str_detect(x, pattern) which returns a logical vector thatâ€™s TRUE for the elements of x that match the pattern, and in Chapter 17 youâ€™ll create logical vectors from the comparison of dates and times. But for now, weâ€™re going to move onto the next most important type of vector: numeric vectors.\nåœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†åå¤çœ‹åˆ°é€»è¾‘å‘é‡ã€‚ä¾‹å¦‚ï¼Œåœ¨ Chapter 14 ä¸­ï¼Œä½ å°†å­¦ä¹  str_detect(x, pattern)ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ªé€»è¾‘å‘é‡ï¼Œå¯¹äº x ä¸­åŒ¹é… pattern çš„å…ƒç´ ï¼Œè¯¥å‘é‡ä¸º TRUEï¼›åœ¨ Chapter 17 ä¸­ï¼Œä½ å°†é€šè¿‡æ¯”è¾ƒæ—¥æœŸå’Œæ—¶é—´æ¥åˆ›å»ºé€»è¾‘å‘é‡ã€‚ä½†ç°åœ¨ï¼Œæˆ‘ä»¬å°†è½¬å‘ä¸‹ä¸€ç§æœ€é‡è¦çš„å‘é‡ç±»å‹ï¼šæ•°å€¼å‘é‡ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "logicals.html#footnotes",
    "href": "logicals.html#footnotes",
    "title": "12Â  Logical vectors",
    "section": "",
    "text": "R normally calls print for you (i.e.Â x is a shortcut for print(x)), but calling it explicitly is useful if you want to provide other arguments.â†©ï¸\nThat is, xor(x, y) is true if x is true, or y is true, but not both. This is how we usually use â€œorâ€ In English. â€œBothâ€ is not usually an acceptable answer to the question â€œwould you like ice cream or cake?â€.â†©ï¸\nWeâ€™ll cover this in Chapter 19.â†©ï¸\ndplyrâ€™s if_else() is very similar to base Râ€™s ifelse(). There are two main advantages of if_else()over ifelse(): you can choose what should happen to missing values, and if_else() is much more likely to give you a meaningful error if your variables have incompatible types.â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Logical vectors</span>"
    ]
  },
  {
    "objectID": "numbers.html",
    "href": "numbers.html",
    "title": "13Â  Numbers",
    "section": "",
    "text": "13.1 Introduction\nNumeric vectors are the backbone of data science, and youâ€™ve already used them a bunch of times earlier in the book.\næ•°å€¼å‘é‡æ˜¯æ•°æ®ç§‘å­¦çš„æ”¯æŸ±ï¼Œä½ å·²ç»åœ¨æœ¬ä¹¦çš„å‰é¢éƒ¨åˆ†å¤šæ¬¡ä½¿ç”¨è¿‡å®ƒä»¬ã€‚\nNow itâ€™s time to systematically survey what you can do with them in R, ensuring that youâ€™re well situated to tackle any future problem involving numeric vectors.\nç°åœ¨æ˜¯æ—¶å€™ç³»ç»Ÿåœ°å®¡è§†ä¸€ä¸‹ä½ å¯ä»¥ç”¨ R å¯¹å®ƒä»¬åšä»€ä¹ˆï¼Œç¡®ä¿ä½ èƒ½å¤Ÿå¾ˆå¥½åœ°åº”å¯¹æœªæ¥ä»»ä½•æ¶‰åŠæ•°å€¼å‘é‡çš„é—®é¢˜ã€‚\nWeâ€™ll start by giving you a couple of tools to make numbers if you have strings, and then going into a little more detail of count().\næˆ‘ä»¬å°†ä»ä»‹ç»å‡ ä¸ªåœ¨ä½ æ‹¥æœ‰å­—ç¬¦ä¸²æ—¶ç”¨æ¥åˆ›å»ºæ•°å­—çš„å·¥å…·å¼€å§‹ï¼Œç„¶åæ›´è¯¦ç»†åœ°æ¢è®¨ count() å‡½æ•°ã€‚\nThen weâ€™ll dive into various numeric transformations that pair well with mutate(), including more general transformations that can be applied to other types of vectors, but are often used with numeric vectors.\næ¥ç€ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ä¸ mutate() æ­é…ä½¿ç”¨çš„å„ç§æ•°å€¼è½¬æ¢ï¼ŒåŒ…æ‹¬é‚£äº›å¯ä»¥åº”ç”¨äºå…¶ä»–ç±»å‹å‘é‡ï¼Œä½†å¸¸ç”¨äºæ•°å€¼å‘é‡çš„æ›´é€šç”¨çš„è½¬æ¢ã€‚\nWeâ€™ll finish off by covering the summary functions that pair well with summarize() and show you how they can also be used with mutate().\næœ€åï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸ summarize() æ­é…ä½¿ç”¨çš„æ‘˜è¦å‡½æ•°ï¼Œå¹¶å±•ç¤ºå®ƒä»¬å¦‚ä½•ä¹Ÿèƒ½ä¸ mutate() ä¸€èµ·ä½¿ç”¨ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#introduction",
    "href": "numbers.html#introduction",
    "title": "13Â  Numbers",
    "section": "",
    "text": "13.1.1 Prerequisites\nThis chapter mostly uses functions from base R, which are available without loading any packages.\næœ¬ç« ä¸»è¦ä½¿ç”¨ base R ä¸­çš„å‡½æ•°ï¼Œè¿™äº›å‡½æ•°æ— éœ€åŠ è½½ä»»ä½•åŒ…å³å¯ä½¿ç”¨ã€‚\nBut we still need the tidyverse because weâ€™ll use these base R functions inside of tidyverse functions like mutate() and filter().\nä½†æˆ‘ä»¬ä»ç„¶éœ€è¦ tidyverseï¼Œå› ä¸ºæˆ‘ä»¬å°†åœ¨ tidyverse å‡½æ•°å¦‚ mutate() å’Œ filter() ä¸­ä½¿ç”¨è¿™äº› base R å‡½æ•°ã€‚\nLike in the last chapter, weâ€™ll use real examples from nycflights13, as well as toy examples made with c() and tribble().\nä¸ä¸Šä¸€ç« ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¥è‡ª nycflights13 çš„çœŸå®ç¤ºä¾‹ï¼Œä»¥åŠç”¨ c() å’Œ tribble() åˆ›å»ºçš„ç©å…·ç¤ºä¾‹ã€‚\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#making-numbers",
    "href": "numbers.html#making-numbers",
    "title": "13Â  Numbers",
    "section": "\n13.2 Making numbers",
    "text": "13.2 Making numbers\nIn most cases, youâ€™ll get numbers already recorded in one of Râ€™s numeric types: integer or double.\nåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ ä¼šå¾—åˆ°å·²ç»ä»¥ R çš„æ•°å€¼ç±»å‹ä¹‹ä¸€ï¼ˆæ•´æ•°æˆ–åŒç²¾åº¦æµ®ç‚¹æ•°ï¼‰è®°å½•çš„æ•°å­—ã€‚\nIn some cases, however, youâ€™ll encounter them as strings, possibly because youâ€™ve created them by pivoting from column headers or because something has gone wrong in your data import process.\nç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä½ ä¼šé‡åˆ°ä»¥å­—ç¬¦ä¸²å½¢å¼å‡ºç°çš„æ•°å­—ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºä½ æ˜¯é€šè¿‡å°†åˆ—æ ‡é¢˜è½¬ç½®è€Œåˆ›å»ºçš„å®ƒä»¬ï¼Œæˆ–è€…æ˜¯å› ä¸ºä½ çš„æ•°æ®å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç°äº†é—®é¢˜ã€‚\nreadr provides two useful functions for parsing strings into numbers: parse_double() and parse_number().\nreadr æä¾›äº†ä¸¤ä¸ªæœ‰ç”¨çš„å‡½æ•°ç”¨äºå°†å­—ç¬¦ä¸²è§£æä¸ºæ•°å­—ï¼šparse_double() å’Œ parse_number()ã€‚\nUse parse_double() when you have numbers that have been written as strings:\nå½“ä½ æ‹¥æœ‰ä»¥å­—ç¬¦ä¸²å½¢å¼ä¹¦å†™çš„æ•°å­—æ—¶ï¼Œè¯·ä½¿ç”¨ parse_double()ï¼š\n\nx &lt;- c(\"1.2\", \"5.6\", \"1e3\")\nparse_double(x)\n#&gt; [1]    1.2    5.6 1000.0\n\nUse parse_number() when the string contains non-numeric text that you want to ignore.\nå½“å­—ç¬¦ä¸²åŒ…å«ä½ æƒ³è¦å¿½ç•¥çš„éæ•°å­—æ–‡æœ¬æ—¶ï¼Œè¯·ä½¿ç”¨ parse_number()ã€‚\nThis is particularly useful for currency data and percentages:\nè¿™å¯¹äºå¤„ç†è´§å¸æ•°æ®å’Œç™¾åˆ†æ¯”ç‰¹åˆ«æœ‰ç”¨ï¼š\n\nx &lt;- c(\"$1,234\", \"USD 3,513\", \"59%\")\nparse_number(x)\n#&gt; [1] 1234 3513   59",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#sec-counts",
    "href": "numbers.html#sec-counts",
    "title": "13Â  Numbers",
    "section": "\n13.3 Counts",
    "text": "13.3 Counts\nItâ€™s surprising how much data science you can do with just counts and a little basic arithmetic, so dplyr strives to make counting as easy as possible with count().\nä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä»…ç”¨è®¡æ•°å’Œä¸€ç‚¹åŸºæœ¬ç®—æœ¯å°±èƒ½å®Œæˆå¤§é‡çš„æ•°æ®ç§‘å­¦å·¥ä½œï¼Œå› æ­¤ dplyr è‡´åŠ›äºé€šè¿‡ count() å‡½æ•°ä½¿è®¡æ•°å°½å¯èƒ½åœ°ç®€å•ã€‚\nThis function is great for quick exploration and checks during analysis:\nè¿™ä¸ªå‡½æ•°éå¸¸é€‚åˆåœ¨åˆ†æè¿‡ç¨‹ä¸­è¿›è¡Œå¿«é€Ÿæ¢ç´¢å’Œæ£€æŸ¥ï¼š\n\nflights |&gt; count(dest)\n#&gt; # A tibble: 105 Ã— 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ABQ     254\n#&gt; 2 ACK     265\n#&gt; 3 ALB     439\n#&gt; 4 ANC       8\n#&gt; 5 ATL   17215\n#&gt; 6 AUS    2439\n#&gt; # â„¹ 99 more rows\n\n(Despite the advice in Chapter 4, we usually put count() on a single line because itâ€™s usually used at the console for a quick check that a calculation is working as expected.)\nï¼ˆå°½ç®¡åœ¨ Chapter 4 ä¸­æœ‰ç›¸å…³å»ºè®®ï¼Œæˆ‘ä»¬é€šå¸¸å°† count() å†™åœ¨å•è¡Œä¸Šï¼Œå› ä¸ºå®ƒé€šå¸¸åœ¨æ§åˆ¶å°ä¸­ç”¨äºå¿«é€Ÿæ£€æŸ¥è®¡ç®—æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œã€‚ï¼‰\nIf you want to see the most common values, add sort = TRUE:\nå¦‚æœä½ æƒ³æŸ¥çœ‹æœ€å¸¸è§çš„å€¼ï¼Œè¯·æ·»åŠ  sort = TRUEï¼š\n\nflights |&gt; count(dest, sort = TRUE)\n#&gt; # A tibble: 105 Ã— 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ORD   17283\n#&gt; 2 ATL   17215\n#&gt; 3 LAX   16174\n#&gt; 4 BOS   15508\n#&gt; 5 MCO   14082\n#&gt; 6 CLT   14064\n#&gt; # â„¹ 99 more rows\n\nAnd remember that if you want to see all the values, you can use |&gt; View() or |&gt; print(n = Inf).\nå¹¶ä¸”è®°ä½ï¼Œå¦‚æœä½ æƒ³æŸ¥çœ‹æ‰€æœ‰å€¼ï¼Œä½ å¯ä»¥ä½¿ç”¨ |&gt; View() æˆ– |&gt; print(n = Inf)ã€‚\nYou can perform the same computation â€œby handâ€ with group_by(), summarize() and n().\nä½ å¯ä»¥ä½¿ç”¨ group_by()ã€summarize() å’Œ n() â€œæ‰‹åŠ¨â€ æ‰§è¡Œç›¸åŒçš„è®¡ç®—ã€‚\nThis is useful because it allows you to compute other summaries at the same time:\nè¿™å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒå…è®¸ä½ åŒæ—¶è®¡ç®—å…¶ä»–æ‘˜è¦ï¼š\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 105 Ã— 3\n#&gt;   dest      n delay\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n#&gt; 1 ABQ     254  4.38\n#&gt; 2 ACK     265  4.85\n#&gt; 3 ALB     439 14.4 \n#&gt; 4 ANC       8 -2.5 \n#&gt; 5 ATL   17215 11.3 \n#&gt; 6 AUS    2439  6.02\n#&gt; # â„¹ 99 more rows\n\nn() is a special summary function that doesnâ€™t take any arguments and instead accesses information about the â€œcurrentâ€ group.n() æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„æ‘˜è¦å‡½æ•°ï¼Œå®ƒä¸æ¥å—ä»»ä½•å‚æ•°ï¼Œè€Œæ˜¯è®¿é—®å…³äº â€œå½“å‰â€ ç»„çš„ä¿¡æ¯ã€‚\nThis means that it only works inside dplyr verbs:\nè¿™æ„å‘³ç€å®ƒåªèƒ½åœ¨ dplyr åŠ¨è¯å†…éƒ¨å·¥ä½œï¼š\n\nn()\n#&gt; Error in `n()`:\n#&gt; ! Must only be used inside data-masking verbs like `mutate()`,\n#&gt;   `filter()`, and `group_by()`.\n\nThere are a couple of variants of n() and count() that you might find useful:n() å’Œ count() æœ‰å‡ ä¸ªä½ å¯èƒ½ä¼šè§‰å¾—æœ‰ç”¨çš„å˜ä½“ï¼š\n\n\nn_distinct(x) counts the number of distinct (unique) values of one or more variables.\nFor example, we could figure out which destinations are served by the most carriers:n_distinct(x) è®¡ç®—ä¸€ä¸ªæˆ–å¤šä¸ªå˜é‡çš„ä¸é‡å¤ï¼ˆå”¯ä¸€ï¼‰å€¼çš„æ•°é‡ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾å‡ºå“ªäº›ç›®çš„åœ°æœ‰æœ€å¤šçš„èˆªç©ºå…¬å¸ä½¿ç”¨ï¼š\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(carriers = n_distinct(carrier)) |&gt; \n  arrange(desc(carriers))\n#&gt; # A tibble: 105 Ã— 2\n#&gt;   dest  carriers\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 ATL          7\n#&gt; 2 BOS          7\n#&gt; 3 CLT          7\n#&gt; 4 ORD          7\n#&gt; 5 TPA          7\n#&gt; 6 AUS          6\n#&gt; # â„¹ 99 more rows\n\n\n\nA weighted count is a sum. For example you could â€œcountâ€ the number of miles each plane flew:\nåŠ æƒè®¡æ•°æ˜¯ä¸€ä¸ªæ±‚å’Œã€‚ ä¾‹å¦‚ï¼Œä½ å¯ä»¥â€œè®¡æ•°â€æ¯æ¶é£æœºé£è¡Œçš„è‹±é‡Œæ•°ï¼š\n\nflights |&gt; \n  group_by(tailnum) |&gt; \n  summarize(miles = sum(distance))\n#&gt; # A tibble: 4,044 Ã— 2\n#&gt;   tailnum  miles\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 D942DN    3418\n#&gt; 2 N0EGMQ  250866\n#&gt; 3 N10156  115966\n#&gt; 4 N102UW   25722\n#&gt; 5 N103US   24619\n#&gt; 6 N104UW   25157\n#&gt; # â„¹ 4,038 more rows\n\n\n\nWeighted counts are a common problem so count() has a wt argument that does the same thing:\nåŠ æƒè®¡æ•°æ˜¯ä¸€ä¸ªå¸¸è§é—®é¢˜ï¼Œå› æ­¤ count() æœ‰ä¸€ä¸ª wt å‚æ•°å¯ä»¥å®ç°åŒæ ·çš„åŠŸèƒ½ï¼š\n\nflights |&gt; count(tailnum, wt = distance)\n\n\n\nYou can count missing values by combining sum() and is.na(). In the flights dataset this represents flights that are cancelled:\nä½ å¯ä»¥é€šè¿‡ç»“åˆ sum() å’Œ is.na() æ¥ç»Ÿè®¡ç¼ºå¤±å€¼çš„æ•°é‡ã€‚ åœ¨ flights æ•°æ®é›†ä¸­ï¼Œè¿™è¡¨ç¤ºè¢«å–æ¶ˆçš„èˆªç­ï¼š\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(n_cancelled = sum(is.na(dep_time))) \n#&gt; # A tibble: 105 Ã— 2\n#&gt;   dest  n_cancelled\n#&gt;   &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 ABQ             0\n#&gt; 2 ACK             0\n#&gt; 3 ALB            20\n#&gt; 4 ANC             0\n#&gt; 5 ATL           317\n#&gt; 6 AUS            21\n#&gt; # â„¹ 99 more rows\n\n\n\n\n13.3.1 Exercises\n\nHow can you use count() to count the number of rows with a missing value for a given variable?\nExpand the following calls to count() to instead use group_by(), summarize(), and arrange():\n\nflights |&gt; count(dest, sort = TRUE)\nflights |&gt; count(tailnum, wt = distance)",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#numeric-transformations",
    "href": "numbers.html#numeric-transformations",
    "title": "13Â  Numbers",
    "section": "\n13.4 Numeric transformations",
    "text": "13.4 Numeric transformations\nTransformation functions work well with mutate() because their output is the same length as the input.\nè½¬æ¢å‡½æ•°ä¸ mutate() é…åˆå¾—å¾ˆå¥½ï¼Œå› ä¸ºå®ƒä»¬çš„è¾“å‡ºé•¿åº¦ä¸è¾“å…¥é•¿åº¦ç›¸åŒã€‚\nThe vast majority of transformation functions are already built into base R.\nç»å¤§å¤šæ•°çš„è½¬æ¢å‡½æ•°éƒ½å·²å†…ç½®åœ¨ base R ä¸­ã€‚\nItâ€™s impractical to list them all so this section will show the most useful ones.\nè¦åˆ—å‡ºæ‰€æœ‰è¿™äº›å‡½æ•°æ˜¯ä¸åˆ‡å®é™…çš„ï¼Œæ‰€ä»¥æœ¬èŠ‚å°†å±•ç¤ºæœ€æœ‰ç”¨çš„é‚£äº›ã€‚\nAs an example, while R provides all the trigonometric functions that you might dream of, we donâ€™t list them here because theyâ€™re rarely needed for data science.\nä¸¾ä¸ªä¾‹å­ï¼Œè™½ç„¶ R æä¾›äº†ä½ å¯èƒ½æ¢¦æƒ³åˆ°çš„æ‰€æœ‰ä¸‰è§’å‡½æ•°ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é‡Œä¸åˆ—å‡ºå®ƒä»¬ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ•°æ®ç§‘å­¦ä¸­å¾ˆå°‘éœ€è¦ã€‚\n\n13.4.1 Arithmetic and recycling rules\nWe introduced the basics of arithmetic (+, -, *, /, ^) in Chapter 2 and have used them a bunch since.\næˆ‘ä»¬åœ¨ Chapter 2 ä¸­ä»‹ç»äº†ç®—æœ¯ï¼ˆ+ã€-ã€*ã€/ã€^ï¼‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¹¶ä¸”ä»é‚£ä»¥åå·²ç»å¤§é‡ä½¿ç”¨å®ƒä»¬ã€‚\nThese functions donâ€™t need a huge amount of explanation because they do what you learned in grade school.\nè¿™äº›å‡½æ•°ä¸éœ€è¦å¤§é‡çš„è§£é‡Šï¼Œå› ä¸ºå®ƒä»¬åšçš„å°±æ˜¯ä½ åœ¨å°å­¦å­¦åˆ°çš„ä¸œè¥¿ã€‚\nBut we need to briefly talk about the recycling rules which determine what happens when the left and right hand sides have different lengths.\nä½†æ˜¯æˆ‘ä»¬éœ€è¦ç®€è¦è®¨è®ºä¸€ä¸‹å¾ªç¯è§„åˆ™ (recycling rules)ï¼Œå®ƒå†³å®šäº†å½“å·¦å³ä¸¤ä¾§é•¿åº¦ä¸åŒæ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚\nThis is important for operations like flights |&gt; mutate(air_time = air_time / 60) because there are 336,776 numbers on the left of / but only one on the right.\nè¿™å¯¹äºåƒ flights |&gt; mutate(air_time = air_time / 60) è¿™æ ·çš„æ“ä½œå¾ˆé‡è¦ï¼Œå› ä¸º / çš„å·¦è¾¹æœ‰ 336,776 ä¸ªæ•°å­—ï¼Œè€Œå³è¾¹åªæœ‰ä¸€ä¸ªã€‚\nR handles mismatched lengths by recycling, or repeating, the short vector.\nR é€šè¿‡å¾ªç¯ (recycling) æˆ–é‡å¤è¾ƒçŸ­çš„å‘é‡æ¥å¤„ç†é•¿åº¦ä¸åŒ¹é…çš„æƒ…å†µã€‚\nWe can see this in operation more easily if we create some vectors outside of a data frame:\nå¦‚æœæˆ‘ä»¬åˆ›å»ºä¸€äº›æ•°æ®æ¡†ä¹‹å¤–çš„å‘é‡ï¼Œå¯ä»¥æ›´å®¹æ˜“åœ°çœ‹åˆ°è¿™ä¸ªæ“ä½œï¼š\n\nx &lt;- c(1, 2, 10, 20)\nx / 5\n#&gt; [1] 0.2 0.4 2.0 4.0\n# is shorthand for\nx / c(5, 5, 5, 5)\n#&gt; [1] 0.2 0.4 2.0 4.0\n\nGenerally, you only want to recycle single numbers (i.e.Â vectors of length 1), but R will recycle any shorter length vector.\né€šå¸¸ï¼Œä½ åªæƒ³å¾ªç¯åˆ©ç”¨å•ä¸ªæ•°å­—ï¼ˆå³é•¿åº¦ä¸º 1 çš„å‘é‡ï¼‰ï¼Œä½† R ä¼šå¾ªç¯åˆ©ç”¨ä»»ä½•æ›´çŸ­é•¿åº¦çš„å‘é‡ã€‚\nIt usually (but not always) gives you a warning if the longer vector isnâ€™t a multiple of the shorter:\nå¦‚æœè¾ƒé•¿çš„å‘é‡ä¸æ˜¯è¾ƒçŸ­å‘é‡çš„å€æ•°ï¼Œå®ƒé€šå¸¸ï¼ˆä½†å¹¶éæ€»æ˜¯ï¼‰ä¼šç»™ä½ ä¸€ä¸ªè­¦å‘Šï¼š\n\nx * c(1, 2)\n#&gt; [1]  1  4 10 40\nx * c(1, 2, 3)\n#&gt; Warning in x * c(1, 2, 3): longer object length is not a multiple of shorter\n#&gt; object length\n#&gt; [1]  1  4 30 20\n\nThese recycling rules are also applied to logical comparisons (==, &lt;, &lt;=, &gt;, &gt;=, !=) and can lead to a surprising result if you accidentally use == instead of %in% and the data frame has an unfortunate number of rows.\nè¿™äº›å¾ªç¯è§„åˆ™ä¹Ÿé€‚ç”¨äºé€»è¾‘æ¯”è¾ƒï¼ˆ==ã€&lt;ã€&lt;=ã€&gt;ã€&gt;=ã€!=ï¼‰ï¼Œå¦‚æœä½ ä¸å°å¿ƒä½¿ç”¨äº† == è€Œä¸æ˜¯ %in%ï¼Œå¹¶ä¸”æ•°æ®æ¡†çš„è¡Œæ•°ä¸å‡‘å·§ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä»¤äººæƒŠè®¶çš„ç»“æœã€‚\nFor example, take this code which attempts to find all flights in January and February:\nä¾‹å¦‚ï¼Œçœ‹è¿™æ®µè¯•å›¾æŸ¥æ‰¾ä¸€æœˆå’ŒäºŒæœˆæ‰€æœ‰èˆªç­çš„ä»£ç ï¼š\n\nflights |&gt; \n  filter(month == c(1, 2))\n#&gt; # A tibble: 25,977 Ã— 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      542            540         2      923            850\n#&gt; 3  2013     1     1      554            600        -6      812            837\n#&gt; 4  2013     1     1      555            600        -5      913            854\n#&gt; 5  2013     1     1      557            600        -3      838            846\n#&gt; 6  2013     1     1      558            600        -2      849            851\n#&gt; # â„¹ 25,971 more rows\n#&gt; # â„¹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\nThe code runs without error, but it doesnâ€™t return what you want.\nä»£ç è¿è¡Œæ²¡æœ‰é”™è¯¯ï¼Œä½†å®ƒæ²¡æœ‰è¿”å›ä½ æƒ³è¦çš„ç»“æœã€‚\nBecause of the recycling rules it finds flights in odd numbered rows that departed in January and flights in even numbered rows that departed in February.\nç”±äºå¾ªç¯è§„åˆ™ï¼Œå®ƒä¼šæŸ¥æ‰¾å¥‡æ•°è¡Œä¸­åœ¨ä¸€æœˆå‡ºå‘çš„èˆªç­å’Œå¶æ•°è¡Œä¸­åœ¨äºŒæœˆå‡ºå‘çš„èˆªç­ã€‚\nAnd unfortunately thereâ€™s no warning because flights has an even number of rows.\nè€Œä¸”ä¸å¹¸çš„æ˜¯ï¼Œå› ä¸º flights æ•°æ®æ¡†æœ‰å¶æ•°è¡Œï¼Œæ‰€ä»¥æ²¡æœ‰è­¦å‘Šã€‚\nTo protect you from this type of silent failure, most tidyverse functions use a stricter form of recycling that only recycles single values.\nä¸ºäº†ä¿æŠ¤ä½ å…å—è¿™ç±»é™é»˜å¤±è´¥çš„å½±å“ï¼Œå¤§å¤šæ•° tidyverse å‡½æ•°ä½¿ç”¨ä¸€ç§æ›´ä¸¥æ ¼çš„å¾ªç¯å½¢å¼ï¼Œåªå¾ªç¯å•ä¸ªå€¼ã€‚\nUnfortunately that doesnâ€™t help here, or in many other cases, because the key computation is performed by the base R function ==, not filter().\nä¸å¹¸çš„æ˜¯ï¼Œè¿™åœ¨è¿™é‡Œæˆ–è®¸å¤šå…¶ä»–æƒ…å†µä¸‹æ²¡æœ‰å¸®åŠ©ï¼Œå› ä¸ºå…³é”®çš„è®¡ç®—æ˜¯ç”± base R å‡½æ•° == æ‰§è¡Œçš„ï¼Œè€Œä¸æ˜¯ filter()ã€‚\n\n13.4.2 Minimum and maximum\nThe arithmetic functions work with pairs of variables.\nç®—æœ¯å‡½æ•°å¤„ç†æˆå¯¹çš„å˜é‡ã€‚\nTwo closely related functions are pmin() and pmax(), which when given two or more variables will return the smallest or largest value in each row:\nä¸¤ä¸ªå¯†åˆ‡ç›¸å…³çš„å‡½æ•°æ˜¯ pmin() å’Œ pmax()ï¼Œå½“ç»™å®šä¸¤ä¸ªæˆ–å¤šä¸ªå˜é‡æ—¶ï¼Œå®ƒä»¬å°†è¿”å›æ¯è¡Œä¸­çš„æœ€å°å€¼æˆ–æœ€å¤§å€¼ï¼š\n\ndf &lt;- tribble(\n  ~x, ~y,\n  1,  3,\n  5,  2,\n  7, NA,\n)\n\ndf |&gt; \n  mutate(\n    min = pmin(x, y, na.rm = TRUE),\n    max = pmax(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 Ã— 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     3\n#&gt; 2     5     2     2     5\n#&gt; 3     7    NA     7     7\n\nNote that these are different to the summary functions min() and max() which take multiple observations and return a single value.\nè¯·æ³¨æ„ï¼Œè¿™äº›å‡½æ•°ä¸æ‘˜è¦å‡½æ•° min() å’Œ max() ä¸åŒï¼Œåè€…æ¥å—å¤šä¸ªè§‚æµ‹å€¼å¹¶è¿”å›å•ä¸ªå€¼ã€‚\nYou can tell that youâ€™ve used the wrong form when all the minimums and all the maximums have the same value:\nå½“æ‰€æœ‰çš„æœ€å°å€¼å’Œæ‰€æœ‰çš„æœ€å¤§å€¼éƒ½å…·æœ‰ç›¸åŒçš„å€¼æ—¶ï¼Œä½ å°±å¯ä»¥åˆ¤æ–­å‡ºä½ ä½¿ç”¨äº†é”™è¯¯çš„å½¢å¼ï¼š\n\ndf |&gt; \n  mutate(\n    min = min(x, y, na.rm = TRUE),\n    max = max(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 Ã— 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     7\n#&gt; 2     5     2     1     7\n#&gt; 3     7    NA     1     7\n\n\n13.4.3 Modular arithmetic\nModular arithmetic is the technical name for the type of math you did before you learned about decimal places, i.e.Â division that yields a whole number and a remainder.\næ¨¡è¿ç®—æ˜¯ä½ åœ¨å­¦ä¹ å°æ•°ä¹‹å‰æ‰€åšçš„é‚£ç§æ•°å­¦çš„ä¸“ä¸šæœ¯è¯­ï¼Œå³äº§ç”Ÿæ•´æ•°å’Œä½™æ•°çš„é™¤æ³•ã€‚\nIn R, %/% does integer division and %% computes the remainder:\nåœ¨ R ä¸­ï¼Œ%/% æ‰§è¡Œæ•´æ•°é™¤æ³•ï¼Œè€Œ %% è®¡ç®—ä½™æ•°ï¼š\n\n1:10 %/% 3\n#&gt;  [1] 0 0 1 1 1 2 2 2 3 3\n1:10 %% 3\n#&gt;  [1] 1 2 0 1 2 0 1 2 0 1\n\nModular arithmetic is handy for the flights dataset, because we can use it to unpack the sched_dep_time variable into hour and minute:\næ¨¡è¿ç®—å¯¹äº flights æ•°æ®é›†éå¸¸æ–¹ä¾¿ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ç”¨å®ƒå°† sched_dep_time å˜é‡åˆ†è§£ä¸º hour å’Œ minuteï¼š\n\nflights |&gt; \n  mutate(\n    hour = sched_dep_time %/% 100,\n    minute = sched_dep_time %% 100,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 Ã— 3\n#&gt;   sched_dep_time  hour minute\n#&gt;            &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1            515     5     15\n#&gt; 2            529     5     29\n#&gt; 3            540     5     40\n#&gt; 4            545     5     45\n#&gt; 5            600     6      0\n#&gt; 6            558     5     58\n#&gt; # â„¹ 336,770 more rows\n\nWe can combine that with the mean(is.na(x)) trick from Section 12.4 to see how the proportion of cancelled flights varies over the course of the day.\næˆ‘ä»¬å¯ä»¥å°†å…¶ä¸ Section 12.4 ä¸­çš„ mean(is.na(x)) æŠ€å·§ç»“åˆèµ·æ¥ï¼Œçœ‹çœ‹å–æ¶ˆèˆªç­çš„æ¯”ä¾‹åœ¨ä¸€å¤©ä¸­æ˜¯å¦‚ä½•å˜åŒ–çš„ã€‚\nThe results are shown in FigureÂ 13.1.\nç»“æœæ˜¾ç¤ºåœ¨ FigureÂ 13.1 ä¸­ã€‚\n\nflights |&gt; \n  group_by(hour = sched_dep_time %/% 100) |&gt; \n  summarize(prop_cancelled = mean(is.na(dep_time)), n = n()) |&gt; \n  filter(hour &gt; 1) |&gt; \n  ggplot(aes(x = hour, y = prop_cancelled)) +\n  geom_line(color = \"grey50\") + \n  geom_point(aes(size = n))\n\n\n\n\n\n\nFigureÂ 13.1: A line plot with scheduled departure hour on the x-axis, and proportion of cancelled flights on the y-axis. Cancellations seem to accumulate over the course of the day until 8pm, very late flights are much less likely to be cancelled.\n\n\n\n\n\n13.4.4 Logarithms\nLogarithms are an incredibly useful transformation for dealing with data that ranges across multiple orders of magnitude and converting exponential growth to linear growth.\nå¯¹æ•°æ˜¯ä¸€ç§éå¸¸æœ‰ç”¨çš„è½¬æ¢ï¼Œç”¨äºå¤„ç†è·¨è¶Šå¤šä¸ªæ•°é‡çº§çš„æ•°æ®ï¼Œå¹¶å°†æŒ‡æ•°å¢é•¿è½¬æ¢ä¸ºçº¿æ€§å¢é•¿ã€‚\nIn R, you have a choice of three logarithms: log() (the natural log, base e), log2() (base 2), and log10() (base 10).\nåœ¨ R ä¸­ï¼Œä½ å¯ä»¥é€‰æ‹©ä¸‰ç§å¯¹æ•°ï¼šlog() (è‡ªç„¶å¯¹æ•°ï¼Œä»¥ e ä¸ºåº•)ã€log2() (ä»¥ 2 ä¸ºåº•) å’Œ log10() (ä»¥ 10 ä¸ºåº•)ã€‚\nWe recommend using log2() or log10().\næˆ‘ä»¬æ¨èä½¿ç”¨ log2() æˆ– log10()ã€‚\nlog2() is easy to interpret because a difference of 1 on the log scale corresponds to doubling on the original scale and a difference of -1 corresponds to halving; whereas log10() is easy to back-transform because (e.g.) 3 is 10^3 = 1000.log2() å¾ˆå®¹æ˜“è§£é‡Šï¼Œå› ä¸ºå¯¹æ•°å°ºåº¦ä¸Šçš„ 1 ä¸ªå•ä½å·®å¼‚å¯¹åº”äºåŸå§‹å°ºåº¦ä¸Šçš„åŠ å€ï¼Œè€Œ -1 çš„å·®å¼‚åˆ™å¯¹åº”äºå‡åŠï¼›è€Œ log10() å¾ˆå®¹æ˜“è¿›è¡Œé€†è½¬æ¢ï¼Œå› ä¸ºï¼ˆä¾‹å¦‚ï¼‰3 æ˜¯ 10^3 = 1000ã€‚\nThe inverse of log() is exp(); to compute the inverse of log2() or log10() youâ€™ll need to use 2^ or 10^.log() çš„é€†è¿ç®—æ˜¯ exp()ï¼›è¦è®¡ç®— log2() æˆ– log10() çš„é€†è¿ç®—ï¼Œä½ éœ€è¦ä½¿ç”¨ 2^ æˆ– 10^ã€‚\n\n13.4.5 Rounding\nUse round(x) to round a number to the nearest integer:\nä½¿ç”¨ round(x) å°†æ•°å­—å››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„æ•´æ•°ï¼š\n\nround(123.456)\n#&gt; [1] 123\n\nYou can control the precision of the rounding with the second argument, digits.\nä½ å¯ä»¥ä½¿ç”¨ç¬¬äºŒä¸ªå‚æ•° digits æ¥æ§åˆ¶å››èˆäº”å…¥çš„ç²¾åº¦ã€‚\nround(x, digits) rounds to the nearest 10^-n so digits = 2 will round to the nearest 0.01.round(x, digits) ä¼šå››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„ 10^-nï¼Œæ‰€ä»¥ digits = 2 ä¼šå››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„ 0.01ã€‚\nThis definition is useful because it implies round(x, -3) will round to the nearest thousand, which indeed it does:\nè¿™ä¸ªå®šä¹‰å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒæ„å‘³ç€ round(x, -3) ä¼šå››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„åƒä½ï¼Œäº‹å®ä¹Ÿç¡®å®å¦‚æ­¤ï¼š\n\nround(123.456, 2)  # two digits\n#&gt; [1] 123.46\nround(123.456, 1)  # one digit\n#&gt; [1] 123.5\nround(123.456, -1) # round to nearest ten\n#&gt; [1] 120\nround(123.456, -2) # round to nearest hundred\n#&gt; [1] 100\n\nThereâ€™s one weirdness with round() that seems surprising at first glance:round() æœ‰ä¸€ä¸ªä¹ä¸€çœ‹ä¼¼ä¹å¾ˆå¥‡æ€ªçš„ç‰¹æ€§ï¼š\n\nround(c(1.5, 2.5))\n#&gt; [1] 2 2\n\nround() uses whatâ€™s known as â€œround half to evenâ€ or Bankerâ€™s rounding: if a number is half way between two integers, it will be rounded to the even integer.round() ä½¿ç”¨æ‰€è°“çš„ â€œå››èˆå…­å…¥äº”æˆåŒâ€ æˆ–é“¶è¡Œå®¶èˆå…¥æ³•ï¼šå¦‚æœä¸€ä¸ªæ•°å­—æ­£å¥½åœ¨ä¸¤ä¸ªæ•´æ•°ä¸­é—´ï¼Œå®ƒå°†è¢«èˆå…¥åˆ°å¶æ•°ã€‚\nThis is a good strategy because it keeps the rounding unbiased: half of all 0.5s are rounded up, and half are rounded down.\nè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç­–ç•¥ï¼Œå› ä¸ºå®ƒèƒ½ä¿æŒèˆå…¥çš„æ— åæ€§ï¼šä¸€åŠçš„ 0.5 ä¼šå‘ä¸Šèˆå…¥ï¼Œä¸€åŠä¼šå‘ä¸‹èˆå…¥ã€‚\nround() is paired with floor() which always rounds down and ceiling() which always rounds up:round() ä¸ floor()ï¼ˆæ€»æ˜¯å‘ä¸‹å–æ•´ï¼‰å’Œ ceiling()ï¼ˆæ€»æ˜¯å‘ä¸Šå–æ•´ï¼‰é…å¯¹ä½¿ç”¨ï¼š\n\nx &lt;- 123.456\n\nfloor(x)\n#&gt; [1] 123\nceiling(x)\n#&gt; [1] 124\n\nThese functions donâ€™t have a digits argument, so you can instead scale down, round, and then scale back up:\nè¿™äº›å‡½æ•°æ²¡æœ‰ digits å‚æ•°ï¼Œæ‰€ä»¥ä½ å¯ä»¥å…ˆç¼©å°ï¼Œç„¶åå–æ•´ï¼Œå†æ”¾å¤§å›å»ï¼š\n\n# Round down to nearest two digits\nfloor(x / 0.01) * 0.01\n#&gt; [1] 123.45\n# Round up to nearest two digits\nceiling(x / 0.01) * 0.01\n#&gt; [1] 123.46\n\nYou can use the same technique if you want to round() to a multiple of some other number:\nå¦‚æœä½ æƒ³ round() åˆ°æŸä¸ªå…¶ä»–æ•°å­—çš„å€æ•°ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ç›¸åŒçš„æŠ€å·§ï¼š\n\n# Round to nearest multiple of 4\nround(x / 4) * 4\n#&gt; [1] 124\n\n# Round to nearest 0.25\nround(x / 0.25) * 0.25\n#&gt; [1] 123.5\n\n\n13.4.6 Cutting numbers into ranges\nUse cut()1 to break up (aka bin) a numeric vector into discrete buckets:\nä½¿ç”¨ cut()1 å°†ä¸€ä¸ªæ•°å€¼å‘é‡åˆ†å‰²ï¼ˆä¹Ÿç§°åˆ†ç®±ï¼‰æˆç¦»æ•£çš„åŒºé—´ï¼š\n\nx &lt;- c(1, 2, 5, 10, 15, 20)\ncut(x, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] (0,5]   (0,5]   (0,5]   (5,10]  (10,15] (15,20]\n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\nThe breaks donâ€™t need to be evenly spaced:\nåˆ†å‰²ç‚¹ä¸éœ€è¦å‡åŒ€åˆ†å¸ƒï¼š\n\ncut(x, breaks = c(0, 5, 10, 100))\n#&gt; [1] (0,5]    (0,5]    (0,5]    (5,10]   (10,100] (10,100]\n#&gt; Levels: (0,5] (5,10] (10,100]\n\nYou can optionally supply your own labels.\nä½ å¯ä»¥é€‰æ‹©æ€§åœ°æä¾›è‡ªå·±çš„ labelsã€‚\nNote that there should be one less labels than breaks.\nè¯·æ³¨æ„ï¼Œlabels çš„æ•°é‡åº”è¯¥æ¯” breaks å°‘ä¸€ä¸ªã€‚\n\ncut(x, \n  breaks = c(0, 5, 10, 15, 20), \n  labels = c(\"sm\", \"md\", \"lg\", \"xl\")\n)\n#&gt; [1] sm sm sm md lg xl\n#&gt; Levels: sm md lg xl\n\nAny values outside of the range of the breaks will become NA:\nä»»ä½•è¶…å‡ºåˆ†å‰²ç‚¹èŒƒå›´çš„å€¼éƒ½å°†å˜ä¸º NAï¼š\n\ny &lt;- c(NA, -10, 5, 10, 30)\ncut(y, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] &lt;NA&gt;   &lt;NA&gt;   (0,5]  (5,10] &lt;NA&gt;  \n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\nSee the documentation for other useful arguments like right and include.lowest, which control if the intervals are [a, b) or (a, b] and if the lowest interval should be [a, b].\nè¯·å‚é˜…æ–‡æ¡£ä»¥äº†è§£å…¶ä»–æœ‰ç”¨çš„å‚æ•°ï¼Œå¦‚ right å’Œ include.lowestï¼Œå®ƒä»¬æ§åˆ¶åŒºé—´æ˜¯ [a, b) è¿˜æ˜¯ (a, b]ï¼Œä»¥åŠæœ€ä½çš„åŒºé—´æ˜¯å¦åº”ä¸º [a, b]ã€‚\n\n13.4.7 Cumulative and rolling aggregates\nBase R provides cumsum(), cumprod(), cummin(), cummax() for running, or cumulative, sums, products, mins and maxes.\nBase R æä¾›äº† cumsum()ã€cumprod()ã€cummin()ã€cummax() ç”¨äºè®¡ç®—æ¸¸åŠ¨æˆ–ç´¯ç§¯çš„å’Œã€ç§¯ã€æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚\ndplyr provides cummean() for cumulative means.\ndplyr æä¾›äº† cummean() ç”¨äºè®¡ç®—ç´¯ç§¯å‡å€¼ã€‚\nCumulative sums tend to come up the most in practice:\nç´¯ç§¯å’Œåœ¨å®è·µä¸­æœ€ä¸ºå¸¸è§ï¼š\n\nx &lt;- 1:10\ncumsum(x)\n#&gt;  [1]  1  3  6 10 15 21 28 36 45 55\n\nIf you need more complex rolling or sliding aggregates, try the slider package.\nå¦‚æœä½ éœ€è¦æ›´å¤æ‚çš„æ»šåŠ¨æˆ–æ»‘åŠ¨èšåˆï¼Œå¯ä»¥è¯•è¯• slider åŒ…ã€‚\n\n13.4.8 Exercises\n\nExplain in words what each line of the code used to generate FigureÂ 13.1 does.\nWhat trigonometric functions does R provide? Guess some names and look up the documentation. Do they use degrees or radians?\n\nCurrently dep_time and sched_dep_time are convenient to look at, but hard to compute with because theyâ€™re not really continuous numbers. You can see the basic problem by running the code below: thereâ€™s a gap between each hour.\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  ggplot(aes(x = sched_dep_time, y = dep_delay)) +\n  geom_point()\n\nConvert them to a more truthful representation of time (either fractional hours or minutes since midnight).\n\nRound dep_time and arr_time to the nearest five minutes.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#general-transformations",
    "href": "numbers.html#general-transformations",
    "title": "13Â  Numbers",
    "section": "\n13.5 General transformations",
    "text": "13.5 General transformations\nThe following sections describe some general transformations which are often used with numeric vectors, but can be applied to all other column types.\nä»¥ä¸‹å„èŠ‚æè¿°äº†ä¸€äº›é€šå¸¸ç”¨äºæ•°å€¼å‘é‡ï¼Œä½†ä¹Ÿå¯ä»¥åº”ç”¨äºæ‰€æœ‰å…¶ä»–åˆ—ç±»å‹çš„ä¸€èˆ¬è½¬æ¢ã€‚\n\n13.5.1 Ranks\ndplyr provides a number of ranking functions inspired by SQL, but you should always start with dplyr::min_rank().\ndplyr æä¾›äº†ä¸€äº›å— SQL å¯å‘çš„æ’åå‡½æ•°ï¼Œä½†ä½ åº”è¯¥æ€»æ˜¯ä» dplyr::min_rank() å¼€å§‹ã€‚\nIt uses the typical method for dealing with ties, e.g., 1st, 2nd, 2nd, 4th.\nå®ƒä½¿ç”¨å¤„ç†å¹³å±€çš„å…¸å‹æ–¹æ³•ï¼Œä¾‹å¦‚ï¼Œç¬¬ 1 åã€ç¬¬ 2 åã€ç¬¬ 2 åã€ç¬¬ 4 åã€‚\n\nx &lt;- c(1, 2, 2, 3, 4, NA)\nmin_rank(x)\n#&gt; [1]  1  2  2  4  5 NA\n\nNote that the smallest values get the lowest ranks; use desc(x) to give the largest values the smallest ranks:\næ³¨æ„ï¼Œæœ€å°å€¼è·å¾—æœ€ä½çš„æ’åï¼›ä½¿ç”¨ desc(x) å¯ä»¥è®©æœ€å¤§å€¼è·å¾—æœ€ä½çš„æ’åï¼š\n\nmin_rank(desc(x))\n#&gt; [1]  5  3  3  2  1 NA\n\nIf min_rank() doesnâ€™t do what you need, look at the variants dplyr::row_number(), dplyr::dense_rank(), dplyr::percent_rank(), and dplyr::cume_dist().\nå¦‚æœ min_rank() ä¸èƒ½æ»¡è¶³ä½ çš„éœ€æ±‚ï¼Œå¯ä»¥çœ‹çœ‹å®ƒçš„å˜ä½“ dplyr::row_number()ã€dplyr::dense_rank()ã€dplyr::percent_rank() å’Œ dplyr::cume_dist()ã€‚\nSee the documentation for details.\nè¯¦æƒ…è¯·å‚é˜…æ–‡æ¡£ã€‚\n\ndf &lt;- tibble(x = x)\ndf |&gt; \n  mutate(\n    row_number = row_number(x),\n    dense_rank = dense_rank(x),\n    percent_rank = percent_rank(x),\n    cume_dist = cume_dist(x)\n  )\n#&gt; # A tibble: 6 Ã— 5\n#&gt;       x row_number dense_rank percent_rank cume_dist\n#&gt;   &lt;dbl&gt;      &lt;int&gt;      &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1          1          1         0          0.2\n#&gt; 2     2          2          2         0.25       0.6\n#&gt; 3     2          3          2         0.25       0.6\n#&gt; 4     3          4          3         0.75       0.8\n#&gt; 5     4          5          4         1          1  \n#&gt; 6    NA         NA         NA        NA         NA\n\nYou can achieve many of the same results by picking the appropriate ties.method argument to base Râ€™s rank(); youâ€™ll probably also want to set na.last = \"keep\" to keep NAs as NA.\né€šè¿‡ä¸º base R çš„ rank() å‡½æ•°é€‰æ‹©åˆé€‚çš„ ties.method å‚æ•°ï¼Œä½ å¯ä»¥å®ç°è®¸å¤šç›¸åŒçš„ç»“æœï¼›ä½ å¯èƒ½è¿˜æƒ³è®¾ç½® na.last = \"keep\" ä»¥å°† NA ä¿ç•™ä¸º NAã€‚\nrow_number() can also be used without any arguments when inside a dplyr verb.row_number() åœ¨ dplyr åŠ¨è¯å†…éƒ¨ä½¿ç”¨æ—¶ä¹Ÿå¯ä»¥ä¸å¸¦ä»»ä½•å‚æ•°ã€‚\nIn this case, itâ€™ll give the number of the â€œcurrentâ€ row.\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒä¼šç»™å‡º â€œå½“å‰â€ è¡Œçš„è¡Œå·ã€‚\nWhen combined with %% or %/% this can be a useful tool for dividing data into similarly sized groups:\nå½“ä¸ %% æˆ– %/% ç»“åˆä½¿ç”¨æ—¶ï¼Œè¿™å¯ä»¥æˆä¸ºå°†æ•°æ®åˆ’åˆ†ä¸ºå¤§å°ç›¸è¿‘çš„ç»„çš„æœ‰ç”¨å·¥å…·ï¼š\n\ndf &lt;- tibble(id = 1:10)\n\ndf |&gt; \n  mutate(\n    row0 = row_number() - 1,\n    three_groups = row0 %% 3,\n    three_in_each_group = row0 %/% 3\n  )\n#&gt; # A tibble: 10 Ã— 4\n#&gt;      id  row0 three_groups three_in_each_group\n#&gt;   &lt;int&gt; &lt;dbl&gt;        &lt;dbl&gt;               &lt;dbl&gt;\n#&gt; 1     1     0            0                   0\n#&gt; 2     2     1            1                   0\n#&gt; 3     3     2            2                   0\n#&gt; 4     4     3            0                   1\n#&gt; 5     5     4            1                   1\n#&gt; 6     6     5            2                   1\n#&gt; # â„¹ 4 more rows\n\n\n13.5.2 Offsets\ndplyr::lead() and dplyr::lag() allow you to refer to the values just before or just after the â€œcurrentâ€ value.dplyr::lead() å’Œ dplyr::lag() å…è®¸ä½ å¼•ç”¨ â€œå½“å‰â€ å€¼ä¹‹å‰æˆ–ä¹‹åçš„å€¼ã€‚\nThey return a vector of the same length as the input, padded with NAs at the start or end:\nå®ƒä»¬è¿”å›ä¸€ä¸ªä¸è¾“å…¥é•¿åº¦ç›¸åŒçš„å‘é‡ï¼Œåœ¨å¼€å¤´æˆ–ç»“å°¾ç”¨ NA å¡«å……ï¼š\n\nx &lt;- c(2, 5, 11, 11, 19, 35)\nlag(x)\n#&gt; [1] NA  2  5 11 11 19\nlead(x)\n#&gt; [1]  5 11 11 19 35 NA\n\n\n\nx - lag(x) gives you the difference between the current and previous value.x - lag(x) ç»™å‡ºå½“å‰å€¼ä¸å‰ä¸€ä¸ªå€¼ä¹‹é—´çš„å·®å¼‚ã€‚\n\nx - lag(x)\n#&gt; [1] NA  3  6  0  8 16\n\n`\n\n\nx == lag(x) tells you when the current value changes.x == lag(x) å‘Šè¯‰ä½ å½“å‰å€¼ä½•æ—¶å‘ç”Ÿå˜åŒ–ã€‚\n\nx == lag(x)\n#&gt; [1]    NA FALSE FALSE  TRUE FALSE FALSE\n\n\n\nYou can lead or lag by more than one position by using the second argument, n.\nä½ å¯ä»¥é€šè¿‡ä½¿ç”¨ç¬¬äºŒä¸ªå‚æ•° n æ¥å‰å¯¼æˆ–æ»åè¶…è¿‡ä¸€ä¸ªä½ç½®ã€‚\n\n13.5.3 Consecutive identifiers\nSometimes you want to start a new group every time some event occurs.\næœ‰æ—¶ä½ å¸Œæœ›åœ¨æ¯æ¬¡æŸä¸ªäº‹ä»¶å‘ç”Ÿæ—¶å¼€å§‹ä¸€ä¸ªæ–°çš„ç»„ã€‚\nFor example, when youâ€™re looking at website data, itâ€™s common to want to break up events into sessions, where you begin a new session after a gap of more than x minutes since the last activity.\nä¾‹å¦‚ï¼Œåœ¨æŸ¥çœ‹ç½‘ç«™æ•°æ®æ—¶ï¼Œé€šå¸¸å¸Œæœ›å°†äº‹ä»¶åˆ†è§£ä¸ºä¼šè¯ (sessions)ï¼Œå³åœ¨è·ç¦»ä¸Šæ¬¡æ´»åŠ¨è¶…è¿‡ x åˆ†é’Ÿåå¼€å§‹ä¸€ä¸ªæ–°çš„ä¼šè¯ã€‚\nFor example, imagine you have the times when someone visited a website:\nä¾‹å¦‚ï¼Œå‡è®¾ä½ æœ‰ä¸€ä¸ªäººè®¿é—®ç½‘ç«™çš„æ—¶é—´è®°å½•ï¼š\n\nevents &lt;- tibble(\n  time = c(0, 1, 2, 3, 5, 10, 12, 15, 17, 19, 20, 27, 28, 30)\n)\n\nAnd youâ€™ve computed the time between each event, and figured out if thereâ€™s a gap thatâ€™s big enough to qualify:\nå¹¶ä¸”ä½ å·²ç»è®¡ç®—äº†æ¯ä¸ªäº‹ä»¶ä¹‹é—´çš„æ—¶é—´ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦å­˜åœ¨è¶³å¤Ÿå¤§çš„é—´éš”ï¼š\n\nevents &lt;- events |&gt; \n  mutate(\n    diff = time - lag(time, default = first(time)),\n    has_gap = diff &gt;= 5\n  )\nevents\n#&gt; # A tibble: 14 Ã— 3\n#&gt;    time  diff has_gap\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  \n#&gt; 1     0     0 FALSE  \n#&gt; 2     1     1 FALSE  \n#&gt; 3     2     1 FALSE  \n#&gt; 4     3     1 FALSE  \n#&gt; 5     5     2 FALSE  \n#&gt; 6    10     5 TRUE   \n#&gt; # â„¹ 8 more rows\n\nBut how do we go from that logical vector to something that we can group_by()?\nä½†æ˜¯æˆ‘ä»¬å¦‚ä½•ä»é‚£ä¸ªé€»è¾‘å‘é‡è½¬å˜ä¸ºå¯ä»¥ç”¨äº group_by() çš„ä¸œè¥¿å‘¢ï¼Ÿ\ncumsum(), from Section 13.4.7, comes to the rescue as gap, i.e.Â has_gap is TRUE, will increment group by one (Section 12.4.2):\næ¥è‡ª Section 13.4.7 çš„ cumsum() æ­¤æ—¶å°±æ´¾ä¸Šç”¨åœºäº†ï¼Œå› ä¸ºå½“é—´éš™å­˜åœ¨æ—¶ï¼Œå³ has_gap ä¸º TRUEï¼Œgroup å°†ä¼šåŠ ä¸€ (Section 12.4.2)ï¼š\n\nevents |&gt; mutate(\n  group = cumsum(has_gap)\n)\n#&gt; # A tibble: 14 Ã— 4\n#&gt;    time  diff has_gap group\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;   &lt;int&gt;\n#&gt; 1     0     0 FALSE       0\n#&gt; 2     1     1 FALSE       0\n#&gt; 3     2     1 FALSE       0\n#&gt; 4     3     1 FALSE       0\n#&gt; 5     5     2 FALSE       0\n#&gt; 6    10     5 TRUE        1\n#&gt; # â„¹ 8 more rows\n\nAnother approach for creating grouping variables is consecutive_id(), which starts a new group every time one of its arguments changes.\nå¦ä¸€ç§åˆ›å»ºåˆ†ç»„å˜é‡çš„æ–¹æ³•æ˜¯ consecutive_id()ï¼Œå®ƒåœ¨æ¯æ¬¡å…¶å‚æ•°ä¹‹ä¸€å‘ç”Ÿå˜åŒ–æ—¶å¼€å§‹ä¸€ä¸ªæ–°çš„ç»„ã€‚\nFor example, inspired by this stackoverflow question, imagine you have a data frame with a bunch of repeated values:\nä¾‹å¦‚ï¼Œå— è¿™ä¸ª stackoverflow é—®é¢˜ çš„å¯å‘ï¼Œæƒ³è±¡ä½ æœ‰ä¸€ä¸ªåŒ…å«è®¸å¤šé‡å¤å€¼çš„æ•°æ®æ¡†ï¼š\n\ndf &lt;- tibble(\n  x = c(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"d\", \"e\", \"a\", \"a\", \"b\", \"b\"),\n  y = c(1, 2, 3, 2, 4, 1, 3, 9, 4, 8, 10, 199)\n)\n\nIf you want to keep the first row from each repeated x, you could use group_by(), consecutive_id(), and slice_head():\nå¦‚æœä½ æƒ³ä¿ç•™æ¯ä¸ªé‡å¤ x çš„ç¬¬ä¸€è¡Œï¼Œä½ å¯ä»¥ä½¿ç”¨ group_by()ã€consecutive_id() å’Œ slice_head()ï¼š\n\ndf |&gt; \n  group_by(id = consecutive_id(x)) |&gt; \n  slice_head(n = 1)\n#&gt; # A tibble: 7 Ã— 3\n#&gt; # Groups:   id [7]\n#&gt;   x         y    id\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 a         1     1\n#&gt; 2 b         2     2\n#&gt; 3 c         4     3\n#&gt; 4 d         3     4\n#&gt; 5 e         9     5\n#&gt; 6 a         4     6\n#&gt; # â„¹ 1 more row\n\n\n13.5.4 Exercises\n\nFind the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank().\nWhich plane (tailnum) has the worst on-time record?\nWhat time of day should you fly if you want to avoid delays as much as possible?\nWhat does flights |&gt; group_by(dest) |&gt; filter(row_number() &lt; 4) do? What does flights |&gt; group_by(dest) |&gt; filter(row_number(dep_delay) &lt; 4) do?\nFor each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.\n\nDelays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag(), explore how the average flight delay for an hour is related to the average delay for the previous hour.\n\nflights |&gt; \n  mutate(hour = dep_time %/% 100) |&gt; \n  group_by(year, month, day, hour) |&gt; \n  summarize(\n    dep_delay = mean(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(n &gt; 5)\n\n\nLook at each destination. Can you find flights that are suspiciously fast (i.e.Â flights that represent a potential data entry error)? Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?\nFind all destinations that are flown by at least two carriers. Use those destinations to come up with a relative ranking of the carriers based on their performance for the same destination.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#numeric-summaries",
    "href": "numbers.html#numeric-summaries",
    "title": "13Â  Numbers",
    "section": "\n13.6 Numeric summaries",
    "text": "13.6 Numeric summaries\nJust using the counts, means, and sums that weâ€™ve introduced already can get you a long way, but R provides many other useful summary functions.\nä»…ä½¿ç”¨æˆ‘ä»¬å·²ç»ä»‹ç»è¿‡çš„è®¡æ•°ã€å‡å€¼å’Œæ€»å’Œå°±å¯ä»¥è®©ä½ èµ°å¾—å¾ˆè¿œï¼Œä½† R æä¾›äº†è®¸å¤šå…¶ä»–æœ‰ç”¨çš„æ‘˜è¦å‡½æ•°ã€‚\nHere is a selection that you might find useful.\nè¿™é‡Œæ˜¯ä¸€äº›ä½ å¯èƒ½ä¼šè§‰å¾—æœ‰ç”¨çš„é€‰æ‹©ã€‚\n\n13.6.1 Center\nSo far, weâ€™ve mostly used mean() to summarize the center of a vector of values.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸»è¦ä½¿ç”¨ mean() æ¥æ¦‚æ‹¬ä¸€ä¸ªæ•°å€¼å‘é‡çš„ä¸­å¿ƒã€‚\nAs weâ€™ve seen in Section 3.6, because the mean is the sum divided by the count, it is sensitive to even just a few unusually high or low values.\næ­£å¦‚æˆ‘ä»¬åœ¨ Section 3.6 ä¸­çœ‹åˆ°çš„ï¼Œå› ä¸ºå‡å€¼æ˜¯æ€»å’Œé™¤ä»¥è®¡æ•°ï¼Œæ‰€ä»¥å®ƒå¯¹å“ªæ€•æ˜¯å°‘æ•°å‡ ä¸ªå¼‚å¸¸é«˜æˆ–ä½çš„å€¼éƒ½å¾ˆæ•æ„Ÿã€‚\nAn alternative is to use the median(), which finds a value that lies in the â€œmiddleâ€ of the vector, i.e.Â 50% of the values are above it and 50% are below it.\nå¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ median()ï¼Œå®ƒä¼šæ‰¾åˆ°ä¸€ä¸ªä½äºå‘é‡â€œä¸­é—´â€çš„å€¼ï¼Œå³ 50% çš„å€¼åœ¨å®ƒä¹‹ä¸Šï¼Œ50% çš„å€¼åœ¨å®ƒä¹‹ä¸‹ã€‚\nDepending on the shape of the distribution of the variable youâ€™re interested in, mean or median might be a better measure of center.\næ ¹æ®ä½ æ‰€å…³å¿ƒå˜é‡çš„åˆ†å¸ƒå½¢çŠ¶ï¼Œå‡å€¼æˆ–ä¸­ä½æ•°å¯èƒ½æ˜¯æ›´å¥½çš„ä¸­å¿ƒåº¦é‡ã€‚\nFor example, for symmetric distributions we generally report the mean while for skewed distributions we usually report the median.\nä¾‹å¦‚ï¼Œå¯¹äºå¯¹ç§°åˆ†å¸ƒï¼Œæˆ‘ä»¬é€šå¸¸æŠ¥å‘Šå‡å€¼ï¼Œè€Œå¯¹äºåæ€åˆ†å¸ƒï¼Œæˆ‘ä»¬é€šå¸¸æŠ¥å‘Šä¸­ä½æ•°ã€‚\nFigureÂ 13.2 compares the mean vs.Â the median departure delay (in minutes) for each destination.FigureÂ 13.2 æ¯”è¾ƒäº†æ¯ä¸ªç›®çš„åœ°çš„å¹³å‡å‡ºå‘å»¶è¿Ÿï¼ˆåˆ†é’Ÿï¼‰ä¸ä¸­ä½æ•°å‡ºå‘å»¶è¿Ÿã€‚\nThe median delay is always smaller than the mean delay because flights sometimes leave multiple hours late, but never leave multiple hours early.\nä¸­ä½æ•°å»¶è¿Ÿæ€»æ˜¯å°äºå¹³å‡å»¶è¿Ÿï¼Œå› ä¸ºèˆªç­æœ‰æ—¶ä¼šæ™šç‚¹æ•°å°æ—¶ï¼Œä½†ä»ä¸ä¼šæå‰æ•°å°æ—¶å‡ºå‘ã€‚\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    mean = mean(dep_delay, na.rm = TRUE),\n    median = median(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  ggplot(aes(x = mean, y = median)) + \n  geom_abline(slope = 1, intercept = 0, color = \"white\", linewidth = 2) +\n  geom_point()\n\n\n\n\n\n\nFigureÂ 13.2: A scatterplot showing the differences of summarizing daily departure delay with median instead of mean.\n\n\n\n\nYou might also wonder about the mode, or the most common value.\nä½ å¯èƒ½è¿˜ä¼šæƒ³çŸ¥é“ä¼—æ•°ï¼Œå³æœ€å¸¸è§çš„å€¼ã€‚\nThis is a summary that only works well for very simple cases (which is why you might have learned about it in high school), but it doesnâ€™t work well for many real datasets.\nè¿™æ˜¯ä¸€ä¸ªåªåœ¨éå¸¸ç®€å•çš„æƒ…å†µä¸‹æ‰æœ‰æ•ˆçš„æ‘˜è¦ï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ å¯èƒ½åœ¨é«˜ä¸­å­¦è¿‡å®ƒï¼‰ï¼Œä½†å®ƒå¯¹è®¸å¤šçœŸå®æ•°æ®é›†æ•ˆæœä¸ä½³ã€‚\nIf the data is discrete, there may be multiple most common values, and if the data is continuous, there might be no most common value because every value is ever so slightly different.\nå¦‚æœæ•°æ®æ˜¯ç¦»æ•£çš„ï¼Œå¯èƒ½ä¼šæœ‰å¤šä¸ªæœ€å¸¸è§çš„å€¼ï¼›å¦‚æœæ•°æ®æ˜¯è¿ç»­çš„ï¼Œå¯èƒ½æ²¡æœ‰æœ€å¸¸è§çš„å€¼ï¼Œå› ä¸ºæ¯ä¸ªå€¼éƒ½ç•¥æœ‰ä¸åŒã€‚\nFor these reasons, the mode tends not to be used by statisticians and thereâ€™s no mode function included in base R2.\nç”±äºè¿™äº›åŸå› ï¼Œç»Ÿè®¡å­¦å®¶å€¾å‘äºä¸ä½¿ç”¨ä¼—æ•°ï¼Œå¹¶ä¸” base R ä¸­æ²¡æœ‰åŒ…å«ä¼—æ•°å‡½æ•°2ã€‚\n\n13.6.2 Minimum, maximum, and quantiles\nWhat if youâ€™re interested in locations other than the center?\nå¦‚æœä½ å¯¹ä¸­å¿ƒä»¥å¤–çš„ä½ç½®æ„Ÿå…´è¶£æ€ä¹ˆåŠï¼Ÿ\nmin() and max() will give you the largest and smallest values.min() å’Œ max() ä¼šç»™ä½ æœ€å¤§å€¼å’Œæœ€å°å€¼ã€‚\nAnother powerful tool is quantile() which is a generalization of the median: quantile(x, 0.25) will find the value of x that is greater than 25% of the values, quantile(x, 0.5) is equivalent to the median, and quantile(x, 0.95) will find the value thatâ€™s greater than 95% of the values.\nå¦ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·æ˜¯ quantile()ï¼Œå®ƒæ˜¯ä¸­ä½æ•°çš„æ¨å¹¿ï¼šquantile(x, 0.25) å°†æ‰¾åˆ° x ä¸­å¤§äº 25% å€¼çš„å€¼ï¼Œquantile(x, 0.5) ç­‰åŒäºä¸­ä½æ•°ï¼Œè€Œ quantile(x, 0.95) å°†æ‰¾åˆ°å¤§äº 95% å€¼çš„å€¼ã€‚\nFor the flights data, you might want to look at the 95% quantile of delays rather than the maximum, because it will ignore the 5% of most delayed flights which can be quite extreme.\nå¯¹äº flights æ•°æ®ï¼Œä½ å¯èƒ½æƒ³æŸ¥çœ‹å»¶è¿Ÿçš„ 95% åˆ†ä½æ•°è€Œä¸æ˜¯æœ€å¤§å€¼ï¼Œå› ä¸ºå®ƒä¼šå¿½ç•¥æœ€å»¶è¿Ÿçš„ 5% èˆªç­ï¼Œè¿™äº›èˆªç­å¯èƒ½éå¸¸æç«¯ã€‚\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    max = max(dep_delay, na.rm = TRUE),\n    q95 = quantile(dep_delay, 0.95, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 Ã— 5\n#&gt;    year month   day   max   q95\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2013     1     1   853  70.1\n#&gt; 2  2013     1     2   379  85  \n#&gt; 3  2013     1     3   291  68  \n#&gt; 4  2013     1     4   288  60  \n#&gt; 5  2013     1     5   327  41  \n#&gt; 6  2013     1     6   202  51  \n#&gt; # â„¹ 359 more rows\n\n\n13.6.3 Spread\nSometimes youâ€™re not so interested in where the bulk of the data lies, but in how it is spread out.\næœ‰æ—¶ä½ ä¸å¤ªå…³å¿ƒæ•°æ®çš„ä¸»ä½“åœ¨å“ªé‡Œï¼Œè€Œå…³å¿ƒå®ƒæ˜¯å¦‚ä½•åˆ†å¸ƒçš„ã€‚\nTwo commonly used summaries are the standard deviation, sd(x), and the inter-quartile range, IQR().\nä¸¤ä¸ªå¸¸ç”¨çš„æ‘˜è¦æ˜¯æ ‡å‡†å·® sd(x) å’Œå››åˆ†ä½è· IQR()ã€‚\nWe wonâ€™t explain sd() here since youâ€™re probably already familiar with it, but IQR() might be new â€” itâ€™s quantile(x, 0.75) - quantile(x, 0.25) and gives you the range that contains the middle 50% of the data.\næˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šè§£é‡Š sd()ï¼Œå› ä¸ºä½ å¯èƒ½å·²ç»ç†Ÿæ‚‰å®ƒäº†ï¼Œä½† IQR() å¯èƒ½å¯¹ä½ æ¥è¯´æ˜¯æ–°çš„â€”â€”å®ƒæ˜¯ quantile(x, 0.75) - quantile(x, 0.25)ï¼Œå¹¶ç»™å‡ºåŒ…å«ä¸­é—´ 50% æ•°æ®çš„èŒƒå›´ã€‚\nWe can use this to reveal a small oddity in the flights data.\næˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæ¥æ­ç¤º flights æ•°æ®ä¸­çš„ä¸€ä¸ªå°å°çš„å¥‡ç‰¹ä¹‹å¤„ã€‚\nYou might expect the spread of the distance between origin and destination to be zero, since airports are always in the same place.\nä½ å¯èƒ½æœŸæœ›å§‹å‘åœ°å’Œç›®çš„åœ°ä¹‹é—´è·ç¦»çš„ç¦»æ•£ç¨‹åº¦ä¸ºé›¶ï¼Œå› ä¸ºæœºåœºæ€»æ˜¯åœ¨åŒä¸€ä¸ªåœ°æ–¹ã€‚\nBut the code below reveals a data oddity for airport EGE:\nä½†æ˜¯ä¸‹é¢çš„ä»£ç æ­ç¤ºäº†å…³äº EGE æœºåœºçš„ä¸€ä¸ªæ•°æ®å¼‚å¸¸ï¼š\n\nflights |&gt; \n  group_by(origin, dest) |&gt; \n  summarize(\n    distance_iqr = IQR(distance), \n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(distance_iqr &gt; 0)\n#&gt; # A tibble: 2 Ã— 4\n#&gt;   origin dest  distance_iqr     n\n#&gt;   &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 EWR    EGE              1   110\n#&gt; 2 JFK    EGE              1   103\n\n\n13.6.4 Distributions\nItâ€™s worth remembering that all of the summary statistics described above are a way of reducing the distribution down to a single number.\nå€¼å¾—è®°ä½çš„æ˜¯ï¼Œä¸Šé¢æè¿°çš„æ‰€æœ‰æ‘˜è¦ç»Ÿè®¡é‡éƒ½æ˜¯å°†åˆ†å¸ƒç®€åŒ–ä¸ºå•ä¸ªæ•°å­—çš„ä¸€ç§æ–¹å¼ã€‚\nThis means that theyâ€™re fundamentally reductive, and if you pick the wrong summary, you can easily miss important differences between groups.\nè¿™æ„å‘³ç€å®ƒä»¬åœ¨æ ¹æœ¬ä¸Šæ˜¯ç®€åŒ–çš„ï¼Œå¦‚æœä½ é€‰æ‹©äº†é”™è¯¯çš„æ‘˜è¦ï¼Œä½ å¾ˆå®¹æ˜“ä¼šé”™è¿‡ç»„é—´çš„é‡è¦å·®å¼‚ã€‚\nThatâ€™s why itâ€™s always a good idea to visualize the distribution before committing to your summary statistics.\nè¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨ç¡®å®šä½ çš„æ‘˜è¦ç»Ÿè®¡æ•°æ®ä¹‹å‰ï¼Œå¯è§†åŒ–åˆ†å¸ƒæ€»æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚\nFigureÂ 13.3 shows the overall distribution of departure delays.FigureÂ 13.3 æ˜¾ç¤ºäº†å‡ºå‘å»¶è¯¯çš„æ€»ä½“åˆ†å¸ƒã€‚\nThe distribution is so skewed that we have to zoom in to see the bulk of the data.\nè¯¥åˆ†å¸ƒéå¸¸åæ–œï¼Œä»¥è‡³äºæˆ‘ä»¬å¿…é¡»æ”¾å¤§æ‰èƒ½çœ‹åˆ°æ•°æ®çš„ä¸»ä½“éƒ¨åˆ†ã€‚\nThis suggests that the mean is unlikely to be a good summary and we might prefer the median instead.\nè¿™è¡¨æ˜å‡å€¼ä¸å¤ªå¯èƒ½æ˜¯ä¸€ä¸ªå¥½çš„æ‘˜è¦ï¼Œæˆ‘ä»¬å¯èƒ½æ›´å€¾å‘äºä½¿ç”¨ä¸­ä½æ•°ã€‚\n\n\n\n\n\n\n\nFigureÂ 13.3: (Left) The histogram of the full data is extremely skewed making it hard to get any details. (Right) Zooming into delays of less than two hours makes it possible to see whatâ€™s happening with the bulk of the observations.\n\n\n\n\nItâ€™s also a good idea to check that distributions for subgroups resemble the whole.\næ£€æŸ¥å­ç»„çš„åˆ†å¸ƒæ˜¯å¦ä¸æ•´ä½“ç›¸ä¼¼ä¹Ÿæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚\nIn the following plot 365 frequency polygons of dep_delay, one for each day, are overlaid.\nåœ¨ä¸‹é¢çš„å›¾ä¸­ï¼Œå åŠ äº† 365 ä¸ª dep_delay çš„é¢‘ç‡å¤šè¾¹å½¢ï¼Œæ¯å¤©ä¸€ä¸ªã€‚\nThe distributions seem to follow a common pattern, suggesting itâ€™s fine to use the same summary for each day.\nè¿™äº›åˆ†å¸ƒä¼¼ä¹éµå¾ªä¸€ä¸ªå…±åŒçš„æ¨¡å¼ï¼Œè¿™è¡¨æ˜æ¯å¤©ä½¿ç”¨ç›¸åŒçš„æ‘˜è¦æ˜¯å¯ä»¥çš„ã€‚\n\nflights |&gt;\n  filter(dep_delay &lt; 120) |&gt; \n  ggplot(aes(x = dep_delay, group = interaction(day, month))) + \n  geom_freqpoly(binwidth = 5, alpha = 1/5)\n\n\n\n\n\n\n\nDonâ€™t be afraid to explore your own custom summaries specifically tailored for the data that youâ€™re working with.\nä¸è¦å®³æ€•æ¢ç´¢ä¸ºä½ æ­£åœ¨å¤„ç†çš„æ•°æ®é‡èº«å®šåˆ¶çš„è‡ªå®šä¹‰æ‘˜è¦ã€‚\nIn this case, that might mean separately summarizing the flights that left early vs.Â the flights that left late, or given that the values are so heavily skewed, you might try a log-transformation.\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™å¯èƒ½æ„å‘³ç€åˆ†åˆ«æ€»ç»“æå‰èµ·é£çš„èˆªç­å’Œæ™šç‚¹èµ·é£çš„èˆªç­ï¼Œæˆ–è€…é‰´äºæ•°å€¼åæ–œä¸¥é‡ï¼Œä½ å¯ä»¥å°è¯•è¿›è¡Œå¯¹æ•°è½¬æ¢ã€‚\nFinally, donâ€™t forget what you learned in Section 3.6: whenever creating numerical summaries, itâ€™s a good idea to include the number of observations in each group.\næœ€åï¼Œåˆ«å¿˜äº†ä½ åœ¨ Section 3.6 ä¸­å­¦åˆ°çš„ï¼šæ¯å½“åˆ›å»ºæ•°å€¼æ‘˜è¦æ—¶ï¼Œæœ€å¥½åŒ…å«æ¯ä¸ªç»„ä¸­çš„è§‚æµ‹æ•°é‡ã€‚\n\n13.6.5 Positions\nThereâ€™s one final type of summary thatâ€™s useful for numeric vectors, but also works with every other type of value: extracting a value at a specific position: first(x), last(x), and nth(x, n).\nè¿˜æœ‰æœ€åä¸€ç§å¯¹æ•°å€¼å‘é‡å¾ˆæœ‰ç”¨ï¼Œä½†ä¹Ÿé€‚ç”¨äºæ‰€æœ‰å…¶ä»–ç±»å‹å€¼çš„æ‘˜è¦ï¼šæå–ç‰¹å®šä½ç½®çš„å€¼ï¼šfirst(x)ã€last(x) å’Œ nth(x, n)ã€‚\nFor example, we can find the first, fifth and last departure for each day:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°æ¯å¤©çš„ç¬¬ä¸€æ¬¡ã€ç¬¬äº”æ¬¡å’Œæœ€åä¸€æ¬¡å‡ºå‘ï¼š\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    first_dep = first(dep_time, na_rm = TRUE), \n    fifth_dep = nth(dep_time, 5, na_rm = TRUE),\n    last_dep = last(dep_time, na_rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n#&gt; # A tibble: 365 Ã— 6\n#&gt; # Groups:   year, month [12]\n#&gt;    year month   day first_dep fifth_dep last_dep\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt;     &lt;int&gt;    &lt;int&gt;\n#&gt; 1  2013     1     1       517       554     2356\n#&gt; 2  2013     1     2        42       535     2354\n#&gt; 3  2013     1     3        32       520     2349\n#&gt; 4  2013     1     4        25       531     2358\n#&gt; 5  2013     1     5        14       534     2357\n#&gt; 6  2013     1     6        16       555     2355\n#&gt; # â„¹ 359 more rows\n\n(NB: Because dplyr functions use _ to separate components of function and arguments names, these functions use na_rm instead of na.rm.)\nï¼ˆæ³¨æ„ï¼šå› ä¸º dplyr å‡½æ•°ä½¿ç”¨ _ æ¥åˆ†éš”å‡½æ•°å’Œå‚æ•°åç§°çš„ç»„æˆéƒ¨åˆ†ï¼Œæ‰€ä»¥è¿™äº›å‡½æ•°ä½¿ç”¨ na_rm è€Œä¸æ˜¯ na.rmã€‚ï¼‰\nIf youâ€™re familiar with [, which weâ€™ll come back to in Section 27.2, you might wonder if you ever need these functions.\nå¦‚æœä½ ç†Ÿæ‚‰ [ï¼ˆæˆ‘ä»¬å°†åœ¨ Section 27.2 ä¸­å›è¿‡å¤´æ¥è®¨è®ºï¼‰ï¼Œä½ å¯èƒ½ä¼šæƒ³çŸ¥é“ä½ æ˜¯å¦çœŸçš„éœ€è¦è¿™äº›å‡½æ•°ã€‚\nThere are three reasons: the default argument allows you to provide a default if the specified position doesnâ€™t exist, the order_by argument allows you to locally override the order of the rows, and the na_rm argument allows you to drop missing values.\næœ‰ä¸‰ä¸ªåŸå› ï¼šdefault å‚æ•°å…è®¸ä½ åœ¨æŒ‡å®šä½ç½®ä¸å­˜åœ¨æ—¶æä¾›ä¸€ä¸ªé»˜è®¤å€¼ï¼Œorder_by å‚æ•°å…è®¸ä½ å±€éƒ¨è¦†ç›–è¡Œçš„é¡ºåºï¼Œè€Œ na_rm å‚æ•°å…è®¸ä½ åˆ é™¤ç¼ºå¤±å€¼ã€‚\nExtracting values at positions is complementary to filtering on ranks.\næŒ‰ä½ç½®æå–å€¼ä¸æŒ‰æ’åç­›é€‰æ˜¯äº’è¡¥çš„ã€‚\nFiltering gives you all variables, with each observation in a separate row:\nç­›é€‰ä¼šç»™ä½ æ‰€æœ‰å˜é‡ï¼Œæ¯ä¸ªè§‚æµ‹å€¼å ä¸€è¡Œï¼š\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  mutate(r = min_rank(sched_dep_time)) |&gt; \n  filter(r %in% c(1, max(r)))\n#&gt; # A tibble: 1,195 Ã— 20\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1     2353           2359        -6      425            445\n#&gt; 3  2013     1     1     2353           2359        -6      418            442\n#&gt; 4  2013     1     1     2356           2359        -3      425            437\n#&gt; 5  2013     1     2       42           2359        43      518            442\n#&gt; 6  2013     1     2      458            500        -2      703            650\n#&gt; # â„¹ 1,189 more rows\n#&gt; # â„¹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, â€¦\n\n\n13.6.6 With mutate()\n\nAs the names suggest, the summary functions are typically paired with summarize().\næ­£å¦‚å…¶åï¼Œæ‘˜è¦å‡½æ•°é€šå¸¸ä¸ summarize() é…å¯¹ä½¿ç”¨ã€‚\nHowever, because of the recycling rules we discussed in Section 13.4.1 they can also be usefully paired with mutate(), particularly when you want do some sort of group standardization.\nç„¶è€Œï¼Œç”±äºæˆ‘ä»¬åœ¨ Section 13.4.1 ä¸­è®¨è®ºçš„å¾ªç¯è§„åˆ™ï¼Œå®ƒä»¬ä¹Ÿå¯ä»¥ä¸ mutate() æœ‰æ•ˆåœ°é…å¯¹ï¼Œç‰¹åˆ«æ˜¯å½“ä½ æƒ³è¦è¿›è¡ŒæŸç§åˆ†ç»„æ ‡å‡†åŒ–æ—¶ã€‚\nFor example:\nä¾‹å¦‚ï¼š\n\nx / sum(x) calculates the proportion of a total.x / sum(x) è®¡ç®—å æ€»æ•°çš„æ¯”ä¾‹ã€‚\n(x - mean(x)) / sd(x) computes a Z-score (standardized to mean 0 and sd 1).(x - mean(x)) / sd(x) è®¡ç®—ä¸€ä¸ª Z åˆ†æ•°ï¼ˆæ ‡å‡†åŒ–ä¸ºå‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ï¼‰ã€‚\n(x - min(x)) / (max(x) - min(x)) standardizes to range [0, 1].(x - min(x)) / (max(x) - min(x)) å°†æ•°æ®æ ‡å‡†åŒ–åˆ° [0, 1] èŒƒå›´ã€‚\nx / first(x) computes an index based on the first observation.x / first(x) æ ¹æ®ç¬¬ä¸€ä¸ªè§‚æµ‹å€¼è®¡ç®—ä¸€ä¸ªæŒ‡æ•°ã€‚\n\n13.6.7 Exercises\n\nBrainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. When is mean() useful? When is median() useful? When might you want to use something else? Should you use arrival delay or departure delay? Why might you want to use data from planes?\nWhich destinations show the greatest variation in air speed?\nCreate a plot to further explore the adventures of EGE. Can you find any evidence that the airport moved locations? Can you find another variable that might explain the difference?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#summary",
    "href": "numbers.html#summary",
    "title": "13Â  Numbers",
    "section": "\n13.7 Summary",
    "text": "13.7 Summary\nYouâ€™re already familiar with many tools for working with numbers, and after reading this chapter you now know how to use them in R.\nä½ å·²ç»ç†Ÿæ‚‰è®¸å¤šå¤„ç†æ•°å­—çš„å·¥å…·ï¼Œåœ¨é˜…è¯»æœ¬ç« åï¼Œä½ ç°åœ¨çŸ¥é“å¦‚ä½•åœ¨ R ä¸­ä½¿ç”¨å®ƒä»¬äº†ã€‚\nYouâ€™ve also learned a handful of useful general transformations that are commonly, but not exclusively, applied to numeric vectors like ranks and offsets.\nä½ è¿˜å­¦åˆ°äº†ä¸€äº›æœ‰ç”¨çš„é€šç”¨è½¬æ¢ï¼Œå®ƒä»¬é€šå¸¸ï¼ˆä½†éå”¯ä¸€ï¼‰åº”ç”¨äºåƒæ’åå’Œåç§»é‡è¿™æ ·çš„æ•°å€¼å‘é‡ã€‚\nFinally, you worked through a number of numeric summaries, and discussed a few of the statistical challenges that you should consider.\næœ€åï¼Œä½ å­¦ä¹ äº†ä¸€äº›æ•°å€¼æ‘˜è¦ï¼Œå¹¶è®¨è®ºäº†ä¸€äº›ä½ åº”è¯¥è€ƒè™‘çš„ç»Ÿè®¡æŒ‘æˆ˜ã€‚\nOver the next two chapters, weâ€™ll dive into working with strings with the stringr package.\nåœ¨æ¥ä¸‹æ¥çš„ä¸¤ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ä½¿ç”¨ stringr åŒ…å¤„ç†å­—ç¬¦ä¸²ã€‚\nStrings are a big topic so they get two chapters, one on the fundamentals of strings and one on regular expressions.\nå­—ç¬¦ä¸²æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ä¸»é¢˜ï¼Œæ‰€ä»¥å®ƒä»¬æœ‰ä¸¤ç« çš„ç¯‡å¹…ï¼Œä¸€ç« å…³äºå­—ç¬¦ä¸²çš„åŸºç¡€çŸ¥è¯†ï¼Œå¦ä¸€ç« å…³äºæ­£åˆ™è¡¨è¾¾å¼ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "numbers.html#footnotes",
    "href": "numbers.html#footnotes",
    "title": "13Â  Numbers",
    "section": "",
    "text": "ggplot2 provides some helpers for common cases in cut_interval(), cut_number(), and cut_width(). ggplot2 is an admittedly weird place for these functions to live, but they are useful as part of histogram computation and were written before any other parts of the tidyverse existed.â†©ï¸\nThe mode() function does something quite different!â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Numbers</span>"
    ]
  },
  {
    "objectID": "strings.html",
    "href": "strings.html",
    "title": "14Â  Strings",
    "section": "",
    "text": "14.1 Introduction\nSo far, youâ€™ve used a bunch of strings without learning much about the details. Now itâ€™s time to dive into them, learn what makes strings tick, and master some of the powerful string manipulation tools you have at your disposal.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»ä½¿ç”¨äº†å¾ˆå¤šå­—ç¬¦ä¸²ï¼Œä½†æ²¡æœ‰å­¦ä¹ å¤ªå¤šç»†èŠ‚ã€‚ç°åœ¨æ˜¯æ—¶å€™æ·±å…¥ç ”ç©¶å®ƒä»¬ï¼Œäº†è§£å­—ç¬¦ä¸²çš„å·¥ä½œåŸç†ï¼Œå¹¶æŒæ¡ä¸€äº›ä½ å¯ä»¥ä½¿ç”¨çš„å¼ºå¤§å­—ç¬¦ä¸²æ“ä½œå·¥å…·äº†ã€‚\nWeâ€™ll begin with the details of creating strings and character vectors. Youâ€™ll then dive into creating strings from data, then the opposite: extracting strings from data. Weâ€™ll then discuss tools that work with individual letters. The chapter finishes with functions that work with individual letters and a brief discussion of where your expectations from English might steer you wrong when working with other languages.\næˆ‘ä»¬å°†ä»åˆ›å»ºå­—ç¬¦ä¸²å’Œå­—ç¬¦å‘é‡çš„ç»†èŠ‚å¼€å§‹ã€‚ç„¶åä½ å°†æ·±å…¥å­¦ä¹ å¦‚ä½•ä»æ•°æ®åˆ›å»ºå­—ç¬¦ä¸²ï¼Œä»¥åŠåè¿‡æ¥ï¼šä»æ•°æ®ä¸­æå–å­—ç¬¦ä¸²ã€‚æ¥ç€æˆ‘ä»¬å°†è®¨è®ºå¤„ç†å•ä¸ªå­—æ¯çš„å·¥å…·ã€‚æœ¬ç« æœ€åä¼šä»‹ç»å¤„ç†å•ä¸ªå­—æ¯çš„å‡½æ•°ï¼Œå¹¶ç®€è¦è®¨è®ºåœ¨å¤„ç†å…¶ä»–è¯­è¨€æ—¶ï¼Œä½ åŸºäºè‹±è¯­çš„é¢„æœŸå¯èƒ½ä¼šå¦‚ä½•è¯¯å¯¼ä½ ã€‚\nWeâ€™ll keep working with strings in the next chapter, where youâ€™ll learn more about the power of regular expressions.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­å­¦ä¹ å­—ç¬¦ä¸²ï¼Œå±Šæ—¶ä½ å°†äº†è§£æ›´å¤šå…³äºæ­£åˆ™è¡¨è¾¾å¼ (regular expressions) çš„å¼ºå¤§åŠŸèƒ½ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#introduction",
    "href": "strings.html#introduction",
    "title": "14Â  Strings",
    "section": "",
    "text": "14.1.1 Prerequisites\nIn this chapter, weâ€™ll use functions from the stringr package, which is part of the core tidyverse. Weâ€™ll also use the babynames data since it provides some fun strings to manipulate.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ stringr åŒ…ä¸­çš„å‡½æ•°ï¼Œå®ƒæ˜¯æ ¸å¿ƒ tidyverse çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬è¿˜å°†ä½¿ç”¨ babynames æ•°æ®ï¼Œå› ä¸ºå®ƒæä¾›äº†ä¸€äº›æœ‰è¶£çš„å­—ç¬¦ä¸²å¯ä¾›æ“ä½œã€‚\n\nlibrary(tidyverse)\nlibrary(babynames)\n\nYou can quickly tell when youâ€™re using a stringr function because all stringr functions start with str_. This is particularly useful if you use RStudio because typing str_ will trigger autocomplete, allowing you to jog your memory of the available functions.\nä½ å¯ä»¥å¾ˆå¿«åˆ¤æ–­å‡ºä½ æ­£åœ¨ä½¿ç”¨çš„æ˜¯ stringr å‡½æ•°ï¼Œå› ä¸ºæ‰€æœ‰çš„ stringr å‡½æ•°éƒ½ä»¥ str_ å¼€å¤´ã€‚å¦‚æœä½ ä½¿ç”¨ RStudioï¼Œè¿™ä¸€ç‚¹ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºè¾“å…¥ str_ ä¼šè§¦å‘è‡ªåŠ¨è¡¥å…¨ï¼Œä»è€Œå¸®åŠ©ä½ è®°èµ·å¯ç”¨çš„å‡½æ•°ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#creating-a-string",
    "href": "strings.html#creating-a-string",
    "title": "14Â  Strings",
    "section": "\n14.2 Creating a string",
    "text": "14.2 Creating a string\nWeâ€™ve created strings in passing earlier in the book but didnâ€™t discuss the details. Firstly, you can create a string using either single quotes (') or double quotes (\"). Thereâ€™s no difference in behavior between the two, so in the interests of consistency, the tidyverse style guide recommends using \", unless the string contains multiple \".\nåœ¨æœ¬ä¹¦å‰é¢éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä¸ç»æ„é—´åˆ›å»ºäº†å­—ç¬¦ä¸²ï¼Œä½†æ²¡æœ‰è®¨è®ºç»†èŠ‚ã€‚é¦–å…ˆï¼Œä½ å¯ä»¥ä½¿ç”¨å•å¼•å· (') æˆ–åŒå¼•å· (\") æ¥åˆ›å»ºå­—ç¬¦ä¸²ã€‚ä¸¤è€…åœ¨è¡Œä¸ºä¸Šæ²¡æœ‰åŒºåˆ«ï¼Œå› æ­¤ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œtidyverse é£æ ¼æŒ‡å— å»ºè®®ä½¿ç”¨ \"ï¼Œé™¤éå­—ç¬¦ä¸²æœ¬èº«åŒ…å«å¤šä¸ª \"ã€‚\n\nstring1 &lt;- \"This is a string\"\nstring2 &lt;- 'If I want to include a \"quote\" inside a string, I use single quotes'\n\nIf you forget to close a quote, youâ€™ll see +, the continuation prompt:\nå¦‚æœä½ å¿˜è®°å…³é—­å¼•å·ï¼Œä½ ä¼šçœ‹åˆ° +ï¼Œå³ç»­è¡Œæç¤ºç¬¦ï¼š\n&gt; \"This is a string without a closing quote\n+ \n+ \n+ HELP I'M STUCK IN A STRING\nIf this happens to you and you canâ€™t figure out which quote to close, press Escape to cancel and try again.\nå¦‚æœä½ é‡åˆ°è¿™ç§æƒ…å†µï¼Œå¹¶ä¸”ä¸çŸ¥é“è¯¥å…³é—­å“ªä¸ªå¼•å·ï¼Œè¯·æŒ‰ Escape é”®å–æ¶ˆå¹¶é‡è¯•ã€‚\n\n14.2.1 Escapes\nTo include a literal single or double quote in a string, you can use \\ to â€œescapeâ€ it:\nè¦åœ¨å­—ç¬¦ä¸²ä¸­åŒ…å«å­—é¢ä¸Šçš„å•å¼•å·æˆ–åŒå¼•å·ï¼Œä½ å¯ä»¥ä½¿ç”¨ \\ æ¥â€œè½¬ä¹‰â€å®ƒï¼š\n\ndouble_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\"\n\nSo if you want to include a literal backslash in your string, youâ€™ll need to escape it: \"\\\\\":\nå› æ­¤ï¼Œå¦‚æœä½ æƒ³åœ¨å­—ç¬¦ä¸²ä¸­åŒ…å«ä¸€ä¸ªå­—é¢ä¸Šçš„åæ–œæ ï¼Œä½ éœ€è¦å¯¹å®ƒè¿›è¡Œè½¬ä¹‰ï¼š\"\\\\\"ï¼š\n\nbackslash &lt;- \"\\\\\"\n\nBeware that the printed representation of a string is not the same as the string itself because the printed representation shows the escapes (in other words, when you print a string, you can copy and paste the output to recreate that string). To see the raw contents of the string, use str_view()1:\næ³¨æ„ï¼Œå­—ç¬¦ä¸²çš„æ‰“å°è¡¨ç¤ºå½¢å¼ä¸å­—ç¬¦ä¸²æœ¬èº«å¹¶ä¸ç›¸åŒï¼Œå› ä¸ºæ‰“å°è¡¨ç¤ºå½¢å¼ä¼šæ˜¾ç¤ºè½¬ä¹‰å­—ç¬¦ï¼ˆæ¢å¥è¯è¯´ï¼Œå½“ä½ æ‰“å°ä¸€ä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œä½ å¯ä»¥å¤åˆ¶å¹¶ç²˜è´´è¾“å‡ºæ¥é‡æ–°åˆ›å»ºè¯¥å­—ç¬¦ä¸²ï¼‰ã€‚è¦æŸ¥çœ‹å­—ç¬¦ä¸²çš„åŸå§‹å†…å®¹ï¼Œè¯·ä½¿ç”¨ str_view()1ï¼š\n\nx &lt;- c(single_quote, double_quote, backslash)\nx\n#&gt; [1] \"'\"  \"\\\"\" \"\\\\\"\nstr_view(x)\n#&gt; [1] â”‚ '\n#&gt; [2] â”‚ \"\n#&gt; [3] â”‚ \\\n\n\n14.2.2 Raw strings\nCreating a string with multiple quotes or backslashes gets confusing quickly. To illustrate the problem, letâ€™s create a string that contains the contents of the code block where we define the double_quote and single_quote variables:\nåˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªå¼•å·æˆ–åæ–œæ çš„å­—ç¬¦ä¸²å¾ˆå¿«å°±ä¼šå˜å¾—æ··ä¹±ã€‚ä¸ºäº†è¯´æ˜è¿™ä¸ªé—®é¢˜ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå®ƒåŒ…å«æˆ‘ä»¬å®šä¹‰ double_quote å’Œ single_quote å˜é‡çš„ä»£ç å—çš„å†…å®¹ï¼š\n\ntricky &lt;- \"double_quote &lt;- \\\"\\\\\\\"\\\" # or '\\\"'\nsingle_quote &lt;- '\\\\'' # or \\\"'\\\"\"\nstr_view(tricky)\n#&gt; [1] â”‚ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     â”‚ single_quote &lt;- '\\'' # or \"'\"\n\nThatâ€™s a lot of backslashes! (This is sometimes called leaning toothpick syndrome.) To eliminate the escaping, you can instead use a raw string2:\nè¿™é‡Œæœ‰å¤ªå¤šçš„åæ–œæ äº†ï¼ï¼ˆè¿™æœ‰æ—¶è¢«ç§°ä¸ºâ€œæ–œæ ç‰™ç­¾ç»¼åˆç—‡â€ (leaning toothpick syndrome)ï¼‰ã€‚ä¸ºäº†æ¶ˆé™¤è½¬ä¹‰ï¼Œä½ å¯ä»¥æ”¹ç”¨åŸå§‹å­—ç¬¦ä¸² (raw string)2ï¼š\n\ntricky &lt;- r\"(double_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\")\"\nstr_view(tricky)\n#&gt; [1] â”‚ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     â”‚ single_quote &lt;- '\\'' # or \"'\"\n\nA raw string usually starts with r\"( and finishes with )\". But if your string contains )\" you can instead use r\"[]\" or r\"{}\", and if thatâ€™s still not enough, you can insert any number of dashes to make the opening and closing pairs unique, e.g., r\"--()--\", r\"---()---\", etc. Raw strings are flexible enough to handle any text.\nåŸå§‹å­—ç¬¦ä¸²é€šå¸¸ä»¥ r\"( å¼€å§‹ï¼Œä»¥ )\" ç»“æŸã€‚ä½†æ˜¯ï¼Œå¦‚æœä½ çš„å­—ç¬¦ä¸²åŒ…å« )\"ï¼Œä½ å¯ä»¥æ”¹ç”¨ r\"[]\" æˆ– r\"{}\"ï¼Œå¦‚æœè¿™è¿˜ä¸å¤Ÿï¼Œä½ å¯ä»¥æ’å…¥ä»»æ„æ•°é‡çš„ç ´æŠ˜å·æ¥ä½¿å¼€å§‹å’Œç»“æŸå¯¹å”¯ä¸€ï¼Œä¾‹å¦‚ r\"--()--\"ã€r\"---()---\" ç­‰ã€‚åŸå§‹å­—ç¬¦ä¸²è¶³å¤Ÿçµæ´»ï¼Œå¯ä»¥å¤„ç†ä»»ä½•æ–‡æœ¬ã€‚\n\n14.2.3 Other special characters\nAs well as \\\", \\', and \\\\, there are a handful of other special characters that may come in handy. The most common are \\n, a new line, and \\t, tab. Youâ€™ll also sometimes see strings containing Unicode escapes that start with \\u or \\U. This is a way of writing non-English characters that work on all systems. You can see the complete list of other special characters in ?Quotes.\né™¤äº† \\\"ã€\\' å’Œ \\\\ï¼Œè¿˜æœ‰ä¸€äº›å…¶ä»–å¯èƒ½æ´¾ä¸Šç”¨åœºçš„ç‰¹æ®Šå­—ç¬¦ã€‚æœ€å¸¸è§çš„æ˜¯ \\nï¼ˆæ¢è¡Œç¬¦ï¼‰å’Œ \\tï¼ˆåˆ¶è¡¨ç¬¦ï¼‰ã€‚ä½ æœ‰æ—¶ä¹Ÿä¼šçœ‹åˆ°åŒ…å«ä»¥ \\u æˆ– \\U å¼€å¤´çš„ Unicode è½¬ä¹‰åºåˆ—çš„å­—ç¬¦ä¸²ã€‚è¿™æ˜¯ä¸€ç§åœ¨æ‰€æœ‰ç³»ç»Ÿä¸Šéƒ½èƒ½æ­£å¸¸å·¥ä½œçš„éè‹±æ–‡å­—ç¬¦çš„ä¹¦å†™æ–¹å¼ã€‚ä½ å¯ä»¥åœ¨ ?Quotes ä¸­çœ‹åˆ°å…¶ä»–ç‰¹æ®Šå­—ç¬¦çš„å®Œæ•´åˆ—è¡¨ã€‚\n\nx &lt;- c(\"one\\ntwo\", \"one\\ttwo\", \"\\u00b5\", \"\\U0001f604\")\nx\n#&gt; [1] \"one\\ntwo\" \"one\\ttwo\" \"Âµ\"        \"ğŸ˜„\"\nstr_view(x)\n#&gt; [1] â”‚ one\n#&gt;     â”‚ two\n#&gt; [2] â”‚ one{\\t}two\n#&gt; [3] â”‚ Âµ\n#&gt; [4] â”‚ ğŸ˜„\n\nNote that str_view() uses curly braces for tabs to make them easier to spot3. One of the challenges of working with text is that thereâ€™s a variety of ways that white space can end up in the text, so this background helps you recognize that something strange is going on.\nè¯·æ³¨æ„ str_view() å¯¹åˆ¶è¡¨ç¬¦ä½¿ç”¨èŠ±æ‹¬å·ï¼Œä»¥ä¾¿æ›´å®¹æ˜“å‘ç°å®ƒä»¬3ã€‚å¤„ç†æ–‡æœ¬çš„æŒ‘æˆ˜ä¹‹ä¸€æ˜¯ï¼Œç©ºç™½å­—ç¬¦ (white space) å¯èƒ½ä»¥å¤šç§æ–¹å¼å‡ºç°åœ¨æ–‡æœ¬ä¸­ï¼Œæ‰€ä»¥è¿™ä¸ªèƒŒæ™¯çŸ¥è¯†å¯ä»¥å¸®åŠ©ä½ è¯†åˆ«å‡ºæ˜¯å¦å‘ç”Ÿäº†å¼‚å¸¸æƒ…å†µã€‚\n\n14.2.4 Exercises\n\n\nCreate strings that contain the following values:\n\nHe said \"That's amazing!\"\n\\a\\b\\c\\d\n\\\\\\\\\\\\\n\n\n\nCreate the string in your R session and print it. What happens to the special â€œ\\u00a0â€? How does str_view() display it? Can you do a little googling to figure out what this special character is?\n{r}     x &lt;- \"This\\u00a0is\\u00a0tricky\"",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#creating-many-strings-from-data",
    "href": "strings.html#creating-many-strings-from-data",
    "title": "14Â  Strings",
    "section": "\n14.3 Creating many strings from data",
    "text": "14.3 Creating many strings from data\nNow that youâ€™ve learned the basics of creating a string or two by â€œhandâ€, weâ€™ll go into the details of creating strings from other strings. This will help you solve the common problem where you have some text you wrote that you want to combine with strings from a data frame. For example, you might combine â€œHelloâ€ with a name variable to create a greeting. Weâ€™ll show you how to do this with str_c() and str_glue() and how you can use them with mutate(). That naturally raises the question of what stringr functions you might use with summarize(), so weâ€™ll finish this section with a discussion of str_flatten(), which is a summary function for strings.\nç°åœ¨ä½ å·²ç»å­¦ä¼šäº†å¦‚ä½•â€œæ‰‹åŠ¨â€åˆ›å»ºä¸€ä¸¤ä¸ªå­—ç¬¦ä¸²çš„åŸºç¡€çŸ¥è¯†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦‚ä½•ä»å…¶ä»–å­—ç¬¦ä¸²åˆ›å»ºå­—ç¬¦ä¸²ã€‚è¿™å°†å¸®åŠ©ä½ è§£å†³ä¸€ä¸ªå¸¸è§é—®é¢˜ï¼šä½ æœ‰ä¸€äº›è‡ªå·±ç¼–å†™çš„æ–‡æœ¬ï¼Œå¹¶å¸Œæœ›å°†å…¶ä¸æ•°æ®æ¡†ä¸­çš„å­—ç¬¦ä¸²ç»“åˆèµ·æ¥ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½æƒ³å°† â€œHelloâ€ ä¸ä¸€ä¸ª name å˜é‡ç»“åˆèµ·æ¥åˆ›å»ºä¸€ä¸ªé—®å€™è¯­ã€‚æˆ‘ä»¬å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨ str_c() å’Œ str_glue() æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä»¥åŠå¦‚ä½•å°†å®ƒä»¬ä¸ mutate() ä¸€èµ·ä½¿ç”¨ã€‚è¿™è‡ªç„¶å¼•å‡ºäº†ä¸€ä¸ªé—®é¢˜ï¼šä½ å¯ä»¥å°†å“ªäº› stringr å‡½æ•°ä¸ summarize() ä¸€èµ·ä½¿ç”¨ï¼Ÿå› æ­¤ï¼Œæœ¬èŠ‚æœ€åå°†è®¨è®º str_flatten()ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå­—ç¬¦ä¸²çš„æ±‡æ€»å‡½æ•°ã€‚\n\n14.3.1 str_c()\n\nstr_c() takes any number of vectors as arguments and returns a character vector:str_c() æ¥å—ä»»æ„æ•°é‡çš„å‘é‡ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦å‘é‡ï¼š\n\nstr_c(\"x\", \"y\")\n#&gt; [1] \"xy\"\nstr_c(\"x\", \"y\", \"z\")\n#&gt; [1] \"xyz\"\nstr_c(\"Hello \", c(\"John\", \"Susan\"))\n#&gt; [1] \"Hello John\"  \"Hello Susan\"\n\nstr_c() is very similar to the base paste0(), but is designed to be used with mutate() by obeying the usual tidyverse rules for recycling and propagating missing values:str_c() ä¸åŸºç¡€å‡½æ•° paste0() éå¸¸ç›¸ä¼¼ï¼Œä½†å®ƒéµå¾ª tidyverse é€šå¸¸çš„å›æ”¶è§„åˆ™å’Œç¼ºå¤±å€¼ä¼ æ’­è§„åˆ™ï¼Œå› æ­¤è¢«è®¾è®¡ä¸ºä¸ mutate() ä¸€èµ·ä½¿ç”¨ï¼š\n\ndf &lt;- tibble(name = c(\"Flora\", \"David\", \"Terra\", NA))\ndf |&gt; mutate(greeting = str_c(\"Hi \", name, \"!\"))\n#&gt; # A tibble: 4 Ã— 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  &lt;NA&gt;\n\nIf you want missing values to display in another way, use coalesce() to replace them. Depending on what you want, you might use it either inside or outside of str_c():\nå¦‚æœä½ æƒ³è®©ç¼ºå¤±å€¼ä»¥å…¶ä»–æ–¹å¼æ˜¾ç¤ºï¼Œå¯ä»¥ä½¿ç”¨ coalesce() æ¥æ›¿æ¢å®ƒä»¬ã€‚æ ¹æ®ä½ çš„éœ€æ±‚ï¼Œä½ å¯ä»¥åœ¨ str_c() å†…éƒ¨æˆ–å¤–éƒ¨ä½¿ç”¨å®ƒï¼š\n\ndf |&gt; \n  mutate(\n    greeting1 = str_c(\"Hi \", coalesce(name, \"you\"), \"!\"),\n    greeting2 = coalesce(str_c(\"Hi \", name, \"!\"), \"Hi!\")\n  )\n#&gt; # A tibble: 4 Ã— 3\n#&gt;   name  greeting1 greeting2\n#&gt;   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora! Hi Flora!\n#&gt; 2 David Hi David! Hi David!\n#&gt; 3 Terra Hi Terra! Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi you!   Hi!\n\n\n14.3.2 str_glue()\n\nIf you are mixing many fixed and variable strings with str_c(), youâ€™ll notice that you type a lot of \"s, making it hard to see the overall goal of the code. An alternative approach is provided by the glue package via str_glue()4. You give it a single string that has a special feature: anything inside {} will be evaluated like itâ€™s outside of the quotes:\nå¦‚æœä½ ä½¿ç”¨ str_c() æ··åˆè®¸å¤šå›ºå®šçš„å’Œå¯å˜çš„å­—ç¬¦ä¸²ï¼Œä½ ä¼šå‘ç°ä½ è¾“å…¥äº†å¤§é‡çš„ \"ï¼Œè¿™ä½¿å¾—ä»£ç çš„æ•´ä½“ç›®æ ‡éš¾ä»¥çœ‹æ¸…ã€‚glue åŒ…é€šè¿‡ str_glue()4 æä¾›äº†å¦ä¸€ç§æ–¹æ³•ã€‚ä½ ç»™å®ƒä¸€ä¸ªå…·æœ‰ç‰¹æ®ŠåŠŸèƒ½çš„å•ä¸€å­—ç¬¦ä¸²ï¼šåœ¨ {} å†…çš„ä»»ä½•å†…å®¹éƒ½ä¼šåƒåœ¨å¼•å·ä¹‹å¤–ä¸€æ ·è¢«æ±‚å€¼ï¼š\n\ndf |&gt; mutate(greeting = str_glue(\"Hi {name}!\"))\n#&gt; # A tibble: 4 Ã— 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;glue&gt;   \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi NA!\n\nAs you can see, str_glue() currently converts missing values to the string \"NA\", unfortunately making it inconsistent with str_c().\næ­£å¦‚ä½ æ‰€è§ï¼Œstr_glue() ç›®å‰å°†ç¼ºå¤±å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸² \"NA\"ï¼Œä¸å¹¸çš„æ˜¯ï¼Œè¿™ä½¿å…¶ä¸ str_c() ä¸ä¸€è‡´ã€‚\nYou also might wonder what happens if you need to include a regular { or } in your string. Youâ€™re on the right track if you guess youâ€™ll need to escape it somehow. The trick is that glue uses a slightly different escaping technique: instead of prefixing with special character like \\, you double up the special characters:\nä½ å¯èƒ½è¿˜ä¼šæƒ³ï¼Œå¦‚æœéœ€è¦åœ¨å­—ç¬¦ä¸²ä¸­åŒ…å«å¸¸è§„çš„ { æˆ– }ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆã€‚å¦‚æœä½ çŒœåˆ°éœ€è¦ä»¥æŸç§æ–¹å¼è½¬ä¹‰å®ƒï¼Œé‚£ä½ å°±çŒœå¯¹äº†ã€‚è¯€çªæ˜¯ glue ä½¿ç”¨ä¸€ç§ç¨æœ‰ä¸åŒçš„è½¬ä¹‰æŠ€æœ¯ï¼šä¸æ˜¯åƒ \\ é‚£æ ·ä½¿ç”¨ç‰¹æ®Šå­—ç¬¦ä½œä¸ºå‰ç¼€ï¼Œè€Œæ˜¯å°†ç‰¹æ®Šå­—ç¬¦åŠ å€ï¼š\n\ndf |&gt; mutate(greeting = str_glue(\"{{Hi {name}!}}\"))\n#&gt; # A tibble: 4 Ã— 2\n#&gt;   name  greeting   \n#&gt;   &lt;chr&gt; &lt;glue&gt;     \n#&gt; 1 Flora {Hi Flora!}\n#&gt; 2 David {Hi David!}\n#&gt; 3 Terra {Hi Terra!}\n#&gt; 4 &lt;NA&gt;  {Hi NA!}\n\n\n14.3.3 str_flatten()\n\nstr_c() and str_glue() work well with mutate() because their output is the same length as their inputs. What if you want a function that works well with summarize(), i.e.Â something that always returns a single string? Thatâ€™s the job of str_flatten()5: it takes a character vector and combines each element of the vector into a single string:str_c() å’Œ str_glue() ä¸ mutate() é…åˆå¾—å¾ˆå¥½ï¼Œå› ä¸ºå®ƒä»¬çš„è¾“å‡ºé•¿åº¦ä¸è¾“å…¥é•¿åº¦ç›¸åŒã€‚å¦‚æœä½ æƒ³è¦ä¸€ä¸ªèƒ½ä¸ summarize() å¾ˆå¥½åœ°é…åˆä½¿ç”¨çš„å‡½æ•°ï¼Œå³ä¸€ä¸ªæ€»æ˜¯è¿”å›å•ä¸ªå­—ç¬¦ä¸²çš„å‡½æ•°ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿè¿™å°±æ˜¯ str_flatten()5 çš„å·¥ä½œï¼šå®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦å‘é‡ï¼Œå¹¶å°†å‘é‡çš„æ¯ä¸ªå…ƒç´ åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å­—ç¬¦ä¸²ï¼š\n\nstr_flatten(c(\"x\", \"y\", \"z\"))\n#&gt; [1] \"xyz\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \")\n#&gt; [1] \"x, y, z\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \", last = \", and \")\n#&gt; [1] \"x, y, and z\"\n\nThis makes it work well with summarize():\nè¿™ä½¿å¾—å®ƒèƒ½ä¸ summarize() å¾ˆå¥½åœ°é…åˆä½¿ç”¨ï¼š\n\ndf &lt;- tribble(\n  ~ name, ~ fruit,\n  \"Carmen\", \"banana\",\n  \"Carmen\", \"apple\",\n  \"Marvin\", \"nectarine\",\n  \"Terence\", \"cantaloupe\",\n  \"Terence\", \"papaya\",\n  \"Terence\", \"mandarin\"\n)\ndf |&gt;\n  group_by(name) |&gt; \n  summarize(fruits = str_flatten(fruit, \", \"))\n#&gt; # A tibble: 3 Ã— 2\n#&gt;   name    fruits                      \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                       \n#&gt; 1 Carmen  banana, apple               \n#&gt; 2 Marvin  nectarine                   \n#&gt; 3 Terence cantaloupe, papaya, mandarin\n\n\n14.3.4 Exercises\n\n\nCompare and contrast the results of paste0() with str_c() for the following inputs:\n\nstr_c(\"hi \", NA)\nstr_c(letters[1:2], letters[1:3])\n\n\nWhatâ€™s the difference between paste() and paste0()? How can you recreate the equivalent of paste() with str_c()?\n\nConvert the following expressions from str_c() to str_glue() or vice versa:\n\nstr_c(\"The price of \", food, \" is \", price)\nstr_glue(\"I'm {age} years old and live in {country}\")\nstr_c(\"\\\\section{\", title, \"}\")",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#extracting-data-from-strings",
    "href": "strings.html#extracting-data-from-strings",
    "title": "14Â  Strings",
    "section": "\n14.4 Extracting data from strings",
    "text": "14.4 Extracting data from strings\nItâ€™s very common for multiple variables to be crammed together into a single string. In this section, youâ€™ll learn how to use four tidyr functions to extract them:\nå°†å¤šä¸ªå˜é‡å¡è¿›ä¸€ä¸ªå­—ç¬¦ä¸²é‡Œæ˜¯éå¸¸å¸¸è§çš„ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨å››ä¸ª tidyr å‡½æ•°æ¥æå–å®ƒä»¬ï¼š\n\ndf |&gt; separate_longer_delim(col, delim)\ndf |&gt; separate_longer_position(col, width)\ndf |&gt; separate_wider_delim(col, delim, names)\ndf |&gt; separate_wider_position(col, widths)\n\nIf you look closely, you can see thereâ€™s a common pattern here: separate_, then longer or wider, then _, then by delim or position. Thatâ€™s because these four functions are composed of two simpler primitives:\nå¦‚æœä½ ä»”ç»†è§‚å¯Ÿï¼Œä½ ä¼šå‘ç°è¿™é‡Œæœ‰ä¸€ä¸ªå…±åŒçš„æ¨¡å¼ï¼šseparate_ï¼Œç„¶åæ˜¯ longer æˆ– widerï¼Œç„¶åæ˜¯ _ï¼Œå†ç„¶åæ˜¯ delim æˆ– positionã€‚è¿™æ˜¯å› ä¸ºè¿™å››ä¸ªå‡½æ•°æ˜¯ç”±ä¸¤ä¸ªæ›´ç®€å•çš„åŸè¯­ç»„æˆçš„ï¼š\n\nJust like with pivot_longer() and pivot_wider(), _longer functions make the input data frame longer by creating new rows and _wider functions make the input data frame wider by generating new columns.\nå°±åƒ pivot_longer() å’Œ pivot_wider() ä¸€æ ·ï¼Œ_longer å‡½æ•°é€šè¿‡åˆ›å»ºæ–°è¡Œæ¥ä½¿è¾“å…¥æ•°æ®æ¡†å˜é•¿ï¼Œè€Œ _wider å‡½æ•°é€šè¿‡ç”Ÿæˆæ–°åˆ—æ¥ä½¿è¾“å…¥æ•°æ®æ¡†å˜å®½ã€‚\ndelim splits up a string with a delimiter like \", \" or \" \"; position splits at specified widths, like c(3, 5, 2).delim ä½¿ç”¨åƒ \", \" æˆ– \" \" è¿™æ ·çš„åˆ†éš”ç¬¦ (delimiter) æ¥åˆ†å‰²å­—ç¬¦ä¸²ï¼›position åˆ™åœ¨æŒ‡å®šçš„å®½åº¦å¤„è¿›è¡Œåˆ†å‰²ï¼Œä¾‹å¦‚ c(3, 5, 2)ã€‚\n\nWeâ€™ll return to the last member of this family, separate_wider_regex(), in Chapter 15. Itâ€™s the most flexible of the wider functions, but you need to know something about regular expressions before you can use it.\næˆ‘ä»¬å°†åœ¨ Chapter 15 ä¸­å›åˆ°è¿™ä¸ªå®¶æ—çš„æœ€åä¸€ä¸ªæˆå‘˜ separate_wider_regex()ã€‚å®ƒæ˜¯ wider å‡½æ•°ä¸­æœ€çµæ´»çš„ä¸€ä¸ªï¼Œä½†åœ¨ä½¿ç”¨å®ƒä¹‹å‰ï¼Œä½ éœ€è¦å¯¹æ­£åˆ™è¡¨è¾¾å¼æœ‰æ‰€äº†è§£ã€‚\nThe following two sections will give you the basic idea behind these separate functions, first separating into rows (which is a little simpler) and then separating into columns. Weâ€™ll finish off by discussing the tools that the wider functions give you to diagnose problems.\næ¥ä¸‹æ¥çš„ä¸¤èŠ‚å°†ä¸ºä½ ä»‹ç»è¿™äº› separate å‡½æ•°èƒŒåçš„åŸºæœ¬æ€æƒ³ï¼Œé¦–å…ˆæ˜¯åˆ†æ‹†åˆ°è¡Œï¼ˆè¿™ç¨å¾®ç®€å•ä¸€äº›ï¼‰ï¼Œç„¶åæ˜¯åˆ†æ‹†åˆ°åˆ—ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è®¨è®º wider å‡½æ•°æä¾›çš„ç”¨äºè¯Šæ–­é—®é¢˜çš„å·¥å…·ã€‚\n\n14.4.1 Separating into rows\nSeparating a string into rows tends to be most useful when the number of components varies from row to row. The most common case is requiring separate_longer_delim() to split based on a delimiter:\nå½“ç»„ä»¶æ•°é‡å› è¡Œè€Œå¼‚æ—¶ï¼Œå°†å­—ç¬¦ä¸²åˆ†æ‹†åˆ°è¡Œé€šå¸¸æœ€æœ‰ç”¨ã€‚æœ€å¸¸è§çš„æƒ…å†µæ˜¯éœ€è¦ separate_longer_delim() åŸºäºåˆ†éš”ç¬¦è¿›è¡Œåˆ†å‰²ï¼š\n\ndf1 &lt;- tibble(x = c(\"a,b,c\", \"d,e\", \"f\"))\ndf1 |&gt; \n  separate_longer_delim(x, delim = \",\")\n#&gt; # A tibble: 6 Ã— 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a    \n#&gt; 2 b    \n#&gt; 3 c    \n#&gt; 4 d    \n#&gt; 5 e    \n#&gt; 6 f\n\nItâ€™s rarer to see separate_longer_position() in the wild, but some older datasets do use a very compact format where each character is used to record a value:\nåœ¨å®é™…åº”ç”¨ä¸­å¾ˆå°‘è§åˆ° separate_longer_position()ï¼Œä½†ä¸€äº›è¾ƒæ—§çš„æ•°æ®é›†ç¡®å®ä¼šä½¿ç”¨ä¸€ç§éå¸¸ç´§å‡‘çš„æ ¼å¼ï¼Œå…¶ä¸­æ¯ä¸ªå­—ç¬¦éƒ½ç”¨äºè®°å½•ä¸€ä¸ªå€¼ï¼š\n\ndf2 &lt;- tibble(x = c(\"1211\", \"131\", \"21\"))\ndf2 |&gt; \n  separate_longer_position(x, width = 1)\n#&gt; # A tibble: 9 Ã— 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1    \n#&gt; 2 2    \n#&gt; 3 1    \n#&gt; 4 1    \n#&gt; 5 1    \n#&gt; 6 3    \n#&gt; # â„¹ 3 more rows\n\n\n14.4.2 Separating into columns\nSeparating a string into columns tends to be most useful when there are a fixed number of components in each string, and you want to spread them into columns. They are slightly more complicated than their longer equivalents because you need to name the columns. For example, in this following dataset, x is made up of a code, an edition number, and a year, separated by \".\". To use separate_wider_delim(), we supply the delimiter and the names in two arguments:\nå½“æ¯ä¸ªå­—ç¬¦ä¸²ä¸­éƒ½æœ‰å›ºå®šæ•°é‡çš„ç»„ä»¶ï¼Œå¹¶ä¸”ä½ æƒ³å°†å®ƒä»¬åˆ†æ•£åˆ°åˆ—ä¸­æ—¶ï¼Œå°†å­—ç¬¦ä¸²åˆ†æ‹†åˆ°åˆ—é€šå¸¸æœ€æœ‰ç”¨ã€‚å®ƒä»¬æ¯” longer å¯¹åº”çš„å‡½æ•°ç¨å¾®å¤æ‚ä¸€äº›ï¼Œå› ä¸ºä½ éœ€è¦ä¸ºåˆ—å‘½åã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„æ•°æ®é›†ä¸­ï¼Œx ç”±ä¸€ä¸ªä»£ç ã€ä¸€ä¸ªç‰ˆæœ¬å·å’Œä¸€ä¸ªå¹´ä»½ç»„æˆï¼Œç”¨ \".\" åˆ†éš”ã€‚è¦ä½¿ç”¨ separate_wider_delim()ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªå‚æ•°ä¸­æä¾›åˆ†éš”ç¬¦å’Œåç§°ï¼š\n\ndf3 &lt;- tibble(x = c(\"a10.1.2022\", \"b10.2.2011\", \"e15.1.2015\"))\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", \"edition\", \"year\")\n  )\n#&gt; # A tibble: 3 Ã— 3\n#&gt;   code  edition year \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 a10   1       2022 \n#&gt; 2 b10   2       2011 \n#&gt; 3 e15   1       2015\n\nIf a specific piece is not useful you can use an NA name to omit it from the results:\nå¦‚æœæŸä¸ªç‰¹å®šçš„éƒ¨åˆ†æ²¡æœ‰ç”¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ NA åç§°å°†å…¶ä»ç»“æœä¸­çœç•¥ï¼š\n\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", NA, \"year\")\n  )\n#&gt; # A tibble: 3 Ã— 2\n#&gt;   code  year \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 a10   2022 \n#&gt; 2 b10   2011 \n#&gt; 3 e15   2015\n\nseparate_wider_position() works a little differently because you typically want to specify the width of each column. So you give it a named integer vector, where the name gives the name of the new column, and the value is the number of characters it occupies. You can omit values from the output by not naming them:separate_wider_position() çš„å·¥ä½œæ–¹å¼ç¨æœ‰ä¸åŒï¼Œå› ä¸ºä½ é€šå¸¸éœ€è¦æŒ‡å®šæ¯åˆ—çš„å®½åº¦ã€‚å› æ­¤ï¼Œä½ éœ€è¦ç»™å®ƒä¸€ä¸ªå‘½åçš„æ•´æ•°å‘é‡ï¼Œå…¶ä¸­åç§°ç»™å‡ºæ–°åˆ—çš„åç§°ï¼Œå€¼æ˜¯å®ƒå ç”¨çš„å­—ç¬¦æ•°ã€‚ä½ å¯ä»¥é€šè¿‡ä¸å‘½åæ¥ä»è¾“å‡ºä¸­çœç•¥å€¼ï¼š\n\ndf4 &lt;- tibble(x = c(\"202215TX\", \"202122LA\", \"202325CA\")) \ndf4 |&gt; \n  separate_wider_position(\n    x,\n    widths = c(year = 4, age = 2, state = 2)\n  )\n#&gt; # A tibble: 3 Ã— 3\n#&gt;   year  age   state\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 2022  15    TX   \n#&gt; 2 2021  22    LA   \n#&gt; 3 2023  25    CA\n\n\n14.4.3 Diagnosing widening problems\nseparate_wider_delim()6 requires a fixed and known set of columns. What happens if some of the rows donâ€™t have the expected number of pieces? There are two possible problems, too few or too many pieces, so separate_wider_delim() provides two arguments to help: too_few and too_many. Letâ€™s first look at the too_few case with the following sample dataset:separate_wider_delim()6 éœ€è¦ä¸€ä¸ªå›ºå®šä¸”å·²çŸ¥çš„åˆ—é›†åˆã€‚å¦‚æœæŸäº›è¡Œæ²¡æœ‰é¢„æœŸçš„ç‰‡æ®µæ•°é‡ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå¯èƒ½å­˜åœ¨ä¸¤ç§é—®é¢˜ï¼Œç‰‡æ®µå¤ªå°‘æˆ–å¤ªå¤šï¼Œå› æ­¤ separate_wider_delim() æä¾›äº†ä¸¤ä¸ªå‚æ•°æ¥å¸®åŠ©è§£å†³ï¼štoo_few å’Œ too_manyã€‚è®©æˆ‘ä»¬é¦–å…ˆç”¨ä»¥ä¸‹ç¤ºä¾‹æ•°æ®é›†çœ‹ä¸€ä¸‹ too_few çš„æƒ…å†µï¼š\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3\", \"1-3-2\", \"1\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too short.\n#&gt; â„¹ Use `too_few = \"debug\"` to diagnose the problem.\n#&gt; â„¹ Use `too_few = \"align_start\"/\"align_end\"` to silence this message.\n\nYouâ€™ll notice that we get an error, but the error gives us some suggestions on how you might proceed. Letâ€™s start by debugging the problem:\nä½ ä¼šæ³¨æ„åˆ°æˆ‘ä»¬æ”¶åˆ°äº†ä¸€ä¸ªé”™è¯¯ï¼Œä½†è¿™ä¸ªé”™è¯¯ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€äº›å…³äºå¦‚ä½•ç»§ç»­æ“ä½œçš„å»ºè®®ã€‚è®©æˆ‘ä»¬ä»è°ƒè¯•é—®é¢˜å¼€å§‹ï¼š\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug\n#&gt; # A tibble: 5 Ã— 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-1-1 1     1     TRUE         3 \"\"         \n#&gt; 2 1-1-2 1     2     TRUE         3 \"\"         \n#&gt; 3 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 4 1-3-2 3     2     TRUE         3 \"\"         \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\nWhen you use the debug mode, you get three extra columns added to the output: x_ok, x_pieces, and x_remainder (if you separate a variable with a different name, youâ€™ll get a different prefix). Here, x_ok lets you quickly find the inputs that failed:\nå½“ä½ ä½¿ç”¨è°ƒè¯•æ¨¡å¼æ—¶ï¼Œè¾“å‡ºä¸­ä¼šæ·»åŠ ä¸‰ä¸ªé¢å¤–çš„åˆ—ï¼šx_okã€x_pieces å’Œ x_remainderï¼ˆå¦‚æœä½ åˆ†å‰²ä¸€ä¸ªä¸åŒåç§°çš„å˜é‡ï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ªä¸åŒçš„å‰ç¼€ï¼‰ã€‚åœ¨è¿™é‡Œï¼Œx_ok å¯ä»¥è®©ä½ å¿«é€Ÿæ‰¾åˆ°å¤±è´¥çš„è¾“å…¥ï¼š\n\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 Ã— 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 2 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\nx_pieces tells us how many pieces were found, compared to the expected 3 (the length of names). x_remainder isnâ€™t useful when there are too few pieces, but weâ€™ll see it again shortly.x_pieces å‘Šè¯‰æˆ‘ä»¬æ‰¾åˆ°äº†å¤šå°‘ä¸ªç‰‡æ®µï¼Œä¸é¢„æœŸçš„ 3 ä¸ªï¼ˆnames çš„é•¿åº¦ï¼‰ç›¸æ¯”ã€‚å½“ç‰‡æ®µå¤ªå°‘æ—¶ï¼Œx_remainder æ²¡æœ‰ç”¨ï¼Œä½†æˆ‘ä»¬å¾ˆå¿«ä¼šå†æ¬¡çœ‹åˆ°å®ƒã€‚\nSometimes looking at this debugging information will reveal a problem with your delimiter strategy or suggest that you need to do more preprocessing before separating. In that case, fix the problem upstream and make sure to remove too_few = \"debug\" to ensure that new problems become errors.\næœ‰æ—¶æŸ¥çœ‹è¿™äº›è°ƒè¯•ä¿¡æ¯ä¼šæ­ç¤ºä½ çš„åˆ†éš”ç¬¦ç­–ç•¥å­˜åœ¨é—®é¢˜ï¼Œæˆ–è€…å»ºè®®ä½ åœ¨åˆ†å‰²ä¹‹å‰éœ€è¦è¿›è¡Œæ›´å¤šçš„é¢„å¤„ç†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·ä¿®å¤ä¸Šæ¸¸çš„é—®é¢˜ï¼Œå¹¶ç¡®ä¿åˆ é™¤ too_few = \"debug\" ä»¥ç¡®ä¿æ–°é—®é¢˜ä¼šæˆä¸ºé”™è¯¯ã€‚\nIn other cases, you may want to fill in the missing pieces with NAs and move on. Thatâ€™s the job of too_few = \"align_start\" and too_few = \"align_end\" which allow you to control where the NAs should go:\nåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½å¸Œæœ›ç”¨ NA å¡«å……ç¼ºå¤±çš„ç‰‡æ®µç„¶åç»§ç»­ã€‚è¿™æ˜¯ too_few = \"align_start\" å’Œ too_few = \"align_end\" çš„å·¥ä½œï¼Œå®ƒä»¬å…è®¸ä½ æ§åˆ¶ NA åº”è¯¥æ”¾åœ¨å“ªé‡Œï¼š\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"align_start\"\n  )\n#&gt; # A tibble: 5 Ã— 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     &lt;NA&gt; \n#&gt; 4 1     3     2    \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;\n\nThe same principles apply if you have too many pieces:\nå¦‚æœä½ æœ‰å¤ªå¤šç‰‡æ®µï¼ŒåŒæ ·çš„åŸåˆ™ä¹Ÿé€‚ç”¨ï¼š\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3-5-6\", \"1-3-2\", \"1-3-5-7-9\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too long.\n#&gt; â„¹ Use `too_many = \"debug\"` to diagnose the problem.\n#&gt; â„¹ Use `too_many = \"drop\"/\"merge\"` to silence this message.\n\nBut now, when we debug the result, you can see the purpose of x_remainder:\nä½†æ˜¯ç°åœ¨ï¼Œå½“æˆ‘ä»¬è°ƒè¯•ç»“æœæ—¶ï¼Œä½ å¯ä»¥çœ‹åˆ° x_remainder çš„ç”¨é€”ï¼š\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 Ã— 6\n#&gt;   x         y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3-5-6   3     5     FALSE        4 -6         \n#&gt; 2 1-3-5-7-9 3     5     FALSE        5 -7-9\n\nYou have a slightly different set of options for handling too many pieces: you can either silently â€œdropâ€ any additional pieces or â€œmergeâ€ them all into the final column:\nå¯¹äºå¤„ç†è¿‡å¤šç‰‡æ®µï¼Œä½ æœ‰ä¸€å¥—ç¨å¾®ä¸åŒçš„é€‰é¡¹ï¼šä½ å¯ä»¥é»˜é»˜åœ°â€œä¸¢å¼ƒâ€(drop) ä»»ä½•é¢å¤–çš„ç‰‡æ®µï¼Œæˆ–è€…å°†å®ƒä»¬å…¨éƒ¨â€œåˆå¹¶â€(merge) åˆ°æœ€åä¸€åˆ—ï¼š\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"drop\"\n  )\n#&gt; # A tibble: 5 Ã— 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5    \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5\n\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"merge\"\n  )\n#&gt; # A tibble: 5 Ã— 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5-6  \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5-7-9",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#letters",
    "href": "strings.html#letters",
    "title": "14Â  Strings",
    "section": "\n14.5 Letters",
    "text": "14.5 Letters\nIn this section, weâ€™ll introduce you to functions that allow you to work with the individual letters within a string. Youâ€™ll learn how to find the length of a string, extract substrings, and handle long strings in plots and tables.\nåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å‘ä½ ä»‹ç»ä¸€äº›å¯ä»¥å¤„ç†å­—ç¬¦ä¸²ä¸­å•ä¸ªå­—æ¯çš„å‡½æ•°ã€‚ä½ å°†å­¦ä¹ å¦‚ä½•æŸ¥æ‰¾å­—ç¬¦ä¸²çš„é•¿åº¦ã€æå–å­å­—ç¬¦ä¸²ä»¥åŠåœ¨å›¾è¡¨å’Œè¡¨æ ¼ä¸­å¤„ç†é•¿å­—ç¬¦ä¸²ã€‚\n\n14.5.1 Length\nstr_length() tells you the number of letters in the string:str_length() ä¼šå‘Šè¯‰ä½ å­—ç¬¦ä¸²ä¸­çš„å­—æ¯æ•°é‡ï¼š\n\nstr_length(c(\"a\", \"R for data science\", NA))\n#&gt; [1]  1 18 NA\n\nYou could use this with count() to find the distribution of lengths of US babynames and then with filter() to look at the longest names, which happen to have 15 letters7:\nä½ å¯ä»¥å°†å…¶ä¸ count() ä¸€èµ·ä½¿ç”¨ï¼Œä»¥æŸ¥æ‰¾ç¾å›½å©´å„¿åå­—é•¿åº¦çš„åˆ†å¸ƒï¼Œç„¶åä¸ filter() ä¸€èµ·ä½¿ç”¨ï¼Œä»¥æŸ¥çœ‹æœ€é•¿çš„åå­—ï¼Œè¿™äº›åå­—æ°å¥½æœ‰ 15 ä¸ªå­—æ¯7ï¼š\n\nbabynames |&gt;\n  count(length = str_length(name), wt = n)\n#&gt; # A tibble: 14 Ã— 2\n#&gt;   length        n\n#&gt;    &lt;int&gt;    &lt;int&gt;\n#&gt; 1      2   338150\n#&gt; 2      3  8589596\n#&gt; 3      4 48506739\n#&gt; 4      5 87011607\n#&gt; 5      6 90749404\n#&gt; 6      7 72120767\n#&gt; # â„¹ 8 more rows\n\nbabynames |&gt; \n  filter(str_length(name) == 15) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 34 Ã— 2\n#&gt;   name                n\n#&gt;   &lt;chr&gt;           &lt;int&gt;\n#&gt; 1 Franciscojavier   123\n#&gt; 2 Christopherjohn   118\n#&gt; 3 Johnchristopher   118\n#&gt; 4 Christopherjame   108\n#&gt; 5 Christophermich    52\n#&gt; 6 Ryanchristopher    45\n#&gt; # â„¹ 28 more rows\n\n\n14.5.2 Subsetting\nYou can extract parts of a string using str_sub(string, start, end), where start and end are the positions where the substring should start and end. The start and end arguments are inclusive, so the length of the returned string will be end - start + 1:\nä½ å¯ä»¥ä½¿ç”¨ str_sub(string, start, end) æ¥æå–å­—ç¬¦ä¸²çš„ä¸€éƒ¨åˆ†ï¼Œå…¶ä¸­ start å’Œ end æ˜¯å­å­—ç¬¦ä¸²åº”è¯¥å¼€å§‹å’Œç»“æŸçš„ä½ç½®ã€‚start å’Œ end å‚æ•°æ˜¯åŒ…å«æ€§çš„ï¼Œæ‰€ä»¥è¿”å›çš„å­—ç¬¦ä¸²é•¿åº¦å°†æ˜¯ end - start + 1ï¼š\n\nx &lt;- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n#&gt; [1] \"App\" \"Ban\" \"Pea\"\n\nYou can use negative values to count back from the end of the string: -1 is the last character, -2 is the second to last character, etc.\nä½ å¯ä»¥ä½¿ç”¨è´Ÿå€¼ä»å­—ç¬¦ä¸²æœ«å°¾å‘åè®¡æ•°ï¼š-1 æ˜¯æœ€åä¸€ä¸ªå­—ç¬¦ï¼Œ-2 æ˜¯å€’æ•°ç¬¬äºŒä¸ªå­—ç¬¦ï¼Œä¾æ­¤ç±»æ¨ã€‚\n\nstr_sub(x, -3, -1)\n#&gt; [1] \"ple\" \"ana\" \"ear\"\n\nNote that str_sub() wonâ€™t fail if the string is too short: it will just return as much as possible:\nè¯·æ³¨æ„ï¼Œå¦‚æœå­—ç¬¦ä¸²å¤ªçŸ­ï¼Œstr_sub() ä¸ä¼šå¤±è´¥ï¼šå®ƒåªä¼šå°½å¯èƒ½å¤šåœ°è¿”å›å†…å®¹ï¼š\n\nstr_sub(\"a\", 1, 5)\n#&gt; [1] \"a\"\n\nWe could use str_sub() with mutate() to find the first and last letter of each name:\næˆ‘ä»¬å¯ä»¥å°† str_sub() ä¸ mutate() ç»“åˆä½¿ç”¨ï¼Œæ‰¾å‡ºæ¯ä¸ªåå­—çš„é¦–å­—æ¯å’Œå°¾å­—æ¯ï¼š\n\nbabynames |&gt; \n  mutate(\n    first = str_sub(name, 1, 1),\n    last = str_sub(name, -1, -1)\n  )\n#&gt; # A tibble: 1,924,665 Ã— 7\n#&gt;    year sex   name          n   prop first last \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1  1880 F     Mary       7065 0.0724 M     y    \n#&gt; 2  1880 F     Anna       2604 0.0267 A     a    \n#&gt; 3  1880 F     Emma       2003 0.0205 E     a    \n#&gt; 4  1880 F     Elizabeth  1939 0.0199 E     h    \n#&gt; 5  1880 F     Minnie     1746 0.0179 M     e    \n#&gt; 6  1880 F     Margaret   1578 0.0162 M     t    \n#&gt; # â„¹ 1,924,659 more rows\n\n\n14.5.3 Exercises\n\nWhen computing the distribution of the length of babynames, why did we use wt = n?\n\nUse str_length() and str_sub() to extract the middle letter from each baby name. What will you do if the string has an even number of characters?\n\nAre there any major trends in the length of babynames over time? What about the popularity of first and last letters?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#sec-other-languages",
    "href": "strings.html#sec-other-languages",
    "title": "14Â  Strings",
    "section": "\n14.6 Non-English text",
    "text": "14.6 Non-English text\nSo far, weâ€™ve focused on English language text which is particularly easy to work with for two reasons. Firstly, the English alphabet is relatively simple: there are just 26 letters. Secondly (and maybe more importantly), the computing infrastructure we use today was predominantly designed by English speakers. Unfortunately, we donâ€™t have room for a full treatment of non-English languages. Still, we wanted to draw your attention to some of the biggest challenges you might encounter: encoding, letter variations, and locale-dependent functions.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´ä¸“æ³¨äºè‹±æ–‡æ–‡æœ¬ï¼Œè¿™ç§æ–‡æœ¬ç‰¹åˆ«å®¹æ˜“å¤„ç†ï¼ŒåŸå› æœ‰äºŒã€‚é¦–å…ˆï¼Œè‹±æ–‡å­—æ¯ç›¸å¯¹ç®€å•ï¼šåªæœ‰ 26 ä¸ªå­—æ¯ã€‚å…¶æ¬¡ï¼ˆä¹Ÿè®¸æ›´é‡è¦çš„æ˜¯ï¼‰ï¼Œæˆ‘ä»¬ä»Šå¤©ä½¿ç”¨çš„è®¡ç®—åŸºç¡€è®¾æ–½ä¸»è¦æ˜¯ç”±è‹±è¯­ä½¿ç”¨è€…è®¾è®¡çš„ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„ç¯‡å¹…æ¥å…¨é¢å¤„ç†éè‹±è¯­è¯­è¨€ã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬æƒ³æé†’ä½ æ³¨æ„ä¸€äº›ä½ å¯èƒ½é‡åˆ°çš„æœ€å¤§æŒ‘æˆ˜ï¼šç¼–ç  (encoding)ã€å­—æ¯å˜ä½“å’Œä¾èµ–äºåŒºåŸŸè®¾ç½® (locale-dependent) çš„å‡½æ•°ã€‚\n\n14.6.1 Encoding\nWhen working with non-English text, the first challenge is often the encoding. To understand whatâ€™s going on, we need to dive into how computers represent strings. In R, we can get at the underlying representation of a string using charToRaw():\nåœ¨å¤„ç†éè‹±æ–‡æ–‡æœ¬æ—¶ï¼Œç¬¬ä¸€ä¸ªæŒ‘æˆ˜é€šå¸¸æ˜¯ç¼–ç  (encoding)ã€‚è¦ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆï¼Œæˆ‘ä»¬éœ€è¦æ·±å…¥äº†è§£è®¡ç®—æœºå¦‚ä½•è¡¨ç¤ºå­—ç¬¦ä¸²ã€‚åœ¨ R ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ charToRaw() æ¥è·å–å­—ç¬¦ä¸²çš„åº•å±‚è¡¨ç¤ºï¼š\n\ncharToRaw(\"Hadley\")\n#&gt; [1] 48 61 64 6c 65 79\n\nEach of these six hexadecimal numbers represents one letter: 48 is H, 61 is a, and so on. The mapping from hexadecimal number to character is called the encoding, and in this case, the encoding is called ASCII. ASCII does a great job of representing English characters because itâ€™s the American Standard Code for Information Interchange.\nè¿™å…­ä¸ªåå…­è¿›åˆ¶æ•°ä¸­çš„æ¯ä¸€ä¸ªéƒ½ä»£è¡¨ä¸€ä¸ªå­—æ¯ï¼š48 æ˜¯ Hï¼Œ61 æ˜¯ aï¼Œä¾æ­¤ç±»æ¨ã€‚ä»åå…­è¿›åˆ¶æ•°åˆ°å­—ç¬¦çš„æ˜ å°„ç§°ä¸ºç¼–ç ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¼–ç è¢«ç§°ä¸º ASCIIã€‚ASCII åœ¨è¡¨ç¤ºè‹±æ–‡å­—ç¬¦æ–¹é¢åšå¾—å¾ˆå¥½ï¼Œå› ä¸ºå®ƒæ˜¯ç¾å›½ä¿¡æ¯äº¤æ¢æ ‡å‡†ä»£ç ã€‚\nThings arenâ€™t so easy for languages other than English. In the early days of computing, there were many competing standards for encoding non-English characters. For example, there were two different encodings for Europe: Latin1 (aka ISO-8859-1) was used for Western European languages, and Latin2 (aka ISO-8859-2) was used for Central European languages. In Latin1, the byte b1 is â€œÂ±â€, but in Latin2, itâ€™s â€œÄ…â€! Fortunately, today there is one standard that is supported almost everywhere: UTF-8. UTF-8 can encode just about every character used by humans today and many extra symbols like emojis.\nå¯¹äºéè‹±è¯­è¯­è¨€æ¥è¯´ï¼Œäº‹æƒ…å°±æ²¡é‚£ä¹ˆç®€å•äº†ã€‚åœ¨è®¡ç®—çš„æ—©æœŸï¼Œæœ‰è®¸å¤šç«äº‰æ€§çš„æ ‡å‡†ç”¨äºç¼–ç éè‹±æ–‡å­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œæ¬§æ´²æœ‰ä¸¤ç§ä¸åŒçš„ç¼–ç ï¼šLatin1ï¼ˆåˆå ISO-8859-1ï¼‰ç”¨äºè¥¿æ¬§è¯­è¨€ï¼Œè€Œ Latin2ï¼ˆåˆå ISO-8859-2ï¼‰ç”¨äºä¸­æ¬§è¯­è¨€ã€‚åœ¨ Latin1 ä¸­ï¼Œå­—èŠ‚ b1 æ˜¯ â€œÂ±â€ï¼Œä½†åœ¨ Latin2 ä¸­ï¼Œå®ƒæ˜¯ â€œÄ…â€ï¼å¹¸è¿çš„æ˜¯ï¼Œå¦‚ä»Šæœ‰ä¸€ä¸ªå‡ ä¹åœ¨ä»»ä½•åœ°æ–¹éƒ½å¾—åˆ°æ”¯æŒçš„æ ‡å‡†ï¼šUTF-8ã€‚UTF-8 å‡ ä¹å¯ä»¥ç¼–ç å½“ä»Šäººç±»ä½¿ç”¨çš„æ‰€æœ‰å­—ç¬¦ä»¥åŠè®¸å¤šé¢å¤–çš„ç¬¦å·ï¼Œå¦‚è¡¨æƒ…ç¬¦å· (emojis)ã€‚\nreadr uses UTF-8 everywhere. This is a good default but will fail for data produced by older systems that donâ€™t use UTF-8. If this happens, your strings will look weird when you print them. Sometimes just one or two characters might be messed up; other times, youâ€™ll get complete gibberish. For example here are two inline CSVs with unusual encodings8:\nreadr åœ¨ä»»ä½•åœ°æ–¹éƒ½ä½¿ç”¨ UTF-8ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é»˜è®¤è®¾ç½®ï¼Œä½†å¯¹äºç”±ä¸ä½¿ç”¨ UTF-8 çš„æ—§ç³»ç»Ÿç”Ÿæˆçš„æ•°æ®ï¼Œå®ƒä¼šå¤±è´¥ã€‚å¦‚æœå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œä½ çš„å­—ç¬¦ä¸²åœ¨æ‰“å°æ—¶ä¼šçœ‹èµ·æ¥å¾ˆå¥‡æ€ªã€‚æœ‰æ—¶å¯èƒ½åªæœ‰ä¸€ä¸¤ä¸ªå­—ç¬¦è¢«å¼„ä¹±ï¼›å…¶ä»–æ—¶å€™ï¼Œä½ ä¼šå¾—åˆ°å®Œå…¨çš„ä¹±ç ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæœ‰ä¸¤ä¸ªå¸¦æœ‰ä¸å¯»å¸¸ç¼–ç çš„å†…è” CSV8ï¼š\n\nx1 &lt;- \"text\\nEl Ni\\xf1o was particularly bad this year\"\nread_csv(x1)$text\n#&gt; [1] \"El Ni\\xf1o was particularly bad this year\"\n\nx2 &lt;- \"text\\n\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd\"\nread_csv(x2)$text\n#&gt; [1] \"\\x82\\xb1\\x82\\xf1\\x82É‚\\xbf\\x82\\xcd\"\n\nTo read these correctly, you specify the encoding via the locale argument:\nè¦æ­£ç¡®è¯»å–è¿™äº›æ–‡ä»¶ï¼Œä½ éœ€è¦é€šè¿‡ locale å‚æ•°æŒ‡å®šç¼–ç ï¼š\n\nread_csv(x1, locale = locale(encoding = \"Latin1\"))$text\n#&gt; [1] \"El NiÃ±o was particularly bad this year\"\n\nread_csv(x2, locale = locale(encoding = \"Shift-JIS\"))$text\n#&gt; [1] \"ã“ã‚“ã«ã¡ã¯\"\n\nHow do you find the correct encoding? If youâ€™re lucky, itâ€™ll be included somewhere in the data documentation. Unfortunately, thatâ€™s rarely the case, so readr provides guess_encoding() to help you figure it out. Itâ€™s not foolproof and works better when you have lots of text (unlike here), but itâ€™s a reasonable place to start. Expect to try a few different encodings before you find the right one.\nä½ å¦‚ä½•æ‰¾åˆ°æ­£ç¡®çš„ç¼–ç ï¼Ÿå¦‚æœå¹¸è¿çš„è¯ï¼Œå®ƒä¼šåŒ…å«åœ¨æ•°æ®æ–‡æ¡£çš„æŸä¸ªåœ°æ–¹ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™ç§æƒ…å†µå¾ˆå°‘è§ï¼Œæ‰€ä»¥ readr æä¾›äº† guess_encoding() æ¥å¸®åŠ©ä½ ç¡®å®šå®ƒã€‚å®ƒå¹¶éä¸‡æ— ä¸€å¤±ï¼Œå¹¶ä¸”åœ¨ä½ æ‹¥æœ‰å¤§é‡æ–‡æœ¬æ—¶æ•ˆæœæ›´å¥½ï¼ˆä¸åƒè¿™é‡Œï¼‰ï¼Œä½†å®ƒæ˜¯ä¸€ä¸ªåˆç†çš„èµ·ç‚¹ã€‚é¢„è®¡ä½ éœ€è¦å°è¯•å‡ ç§ä¸åŒçš„ç¼–ç æ‰èƒ½æ‰¾åˆ°æ­£ç¡®çš„é‚£ä¸€ä¸ªã€‚\nEncodings are a rich and complex topic; weâ€™ve only scratched the surface here. If youâ€™d like to learn more, we recommend reading the detailed explanation at http://kunststube.net/encoding/.\nç¼–ç æ˜¯ä¸€ä¸ªå†…å®¹ä¸°å¯Œä¸”å¤æ‚çš„ä¸»é¢˜ï¼›æˆ‘ä»¬åœ¨è¿™é‡Œåªæ˜¯æµ…å°è¾„æ­¢ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šï¼Œæˆ‘ä»¬å»ºè®®é˜…è¯» http://kunststube.net/encoding/ ä¸Šçš„è¯¦ç»†è§£é‡Šã€‚\n\n14.6.2 Letter variations\nWorking in languages with accents poses a significant challenge when determining the position of letters (e.g., with str_length() and str_sub()) as accented letters might be encoded as a single individual character (e.g., Ã¼) or as two characters by combining an unaccented letter (e.g., u) with a diacritic mark (e.g., Â¨). For example, this code shows two ways of representing Ã¼ that look identical:\nåœ¨å¤„ç†å¸¦é‡éŸ³ç¬¦å·çš„è¯­è¨€æ—¶ï¼Œç¡®å®šå­—æ¯çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨ str_length() å’Œ str_sub()ï¼‰ä¼šå¸¦æ¥é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºå¸¦é‡éŸ³çš„å­—æ¯å¯èƒ½è¢«ç¼–ç ä¸ºå•ä¸ªç‹¬ç«‹å­—ç¬¦ï¼ˆä¾‹å¦‚ï¼ŒÃ¼ï¼‰ï¼Œæˆ–è€…é€šè¿‡ç»„åˆä¸€ä¸ªä¸å¸¦é‡éŸ³çš„å­—æ¯ï¼ˆä¾‹å¦‚ï¼Œuï¼‰å’Œä¸€ä¸ªå˜éŸ³ç¬¦å·ï¼ˆä¾‹å¦‚ï¼ŒÂ¨ï¼‰è€Œè¢«ç¼–ç ä¸ºä¸¤ä¸ªå­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œè¿™æ®µä»£ç æ˜¾ç¤ºäº†ä¸¤ç§çœ‹èµ·æ¥å®Œå…¨ç›¸åŒçš„è¡¨ç¤º Ã¼ çš„æ–¹å¼ï¼š\n\nu &lt;- c(\"\\u00fc\", \"u\\u0308\")\nstr_view(u)\n#&gt; [1] â”‚ Ã¼\n#&gt; [2] â”‚ uÌˆ\n\nBut both strings differ in length, and their first characters are different:\nä½†è¿™ä¸¤ä¸ªå­—ç¬¦ä¸²çš„é•¿åº¦ä¸åŒï¼Œå®ƒä»¬çš„ç¬¬ä¸€ä¸ªå­—ç¬¦ä¹Ÿä¸åŒï¼š\n\nstr_length(u)\n#&gt; [1] 1 2\nstr_sub(u, 1, 1)\n#&gt; [1] \"Ã¼\" \"u\"\n\nFinally, note that a comparison of these strings with == interprets these strings as different, while the handy str_equal() function in stringr recognizes that both have the same appearance:\næœ€åï¼Œè¯·æ³¨æ„ï¼Œä½¿ç”¨ == æ¯”è¾ƒè¿™äº›å­—ç¬¦ä¸²ä¼šå°†å…¶è§£é‡Šä¸ºä¸åŒçš„å­—ç¬¦ä¸²ï¼Œè€Œ stringr ä¸­æ–¹ä¾¿çš„ str_equal() å‡½æ•°åˆ™èƒ½è¯†åˆ«å‡ºä¸¤è€…å…·æœ‰ç›¸åŒçš„å¤–è§‚ï¼š\n\nu[[1]] == u[[2]]\n#&gt; [1] FALSE\n\nstr_equal(u[[1]], u[[2]])\n#&gt; [1] TRUE\n\n\n14.6.3 Locale-dependent functions\nFinally, there are a handful of stringr functions whose behavior depends on your locale. A locale is similar to a language but includes an optional region specifier to handle regional variations within a language. A locale is specified by a lower-case language abbreviation, optionally followed by a _ and an upper-case region identifier. For example, â€œenâ€ is English, â€œen_GBâ€ is British English, and â€œen_USâ€ is American English. If you donâ€™t already know the code for your language, Wikipedia has a good list, and you can see which are supported in stringr by looking at stringi::stri_locale_list().\næœ€åï¼Œè¿˜æœ‰ä¸€äº› stringr å‡½æ•°çš„è¡Œä¸ºå–å†³äºä½ çš„åŒºåŸŸè®¾ç½® (locale)ã€‚locale ç±»ä¼¼äºä¸€ç§è¯­è¨€ï¼Œä½†åŒ…å«ä¸€ä¸ªå¯é€‰çš„åŒºåŸŸè¯´æ˜ç¬¦ï¼Œä»¥å¤„ç†ä¸€ç§è¯­è¨€å†…éƒ¨çš„åŒºåŸŸå·®å¼‚ã€‚locale ç”±å°å†™è¯­è¨€ç¼©å†™æŒ‡å®šï¼Œåé¢å¯é€‰æ‹©æ€§åœ°è·Ÿä¸€ä¸ª _ å’Œä¸€ä¸ªå¤§å†™çš„åŒºåŸŸæ ‡è¯†ç¬¦ã€‚ä¾‹å¦‚ï¼Œâ€œenâ€ æ˜¯è‹±è¯­ï¼Œâ€œen_GBâ€ æ˜¯è‹±å¼è‹±è¯­ï¼Œâ€œen_USâ€ æ˜¯ç¾å¼è‹±è¯­ã€‚å¦‚æœä½ è¿˜ä¸çŸ¥é“ä½ è¯­è¨€çš„ä»£ç ï¼Œç»´åŸºç™¾ç§‘ æœ‰ä¸€ä¸ªå¾ˆå¥½çš„åˆ—è¡¨ï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡æŸ¥çœ‹ stringi::stri_locale_list() æ¥çœ‹ stringr æ”¯æŒå“ªäº›ã€‚\nBase R string functions automatically use the locale set by your operating system. This means that base R string functions do what you expect for your language, but your code might work differently if you share it with someone who lives in a different country. To avoid this problem, stringr defaults to English rules by using the â€œenâ€ locale and requires you to specify the locale argument to override it. Fortunately, there are only two sets of functions where the locale really matters: changing case and sorting.\nåŸºç¡€ R å­—ç¬¦ä¸²å‡½æ•°ä¼šè‡ªåŠ¨ä½¿ç”¨ä½ çš„æ“ä½œç³»ç»Ÿè®¾ç½®çš„ localeã€‚è¿™æ„å‘³ç€åŸºç¡€ R å­—ç¬¦ä¸²å‡½æ•°ä¼šæŒ‰ç…§ä½ è¯­è¨€çš„é¢„æœŸå·¥ä½œï¼Œä½†å¦‚æœä½ çš„ä»£ç ä¸ç”Ÿæ´»åœ¨ä¸åŒå›½å®¶çš„äººå…±äº«ï¼Œå®ƒçš„å·¥ä½œæ–¹å¼å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚ä¸ºé¿å…æ­¤é—®é¢˜ï¼Œstringr é»˜è®¤ä½¿ç”¨ â€œenâ€ localeï¼Œå³è‹±è¯­è§„åˆ™ï¼Œå¹¶è¦æ±‚ä½ æŒ‡å®š locale å‚æ•°æ¥è¦†ç›–å®ƒã€‚å¹¸è¿çš„æ˜¯ï¼Œåªæœ‰ä¸¤ç»„å‡½æ•°çš„ locale çœŸæ­£é‡è¦ï¼šæ”¹å˜å¤§å°å†™å’Œæ’åºã€‚\nThe rules for changing cases differ among languages. For example, Turkish has two iâ€™s: with and without a dot. Since theyâ€™re two distinct letters, theyâ€™re capitalized differently:\nä¸åŒè¯­è¨€çš„å¤§å°å†™è½¬æ¢è§„åˆ™ä¸åŒã€‚ä¾‹å¦‚ï¼ŒåœŸè€³å…¶è¯­ä¸­æœ‰ä¸¤ä¸ª iï¼šå¸¦ç‚¹çš„å’Œä¸å¸¦ç‚¹çš„ã€‚ç”±äºå®ƒä»¬æ˜¯ä¸¤ä¸ªä¸åŒçš„å­—æ¯ï¼Œå®ƒä»¬çš„å¤§å†™æ–¹å¼ä¹Ÿä¸åŒï¼š\n\nstr_to_upper(c(\"i\", \"Ä±\"))\n#&gt; [1] \"I\" \"I\"\nstr_to_upper(c(\"i\", \"Ä±\"), locale = \"tr\")\n#&gt; [1] \"Ä°\" \"I\"\n\nSorting strings depends on the order of the alphabet, and the order of the alphabet is not the same in every language9! Hereâ€™s an example: in Czech, â€œchâ€ is a compound letter that appears after h in the alphabet.\nå­—ç¬¦ä¸²æ’åºå–å†³äºå­—æ¯è¡¨çš„é¡ºåºï¼Œè€Œå¹¶éæ¯ç§è¯­è¨€çš„å­—æ¯è¡¨é¡ºåºéƒ½ç›¸åŒ9ï¼è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­ï¼šåœ¨æ·å…‹è¯­ä¸­ï¼Œâ€œchâ€ æ˜¯ä¸€ä¸ªå¤åˆå­—æ¯ï¼Œåœ¨å­—æ¯è¡¨ä¸­å‡ºç°åœ¨ h ä¹‹åã€‚\n\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"))\n#&gt; [1] \"a\"  \"c\"  \"ch\" \"h\"  \"z\"\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"), locale = \"cs\")\n#&gt; [1] \"a\"  \"c\"  \"h\"  \"ch\" \"z\"\n\nThis also comes up when sorting strings with dplyr::arrange(), which is why it also has a locale argument.\nåœ¨ä½¿ç”¨ dplyr::arrange() å¯¹å­—ç¬¦ä¸²è¿›è¡Œæ’åºæ—¶ä¹Ÿä¼šé‡åˆ°è¿™ç§æƒ…å†µï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒä¹Ÿæœ‰ä¸€ä¸ª locale å‚æ•°ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#summary",
    "href": "strings.html#summary",
    "title": "14Â  Strings",
    "section": "\n14.7 Summary",
    "text": "14.7 Summary\nIn this chapter, youâ€™ve learned about some of the power of the stringr package: how to create, combine, and extract strings, and about some of the challenges you might face with non-English strings. Now itâ€™s time to learn one of the most important and powerful tools for working with strings: regular expressions. Regular expressions are a very concise but very expressive language for describing patterns within strings and are the topic of the next chapter.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº† stringr åŒ…çš„ä¸€äº›å¼ºå¤§åŠŸèƒ½ï¼šå¦‚ä½•åˆ›å»ºã€ç»„åˆå’Œæå–å­—ç¬¦ä¸²ï¼Œä»¥åŠåœ¨å¤„ç†éè‹±è¯­å­—ç¬¦ä¸²æ—¶å¯èƒ½é¢ä¸´çš„ä¸€äº›æŒ‘æˆ˜ã€‚ç°åœ¨æ˜¯æ—¶å€™å­¦ä¹ å¤„ç†å­—ç¬¦ä¸²æœ€é‡è¦å’Œæœ€å¼ºå¤§çš„å·¥å…·ä¹‹ä¸€ï¼šæ­£åˆ™è¡¨è¾¾å¼ã€‚æ­£åˆ™è¡¨è¾¾å¼æ˜¯ä¸€ç§éå¸¸ç®€æ´ä½†è¡¨è¾¾èƒ½åŠ›æå¼ºçš„è¯­è¨€ï¼Œç”¨äºæè¿°å­—ç¬¦ä¸²å†…çš„æ¨¡å¼ï¼Œè¿™ä¹Ÿæ˜¯ä¸‹ä¸€ç« çš„ä¸»é¢˜ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#footnotes",
    "href": "strings.html#footnotes",
    "title": "14Â  Strings",
    "section": "",
    "text": "Or use the base R function writeLines().â†©ï¸\nAvailable in R 4.0.0 and above.â†©ï¸\nstr_view() also uses color to bring tabs, spaces, matches, etc. to your attention. The colors donâ€™t currently show up in the book, but youâ€™ll notice them when running code interactively.â†©ï¸\nIf youâ€™re not using stringr, you can also access it directly with glue::glue().â†©ï¸\nThe base R equivalent is paste() used with the collapse argument.â†©ï¸\nThe same principles apply to separate_wider_position() and separate_wider_regex().â†©ï¸\nLooking at these entries, weâ€™d guess that the babynames data drops spaces or hyphens and truncates after 15 letters.â†©ï¸\nHere Iâ€™m using the special \\x to encode binary data directly into a string.â†©ï¸\nSorting in languages that donâ€™t have an alphabet, like Chinese, is more complicated still.â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "regexps.html",
    "href": "regexps.html",
    "title": "15Â  Regular expressions",
    "section": "",
    "text": "15.1 Introduction\nIn Chapter 14, you learned a whole bunch of useful functions for working with strings. This chapter will focus on functions that use regular expressions, a concise and powerful language for describing patterns within strings. The term â€œregular expressionâ€ is a bit of a mouthful, so most people abbreviate it to â€œregexâ€1 or â€œregexpâ€.\nåœ¨ Chapter 14 ä¸­ï¼Œä½ å­¦ä¹ äº†ä¸€ç³»åˆ—å¤„ç†å­—ç¬¦ä¸²çš„æœ‰ç”¨å‡½æ•°ã€‚æœ¬ç« å°†é‡ç‚¹ä»‹ç»ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼çš„å‡½æ•°ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæè¿°å­—ç¬¦ä¸²å†…æ¨¡å¼çš„ç®€æ´è€Œå¼ºå¤§çš„è¯­è¨€ã€‚æœ¯è¯­â€œregular expressionâ€æœ‰ç‚¹æ‹—å£ï¼Œæ‰€ä»¥å¤§å¤šæ•°äººå°†å…¶ç¼©å†™ä¸ºâ€œregexâ€1 æˆ–â€œregexpâ€ã€‚\nThe chapter starts with the basics of regular expressions and the most useful stringr functions for data analysis. Weâ€™ll then expand your knowledge of patterns and cover seven important new topics (escaping, anchoring, character classes, shorthand classes, quantifiers, precedence, and grouping). Next, weâ€™ll talk about some of the other types of patterns that stringr functions can work with and the various â€œflagsâ€ that allow you to tweak the operation of regular expressions. Weâ€™ll finish with a survey of other places in the tidyverse and base R where you might use regexes.\næœ¬ç« é¦–å…ˆä»‹ç»æ­£åˆ™è¡¨è¾¾å¼çš„åŸºç¡€çŸ¥è¯†ä»¥åŠç”¨äºæ•°æ®åˆ†æçš„æœ€æœ‰ç”¨çš„ stringr å‡½æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æ‰©å±•ä½ çš„æ¨¡å¼çŸ¥è¯†ï¼Œå¹¶æ¶µç›–ä¸ƒä¸ªé‡è¦çš„æ–°ä¸»é¢˜ï¼ˆè½¬ä¹‰ã€é”šå®šã€å­—ç¬¦ç±»ã€ç®€å†™ç±»ã€é‡è¯ã€ä¼˜å…ˆçº§å’Œåˆ†ç»„ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è®¨è®º stringr å‡½æ•°å¯ä»¥å¤„ç†çš„å…¶ä»–ä¸€äº›æ¨¡å¼ç±»å‹ä»¥åŠå…è®¸ä½ è°ƒæ•´æ­£åˆ™è¡¨è¾¾å¼æ“ä½œçš„å„ç§â€œæ ‡å¿—â€ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æ¦‚è¿°åœ¨ tidyverse å’ŒåŸºç¡€ R ä¸­å¯èƒ½ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼çš„å…¶ä»–åœ°æ–¹ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#introduction",
    "href": "regexps.html#introduction",
    "title": "15Â  Regular expressions",
    "section": "",
    "text": "15.1.1 Prerequisites\nIn this chapter, weâ€™ll use regular expression functions from stringr and tidyr, both core members of the tidyverse, as well as data from the babynames package.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ tidyverse çš„æ ¸å¿ƒæˆå‘˜ stringr å’Œ tidyr ä¸­çš„æ­£åˆ™è¡¨è¾¾å¼å‡½æ•°ï¼Œä»¥åŠæ¥è‡ª babynames åŒ…çš„æ•°æ®ã€‚\n\nlibrary(tidyverse)\nlibrary(babynames)\n\nThrough this chapter, weâ€™ll use a mix of very simple inline examples so you can get the basic idea, the baby names data, and three character vectors from stringr:\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ··åˆä½¿ç”¨éå¸¸ç®€å•çš„å†…è”ç¤ºä¾‹ï¼Œä»¥ä¾¿ä½ äº†è§£åŸºæœ¬æ¦‚å¿µã€å©´å„¿å§“åæ•°æ®ä»¥åŠæ¥è‡ª stringr çš„ä¸‰ä¸ªå­—ç¬¦å‘é‡ï¼š\n\nfruit contains the names of 80 fruits.fruit åŒ…å«äº† 80 ç§æ°´æœçš„åç§°ã€‚\nwords contains 980 common English words.words åŒ…å«äº† 980 ä¸ªå¸¸è§çš„è‹±æ–‡å•è¯ã€‚\nsentences contains 720 short sentences.sentences åŒ…å«äº† 720 ä¸ªçŸ­å¥ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-reg-basics",
    "href": "regexps.html#sec-reg-basics",
    "title": "15Â  Regular expressions",
    "section": "\n15.2 Pattern basics",
    "text": "15.2 Pattern basics\nWeâ€™ll use str_view() to learn how regex patterns work. We used str_view() in the last chapter to better understand a string vs.Â its printed representation, and now weâ€™ll use it with its second argument, a regular expression. When this is supplied, str_view() will show only the elements of the string vector that match, surrounding each match with &lt;&gt;, and, where possible, highlighting the match in blue.\næˆ‘ä»¬å°†ä½¿ç”¨ str_view() æ¥å­¦ä¹ æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚åœ¨ä¸Šä¸€ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ str_view() æ¥æ›´å¥½åœ°ç†è§£å­—ç¬¦ä¸²ä¸å…¶æ‰“å°è¡¨ç¤ºä¹‹é—´çš„åŒºåˆ«ï¼Œç°åœ¨æˆ‘ä»¬å°†å…¶ä¸ç¬¬äºŒä¸ªå‚æ•°ï¼ˆä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼‰ä¸€èµ·ä½¿ç”¨ã€‚å½“æä¾›æ­¤å‚æ•°æ—¶ï¼Œstr_view() å°†ä»…æ˜¾ç¤ºå­—ç¬¦ä¸²å‘é‡ä¸­åŒ¹é…çš„å…ƒç´ ï¼Œç”¨ &lt;&gt; å°†æ¯ä¸ªåŒ¹é…é¡¹æ‹¬èµ·æ¥ï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ç”¨è“è‰²çªå‡ºæ˜¾ç¤ºåŒ¹é…é¡¹ã€‚\nThe simplest patterns consist of letters and numbers which match those characters exactly:\næœ€ç®€å•çš„æ¨¡å¼ç”±å­—æ¯å’Œæ•°å­—ç»„æˆï¼Œå®ƒä»¬ç²¾ç¡®åŒ¹é…è¿™äº›å­—ç¬¦ï¼š\n\nstr_view(fruit, \"berry\")\n#&gt;  [6] â”‚ bil&lt;berry&gt;\n#&gt;  [7] â”‚ black&lt;berry&gt;\n#&gt; [10] â”‚ blue&lt;berry&gt;\n#&gt; [11] â”‚ boysen&lt;berry&gt;\n#&gt; [19] â”‚ cloud&lt;berry&gt;\n#&gt; [21] â”‚ cran&lt;berry&gt;\n#&gt; ... and 8 more\n\nLetters and numbers match exactly and are called literal characters. Most punctuation characters, like ., +, *, [, ], and ?, have special meanings2 and are called metacharacters. For example, . will match any character3, so \"a.\" will match any string that contains an â€œaâ€ followed by another character :\nå­—æ¯å’Œæ•°å­—ç²¾ç¡®åŒ¹é…ï¼Œè¢«ç§°ä¸ºå­—é¢å­—ç¬¦ (literal characters)ã€‚å¤§å¤šæ•°æ ‡ç‚¹ç¬¦å·ï¼Œå¦‚ .ã€+ã€*ã€[ã€] å’Œ ?ï¼Œå…·æœ‰ç‰¹æ®Šå«ä¹‰2ï¼Œè¢«ç§°ä¸ºå…ƒå­—ç¬¦ (metacharacters)ã€‚ä¾‹å¦‚ï¼Œ. å°†åŒ¹é…ä»»ä½•å­—ç¬¦3ï¼Œæ‰€ä»¥ \"a.\" å°†åŒ¹é…ä»»ä½•åŒ…å«ä¸€ä¸ªâ€œaâ€åè·Ÿå¦ä¸€ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ï¼š\n\nstr_view(c(\"a\", \"ab\", \"ae\", \"bd\", \"ea\", \"eab\"), \"a.\")\n#&gt; [2] â”‚ &lt;ab&gt;\n#&gt; [3] â”‚ &lt;ae&gt;\n#&gt; [6] â”‚ e&lt;ab&gt;\n\nOr we could find all the fruits that contain an â€œaâ€, followed by three letters, followed by an â€œeâ€:\næˆ–è€…æˆ‘ä»¬å¯ä»¥æ‰¾åˆ°æ‰€æœ‰åŒ…å«ä¸€ä¸ªâ€œaâ€ï¼Œåè·Ÿä¸‰ä¸ªå­—æ¯ï¼Œå†åè·Ÿä¸€ä¸ªâ€œeâ€çš„æ°´æœï¼š\n\nstr_view(fruit, \"a...e\")\n#&gt;  [1] â”‚ &lt;apple&gt;\n#&gt;  [7] â”‚ bl&lt;ackbe&gt;rry\n#&gt; [48] â”‚ mand&lt;arine&gt;\n#&gt; [51] â”‚ nect&lt;arine&gt;\n#&gt; [62] â”‚ pine&lt;apple&gt;\n#&gt; [64] â”‚ pomegr&lt;anate&gt;\n#&gt; ... and 2 more\n\nQuantifiers control how many times a pattern can match:é‡è¯ (Quantifiers) æ§åˆ¶ä¸€ä¸ªæ¨¡å¼å¯ä»¥åŒ¹é…å¤šå°‘æ¬¡ï¼š\n\n? makes a pattern optional (i.e.Â it matches 0 or 1 times)? ä½¿æ¨¡å¼æˆä¸ºå¯é€‰çš„ï¼ˆå³å®ƒåŒ¹é… 0 æ¬¡æˆ– 1 æ¬¡ï¼‰\n+ lets a pattern repeat (i.e.Â it matches at least once) + è®©æ¨¡å¼é‡å¤ï¼ˆå³å®ƒè‡³å°‘åŒ¹é…ä¸€æ¬¡ï¼‰\n* lets a pattern be optional or repeat (i.e.Â it matches any number of times, including 0).* è®©æ¨¡å¼æˆä¸ºå¯é€‰çš„æˆ–é‡å¤çš„ï¼ˆå³å®ƒåŒ¹é…ä»»æ„æ¬¡æ•°ï¼ŒåŒ…æ‹¬ 0 æ¬¡ï¼‰ã€‚\n\n\n# ab? matches an \"a\", optionally followed by a \"b\".\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n#&gt; [1] â”‚ &lt;a&gt;\n#&gt; [2] â”‚ &lt;ab&gt;\n#&gt; [3] â”‚ &lt;ab&gt;b\n\n# ab+ matches an \"a\", followed by at least one \"b\".\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n#&gt; [2] â”‚ &lt;ab&gt;\n#&gt; [3] â”‚ &lt;abb&gt;\n\n# ab* matches an \"a\", followed by any number of \"b\"s.\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n#&gt; [1] â”‚ &lt;a&gt;\n#&gt; [2] â”‚ &lt;ab&gt;\n#&gt; [3] â”‚ &lt;abb&gt;\n\nCharacter classes are defined by [] and let you match a set of characters, e.g., [abcd] matches â€œaâ€, â€œbâ€, â€œcâ€, or â€œdâ€. You can also invert the match by starting with ^: [^abcd] matches anything except â€œaâ€, â€œbâ€, â€œcâ€, or â€œdâ€. We can use this idea to find the words containing an â€œxâ€ surrounded by vowels, or a â€œyâ€ surrounded by consonants:å­—ç¬¦ç±» (Character classes) ç”± [] å®šä¹‰ï¼Œè®©ä½ åŒ¹é…ä¸€ç»„å­—ç¬¦ï¼Œä¾‹å¦‚ [abcd] åŒ¹é… â€œaâ€ã€â€œbâ€ã€â€œcâ€ æˆ– â€œdâ€ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ä»¥ ^ å¼€å¤´æ¥åè½¬åŒ¹é…ï¼š[^abcd] åŒ¹é…é™¤ â€œaâ€ã€â€œbâ€ã€â€œcâ€ æˆ– â€œdâ€ ä¹‹å¤–çš„ä»»ä½•å†…å®¹ã€‚æˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæƒ³æ³•æ¥æŸ¥æ‰¾åŒ…å«è¢«å…ƒéŸ³åŒ…å›´çš„ â€œxâ€ æˆ–è¢«è¾…éŸ³åŒ…å›´çš„ â€œyâ€ çš„å•è¯ï¼š\n\nstr_view(words, \"[aeiou]x[aeiou]\")\n#&gt; [284] â”‚ &lt;exa&gt;ct\n#&gt; [285] â”‚ &lt;exa&gt;mple\n#&gt; [288] â”‚ &lt;exe&gt;rcise\n#&gt; [289] â”‚ &lt;exi&gt;st\nstr_view(words, \"[^aeiou]y[^aeiou]\")\n#&gt; [836] â”‚ &lt;sys&gt;tem\n#&gt; [901] â”‚ &lt;typ&gt;e\n\nYou can use alternation, |, to pick between one or more alternative patterns. For example, the following patterns look for fruits containing â€œappleâ€, â€œmelonâ€, or â€œnutâ€, or a repeated vowel.\nä½ å¯ä»¥ä½¿ç”¨äº¤æ›¿ (alternation)ï¼Œå³ |ï¼Œæ¥åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªå¤‡é€‰æ¨¡å¼ä¹‹é—´è¿›è¡Œé€‰æ‹©ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹æ¨¡å¼æŸ¥æ‰¾åŒ…å«â€œappleâ€ã€â€œmelonâ€æˆ–â€œnutâ€çš„æ°´æœï¼Œæˆ–è€…åŒ…å«é‡å¤å…ƒéŸ³çš„æ°´æœã€‚\n\nstr_view(fruit, \"apple|melon|nut\")\n#&gt;  [1] â”‚ &lt;apple&gt;\n#&gt; [13] â”‚ canary &lt;melon&gt;\n#&gt; [20] â”‚ coco&lt;nut&gt;\n#&gt; [52] â”‚ &lt;nut&gt;\n#&gt; [62] â”‚ pine&lt;apple&gt;\n#&gt; [72] â”‚ rock &lt;melon&gt;\n#&gt; ... and 1 more\nstr_view(fruit, \"aa|ee|ii|oo|uu\")\n#&gt;  [9] â”‚ bl&lt;oo&gt;d orange\n#&gt; [33] â”‚ g&lt;oo&gt;seberry\n#&gt; [47] â”‚ lych&lt;ee&gt;\n#&gt; [66] â”‚ purple mangost&lt;ee&gt;n\n\nRegular expressions are very compact and use a lot of punctuation characters, so they can seem overwhelming and hard to read at first. Donâ€™t worry; youâ€™ll get better with practice, and simple patterns will soon become second nature. Letâ€™s kick off that process by practicing with some useful stringr functions.\næ­£åˆ™è¡¨è¾¾å¼éå¸¸ç´§å‡‘ï¼Œä½¿ç”¨äº†å¤§é‡çš„æ ‡ç‚¹ç¬¦å·ï¼Œæ‰€ä»¥åˆçœ‹èµ·æ¥å¯èƒ½ä¼šè®©äººè§‰å¾—ä¸çŸ¥æ‰€æªï¼Œéš¾ä»¥é˜…è¯»ã€‚åˆ«æ‹…å¿ƒï¼Œé€šè¿‡ç»ƒä¹ ä½ ä¼šè¶Šæ¥è¶Šç†Ÿç»ƒï¼Œç®€å•çš„æ¨¡å¼å¾ˆå¿«å°±ä¼šæˆä¸ºä½ çš„ç¬¬äºŒå¤©æ€§ã€‚è®©æˆ‘ä»¬é€šè¿‡ç»ƒä¹ ä¸€äº›æœ‰ç”¨çš„ stringr å‡½æ•°æ¥å¼€å§‹è¿™ä¸ªè¿‡ç¨‹ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-stringr-regex-funs",
    "href": "regexps.html#sec-stringr-regex-funs",
    "title": "15Â  Regular expressions",
    "section": "\n15.3 Key functions",
    "text": "15.3 Key functions\nNow that youâ€™ve got the basics of regular expressions under your belt, letâ€™s use them with some stringr and tidyr functions. In the following section, youâ€™ll learn how to detect the presence or absence of a match, how to count the number of matches, how to replace a match with fixed text, and how to extract text using a pattern.\næ—¢ç„¶ä½ å·²ç»æŒæ¡äº†æ­£åˆ™è¡¨è¾¾å¼çš„åŸºç¡€çŸ¥è¯†ï¼Œè®©æˆ‘ä»¬å°†å®ƒä»¬ä¸ä¸€äº› stringr å’Œ tidyr å‡½æ•°ä¸€èµ·ä½¿ç”¨ã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ£€æµ‹åŒ¹é…çš„å­˜åœ¨ä¸å¦ï¼Œå¦‚ä½•è®¡ç®—åŒ¹é…çš„æ•°é‡ï¼Œå¦‚ä½•ç”¨å›ºå®šæ–‡æœ¬æ›¿æ¢åŒ¹é…ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨æ¨¡å¼æå–æ–‡æœ¬ã€‚\n\n15.3.1 Detect matches\nstr_detect() returns a logical vector that is TRUE if the pattern matches an element of the character vector and FALSE otherwise:str_detect() è¿”å›ä¸€ä¸ªé€»è¾‘å‘é‡ï¼Œå¦‚æœæ¨¡å¼åŒ¹é…å­—ç¬¦å‘é‡ä¸­çš„æŸä¸ªå…ƒç´ ï¼Œåˆ™ä¸º TRUEï¼Œå¦åˆ™ä¸º FALSEï¼š\n\nstr_detect(c(\"a\", \"b\", \"c\"), \"[aeiou]\")\n#&gt; [1]  TRUE FALSE FALSE\n\nSince str_detect() returns a logical vector of the same length as the initial vector, it pairs well with filter(). For example, this code finds all the most popular names containing a lower-case â€œxâ€:\nç”±äº str_detect() è¿”å›ä¸€ä¸ªä¸åˆå§‹å‘é‡é•¿åº¦ç›¸åŒçš„é€»è¾‘å‘é‡ï¼Œå®ƒä¸ filter() é…åˆå¾—å¾ˆå¥½ã€‚ä¾‹å¦‚ï¼Œè¿™æ®µä»£ç æŸ¥æ‰¾æ‰€æœ‰åŒ…å«å°å†™å­—æ¯â€œxâ€çš„æœ€å—æ¬¢è¿çš„åå­—ï¼š\n\nbabynames |&gt; \n  filter(str_detect(name, \"x\")) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 974 Ã— 2\n#&gt;   name           n\n#&gt;   &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 Alexander 665492\n#&gt; 2 Alexis    399551\n#&gt; 3 Alex      278705\n#&gt; 4 Alexandra 232223\n#&gt; 5 Max       148787\n#&gt; 6 Alexa     123032\n#&gt; # â„¹ 968 more rows\n\nWe can also use str_detect() with summarize() by pairing it with sum() or mean(): sum(str_detect(x, pattern)) tells you the number of observations that match and mean(str_detect(x, pattern)) tells you the proportion that match. For example, the following snippet computes and visualizes the proportion of baby names4 that contain â€œxâ€, broken down by year. It looks like theyâ€™ve radically increased in popularity lately!\næˆ‘ä»¬ä¹Ÿå¯ä»¥å°† str_detect() ä¸ summarize() ä¸€èµ·ä½¿ç”¨ï¼Œæ–¹æ³•æ˜¯å°†å…¶ä¸ sum() æˆ– mean() é…å¯¹ï¼šsum(str_detect(x, pattern)) å‘Šè¯‰ä½ åŒ¹é…çš„è§‚æµ‹æ•°é‡ï¼Œè€Œ mean(str_detect(x, pattern)) å‘Šè¯‰ä½ åŒ¹é…çš„æ¯”ä¾‹ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„ä»£ç ç‰‡æ®µè®¡ç®—å¹¶å¯è§†åŒ–äº†åŒ…å«â€œxâ€çš„å©´å„¿å§“å4çš„æ¯”ä¾‹ï¼ŒæŒ‰å¹´ä»½ç»†åˆ†ã€‚çœ‹èµ·æ¥å®ƒä»¬æœ€è¿‘çš„å—æ¬¢è¿ç¨‹åº¦æ€¥å‰§å¢åŠ ï¼\n\nbabynames |&gt; \n  group_by(year) |&gt; \n  summarize(prop_x = mean(str_detect(name, \"x\"))) |&gt; \n  ggplot(aes(x = year, y = prop_x)) + \n  geom_line()\n\n\n\n\n\n\n\nThere are two functions that are closely related to str_detect(): str_subset() and str_which(). str_subset() returns a character vector containing only the strings that match. str_which() returns an integer vector giving the positions of the strings that match.\næœ‰ä¸¤ä¸ªä¸ str_detect() å¯†åˆ‡ç›¸å…³çš„å‡½æ•°ï¼šstr_subset() å’Œ str_which()ã€‚str_subset() è¿”å›ä¸€ä¸ªåªåŒ…å«åŒ¹é…å­—ç¬¦ä¸²çš„å­—ç¬¦å‘é‡ã€‚str_which() è¿”å›ä¸€ä¸ªç»™å‡ºåŒ¹é…å­—ç¬¦ä¸²ä½ç½®çš„æ•´æ•°å‘é‡ã€‚\n\n15.3.2 Count matches\nThe next step up in complexity from str_detect() is str_count(): rather than a true or false, it tells you how many matches there are in each string.\næ¯” str_detect() æ›´å¤æ‚ä¸€æ­¥çš„æ˜¯ str_count()ï¼šå®ƒä¸æ˜¯è¿”å›çœŸæˆ–å‡ï¼Œè€Œæ˜¯å‘Šè¯‰ä½ æ¯ä¸ªå­—ç¬¦ä¸²ä¸­æœ‰å¤šå°‘ä¸ªåŒ¹é…é¡¹ã€‚\n\nx &lt;- c(\"apple\", \"banana\", \"pear\")\nstr_count(x, \"p\")\n#&gt; [1] 2 0 1\n\nNote that each match starts at the end of the previous match, i.e.Â regex matches never overlap. For example, in \"abababa\", how many times will the pattern \"aba\" match? Regular expressions say two, not three:\nè¯·æ³¨æ„ï¼Œæ¯ä¸ªåŒ¹é…éƒ½ä»å‰ä¸€ä¸ªåŒ¹é…çš„æœ«å°¾å¼€å§‹ï¼Œå³æ­£åˆ™è¡¨è¾¾å¼çš„åŒ¹é…ä»ä¸é‡å ã€‚ä¾‹å¦‚ï¼Œåœ¨ \"abababa\" ä¸­ï¼Œæ¨¡å¼ \"aba\" ä¼šåŒ¹é…å¤šå°‘æ¬¡ï¼Ÿæ­£åˆ™è¡¨è¾¾å¼ä¼šè¯´æ˜¯ä¸¤æ¬¡ï¼Œè€Œä¸æ˜¯ä¸‰æ¬¡ï¼š\n\nstr_count(\"abababa\", \"aba\")\n#&gt; [1] 2\nstr_view(\"abababa\", \"aba\")\n#&gt; [1] â”‚ &lt;aba&gt;b&lt;aba&gt;\n\nItâ€™s natural to use str_count() with mutate(). The following example uses str_count() with character classes to count the number of vowels and consonants in each name.\nå¾ˆè‡ªç„¶åœ°ï¼Œstr_count() å¯ä»¥ä¸ mutate() ä¸€èµ·ä½¿ç”¨ã€‚ä¸‹é¢çš„ä¾‹å­ä½¿ç”¨ str_count() å’Œå­—ç¬¦ç±»æ¥è®¡ç®—æ¯ä¸ªåå­—ä¸­å…ƒéŸ³å’Œè¾…éŸ³çš„æ•°é‡ã€‚\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 Ã— 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 Aaban        10      2          3\n#&gt; 2 Aabha         5      2          3\n#&gt; 3 Aabid         2      2          3\n#&gt; 4 Aabir         1      2          3\n#&gt; 5 Aabriella     5      4          5\n#&gt; 6 Aada          1      2          2\n#&gt; # â„¹ 97,304 more rows\n\nIf you look closely, youâ€™ll notice that thereâ€™s something off with our calculations: â€œAabanâ€ contains three â€œaâ€s, but our summary reports only two vowels. Thatâ€™s because regular expressions are case sensitive. There are three ways we could fix this:\nå¦‚æœä½ ä»”ç»†çœ‹ï¼Œä½ ä¼šå‘ç°æˆ‘ä»¬çš„è®¡ç®—æœ‰äº›é—®é¢˜ï¼šâ€œAabanâ€ åŒ…å«ä¸‰ä¸ª â€œaâ€ï¼Œä½†æˆ‘ä»¬çš„æ‘˜è¦åªæŠ¥å‘Šäº†ä¸¤ä¸ªå…ƒéŸ³ã€‚è¿™æ˜¯å› ä¸ºæ­£åˆ™è¡¨è¾¾å¼æ˜¯åŒºåˆ†å¤§å°å†™çš„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‰ç§æ–¹å¼æ¥ä¿®æ­£è¿™ä¸ªé—®é¢˜ï¼š\n\nAdd the upper case vowels to the character class: str_count(name, \"[aeiouAEIOU]\").\nå°†å¤§å†™å…ƒéŸ³æ·»åŠ åˆ°å­—ç¬¦ç±»ä¸­ï¼šstr_count(name, \"[aeiouAEIOU]\")ã€‚\nTell the regular expression to ignore case: str_count(name, regex(\"[aeiou]\", ignore_case = TRUE)). Weâ€™ll talk about more in Section 15.5.1.\nå‘Šè¯‰æ­£åˆ™è¡¨è¾¾å¼å¿½ç•¥å¤§å°å†™ï¼šstr_count(name, regex(&quot;[aeiou]&quot;, ignore_case = TRUE))ã€‚æˆ‘ä»¬å°†åœ¨ Section 15.5.1 ä¸­è¯¦ç»†è®¨è®ºã€‚\nUse str_to_lower() to convert the names to lower case: str_count(str_to_lower(name), &quot;[aeiou]&quot;).\nä½¿ç”¨ str_to_lower() å°†åç§°è½¬æ¢ä¸ºå°å†™ï¼šstr_count(str_to_lower(name), &quot;[aeiou]&quot;)ã€‚\n\nThis variety of approaches is pretty typical when working with strings â€” there are often multiple ways to reach your goal, either by making your pattern more complicated or by doing some preprocessing on your string. If you get stuck trying one approach, it can often be useful to switch gears and tackle the problem from a different perspective.\nè¿™ç§å¤šæ ·åŒ–çš„æ–¹æ³•åœ¨å¤„ç†å­—ç¬¦ä¸²æ—¶éå¸¸å…¸å‹â€”â€”é€šå¸¸æœ‰å¤šç§æ–¹å¼å¯ä»¥è¾¾åˆ°ä½ çš„ç›®æ ‡ï¼Œè¦ä¹ˆä½¿ä½ çš„æ¨¡å¼æ›´å¤æ‚ï¼Œè¦ä¹ˆå¯¹ä½ çš„å­—ç¬¦ä¸²è¿›è¡Œä¸€äº›é¢„å¤„ç†ã€‚å¦‚æœä½ åœ¨å°è¯•ä¸€ç§æ–¹æ³•æ—¶é‡åˆ°å›°éš¾ï¼Œæ¢ä¸ªè§’åº¦ä»ä¸åŒçš„è§†è§’æ¥è§£å†³é—®é¢˜é€šå¸¸ä¼šå¾ˆæœ‰ç”¨ã€‚\nIn this case, since weâ€™re applying two functions to the name, I think itâ€™s easier to transform it first:\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºæˆ‘ä»¬å¯¹åç§°åº”ç”¨äº†ä¸¤ä¸ªå‡½æ•°ï¼Œæˆ‘è®¤ä¸ºå…ˆè½¬æ¢å®ƒä¼šæ›´å®¹æ˜“ï¼š\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    name = str_to_lower(name),\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 Ã— 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 aaban        10      3          2\n#&gt; 2 aabha         5      3          2\n#&gt; 3 aabid         2      3          2\n#&gt; 4 aabir         1      3          2\n#&gt; 5 aabriella     5      5          4\n#&gt; 6 aada          1      3          1\n#&gt; # â„¹ 97,304 more rows\n\n\n15.3.3 Replace values\nAs well as detecting and counting matches, we can also modify them with str_replace() and str_replace_all(). str_replace() replaces the first match, and as the name suggests, str_replace_all() replaces all matches.\né™¤äº†æ£€æµ‹å’Œè®¡æ•°åŒ¹é…é¡¹ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ str_replace() å’Œ str_replace_all() æ¥ä¿®æ”¹å®ƒä»¬ã€‚str_replace() æ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹ï¼Œé¡¾åæ€ä¹‰ï¼Œstr_replace_all() æ›¿æ¢æ‰€æœ‰åŒ¹é…é¡¹ã€‚\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_replace_all(x, \"[aeiou]\", \"-\")\n#&gt; [1] \"-ppl-\"  \"p--r\"   \"b-n-n-\"\n\nstr_remove() and str_remove_all() are handy shortcuts for str_replace(x, pattern, \"\"):str_remove() å’Œ str_remove_all() æ˜¯ str_replace(x, pattern, \"\") çš„ä¾¿æ·å¿«æ·æ–¹å¼ï¼š\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_remove_all(x, \"[aeiou]\")\n#&gt; [1] \"ppl\" \"pr\"  \"bnn\"\n\nThese functions are naturally paired with mutate() when doing data cleaning, and youâ€™ll often apply them repeatedly to peel off layers of inconsistent formatting.\nåœ¨è¿›è¡Œæ•°æ®æ¸…æ´—æ—¶ï¼Œè¿™äº›å‡½æ•°å¾ˆè‡ªç„¶åœ°ä¸ mutate() é…å¯¹ä½¿ç”¨ï¼Œä½ é€šå¸¸ä¼šé‡å¤åº”ç”¨å®ƒä»¬æ¥å‰¥ç¦»ä¸ä¸€è‡´çš„æ ¼å¼å±‚ã€‚\n\n15.3.4 Extract variables\nThe last function weâ€™ll discuss uses regular expressions to extract data out of one column into one or more new columns: separate_wider_regex(). Itâ€™s a peer of the separate_wider_position() and separate_wider_delim() functions that you learned about in Section 14.4.2. These functions live in tidyr because they operate on (columns of) data frames, rather than individual vectors.\næˆ‘ä»¬è¦è®¨è®ºçš„æœ€åä¸€ä¸ªå‡½æ•°ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å°†æ•°æ®ä»ä¸€åˆ—æå–åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªæ–°åˆ—ä¸­ï¼šseparate_wider_regex()ã€‚å®ƒä¸ä½ åœ¨ Section 14.4.2 ä¸­å­¦åˆ°çš„ separate_wider_position() å’Œ separate_wider_delim() å‡½æ•°æ˜¯åŒç±»ã€‚è¿™äº›å‡½æ•°ä½äº tidyr åŒ…ä¸­ï¼Œå› ä¸ºå®ƒä»¬ä½œç”¨äºæ•°æ®æ¡†çš„ï¼ˆåˆ—ï¼‰ï¼Œè€Œä¸æ˜¯å•ä¸ªå‘é‡ã€‚\nLetâ€™s create a simple dataset to show how it works. Here we have some data derived from babynames where we have the name, gender, and age of a bunch of people in a rather weird format5:\nè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®é›†æ¥å±•ç¤ºå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚è¿™é‡Œæˆ‘ä»¬æœ‰ä¸€äº›ä» babynames æ´¾ç”Ÿçš„æ•°æ®ï¼Œå…¶ä¸­åŒ…å«äº†ä¸€ç¾¤äººçš„å§“åã€æ€§åˆ«å’Œå¹´é¾„ï¼Œæ ¼å¼ç›¸å½“å¥‡æ€ª5ï¼š\n\ndf &lt;- tribble(\n  ~str,\n  \"&lt;Sheryl&gt;-F_34\",\n  \"&lt;Kisha&gt;-F_45\", \n  \"&lt;Brandon&gt;-N_33\",\n  \"&lt;Sharon&gt;-F_38\", \n  \"&lt;Penny&gt;-F_58\",\n  \"&lt;Justin&gt;-M_41\", \n  \"&lt;Patricia&gt;-F_84\", \n)\n\nTo extract this data using separate_wider_regex() we just need to construct a sequence of regular expressions that match each piece. If we want the contents of that piece to appear in the output, we give it a name:\nè¦ä½¿ç”¨ separate_wider_regex() æå–è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬åªéœ€è¦æ„å»ºä¸€ç³»åˆ—åŒ¹é…æ¯ä¸ªéƒ¨åˆ†çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚å¦‚æœæˆ‘ä»¬å¸Œæœ›è¯¥éƒ¨åˆ†çš„å†…å®¹å‡ºç°åœ¨è¾“å‡ºä¸­ï¼Œæˆ‘ä»¬ç»™å®ƒä¸€ä¸ªåå­—ï¼š\n\ndf |&gt; \n  separate_wider_regex(\n    str,\n    patterns = c(\n      \"&lt;\", \n      name = \"[A-Za-z]+\", \n      \"&gt;-\", \n      gender = \".\",\n      \"_\",\n      age = \"[0-9]+\"\n    )\n  )\n#&gt; # A tibble: 7 Ã— 3\n#&gt;   name    gender age  \n#&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 Sheryl  F      34   \n#&gt; 2 Kisha   F      45   \n#&gt; 3 Brandon N      33   \n#&gt; 4 Sharon  F      38   \n#&gt; 5 Penny   F      58   \n#&gt; 6 Justin  M      41   \n#&gt; # â„¹ 1 more row\n\nIf the match fails, you can use too_few = \"debug\" to figure out what went wrong, just like separate_wider_delim() and separate_wider_position().\nå¦‚æœåŒ¹é…å¤±è´¥ï¼Œä½ å¯ä»¥ä½¿ç”¨ too_few = \"debug\" æ¥æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ï¼Œå°±åƒ separate_wider_delim() å’Œ separate_wider_position() ä¸€æ ·ã€‚\n\n15.3.5 Exercises\n\nWhat baby name has the most vowels? What name has the highest proportion of vowels? (Hint: what is the denominator?)\nReplace all forward slashes in \"a/b/c/d/e\" with backslashes. What happens if you attempt to undo the transformation by replacing all backslashes with forward slashes? (Weâ€™ll discuss the problem very soon.)\nImplement a simple version of str_to_lower() using str_replace_all().\nCreate a regular expression that will match telephone numbers as commonly written in your country.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#pattern-details",
    "href": "regexps.html#pattern-details",
    "title": "15Â  Regular expressions",
    "section": "\n15.4 Pattern details",
    "text": "15.4 Pattern details\nNow that you understand the basics of the pattern language and how to use it with some stringr and tidyr functions, itâ€™s time to dig into more of the details. First, weâ€™ll start with escaping, which allows you to match metacharacters that would otherwise be treated specially. Next, youâ€™ll learn about anchors which allow you to match the start or end of the string. Then, youâ€™ll learn more about character classes and their shortcuts which allow you to match any character from a set. Next, youâ€™ll learn the final details of quantifiers which control how many times a pattern can match. Then, we have to cover the important (but complex) topic of operator precedence and parentheses. And weâ€™ll finish off with some details of grouping components of the pattern.\nç°åœ¨ä½ å·²ç»äº†è§£äº†æ¨¡å¼è¯­è¨€çš„åŸºç¡€çŸ¥è¯†ä»¥åŠå¦‚ä½•å°†å…¶ä¸ä¸€äº› stringr å’Œ tidyr å‡½æ•°ä¸€èµ·ä½¿ç”¨ï¼Œæ˜¯æ—¶å€™æ·±å…¥äº†è§£æ›´å¤šç»†èŠ‚äº†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä»è½¬ä¹‰ (escaping) å¼€å§‹ï¼Œå®ƒå…è®¸ä½ åŒ¹é…é‚£äº›åŸæœ¬ä¼šè¢«ç‰¹æ®Šå¤„ç†çš„å…ƒå­—ç¬¦ã€‚æ¥ä¸‹æ¥ï¼Œä½ å°†å­¦ä¹ é”šç‚¹ (anchors)ï¼Œå®ƒå…è®¸ä½ åŒ¹é…å­—ç¬¦ä¸²çš„å¼€å¤´æˆ–ç»“å°¾ã€‚ç„¶åï¼Œä½ å°†å­¦ä¹ æ›´å¤šå…³äºå­—ç¬¦ç±» (character classes) åŠå…¶å¿«æ·æ–¹å¼çš„çŸ¥è¯†ï¼Œè¿™äº›å¿«æ·æ–¹å¼å…è®¸ä½ åŒ¹é…é›†åˆä¸­çš„ä»»ä½•å­—ç¬¦ã€‚æ¥ä¸‹æ¥ï¼Œä½ å°†å­¦ä¹ é‡è¯ (quantifiers) çš„æœ€åç»†èŠ‚ï¼Œå®ƒæ§åˆ¶æ¨¡å¼å¯ä»¥åŒ¹é…å¤šå°‘æ¬¡ã€‚ç„¶åï¼Œæˆ‘ä»¬å¿…é¡»æ¶µç›–æ“ä½œç¬¦ä¼˜å…ˆçº§ (operator precedence) å’Œæ‹¬å·è¿™ä¸ªé‡è¦ï¼ˆä½†å¤æ‚ï¼‰çš„ä¸»é¢˜ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ä»¥åˆ†ç»„ (grouping) æ¨¡å¼ç»„ä»¶çš„ä¸€äº›ç»†èŠ‚ä½œä¸ºç»“å°¾ã€‚\nThe terms we use here are the technical names for each component. Theyâ€™re not always the most evocative of their purpose, but itâ€™s very helpful to know the correct terms if you later want to Google for more details.\næˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨çš„æœ¯è¯­æ˜¯æ¯ä¸ªç»„ä»¶çš„æŠ€æœ¯åç§°ã€‚å®ƒä»¬å¹¶ä¸æ€»æ˜¯æœ€èƒ½è¯´æ˜å…¶ç”¨é€”ï¼Œä½†å¦‚æœä½ ä»¥åæƒ³é€šè¿‡ Google æœç´¢æ›´å¤šç»†èŠ‚ï¼Œäº†è§£æ­£ç¡®çš„æœ¯è¯­ä¼šéå¸¸æœ‰å¸®åŠ©ã€‚\n\n15.4.1 Escaping\nIn order to match a literal ., you need an escape which tells the regular expression to match metacharacters6 literally. Like strings, regexps use the backslash for escaping. So, to match a ., you need the regexp \\.. Unfortunately this creates a problem. We use strings to represent regular expressions, and \\ is also used as an escape symbol in strings. So to create the regular expression \\. we need the string \"\\\\.\", as the following example shows.\nä¸ºäº†åŒ¹é…å­—é¢æ„ä¹‰ä¸Šçš„ .ï¼Œä½ éœ€è¦ä¸€ä¸ªè½¬ä¹‰ (escape)ï¼Œå®ƒå‘Šè¯‰æ­£åˆ™è¡¨è¾¾å¼æŒ‰å­—é¢æ„ä¹‰åŒ¹é…å…ƒå­—ç¬¦6ã€‚ä¸å­—ç¬¦ä¸²ä¸€æ ·ï¼Œæ­£åˆ™è¡¨è¾¾å¼ä½¿ç”¨åæ–œæ è¿›è¡Œè½¬ä¹‰ã€‚å› æ­¤ï¼Œè¦åŒ¹é… .ï¼Œä½ éœ€è¦æ­£åˆ™è¡¨è¾¾å¼ \\.ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™ä¼šäº§ç”Ÿä¸€ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬ä½¿ç”¨å­—ç¬¦ä¸²æ¥è¡¨ç¤ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œè€Œ \\ åœ¨å­—ç¬¦ä¸²ä¸­ä¹Ÿç”¨ä½œè½¬ä¹‰ç¬¦å·ã€‚æ‰€ä»¥è¦åˆ›å»ºæ­£åˆ™è¡¨è¾¾å¼ \\.ï¼Œæˆ‘ä»¬éœ€è¦å­—ç¬¦ä¸² \"\\\\.\"ï¼Œå¦‚ä¸‹ä¾‹æ‰€ç¤ºã€‚\n\n# To create the regular expression \\., we need to use \\\\.\ndot &lt;- \"\\\\.\"\n\n# But the expression itself only contains one \\\nstr_view(dot)\n#&gt; [1] â”‚ \\.\n\n# And this tells R to look for an explicit .\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n#&gt; [2] â”‚ &lt;a.c&gt;\n\nIn this book, weâ€™ll usually write regular expression without quotes, like \\.. If we need to emphasize what youâ€™ll actually type, weâ€™ll surround it with quotes and add extra escapes, like \"\\\\.\".\nåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä¸å¸¦å¼•å·åœ°ç¼–å†™æ­£åˆ™è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ \\.ã€‚å¦‚æœæˆ‘ä»¬éœ€è¦å¼ºè°ƒä½ å®é™…è¾“å…¥çš„å†…å®¹ï¼Œæˆ‘ä»¬ä¼šç”¨å¼•å·å°†å…¶æ‹¬èµ·æ¥å¹¶æ·»åŠ é¢å¤–çš„è½¬ä¹‰ï¼Œä¾‹å¦‚ \"\\\\.\"ã€‚\nIf \\ is used as an escape character in regular expressions, how do you match a literal \\? Well, you need to escape it, creating the regular expression \\\\. To create that regular expression, you need to use a string, which also needs to escape \\. That means to match a literal \\ you need to write \"\\\\\\\\\" â€” you need four backslashes to match one!\nå¦‚æœåœ¨æ­£åˆ™è¡¨è¾¾å¼ä¸­ \\ è¢«ç”¨ä½œè½¬ä¹‰å­—ç¬¦ï¼Œé‚£ä¹ˆå¦‚ä½•åŒ¹é…å­—é¢æ„ä¹‰ä¸Šçš„ \\ å‘¢ï¼Ÿå—¯ï¼Œä½ éœ€è¦å¯¹å®ƒè¿›è¡Œè½¬ä¹‰ï¼Œä»è€Œåˆ›å»ºæ­£åˆ™è¡¨è¾¾å¼ \\\\ã€‚è¦åˆ›å»ºè¯¥æ­£åˆ™è¡¨è¾¾å¼ï¼Œä½ éœ€è¦ä½¿ç”¨ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè€Œè¯¥å­—ç¬¦ä¸²ä¹Ÿéœ€è¦å¯¹ \\ è¿›è¡Œè½¬ä¹‰ã€‚è¿™æ„å‘³ç€è¦åŒ¹é…ä¸€ä¸ªå­—é¢æ„ä¹‰ä¸Šçš„ \\ï¼Œä½ éœ€è¦å†™æˆ \"\\\\\\\\\" â€”â€” ä½ éœ€è¦å››ä¸ªåæ–œæ æ¥åŒ¹é…ä¸€ä¸ªï¼\n\nx &lt;- \"a\\\\b\"\nstr_view(x)\n#&gt; [1] â”‚ a\\b\nstr_view(x, \"\\\\\\\\\")\n#&gt; [1] â”‚ a&lt;\\&gt;b\n\nAlternatively, you might find it easier to use the raw strings you learned about in Section 14.2.2). That lets you avoid one layer of escaping:\næˆ–è€…ï¼Œä½ å¯èƒ½ä¼šå‘ç°ä½¿ç”¨åœ¨ Section 14.2.2 ä¸­å­¦åˆ°çš„åŸå§‹å­—ç¬¦ä¸² (raw strings) æ›´å®¹æ˜“ã€‚è¿™æ ·å¯ä»¥é¿å…ä¸€å±‚è½¬ä¹‰ï¼š\n\nstr_view(x, r\"{\\\\}\")\n#&gt; [1] â”‚ a&lt;\\&gt;b\n\nIf youâ€™re trying to match a literal ., $, |, *, +, ?, {, }, (, ), thereâ€™s an alternative to using a backslash escape: you can use a character class: [.], [$], [|], â€¦ all match the literal values.\nå¦‚æœä½ è¯•å›¾åŒ¹é…å­—é¢ä¸Šçš„ .ã€$ã€|ã€*ã€+ã€?ã€{ã€}ã€(ã€)ï¼Œé™¤äº†ä½¿ç”¨åæ–œæ è½¬ä¹‰å¤–ï¼Œè¿˜æœ‰å¦ä¸€ç§é€‰æ‹©ï¼šä½ å¯ä»¥ä½¿ç”¨å­—ç¬¦ç±»ï¼š[.]ã€[$]ã€[|] ç­‰éƒ½åŒ¹é…å­—é¢å€¼ã€‚\n\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[.]c\")\n#&gt; [2] â”‚ &lt;a.c&gt;\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \".[*]c\")\n#&gt; [3] â”‚ &lt;a*c&gt;\n\n\n15.4.2 Anchors\nBy default, regular expressions will match any part of a string. If you want to match at the start or end you need to anchor the regular expression using ^ to match the start or $ to match the end:\né»˜è®¤æƒ…å†µä¸‹ï¼Œæ­£åˆ™è¡¨è¾¾å¼å°†åŒ¹é…å­—ç¬¦ä¸²çš„ä»»ä½•éƒ¨åˆ†ã€‚å¦‚æœä½ æƒ³åœ¨å¼€å¤´æˆ–ç»“å°¾è¿›è¡ŒåŒ¹é…ï¼Œä½ éœ€è¦ä½¿ç”¨ ^ æ¥é”šå®š (anchor) æ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…å¼€å¤´ï¼Œæˆ–ä½¿ç”¨ $ æ¥åŒ¹é…ç»“å°¾ï¼š\n\nstr_view(fruit, \"^a\")\n#&gt; [1] â”‚ &lt;a&gt;pple\n#&gt; [2] â”‚ &lt;a&gt;pricot\n#&gt; [3] â”‚ &lt;a&gt;vocado\nstr_view(fruit, \"a$\")\n#&gt;  [4] â”‚ banan&lt;a&gt;\n#&gt; [15] â”‚ cherimoy&lt;a&gt;\n#&gt; [30] â”‚ feijo&lt;a&gt;\n#&gt; [36] â”‚ guav&lt;a&gt;\n#&gt; [56] â”‚ papay&lt;a&gt;\n#&gt; [74] â”‚ satsum&lt;a&gt;\n\nItâ€™s tempting to think that $ should match the start of a string, because thatâ€™s how we write dollar amounts, but thatâ€™s not what regular expressions want.\næˆ‘ä»¬å¾ˆè‡ªç„¶åœ°ä¼šè®¤ä¸º $ åº”è¯¥åŒ¹é…å­—ç¬¦ä¸²çš„å¼€å¤´ï¼Œå› ä¸ºæˆ‘ä»¬å°±æ˜¯è¿™æ ·å†™ç¾å…ƒé‡‘é¢çš„ï¼Œä½†æ­£åˆ™è¡¨è¾¾å¼å¹¶ä¸æ˜¯è¿™æ ·è®¾è®¡çš„ã€‚\nTo force a regular expression to match only the full string, anchor it with both ^ and $:\nè¦å¼ºåˆ¶ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼åªåŒ¹é…æ•´ä¸ªå­—ç¬¦ä¸²ï¼Œè¯·ä½¿ç”¨ ^ å’Œ $ å°†å…¶é”šå®šï¼š\n\nstr_view(fruit, \"apple\")\n#&gt;  [1] â”‚ &lt;apple&gt;\n#&gt; [62] â”‚ pine&lt;apple&gt;\nstr_view(fruit, \"^apple$\")\n#&gt; [1] â”‚ &lt;apple&gt;\n\nYou can also match the boundary between words (i.e.Â the start or end of a word) with \\b. This can be particularly useful when using RStudioâ€™s find and replace tool. For example, if to find all uses of sum(), you can search for \\bsum\\b to avoid matching summarize, summary, rowsum and so on:\nä½ è¿˜å¯ä»¥ä½¿ç”¨ \\b æ¥åŒ¹é…å•è¯ä¹‹é—´çš„è¾¹ç•Œï¼ˆå³å•è¯çš„å¼€å¤´æˆ–ç»“å°¾ï¼‰ã€‚è¿™åœ¨ä½¿ç”¨ RStudio çš„æŸ¥æ‰¾å’Œæ›¿æ¢å·¥å…·æ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœè¦æŸ¥æ‰¾ sum() çš„æ‰€æœ‰ç”¨æ³•ï¼Œä½ å¯ä»¥æœç´¢ \\bsum\\b ä»¥é¿å…åŒ¹é… summarizeã€summaryã€rowsum ç­‰ï¼š\n\nx &lt;- c(\"summary(x)\", \"summarize(df)\", \"rowsum(x)\", \"sum(x)\")\nstr_view(x, \"sum\")\n#&gt; [1] â”‚ &lt;sum&gt;mary(x)\n#&gt; [2] â”‚ &lt;sum&gt;marize(df)\n#&gt; [3] â”‚ row&lt;sum&gt;(x)\n#&gt; [4] â”‚ &lt;sum&gt;(x)\nstr_view(x, \"\\\\bsum\\\\b\")\n#&gt; [4] â”‚ &lt;sum&gt;(x)\n\nWhen used alone, anchors will produce a zero-width match:\nå½“å•ç‹¬ä½¿ç”¨æ—¶ï¼Œé”šç‚¹ä¼šäº§ç”Ÿä¸€ä¸ªé›¶å®½åº¦åŒ¹é…ï¼š\n\nstr_view(\"abc\", c(\"$\", \"^\", \"\\\\b\"))\n#&gt; [1] â”‚ abc&lt;&gt;\n#&gt; [2] â”‚ &lt;&gt;abc\n#&gt; [3] â”‚ &lt;&gt;abc&lt;&gt;\n\nThis helps you understand what happens when you replace a standalone anchor:\nè¿™æœ‰åŠ©äºä½ ç†è§£å½“ä½ æ›¿æ¢ä¸€ä¸ªç‹¬ç«‹çš„é”šç‚¹æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼š\n\nstr_replace_all(\"abc\", c(\"$\", \"^\", \"\\\\b\"), \"--\")\n#&gt; [1] \"abc--\"   \"--abc\"   \"--abc--\"\n\n\n15.4.3 Character classes\nA character class, or character set, allows you to match any character in a set. As we discussed above, you can construct your own sets with [], where [abc] matches â€œaâ€, â€œbâ€, or â€œcâ€ and [^abc] matches any character except â€œaâ€, â€œbâ€, or â€œcâ€. Apart from ^ there are two other characters that have special meaning inside of []:å­—ç¬¦ç±» (character class)ï¼Œæˆ–ç§°å­—ç¬¦é›† (set)ï¼Œå…è®¸ä½ åŒ¹é…ä¸€ä¸ªé›†åˆä¸­çš„ä»»ä½•å­—ç¬¦ã€‚å¦‚ä¸Šæ‰€è¿°ï¼Œä½ å¯ä»¥ä½¿ç”¨ [] æ„å»ºè‡ªå·±çš„é›†åˆï¼Œå…¶ä¸­ [abc] åŒ¹é… â€œaâ€ã€â€œbâ€ æˆ– â€œcâ€ï¼Œè€Œ [^abc] åŒ¹é…é™¤ â€œaâ€ã€â€œbâ€ æˆ– â€œcâ€ ä¹‹å¤–çš„ä»»ä½•å­—ç¬¦ã€‚é™¤äº† ^ï¼Œåœ¨ [] å†…éƒ¨è¿˜æœ‰å¦å¤–ä¸¤ä¸ªå…·æœ‰ç‰¹æ®Šå«ä¹‰çš„å­—ç¬¦ï¼š\n\n- defines a range, e.g., [a-z] matches any lower case letter and [0-9] matches any number.- å®šä¹‰ä¸€ä¸ªèŒƒå›´ï¼Œä¾‹å¦‚ [a-z] åŒ¹é…ä»»ä½•å°å†™å­—æ¯ï¼Œ[0-9] åŒ¹é…ä»»ä½•æ•°å­—ã€‚\n\\ escapes special characters, so [\\^-\\]] matches ^, -, or ].\\ è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼Œæ‰€ä»¥ [\\^-\\]] åŒ¹é… ^ã€- æˆ– ]ã€‚\n\nHere are few examples:\nè¿™é‡Œæœ‰ä¸€äº›ä¾‹å­ï¼š\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"[abc]+\")\n#&gt; [1] â”‚ &lt;abc&gt;d ABCD 12345 -!@#%.\nstr_view(x, \"[a-z]+\")\n#&gt; [1] â”‚ &lt;abcd&gt; ABCD 12345 -!@#%.\nstr_view(x, \"[^a-z0-9]+\")\n#&gt; [1] â”‚ abcd&lt; ABCD &gt;12345&lt; -!@#%.&gt;\n\n# You need an escape to match characters that are otherwise\n# special inside of []\nstr_view(\"a-b-c\", \"[a-c]\")\n#&gt; [1] â”‚ &lt;a&gt;-&lt;b&gt;-&lt;c&gt;\nstr_view(\"a-b-c\", \"[a\\\\-c]\")\n#&gt; [1] â”‚ &lt;a&gt;&lt;-&gt;b&lt;-&gt;&lt;c&gt;\n\nSome character classes are used so commonly that they get their own shortcut. Youâ€™ve already seen ., which matches any character apart from a newline. There are three other particularly useful pairs7:\næœ‰äº›å­—ç¬¦ç±»éå¸¸å¸¸ç”¨ï¼Œä»¥è‡³äºå®ƒä»¬æœ‰è‡ªå·±çš„å¿«æ·æ–¹å¼ã€‚ä½ å·²ç»è§è¿‡äº† .ï¼Œå®ƒåŒ¹é…é™¤æ¢è¡Œç¬¦ä»¥å¤–çš„ä»»ä½•å­—ç¬¦ã€‚è¿˜æœ‰å¦å¤–ä¸‰å¯¹ç‰¹åˆ«æœ‰ç”¨çš„å¿«æ·æ–¹å¼7ï¼š\n\n\\d matches any digit;\\D matches anything that isnâ€™t a digit.\\d åŒ¹é…ä»»ä½•æ•°å­—ï¼› \\D åŒ¹é…ä»»ä½•éæ•°å­—çš„å­—ç¬¦ã€‚\n\\s matches any whitespace (e.g., space, tab, newline);\\S matches anything that isnâ€™t whitespace.\\s åŒ¹é…ä»»ä½•ç©ºç™½å­—ç¬¦ï¼ˆä¾‹å¦‚ï¼Œç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€æ¢è¡Œç¬¦ï¼‰ï¼›\\S åŒ¹é…ä»»ä½•éç©ºç™½å­—ç¬¦ã€‚\n\\w matches any â€œwordâ€ character, i.e.Â letters and numbers;\\W matches any â€œnon-wordâ€ character.\\w åŒ¹é…ä»»ä½•â€œå•è¯â€å­—ç¬¦ï¼Œå³å­—æ¯å’Œæ•°å­—ï¼›\\W åŒ¹é…ä»»ä½•â€œéå•è¯â€å­—ç¬¦ã€‚\n\nThe following code demonstrates the six shortcuts with a selection of letters, numbers, and punctuation characters.\nä¸‹é¢çš„ä»£ç ç”¨ä¸€äº›å­—æ¯ã€æ•°å­—å’Œæ ‡ç‚¹ç¬¦å·æ¼”ç¤ºäº†è¿™å…­ä¸ªå¿«æ·æ–¹å¼ã€‚\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"\\\\d+\")\n#&gt; [1] â”‚ abcd ABCD &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\D+\")\n#&gt; [1] â”‚ &lt;abcd ABCD &gt;12345&lt; -!@#%.&gt;\nstr_view(x, \"\\\\s+\")\n#&gt; [1] â”‚ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; &gt;-!@#%.\nstr_view(x, \"\\\\S+\")\n#&gt; [1] â”‚ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; &lt;-!@#%.&gt;\nstr_view(x, \"\\\\w+\")\n#&gt; [1] â”‚ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\W+\")\n#&gt; [1] â”‚ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; -!@#%.&gt;\n\n\n15.4.4 Quantifiers\nQuantifiers control how many times a pattern matches. In Section 15.2 you learned about ? (0 or 1 matches), + (1 or more matches), and * (0 or more matches). For example, colou?r will match American or British spelling, \\d+ will match one or more digits, and \\s? will optionally match a single item of whitespace. You can also specify the number of matches precisely with {}:é‡è¯ (Quantifiers) æ§åˆ¶ä¸€ä¸ªæ¨¡å¼åŒ¹é…çš„æ¬¡æ•°ã€‚åœ¨ Section 15.2 ä¸­ä½ å­¦ä¹ äº† ?ï¼ˆ0 æˆ– 1 æ¬¡åŒ¹é…ï¼‰ã€+ï¼ˆ1 æ¬¡æˆ–å¤šæ¬¡åŒ¹é…ï¼‰å’Œ *ï¼ˆ0 æ¬¡æˆ–å¤šæ¬¡åŒ¹é…ï¼‰ã€‚ä¾‹å¦‚ï¼Œcolou?r å°†åŒ¹é…ç¾å¼æˆ–è‹±å¼æ‹¼å†™ï¼Œ\\d+ å°†åŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªæ•°å­—ï¼Œ\\s? å°†å¯é€‰åœ°åŒ¹é…ä¸€ä¸ªç©ºç™½é¡¹ã€‚ä½ è¿˜å¯ä»¥ä½¿ç”¨ {} ç²¾ç¡®æŒ‡å®šåŒ¹é…æ¬¡æ•°ï¼š\n\n{n} matches exactly n times.{n} ç²¾ç¡®åŒ¹é… n æ¬¡ã€‚\n{n,} matches at least n times. {n,} è‡³å°‘åŒ¹é… n æ¬¡ã€‚\n{n,m} matches between n and m times.{n,m} åŒ¹é… n åˆ° m æ¬¡ã€‚\n\n15.4.5 Operator precedence and parentheses\nWhat does ab+ match? Does it match â€œaâ€ followed by one or more â€œbâ€s, or does it match â€œabâ€ repeated any number of times? What does ^a|b$ match? Does it match the complete string a or the complete string b, or does it match a string starting with a or a string ending with b?ab+ åŒ¹é…ä»€ä¹ˆï¼Ÿæ˜¯åŒ¹é…ä¸€ä¸ª â€œaâ€ åé¢è·Ÿç€ä¸€ä¸ªæˆ–å¤šä¸ª â€œbâ€ï¼Œè¿˜æ˜¯åŒ¹é… â€œabâ€ é‡å¤ä»»æ„æ¬¡æ•°ï¼Ÿ^a|b$ åŒ¹é…ä»€ä¹ˆï¼Ÿæ˜¯åŒ¹é…å®Œæ•´çš„å­—ç¬¦ä¸² â€œaâ€ æˆ–å®Œæ•´çš„å­—ç¬¦ä¸² â€œbâ€ï¼Œè¿˜æ˜¯åŒ¹é…ä»¥ â€œaâ€ å¼€å¤´çš„å­—ç¬¦ä¸²æˆ–ä»¥ â€œbâ€ ç»“å°¾çš„å­—ç¬¦ä¸²ï¼Ÿ\nThe answer to these questions is determined by operator precedence, similar to the PEMDAS or BEDMAS rules you might have learned in school. You know that a + b * c is equivalent to a + (b * c) not (a + b) * c because * has higher precedence and + has lower precedence: you compute * before +.\nè¿™äº›é—®é¢˜çš„ç­”æ¡ˆç”±è¿ç®—ç¬¦ä¼˜å…ˆçº§å†³å®šï¼Œç±»ä¼¼äºä½ åœ¨å­¦æ ¡å¯èƒ½å­¦åˆ°çš„ PEMDAS æˆ– BEDMAS è§„åˆ™ã€‚ä½ çŸ¥é“ a + b * c ç­‰åŒäº a + (b * c) è€Œä¸æ˜¯ (a + b) * cï¼Œå› ä¸º * çš„ä¼˜å…ˆçº§é«˜äº +ï¼šä½ å…ˆè®¡ç®— * å†è®¡ç®— +ã€‚\nSimilarly, regular expressions have their own precedence rules: quantifiers have high precedence and alternation has low precedence which means that ab+ is equivalent to a(b+), and ^a|b$ is equivalent to (^a)|(b$). Just like with algebra, you can use parentheses to override the usual order. But unlike algebra youâ€™re unlikely to remember the precedence rules for regexes, so feel free to use parentheses liberally.\nç±»ä¼¼åœ°ï¼Œæ­£åˆ™è¡¨è¾¾å¼ä¹Ÿæœ‰è‡ªå·±çš„ä¼˜å…ˆçº§è§„åˆ™ï¼šé‡è¯å…·æœ‰é«˜ä¼˜å…ˆçº§ï¼Œè€Œäº¤æ›¿å…·æœ‰ä½ä¼˜å…ˆçº§ï¼Œè¿™æ„å‘³ç€ ab+ ç­‰ä»·äº a(b+)ï¼Œè€Œ ^a|b$ ç­‰ä»·äº (^a)|(b$)ã€‚å°±åƒä»£æ•°ä¸€æ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨æ‹¬å·æ¥è¦†ç›–é€šå¸¸çš„é¡ºåºã€‚ä½†ä¸ä»£æ•°ä¸åŒï¼Œä½ ä¸å¤ªå¯èƒ½è®°ä½æ­£åˆ™è¡¨è¾¾å¼çš„ä¼˜å…ˆçº§è§„åˆ™ï¼Œæ‰€ä»¥è¯·éšæ„å¤§é‡ä½¿ç”¨æ‹¬å·ã€‚\n\n15.4.6 Grouping and capturing\nAs well as overriding operator precedence, parentheses have another important effect: they create capturing groups that allow you to use sub-components of the match.\né™¤äº†è¦†ç›–è¿ç®—ç¬¦ä¼˜å…ˆçº§ï¼Œæ‹¬å·è¿˜æœ‰å¦ä¸€ä¸ªé‡è¦ä½œç”¨ï¼šå®ƒä»¬åˆ›å»ºäº†æ•è·ç»„ (capturing groups)ï¼Œå…è®¸ä½ ä½¿ç”¨åŒ¹é…çš„å­ç»„ä»¶ã€‚\nThe first way to use a capturing group is to refer back to it within a match with back reference: \\1 refers to the match contained in the first parenthesis, \\2 in the second parenthesis, and so on. For example, the following pattern finds all fruits that have a repeated pair of letters:\nä½¿ç”¨æ•è·ç»„çš„ç¬¬ä¸€ç§æ–¹æ³•æ˜¯åœ¨åŒ¹é…ä¸­ä½¿ç”¨åå‘å¼•ç”¨ (back reference) æ¥å¼•ç”¨å®ƒï¼š\\1 å¼•ç”¨ç¬¬ä¸€ä¸ªæ‹¬å·ä¸­åŒ…å«çš„åŒ¹é…é¡¹ï¼Œ\\2 å¼•ç”¨ç¬¬äºŒä¸ªæ‹¬å·ä¸­çš„åŒ¹é…é¡¹ï¼Œä¾æ­¤ç±»æ¨ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹æ¨¡å¼æŸ¥æ‰¾æ‰€æœ‰å…·æœ‰é‡å¤å­—æ¯å¯¹çš„æ°´æœï¼š\n\nstr_view(fruit, \"(..)\\\\1\")\n#&gt;  [4] â”‚ b&lt;anan&gt;a\n#&gt; [20] â”‚ &lt;coco&gt;nut\n#&gt; [22] â”‚ &lt;cucu&gt;mber\n#&gt; [41] â”‚ &lt;juju&gt;be\n#&gt; [56] â”‚ &lt;papa&gt;ya\n#&gt; [73] â”‚ s&lt;alal&gt; berry\n\nAnd this one finds all words that start and end with the same pair of letters:\nè€Œè¿™ä¸ªåˆ™æŸ¥æ‰¾æ‰€æœ‰ä»¥ç›¸åŒå­—æ¯å¯¹å¼€å¤´å’Œç»“å°¾çš„å•è¯ï¼š\n\nstr_view(words, \"^(..).*\\\\1$\")\n#&gt; [152] â”‚ &lt;church&gt;\n#&gt; [217] â”‚ &lt;decide&gt;\n#&gt; [617] â”‚ &lt;photograph&gt;\n#&gt; [699] â”‚ &lt;require&gt;\n#&gt; [739] â”‚ &lt;sense&gt;\n\nYou can also use back references in str_replace(). For example, this code switches the order of the second and third words in sentences:\nä½ ä¹Ÿå¯ä»¥åœ¨ str_replace() ä¸­ä½¿ç”¨åå‘å¼•ç”¨ã€‚ä¾‹å¦‚ï¼Œè¿™æ®µä»£ç äº¤æ¢äº† sentences ä¸­ç¬¬äºŒä¸ªå’Œç¬¬ä¸‰ä¸ªå•è¯çš„é¡ºåºï¼š\n\nsentences |&gt; \n  str_replace(\"(\\\\w+) (\\\\w+) (\\\\w+)\", \"\\\\1 \\\\3 \\\\2\") |&gt; \n  str_view()\n#&gt; [1] â”‚ The canoe birch slid on the smooth planks.\n#&gt; [2] â”‚ Glue sheet the to the dark blue background.\n#&gt; [3] â”‚ It's to easy tell the depth of a well.\n#&gt; [4] â”‚ These a days chicken leg is a rare dish.\n#&gt; [5] â”‚ Rice often is served in round bowls.\n#&gt; [6] â”‚ The of juice lemons makes fine punch.\n#&gt; ... and 714 more\n\nIf you want to extract the matches for each group you can use str_match(). But str_match() returns a matrix, so itâ€™s not particularly easy to work with8:\nå¦‚æœä½ æƒ³æå–æ¯ä¸ªç»„çš„åŒ¹é…é¡¹ï¼Œå¯ä»¥ä½¿ç”¨ str_match()ã€‚ä½†æ˜¯ str_match() è¿”å›ä¸€ä¸ªçŸ©é˜µï¼Œæ‰€ä»¥å¤„ç†èµ·æ¥ä¸æ˜¯ç‰¹åˆ«å®¹æ˜“8ï¼š\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  head()\n#&gt;      [,1]                [,2]     [,3]    \n#&gt; [1,] \"the smooth planks\" \"smooth\" \"planks\"\n#&gt; [2,] \"the sheet to\"      \"sheet\"  \"to\"    \n#&gt; [3,] \"the depth of\"      \"depth\"  \"of\"    \n#&gt; [4,] NA                  NA       NA      \n#&gt; [5,] NA                  NA       NA      \n#&gt; [6,] NA                  NA       NA\n\nYou could convert to a tibble and name the columns:\nä½ å¯ä»¥å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ª tibble å¹¶å‘½ååˆ—ï¼š\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  as_tibble(.name_repair = \"minimal\") |&gt; \n  set_names(\"match\", \"word1\", \"word2\")\n#&gt; # A tibble: 720 Ã— 3\n#&gt;   match             word1  word2 \n#&gt;   &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 the smooth planks smooth planks\n#&gt; 2 the sheet to      sheet  to    \n#&gt; 3 the depth of      depth  of    \n#&gt; 4 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 5 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 6 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; # â„¹ 714 more rows\n\nBut then youâ€™ve basically recreated your own version of separate_wider_regex(). Indeed, behind the scenes, separate_wider_regex() converts your vector of patterns to a single regex that uses grouping to capture the named components.\nä½†è¿™æ ·ä¸€æ¥ï¼Œä½ åŸºæœ¬ä¸Šå°±é‡æ–°åˆ›å»ºäº†è‡ªå·±ç‰ˆæœ¬çš„ separate_wider_regex()ã€‚å®é™…ä¸Šï¼Œåœ¨å¹•åï¼Œseparate_wider_regex() ä¼šå°†ä½ çš„æ¨¡å¼å‘é‡è½¬æ¢ä¸ºä¸€ä¸ªå•ä¸€çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¯¥è¡¨è¾¾å¼ä½¿ç”¨åˆ†ç»„æ¥æ•è·å‘½åçš„ç»„ä»¶ã€‚\nOccasionally, youâ€™ll want to use parentheses without creating matching groups. You can create a non-capturing group with (?:).\næœ‰æ—¶ï¼Œä½ ä¼šæƒ³ä½¿ç”¨æ‹¬å·è€Œä¸åˆ›å»ºåŒ¹é…ç»„ã€‚ä½ å¯ä»¥ä½¿ç”¨ (?:) åˆ›å»ºä¸€ä¸ªéæ•è·ç»„ã€‚\n\nx &lt;- c(\"a gray cat\", \"a grey dog\")\nstr_match(x, \"gr(e|a)y\")\n#&gt;      [,1]   [,2]\n#&gt; [1,] \"gray\" \"a\" \n#&gt; [2,] \"grey\" \"e\"\nstr_match(x, \"gr(?:e|a)y\")\n#&gt;      [,1]  \n#&gt; [1,] \"gray\"\n#&gt; [2,] \"grey\"\n\n\n15.4.7 Exercises\n\nHow would you match the literal string \"'\\? How about \"$^$\"?\nExplain why each of these patterns donâ€™t match a \\: \"\\\", \"\\\\\", \"\\\\\\\".\n\nGiven the corpus of common words in stringr::words, create regular expressions that find all words that:\n\nStart with â€œyâ€.\nDonâ€™t start with â€œyâ€.\nEnd with â€œxâ€.\nAre exactly three letters long. (Donâ€™t cheat by using str_length()!)\nHave seven letters or more.\nContain a vowel-consonant pair.\nContain at least two vowel-consonant pairs in a row.\nOnly consist of repeated vowel-consonant pairs.\n\n\nCreate 11 regular expressions that match the British or American spellings for each of the following words: airplane/aeroplane, aluminum/aluminium, analog/analogue, ass/arse, center/centre, defense/defence, donut/doughnut, gray/grey, modeling/modelling, skeptic/sceptic, summarize/summarise. Try and make the shortest possible regex!\nSwitch the first and last letters in words. Which of those strings are still words?\n\nDescribe in words what these regular expressions match: (read carefully to see if each entry is a regular expression or a string that defines a regular expression.)\n\n^.*$\n\"\\\\{.+\\\\}\"\n\\d{4}-\\d{2}-\\d{2}\n\"\\\\\\\\{4}\"\n\\..\\..\\..\n(.)\\1\\1\n\"(..)\\\\1\"\n\n\nSolve the beginner regexp crosswords at https://regexcrossword.com/challenges/beginner.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#pattern-control",
    "href": "regexps.html#pattern-control",
    "title": "15Â  Regular expressions",
    "section": "\n15.5 Pattern control",
    "text": "15.5 Pattern control\nItâ€™s possible to exercise extra control over the details of the match by using a pattern object instead of just a string. This allows you to control the so called regex flags and match various types of fixed strings, as described below.\né€šè¿‡ä½¿ç”¨æ¨¡å¼å¯¹è±¡è€Œä¸ä»…ä»…æ˜¯å­—ç¬¦ä¸²ï¼Œå¯ä»¥å¯¹åŒ¹é…çš„ç»†èŠ‚è¿›è¡Œé¢å¤–çš„æ§åˆ¶ã€‚è¿™å…è®¸ä½ æ§åˆ¶æ‰€è°“çš„æ­£åˆ™è¡¨è¾¾å¼æ ‡å¿—ï¼Œå¹¶åŒ¹é…å„ç§ç±»å‹çš„å›ºå®šå­—ç¬¦ä¸²ï¼Œå¦‚ä¸‹æ‰€è¿°ã€‚\n\n15.5.1 Regex flags\nThere are a number of settings that can be used to control the details of the regexp. These settings are often called flags in other programming languages. In stringr, you can use these by wrapping the pattern in a call to regex(). The most useful flag is probably ignore_case = TRUE because it allows characters to match either their uppercase or lowercase forms:\næœ‰è®¸å¤šè®¾ç½®å¯ç”¨äºæ§åˆ¶æ­£åˆ™è¡¨è¾¾å¼çš„ç»†èŠ‚ã€‚è¿™äº›è®¾ç½®åœ¨å…¶ä»–ç¼–ç¨‹è¯­è¨€ä¸­é€šå¸¸è¢«ç§°ä¸ºæ ‡å¿— (flags)ã€‚åœ¨ stringr ä¸­ï¼Œä½ å¯ä»¥é€šè¿‡å°†æ¨¡å¼åŒ…è£…åœ¨å¯¹ regex() çš„è°ƒç”¨ä¸­ä½¿ç”¨å®ƒä»¬ã€‚æœ€æœ‰ç”¨çš„æ ‡å¿—å¯èƒ½æ˜¯ ignore_case = TRUEï¼Œå› ä¸ºå®ƒå…è®¸å­—ç¬¦åŒ¹é…å…¶å¤§å†™æˆ–å°å†™å½¢å¼ï¼š\n\nbananas &lt;- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n#&gt; [1] â”‚ &lt;banana&gt;\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n#&gt; [1] â”‚ &lt;banana&gt;\n#&gt; [2] â”‚ &lt;Banana&gt;\n#&gt; [3] â”‚ &lt;BANANA&gt;\n\nIf youâ€™re doing a lot of work with multiline strings (i.e.Â strings that contain \\n), dotalland multiline may also be useful:\nå¦‚æœä½ æ­£åœ¨å¤„ç†å¤§é‡å¤šè¡Œå­—ç¬¦ä¸²ï¼ˆå³åŒ…å« \\n çš„å­—ç¬¦ä¸²ï¼‰ï¼Œdotall å’Œ multiline ä¹Ÿå¯èƒ½å¾ˆæœ‰ç”¨ï¼š\n\n\ndotall = TRUE lets . match everything, including \\n:dotall = TRUE è®© . åŒ¹é…æ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬ \\nï¼š\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \".Line\")\nstr_view(x, regex(\".Line\", dotall = TRUE))\n#&gt; [1] â”‚ Line 1&lt;\n#&gt;     â”‚ Line&gt; 2&lt;\n#&gt;     â”‚ Line&gt; 3\n\n\n\nmultiline = TRUE makes ^ and $ match the start and end of each line rather than the start and end of the complete string:multiline = TRUE ä½¿ ^ å’Œ $ åŒ¹é…æ¯è¡Œçš„å¼€å¤´å’Œç»“å°¾ï¼Œè€Œä¸æ˜¯æ•´ä¸ªå­—ç¬¦ä¸²çš„å¼€å¤´å’Œç»“å°¾ï¼š\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \"^Line\")\n#&gt; [1] â”‚ &lt;Line&gt; 1\n#&gt;     â”‚ Line 2\n#&gt;     â”‚ Line 3\nstr_view(x, regex(\"^Line\", multiline = TRUE))\n#&gt; [1] â”‚ &lt;Line&gt; 1\n#&gt;     â”‚ &lt;Line&gt; 2\n#&gt;     â”‚ &lt;Line&gt; 3\n\n\n\nFinally, if youâ€™re writing a complicated regular expression and youâ€™re worried you might not understand it in the future, you might try comments = TRUE. It tweaks the pattern language to ignore spaces and new lines, as well as everything after #. This allows you to use comments and whitespace to make complex regular expressions more understandable9, as in the following example:\næœ€åï¼Œå¦‚æœä½ æ­£åœ¨ç¼–å†™ä¸€ä¸ªå¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¹¶ä¸”æ‹…å¿ƒå°†æ¥å¯èƒ½æ— æ³•ç†è§£å®ƒï¼Œä½ å¯ä»¥å°è¯•ä½¿ç”¨ comments = TRUEã€‚å®ƒä¼šè°ƒæ•´æ¨¡å¼è¯­è¨€ï¼Œä½¿å…¶å¿½ç•¥ç©ºæ ¼å’Œæ¢è¡Œç¬¦ï¼Œä»¥åŠ # ä¹‹åçš„æ‰€æœ‰å†…å®¹ã€‚è¿™å…è®¸ä½ ä½¿ç”¨æ³¨é‡Šå’Œç©ºç™½æ¥ä½¿å¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼æ›´æ˜“äºç†è§£9ï¼Œå¦‚ä¸‹ä¾‹æ‰€ç¤ºï¼š\n\nphone &lt;- regex(\n  r\"(\n    \\(?     # optional opening parens\n    (\\d{3}) # area code\n    [)-]?  # optional closing parens or dash\n    \\ ?     # optional space\n    (\\d{3}) # another three numbers\n    [\\ -]?  # optional space or dash\n    (\\d{4}) # four more numbers\n  )\", \n  comments = TRUE\n)\n\nstr_extract(c(\"514-791-8141\", \"(123) 456 7890\", \"123456\"), phone)\n#&gt; [1] \"514-791-8141\"   \"(123) 456 7890\" NA\n\nIf youâ€™re using comments and want to match a space, newline, or #, youâ€™ll need to escape it with \\.\nå¦‚æœä½ æ­£åœ¨ä½¿ç”¨æ³¨é‡Šå¹¶ä¸”æƒ³è¦åŒ¹é…ç©ºæ ¼ã€æ¢è¡Œç¬¦æˆ– #ï¼Œä½ éœ€è¦ä½¿ç”¨ \\ å¯¹å…¶è¿›è¡Œè½¬ä¹‰ã€‚\n\n15.5.2 Fixed matches\nYou can opt-out of the regular expression rules by using fixed():\nä½ å¯ä»¥é€šè¿‡ä½¿ç”¨ fixed() æ¥é€‰æ‹©ä¸ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§„åˆ™ï¼š\n\nstr_view(c(\"\", \"a\", \".\"), fixed(\".\"))\n#&gt; [3] â”‚ &lt;.&gt;\n\nfixed() also gives you the ability to ignore case:fixed() è¿˜è®©ä½ èƒ½å¤Ÿå¿½ç•¥å¤§å°å†™ï¼š\n\nstr_view(\"x X\", \"X\")\n#&gt; [1] â”‚ x &lt;X&gt;\nstr_view(\"x X\", fixed(\"X\", ignore_case = TRUE))\n#&gt; [1] â”‚ &lt;x&gt; &lt;X&gt;\n\nIf youâ€™re working with non-English text, you will probably want coll() instead of fixed(), as it implements the full rules for capitalization as used by the locale you specify. See Section 14.6 for more details on locales.\nå¦‚æœä½ æ­£åœ¨å¤„ç†éè‹±è¯­æ–‡æœ¬ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨ coll() è€Œä¸æ˜¯ fixed()ï¼Œå› ä¸ºå®ƒå®ç°äº†ä½ æŒ‡å®šçš„ locale æ‰€ä½¿ç”¨çš„å®Œæ•´å¤§å†™è§„åˆ™ã€‚æœ‰å…³åŒºåŸŸè®¾ç½®çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… Section 14.6ã€‚\n\nstr_view(\"i Ä° Ä± I\", fixed(\"Ä°\", ignore_case = TRUE))\n#&gt; [1] â”‚ i &lt;Ä°&gt; Ä± I\nstr_view(\"i Ä° Ä± I\", coll(\"Ä°\", ignore_case = TRUE, locale = \"tr\"))\n#&gt; [1] â”‚ &lt;i&gt; &lt;Ä°&gt; Ä± I",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#practice",
    "href": "regexps.html#practice",
    "title": "15Â  Regular expressions",
    "section": "\n15.6 Practice",
    "text": "15.6 Practice\nTo put these ideas into practice weâ€™ll solve a few semi-authentic problems next. Weâ€™ll discuss three general techniques:\nä¸ºäº†å°†è¿™äº›æƒ³æ³•ä»˜è¯¸å®è·µï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥å°†è§£å†³ä¸€äº›åŠçœŸå®çš„é—®é¢˜ã€‚æˆ‘ä»¬å°†è®¨è®ºä¸‰ç§é€šç”¨æŠ€æœ¯ï¼š\n\nchecking your work by creating simple positive and negative controls\n\né€šè¿‡åˆ›å»ºç®€å•çš„é˜³æ€§å’Œé˜´æ€§å¯¹ç…§æ¥æ£€æŸ¥ä½ çš„å·¥ä½œ\n\ncombining regular expressions with Boolean algebra\n\n\n\n2. å°†æ­£åˆ™è¡¨è¾¾å¼ä¸å¸ƒå°”ä»£æ•°ç›¸ç»“åˆ 3. creating complex patterns using string manipulation\n3. ä½¿ç”¨å­—ç¬¦ä¸²æ“ä½œåˆ›å»ºå¤æ‚æ¨¡å¼\n\n15.6.1 Check your work\nFirst, letâ€™s find all sentences that start with â€œTheâ€. Using the ^ anchor alone is not enough:\né¦–å…ˆï¼Œè®©æˆ‘ä»¬æ‰¾åˆ°æ‰€æœ‰ä»¥â€œTheâ€å¼€å¤´çš„å¥å­ã€‚ä»…ä½¿ç”¨ ^ é”šç‚¹æ˜¯ä¸å¤Ÿçš„ï¼š\n\nstr_view(sentences, \"^The\")\n#&gt;  [1] â”‚ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [4] â”‚ &lt;The&gt;se days a chicken leg is a rare dish.\n#&gt;  [6] â”‚ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] â”‚ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] â”‚ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] â”‚ &lt;The&gt; boy was there when the sun rose.\n#&gt; ... and 271 more\n\nBecause that pattern also matches sentences starting with words like They or These. We need to make sure that the â€œeâ€ is the last letter in the word, which we can do by adding a word boundary:\nå› ä¸ºè¯¥æ¨¡å¼ä¹ŸåŒ¹é…ä»¥ They æˆ– These ç­‰è¯å¼€å¤´çš„å¥å­ã€‚æˆ‘ä»¬éœ€è¦ç¡®ä¿ â€œeâ€ æ˜¯å•è¯ä¸­çš„æœ€åä¸€ä¸ªå­—æ¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ·»åŠ ä¸€ä¸ªè¯è¾¹ç•Œæ¥å®ç°è¿™ä¸€ç‚¹ï¼š\n\nstr_view(sentences, \"^The\\\\b\")\n#&gt;  [1] â”‚ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [6] â”‚ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] â”‚ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] â”‚ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] â”‚ &lt;The&gt; boy was there when the sun rose.\n#&gt; [13] â”‚ &lt;The&gt; source of the huge river is the clear spring.\n#&gt; ... and 250 more\n\nWhat about finding all sentences that begin with a pronoun?\né‚£ä¹ˆï¼Œå¦‚ä½•æ‰¾åˆ°æ‰€æœ‰ä»¥ä»£è¯å¼€å¤´çš„å¥å­å‘¢ï¼Ÿ\n\nstr_view(sentences, \"^She|He|It|They\\\\b\")\n#&gt;  [3] â”‚ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt; [15] â”‚ &lt;He&gt;lp the woman get back to her feet.\n#&gt; [27] â”‚ &lt;He&gt;r purse was full of useless trash.\n#&gt; [29] â”‚ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt; [63] â”‚ &lt;He&gt; ran half way to the hardware store.\n#&gt; [90] â”‚ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; ... and 57 more\n\nA quick inspection of the results shows that weâ€™re getting some spurious matches. Thatâ€™s because weâ€™ve forgotten to use parentheses:\nå¿«é€Ÿæ£€æŸ¥ç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€äº›è™šå‡çš„åŒ¹é…ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬å¿˜è®°äº†ä½¿ç”¨æ‹¬å·ï¼š\n\nstr_view(sentences, \"^(She|He|It|They)\\\\b\")\n#&gt;   [3] â”‚ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt;  [29] â”‚ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt;  [63] â”‚ &lt;He&gt; ran half way to the hardware store.\n#&gt;  [90] â”‚ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; [116] â”‚ &lt;He&gt; ordered peach pie with ice cream.\n#&gt; [127] â”‚ &lt;It&gt; caught its hind paw in a rusty trap.\n#&gt; ... and 51 more\n\nYou might wonder how you might spot such a mistake if it didnâ€™t occur in the first few matches. A good technique is to create a few positive and negative matches and use them to test that your pattern works as expected:\nä½ å¯èƒ½ä¼šæƒ³ï¼Œå¦‚æœè¿™ç§é”™è¯¯æ²¡æœ‰å‡ºç°åœ¨å‰å‡ ä¸ªåŒ¹é…é¡¹ä¸­ï¼Œä½ è¯¥å¦‚ä½•å‘ç°å®ƒã€‚ä¸€ä¸ªå¥½çš„æŠ€å·§æ˜¯åˆ›å»ºä¸€äº›é˜³æ€§å’Œé˜´æ€§åŒ¹é…ï¼Œå¹¶ç”¨å®ƒä»¬æ¥æµ‹è¯•ä½ çš„æ¨¡å¼æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œï¼š\n\npos &lt;- c(\"He is a boy\", \"She had a good time\")\nneg &lt;- c(\"Shells come from the sea\", \"Hadley said 'It's a great day'\")\n\npattern &lt;- \"^(She|He|It|They)\\\\b\"\nstr_detect(pos, pattern)\n#&gt; [1] TRUE TRUE\nstr_detect(neg, pattern)\n#&gt; [1] FALSE FALSE\n\nItâ€™s typically much easier to come up with good positive examples than negative examples, because it takes a while before youâ€™re good enough with regular expressions to predict where your weaknesses are. Nevertheless, theyâ€™re still useful: as you work on the problem you can slowly accumulate a collection of your mistakes, ensuring that you never make the same mistake twice.\né€šå¸¸ï¼Œæƒ³å‡ºå¥½çš„æ­£é¢ä¾‹å­æ¯”è´Ÿé¢ä¾‹å­è¦å®¹æ˜“å¾—å¤šï¼Œå› ä¸ºä½ éœ€è¦ä¸€æ®µæ—¶é—´æ‰èƒ½ç†Ÿç»ƒæŒæ¡æ­£åˆ™è¡¨è¾¾å¼ï¼Œä»è€Œé¢„æµ‹ä½ çš„å¼±ç‚¹åœ¨å“ªé‡Œã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒä»¬ä»ç„¶å¾ˆæœ‰ç”¨ï¼šåœ¨è§£å†³é—®é¢˜çš„è¿‡ç¨‹ä¸­ï¼Œä½ å¯ä»¥æ…¢æ…¢ç§¯ç´¯ä½ çš„é”™è¯¯é›†åˆï¼Œç¡®ä¿ä½ ä¸ä¼šçŠ¯åŒæ ·çš„é”™è¯¯ä¸¤æ¬¡ã€‚\n\n15.6.2 Boolean operations\nImagine we want to find words that only contain consonants. One technique is to create a character class that contains all letters except for the vowels ([^aeiou]), then allow that to match any number of letters ([^aeiou]+), then force it to match the whole string by anchoring to the beginning and the end (^[^aeiou]+$):\næƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬æƒ³æ‰¾åˆ°åªåŒ…å«è¾…éŸ³çš„å•è¯ã€‚ä¸€ç§æ–¹æ³•æ˜¯åˆ›å»ºä¸€ä¸ªåŒ…å«é™¤å…ƒéŸ³å¤–æ‰€æœ‰å­—æ¯çš„å­—ç¬¦ç±» ([^aeiou])ï¼Œç„¶åè®©å®ƒåŒ¹é…ä»»æ„æ•°é‡çš„å­—æ¯ ([^aeiou]+)ï¼Œæœ€åé€šè¿‡é”šå®šåˆ°å¼€å¤´å’Œç»“å°¾ (^[^aeiou]+$) æ¥å¼ºåˆ¶å®ƒåŒ¹é…æ•´ä¸ªå­—ç¬¦ä¸²ï¼š\n\nstr_view(words, \"^[^aeiou]+$\")\n#&gt; [123] â”‚ &lt;by&gt;\n#&gt; [249] â”‚ &lt;dry&gt;\n#&gt; [328] â”‚ &lt;fly&gt;\n#&gt; [538] â”‚ &lt;mrs&gt;\n#&gt; [895] â”‚ &lt;try&gt;\n#&gt; [952] â”‚ &lt;why&gt;\n\nBut you can make this problem a bit easier by flipping the problem around. Instead of looking for words that contain only consonants, we could look for words that donâ€™t contain any vowels:\nä½†æ˜¯ä½ å¯ä»¥é€šè¿‡åå‘æ€è€ƒæ¥è®©è¿™ä¸ªé—®é¢˜å˜å¾—æ›´ç®€å•ã€‚ä¸å…¶å¯»æ‰¾åªåŒ…å«è¾…éŸ³çš„å•è¯ï¼Œæˆ‘ä»¬å¯ä»¥å¯»æ‰¾ä¸åŒ…å«ä»»ä½•å…ƒéŸ³çš„å•è¯ï¼š\n\nstr_view(words[!str_detect(words, \"[aeiou]\")])\n#&gt; [1] â”‚ by\n#&gt; [2] â”‚ dry\n#&gt; [3] â”‚ fly\n#&gt; [4] â”‚ mrs\n#&gt; [5] â”‚ try\n#&gt; [6] â”‚ why\n\nThis is a useful technique whenever youâ€™re dealing with logical combinations, particularly those involving â€œandâ€ or â€œnotâ€. For example, imagine if you want to find all words that contain â€œaâ€ and â€œbâ€. Thereâ€™s no â€œandâ€ operator built in to regular expressions so we have to tackle it by looking for all words that contain an â€œaâ€ followed by a â€œbâ€, or a â€œbâ€ followed by an â€œaâ€:\nåœ¨å¤„ç†é€»è¾‘ç»„åˆæ—¶ï¼Œè¿™æ˜¯ä¸€ç§æœ‰ç”¨çš„æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠâ€œä¸â€æˆ–â€œéâ€çš„ç»„åˆã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä½ æƒ³æŸ¥æ‰¾æ‰€æœ‰åŒæ—¶åŒ…å«â€œaâ€å’Œâ€œbâ€çš„å•è¯ã€‚æ­£åˆ™è¡¨è¾¾å¼ä¸­æ²¡æœ‰å†…ç½®çš„â€œä¸â€è¿ç®—ç¬¦ï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»é€šè¿‡æŸ¥æ‰¾æ‰€æœ‰åŒ…å«â€œaâ€åè·Ÿâ€œbâ€çš„å•è¯ï¼Œæˆ–è€…â€œbâ€åè·Ÿâ€œaâ€çš„å•è¯æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š\n\nstr_view(words, \"a.*b|b.*a\")\n#&gt;  [2] â”‚ &lt;ab&gt;le\n#&gt;  [3] â”‚ &lt;ab&gt;out\n#&gt;  [4] â”‚ &lt;ab&gt;solute\n#&gt; [62] â”‚ &lt;availab&gt;le\n#&gt; [66] â”‚ &lt;ba&gt;by\n#&gt; [67] â”‚ &lt;ba&gt;ck\n#&gt; ... and 24 more\n\nItâ€™s simpler to combine the results of two calls to str_detect():\nå°†ä¸¤æ¬¡è°ƒç”¨ str_detect() çš„ç»“æœç»“åˆèµ·æ¥ä¼šæ›´ç®€å•ï¼š\n\nwords[str_detect(words, \"a\") & str_detect(words, \"b\")]\n#&gt;  [1] \"able\"      \"about\"     \"absolute\"  \"available\" \"baby\"      \"back\"     \n#&gt;  [7] \"bad\"       \"bag\"       \"balance\"   \"ball\"      \"bank\"      \"bar\"      \n#&gt; [13] \"base\"      \"basis\"     \"bear\"      \"beat\"      \"beauty\"    \"because\"  \n#&gt; [19] \"black\"     \"board\"     \"boat\"      \"break\"     \"brilliant\" \"britain\"  \n#&gt; [25] \"debate\"    \"husband\"   \"labour\"    \"maybe\"     \"probable\"  \"table\"\n\nWhat if we wanted to see if there was a word that contains all vowels? If we did it with patterns weâ€™d need to generate 5! (120) different patterns:\nå¦‚æœæˆ‘ä»¬æƒ³çœ‹çœ‹æ˜¯å¦æœ‰ä¸€ä¸ªå•è¯åŒ…å«æ‰€æœ‰å…ƒéŸ³æ€ä¹ˆåŠï¼Ÿå¦‚æœç”¨æ¨¡å¼æ¥åšï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆ 5! (120) ä¸ªä¸åŒçš„æ¨¡å¼ï¼š\n\nwords[str_detect(words, \"a.*e.*i.*o.*u\")]\n# ...\nwords[str_detect(words, \"u.*o.*i.*e.*a\")]\n\nItâ€™s much simpler to combine five calls to str_detect():\nç»“åˆäº”æ¬¡è°ƒç”¨ str_detect() è¦ç®€å•å¾—å¤šï¼š\n\nwords[\n  str_detect(words, \"a\") &\n  str_detect(words, \"e\") &\n  str_detect(words, \"i\") &\n  str_detect(words, \"o\") &\n  str_detect(words, \"u\")\n]\n#&gt; character(0)\n\nIn general, if you get stuck trying to create a single regexp that solves your problem, take a step back and think if you could break the problem down into smaller pieces, solving each challenge before moving onto the next one.\næ€»çš„æ¥è¯´ï¼Œå¦‚æœä½ åœ¨å°è¯•åˆ›å»ºä¸€ä¸ªå•ä¸€çš„æ­£åˆ™è¡¨è¾¾å¼æ¥è§£å†³é—®é¢˜æ—¶é‡åˆ°å›°éš¾ï¼Œä¸å¦¨é€€åä¸€æ­¥ï¼Œæ€è€ƒæ˜¯å¦å¯ä»¥å°†é—®é¢˜åˆ†è§£æˆæ›´å°çš„éƒ¨åˆ†ï¼Œå…ˆè§£å†³æ¯ä¸ªæŒ‘æˆ˜ï¼Œç„¶åå†è¿›å…¥ä¸‹ä¸€ä¸ªã€‚\n\n15.6.3 Creating a pattern with code\nWhat if we wanted to find all sentences that mention a color? The basic idea is simple: we just combine alternation with word boundaries.\nå¦‚æœæˆ‘ä»¬æƒ³æ‰¾åˆ°æ‰€æœ‰æåˆ°é¢œè‰²çš„ sentences è¯¥æ€ä¹ˆåŠï¼ŸåŸºæœ¬æ€æƒ³å¾ˆç®€å•ï¼šæˆ‘ä»¬åªéœ€å°†äº¤æ›¿ä¸è¯è¾¹ç•Œç»“åˆèµ·æ¥ã€‚\n\nstr_view(sentences, \"\\\\b(red|green|blue)\\\\b\")\n#&gt;   [2] â”‚ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [26] â”‚ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [92] â”‚ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [148] â”‚ The spot on the blotter was made by &lt;green&gt; ink.\n#&gt; [160] â”‚ The sofa cushion is &lt;red&gt; and of light weight.\n#&gt; [174] â”‚ The sky that morning was clear and bright &lt;blue&gt;.\n#&gt; ... and 20 more\n\nBut as the number of colors grows, it would quickly get tedious to construct this pattern by hand. Wouldnâ€™t it be nice if we could store the colors in a vector?\nä½†æ˜¯éšç€é¢œè‰²æ•°é‡çš„å¢åŠ ï¼Œæ‰‹åŠ¨æ„å»ºè¿™ä¸ªæ¨¡å¼å¾ˆå¿«å°±ä¼šå˜å¾—ä¹å‘³ã€‚å¦‚æœèƒ½æŠŠé¢œè‰²å­˜å‚¨åœ¨ä¸€ä¸ªå‘é‡é‡Œï¼Œå²‚ä¸æ˜¯å¾ˆå¥½ï¼Ÿ\n\nrgb &lt;- c(\"red\", \"green\", \"blue\")\n\nWell, we can! Weâ€™d just need to create the pattern from the vector using str_c() and str_flatten():\nå—¯ï¼Œæˆ‘ä»¬å¯ä»¥ï¼æˆ‘ä»¬åªéœ€è¦ä½¿ç”¨ str_c() å’Œ str_flatten() ä»å‘é‡åˆ›å»ºæ¨¡å¼ï¼š\n\nstr_c(\"\\\\b(\", str_flatten(rgb, \"|\"), \")\\\\b\")\n#&gt; [1] \"\\\\b(red|green|blue)\\\\b\"\n\nWe could make this pattern more comprehensive if we had a good list of colors. One place we could start from is the list of built-in colors that R can use for plots:\nå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªå¥½çš„é¢œè‰²åˆ—è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿è¿™ä¸ªæ¨¡å¼æ›´å…¨é¢ã€‚ä¸€ä¸ªå¯ä»¥å¼€å§‹çš„åœ°æ–¹æ˜¯ R ä¸­ç”¨äºç»˜å›¾çš„å†…ç½®é¢œè‰²åˆ—è¡¨ï¼š\n\nstr_view(colors())\n#&gt; [1] â”‚ white\n#&gt; [2] â”‚ aliceblue\n#&gt; [3] â”‚ antiquewhite\n#&gt; [4] â”‚ antiquewhite1\n#&gt; [5] â”‚ antiquewhite2\n#&gt; [6] â”‚ antiquewhite3\n#&gt; ... and 651 more\n\nBut lets first eliminate the numbered variants:\nä½†è®©æˆ‘ä»¬é¦–å…ˆæ¶ˆé™¤å¸¦ç¼–å·çš„å˜ä½“ï¼š\n\ncols &lt;- colors()\ncols &lt;- cols[!str_detect(cols, \"\\\\d\")]\nstr_view(cols)\n#&gt; [1] â”‚ white\n#&gt; [2] â”‚ aliceblue\n#&gt; [3] â”‚ antiquewhite\n#&gt; [4] â”‚ aquamarine\n#&gt; [5] â”‚ azure\n#&gt; [6] â”‚ beige\n#&gt; ... and 137 more\n\nThen we can turn this into one giant pattern. We wonâ€™t show the pattern here because itâ€™s huge, but you can see it working:\nç„¶åæˆ‘ä»¬å¯ä»¥æŠŠå®ƒå˜æˆä¸€ä¸ªå·¨å¤§çš„æ¨¡å¼ã€‚æˆ‘ä»¬ä¸ä¼šåœ¨è¿™é‡Œæ˜¾ç¤ºè¿™ä¸ªæ¨¡å¼ï¼Œå› ä¸ºå®ƒå¤ªå¤§äº†ï¼Œä½†ä½ å¯ä»¥çœ‹åˆ°å®ƒçš„å·¥ä½œæ•ˆæœï¼š\n\npattern &lt;- str_c(\"\\\\b(\", str_flatten(cols, \"|\"), \")\\\\b\")\nstr_view(sentences, pattern)\n#&gt;   [2] â”‚ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [12] â”‚ A rod is used to catch &lt;pink&gt; &lt;salmon&gt;.\n#&gt;  [26] â”‚ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [66] â”‚ Cars and busses stalled in &lt;snow&gt; drifts.\n#&gt;  [92] â”‚ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [112] â”‚ Leaves turn &lt;brown&gt; and &lt;yellow&gt; in the fall.\n#&gt; ... and 57 more\n\nIn this example, cols only contains numbers and letters so you donâ€™t need to worry about metacharacters. But in general, whenever you create patterns from existing strings itâ€™s wise to run them through str_escape() to ensure they match literally.\nåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œcols åªåŒ…å«æ•°å­—å’Œå­—æ¯ï¼Œæ‰€ä»¥ä½ ä¸éœ€è¦æ‹…å¿ƒå…ƒå­—ç¬¦ã€‚ä½†æ€»çš„æ¥è¯´ï¼Œæ¯å½“ä½ ä»ç°æœ‰å­—ç¬¦ä¸²åˆ›å»ºæ¨¡å¼æ—¶ï¼Œæœ€å¥½å°†å®ƒä»¬é€šè¿‡ str_escape() å¤„ç†ï¼Œä»¥ç¡®ä¿å®ƒä»¬æ˜¯å­—é¢åŒ¹é…ã€‚\n\n15.6.4 Exercises\n\n\nFor each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple str_detect() calls.\n\nFind all words that start or end with x.\nFind all words that start with a vowel and end with a consonant.\nAre there any words that contain at least one of each different vowel?\n\n\nConstruct patterns to find evidence for and against the rule â€œi before e except after câ€?\ncolors() contains a number of modifiers like â€œlightgrayâ€ and â€œdarkblueâ€. How could you automatically identify these modifiers? (Think about how you might detect and then remove the colors that are modified).\nCreate a regular expression that finds any base R dataset. You can get a list of these datasets via a special use of the data() function: data(package = \"datasets\")$results[, \"Item\"]. Note that a number of old datasets are individual vectors; these contain the name of the grouping â€œdata frameâ€ in parentheses, so youâ€™ll need to strip those off.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#regular-expressions-in-other-places",
    "href": "regexps.html#regular-expressions-in-other-places",
    "title": "15Â  Regular expressions",
    "section": "\n15.7 Regular expressions in other places",
    "text": "15.7 Regular expressions in other places\nJust like in the stringr and tidyr functions, there are many other places in R where you can use regular expressions. The following sections describe some other useful functions in the wider tidyverse and base R.\nå°±åƒåœ¨ stringr å’Œ tidyr å‡½æ•°ä¸­ä¸€æ ·ï¼ŒR ä¸­è¿˜æœ‰è®¸å¤šå…¶ä»–åœ°æ–¹å¯ä»¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ã€‚ä»¥ä¸‹å„èŠ‚æè¿°äº†æ›´å¹¿æ³›çš„ tidyverse å’ŒåŸºç¡€ R ä¸­çš„ä¸€äº›å…¶ä»–æœ‰ç”¨å‡½æ•°ã€‚\n\n15.7.1 tidyverse\nThere are three other particularly useful places where you might want to use a regular expressions\nè¿˜æœ‰å¦å¤–ä¸‰ä¸ªç‰¹åˆ«æœ‰ç”¨çš„åœ°æ–¹ï¼Œä½ å¯èƒ½æƒ³åœ¨å…¶ä¸­ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼\n\nmatches(pattern) will select all variables whose name matches the supplied pattern. Itâ€™s a â€œtidyselectâ€ function that you can use anywhere in any tidyverse function that selects variables (e.g., select(), rename_with() and across()).matches(pattern) å°†é€‰æ‹©æ‰€æœ‰åç§°ä¸æ‰€æä¾›æ¨¡å¼åŒ¹é…çš„å˜é‡ã€‚å®ƒæ˜¯ä¸€ä¸ªâ€œtidyselectâ€å‡½æ•°ï¼Œä½ å¯ä»¥åœ¨ä»»ä½•é€‰æ‹©å˜é‡çš„ tidyverse å‡½æ•°ï¼ˆä¾‹å¦‚ select()ã€rename_with() å’Œ across()ï¼‰ä¸­ä½¿ç”¨å®ƒã€‚\npivot_longer()'s names_pattern argument takes a vector of regular expressions, just like separate_wider_regex(). Itâ€™s useful when extracting data out of variable names with a complex structurepivot_longer() çš„ names_pattern å‚æ•°æ¥å—ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼å‘é‡ï¼Œå°±åƒ separate_wider_regex() ä¸€æ ·ã€‚å½“ä»å…·æœ‰å¤æ‚ç»“æ„çš„å˜é‡åä¸­æå–æ•°æ®æ—¶ï¼Œå®ƒå¾ˆæœ‰ç”¨ã€‚\nThe delim argument in separate_longer_delim() and separate_wider_delim() usually matches a fixed string, but you can use regex() to make it match a pattern. This is useful, for example, if you want to match a comma that is optionally followed by a space, i.e.Â regex(\", ?\").separate_longer_delim() å’Œ separate_wider_delim() ä¸­çš„ delim å‚æ•°é€šå¸¸åŒ¹é…ä¸€ä¸ªå›ºå®šçš„å­—ç¬¦ä¸²ï¼Œä½†ä½ å¯ä»¥ä½¿ç”¨ regex() ä½¿å…¶åŒ¹é…ä¸€ä¸ªæ¨¡å¼ã€‚è¿™å¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³åŒ¹é…ä¸€ä¸ªé€—å·ï¼Œåé¢å¯ä»¥è·Ÿä¸€ä¸ªç©ºæ ¼ï¼Œå³ regex(\", ?\")ã€‚\n\n15.7.2 Base R\napropos(pattern) searches all objects available from the global environment that match the given pattern. This is useful if you canâ€™t quite remember the name of a function:apropos(pattern) åœ¨å…¨å±€ç¯å¢ƒä¸­æœç´¢æ‰€æœ‰ä¸ç»™å®šæ¨¡å¼åŒ¹é…çš„å¯ç”¨å¯¹è±¡ã€‚å¦‚æœä½ è®°ä¸å¤ªæ¸…å‡½æ•°åï¼Œè¿™ä¸ªåŠŸèƒ½ä¼šå¾ˆæœ‰ç”¨ï¼š\n\napropos(\"replace\")\n#&gt; [1] \"%+replace%\"       \"replace\"          \"replace_na\"      \n#&gt; [4] \"setReplaceMethod\" \"str_replace\"      \"str_replace_all\" \n#&gt; [7] \"str_replace_na\"   \"theme_replace\"\n\nlist.files(path, pattern) lists all files in path that match a regular expression pattern. For example, you can find all the R Markdown files in the current directory with:list.files(path, pattern) åˆ—å‡º path ä¸­æ‰€æœ‰åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼ pattern çš„æ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤æ‰¾åˆ°å½“å‰ç›®å½•ä¸­æ‰€æœ‰çš„ R Markdown æ–‡ä»¶ï¼š\n\nhead(list.files(pattern = \"\\\\.Rmd$\"))\n#&gt; character(0)\n\nItâ€™s worth noting that the pattern language used by base R is very slightly different to that used by stringr. Thatâ€™s because stringr is built on top of the stringi package, which is in turn built on top of the ICU engine, whereas base R functions use either the TRE engine or the PCRE engine, depending on whether or not youâ€™ve set perl = TRUE. Fortunately, the basics of regular expressions are so well established that youâ€™ll encounter few variations when working with the patterns youâ€™ll learn in this book. You only need to be aware of the difference when you start to rely on advanced features like complex Unicode character ranges or special features that use the (?â€¦) syntax.\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒåŸºç¡€ R ä½¿ç”¨çš„æ¨¡å¼è¯­è¨€ä¸ stringr ä½¿ç”¨çš„ç•¥æœ‰ä¸åŒã€‚è¿™æ˜¯å› ä¸º stringr æ˜¯å»ºç«‹åœ¨ stringi åŒ… ä¹‹ä¸Šçš„ï¼Œè€Œ stringi åŒ…åˆæ˜¯å»ºç«‹åœ¨ ICU å¼•æ“ ä¹‹ä¸Šçš„ï¼Œè€ŒåŸºç¡€ R å‡½æ•°åˆ™ä½¿ç”¨ TRE å¼•æ“ æˆ– PCRE å¼•æ“ï¼Œè¿™å–å†³äºä½ æ˜¯å¦è®¾ç½®äº† perl = TRUEã€‚å¹¸è¿çš„æ˜¯ï¼Œæ­£åˆ™è¡¨è¾¾å¼çš„åŸºç¡€çŸ¥è¯†å·²ç»éå¸¸æˆç†Ÿï¼Œå› æ­¤åœ¨ä½¿ç”¨æœ¬ä¹¦ä¸­å­¦åˆ°çš„æ¨¡å¼æ—¶ï¼Œä½ å‡ ä¹ä¸ä¼šé‡åˆ°ä»€ä¹ˆå˜åŒ–ã€‚ä½ åªéœ€è¦åœ¨å¼€å§‹ä¾èµ–é«˜çº§åŠŸèƒ½ï¼ˆå¦‚å¤æ‚çš„ Unicode å­—ç¬¦èŒƒå›´æˆ–ä½¿ç”¨ (?â€¦) è¯­æ³•çš„ç‰¹æ®ŠåŠŸèƒ½ï¼‰æ—¶æ„è¯†åˆ°è¿™ç§å·®å¼‚ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#summary",
    "href": "regexps.html#summary",
    "title": "15Â  Regular expressions",
    "section": "\n15.8 Summary",
    "text": "15.8 Summary\nWith every punctuation character potentially overloaded with meaning, regular expressions are one of the most compact languages out there. Theyâ€™re definitely confusing at first but as you train your eyes to read them and your brain to understand them, you unlock a powerful skill that you can use in R and in many other places.\nç”±äºæ¯ä¸ªæ ‡ç‚¹ç¬¦å·éƒ½å¯èƒ½è¢«èµ‹äºˆå¤šé‡å«ä¹‰ï¼Œæ­£åˆ™è¡¨è¾¾å¼æ˜¯ç°å­˜æœ€ç´§å‡‘çš„è¯­è¨€ä¹‹ä¸€ã€‚å®ƒä»¬èµ·åˆç¡®å®ä»¤äººå›°æƒ‘ï¼Œä½†éšç€ä½ è®­ç»ƒçœ¼ç›å»é˜…è¯»å®ƒä»¬ã€è®­ç»ƒå¤§è„‘å»ç†è§£å®ƒä»¬ï¼Œä½ å°†è§£é”ä¸€é¡¹å¼ºå¤§çš„æŠ€èƒ½ï¼Œå¯ä»¥åœ¨ R å’Œè®¸å¤šå…¶ä»–åœ°æ–¹ä½¿ç”¨ã€‚\nIn this chapter, youâ€™ve started your journey to become a regular expression master by learning the most useful stringr functions and the most important components of the regular expression language. And there are plenty of resources to learn more.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ é€šè¿‡å­¦ä¹ æœ€å®ç”¨çš„ stringr å‡½æ•°å’Œæ­£åˆ™è¡¨è¾¾å¼è¯­è¨€æœ€é‡è¦çš„ç»„æˆéƒ¨åˆ†ï¼Œå¼€å¯äº†æˆä¸ºæ­£åˆ™è¡¨è¾¾å¼å¤§å¸ˆçš„æ—…ç¨‹ã€‚å¹¶ä¸”æœ‰å¤§é‡çš„èµ„æºå¯ä»¥è®©ä½ å­¦ä¹ æ›´å¤šã€‚\nA good place to start is vignette(\"regular-expressions\", package = \"stringr\"): it documents the full set of syntax supported by stringr. Another useful reference is https://www.regular-expressions.info/. Itâ€™s not R specific, but you can use it to learn about the most advanced features of regexes and how they work under the hood.\nä¸€ä¸ªå¥½çš„èµ·ç‚¹æ˜¯ vignette(\"regular-expressions\", package = \"stringr\")ï¼šå®ƒè®°å½•äº† stringr æ”¯æŒçš„å®Œæ•´è¯­æ³•é›†ã€‚å¦ä¸€ä¸ªæœ‰ç”¨çš„å‚è€ƒæ˜¯ https://www.regular-expressions.info/ã€‚å®ƒå¹¶é R ä¸“å±ï¼Œä½†ä½ å¯ä»¥ç”¨å®ƒæ¥å­¦ä¹ æ­£åˆ™è¡¨è¾¾å¼æœ€é«˜çº§çš„åŠŸèƒ½ä»¥åŠå®ƒä»¬åœ¨åº•å±‚æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚\nItâ€™s also good to know that stringr is implemented on top of the stringi package by Marek Gagolewski. If youâ€™re struggling to find a function that does what you need in stringr, donâ€™t be afraid to look in stringi. Youâ€™ll find stringi very easy to pick up because it follows many of the the same conventions as stringr.\näº†è§£ stringr æ˜¯ç”± Marek Gagolewski åœ¨ stringi åŒ…ä¹‹ä¸Šå®ç°çš„ä¹Ÿå¾ˆæœ‰å¥½å¤„ã€‚å¦‚æœä½ åœ¨ stringr ä¸­æ‰¾ä¸åˆ°æ‰€éœ€åŠŸèƒ½çš„å‡½æ•°ï¼Œä¸è¦å®³æ€•å» stringi ä¸­å¯»æ‰¾ã€‚ä½ ä¼šå‘ç° stringi éå¸¸å®¹æ˜“ä¸Šæ‰‹ï¼Œå› ä¸ºå®ƒéµå¾ªäº†è®¸å¤šä¸ stringr ç›¸åŒçš„çº¦å®šã€‚\nIn the next chapter, weâ€™ll talk about a data structure closely related to strings: factors. Factors are used to represent categorical data in R, i.e.Â data with a fixed and known set of possible values identified by a vector of strings.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸€ç§ä¸å­—ç¬¦ä¸²å¯†åˆ‡ç›¸å…³çš„æ•°æ®ç»“æ„ï¼šå› å­ (factors)ã€‚å› å­ç”¨äºåœ¨ R ä¸­è¡¨ç¤ºåˆ†ç±»æ•°æ®ï¼Œå³å…·æœ‰ä¸€ç»„å›ºå®šçš„ã€å·²çŸ¥çš„å¯èƒ½å€¼çš„æ•°æ®ï¼Œè¿™äº›å€¼ç”±ä¸€ä¸ªå­—ç¬¦ä¸²å‘é‡æ ‡è¯†ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#footnotes",
    "href": "regexps.html#footnotes",
    "title": "15Â  Regular expressions",
    "section": "",
    "text": "You can pronounce it with either a hard-g (reg-x) or a soft-g (rej-x).â†©ï¸\nYouâ€™ll learn how to escape these special meanings in Section 15.4.1.â†©ï¸\nWell, any character apart from \\n.â†©ï¸\nThis gives us the proportion of names that contain an â€œxâ€; if you wanted the proportion of babies with a name containing an x, youâ€™d need to perform a weighted mean.â†©ï¸\nWe wish we could reassure you that youâ€™d never see something this weird in real life, but unfortunately over the course of your career youâ€™re likely to see much weirder!â†©ï¸\nThe complete set of metacharacters is .^$\\|*+?{}[]()â†©ï¸\nRemember, to create a regular expression containing \\d or \\s, youâ€™ll need to escape the \\ for the string, so youâ€™ll type \"\\\\d\" or \"\\\\s\".â†©ï¸\nMostly because we never discuss matrices in this book!â†©ï¸\ncomments = TRUE is particularly effective in combination with a raw string, as we use here.â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "factors.html",
    "href": "factors.html",
    "title": "16Â  Factors",
    "section": "",
    "text": "16.1 Introduction\nFactors are used for categorical variables, variables that have a fixed and known set of possible values.\nå› å­ (factor) ç”¨äºå¤„ç†åˆ†ç±»å˜é‡ (categorical variable)ï¼Œå³å–å€¼èŒƒå›´æ˜¯å›ºå®šçš„ã€å·²çŸ¥çš„æœ‰é™é›†åˆçš„å˜é‡ã€‚\nThey are also useful when you want to display character vectors in a non-alphabetical order.\nå½“ä½ æƒ³è¦ä»¥éå­—æ¯é¡ºåºæ˜¾ç¤ºå­—ç¬¦å‘é‡æ—¶ï¼Œå› å­ä¹Ÿå¾ˆæœ‰ç”¨ã€‚\nWeâ€™ll start by motivating why factors are needed for data analysis1 and how you can create them with factor().\næˆ‘ä»¬å°†é¦–å…ˆé˜è¿°ä¸ºä½•æ•°æ®åˆ†æéœ€è¦å› å­1ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ factor() å‡½æ•°åˆ›å»ºå®ƒä»¬ã€‚\nWeâ€™ll then introduce you to the gss_cat dataset which contains a bunch of categorical variables to experiment with.\næ¥ç€ï¼Œæˆ‘ä»¬å°†å‘ä½ ä»‹ç» gss_cat æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«è®¸å¤šåˆ†ç±»å˜é‡å¯ä¾›ä½ è¿›è¡Œå®éªŒã€‚\nYouâ€™ll then use that dataset to practice modifying the order and values of factors, before we finish up with a discussion of ordered factors.\nç„¶åï¼Œä½ å°†ä½¿ç”¨è¯¥æ•°æ®é›†ç»ƒä¹ ä¿®æ”¹å› å­çš„é¡ºåºå’Œå€¼ï¼Œæœ€åæˆ‘ä»¬å°†è®¨è®ºæœ‰åºå› å­ (ordered factor)ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#introduction",
    "href": "factors.html#introduction",
    "title": "16Â  Factors",
    "section": "",
    "text": "16.1.1 Prerequisites\nBase R provides some basic tools for creating and manipulating factors.\nåŸºç¡€ R æä¾›äº†ä¸€äº›ç”¨äºåˆ›å»ºå’Œæ“ä½œå› å­çš„åŸºæœ¬å·¥å…·ã€‚\nWeâ€™ll supplement these with the forcats package, which is part of the core tidyverse.\næˆ‘ä»¬å°†ä½¿ç”¨ forcats åŒ…ä½œä¸ºè¡¥å……ï¼Œå®ƒæ˜¯æ ¸å¿ƒ tidyverse çš„ä¸€éƒ¨åˆ†ã€‚\nIt provides tools for dealing with categorical variables (and itâ€™s an anagram of factors!) using a wide range of helpers for working with factors.\nå®ƒæä¾›äº†ä¸€ç³»åˆ—å¤„ç†åˆ†ç±» ( categorical ) å˜é‡çš„å·¥å…· ( forcats æ˜¯ factors çš„å˜ä½è¯ï¼)ï¼ŒåŒ…å«äº†å¤§é‡ç”¨äºå¤„ç†å› å­çš„è¾…åŠ©å‡½æ•°ã€‚\n\nlibrary(tidyverse)",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#factor-basics",
    "href": "factors.html#factor-basics",
    "title": "16Â  Factors",
    "section": "\n16.2 Factor basics",
    "text": "16.2 Factor basics\nImagine that you have a variable that records month:\næƒ³è±¡ä¸€ä¸‹ï¼Œä½ æœ‰ä¸€ä¸ªè®°å½•æœˆä»½çš„å˜é‡ï¼š\n\nx1 &lt;- c(\"Dec\", \"Apr\", \"Jan\", \"Mar\")\n\nUsing a string to record this variable has two problems:\nä½¿ç”¨å­—ç¬¦ä¸²æ¥è®°å½•æ­¤å˜é‡å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼š\n\n\nThere are only twelve possible months, and thereâ€™s nothing saving you from typos:\nåªæœ‰åäºŒä¸ªå¯èƒ½çš„æœˆä»½ï¼Œä½†æ²¡æœ‰ä»»ä½•æœºåˆ¶å¯ä»¥é˜²æ­¢ä½ è¾“å…¥é”™è¯¯ï¼š\n\nx2 &lt;- c(\"Dec\", \"Apr\", \"Jam\", \"Mar\")\n\n\n\nIt doesnâ€™t sort in a useful way:\nå®ƒçš„æ’åºæ–¹å¼æ²¡ä»€ä¹ˆç”¨ï¼š\n\nsort(x1)\n#&gt; [1] \"Apr\" \"Dec\" \"Jan\" \"Mar\"\n\n\n\nYou can fix both of these problems with a factor.\nä½ å¯ä»¥ç”¨å› å­æ¥è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚\nTo create a factor you must start by creating a list of the valid levels:\nè¦åˆ›å»ºä¸€ä¸ªå› å­ï¼Œä½ å¿…é¡»é¦–å…ˆåˆ›å»ºä¸€ä¸ªæœ‰æ•ˆæ°´å¹³ (levels) çš„åˆ—è¡¨ï¼š\n\nmonth_levels &lt;- c(\n  \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n)\n\nNow you can create a factor:\nç°åœ¨ä½ å¯ä»¥åˆ›å»ºä¸€ä¸ªå› å­ï¼š\n\ny1 &lt;- factor(x1, levels = month_levels)\ny1\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nsort(y1)\n#&gt; [1] Jan Mar Apr Dec\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nAnd any values not in the level will be silently converted to NA:\nä»»ä½•ä¸åœ¨æ°´å¹³ä¸­çš„å€¼éƒ½å°†è¢«é™é»˜åœ°è½¬æ¢ä¸º NAï¼š\n\ny2 &lt;- factor(x2, levels = month_levels)\ny2\n#&gt; [1] Dec  Apr  &lt;NA&gt; Mar \n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nThis seems risky, so you might want to use forcats::fct() instead:\nè¿™çœ‹èµ·æ¥æœ‰é£é™©ï¼Œæ‰€ä»¥ä½ å¯èƒ½æƒ³æ”¹ç”¨ forcats::fct()ï¼š\n\ny2 &lt;- fct(x2, levels = month_levels)\n#&gt; Error in `fct()`:\n#&gt; ! All values of `x` must appear in `levels` or `na`\n#&gt; â„¹ Missing level: \"Jam\"\n\nIf you omit the levels, theyâ€™ll be taken from the data in alphabetical order:\nå¦‚æœä½ çœç•¥äº†æ°´å¹³ (levels)ï¼Œå®ƒä»¬å°†æŒ‰å­—æ¯é¡ºåºä»æ•°æ®ä¸­æå–ï¼š\n\nfactor(x1)\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Apr Dec Jan Mar\n\nSorting alphabetically is slightly risky because not every computer will sort strings in the same way.\næŒ‰å­—æ¯é¡ºåºæ’åºæœ‰ç‚¹é£é™©ï¼Œå› ä¸ºå¹¶éæ¯å°è®¡ç®—æœºéƒ½ä»¥ç›¸åŒçš„æ–¹å¼å¯¹å­—ç¬¦ä¸²è¿›è¡Œæ’åºã€‚\nSo forcats::fct() orders by first appearance:\nå› æ­¤ï¼Œforcats::fct() ä¼šæŒ‰ç…§é¦–æ¬¡å‡ºç°çš„é¡ºåºè¿›è¡Œæ’åºï¼š\n\nfct(x1)\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Dec Apr Jan Mar\n\nIf you ever need to access the set of valid levels directly, you can do so with levels():\nå¦‚æœä½ éœ€è¦ç›´æ¥è®¿é—®æœ‰æ•ˆçš„æ°´å¹³é›†åˆï¼Œå¯ä»¥ä½¿ç”¨ levels() å‡½æ•°ï¼š\n\nlevels(y2)\n#&gt;  [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\nYou can also create a factor when reading your data with readr with col_factor():\nä½ ä¹Ÿå¯ä»¥åœ¨ä½¿ç”¨ readr è¯»å–æ•°æ®æ—¶ï¼Œé€šè¿‡ col_factor() æ¥åˆ›å»ºå› å­ï¼š\n\ncsv &lt;- \"\nmonth,value\nJan,12\nFeb,56\nMar,12\"\n\ndf &lt;- read_csv(csv, col_types = cols(month = col_factor(month_levels)))\ndf$month\n#&gt; [1] Jan Feb Mar\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#general-social-survey",
    "href": "factors.html#general-social-survey",
    "title": "16Â  Factors",
    "section": "\n16.3 General Social Survey",
    "text": "16.3 General Social Survey\nFor the rest of this chapter, weâ€™re going to use forcats::gss_cat.\nåœ¨æœ¬ç« çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ forcats::gss_cat æ•°æ®é›†ã€‚\nItâ€™s a sample of data from the General Social Survey, a long-running US survey conducted by the independent research organization NORC at the University of Chicago.\nå®ƒæ¥è‡ª General Social Survey çš„æ•°æ®æ ·æœ¬ï¼Œè¿™æ˜¯ç”±èŠåŠ å“¥å¤§å­¦çš„ç‹¬ç«‹ç ”ç©¶æœºæ„ NORC è¿›è¡Œçš„ä¸€é¡¹é•¿æœŸç¾å›½è°ƒæŸ¥ã€‚\nThe survey has thousands of questions, so in gss_cat Hadley selected a handful that will illustrate some common challenges youâ€™ll encounter when working with factors.\nè¯¥è°ƒæŸ¥åŒ…å«æ•°åƒä¸ªé—®é¢˜ï¼Œå› æ­¤åœ¨ gss_cat ä¸­ï¼ŒHadley é€‰æ‹©äº†ä¸€äº›èƒ½å¤Ÿè¯´æ˜ä½ åœ¨ä½¿ç”¨å› å­æ—¶ä¼šé‡åˆ°çš„ä¸€äº›å¸¸è§æŒ‘æˆ˜çš„é—®é¢˜ã€‚\n\ngss_cat\n#&gt; # A tibble: 21,483 Ã— 9\n#&gt;    year marital         age race  rincome        partyid           \n#&gt;   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;             \n#&gt; 1  2000 Never married    26 White $8000 to 9999  Ind,near rep      \n#&gt; 2  2000 Divorced         48 White $8000 to 9999  Not str republican\n#&gt; 3  2000 Widowed          67 White Not applicable Independent       \n#&gt; 4  2000 Never married    39 White Not applicable Ind,near rep      \n#&gt; 5  2000 Divorced         25 White Not applicable Not str democrat  \n#&gt; 6  2000 Married          25 White $20000 - 24999 Strong democrat   \n#&gt; # â„¹ 21,477 more rows\n#&gt; # â„¹ 3 more variables: relig &lt;fct&gt;, denom &lt;fct&gt;, tvhours &lt;int&gt;\n\n(Remember, since this dataset is provided by a package, you can get more information about the variables with ?gss_cat.)\nï¼ˆè¯·è®°ä½ï¼Œç”±äºè¯¥æ•°æ®é›†æ˜¯ç”±ä¸€ä¸ªåŒ…æä¾›çš„ï¼Œä½ å¯ä»¥ä½¿ç”¨ ?gss_cat è·å–æœ‰å…³å˜é‡çš„æ›´å¤šä¿¡æ¯ã€‚ï¼‰\nWhen factors are stored in a tibble, you canâ€™t see their levels so easily.\nå½“å› å­å­˜å‚¨åœ¨ tibble ä¸­æ—¶ï¼Œä½ æ— æ³•è½»æ˜“çœ‹åˆ°å®ƒä»¬çš„æ°´å¹³ã€‚\nOne way to view them is with count():\næŸ¥çœ‹å®ƒä»¬çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ count()ï¼š\n\ngss_cat |&gt;\n  count(race)\n#&gt; # A tibble: 3 Ã— 2\n#&gt;   race      n\n#&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1 Other  1959\n#&gt; 2 Black  3129\n#&gt; 3 White 16395\n\nWhen working with factors, the two most common operations are changing the order of the levels, and changing the values of the levels.\nåœ¨ä½¿ç”¨å› å­æ—¶ï¼Œä¸¤ä¸ªæœ€å¸¸è§çš„æ“ä½œæ˜¯æ›´æ”¹æ°´å¹³çš„é¡ºåºå’Œæ›´æ”¹æ°´å¹³çš„å€¼ã€‚\nThose operations are described in the sections below.\nè¿™äº›æ“ä½œå°†åœ¨ä¸‹é¢çš„ç« èŠ‚ä¸­æè¿°ã€‚\n\n16.3.1 Exercises\n\nExplore the distribution of rincome (reported income). What makes the default bar chart hard to understand? How could you improve the plot?\nWhat is the most common relig in this survey? Whatâ€™s the most common partyid?\nWhich relig does denom (denomination) apply to? How can you find out with a table? How can you find out with a visualization?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-modifying-factor-order",
    "href": "factors.html#sec-modifying-factor-order",
    "title": "16Â  Factors",
    "section": "\n16.4 Modifying factor order",
    "text": "16.4 Modifying factor order\nItâ€™s often useful to change the order of the factor levels in a visualization.\nåœ¨å¯è§†åŒ–ä¸­ï¼Œæ›´æ”¹å› å­æ°´å¹³çš„é¡ºåºé€šå¸¸å¾ˆæœ‰ç”¨ã€‚\nFor example, imagine you want to explore the average number of hours spent watching TV per day across religions:\nä¾‹å¦‚ï¼Œå‡è®¾ä½ æƒ³æ¢ç©¶ä¸åŒå®—æ•™æ¯å¤©çœ‹ç”µè§†çš„å¹³å‡å°æ—¶æ•°ï¼š\n\nrelig_summary &lt;- gss_cat |&gt;\n  group_by(relig) |&gt;\n  summarize(\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(relig_summary, aes(x = tvhours, y = relig)) +\n  geom_point()\n\n\n\n\n\n\n\nIt is hard to read this plot because thereâ€™s no overall pattern.\nè¿™å¼ å›¾å¾ˆéš¾è§£è¯»ï¼Œå› ä¸ºæ²¡æœ‰æ˜æ˜¾çš„æ•´ä½“æ¨¡å¼ã€‚\nWe can improve it by reordering the levels of relig using fct_reorder().\næˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ fct_reorder() é‡æ–°æ’åº relig çš„æ°´å¹³æ¥æ”¹è¿›å®ƒã€‚\nfct_reorder() takes three arguments:fct_reorder() æ¥å—ä¸‰ä¸ªå‚æ•°ï¼š\n\n.f, the factor whose levels you want to modify.\n.f, ä½ æƒ³è¦ä¿®æ”¹å…¶æ°´å¹³çš„å› å­ã€‚\n.x, a numeric vector that you want to use to reorder the levels.\n.x, ä¸€ä¸ªä½ æƒ³è¦ç”¨æ¥é‡æ–°æ’åºæ°´å¹³çš„æ•°å€¼å‘é‡ã€‚\nOptionally, .fun, a function thatâ€™s used if there are multiple values of .x for each value of .f. The default value is median.\nå¯é€‰çš„ .fun, ä¸€ä¸ªå‡½æ•°ï¼Œå½“ .f çš„æ¯ä¸ªå€¼å¯¹åº”å¤šä¸ª .x å€¼æ—¶ä½¿ç”¨ã€‚é»˜è®¤å€¼ä¸º medianã€‚\n\n\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n  geom_point()\n\n\n\n\n\n\n\nReordering religion makes it much easier to see that people in the â€œDonâ€™t knowâ€ category watch much more TV, and Hinduism & Other Eastern religions watch much less.\nå¯¹å®—æ•™è¿›è¡Œé‡æ–°æ’åºåï¼Œæˆ‘ä»¬å¯ä»¥æ›´å®¹æ˜“åœ°çœ‹å‡ºï¼Œâ€œDonâ€™t knowâ€ ç±»åˆ«çš„äººçœ‹ç”µè§†çš„æ—¶é—´è¦å¤šå¾—å¤šï¼Œè€Œå°åº¦æ•™ (Hinduism) å’Œå…¶ä»–ä¸œæ–¹å®—æ•™ (Other Eastern religions) çš„äººçœ‹ç”µè§†çš„æ—¶é—´åˆ™å°‘å¾—å¤šã€‚\nAs you start making more complicated transformations, we recommend moving them out of aes() and into a separate mutate() step.\nå½“ä½ å¼€å§‹è¿›è¡Œæ›´å¤æ‚çš„è½¬æ¢æ—¶ï¼Œæˆ‘ä»¬å»ºè®®å°†å®ƒä»¬ä» aes() ä¸­ç§»å‡ºï¼Œæ”¾åˆ°ä¸€ä¸ªå•ç‹¬çš„ mutate() æ­¥éª¤ä¸­ã€‚\nFor example, you could rewrite the plot above as:\nä¾‹å¦‚ï¼Œä½ å¯ä»¥å°†ä¸Šé¢çš„å›¾é‡å†™ä¸ºï¼š\n\nrelig_summary |&gt;\n  mutate(\n    relig = fct_reorder(relig, tvhours)\n  ) |&gt;\n  ggplot(aes(x = tvhours, y = relig)) +\n  geom_point()\n\nWhat if we create a similar plot looking at how average age varies across reported income level?\nå¦‚æœæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç±»ä¼¼çš„å›¾ï¼Œæ¥è§‚å¯Ÿå¹³å‡å¹´é¾„åœ¨ä¸åŒæŠ¥å‘Šæ”¶å…¥æ°´å¹³ä¸Šçš„å˜åŒ–æƒ…å†µï¼Œä¼šæ€ä¹ˆæ ·ï¼Ÿ\n\nrincome_summary &lt;- gss_cat |&gt;\n  group_by(rincome) |&gt;\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(rincome_summary, aes(x = age, y = fct_reorder(rincome, age))) +\n  geom_point()\n\n\n\n\n\n\n\nHere, arbitrarily reordering the levels isnâ€™t a good idea!\nåœ¨è¿™é‡Œï¼Œä»»æ„åœ°é‡æ–°æ’åºæ°´å¹³ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼\nThatâ€™s because rincome already has a principled order that we shouldnâ€™t mess with.\nè¿™æ˜¯å› ä¸º rincome å·²ç»æœ‰äº†ä¸€ä¸ªæˆ‘ä»¬ä¸åº”è¯¥æ‰“ä¹±çš„åŸåˆ™æ€§é¡ºåºã€‚\nReserve fct_reorder() for factors whose levels are arbitrarily ordered.\nè¯·å°† fct_reorder() ç”¨äºé‚£äº›æ°´å¹³æ˜¯ä»»æ„æ’åºçš„å› å­ã€‚\nHowever, it does make sense to pull â€œNot applicableâ€ to the front with the other special levels.\nç„¶è€Œï¼Œå°† â€œNot applicableâ€ å’Œå…¶ä»–ç‰¹æ®Šæ°´å¹³ä¸€èµ·ç§»åˆ°æœ€å‰é¢æ˜¯åˆç†çš„ã€‚\nYou can use fct_relevel().\nä½ å¯ä»¥ä½¿ç”¨ fct_relevel()ã€‚\nIt takes a factor, .f, and then any number of levels that you want to move to the front of the line.\nå®ƒæ¥å—ä¸€ä¸ªå› å­ .fï¼Œä»¥åŠä»»æ„æ•°é‡ä½ æƒ³è¦ç§»åŠ¨åˆ°æœ€å‰é¢çš„æ°´å¹³ã€‚\n\nggplot(rincome_summary, aes(x = age, y = fct_relevel(rincome, \"Not applicable\"))) +\n  geom_point()\n\n\n\n\n\n\n\nWhy do you think the average age for â€œNot applicableâ€ is so high?\nä½ è®¤ä¸º â€œNot applicableâ€ çš„å¹³å‡å¹´é¾„ä¸ºä»€ä¹ˆè¿™ä¹ˆé«˜ï¼Ÿ\nAnother type of reordering is useful when you are coloring the lines on a plot.\nå½“ä½ åœ¨å›¾ä¸Šä¸ºçº¿æ¡ç€è‰²æ—¶ï¼Œå¦ä¸€ç§é‡æ’åºä¹Ÿå¾ˆæœ‰ç”¨ã€‚\nfct_reorder2(.f, .x, .y) reorders the factor .f by the .y values associated with the largest .x values.fct_reorder2(.f, .x, .y) ä¼šæ ¹æ®ä¸æœ€å¤§ .x å€¼ç›¸å…³è”çš„ .y å€¼æ¥å¯¹å› å­ .f è¿›è¡Œé‡æ’åºã€‚\nThis makes the plot easier to read because the colors of the line at the far right of the plot will line up with the legend.\nè¿™ä½¿å¾—å›¾æ›´å®¹æ˜“é˜…è¯»ï¼Œå› ä¸ºå›¾æœ€å³ä¾§çš„çº¿æ¡é¢œè‰²å°†ä¸å›¾ä¾‹å¯¹é½ã€‚\nby_age &lt;- gss_cat |&gt;\n  filter(!is.na(age)) |&gt;\n  count(age, marital) |&gt;\n  group_by(age) |&gt;\n  mutate(\n    prop = n / sum(n)\n  )\n\nggplot(by_age, aes(x = age, y = prop, color = marital)) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\")\n\nggplot(by_age, aes(x = age, y = prop, color = fct_reorder2(marital, age, prop))) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(color = \"marital\")\n\n\n\n\n\n\n\n\n\n\nFinally, for bar plots, you can use fct_infreq() to order levels in decreasing frequency: this is the simplest type of reordering because it doesnâ€™t need any extra variables.\næœ€åï¼Œå¯¹äºæ¡å½¢å›¾ï¼Œä½ å¯ä»¥ä½¿ç”¨ fct_infreq() æŒ‰é¢‘ç‡é€’å‡çš„é¡ºåºæ’åˆ—æ°´å¹³ï¼šè¿™æ˜¯æœ€ç®€å•çš„é‡æ’åºç±»å‹ï¼Œå› ä¸ºå®ƒä¸éœ€è¦ä»»ä½•é¢å¤–çš„å˜é‡ã€‚\nCombine it with fct_rev() if you want them in increasing frequency so that in the bar plot largest values are on the right, not the left.\nå¦‚æœä½ å¸Œæœ›å®ƒä»¬æŒ‰é¢‘ç‡é€’å¢çš„é¡ºåºæ’åˆ—ï¼Œä»¥ä¾¿åœ¨æ¡å½¢å›¾ä¸­æœ€å¤§çš„å€¼åœ¨å³è¾¹è€Œä¸æ˜¯å·¦è¾¹ï¼Œå¯ä»¥å°†å…¶ä¸ fct_rev() ç»“åˆä½¿ç”¨ã€‚\n\ngss_cat |&gt;\n  mutate(marital = marital |&gt; fct_infreq() |&gt; fct_rev()) |&gt;\n  ggplot(aes(x = marital)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n16.4.1 Exercises\n\nThere are some suspiciously high numbers in tvhours. Is the mean a good summary?\nFor each factor in gss_cat identify whether the order of the levels is arbitrary or principled.\nWhy did moving â€œNot applicableâ€ to the front of the levels move it to the bottom of the plot?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#modifying-factor-levels",
    "href": "factors.html#modifying-factor-levels",
    "title": "16Â  Factors",
    "section": "\n16.5 Modifying factor levels",
    "text": "16.5 Modifying factor levels\nMore powerful than changing the orders of the levels is changing their values.\næ¯”æ›´æ”¹æ°´å¹³é¡ºåºæ›´å¼ºå¤§çš„æ˜¯æ›´æ”¹å®ƒä»¬çš„å€¼ã€‚\nThis allows you to clarify labels for publication, and collapse levels for high-level displays.\nè¿™å¯ä»¥è®©ä½ ä¸ºå‡ºç‰ˆç‰©æ¾„æ¸…æ ‡ç­¾ï¼Œå¹¶ä¸ºé«˜å±‚æ¬¡çš„å±•ç¤ºæŠ˜å æ°´å¹³ã€‚\nThe most general and powerful tool is fct_recode().\næœ€é€šç”¨å’Œæœ€å¼ºå¤§çš„å·¥å…·æ˜¯ fct_recode()ã€‚\nIt allows you to recode, or change, the value of each level.\nå®ƒå…è®¸ä½ é‡æ–°ç¼–ç  (recode)ï¼Œæˆ–æ›´æ”¹æ¯ä¸ªæ°´å¹³çš„å€¼ã€‚\nFor example, take the partyid variable from the gss_cat data frame:\nä¾‹å¦‚ï¼Œä»¥ gss_cat æ•°æ®æ¡†ä¸­çš„ partyid å˜é‡ä¸ºä¾‹ï¼š\n\ngss_cat |&gt; count(partyid)\n#&gt; # A tibble: 10 Ã— 2\n#&gt;   partyid                n\n#&gt;   &lt;fct&gt;              &lt;int&gt;\n#&gt; 1 No answer            154\n#&gt; 2 Don't know             1\n#&gt; 3 Other party          393\n#&gt; 4 Strong republican   2314\n#&gt; 5 Not str republican  3032\n#&gt; 6 Ind,near rep        1791\n#&gt; # â„¹ 4 more rows\n\nThe levels are terse and inconsistent.\nè¿™äº›æ°´å¹³æ—¢ç®€æ´åˆä¸ä¸€è‡´ã€‚\nLetâ€™s tweak them to be longer and use a parallel construction.\nè®©æˆ‘ä»¬è°ƒæ•´å®ƒä»¬ï¼Œä½¿å…¶æ›´é•¿å¹¶ä½¿ç”¨å¹¶åˆ—ç»“æ„ã€‚\nLike most rename and recoding functions in the tidyverse, the new values go on the left and the old values go on the right:\nåƒ tidyverse ä¸­å¤§å¤šæ•°é‡å‘½åå’Œé‡æ–°ç¼–ç çš„å‡½æ•°ä¸€æ ·ï¼Œæ–°å€¼åœ¨å·¦è¾¹ï¼Œæ—§å€¼åœ¨å³è¾¹ï¼š\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\"\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 10 Ã— 2\n#&gt;   partyid                   n\n#&gt;   &lt;fct&gt;                 &lt;int&gt;\n#&gt; 1 No answer               154\n#&gt; 2 Don't know                1\n#&gt; 3 Other party             393\n#&gt; 4 Republican, strong     2314\n#&gt; 5 Republican, weak       3032\n#&gt; 6 Independent, near rep  1791\n#&gt; # â„¹ 4 more rows\n\nfct_recode() will leave the levels that arenâ€™t explicitly mentioned as is, and will warn you if you accidentally refer to a level that doesnâ€™t exist.fct_recode() ä¼šä¿æŒæœªæ˜ç¡®æåŠçš„æ°´å¹³ä¸å˜ï¼Œå¹¶ä¸”å¦‚æœä½ æ„å¤–å¼•ç”¨äº†ä¸€ä¸ªä¸å­˜åœ¨çš„æ°´å¹³ï¼Œå®ƒä¼šå‘å‡ºè­¦å‘Šã€‚\nTo combine groups, you can assign multiple old levels to the same new level:\nè¦åˆå¹¶ç»„ï¼Œä½ å¯ä»¥å°†å¤šä¸ªæ—§æ°´å¹³åˆ†é…ç»™åŒä¸€ä¸ªæ–°æ°´å¹³ï¼š\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\",\n      \"Other\"                 = \"No answer\",\n      \"Other\"                 = \"Don't know\",\n      \"Other\"                 = \"Other party\"\n    )\n  )\n\nUse this technique with care: if you group together categories that are truly different you will end up with misleading results.\nè¯·è°¨æ…ä½¿ç”¨æ­¤æŠ€æœ¯ï¼šå¦‚æœå°†çœŸæ­£ä¸åŒçš„ç±»åˆ«ç»„åˆåœ¨ä¸€èµ·ï¼Œä½ å°†å¾—åˆ°è¯¯å¯¼æ€§çš„ç»“æœã€‚\nIf you want to collapse a lot of levels, fct_collapse() is a useful variant of fct_recode().\nå¦‚æœä½ æƒ³æŠ˜å è®¸å¤šæ°´å¹³ï¼Œfct_collapse() æ˜¯ fct_recode() çš„ä¸€ä¸ªæœ‰ç”¨å˜ä½“ã€‚\nFor each new variable, you can provide a vector of old levels:\nå¯¹äºæ¯ä¸ªæ–°å˜é‡ï¼Œä½ å¯ä»¥æä¾›ä¸€ä¸ªæ—§æ°´å¹³çš„å‘é‡ï¼š\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_collapse(partyid,\n      \"other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n      \"rep\" = c(\"Strong republican\", \"Not str republican\"),\n      \"ind\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n      \"dem\" = c(\"Not str democrat\", \"Strong democrat\")\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 4 Ã— 2\n#&gt;   partyid     n\n#&gt;   &lt;fct&gt;   &lt;int&gt;\n#&gt; 1 other     548\n#&gt; 2 rep      5346\n#&gt; 3 ind      8409\n#&gt; 4 dem      7180\n\nSometimes you just want to lump together the small groups to make a plot or table simpler.\næœ‰æ—¶ä½ åªæ˜¯æƒ³æŠŠå°çš„ç»„åˆå¹¶åœ¨ä¸€èµ·ï¼Œä½¿å›¾è¡¨æˆ–è¡¨æ ¼æ›´ç®€å•ã€‚\nThatâ€™s the job of the fct_lump_*() family of functions.\nè¿™æ˜¯ fct_lump_*() ç³»åˆ—å‡½æ•°çš„å·¥ä½œã€‚\nfct_lump_lowfreq() is a simple starting point that progressively lumps the smallest groups categories into â€œOtherâ€, always keeping â€œOtherâ€ as the smallest category.fct_lump_lowfreq() æ˜¯ä¸€ä¸ªç®€å•çš„èµ·ç‚¹ï¼Œå®ƒä¼šé€æ­¥å°†æœ€å°çš„ç»„ç±»åˆ«åˆå¹¶åˆ° â€œOtherâ€ ä¸­ï¼Œå¹¶å§‹ç»ˆä¿æŒ â€œOtherâ€ æ˜¯æœ€å°çš„ç±»åˆ«ã€‚\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_lowfreq(relig)) |&gt;\n  count(relig)\n#&gt; # A tibble: 2 Ã— 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Other      10637\n\nIn this case itâ€™s not very helpful: it is true that the majority of Americans in this survey are Protestant, but weâ€™d probably like to see some more details!\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒä¸æ˜¯å¾ˆæœ‰ç”¨ï¼šç¡®å®ï¼Œè¿™é¡¹è°ƒæŸ¥ä¸­çš„å¤§å¤šæ•°ç¾å›½äººæ˜¯æ–°æ•™å¾’ (Protestant)ï¼Œä½†æˆ‘ä»¬å¯èƒ½æƒ³çœ‹åˆ°æ›´å¤šç»†èŠ‚ï¼\nInstead, we can use the fct_lump_n() to specify that we want exactly 10 groups:\nç›¸åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ fct_lump_n() æ¥æŒ‡å®šæˆ‘ä»¬æƒ³è¦æ­£å¥½ 10 ä¸ªç»„ï¼š\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_n(relig, n = 10)) |&gt;\n  count(relig, sort = TRUE)\n#&gt; # A tibble: 10 Ã— 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Catholic    5124\n#&gt; 3 None        3523\n#&gt; 4 Christian    689\n#&gt; 5 Other        458\n#&gt; 6 Jewish       388\n#&gt; # â„¹ 4 more rows\n\nRead the documentation to learn about fct_lump_min() and fct_lump_prop() which are useful in other cases.\né˜…è¯»æ–‡æ¡£ä»¥äº†è§£ fct_lump_min() å’Œ fct_lump_prop()ï¼Œå®ƒä»¬åœ¨å…¶ä»–æƒ…å†µä¸‹ä¹Ÿå¾ˆæœ‰ç”¨ã€‚\n\n16.5.1 Exercises\n\nHow have the proportions of people identifying as Democrat, Republican, and Independent changed over time?\nHow could you collapse rincome into a small set of categories?\nNotice there are 9 groups (excluding other) in the fct_lump example above. Why not 10? (Hint: type ?fct_lump, and find the default for the argument other_level is â€œOtherâ€.)",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-ordered-factors",
    "href": "factors.html#sec-ordered-factors",
    "title": "16Â  Factors",
    "section": "\n16.6 Ordered factors",
    "text": "16.6 Ordered factors\nBefore we continue, itâ€™s important to briefly mention a special type of factor: ordered factors.\nåœ¨ç»§ç»­ä¹‹å‰ï¼Œæœ‰å¿…è¦ç®€è¦æåŠä¸€ç§ç‰¹æ®Šçš„å› å­ï¼šæœ‰åºå› å­ (ordered factor)ã€‚\nCreated with the ordered() function, ordered factors imply a strict ordering between levels, but donâ€™t specify anything about the magnitude of the differences between the levels.\næœ‰åºå› å­æ˜¯ä½¿ç”¨ ordered() å‡½æ•°åˆ›å»ºçš„ï¼Œå®ƒæ„å‘³ç€æ°´å¹³ä¹‹é—´å­˜åœ¨ä¸¥æ ¼çš„æ’åºï¼Œä½†æ²¡æœ‰æŒ‡å®šæ°´å¹³ä¹‹é—´å·®å¼‚çš„å¤§å°ã€‚\nYou use ordered factors when you know there the levels are ranked, but thereâ€™s no precise numerical ranking.\nå½“ä½ çŸ¥é“æ°´å¹³æœ‰æ’åä½†æ²¡æœ‰ç²¾ç¡®çš„æ•°å€¼æ’åæ—¶ï¼Œå°±å¯ä»¥ä½¿ç”¨æœ‰åºå› å­ã€‚\nYou can identify an ordered factor when its printed because it uses &lt; symbols between the factor levels:\nä½ å¯ä»¥é€šè¿‡æ‰“å°è¾“å‡ºæ¥è¯†åˆ«æœ‰åºå› å­ï¼Œå› ä¸ºå®ƒåœ¨å› å­æ°´å¹³ä¹‹é—´ä½¿ç”¨äº† &lt; ç¬¦å·ï¼š\n\nordered(c(\"a\", \"b\", \"c\"))\n#&gt; [1] a b c\n#&gt; Levels: a &lt; b &lt; c\n\nIn both base R and the tidyverse, ordered factors behave very similarly to regular factors.\nåœ¨åŸºç¡€ R å’Œ tidyverse ä¸­ï¼Œæœ‰åºå› å­çš„è¡Œä¸ºä¸å¸¸è§„å› å­éå¸¸ç›¸ä¼¼ã€‚\nThere are only two places where you might notice different behavior:\nåªæœ‰åœ¨ä¸¤ä¸ªåœ°æ–¹ä½ å¯èƒ½ä¼šæ³¨æ„åˆ°ä¸åŒçš„è¡Œä¸ºï¼š\n\nIf you map an ordered factor to color or fill in ggplot2, it will default to scale_color_viridis()/scale_fill_viridis(), a color scale that implies a ranking.\nå¦‚æœä½ åœ¨ ggplot2 ä¸­å°†æœ‰åºå› å­æ˜ å°„åˆ°é¢œè‰²æˆ–å¡«å……ï¼Œå®ƒå°†é»˜è®¤ä¸º scale_color_viridis() / scale_fill_viridis()ï¼Œè¿™æ˜¯ä¸€ä¸ªæš—ç¤ºæ’åçš„è‰²é˜¶ã€‚\nIf you use an ordered predictor in a linear model, it will use â€œpolynomial contrastsâ€. These are mildly useful, but you are unlikely to have heard of them unless you have a PhD in Statistics, and even then you probably donâ€™t routinely interpret them. If you want to learn more, we recommend vignette(\"contrasts\", package = \"faux\") by Lisa DeBruine.\nå¦‚æœä½ åœ¨çº¿æ€§æ¨¡å‹ä¸­ä½¿ç”¨æœ‰åºé¢„æµ‹å˜é‡ï¼Œå®ƒå°†ä½¿ç”¨â€œå¤šé¡¹å¼å¯¹æ¯”â€ (polynomial contrasts)ã€‚è¿™äº›æœ‰äº›ç”¨å¤„ï¼Œä½†é™¤éä½ æ‹¥æœ‰ç»Ÿè®¡å­¦åšå£«å­¦ä½ï¼Œå¦åˆ™ä½ ä¸å¤ªå¯èƒ½å¬è¯´è¿‡å®ƒä»¬ï¼Œå³ä½¿é‚£æ ·ï¼Œä½ å¯èƒ½ä¹Ÿä¸ä¼šå¸¸è§„åœ°è§£é‡Šå®ƒä»¬ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šï¼Œæˆ‘ä»¬æ¨è Lisa DeBruine çš„ vignette(\"contrasts\", package = \"faux\")ã€‚\n\nFor the purposes of this book, correctly distinguishing between regular and ordered factors is not particularly important.\nå°±æœ¬ä¹¦è€Œè¨€ï¼Œæ­£ç¡®åŒºåˆ†å¸¸è§„å› å­å’Œæœ‰åºå› å­å¹¶éç‰¹åˆ«é‡è¦ã€‚\nMore broadly, however, certain fields (particularly the social sciences) do use ordered factors extensively.\nç„¶è€Œï¼Œåœ¨æ›´å¹¿æ³›çš„èŒƒå›´å†…ï¼ŒæŸäº›é¢†åŸŸï¼ˆç‰¹åˆ«æ˜¯ç¤¾ä¼šç§‘å­¦ï¼‰ç¡®å®å¹¿æ³›ä½¿ç”¨æœ‰åºå› å­ã€‚\nIn these contexts, itâ€™s important to correctly identify them so that other analysis packages can offer the appropriate behavior.\nåœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæ­£ç¡®è¯†åˆ«å®ƒä»¬éå¸¸é‡è¦ï¼Œä»¥ä¾¿å…¶ä»–åˆ†æåŒ…å¯ä»¥æä¾›é€‚å½“çš„è¡Œä¸ºã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#summary",
    "href": "factors.html#summary",
    "title": "16Â  Factors",
    "section": "\n16.7 Summary",
    "text": "16.7 Summary\nThis chapter introduced you to the handy forcats package for working with factors, introducing you to the most commonly used functions.\næœ¬ç« å‘ä½ ä»‹ç»äº†ç”¨äºå¤„ç†å› å­çš„ä¾¿æ· forcats åŒ…ï¼Œå¹¶ä»‹ç»äº†æœ€å¸¸ç”¨çš„å‡½æ•°ã€‚\nforcats contains a wide range of other helpers that we didnâ€™t have space to discuss here, so whenever youâ€™re facing a factor analysis challenge that you havenâ€™t encountered before, I highly recommend skimming the reference index to see if thereâ€™s a canned function that can help solve your problem.\nforcats åŒ…å«è®¸å¤šæˆ‘ä»¬åœ¨æ­¤æ²¡æœ‰ç¯‡å¹…è®¨è®ºçš„å…¶ä»–è¾…åŠ©å‡½æ•°ï¼Œå› æ­¤ï¼Œå½“ä½ é‡åˆ°ä»¥å‰ä»æœªè§è¿‡çš„å› å­åˆ†ææŒ‘æˆ˜æ—¶ï¼Œæˆ‘å¼ºçƒˆå»ºè®®ä½ æµè§ˆå‚è€ƒç´¢å¼•ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰ç°æˆçš„å‡½æ•°å¯ä»¥å¸®åŠ©ä½ è§£å†³é—®é¢˜ã€‚\nIf you want to learn more about factors after reading this chapter, we recommend reading Amelia McNamara and Nicholas Hortonâ€™s paper, Wrangling categorical data in R.\nå¦‚æœä½ åœ¨é˜…è¯»æœ¬ç« åæƒ³äº†è§£æ›´å¤šå…³äºå› å­çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬å»ºè®®é˜…è¯» Amelia McNamara å’Œ Nicholas Horton çš„è®ºæ–‡ï¼ŒWrangling categorical data in Rã€‚\nThis paper lays out some of the history discussed in stringsAsFactors: An unauthorized biography and stringsAsFactors = &lt;sigh&gt;, and compares the tidy approaches to categorical data outlined in this book with base R methods.\nè¯¥è®ºæ–‡é˜è¿°äº† stringsAsFactors: An unauthorized biography å’Œ stringsAsFactors = &lt;sigh&gt; ä¸­è®¨è®ºçš„ä¸€äº›å†å²ï¼Œå¹¶æ¯”è¾ƒäº†æœ¬ä¹¦ä¸­æ¦‚è¿°çš„å¤„ç†åˆ†ç±»æ•°æ®çš„æ•´æ´æ–¹æ³•ä¸åŸºç¡€ R çš„æ–¹æ³•ã€‚\nAn early version of the paper helped motivate and scope the forcats package; thanks Amelia & Nick!\nè¯¥è®ºæ–‡çš„æ—©æœŸç‰ˆæœ¬å¸®åŠ©æ¿€å‘å¹¶ç¡®å®šäº† forcats åŒ…çš„èŒƒå›´ï¼›æ„Ÿè°¢ Amelia å’Œ Nickï¼\nIn the next chapter weâ€™ll switch gears to start learning about dates and times in R.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†è½¬æ¢ä¸»é¢˜ï¼Œå¼€å§‹å­¦ä¹  R ä¸­çš„æ—¥æœŸå’Œæ—¶é—´ã€‚\nDates and times seem deceptively simple, but as youâ€™ll soon see, the more you learn about them, the more complex they seem to get!\næ—¥æœŸå’Œæ—¶é—´çœ‹èµ·æ¥ä¼¼ä¹å¾ˆç®€å•ï¼Œä½†ä½ å¾ˆå¿«å°±ä¼šå‘ç°ï¼Œä½ å¯¹å®ƒä»¬äº†è§£å¾—è¶Šå¤šï¼Œå®ƒä»¬ä¼¼ä¹å°±è¶Šå¤æ‚ï¼",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "factors.html#footnotes",
    "href": "factors.html#footnotes",
    "title": "16Â  Factors",
    "section": "",
    "text": "Theyâ€™re also really important for modelling.â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>16</span>Â  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "datetimes.html",
    "href": "datetimes.html",
    "title": "17Â  Dates and times",
    "section": "",
    "text": "17.1 Introduction\nThis chapter will show you how to work with dates and times in R. At first glance, dates and times seem simple. You use them all the time in your regular life, and they donâ€™t seem to cause much confusion. However, the more you learn about dates and times, the more complicated they seem to get!\næœ¬ç« å°†å‘ä½ å±•ç¤ºå¦‚ä½•åœ¨ R ä¸­å¤„ç†æ—¥æœŸå’Œæ—¶é—´ã€‚ä¹ä¸€çœ‹ï¼Œæ—¥æœŸå’Œæ—¶é—´ä¼¼ä¹å¾ˆç®€å•ã€‚ä½ åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ä¸€ç›´ä½¿ç”¨å®ƒä»¬ï¼Œè€Œä¸”å®ƒä»¬ä¼¼ä¹æ²¡æœ‰å¼•èµ·å¤ªå¤šå›°æƒ‘ã€‚ç„¶è€Œï¼Œä½ å¯¹æ—¥æœŸå’Œæ—¶é—´äº†è§£å¾—è¶Šå¤šï¼Œå®ƒä»¬ä¼¼ä¹å°±å˜å¾—è¶Šå¤æ‚ï¼\nTo warm up think about how many days there are in a year, and how many hours there are in a day. You probably remembered that most years have 365 days, but leap years have 366. Do you know the full rule for determining if a year is a leap year1? The number of hours in a day is a little less obvious: most days have 24 hours, but in places that use daylight saving time (DST), one day each year has 23 hours and another has 25.\nä¸ºäº†çƒ­èº«ï¼Œæƒ³ä¸€æƒ³ä¸€å¹´æœ‰å¤šå°‘å¤©ï¼Œä¸€å¤©æœ‰å¤šå°‘å°æ—¶ã€‚ä½ å¯èƒ½è®°å¾—å¤§å¤šæ•°å¹´ä»½æœ‰ 365 å¤©ï¼Œä½†é—°å¹´æœ‰ 366 å¤©ã€‚ä½ çŸ¥é“åˆ¤æ–­ä¸€å¹´æ˜¯å¦æ˜¯é—°å¹´çš„å®Œæ•´è§„åˆ™å—1ï¼Ÿä¸€å¤©ä¸­çš„å°æ—¶æ•°åˆ™ä¸é‚£ä¹ˆæ˜æ˜¾ï¼šå¤§å¤šæ•°æ—¥å­æœ‰ 24 å°æ—¶ï¼Œä½†åœ¨ä½¿ç”¨å¤ä»¤æ—¶ (Daylight Saving Time, DST) çš„åœ°æ–¹ï¼Œæ¯å¹´æœ‰ä¸€å¤©æ˜¯ 23 å°æ—¶ï¼Œå¦ä¸€å¤©æ˜¯ 25 å°æ—¶ã€‚\nDates and times are hard because they have to reconcile two physical phenomena (the rotation of the Earth and its orbit around the sun) with a whole raft of geopolitical phenomena including months, time zones, and DST. This chapter wonâ€™t teach you every last detail about dates and times, but it will give you a solid grounding of practical skills that will help you with common data analysis challenges.\næ—¥æœŸå’Œæ—¶é—´ä¹‹æ‰€ä»¥å›°éš¾ï¼Œæ˜¯å› ä¸ºå®ƒä»¬å¿…é¡»è°ƒå’Œä¸¤ç§ç‰©ç†ç°è±¡ï¼ˆåœ°çƒçš„è‡ªè½¬å’Œç»•å¤ªé˜³çš„å…¬è½¬ï¼‰ä¸ä¸€ç³»åˆ—åœ°ç¼˜æ”¿æ²»ç°è±¡ï¼ŒåŒ…æ‹¬æœˆä»½ã€æ—¶åŒºå’Œå¤ä»¤æ—¶ã€‚æœ¬ç« ä¸ä¼šæ•™ä½ å…³äºæ—¥æœŸå’Œæ—¶é—´çš„æ¯ä¸€ä¸ªç»†èŠ‚ï¼Œä½†å®ƒä¼šä¸ºä½ æä¾›åšå®çš„å®è·µæŠ€èƒ½åŸºç¡€ï¼Œå¸®åŠ©ä½ åº”å¯¹å¸¸è§çš„æ•°æ®åˆ†ææŒ‘æˆ˜ã€‚\nWeâ€™ll begin by showing you how to create date-times from various inputs, and then once youâ€™ve got a date-time, how you can extract components like year, month, and day. Weâ€™ll then dive into the tricky topic of working with time spans, which come in a variety of flavors depending on what youâ€™re trying to do. Weâ€™ll conclude with a brief discussion of the additional challenges posed by time zones.\næˆ‘ä»¬å°†é¦–å…ˆå‘ä½ å±•ç¤ºå¦‚ä½•ä»å„ç§è¾“å…¥åˆ›å»ºæ—¥æœŸæ—¶é—´ï¼Œç„¶åä¸€æ—¦ä½ æœ‰äº†æ—¥æœŸæ—¶é—´ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æå–å¹´ã€æœˆã€æ—¥ç­‰ç»„ä»¶ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¤„ç†æ—¶é—´è·¨åº¦è¿™ä¸ªæ£˜æ‰‹çš„è¯é¢˜ï¼Œå®ƒæ ¹æ®ä½ çš„ä¸åŒéœ€æ±‚æœ‰å¤šç§å½¢å¼ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ç®€è¦è®¨è®ºæ—¶åŒºå¸¦æ¥çš„é¢å¤–æŒ‘æˆ˜ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#introduction",
    "href": "datetimes.html#introduction",
    "title": "17Â  Dates and times",
    "section": "",
    "text": "17.1.1 Prerequisites\nThis chapter will focus on the lubridate package, which makes it easier to work with dates and times in R. As of the latest tidyverse release, lubridate is part of core tidyverse. We will also need nycflights13 for practice data.\næœ¬ç« å°†é‡ç‚¹ä»‹ç» lubridate åŒ…ï¼Œå®ƒä½¿å¾—åœ¨ R ä¸­å¤„ç†æ—¥æœŸå’Œæ—¶é—´å˜å¾—æ›´åŠ å®¹æ˜“ã€‚ä»æœ€æ–°çš„ tidyverse ç‰ˆæœ¬å¼€å§‹ï¼Œlubridate å·²æˆä¸ºæ ¸å¿ƒ tidyverse çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬è¿˜å°†éœ€è¦ nycflights13 åŒ…æ¥è·å–ç»ƒä¹ æ•°æ®ã€‚\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#sec-creating-datetimes",
    "href": "datetimes.html#sec-creating-datetimes",
    "title": "17Â  Dates and times",
    "section": "\n17.2 Creating date/times",
    "text": "17.2 Creating date/times\nThere are three types of date/time data that refer to an instant in time:\næœ‰ä¸‰ç§ç±»å‹çš„æ—¥æœŸ/æ—¶é—´æ•°æ®å¯ä»¥æŒ‡ä»£ä¸€ä¸ªæ—¶é—´ç‚¹ï¼š\n\nA date. Tibbles print this as &lt;date&gt;.date (æ—¥æœŸ)ã€‚Tibbles å°†å…¶æ‰“å°ä¸º &lt;date&gt;ã€‚\nA time within a day. Tibbles print this as &lt;time&gt;.\nä¸€å¤©ä¸­çš„ time (æ—¶é—´)ã€‚Tibbles å°†å…¶æ‰“å°ä¸º &lt;time&gt;ã€‚\nA date-time is a date plus a time: it uniquely identifies an instant in time (typically to the nearest second). Tibbles print this as &lt;dttm&gt;. Base R calls these POSIXct, but that doesnâ€™t exactly trip off the tongue.date-time (æ—¥æœŸæ—¶é—´) æ˜¯æ—¥æœŸåŠ ä¸Šæ—¶é—´ï¼šå®ƒå”¯ä¸€åœ°æ ‡è¯†äº†ä¸€ä¸ªæ—¶é—´ç‚¹ï¼ˆé€šå¸¸ç²¾ç¡®åˆ°ç§’ï¼‰ã€‚Tibbles å°†å…¶æ‰“å°ä¸º &lt;dttm&gt;ã€‚åŸºç¡€ R ç§°ä¹‹ä¸º POSIXctï¼Œä½†è¿™åå­—å¹¶ä¸æ€ä¹ˆä¸Šå£ã€‚\n\nIn this chapter we are going to focus on dates and date-times as R doesnâ€™t have a native class for storing times. If you need one, you can use the hms package.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºæ—¥æœŸå’Œæ—¥æœŸæ—¶é—´ï¼Œå› ä¸º R æ²¡æœ‰ç”¨äºå­˜å‚¨æ—¶é—´çš„åŸç”Ÿç±»ã€‚å¦‚æœä½ éœ€è¦ï¼Œå¯ä»¥ä½¿ç”¨ hms åŒ…ã€‚\nYou should always use the simplest possible data type that works for your needs. That means if you can use a date instead of a date-time, you should. Date-times are substantially more complicated because of the need to handle time zones, which weâ€™ll come back to at the end of the chapter.\nä½ åº”è¯¥å§‹ç»ˆä½¿ç”¨èƒ½æ»¡è¶³ä½ éœ€æ±‚çš„ã€å°½å¯èƒ½ç®€å•çš„æ•°æ®ç±»å‹ã€‚è¿™æ„å‘³ç€å¦‚æœä½ å¯ä»¥ä½¿ç”¨æ—¥æœŸè€Œä¸æ˜¯æ—¥æœŸæ—¶é—´ï¼Œä½ å°±åº”è¯¥è¿™æ ·åšã€‚æ—¥æœŸæ—¶é—´è¦å¤æ‚å¾—å¤šï¼Œå› ä¸ºéœ€è¦å¤„ç†æ—¶åŒºé—®é¢˜ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ç« æœ«å°¾å†å›åˆ°è¿™ä¸ªè¯é¢˜ã€‚\nTo get the current date or date-time you can use today() or now():\nè¦è·å–å½“å‰æ—¥æœŸæˆ–æ—¥æœŸæ—¶é—´ï¼Œä½ å¯ä»¥ä½¿ç”¨ today() æˆ– now()ï¼š\n\ntoday()\n#&gt; [1] \"2025-07-11\"\nnow()\n#&gt; [1] \"2025-07-11 16:41:28 CST\"\n\nOtherwise, the following sections describe the four ways youâ€™re likely to create a date/time:\næ­¤å¤–ï¼Œä»¥ä¸‹å„èŠ‚æè¿°äº†ä½ å¯èƒ½ç”¨æ¥åˆ›å»ºæ—¥æœŸ/æ—¶é—´çš„å››ç§æ–¹å¼ï¼š\n\nWhile reading a file with readr.\nä½¿ç”¨ readr è¯»å–æ–‡ä»¶æ—¶ã€‚\nFrom a string.\nä»å­—ç¬¦ä¸²åˆ›å»ºã€‚\nFrom individual date-time components.\nä»å•ä¸ªæ—¥æœŸæ—¶é—´ç»„ä»¶åˆ›å»ºã€‚\nFrom an existing date/time object.\nä»ç°æœ‰çš„æ—¥æœŸ/æ—¶é—´å¯¹è±¡åˆ›å»ºã€‚\n\n\n17.2.1 During import\nIf your CSV contains an ISO8601 date or date-time, you donâ€™t need to do anything; readr will automatically recognize it:\nå¦‚æœä½ çš„ CSV æ–‡ä»¶åŒ…å« ISO8601 æ ¼å¼çš„æ—¥æœŸæˆ–æ—¥æœŸæ—¶é—´ï¼Œä½ ä»€ä¹ˆéƒ½ä¸ç”¨åšï¼›readr ä¼šè‡ªåŠ¨è¯†åˆ«å®ƒï¼š\n\ncsv &lt;- \"\n  date,datetime\n  2022-01-02,2022-01-02 05:12\n\"\nread_csv(csv)\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   date       datetime           \n#&gt;   &lt;date&gt;     &lt;dttm&gt;             \n#&gt; 1 2022-01-02 2022-01-02 05:12:00\n\nIf you havenâ€™t heard of ISO8601 before, itâ€™s an international standard2 for writing dates where the components of a date are organized from biggest to smallest separated by -. For example, in ISO8601 May 3 2022 is 2022-05-03. ISO8601 dates can also include times, where hour, minute, and second are separated by :, and the date and time components are separated by either a T or a space. For example, you could write 4:26pm on May 3 2022 as either 2022-05-03 16:26 or 2022-05-03T16:26.\nå¦‚æœä½ ä¹‹å‰æ²¡æœ‰å¬è¯´è¿‡ ISO8601ï¼Œå®ƒæ˜¯ä¸€ä¸ªä¹¦å†™æ—¥æœŸçš„å›½é™…æ ‡å‡†2ï¼Œå…¶ä¸­æ—¥æœŸçš„å„ä¸ªç»„æˆéƒ¨åˆ†æŒ‰ä»å¤§åˆ°å°çš„é¡ºåºæ’åˆ—ï¼Œå¹¶ç”¨ - åˆ†éš”ã€‚ä¾‹å¦‚ï¼Œåœ¨ ISO8601 æ ‡å‡†ä¸­ï¼Œ2022 å¹´ 5 æœˆ 3 æ—¥å†™ä½œ 2022-05-03ã€‚ISO8601 æ—¥æœŸä¹Ÿå¯ä»¥åŒ…å«æ—¶é—´ï¼Œå…¶ä¸­å°æ—¶ã€åˆ†é’Ÿå’Œç§’ç”¨ : åˆ†éš”ï¼Œæ—¥æœŸå’Œæ—¶é—´éƒ¨åˆ†å¯ä»¥ç”¨ T æˆ–ç©ºæ ¼åˆ†éš”ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å°† 2022 å¹´ 5 æœˆ 3 æ—¥ä¸‹åˆ 4:26 å†™æˆ 2022-05-03 16:26 æˆ– 2022-05-03T16:26ã€‚\nFor other date-time formats, youâ€™ll need to use col_types plus col_date() or col_datetime() along with a date-time format. The date-time format used by readr is a standard used across many programming languages, describing a date component with a % followed by a single character. For example, %Y-%m-%d specifies a date thatâ€™s a year, -, month (as number) -, day. Table TableÂ 17.1 lists all the options.\nå¯¹äºå…¶ä»–æ—¥æœŸæ—¶é—´æ ¼å¼ï¼Œä½ éœ€è¦ä½¿ç”¨ col_types åŠ ä¸Š col_date() æˆ– col_datetime() ä»¥åŠä¸€ä¸ªæ—¥æœŸæ—¶é—´æ ¼å¼ã€‚readr ä½¿ç”¨çš„æ—¥æœŸæ—¶é—´æ ¼å¼æ˜¯è®¸å¤šç¼–ç¨‹è¯­è¨€é€šç”¨çš„æ ‡å‡†ï¼Œç”¨ % åè·Ÿä¸€ä¸ªå•å­—ç¬¦æ¥æè¿°æ—¥æœŸç»„ä»¶ã€‚ä¾‹å¦‚ï¼Œ%Y-%m-%d æŒ‡å®šäº†ä¸€ä¸ªç”±å¹´ã€-ã€æœˆï¼ˆæ•°å­—ï¼‰ã€-ã€æ—¥ç»„æˆçš„æ—¥æœŸã€‚è¡¨æ ¼ TableÂ 17.1 åˆ—å‡ºäº†æ‰€æœ‰é€‰é¡¹ã€‚\n\n\nTableÂ 17.1: All date formats understood by readr\n\n\n\n\n\n\n\n\n\nType\nCode\nMeaning\nExample\n\n\n\nYear\n%Y\n4 digit year / 4 ä½æ•°å¹´ä»½\n2021\n\n\n\n%y\n2 digit year / 2 ä½æ•°å¹´ä»½\n21\n\n\nMonth\n%m\nNumber / æ•°å­—\n2\n\n\n\n%b\nAbbreviated name / ç¼©å†™åç§°\nFeb\n\n\n\n%B\nFull name / å®Œæ•´åç§°\nFebruary\n\n\nDay\n%d\nOne or two digits / ä¸€ä½æˆ–ä¸¤ä½æ•°å­—\n2\n\n\n\n%e\nTwo digits / ä¸¤ä½æ•°\n02\n\n\nTime\n%H\n24-hour hour / 24 å°æ—¶åˆ¶å°æ—¶\n13\n\n\n\n%I\n12-hour hour / 12 å°æ—¶åˆ¶å°æ—¶\n1\n\n\n\n%p\nAM/PM / ä¸Šåˆ/ä¸‹åˆ\npm\n\n\n\n%M\nMinutes / åˆ†é’Ÿ\n35\n\n\n\n%S\nSeconds / ç§’\n45\n\n\n\n%OS\nSeconds with decimal component / å¸¦å°æ•°çš„ç§’\n45.35\n\n\n\n%Z\nTime zone name / æ—¶åŒºåç§°\nAmerica/Chicago\n\n\n\n%z\nOffset from UTC / ä¸ UTC çš„åç§»é‡\n+0800\n\n\nOther\n%.\nSkip one non-digit / è·³è¿‡ä¸€ä¸ªéæ•°å­—å­—ç¬¦\n:\n\n\n\n%*\nSkip any number of non-digits / è·³è¿‡ä»»æ„æ•°é‡çš„éæ•°å­—å­—ç¬¦\n\n\n\n\n\n\n\nAnd this code shows a few options applied to a very ambiguous date:\nä¸‹é¢çš„ä»£ç å±•ç¤ºäº†å°†å‡ ç§é€‰é¡¹åº”ç”¨äºä¸€ä¸ªéå¸¸æ¨¡ç³Šçš„æ—¥æœŸï¼š\n\ncsv &lt;- \"\n  date\n  01/02/15\n\"\n\nread_csv(csv, col_types = cols(date = col_date(\"%m/%d/%y\")))\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-01-02\n\nread_csv(csv, col_types = cols(date = col_date(\"%d/%m/%y\")))\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-02-01\n\nread_csv(csv, col_types = cols(date = col_date(\"%y/%m/%d\")))\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2001-02-15\n\nNote that no matter how you specify the date format, itâ€™s always displayed the same way once you get it into R.\nè¯·æ³¨æ„ï¼Œæ— è®ºä½ å¦‚ä½•æŒ‡å®šæ—¥æœŸæ ¼å¼ï¼Œä¸€æ—¦å°†å…¶è¯»å…¥ Rï¼Œå®ƒçš„æ˜¾ç¤ºæ–¹å¼æ€»æ˜¯ç›¸åŒçš„ã€‚\nIf youâ€™re using %b or %B and working with non-English dates, youâ€™ll also need to provide a locale(). See the list of built-in languages in date_names_langs(), or create your own with date_names(),\nå¦‚æœä½ æ­£åœ¨ä½¿ç”¨ %b æˆ– %B å¤„ç†éè‹±è¯­æ—¥æœŸï¼Œä½ è¿˜éœ€è¦æä¾›ä¸€ä¸ª locale()ã€‚å¯ä»¥åœ¨ date_names_langs() ä¸­æŸ¥çœ‹å†…ç½®è¯­è¨€åˆ—è¡¨ï¼Œæˆ–è€…ä½¿ç”¨ date_names() åˆ›å»ºè‡ªå·±çš„è¯­è¨€ç¯å¢ƒã€‚\n\n17.2.2 From strings\nThe date-time specification language is powerful, but requires careful analysis of the date format. An alternative approach is to use lubridateâ€™s helpers which attempt to automatically determine the format once you specify the order of the component. To use them, identify the order in which year, month, and day appear in your dates, then arrange â€œyâ€, â€œmâ€, and â€œdâ€ in the same order. That gives you the name of the lubridate function that will parse your date. For example:\næ—¥æœŸæ—¶é—´è§„èŒƒè¯­è¨€åŠŸèƒ½å¼ºå¤§ï¼Œä½†éœ€è¦ä»”ç»†åˆ†ææ—¥æœŸæ ¼å¼ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ lubridate çš„è¾…åŠ©å‡½æ•°ï¼Œä¸€æ—¦ä½ æŒ‡å®šäº†ç»„ä»¶çš„é¡ºåºï¼Œå®ƒä»¬å°±ä¼šå°è¯•è‡ªåŠ¨ç¡®å®šæ ¼å¼ã€‚è¦ä½¿ç”¨å®ƒä»¬ï¼Œè¯·ç¡®å®šå¹´ã€æœˆã€æ—¥åœ¨ä½ çš„æ—¥æœŸä¸­å‡ºç°çš„é¡ºåºï¼Œç„¶åæŒ‰ç›¸åŒçš„é¡ºåºæ’åˆ— â€œyâ€ã€â€œmâ€ å’Œ â€œdâ€ã€‚è¿™æ ·ä½ å°±å¾—åˆ°äº†å°†è§£æä½ çš„æ—¥æœŸçš„ lubridate å‡½æ•°çš„åç§°ã€‚ä¾‹å¦‚ï¼š\n\nymd(\"2017-01-31\")\n#&gt; [1] \"2017-01-31\"\nmdy(\"January 31st, 2017\")\n#&gt; [1] \"2017-01-31\"\ndmy(\"31-Jan-2017\")\n#&gt; [1] \"2017-01-31\"\n\nymd() and friends create dates. To create a date-time, add an underscore and one or more of â€œhâ€, â€œmâ€, and â€œsâ€ to the name of the parsing function:ymd() å’Œå®ƒçš„æœ‹å‹ä»¬åˆ›å»ºçš„æ˜¯æ—¥æœŸã€‚è¦åˆ›å»ºæ—¥æœŸæ—¶é—´ï¼Œè¯·åœ¨è§£æå‡½æ•°åç§°åæ·»åŠ ä¸€ä¸ªä¸‹åˆ’çº¿ä»¥åŠ â€œhâ€ã€â€œmâ€ å’Œ â€œsâ€ ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªï¼š\n\nymd_hms(\"2017-01-31 20:11:59\")\n#&gt; [1] \"2017-01-31 20:11:59 UTC\"\nmdy_hm(\"01/31/2017 08:01\")\n#&gt; [1] \"2017-01-31 08:01:00 UTC\"\n\nYou can also force the creation of a date-time from a date by supplying a timezone:\nä½ è¿˜å¯ä»¥é€šè¿‡æä¾›æ—¶åŒºæ¥å¼ºåˆ¶ä»æ—¥æœŸåˆ›å»ºæ—¥æœŸæ—¶é—´ï¼š\n\nymd(\"2017-01-31\", tz = \"UTC\")\n#&gt; [1] \"2017-01-31 UTC\"\n\nHere I use the UTC3 timezone which you might also know as GMT, or Greenwich Mean Time, the time at 0Â° longitude4 . It doesnâ€™t use daylight saving time, making it a bit easier to compute with .\nè¿™é‡Œæˆ‘ä½¿ç”¨äº† UTC3 æ—¶åŒºï¼Œä½ å¯èƒ½ä¹ŸçŸ¥é“å®ƒå« GMTï¼Œå³æ ¼æ—å°¼æ²»æ ‡å‡†æ—¶é—´ (Greenwich Mean Time)ï¼Œæ˜¯ç»åº¦ 0Â° çš„æ—¶é—´4ã€‚å®ƒä¸ä½¿ç”¨å¤ä»¤æ—¶ï¼Œè¿™ä½¿å¾—è®¡ç®—èµ·æ¥æ›´å®¹æ˜“ä¸€äº›ã€‚\n\n17.2.3 From individual components\nInstead of a single string, sometimes youâ€™ll have the individual components of the date-time spread across multiple columns. This is what we have in the flights data:\næœ‰æ—¶ï¼Œä½ ä¸ä¼šæœ‰ä¸€ä¸ªå•ä¸€çš„å­—ç¬¦ä¸²ï¼Œè€Œæ˜¯å°†æ—¥æœŸæ—¶é—´çš„å„ä¸ªç»„æˆéƒ¨åˆ†åˆ†å¸ƒåœ¨å¤šä¸ªåˆ—ä¸­ã€‚flights æ•°æ®å°±æ˜¯è¿™ç§æƒ…å†µï¼š\n\nflights |&gt; \n  select(year, month, day, hour, minute)\n#&gt; # A tibble: 336,776 Ã— 5\n#&gt;    year month   day  hour minute\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  2013     1     1     5     15\n#&gt; 2  2013     1     1     5     29\n#&gt; 3  2013     1     1     5     40\n#&gt; 4  2013     1     1     5     45\n#&gt; 5  2013     1     1     6      0\n#&gt; 6  2013     1     1     5     58\n#&gt; # â„¹ 336,770 more rows\n\nTo create a date/time from this sort of input, use make_date() for dates, or make_datetime() for date-times:\nè¦ä»æ­¤ç±»è¾“å…¥åˆ›å»ºæ—¥æœŸ/æ—¶é—´ï¼Œå¯¹æ—¥æœŸä½¿ç”¨ make_date()ï¼Œå¯¹æ—¥æœŸæ—¶é—´ä½¿ç”¨ make_datetime()ï¼š\n\nflights |&gt; \n  select(year, month, day, hour, minute) |&gt; \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n#&gt; # A tibble: 336,776 Ã— 6\n#&gt;    year month   day  hour minute departure          \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n#&gt; 1  2013     1     1     5     15 2013-01-01 05:15:00\n#&gt; 2  2013     1     1     5     29 2013-01-01 05:29:00\n#&gt; 3  2013     1     1     5     40 2013-01-01 05:40:00\n#&gt; 4  2013     1     1     5     45 2013-01-01 05:45:00\n#&gt; 5  2013     1     1     6      0 2013-01-01 06:00:00\n#&gt; 6  2013     1     1     5     58 2013-01-01 05:58:00\n#&gt; # â„¹ 336,770 more rows\n\nLetâ€™s do the same thing for each of the four time columns in flights. The times are represented in a slightly odd format, so we use modulus arithmetic to pull out the hour and minute components. Once weâ€™ve created the date-time variables, we focus in on the variables weâ€™ll explore in the rest of the chapter.\nè®©æˆ‘ä»¬å¯¹ flights æ•°æ®ä¸­çš„å››ä¸ªæ—¶é—´åˆ—éƒ½æ‰§è¡Œç›¸åŒçš„æ“ä½œã€‚è¿™äº›æ—¶é—´ä»¥ä¸€ç§ç¨å¾®å¥‡æ€ªçš„æ ¼å¼è¡¨ç¤ºï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨æ¨¡è¿ç®—æ¥æå–å°æ—¶å’Œåˆ†é’Ÿéƒ¨åˆ†ã€‚ä¸€æ—¦æˆ‘ä»¬åˆ›å»ºäº†æ—¥æœŸæ—¶é—´å˜é‡ï¼Œæˆ‘ä»¬å°±ä¸“æ³¨äºå°†åœ¨æœ¬ç« å…¶ä½™éƒ¨åˆ†æ¢è®¨çš„å˜é‡ã€‚\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\nflights_dt &lt;- flights |&gt; \n  filter(!is.na(dep_time), !is.na(arr_time)) |&gt; \n  mutate(\n    dep_time = make_datetime_100(year, month, day, dep_time),\n    arr_time = make_datetime_100(year, month, day, arr_time),\n    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)\n  ) |&gt; \n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\nflights_dt\n#&gt; # A tibble: 328,063 Ã— 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n#&gt; 2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n#&gt; 3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n#&gt; 4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n#&gt; 5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n#&gt; 6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n#&gt; # â„¹ 328,057 more rows\n#&gt; # â„¹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, â€¦\n\nWith this data, we can visualize the distribution of departure times across the year:\næœ‰äº†è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å¯è§†åŒ–ä¸€å¹´ä¸­å‡ºå‘æ—¶é—´çš„åˆ†å¸ƒï¼š\n\nflights_dt |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day\n\n\n\n\n\n\n\nOr within a single day:\næˆ–è€…åœ¨ä¸€å¤©ä¹‹å†…ï¼š\n\nflights_dt |&gt; \n  filter(dep_time &lt; ymd(20130102)) |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes\n\n\n\n\n\n\n\nNote that when you use date-times in a numeric context (like in a histogram), 1 means 1 second, so a binwidth of 86400 means one day. For dates, 1 means 1 day.\nè¯·æ³¨æ„ï¼Œå½“ä½ åœ¨æ•°å€¼ä¸Šä¸‹æ–‡ï¼ˆå¦‚ç›´æ–¹å›¾ï¼‰ä¸­ä½¿ç”¨æ—¥æœŸæ—¶é—´æ—¶ï¼Œ1 ä»£è¡¨ 1 ç§’ï¼Œå› æ­¤ 86400 çš„ binwidth (ç»„è·) ä»£è¡¨ä¸€å¤©ã€‚å¯¹äºæ—¥æœŸï¼Œ1 ä»£è¡¨ 1 å¤©ã€‚\n\n17.2.4 From other types\nYou may want to switch between a date-time and a date. Thatâ€™s the job of as_datetime() and as_date():\nä½ å¯èƒ½æƒ³è¦åœ¨æ—¥æœŸæ—¶é—´å’Œæ—¥æœŸä¹‹é—´è¿›è¡Œåˆ‡æ¢ã€‚è¿™æ˜¯ as_datetime() å’Œ as_date() çš„å·¥ä½œï¼š\n\nas_datetime(today())\n#&gt; [1] \"2025-07-11 UTC\"\nas_date(now())\n#&gt; [1] \"2025-07-11\"\n\nSometimes youâ€™ll get date/times as numeric offsets from the â€œUnix Epochâ€, 1970-01-01. If the offset is in seconds, use as_datetime(); if itâ€™s in days, use as_date().\næœ‰æ—¶ä½ ä¼šå¾—åˆ°ä»¥ â€œUnix çºªå…ƒâ€ (Unix Epoch, 1970-01-01) ä¸ºåŸºå‡†çš„æ•°å€¼åç§»é‡å½¢å¼çš„æ—¥æœŸ/æ—¶é—´ã€‚å¦‚æœåç§»é‡ä»¥ç§’ä¸ºå•ä½ï¼Œä½¿ç”¨ as_datetime()ï¼›å¦‚æœä»¥å¤©ä¸ºå•ä½ï¼Œä½¿ç”¨ as_date()ã€‚\n\nas_datetime(60 * 60 * 10)\n#&gt; [1] \"1970-01-01 10:00:00 UTC\"\nas_date(365 * 10 + 2)\n#&gt; [1] \"1980-01-01\"\n\n\n17.2.5 Exercises\n\n\nWhat happens if you parse a string that contains invalid dates?\n\nymd(c(\"2010-10-10\", \"bananas\"))\n\n\nWhat does the tzone argument to today() do? Why is it important?\n\nFor each of the following date-times, show how youâ€™d parse it using a readr column specification and a lubridate function.\n\nd1 &lt;- \"January 1, 2010\"\nd2 &lt;- \"2015-Mar-07\"\nd3 &lt;- \"06-Jun-2017\"\nd4 &lt;- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 &lt;- \"12/30/14\" # Dec 30, 2014\nt1 &lt;- \"1705\"\nt2 &lt;- \"11:15:10.12 PM\"",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#date-time-components",
    "href": "datetimes.html#date-time-components",
    "title": "17Â  Dates and times",
    "section": "\n17.3 Date-time components",
    "text": "17.3 Date-time components\nNow that you know how to get date-time data into Râ€™s date-time data structures, letâ€™s explore what you can do with them. This section will focus on the accessor functions that let you get and set individual components. The next section will look at how arithmetic works with date-times.\næ—¢ç„¶ä½ çŸ¥é“å¦‚ä½•å°†æ—¥æœŸæ—¶é—´æ•°æ®å¯¼å…¥ R çš„æ—¥æœŸæ—¶é—´æ•°æ®ç»“æ„ä¸­ï¼Œè®©æˆ‘ä»¬æ¥æ¢ç´¢ä¸€ä¸‹ä½ å¯ä»¥ç”¨å®ƒä»¬åšä»€ä¹ˆã€‚æœ¬èŠ‚å°†é‡ç‚¹ä»‹ç»å…è®¸ä½ è·å–å’Œè®¾ç½®å•ä¸ªç»„ä»¶çš„è®¿é—®å™¨å‡½æ•°ã€‚ä¸‹ä¸€èŠ‚å°†æ¢è®¨æ—¥æœŸæ—¶é—´çš„ç®—æœ¯è¿ç®—ã€‚\n\n17.3.1 Getting components\nYou can pull out individual parts of the date with the accessor functions year(), month(), mday() (day of the month), yday() (day of the year), wday() (day of the week), hour(), minute(), and second(). These are effectively the opposites of make_datetime().\nä½ å¯ä»¥ä½¿ç”¨è®¿é—®å™¨å‡½æ•° year()ã€month()ã€mday() (æœˆä¸­çš„å¤©)ã€yday() (å¹´ä¸­çš„å¤©)ã€wday() (å‘¨ä¸­çš„å¤©)ã€hour()ã€minute() å’Œ second() æ¥æå–æ—¥æœŸçš„å„ä¸ªéƒ¨åˆ†ã€‚è¿™äº›å‡½æ•°å®é™…ä¸Šæ˜¯ make_datetime() çš„åå‘æ“ä½œã€‚\n\ndatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n#&gt; [1] 2026\nmonth(datetime)\n#&gt; [1] 7\nmday(datetime)\n#&gt; [1] 8\n\nyday(datetime)\n#&gt; [1] 189\nwday(datetime)\n#&gt; [1] 4\n\nFor month() and wday() you can set label = TRUE to return the abbreviated name of the month or day of the week. Set abbr = FALSE to return the full name.\nå¯¹äº month() å’Œ wday()ï¼Œä½ å¯ä»¥è®¾ç½® label = TRUE æ¥è¿”å›æœˆä»½æˆ–æ˜ŸæœŸçš„ç¼©å†™åç§°ã€‚è®¾ç½® abbr = FALSE å¯ä»¥è¿”å›å®Œæ•´åç§°ã€‚\n\nmonth(datetime, label = TRUE)\n#&gt; [1] 7æœˆ\n#&gt; 12 Levels: 1æœˆ &lt; 2æœˆ &lt; 3æœˆ &lt; 4æœˆ &lt; 5æœˆ &lt; 6æœˆ &lt; 7æœˆ &lt; 8æœˆ &lt; 9æœˆ &lt; ... &lt; 12æœˆ\nwday(datetime, label = TRUE, abbr = FALSE)\n#&gt; [1] æ˜ŸæœŸä¸‰\n#&gt; 7 Levels: æ˜ŸæœŸæ—¥ &lt; æ˜ŸæœŸä¸€ &lt; æ˜ŸæœŸäºŒ &lt; æ˜ŸæœŸä¸‰ &lt; æ˜ŸæœŸå›› &lt; ... &lt; æ˜ŸæœŸå…­\n\nWe can use wday() to see that more flights depart during the week than on the weekend:\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨ wday() å‘ç°ï¼Œå·¥ä½œæ—¥èµ·é£çš„èˆªç­æ¯”å‘¨æœ«å¤šï¼š\n\nflights_dt |&gt; \n  mutate(wday = wday(dep_time, label = TRUE)) |&gt; \n  ggplot(aes(x = wday)) +\n  geom_bar()\n\n\n\n\n\n\n\nWe can also look at the average departure delay by minute within the hour. Thereâ€™s an interesting pattern: flights leaving in minutes 20-30 and 50-60 have much lower delays than the rest of the hour!\næˆ‘ä»¬è¿˜å¯ä»¥æŒ‰å°æ—¶å†…çš„åˆ†é’ŸæŸ¥çœ‹å¹³å‡èµ·é£å»¶è¯¯ã€‚æœ‰ä¸€ä¸ªæœ‰è¶£çš„æ¨¡å¼ï¼šåœ¨ 20-30 åˆ†é’Ÿå’Œ 50-60 åˆ†é’Ÿä¹‹é—´èµ·é£çš„èˆªç­ï¼Œå…¶å»¶è¯¯æ—¶é—´è¿œä½äºè¯¥å°æ—¶çš„å…¶ä»–æ—¶é—´æ®µï¼\n\nflights_dt |&gt; \n  mutate(minute = minute(dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE),\n    n = n()\n  ) |&gt; \n  ggplot(aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\nInterestingly, if we look at the scheduled departure time we donâ€™t see such a strong pattern:\næœ‰è¶£çš„æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æŸ¥çœ‹ è®¡åˆ’ å‡ºå‘æ—¶é—´ï¼Œæˆ‘ä»¬çœ‹ä¸åˆ°å¦‚æ­¤å¼ºçƒˆçš„æ¨¡å¼ï¼š\n\nsched_dep &lt;- flights_dt |&gt; \n  mutate(minute = minute(sched_dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(sched_dep, aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\nSo why do we see that pattern with the actual departure times? Well, like much data collected by humans, thereâ€™s a strong bias towards flights leaving at â€œniceâ€ departure times, as FigureÂ 17.1 shows. Always be alert for this sort of pattern whenever you work with data that involves human judgement!\né‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬ä¼šåœ¨å®é™…å‡ºå‘æ—¶é—´ä¸­çœ‹åˆ°è¿™ç§æ¨¡å¼å‘¢ï¼Ÿå—¯ï¼Œå°±åƒè®¸å¤šç”±äººç±»æ”¶é›†çš„æ•°æ®ä¸€æ ·ï¼Œèˆªç­å‡ºå‘æ—¶é—´å­˜åœ¨ä¸€ç§å¼ºçƒˆçš„åå¥½ï¼Œå€¾å‘äºâ€œæ•´ç‚¹â€çš„å‡ºå‘æ—¶é—´ï¼Œå¦‚ FigureÂ 17.1 æ‰€ç¤ºã€‚åœ¨å¤„ç†æ¶‰åŠäººç±»åˆ¤æ–­çš„æ•°æ®æ—¶ï¼Œè¦å§‹ç»ˆè­¦æƒ•è¿™ç§æ¨¡å¼ï¼\n\n#| fig-alt: |\n#|   A line plot with departure minute (0-60) on the x-axis and number of\n#|   flights (0-60000) on the y-axis. Most flights are scheduled to depart\n#|   on either the hour (~60,000) or the half hour (~35,000). Otherwise,\n#|   all most all flights are scheduled to depart on multiples of five, \n#|   with a few extra at 15, 45, and 55 minutes.\n#| echo: false\nggplot(sched_dep, aes(x = minute, y = n)) +\n  geom_line()\n\n\n\n\n\n\nFigureÂ 17.1: A frequency polygon showing the number of flights scheduled to depart each hour. You can see a strong preference for round numbers like 0 and 30 and generally for numbers that are a multiple of five.\n\n\n\n\n\n17.3.2 Rounding\nAn alternative approach to plotting individual components is to round the date to a nearby unit of time, with floor_date(), round_date(), and ceiling_date(). Each function takes a vector of dates to adjust and then the name of the unit to round down (floor), round up (ceiling), or round to. This, for example, allows us to plot the number of flights per week:\nç»˜åˆ¶å•ä¸ªç»„ä»¶çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ floor_date()ã€round_date() å’Œ ceiling_date() å°†æ—¥æœŸèˆå…¥åˆ°é™„è¿‘çš„æ—¶é—´å•ä½ã€‚æ¯ä¸ªå‡½æ•°éƒ½æ¥å—ä¸€ä¸ªè¦è°ƒæ•´çš„æ—¥æœŸå‘é‡ï¼Œç„¶åæ˜¯è¦å‘ä¸‹èˆå…¥ï¼ˆfloorï¼‰ã€å‘ä¸Šèˆå…¥ï¼ˆceilingï¼‰æˆ–å››èˆäº”å…¥çš„å•ä½åç§°ã€‚ä¾‹å¦‚ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿç»˜åˆ¶æ¯å‘¨çš„èˆªç­æ•°é‡ï¼š\n\nflights_dt |&gt; \n  count(week = floor_date(dep_time, \"week\")) |&gt; \n  ggplot(aes(x = week, y = n)) +\n  geom_line() + \n  geom_point()\n\n\n\n\n\n\n\nYou can use rounding to show the distribution of flights across the course of a day by computing the difference between dep_time and the earliest instant of that day:\nä½ å¯ä»¥é€šè¿‡è®¡ç®— dep_time ä¸å½“å¤©æœ€æ—©æ—¶åˆ»ä¹‹é—´çš„å·®å€¼ï¼Œæ¥ä½¿ç”¨èˆå…¥åŠŸèƒ½æ˜¾ç¤ºä¸€å¤©ä¸­èˆªç­çš„åˆ†å¸ƒæƒ…å†µï¼š\n\nflights_dt |&gt; \n  mutate(dep_hour = dep_time - floor_date(dep_time, \"day\")) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n#&gt; Don't know how to automatically pick scale for object of type &lt;difftime&gt;.\n#&gt; Defaulting to continuous.\n\n\n\n\n\n\n\nComputing the difference between a pair of date-times yields a difftime (more on that in Section 17.4.3). We can convert that to an hms object to get a more useful x-axis:\nè®¡ç®—ä¸€å¯¹æ—¥æœŸæ—¶é—´ä¹‹é—´çš„å·®å€¼ä¼šå¾—åˆ°ä¸€ä¸ª difftime å¯¹è±¡ï¼ˆæ›´å¤šç›¸å…³å†…å®¹è¯·å‚è§ Section 17.4.3ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥å°†å…¶è½¬æ¢ä¸º hms å¯¹è±¡ï¼Œä»¥è·å¾—æ›´æœ‰ç”¨çš„ x è½´ï¼š\n\nflights_dt |&gt; \n  mutate(dep_hour = hms::as_hms(dep_time - floor_date(dep_time, \"day\"))) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n\n\n\n\n\n\n\n\n17.3.3 Modifying components\nYou can also use each accessor function to modify the components of a date/time. This doesnâ€™t come up much in data analysis, but can be useful when cleaning data that has clearly incorrect dates.\nä½ è¿˜å¯ä»¥ä½¿ç”¨æ¯ä¸ªè®¿é—®å™¨å‡½æ•°æ¥ä¿®æ”¹æ—¥æœŸ/æ—¶é—´çš„ç»„ä»¶ã€‚è¿™åœ¨æ•°æ®åˆ†æä¸­ä¸å¸¸ç”¨ï¼Œä½†åœ¨æ¸…ç†å«æœ‰æ˜æ˜¾é”™è¯¯æ—¥æœŸçš„æ•°æ®æ—¶å¯èƒ½å¾ˆæœ‰ç”¨ã€‚\n\n(datetime &lt;- ymd_hms(\"2026-07-08 12:34:56\"))\n#&gt; [1] \"2026-07-08 12:34:56 UTC\"\n\nyear(datetime) &lt;- 2030\ndatetime\n#&gt; [1] \"2030-07-08 12:34:56 UTC\"\nmonth(datetime) &lt;- 01\ndatetime\n#&gt; [1] \"2030-01-08 12:34:56 UTC\"\nhour(datetime) &lt;- hour(datetime) + 1\ndatetime\n#&gt; [1] \"2030-01-08 13:34:56 UTC\"\n\nAlternatively, rather than modifying an existing variable, you can create a new date-time with update(). This also allows you to set multiple values in one step:\næˆ–è€…ï¼Œä½ å¯ä»¥ä¸ä¿®æ”¹ç°æœ‰å˜é‡ï¼Œè€Œæ˜¯ç”¨ update() åˆ›å»ºä¸€ä¸ªæ–°çš„æ—¥æœŸæ—¶é—´ã€‚è¿™ä¹Ÿå…è®¸ä½ ä¸€æ­¥è®¾ç½®å¤šä¸ªå€¼ï¼š\n\nupdate(datetime, year = 2030, month = 2, mday = 2, hour = 2)\n#&gt; [1] \"2030-02-02 02:34:56 UTC\"\n\nIf values are too big, they will roll-over:\nå¦‚æœå€¼å¤ªå¤§ï¼Œå®ƒä»¬å°†ä¼šâ€œæ»šåŠ¨â€è¿›ä½ï¼š\n\nupdate(ymd(\"2023-02-01\"), mday = 30)\n#&gt; [1] \"2023-03-02\"\nupdate(ymd(\"2023-02-01\"), hour = 400)\n#&gt; [1] \"2023-02-17 16:00:00 UTC\"\n\n\n17.3.4 Exercises\n\nHow does the distribution of flight times within a day change over the course of the year?\nCompare dep_time, sched_dep_time and dep_delay. Are they consistent? Explain your findings.\nCompare air_time with the duration between the departure and arrival. Explain your findings. (Hint: consider the location of the airport.)\nHow does the average delay time change over the course of a day? Should you use dep_time or sched_dep_time? Why?\nOn what day of the week should you leave if you want to minimise the chance of a delay?\nWhat makes the distribution of diamonds$carat and flights$sched_dep_time similar?\nConfirm our hypothesis that the early departures of flights in minutes 20-30 and 50-60 are caused by scheduled flights that leave early. Hint: create a binary variable that tells you whether or not a flight was delayed.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#time-spans",
    "href": "datetimes.html#time-spans",
    "title": "17Â  Dates and times",
    "section": "\n17.4 Time spans",
    "text": "17.4 Time spans\nNext youâ€™ll learn about how arithmetic with dates works, including subtraction, addition, and division. Along the way, youâ€™ll learn about three important classes that represent time spans:\næ¥ä¸‹æ¥ï¼Œä½ å°†å­¦ä¹ æ—¥æœŸç®—æœ¯çš„è¿ä½œæ–¹å¼ï¼ŒåŒ…æ‹¬å‡æ³•ã€åŠ æ³•å’Œé™¤æ³•ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä½ å°†äº†è§£ä¸‰ä¸ªä»£è¡¨æ—¶é—´è·¨åº¦çš„é‡è¦ç±»ï¼š\n\nDurations, which represent an exact number of seconds.Durations (æ—¶é•¿)ï¼Œè¡¨ç¤ºç²¾ç¡®çš„ç§’æ•°ã€‚\nPeriods, which represent human units like weeks and months.Periods (å‘¨æœŸ)ï¼Œè¡¨ç¤ºäººç±»ä½¿ç”¨çš„å•ä½ï¼Œå¦‚å‘¨å’Œæœˆã€‚\nIntervals, which represent a starting and ending point.Intervals (æ—¶é—´é—´éš”)ï¼Œè¡¨ç¤ºä¸€ä¸ªèµ·ç‚¹å’Œä¸€ä¸ªç»ˆç‚¹ã€‚\n\nHow do you pick between duration, periods, and intervals? As always, pick the simplest data structure that solves your problem. If you only care about physical time, use a duration; if you need to add human times, use a period; if you need to figure out how long a span is in human units, use an interval.\nä½ å¦‚ä½•åœ¨ durationã€period å’Œ interval ä¹‹é—´åšå‡ºé€‰æ‹©ï¼Ÿä¸€å¦‚æ—¢å¾€ï¼Œé€‰æ‹©èƒ½è§£å†³ä½ é—®é¢˜çš„æœ€ç®€å•çš„æ•°æ®ç»“æ„ã€‚å¦‚æœä½ åªå…³å¿ƒç‰©ç†æ—¶é—´ï¼Œè¯·ä½¿ç”¨ durationï¼›å¦‚æœä½ éœ€è¦æ·»åŠ äººç±»æ—¶é—´å•ä½ï¼Œè¯·ä½¿ç”¨ periodï¼›å¦‚æœä½ éœ€è¦è®¡ç®—ä¸€ä¸ªæ—¶é—´è·¨åº¦åœ¨äººç±»å•ä½ä¸­æœ‰å¤šé•¿ï¼Œè¯·ä½¿ç”¨ intervalã€‚\n\n17.4.1 Durations\nIn R, when you subtract two dates, you get a difftime object:\nåœ¨ R ä¸­ï¼Œå½“ä½ å‡å»ä¸¤ä¸ªæ—¥æœŸæ—¶ï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ª difftime å¯¹è±¡ï¼š\n\n# How old is Hadley?\nh_age &lt;- today() - ymd(\"1979-10-14\")\nh_age\n#&gt; Time difference of 16707 days\n\nA difftime class object records a time span of seconds, minutes, hours, days, or weeks. This ambiguity can make difftimes a little painful to work with, so lubridate provides an alternative which always uses seconds: the duration.difftime ç±»å¯¹è±¡è®°å½•ä¸€ä¸ªä»¥ç§’ã€åˆ†é’Ÿã€å°æ—¶ã€å¤©æˆ–å‘¨ä¸ºå•ä½çš„æ—¶é—´è·¨åº¦ã€‚è¿™ç§æ¨¡ç³Šæ€§ä½¿å¾—ä½¿ç”¨ difftimes æœ‰äº›ç—›è‹¦ï¼Œæ‰€ä»¥ lubridate æä¾›äº†ä¸€ä¸ªæ€»æ˜¯ä½¿ç”¨ç§’çš„æ›¿ä»£æ–¹æ¡ˆï¼šduration (æ—¶é•¿)ã€‚\n\nas.duration(h_age)\n#&gt; [1] \"1443484800s (~45.74 years)\"\n\nDurations come with a bunch of convenient constructors:\nDuration æœ‰è®¸å¤šæ–¹ä¾¿çš„æ„é€ å‡½æ•°ï¼š\n\ndseconds(15)\n#&gt; [1] \"15s\"\ndminutes(10)\n#&gt; [1] \"600s (~10 minutes)\"\ndhours(c(12, 24))\n#&gt; [1] \"43200s (~12 hours)\" \"86400s (~1 days)\"\nddays(0:5)\n#&gt; [1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n#&gt; [4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\ndweeks(3)\n#&gt; [1] \"1814400s (~3 weeks)\"\ndyears(1)\n#&gt; [1] \"31557600s (~1 years)\"\n\nDurations always record the time span in seconds. Larger units are created by converting minutes, hours, days, weeks, and years to seconds: 60 seconds in a minute, 60 minutes in an hour, 24 hours in a day, and 7 days in a week. Larger time units are more problematic. A year uses the â€œaverageâ€ number of days in a year, i.e.Â 365.25. Thereâ€™s no way to convert a month to a duration, because thereâ€™s just too much variation.\nDuration æ€»æ˜¯ä»¥ç§’ä¸ºå•ä½è®°å½•æ—¶é—´è·¨åº¦ã€‚æ›´å¤§çš„å•ä½æ˜¯é€šè¿‡å°†åˆ†é’Ÿã€å°æ—¶ã€å¤©ã€å‘¨å’Œå¹´è½¬æ¢ä¸ºç§’æ¥åˆ›å»ºçš„ï¼š1 åˆ†é’Ÿ 60 ç§’ï¼Œ1 å°æ—¶ 60 åˆ†é’Ÿï¼Œ1 å¤© 24 å°æ—¶ï¼Œ1 å‘¨ 7 å¤©ã€‚æ›´å¤§çš„æ—¶é—´å•ä½åˆ™æ›´æœ‰é—®é¢˜ã€‚ä¸€å¹´ä½¿ç”¨â€œå¹³å‡â€å¤©æ•°ï¼Œå³ 365.25 å¤©ã€‚æ— æ³•å°†ä¸€ä¸ªæœˆè½¬æ¢ä¸º durationï¼Œå› ä¸ºæœˆä»½çš„å˜åŒ–å¤ªå¤§ã€‚\nYou can add and multiply durations:\nä½ å¯ä»¥å¯¹ duration è¿›è¡ŒåŠ æ³•å’Œä¹˜æ³•è¿ç®—ï¼š\n\n2 * dyears(1)\n#&gt; [1] \"63115200s (~2 years)\"\ndyears(1) + dweeks(12) + dhours(15)\n#&gt; [1] \"38869200s (~1.23 years)\"\n\nYou can add and subtract durations to and from days:\nä½ å¯ä»¥å°† duration ä¸æ—¥æœŸè¿›è¡ŒåŠ å‡è¿ç®—ï¼š\n\ntomorrow &lt;- today() + ddays(1)\nlast_year &lt;- today() - dyears(1)\n\nHowever, because durations represent an exact number of seconds, sometimes you might get an unexpected result:\nç„¶è€Œï¼Œå› ä¸º duration è¡¨ç¤ºçš„æ˜¯ç²¾ç¡®çš„ç§’æ•°ï¼Œæœ‰æ—¶ä½ å¯èƒ½ä¼šå¾—åˆ°æ„æƒ³ä¸åˆ°çš„ç»“æœï¼š\n\none_am &lt;- ymd_hms(\"2026-03-08 01:00:00\", tz = \"America/New_York\")\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\n\nWhy is one day after 1am March 8, 2am March 9? If you look carefully at the date you might also notice that the time zones have changed. March 8 only has 23 hours because itâ€™s when DST starts, so if we add a full days worth of seconds we end up with a different time.\nä¸ºä»€ä¹ˆ 3 æœˆ 8 æ—¥å‡Œæ™¨ 1 ç‚¹ä¹‹åçš„ä¸€å¤©æ˜¯ 3 æœˆ 9 æ—¥å‡Œæ™¨ 2 ç‚¹ï¼Ÿå¦‚æœä½ ä»”ç»†è§‚å¯Ÿæ—¥æœŸï¼Œä½ å¯èƒ½è¿˜ä¼šæ³¨æ„åˆ°æ—¶åŒºå·²ç»æ”¹å˜äº†ã€‚3 æœˆ 8 æ—¥åªæœ‰ 23 ä¸ªå°æ—¶ï¼Œå› ä¸ºé‚£æ˜¯å¤ä»¤æ—¶ (DST) å¼€å§‹çš„æ—¶å€™ï¼Œæ‰€ä»¥å¦‚æœæˆ‘ä»¬åŠ ä¸Šä¸€æ•´å¤©çš„ç§’æ•°ï¼Œæˆ‘ä»¬æœ€ç»ˆä¼šå¾—åˆ°ä¸€ä¸ªä¸åŒçš„æ—¶é—´ã€‚\n\n17.4.2 Periods\nTo solve this problem, lubridate provides periods. Periods are time spans but donâ€™t have a fixed length in seconds, instead they work with â€œhumanâ€ times, like days and months. That allows them to work in a more intuitive way:\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œlubridate æä¾›äº† periods (å‘¨æœŸ)ã€‚Periods ä¹Ÿæ˜¯æ—¶é—´è·¨åº¦ï¼Œä½†æ²¡æœ‰å›ºå®šçš„ç§’æ•°é•¿åº¦ï¼Œè€Œæ˜¯ä½¿ç”¨â€œäººç±»â€æ—¶é—´å•ä½ï¼Œå¦‚å¤©å’Œæœˆã€‚è¿™è®©å®ƒä»¬èƒ½ä»¥æ›´ç›´è§‚çš„æ–¹å¼å·¥ä½œï¼š\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\nLike durations, periods can be created with a number of friendly constructor functions.\nä¸ duration ç±»ä¼¼ï¼Œperiod ä¹Ÿå¯ä»¥ç”¨è®¸å¤šæ–¹ä¾¿çš„æ„é€ å‡½æ•°åˆ›å»ºã€‚\n\nhours(c(12, 24))\n#&gt; [1] \"12H 0M 0S\" \"24H 0M 0S\"\ndays(7)\n#&gt; [1] \"7d 0H 0M 0S\"\nmonths(1:6)\n#&gt; [1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n#&gt; [5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\n\nYou can add and multiply periods:\nä½ å¯ä»¥å¯¹ period è¿›è¡ŒåŠ æ³•å’Œä¹˜æ³•è¿ç®—ï¼š\n\n10 * (months(6) + days(1))\n#&gt; [1] \"60m 10d 0H 0M 0S\"\ndays(50) + hours(25) + minutes(2)\n#&gt; [1] \"50d 25H 2M 0S\"\n\nAnd of course, add them to dates. Compared to durations, periods are more likely to do what you expect:\nå½“ç„¶ï¼Œä¹Ÿå¯ä»¥æŠŠå®ƒä»¬åŠ åˆ°æ—¥æœŸä¸Šã€‚ä¸ duration ç›¸æ¯”ï¼Œperiod æ›´å¯èƒ½æŒ‰ç…§ä½ çš„é¢„æœŸå·¥ä½œï¼š\n\n# A leap year\nymd(\"2024-01-01\") + dyears(1)\n#&gt; [1] \"2024-12-31 06:00:00 UTC\"\nymd(\"2024-01-01\") + years(1)\n#&gt; [1] \"2025-01-01\"\n\n# Daylight saving time\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\nLetâ€™s use periods to fix an oddity related to our flight dates. Some planes appear to have arrived at their destination before they departed from New York City.\nè®©æˆ‘ä»¬ç”¨ period æ¥ä¿®æ­£èˆªç­æ—¥æœŸä¸­çš„ä¸€ä¸ªå¥‡æ€ªä¹‹å¤„ã€‚æœ‰äº›é£æœºä¼¼ä¹åœ¨ä»çº½çº¦å¸‚èµ·é£ä¹‹å‰å°±åˆ°è¾¾äº†ç›®çš„åœ°ã€‚\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 10,633 Ã— 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    BQN           9        -4 2013-01-01 19:29:00 2013-01-01 19:20:00\n#&gt; 2 JFK    DFW          59        NA 2013-01-01 19:39:00 2013-01-01 18:40:00\n#&gt; 3 EWR    TPA          -2         9 2013-01-01 20:58:00 2013-01-01 21:00:00\n#&gt; 4 EWR    SJU          -6       -12 2013-01-01 21:02:00 2013-01-01 21:08:00\n#&gt; 5 EWR    SFO          11       -14 2013-01-01 21:08:00 2013-01-01 20:57:00\n#&gt; 6 LGA    FLL         -10        -2 2013-01-01 21:20:00 2013-01-01 21:30:00\n#&gt; # â„¹ 10,627 more rows\n#&gt; # â„¹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, â€¦\n\nThese are overnight flights. We used the same date information for both the departure and the arrival times, but these flights arrived on the following day. We can fix this by adding days(1) to the arrival time of each overnight flight.\nè¿™äº›æ˜¯å¤œé—´èˆªç­ã€‚æˆ‘ä»¬å¯¹å‡ºå‘å’Œåˆ°è¾¾æ—¶é—´ä½¿ç”¨äº†ç›¸åŒçš„æ—¥æœŸä¿¡æ¯ï¼Œä½†è¿™äº›èˆªç­æ˜¯åœ¨ç¬¬äºŒå¤©åˆ°è¾¾çš„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç»™æ¯ä¸ªå¤œé—´èˆªç­çš„åˆ°è¾¾æ—¶é—´åŠ ä¸Š days(1) æ¥ä¿®æ­£è¿™ä¸ªé—®é¢˜ã€‚\n\nflights_dt &lt;- flights_dt |&gt; \n  mutate(\n    overnight = arr_time &lt; dep_time,\n    arr_time = arr_time + days(overnight),\n    sched_arr_time = sched_arr_time + days(overnight)\n  )\n\nNow all of our flights obey the laws of physics.\nç°åœ¨æˆ‘ä»¬æ‰€æœ‰çš„èˆªç­éƒ½éµå®ˆç‰©ç†å®šå¾‹äº†ã€‚\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 0 Ã— 10\n#&gt; # â„¹ 10 variables: origin &lt;chr&gt;, dest &lt;chr&gt;, dep_delay &lt;dbl&gt;,\n#&gt; #   arr_delay &lt;dbl&gt;, dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, â€¦\n\n\n17.4.3 Intervals\nWhat does dyears(1) / ddays(365) return? Itâ€™s not quite one, because dyears() is defined as the number of seconds per average year, which is 365.25 days.dyears(1) / ddays(365) è¿”å›ä»€ä¹ˆï¼Ÿç»“æœä¸å®Œå…¨æ˜¯ 1ï¼Œå› ä¸º dyears() è¢«å®šä¹‰ä¸ºå¹³å‡æ¯å¹´çš„ç§’æ•°ï¼Œå³ 365.25 å¤©ã€‚\nWhat does years(1) / days(1) return? Well, if the year was 2015 it should return 365, but if it was 2016, it should return 366! Thereâ€™s not quite enough information for lubridate to give a single clear answer. What it does instead is give an estimate:years(1) / days(1) ä¼šè¿”å›ä»€ä¹ˆï¼Ÿå—¯ï¼Œå¦‚æœå¹´ä»½æ˜¯ 2015 å¹´ï¼Œå®ƒåº”è¯¥è¿”å› 365ï¼Œä½†å¦‚æœæ˜¯ 2016 å¹´ï¼Œå®ƒåº”è¯¥è¿”å› 366ï¼lubridate æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯ç»™å‡ºä¸€ä¸ªæ˜ç¡®çš„ç­”æ¡ˆã€‚å®ƒæ‰€åšçš„æ˜¯ç»™å‡ºä¸€ä¸ªä¼°è®¡å€¼ï¼š\n\nyears(1) / days(1)\n#&gt; [1] 365.25\n\nIf you want a more accurate measurement, youâ€™ll have to use an interval. An interval is a pair of starting and ending date times, or you can think of it as a duration with a starting point.\nå¦‚æœä½ æƒ³è¦æ›´ç²¾ç¡®çš„æµ‹é‡ï¼Œå°±å¿…é¡»ä½¿ç”¨ interval (æ—¶é—´é—´éš”)ã€‚ä¸€ä¸ª interval æ˜¯ä¸€å¯¹èµ·å§‹å’Œç»“æŸçš„æ—¥æœŸæ—¶é—´ï¼Œæˆ–è€…ä½ å¯ä»¥æŠŠå®ƒçœ‹ä½œæ˜¯ä¸€ä¸ªæœ‰èµ·ç‚¹çš„ durationã€‚\nYou can create an interval by writing start %--% end:\nä½ å¯ä»¥é€šè¿‡ start %--% end çš„æ–¹å¼åˆ›å»ºä¸€ä¸ª intervalï¼š\n\ny2023 &lt;- ymd(\"2023-01-01\") %--% ymd(\"2024-01-01\")\ny2024 &lt;- ymd(\"2024-01-01\") %--% ymd(\"2025-01-01\")\n\ny2023\n#&gt; [1] 2023-01-01 UTC--2024-01-01 UTC\ny2024\n#&gt; [1] 2024-01-01 UTC--2025-01-01 UTC\n\nYou could then divide it by days() to find out how many days fit in the year:\nç„¶åä½ å¯ä»¥ç”¨å®ƒé™¤ä»¥ days() æ¥è®¡ç®—å‡ºä¸€å¹´æœ‰å¤šå°‘å¤©ï¼š\n\ny2023 / days(1)\n#&gt; [1] 365\ny2024 / days(1)\n#&gt; [1] 366\n\n\n17.4.4 Exercises\n\nExplain days(!overnight) and days(overnight) to someone who has just started learning R. What is the key fact you need to know?\nCreate a vector of dates giving the first day of every month in 2015. Create a vector of dates giving the first day of every month in the current year.\nWrite a function that given your birthday (as a date), returns how old you are in years.\nWhy canâ€™t (today() %--% (today() + years(1))) / months(1) work?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#time-zones",
    "href": "datetimes.html#time-zones",
    "title": "17Â  Dates and times",
    "section": "\n17.5 Time zones",
    "text": "17.5 Time zones\nTime zones are an enormously complicated topic because of their interaction with geopolitical entities. Fortunately we donâ€™t need to dig into all the details as theyâ€™re not all important for data analysis, but there are a few challenges weâ€™ll need to tackle head on.\næ—¶åŒºæ˜¯ä¸€ä¸ªæå…¶å¤æ‚çš„è¯é¢˜ï¼Œå› ä¸ºå®ƒä¸åœ°ç¼˜æ”¿æ²»å®ä½“ç›¸äº’ä½œç”¨ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ·±å…¥äº†è§£æ‰€æœ‰ç»†èŠ‚ï¼Œå› ä¸ºå®ƒä»¬å¯¹æ•°æ®åˆ†æå¹¶ééƒ½é‡è¦ï¼Œä½†æˆ‘ä»¬ä»éœ€è¦æ­£é¢è§£å†³ä¸€äº›æŒ‘æˆ˜ã€‚\nThe first challenge is that everyday names of time zones tend to be ambiguous. For example, if youâ€™re American youâ€™re probably familiar with EST, or Eastern Standard Time. However, both Australia and Canada also have EST! To avoid confusion, R uses the international standard IANA time zones. These use a consistent naming scheme {area}/{location}, typically in the form {continent}/{city} or {ocean}/{city}. Examples include â€œAmerica/New_Yorkâ€, â€œEurope/Parisâ€, and â€œPacific/Aucklandâ€.\nç¬¬ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ï¼Œæ—¥å¸¸ä½¿ç”¨çš„æ—¶åŒºåç§°å¾€å¾€æ˜¯æ¨¡ç³Šçš„ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æ˜¯ç¾å›½äººï¼Œä½ å¯èƒ½ç†Ÿæ‚‰ ESTï¼Œå³ä¸œéƒ¨æ ‡å‡†æ—¶é—´ã€‚ç„¶è€Œï¼Œæ¾³å¤§åˆ©äºšå’ŒåŠ æ‹¿å¤§ä¹Ÿéƒ½æœ‰ ESTï¼ä¸ºäº†é¿å…æ··æ·†ï¼ŒR ä½¿ç”¨å›½é™…æ ‡å‡†çš„ IANA æ—¶åŒºã€‚è¿™äº›æ—¶åŒºä½¿ç”¨ä¸€è‡´çš„å‘½åæ–¹æ¡ˆ {åŒºåŸŸ}/{åœ°ç‚¹}ï¼Œé€šå¸¸å½¢å¼ä¸º {å¤§æ´²}/{åŸå¸‚} æˆ– {å¤§æ´‹}/{åŸå¸‚}ã€‚ä¾‹å¦‚ â€œAmerica/New_Yorkâ€ã€â€œEurope/Parisâ€ å’Œ â€œPacific/Aucklandâ€ã€‚\nYou might wonder why the time zone uses a city, when typically you think of time zones as associated with a country or region within a country. This is because the IANA database has to record decades worth of time zone rules. Over the course of decades, countries change names (or break apart) fairly frequently, but city names tend to stay the same. Another problem is that the name needs to reflect not only the current behavior, but also the complete history. For example, there are time zones for both â€œAmerica/New_Yorkâ€ and â€œAmerica/Detroitâ€. These cities both currently use Eastern Standard Time but in 1969-1972 Michigan (the state in which Detroit is located), did not follow DST, so it needs a different name. Itâ€™s worth reading the raw time zone database (available at https://www.iana.org/time-zones) just to read some of these stories!\nä½ å¯èƒ½ä¼šæƒ³ï¼Œä¸ºä»€ä¹ˆæ—¶åŒºä½¿ç”¨åŸå¸‚åç§°ï¼Œè€Œé€šå¸¸ä½ è®¤ä¸ºæ—¶åŒºæ˜¯ä¸ä¸€ä¸ªå›½å®¶æˆ–å›½å®¶å†…çš„æŸä¸ªåœ°åŒºç›¸å…³è”çš„ã€‚è¿™æ˜¯å› ä¸º IANA æ•°æ®åº“å¿…é¡»è®°å½•æ•°åå¹´çš„æ—¶åŒºè§„åˆ™ã€‚å‡ åå¹´æ¥ï¼Œå›½å®¶åç§°ï¼ˆæˆ–åˆ†è£‚ï¼‰å˜åŒ–ç›¸å½“é¢‘ç¹ï¼Œä½†åŸå¸‚åç§°å¾€å¾€ä¿æŒä¸å˜ã€‚å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œåç§°ä¸ä»…éœ€è¦åæ˜ å½“å‰çš„è¡Œä¸ºï¼Œè¿˜éœ€è¦åæ˜ å®Œæ•´çš„å†å²ã€‚ä¾‹å¦‚ï¼Œâ€œAmerica/New_Yorkâ€ å’Œ â€œAmerica/Detroitâ€ éƒ½æœ‰æ—¶åŒºã€‚è¿™ä¸¤ä¸ªåŸå¸‚ç›®å‰éƒ½ä½¿ç”¨ä¸œéƒ¨æ ‡å‡†æ—¶é—´ï¼Œä½†åœ¨ 1969-1972 å¹´ï¼Œå¯†æ­‡æ ¹å·ï¼ˆåº•ç‰¹å¾‹æ‰€åœ¨çš„å·ï¼‰æ²¡æœ‰éµå¾ªå¤ä»¤æ—¶ï¼Œæ‰€ä»¥å®ƒéœ€è¦ä¸€ä¸ªä¸åŒçš„åç§°ã€‚å€¼å¾—é˜…è¯»åŸå§‹æ—¶åŒºæ•°æ®åº“ï¼ˆå¯åœ¨ https://www.iana.org/time-zones è·å¾—ï¼‰æ¥äº†è§£è¿™äº›æ•…äº‹ï¼\nYou can find out what R thinks your current time zone is with Sys.timezone():\nä½ å¯ä»¥ä½¿ç”¨ Sys.timezone() æŸ¥æ˜ R è®¤ä¸ºä½ å½“å‰æ‰€åœ¨çš„æ—¶åŒºï¼š\n\nSys.timezone()\n#&gt; [1] \"Asia/Shanghai\"\n\n(If R doesnâ€™t know, youâ€™ll get an NA.)\nï¼ˆå¦‚æœ R ä¸çŸ¥é“ï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ª NAã€‚ï¼‰\nAnd see the complete list of all time zone names with OlsonNames():\nå¹¶ä½¿ç”¨ OlsonNames() æŸ¥çœ‹æ‰€æœ‰æ—¶åŒºåç§°çš„å®Œæ•´åˆ—è¡¨ï¼š\n\nlength(OlsonNames())\n#&gt; [1] 597\nhead(OlsonNames())\n#&gt; [1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n#&gt; [4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"\n\nIn R, the time zone is an attribute of the date-time that only controls printing. For example, these three objects represent the same instant in time:\nåœ¨ R ä¸­ï¼Œæ—¶åŒºæ˜¯æ—¥æœŸæ—¶é—´çš„ä¸€ä¸ªå±æ€§ï¼Œåªæ§åˆ¶æ‰“å°æ˜¾ç¤ºã€‚ä¾‹å¦‚ï¼Œä¸‹é¢è¿™ä¸‰ä¸ªå¯¹è±¡ä»£è¡¨åŒä¸€ä¸ªæ—¶é—´ç‚¹ï¼š\n\nx1 &lt;- ymd_hms(\"2024-06-01 12:00:00\", tz = \"America/New_York\")\nx1\n#&gt; [1] \"2024-06-01 12:00:00 EDT\"\n\nx2 &lt;- ymd_hms(\"2024-06-01 18:00:00\", tz = \"Europe/Copenhagen\")\nx2\n#&gt; [1] \"2024-06-01 18:00:00 CEST\"\n\nx3 &lt;- ymd_hms(\"2024-06-02 04:00:00\", tz = \"Pacific/Auckland\")\nx3\n#&gt; [1] \"2024-06-02 04:00:00 NZST\"\n\nYou can verify that theyâ€™re the same time using subtraction:\nä½ å¯ä»¥é€šè¿‡å‡æ³•æ¥éªŒè¯å®ƒä»¬æ˜¯åŒä¸€æ—¶é—´ï¼š\n\nx1 - x2\n#&gt; Time difference of 0 secs\nx1 - x3\n#&gt; Time difference of 0 secs\n\nUnless otherwise specified, lubridate always uses UTC. UTC (Coordinated Universal Time) is the standard time zone used by the scientific community and is roughly equivalent to GMT (Greenwich Mean Time). It does not have DST, which makes a convenient representation for computation. Operations that combine date-times, like c(), will often drop the time zone. In that case, the date-times will display in the time zone of the first element:\né™¤éå¦æœ‰è¯´æ˜ï¼Œlubridate æ€»æ˜¯ä½¿ç”¨ UTCã€‚UTCï¼ˆåè°ƒä¸–ç•Œæ—¶ï¼‰æ˜¯ç§‘å­¦ç•Œä½¿ç”¨çš„æ ‡å‡†æ—¶åŒºï¼Œå¤§è‡´ç›¸å½“äº GMTï¼ˆæ ¼æ—å°¼æ²»æ ‡å‡†æ—¶é—´ï¼‰ã€‚å®ƒæ²¡æœ‰å¤ä»¤æ—¶ï¼Œè¿™ä½¿å¾—å®ƒæˆä¸ºä¸€ä¸ªæ–¹ä¾¿çš„è®¡ç®—è¡¨ç¤ºã€‚åƒ c() è¿™æ ·ç»„åˆæ—¥æœŸæ—¶é—´çš„æ“ä½œé€šå¸¸ä¼šä¸¢å¼ƒæ—¶åŒºä¿¡æ¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ—¥æœŸæ—¶é—´å°†ä»¥ç¬¬ä¸€ä¸ªå…ƒç´ çš„æ—¶åŒºæ˜¾ç¤ºï¼š\n\nx4 &lt;- c(x1, x2, x3)\nx4\n#&gt; [1] \"2024-06-01 12:00:00 EDT\" \"2024-06-01 12:00:00 EDT\"\n#&gt; [3] \"2024-06-01 12:00:00 EDT\"\n\nYou can change the time zone in two ways:\nä½ å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼æ›´æ”¹æ—¶åŒºï¼š\n\n\nKeep the instant in time the same, and change how itâ€™s displayed. Use this when the instant is correct, but you want a more natural display.\nä¿æŒæ—¶é—´ç‚¹ä¸å˜ï¼Œåªæ”¹å˜å…¶æ˜¾ç¤ºæ–¹å¼ã€‚å½“æ—¶é—´ç‚¹æ­£ç¡®ï¼Œä½†ä½ æƒ³è¦æ›´è‡ªç„¶çš„æ˜¾ç¤ºæ—¶ä½¿ç”¨æ­¤æ–¹æ³•ã€‚\n\nx4a &lt;- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n#&gt; [1] \"2024-06-02 02:30:00 +1030\" \"2024-06-02 02:30:00 +1030\"\n#&gt; [3] \"2024-06-02 02:30:00 +1030\"\nx4a - x4\n#&gt; Time differences in secs\n#&gt; [1] 0 0 0\n\n(This also illustrates another challenge of times zones: theyâ€™re not all integer hour offsets!)\nï¼ˆè¿™ä¹Ÿè¯´æ˜äº†æ—¶åŒºçš„å¦ä¸€ä¸ªæŒ‘æˆ˜ï¼šå®ƒä»¬å¹¶ééƒ½æ˜¯æ•´æ•°å°æ—¶çš„åç§»é‡ï¼ï¼‰\n\n\nChange the underlying instant in time. Use this when you have an instant that has been labelled with the incorrect time zone, and you need to fix it.\næ”¹å˜åº•å±‚çš„æ—¶é—´ç‚¹ã€‚å½“ä½ æœ‰ä¸€ä¸ªè¢«æ ‡è®°äº†é”™è¯¯æ—¶åŒºçš„æ—¶é—´ç‚¹ï¼Œå¹¶ä¸”éœ€è¦ä¿®æ­£å®ƒæ—¶ä½¿ç”¨æ­¤æ–¹æ³•ã€‚\n\nx4b &lt;- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n#&gt; [1] \"2024-06-01 12:00:00 +1030\" \"2024-06-01 12:00:00 +1030\"\n#&gt; [3] \"2024-06-01 12:00:00 +1030\"\nx4b - x4\n#&gt; Time differences in hours\n#&gt; [1] -14.5 -14.5 -14.5",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#summary",
    "href": "datetimes.html#summary",
    "title": "17Â  Dates and times",
    "section": "\n17.6 Summary",
    "text": "17.6 Summary\nThis chapter has introduced you to the tools that lubridate provides to help you work with date-time data. Working with dates and times can seem harder than necessary, but hopefully this chapter has helped you see why â€” date-times are more complex than they seem at first glance, and handling every possible situation adds complexity. Even if your data never crosses a day light savings boundary or involves a leap year, the functions need to be able to handle it.\næœ¬ç« å‘ä½ ä»‹ç»äº† lubridate æä¾›çš„ç”¨äºå¤„ç†æ—¥æœŸæ—¶é—´æ•°æ®çš„å·¥å…·ã€‚å¤„ç†æ—¥æœŸå’Œæ—¶é—´ä¼¼ä¹æ¯”å¿…è¦çš„è¦å›°éš¾ï¼Œä½†å¸Œæœ›æœ¬ç« èƒ½å¸®åŠ©ä½ ç†è§£å…¶ä¸­çš„åŸå› â€”â€”æ—¥æœŸæ—¶é—´æ¯”åˆçœ‹èµ·æ¥è¦å¤æ‚å¾—å¤šï¼Œå¤„ç†æ¯ä¸€ç§å¯èƒ½çš„æƒ…å†µéƒ½ä¼šå¢åŠ å¤æ‚æ€§ã€‚å³ä½¿ä½ çš„æ•°æ®ä»æœªè·¨è¶Šå¤ä»¤æ—¶è¾¹ç•Œæˆ–æ¶‰åŠé—°å¹´ï¼Œè¿™äº›å‡½æ•°ä¹Ÿéœ€è¦èƒ½å¤Ÿå¤„ç†è¿™äº›æƒ…å†µã€‚\nThe next chapter gives a round up of missing values. Youâ€™ve seen them in a few places and have no doubt encounter in your own analysis, and itâ€™s now time to provide a grab bag of useful techniques for dealing with them.\nä¸‹ä¸€ç« å°†å¯¹ç¼ºå¤±å€¼è¿›è¡Œæ€»ç»“ã€‚ä½ å·²ç»åœ¨ä¸€äº›åœ°æ–¹è§è¿‡å®ƒä»¬ï¼Œå¹¶ä¸”æ¯«æ— ç–‘é—®åœ¨è‡ªå·±çš„åˆ†æä¸­ä¹Ÿé‡åˆ°è¿‡ï¼Œç°åœ¨æ˜¯æ—¶å€™æä¾›ä¸€ç³»åˆ—å¤„ç†å®ƒä»¬çš„æœ‰ç”¨æŠ€å·§äº†ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#footnotes",
    "href": "datetimes.html#footnotes",
    "title": "17Â  Dates and times",
    "section": "",
    "text": "A year is a leap year if itâ€™s divisible by 4, unless itâ€™s also divisible by 100, except if itâ€™s also divisible by 400. In other words, in every set of 400 years, thereâ€™s 97 leap years.â†©ï¸\nhttps://xkcd.com/1179/â†©ï¸\nYou might wonder what UTC stands for. Itâ€™s a compromise between the English â€œCoordinated Universal Timeâ€ and French â€œTemps Universel CoordonnÃ©â€.â†©ï¸\nNo prizes for guessing which country came up with the longitude system.â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>17</span>Â  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "missing-values.html",
    "href": "missing-values.html",
    "title": "18Â  Missing values",
    "section": "",
    "text": "18.1 Introduction\nYouâ€™ve already learned the basics of missing values earlier in the book.\nä½ å·²ç»åœ¨æœ¬ä¹¦çš„å‰é¢éƒ¨åˆ†å­¦ä¹ äº†ç¼ºå¤±å€¼çš„åŸºç¡€çŸ¥è¯†ã€‚\nYou first saw them in Chapter 1 where they resulted in a warning when making a plot as well as in Section 3.5.2 where they interfered with computing summary statistics, and you learned about their infectious nature and how to check for their presence in Section 12.2.2.\nä½ ç¬¬ä¸€æ¬¡è§åˆ°å®ƒä»¬æ˜¯åœ¨ Chapter 1 ä¸­ï¼Œå®ƒä»¬åœ¨åˆ¶ä½œå›¾è¡¨æ—¶å¯¼è‡´äº†ä¸€ä¸ªè­¦å‘Šï¼›åœ¨ Section 3.5.2 ä¸­ï¼Œå®ƒä»¬å¹²æ‰°äº†æ‘˜è¦ç»Ÿè®¡çš„è®¡ç®—ï¼›åœ¨ Section 12.2.2 ä¸­ï¼Œä½ å­¦ä¹ äº†å®ƒä»¬çš„ä¼ æŸ“æ€§ä»¥åŠå¦‚ä½•æ£€æŸ¥å®ƒä»¬çš„å­˜åœ¨ã€‚\nNow weâ€™ll come back to them in more depth, so you can learn more of the details.\nç°åœ¨æˆ‘ä»¬å°†æ›´æ·±å…¥åœ°æ¢è®¨å®ƒä»¬ï¼Œä»¥ä¾¿ä½ äº†è§£æ›´å¤šç»†èŠ‚ã€‚\nWeâ€™ll start by discussing some general tools for working with missing values recorded as NAs.\næˆ‘ä»¬å°†ä»è®¨è®ºä¸€äº›å¤„ç†è¢«è®°å½•ä¸º NA çš„ç¼ºå¤±å€¼çš„é€šç”¨å·¥å…·å¼€å§‹ã€‚\nWeâ€™ll then explore the idea of implicitly missing values, values that are simply absent from your data, and show some tools you can use to make them explicit.\nç„¶åï¼Œæˆ‘ä»¬å°†æ¢è®¨éšå¼ç¼ºå¤±å€¼çš„æ¦‚å¿µï¼Œå³é‚£äº›æ ¹æœ¬ä¸å­˜åœ¨äºä½ çš„æ•°æ®ä¸­çš„å€¼ï¼Œå¹¶å±•ç¤ºä¸€äº›å¯ä»¥ç”¨æ¥å°†å®ƒä»¬æ˜¾å¼åŒ–çš„å·¥å…·ã€‚\nWeâ€™ll finish off with a related discussion of empty groups, caused by factor levels that donâ€™t appear in the data.\næœ€åï¼Œæˆ‘ä»¬å°†ä»¥ä¸€ä¸ªç›¸å…³çš„è®¨è®ºç»“æŸï¼Œå³ç©ºç»„ï¼Œè¿™æ˜¯ç”±æœªå‡ºç°åœ¨æ•°æ®ä¸­çš„å› å­æ°´å¹³å¼•èµ·çš„ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>18</span>Â  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "missing-values.html#introduction",
    "href": "missing-values.html#introduction",
    "title": "18Â  Missing values",
    "section": "",
    "text": "18.1.1 Prerequisites\nThe functions for working with missing data mostly come from dplyr and tidyr, which are core members of the tidyverse.\nå¤„ç†ç¼ºå¤±æ•°æ®çš„å‡½æ•°ä¸»è¦æ¥è‡ª dplyr å’Œ tidyrï¼Œå®ƒä»¬æ˜¯ tidyverse çš„æ ¸å¿ƒæˆå‘˜ã€‚\n\nlibrary(tidyverse)",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>18</span>Â  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "missing-values.html#explicit-missing-values",
    "href": "missing-values.html#explicit-missing-values",
    "title": "18Â  Missing values",
    "section": "\n18.2 Explicit missing values",
    "text": "18.2 Explicit missing values\nTo begin, letâ€™s explore a few handy tools for creating or eliminating missing explicit values, i.e.Â cells where you see an NA.\né¦–å…ˆï¼Œè®©æˆ‘ä»¬æ¥æ¢ç´¢ä¸€äº›æ–¹ä¾¿çš„å·¥å…·ï¼Œç”¨äºåˆ›å»ºæˆ–æ¶ˆé™¤æ˜¾å¼ç¼ºå¤±å€¼ï¼Œå³é‚£äº›ä½ çœ‹åˆ° NA çš„å•å…ƒæ ¼ã€‚\n\n18.2.1 Last observation carried forward\nA common use for missing values is as a data entry convenience.\nç¼ºå¤±å€¼çš„ä¸€ä¸ªå¸¸è§ç”¨é€”æ˜¯ä½œä¸ºæ•°æ®å½•å…¥çš„ä¾¿åˆ©æ‰‹æ®µã€‚\nWhen data is entered by hand, missing values sometimes indicate that the value in the previous row has been repeated (or carried forward):\nå½“æ‰‹åŠ¨è¾“å…¥æ•°æ®æ—¶ï¼Œç¼ºå¤±å€¼æœ‰æ—¶è¡¨ç¤ºå‰ä¸€è¡Œçš„å€¼è¢«é‡å¤ï¼ˆæˆ–ç»“è½¬ï¼‰äº†ï¼š\n\ntreatment &lt;- tribble(\n  ~person,           ~treatment, ~response,\n  \"Derrick Whitmore\", 1,         7,\n  NA,                 2,         10,\n  NA,                 3,         NA,\n  \"Katherine Burke\",  1,         4\n)\n\nYou can fill in these missing values with tidyr::fill().\nä½ å¯ä»¥ä½¿ç”¨ tidyr::fill() æ¥å¡«å……è¿™äº›ç¼ºå¤±å€¼ã€‚\nIt works like select(), taking a set of columns:\nå®ƒçš„å·¥ä½œæ–¹å¼ç±»ä¼¼äº select()ï¼Œæ¥å—ä¸€ç»„åˆ—ï¼š\n\ntreatment |&gt;\n  fill(everything())\n#&gt; # A tibble: 4 Ã— 3\n#&gt;   person           treatment response\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 Derrick Whitmore         1        7\n#&gt; 2 Derrick Whitmore         2       10\n#&gt; 3 Derrick Whitmore         3       10\n#&gt; 4 Katherine Burke          1        4\n\nThis treatment is sometimes called â€œlast observation carried forwardâ€, or locf for short.\nè¿™ç§å¤„ç†æ–¹æ³•æœ‰æ—¶è¢«ç§°ä¸ºâ€œæœ«æ¬¡è§‚æµ‹å€¼ç»“è½¬æ³•â€ï¼Œç®€ç§° locf (last observation carried forward)ã€‚\nYou can use the .direction argument to fill in missing values that have been generated in more exotic ways.\nä½ å¯ä»¥ä½¿ç”¨ .direction å‚æ•°æ¥å¡«å……ä»¥æ›´ç‰¹æ®Šæ–¹å¼ç”Ÿæˆçš„ç¼ºå¤±å€¼ã€‚\n\n18.2.2 Fixed values\nSome times missing values represent some fixed and known value, most commonly 0.\næœ‰æ—¶ç¼ºå¤±å€¼ä»£è¡¨æŸä¸ªå›ºå®šçš„å·²çŸ¥å€¼ï¼Œæœ€å¸¸è§çš„æ˜¯ 0ã€‚\nYou can use dplyr::coalesce() to replace them:\nä½ å¯ä»¥ä½¿ç”¨ dplyr::coalesce() æ¥æ›¿æ¢å®ƒä»¬ï¼š\n\nx &lt;- c(1, 4, 5, 7, NA)\ncoalesce(x, 0)\n#&gt; [1] 1 4 5 7 0\n\nSometimes youâ€™ll hit the opposite problem where some concrete value actually represents a missing value.\næœ‰æ—¶ä½ ä¼šé‡åˆ°ç›¸åçš„é—®é¢˜ï¼Œå³æŸä¸ªå…·ä½“çš„å€¼å®é™…ä¸Šä»£è¡¨ä¸€ä¸ªç¼ºå¤±å€¼ã€‚\nThis typically arises in data generated by older software that doesnâ€™t have a proper way to represent missing values, so it must instead use some special value like 99 or -999.\nè¿™é€šå¸¸å‘ç”Ÿåœ¨ç”±æ—§è½¯ä»¶ç”Ÿæˆçš„æ•°æ®ä¸­ï¼Œè¿™äº›è½¯ä»¶æ²¡æœ‰åˆé€‚çš„æ–¹å¼æ¥è¡¨ç¤ºç¼ºå¤±å€¼ï¼Œå› æ­¤å¿…é¡»ä½¿ç”¨ä¸€äº›ç‰¹æ®Šå€¼ï¼Œå¦‚ 99 æˆ– -999ã€‚\nIf possible, handle this when reading in the data, for example, by using the na argument to readr::read_csv(), e.g., read_csv(path, na = \"99\").\nå¦‚æœå¯èƒ½çš„è¯ï¼Œåœ¨è¯»å…¥æ•°æ®æ—¶å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡ä½¿ç”¨ readr::read_csv() çš„ na å‚æ•°ï¼Œå¦‚ read_csv(path, na = \"99\")ã€‚\nIf you discover the problem later, or your data source doesnâ€™t provide a way to handle it on read, you can use dplyr::na_if():\nå¦‚æœä½ åæ¥æ‰å‘ç°è¿™ä¸ªé—®é¢˜ï¼Œæˆ–è€…ä½ çš„æ•°æ®æºæ²¡æœ‰æä¾›åœ¨è¯»å–æ—¶å¤„ç†å®ƒçš„æ–¹æ³•ï¼Œä½ å¯ä»¥ä½¿ç”¨ dplyr::na_if()ï¼š\n\nx &lt;- c(1, 4, 5, 7, -99)\nna_if(x, -99)\n#&gt; [1]  1  4  5  7 NA\n\n\n18.2.3 NaN\nBefore we continue, thereâ€™s one special type of missing value that youâ€™ll encounter from time to time: a NaN (pronounced â€œnanâ€), or not a number.\nåœ¨ç»§ç»­ä¹‹å‰ï¼Œæœ‰ä¸€ç§ä½ å¶å°”ä¼šé‡åˆ°çš„ç‰¹æ®Šç±»å‹çš„ç¼ºå¤±å€¼ï¼šNaNï¼ˆå‘éŸ³ä¸ºâ€œnanâ€ï¼‰ï¼Œå³ not a number (éæ•°å€¼)ã€‚\nItâ€™s not that important to know about because it generally behaves just like NA:\näº†è§£å®ƒå¹¶ä¸æ˜¯é‚£ä¹ˆé‡è¦ï¼Œå› ä¸ºå®ƒé€šå¸¸è¡¨ç°å¾—å°±åƒ NA ä¸€æ ·ï¼š\n\nx &lt;- c(NA, NaN)\nx * 10\n#&gt; [1]  NA NaN\nx == 1\n#&gt; [1] NA NA\nis.na(x)\n#&gt; [1] TRUE TRUE\n\nIn the rare case you need to distinguish an NA from a NaN, you can use is.nan(x).\nåœ¨æå°‘æ•°æƒ…å†µä¸‹ï¼Œå¦‚æœä½ éœ€è¦åŒºåˆ† NA å’Œ NaNï¼Œå¯ä»¥ä½¿ç”¨ is.nan(x)ã€‚\nYouâ€™ll generally encounter a NaN when you perform a mathematical operation that has an indeterminate result:\nä½ é€šå¸¸ä¼šåœ¨æ‰§è¡Œç»“æœä¸ç¡®å®šçš„æ•°å­¦è¿ç®—æ—¶é‡åˆ° NaNï¼š\n\n0 / 0 \n#&gt; [1] NaN\n0 * Inf\n#&gt; [1] NaN\nInf - Inf\n#&gt; [1] NaN\nsqrt(-1)\n#&gt; Warning in sqrt(-1): NaNs produced\n#&gt; [1] NaN",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>18</span>Â  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "missing-values.html#sec-missing-implicit",
    "href": "missing-values.html#sec-missing-implicit",
    "title": "18Â  Missing values",
    "section": "\n18.3 Implicit missing values",
    "text": "18.3 Implicit missing values\nSo far weâ€™ve talked about missing values that are explicitly missing, i.e.Â you can see an NA in your data.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¨è®ºçš„éƒ½æ˜¯æ˜¾å¼ç¼ºå¤±çš„å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä½ å¯ä»¥åœ¨æ•°æ®ä¸­çœ‹åˆ°ä¸€ä¸ª NAã€‚\nBut missing values can also be implicitly missing, if an entire row of data is simply absent from the data.\nä½†ç¼ºå¤±å€¼ä¹Ÿå¯èƒ½æ˜¯éšå¼çš„ï¼Œå¦‚æœä¸€æ•´è¡Œæ•°æ®æ ¹æœ¬å°±ä¸åœ¨æ•°æ®ä¸­ã€‚\nLetâ€™s illustrate the difference with a simple dataset that records the price of some stock each quarter:\nè®©æˆ‘ä»¬ç”¨ä¸€ä¸ªè®°å½•æŸåªè‚¡ç¥¨æ¯ä¸ªå­£åº¦ä»·æ ¼çš„ç®€å•æ•°æ®é›†æ¥è¯´æ˜è¿™ç§å·®å¼‚ï¼š\n\nstocks &lt;- tibble(\n  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),\n  qtr   = c(   1,    2,    3,    4,    2,    3,    4),\n  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)\n)\n\nThis dataset has two missing observations:\nè¿™ä¸ªæ•°æ®é›†æœ‰ä¸¤ä¸ªç¼ºå¤±çš„è§‚æµ‹å€¼ï¼š\n\nThe price in the fourth quarter of 2020 is explicitly missing, because its value is NA.\n2020 å¹´ç¬¬å››å­£åº¦çš„ price æ˜¯æ˜¾å¼ç¼ºå¤±çš„ï¼Œå› ä¸ºå®ƒçš„å€¼æ˜¯ NAã€‚\nThe price for the first quarter of 2021 is implicitly missing, because it simply does not appear in the dataset.\n2021 å¹´ç¬¬ä¸€å­£åº¦çš„ price æ˜¯éšå¼ç¼ºå¤±çš„ï¼Œå› ä¸ºå®ƒæ ¹æœ¬æ²¡æœ‰å‡ºç°åœ¨æ•°æ®é›†ä¸­ã€‚\n\nOne way to think about the difference is with this Zen-like koan:\nç†è§£è¿™ç§å·®å¼‚çš„ä¸€ç§æ–¹å¼æ˜¯è¿™ä¸ªå¯Œæœ‰ç¦…æ„çš„å…¬æ¡ˆï¼š\n\nAn explicit missing value is the presence of an absence.\nAn implicit missing value is the absence of a presence.\næ˜¾å¼ç¼ºå¤±æ˜¯â€œæ— â€ä¹‹æ‰€åœ¨ã€‚\néšå¼ç¼ºå¤±æ˜¯â€œåœ¨â€ä¹‹æ‰€æ— ã€‚\n\nSometimes you want to make implicit missings explicit in order to have something physical to work with.\næœ‰æ—¶ä½ æƒ³è¦å°†éšå¼ç¼ºå¤±æ˜¾å¼åŒ–ï¼Œä»¥ä¾¿æœ‰ä¸€ä¸ªå®ä½“å¯ä»¥æ“ä½œã€‚\nIn other cases, explicit missings are forced upon you by the structure of the data and you want to get rid of them.\nåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œæ•°æ®çš„ç»“æ„ä¼šè¿«ä½¿ä½ é¢å¯¹æ˜¾å¼ç¼ºå¤±ï¼Œè€Œä½ æƒ³è¦æ‘†è„±å®ƒä»¬ã€‚\nThe following sections discuss some tools for moving between implicit and explicit missingness.\nä»¥ä¸‹å„èŠ‚è®¨è®ºäº†ä¸€äº›åœ¨éšå¼å’Œæ˜¾å¼ç¼ºå¤±ä¹‹é—´è½¬æ¢çš„å·¥å…·ã€‚\n\n18.3.1 Pivoting\nYouâ€™ve already seen one tool that can make implicit missings explicit and vice versa: pivoting.\nä½ å·²ç»è§è¿‡ä¸€ä¸ªå¯ä»¥åœ¨éšå¼ç¼ºå¤±å’Œæ˜¾å¼ç¼ºå¤±ä¹‹é—´ç›¸äº’è½¬æ¢çš„å·¥å…·ï¼šé€è§† (pivoting)ã€‚\nMaking data wider can make implicit missing values explicit because every combination of the rows and new columns must have some value.\nå°†æ•°æ®å˜å®½å¯ä»¥ä½¿éšå¼ç¼ºå¤±å€¼æ˜¾å¼åŒ–ï¼Œå› ä¸ºè¡Œå’Œæ–°åˆ—çš„æ¯ç§ç»„åˆéƒ½å¿…é¡»æœ‰æŸä¸ªå€¼ã€‚\nFor example, if we pivot stocks to put the quarter in the columns, both missing values become explicit:\nä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°† stocks æ•°æ®è¿›è¡Œé€è§†ï¼ŒæŠŠ quarter æ”¾åˆ°åˆ—ä¸­ï¼Œé‚£ä¹ˆä¸¤ä¸ªç¼ºå¤±å€¼éƒ½ä¼šå˜å¾—æ˜¾å¼ï¼š\n\nstocks |&gt;\n  pivot_wider(\n    names_from = qtr, \n    values_from = price\n  )\n#&gt; # A tibble: 2 Ã— 5\n#&gt;    year   `1`   `2`   `3`   `4`\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020  1.88  0.59  0.35 NA   \n#&gt; 2  2021 NA     0.92  0.17  2.66\n\nBy default, making data longer preserves explicit missing values, but if they are structurally missing values that only exist because the data is not tidy, you can drop them (make them implicit) by setting values_drop_na = TRUE.\né»˜è®¤æƒ…å†µä¸‹ï¼Œå°†æ•°æ®å˜é•¿ä¼šä¿ç•™æ˜¾å¼ç¼ºå¤±å€¼ï¼Œä½†å¦‚æœå®ƒä»¬æ˜¯ç”±äºæ•°æ®ä¸æ•´æ´è€Œå­˜åœ¨çš„ç»“æ„æ€§ç¼ºå¤±å€¼ï¼Œä½ å¯ä»¥é€šè¿‡è®¾ç½® values_drop_na = TRUE æ¥ä¸¢å¼ƒå®ƒä»¬ï¼ˆä½¿å…¶å˜ä¸ºéšå¼ï¼‰ã€‚\nSee the examples in Section 5.2 for more details.\næ›´å¤šç»†èŠ‚è¯·å‚è§ Section 5.2 ä¸­çš„ç¤ºä¾‹ã€‚\n\n18.3.2 Complete\ntidyr::complete() allows you to generate explicit missing values by providing a set of variables that define the combination of rows that should exist.tidyr::complete() å…è®¸ä½ é€šè¿‡æä¾›ä¸€ç»„å®šä¹‰åº”å­˜åœ¨çš„è¡Œç»„åˆçš„å˜é‡æ¥ç”Ÿæˆæ˜¾å¼ç¼ºå¤±å€¼ã€‚\nFor example, we know that all combinations of year and qtr should exist in the stocks data:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬çŸ¥é“ stocks æ•°æ®ä¸­åº”è¯¥å­˜åœ¨ year å’Œ qtr çš„æ‰€æœ‰ç»„åˆï¼š\n\nstocks |&gt;\n  complete(year, qtr)\n#&gt; # A tibble: 8 Ã— 3\n#&gt;    year   qtr price\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020     1  1.88\n#&gt; 2  2020     2  0.59\n#&gt; 3  2020     3  0.35\n#&gt; 4  2020     4 NA   \n#&gt; 5  2021     1 NA   \n#&gt; 6  2021     2  0.92\n#&gt; # â„¹ 2 more rows\n\nTypically, youâ€™ll call complete() with names of existing variables, filling in the missing combinations.\né€šå¸¸ï¼Œä½ ä¼šä½¿ç”¨ç°æœ‰å˜é‡çš„åç§°æ¥è°ƒç”¨ complete()ï¼Œä»¥å¡«è¡¥ç¼ºå¤±çš„ç»„åˆã€‚\nHowever, sometimes the individual variables are themselves incomplete, so you can instead provide your own data.\nç„¶è€Œï¼Œæœ‰æ—¶å•ä¸ªå˜é‡æœ¬èº«å°±æ˜¯ä¸å®Œæ•´çš„ï¼Œæ‰€ä»¥ä½ å¯ä»¥æä¾›è‡ªå·±çš„æ•°æ®ã€‚\nFor example, you might know that the stocks dataset is supposed to run from 2019 to 2021, so you could explicitly supply those values for year:\nä¾‹å¦‚ï¼Œä½ å¯èƒ½çŸ¥é“ stocks æ•°æ®é›†åº”è¯¥ä» 2019 å¹´è¿è¡Œåˆ° 2021 å¹´ï¼Œæ‰€ä»¥ä½ å¯ä»¥æ˜ç¡®åœ°ä¸º year æä¾›è¿™äº›å€¼ï¼š\n\nstocks |&gt;\n  complete(year = 2019:2021, qtr)\n#&gt; # A tibble: 12 Ã— 3\n#&gt;    year   qtr price\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2019     1 NA   \n#&gt; 2  2019     2 NA   \n#&gt; 3  2019     3 NA   \n#&gt; 4  2019     4 NA   \n#&gt; 5  2020     1  1.88\n#&gt; 6  2020     2  0.59\n#&gt; # â„¹ 6 more rows\n\nIf the range of a variable is correct, but not all values are present, you could use full_seq(x, 1) to generate all values from min(x) to max(x) spaced out by 1.\nå¦‚æœä¸€ä¸ªå˜é‡çš„èŒƒå›´æ˜¯æ­£ç¡®çš„ï¼Œä½†å¹¶éæ‰€æœ‰å€¼éƒ½å­˜åœ¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ full_seq(x, 1) æ¥ç”Ÿæˆä» min(x) åˆ° max(x) ä¹‹é—´æ‰€æœ‰ä»¥ 1 ä¸ºé—´éš”çš„å€¼ã€‚\nIn some cases, the complete set of observations canâ€™t be generated by a simple combination of variables.\nåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå®Œæ•´çš„è§‚æµ‹é›†æ— æ³•é€šè¿‡å˜é‡çš„ç®€å•ç»„åˆç”Ÿæˆã€‚\nIn that case, you can do manually what complete() does for you: create a data frame that contains all the rows that should exist (using whatever combination of techniques you need), then combine it with your original dataset with dplyr::full_join().\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥æ‰‹åŠ¨å®Œæˆ complete() ä¸ºä½ åšçš„äº‹æƒ…ï¼šåˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰åº”å­˜åœ¨çš„è¡Œçš„æ•°æ®æ¡†ï¼ˆä½¿ç”¨ä½ éœ€è¦çš„ä»»ä½•æŠ€æœ¯ç»„åˆï¼‰ï¼Œç„¶åä½¿ç”¨ dplyr::full_join() å°†å…¶ä¸åŸå§‹æ•°æ®é›†ç»“åˆèµ·æ¥ã€‚\n\n18.3.3 Joins\nThis brings us to another important way of revealing implicitly missing observations: joins.\nè¿™å°±å¼•å‡ºäº†å¦ä¸€ç§æ­ç¤ºéšå¼ç¼ºå¤±è§‚æµ‹å€¼çš„é‡è¦æ–¹æ³•ï¼šè¿æ¥ (joins)ã€‚\nYouâ€™ll learn more about joins in Chapter 19, but we wanted to quickly mention them to you here since you can often only know that values are missing from one dataset when you compare it to another.\nä½ å°†åœ¨ Chapter 19 ä¸­å­¦ä¹ æ›´å¤šå…³äºè¿æ¥çš„çŸ¥è¯†ï¼Œä½†æˆ‘ä»¬æƒ³åœ¨è¿™é‡Œå¿«é€ŸæåŠå®ƒä»¬ï¼Œå› ä¸ºä½ é€šå¸¸åªæœ‰åœ¨å°†ä¸€ä¸ªæ•°æ®é›†ä¸å¦ä¸€ä¸ªæ•°æ®é›†è¿›è¡Œæ¯”è¾ƒæ—¶ï¼Œæ‰èƒ½çŸ¥é“å…¶ä¸­çš„å€¼æ˜¯ç¼ºå¤±çš„ã€‚\ndplyr::anti_join(x, y) is a particularly useful tool here because it selects only the rows in x that donâ€™t have a match in y.dplyr::anti_join(x, y) åœ¨è¿™é‡Œæ˜¯ä¸€ä¸ªç‰¹åˆ«æœ‰ç”¨çš„å·¥å…·ï¼Œå› ä¸ºå®ƒåªé€‰æ‹© x ä¸­åœ¨ y ä¸­æ²¡æœ‰åŒ¹é…é¡¹çš„è¡Œã€‚\nFor example, we can use two anti_join()s to reveal that weâ€™re missing information for four airports and 722 planes mentioned in flights:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸¤ä¸ª anti_join() æ¥æ­ç¤ºæˆ‘ä»¬ç¼ºå°‘ flights ä¸­æåˆ°çš„å››ä¸ªæœºåœºå’Œ 722 æ¶é£æœºçš„ä¿¡æ¯ï¼š\n\nlibrary(nycflights13)\n\nflights |&gt; \n  distinct(faa = dest) |&gt; \n  anti_join(airports)\n#&gt; Joining with `by = join_by(faa)`\n#&gt; # A tibble: 4 Ã— 1\n#&gt;   faa  \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\nflights |&gt; \n  distinct(tailnum) |&gt; \n  anti_join(planes)\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 722 Ã— 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # â„¹ 716 more rows\n\n\n18.3.4 Exercises\n\nCan you find any relationship between the carrier and the rows that appear to be missing from planes?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>18</span>Â  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "missing-values.html#factors-and-empty-groups",
    "href": "missing-values.html#factors-and-empty-groups",
    "title": "18Â  Missing values",
    "section": "\n18.4 Factors and empty groups",
    "text": "18.4 Factors and empty groups\nA final type of missingness is the empty group, a group that doesnâ€™t contain any observations, which can arise when working with factors.\næœ€åä¸€ç§ç¼ºå¤±ç±»å‹æ˜¯ç©ºç»„ï¼Œå³ä¸åŒ…å«ä»»ä½•è§‚æµ‹å€¼çš„ç»„ï¼Œè¿™åœ¨ä½¿ç”¨å› å­ (factors) æ—¶å¯èƒ½ä¼šå‡ºç°ã€‚\nFor example, imagine we have a dataset that contains some health information about people:\nä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«ä¸€äº›äººå¥åº·ä¿¡æ¯çš„æ•°æ®é›†ï¼š\n\nhealth &lt;- tibble(\n  name   = c(\"Ikaia\", \"Oletta\", \"Leriah\", \"Dashay\", \"Tresaun\"),\n  smoker = factor(c(\"no\", \"no\", \"no\", \"no\", \"no\"), levels = c(\"yes\", \"no\")),\n  age    = c(34, 88, 75, 47, 56),\n)\n\nAnd we want to count the number of smokers with dplyr::count():\næˆ‘ä»¬æƒ³ç”¨ dplyr::count() æ¥è®¡ç®—å¸çƒŸè€…çš„æ•°é‡ï¼š\n\nhealth |&gt; count(smoker)\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   smoker     n\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 no         5\n\nThis dataset only contains non-smokers, but we know that smokers exist; the group of non-smokers is empty.\nè¿™ä¸ªæ•°æ®é›†åªåŒ…å«éå¸çƒŸè€…ï¼Œä½†æˆ‘ä»¬çŸ¥é“å¸çƒŸè€…æ˜¯å­˜åœ¨çš„ï¼›å¸çƒŸè€…è¿™ä¸ªç»„æ˜¯ç©ºçš„ã€‚\nWe can request count() to keep all the groups, even those not seen in the data by using .drop = FALSE:\næˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ .drop = FALSE æ¥è¦æ±‚ count() ä¿ç•™æ‰€æœ‰çš„ç»„ï¼Œå³ä½¿æ˜¯é‚£äº›åœ¨æ•°æ®ä¸­æœªå‡ºç°çš„ç»„ï¼š\n\nhealth |&gt; count(smoker, .drop = FALSE)\n#&gt; # A tibble: 2 Ã— 2\n#&gt;   smoker     n\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 yes        0\n#&gt; 2 no         5\n\nThe same principle applies to ggplot2â€™s discrete axes, which will also drop levels that donâ€™t have any values.\nåŒæ ·çš„åŸåˆ™ä¹Ÿé€‚ç”¨äº ggplot2 çš„ç¦»æ•£åæ ‡è½´ï¼Œå®ƒä¹Ÿä¼šä¸¢å¼ƒæ²¡æœ‰ä»»ä½•å€¼çš„æ°´å¹³ (levels)ã€‚\nYou can force them to display by supplying drop = FALSE to the appropriate discrete axis:\nä½ å¯ä»¥é€šè¿‡å‘ç›¸åº”çš„ç¦»æ•£åæ ‡è½´æä¾› drop = FALSE æ¥å¼ºåˆ¶æ˜¾ç¤ºå®ƒä»¬ï¼š\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete()\n\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete(drop = FALSE)\n\n\n\n\n\n\n\n\n\n\nThe same problem comes up more generally with dplyr::group_by().\næ›´æ™®éåœ°ï¼Œdplyr::group_by() ä¹Ÿä¼šå‡ºç°åŒæ ·çš„é—®é¢˜ã€‚\nAnd again you can use .drop = FALSE to preserve all factor levels:\nåŒæ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨ .drop = FALSE æ¥ä¿ç•™æ‰€æœ‰çš„å› å­æ°´å¹³ï¼š\n\nhealth |&gt; \n  group_by(smoker, .drop = FALSE) |&gt; \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  )\n#&gt; # A tibble: 2 Ã— 6\n#&gt;   smoker     n mean_age min_age max_age sd_age\n#&gt;   &lt;fct&gt;  &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 yes        0      NaN     Inf    -Inf   NA  \n#&gt; 2 no         5       60      34      88   21.6\n\nWe get some interesting results here because when summarizing an empty group, the summary functions are applied to zero-length vectors.\næˆ‘ä»¬åœ¨è¿™é‡Œå¾—åˆ°äº†ä¸€äº›æœ‰è¶£çš„ç»“æœï¼Œå› ä¸ºå½“å¯¹ä¸€ä¸ªç©ºç»„è¿›è¡Œæ±‡æ€»æ—¶ï¼Œæ±‡æ€»å‡½æ•°è¢«åº”ç”¨äºé•¿åº¦ä¸ºé›¶çš„å‘é‡ã€‚\nThereâ€™s an important distinction between empty vectors, which have length 0, and missing values, each of which has length 1.\nç©ºå‘é‡ï¼ˆé•¿åº¦ä¸º 0ï¼‰å’Œç¼ºå¤±å€¼ï¼ˆæ¯ä¸ªé•¿åº¦ä¸º 1ï¼‰ä¹‹é—´æœ‰ä¸€ä¸ªé‡è¦çš„åŒºåˆ«ã€‚\n\n# A vector containing two missing values\nx1 &lt;- c(NA, NA)\nlength(x1)\n#&gt; [1] 2\n\n# A vector containing nothing\nx2 &lt;- numeric()\nlength(x2)\n#&gt; [1] 0\n\nAll summary functions work with zero-length vectors, but they may return results that are surprising at first glance.\næ‰€æœ‰çš„æ±‡æ€»å‡½æ•°éƒ½å¯ä»¥å¤„ç†é›¶é•¿åº¦å‘é‡ï¼Œä½†å®ƒä»¬è¿”å›çš„ç»“æœä¹ä¸€çœ‹å¯èƒ½ä¼šä»¤äººæƒŠè®¶ã€‚\nHere we see mean(age) returning NaN because mean(age) = sum(age)/length(age) which here is 0/0.\nåœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ° mean(age) è¿”å› NaNï¼Œå› ä¸º mean(age) = sum(age)/length(age)ï¼Œåœ¨è¿™é‡Œæ˜¯ 0/0ã€‚\nmax() and min() return -Inf and Inf for empty vectors so if you combine the results with a non-empty vector of new data and recompute youâ€™ll get the minimum or maximum of the new data1.\nå¯¹äºç©ºå‘é‡ï¼Œmax() å’Œ min() ä¼šè¿”å› -Inf å’Œ Infï¼Œæ‰€ä»¥å¦‚æœä½ å°†ç»“æœä¸ä¸€ä¸ªæ–°çš„éç©ºå‘é‡æ•°æ®ç»“åˆèµ·æ¥é‡æ–°è®¡ç®—ï¼Œä½ å°†å¾—åˆ°æ–°æ•°æ®çš„æœ€å°å€¼æˆ–æœ€å¤§å€¼1ã€‚\nSometimes a simpler approach is to perform the summary and then make the implicit missings explicit with complete().\næœ‰æ—¶ï¼Œä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ³•æ˜¯å…ˆæ‰§è¡Œæ±‡æ€»ï¼Œç„¶åä½¿ç”¨ complete() å°†éšå¼ç¼ºå¤±æ˜¾å¼åŒ–ã€‚\n\nhealth |&gt; \n  group_by(smoker) |&gt; \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  ) |&gt; \n  complete(smoker)\n#&gt; # A tibble: 2 Ã— 6\n#&gt;   smoker     n mean_age min_age max_age sd_age\n#&gt;   &lt;fct&gt;  &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 yes       NA       NA      NA      NA   NA  \n#&gt; 2 no         5       60      34      88   21.6\n\nThe main drawback of this approach is that you get an NA for the count, even though you know that it should be zero.\nè¿™ç§æ–¹æ³•çš„ä¸»è¦ç¼ºç‚¹æ˜¯ï¼Œå°½ç®¡ä½ çŸ¥é“è®¡æ•°åº”è¯¥ä¸ºé›¶ï¼Œä½†ä½ å´å¾—åˆ°äº†ä¸€ä¸ª NAã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>18</span>Â  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "missing-values.html#summary",
    "href": "missing-values.html#summary",
    "title": "18Â  Missing values",
    "section": "\n18.5 Summary",
    "text": "18.5 Summary\nMissing values are weird!\nç¼ºå¤±å€¼å¾ˆå¥‡æ€ªï¼\nSometimes theyâ€™re recorded as an explicit NA but other times you only notice them by their absence.\næœ‰æ—¶å®ƒä»¬è¢«è®°å½•ä¸ºæ˜¾å¼çš„ NAï¼Œä½†å…¶ä»–æ—¶å€™ä½ åªèƒ½é€šè¿‡å®ƒä»¬çš„ç¼ºå¸­æ¥æ³¨æ„åˆ°å®ƒä»¬ã€‚\nThis chapter has given you some tools for working with explicit missing values, tools for uncovering implicit missing values, and discussed some of the ways that implicit can become explicit and vice versa.\næœ¬ç« ä¸ºä½ æä¾›äº†ä¸€äº›å¤„ç†æ˜¾å¼ç¼ºå¤±å€¼çš„å·¥å…·ï¼Œä¸€äº›æ­ç¤ºéšå¼ç¼ºå¤±å€¼çš„å·¥å…·ï¼Œå¹¶è®¨è®ºäº†éšå¼å¦‚ä½•å˜ä¸ºæ˜¾å¼ä»¥åŠåä¹‹äº¦ç„¶çš„ä¸€äº›æ–¹æ³•ã€‚\nIn the next chapter, we tackle the final chapter in this part of the book: joins.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨æœ¬ä¹¦è¿™ä¸€éƒ¨åˆ†çš„æœ€åä¸€ç« ï¼šè¿æ¥ (joins)ã€‚\nThis is a bit of a change from the chapters so far because weâ€™re going to discuss tools that work with data frames as a whole, not something that you put inside a data frame.\nè¿™ä¸åˆ°ç›®å‰ä¸ºæ­¢çš„ç« èŠ‚æœ‰äº›ä¸åŒï¼Œå› ä¸ºæˆ‘ä»¬å°†è¦è®¨è®ºçš„æ˜¯ä½œç”¨äºæ•´ä¸ªæ•°æ®æ¡†çš„å·¥å…·ï¼Œè€Œä¸æ˜¯ä½ æ”¾åœ¨æ•°æ®æ¡†å†…éƒ¨çš„ä¸œè¥¿ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>18</span>Â  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "missing-values.html#footnotes",
    "href": "missing-values.html#footnotes",
    "title": "18Â  Missing values",
    "section": "",
    "text": "In other words, min(c(x, y)) is always equal to min(min(x), min(y)).â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>18</span>Â  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "joins.html",
    "href": "joins.html",
    "title": "19Â  Joins",
    "section": "",
    "text": "19.1 Introduction\nItâ€™s rare that a data analysis involves only a single data frame.\næ•°æ®åˆ†æå¾ˆå°‘åªæ¶‰åŠå•ä¸ªæ•°æ®æ¡†ã€‚\nTypically you have many data frames, and you must join them together to answer the questions that youâ€™re interested in.\né€šå¸¸ä½ ä¼šæœ‰å¾ˆå¤šæ•°æ®æ¡†ï¼Œä½ å¿…é¡»å°†å®ƒä»¬ è¿æ¥ (join) åœ¨ä¸€èµ·æ‰èƒ½å›ç­”ä½ æ„Ÿå…´è¶£çš„é—®é¢˜ã€‚\nThis chapter will introduce you to two important types of joins:\næœ¬ç« å°†å‘ä½ ä»‹ç»ä¸¤ç§é‡è¦çš„è¿æ¥ç±»å‹ï¼š\nWeâ€™ll begin by discussing keys, the variables used to connect a pair of data frames in a join.\næˆ‘ä»¬å°†ä»è®¨è®ºé”® (keys) å¼€å§‹ï¼Œé”®æ˜¯ç”¨äºåœ¨è¿æ¥ä¸­è¿æ¥ä¸€å¯¹æ•°æ®æ¡†çš„å˜é‡ã€‚\nWe cement the theory with an examination of the keys in the datasets from the nycflights13 package, then use that knowledge to start joining data frames together.\næˆ‘ä»¬å°†é€šè¿‡æ£€æŸ¥ nycflights13 åŒ…ä¸­æ•°æ®é›†çš„é”®æ¥å·©å›ºç†è®ºï¼Œç„¶ååˆ©ç”¨è¿™äº›çŸ¥è¯†å¼€å§‹å°†æ•°æ®æ¡†è¿æ¥åœ¨ä¸€èµ·ã€‚\nNext weâ€™ll discuss how joins work, focusing on their action on the rows.\næ¥ä¸‹æ¥æˆ‘ä»¬å°†è®¨è®ºè¿æ¥çš„å·¥ä½œåŸç†ï¼Œé‡ç‚¹å…³æ³¨å®ƒä»¬å¯¹è¡Œçš„æ“ä½œã€‚\nWeâ€™ll finish up with a discussion of non-equi joins, a family of joins that provide a more flexible way of matching keys than the default equality relationship.\næœ€åï¼Œæˆ‘ä»¬å°†è®¨è®ºéç­‰å€¼è¿æ¥ (non-equi joins)ï¼Œè¿™ç±»è¿æ¥æä¾›äº†ä¸€ç§æ¯”é»˜è®¤çš„ç›¸ç­‰å…³ç³»æ›´çµæ´»çš„é”®åŒ¹é…æ–¹å¼ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#introduction",
    "href": "joins.html#introduction",
    "title": "19Â  Joins",
    "section": "",
    "text": "Mutating joins, which add new variables to one data frame from matching observations in another.\nä¿®æ”¹è¿æ¥ (Mutating joins)ï¼Œå®ƒå°†ä¸€ä¸ªæ•°æ®æ¡†ä¸­çš„åŒ¹é…è§‚æµ‹å€¼çš„æ–°å˜é‡æ·»åŠ åˆ°å¦ä¸€ä¸ªæ•°æ®æ¡†ä¸­ã€‚\nFiltering joins, which filter observations from one data frame based on whether or not they match an observation in another.\nè¿‡æ»¤è¿æ¥ (Filtering joins)ï¼Œå®ƒæ ¹æ®ä¸€ä¸ªæ•°æ®æ¡†ä¸­çš„è§‚æµ‹å€¼æ˜¯å¦ä¸å¦ä¸€ä¸ªæ•°æ®æ¡†ä¸­çš„è§‚æµ‹å€¼åŒ¹é…æ¥è¿‡æ»¤å®ƒä»¬ã€‚\n\n\n\n\n\n\n19.1.1 Prerequisites\nIn this chapter, weâ€™ll explore the five related datasets from nycflights13 using the join functions from dplyr.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ dplyr ä¸­çš„è¿æ¥å‡½æ•°æ¥æ¢ç´¢ nycflights13 ä¸­çš„äº”ä¸ªç›¸å…³æ•°æ®é›†ã€‚\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#keys",
    "href": "joins.html#keys",
    "title": "19Â  Joins",
    "section": "\n19.2 Keys",
    "text": "19.2 Keys\nTo understand joins, you need to first understand how two tables can be connected through a pair of keys, within each table.\nè¦ç†è§£è¿æ¥ï¼Œä½ é¦–å…ˆéœ€è¦ç†è§£ä¸¤ä¸ªè¡¨å¦‚ä½•é€šè¿‡æ¯ä¸ªè¡¨å†…çš„ä¸€å¯¹é”®è¿›è¡Œè¿æ¥ã€‚\nIn this section, youâ€™ll learn about the two types of key and see examples of both in the datasets of the nycflights13 package.\nåœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸¤ç§ç±»å‹çš„é”®ï¼Œå¹¶åœ¨ nycflights13 åŒ…çš„æ•°æ®é›†ä¸­çœ‹åˆ°è¿™ä¸¤ç§é”®çš„ç¤ºä¾‹ã€‚\nYouâ€™ll also learn how to check that your keys are valid, and what to do if your table lacks a key.\nä½ è¿˜å°†å­¦ä¹ å¦‚ä½•æ£€æŸ¥ä½ çš„é”®æ˜¯å¦æœ‰æ•ˆï¼Œä»¥åŠå½“ä½ çš„è¡¨ç¼ºå°‘é”®æ—¶è¯¥æ€ä¹ˆåšã€‚\n\n19.2.1 Primary and foreign keys\nEvery join involves a pair of keys: a primary key and a foreign key.\næ¯ä¸ªè¿æ¥éƒ½æ¶‰åŠä¸€å¯¹é”®ï¼šä¸»é”® (primary key) å’Œå¤–é”® (foreign key)ã€‚\nA primary key is a variable or set of variables that uniquely identifies each observation.ä¸»é”® (primary key) æ˜¯ä¸€ä¸ªæˆ–ä¸€ç»„å”¯ä¸€æ ‡è¯†æ¯ä¸ªè§‚æµ‹å€¼çš„å˜é‡ã€‚\nWhen more than one variable is needed, the key is called a compound key. For example, in nycflights13:\nå½“éœ€è¦å¤šä¸ªå˜é‡æ—¶ï¼Œè¯¥é”®ç§°ä¸º å¤åˆé”® (compound key)ã€‚ä¾‹å¦‚ï¼Œåœ¨ nycflights13 ä¸­ï¼š\n\n\nairlines records two pieces of data about each airline: its carrier code and its full name. You can identify an airline with its two letter carrier code, making carrier the primary key.airlines è®°å½•äº†æ¯å®¶èˆªç©ºå…¬å¸çš„ä¸¤éƒ¨åˆ†æ•°æ®ï¼šå…¶æ‰¿è¿äººä»£ç  (carrier code) å’Œå…¶å…¨åã€‚ä½ å¯ä»¥ç”¨å…¶ä¸¤ä½å­—æ¯çš„æ‰¿è¿äººä»£ç æ¥è¯†åˆ«ä¸€å®¶èˆªç©ºå…¬å¸ï¼Œå› æ­¤ carrier æ˜¯ä¸»é”®ã€‚\n\nairlines\n#&gt; # A tibble: 16 Ã— 2\n#&gt;   carrier name                    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                   \n#&gt; 1 9E      Endeavor Air Inc.       \n#&gt; 2 AA      American Airlines Inc.  \n#&gt; 3 AS      Alaska Airlines Inc.    \n#&gt; 4 B6      JetBlue Airways         \n#&gt; 5 DL      Delta Air Lines Inc.    \n#&gt; 6 EV      ExpressJet Airlines Inc.\n#&gt; # â„¹ 10 more rows\n\n\n\nairports records data about each airport. You can identify each airport by its three letter airport code, making faa the primary key.airports è®°å½•äº†æ¯ä¸ªæœºåœºçš„æ•°æ®ã€‚ä½ å¯ä»¥ç”¨å…¶ä¸‰ä½å­—æ¯çš„æœºåœºä»£ç æ¥è¯†åˆ«æ¯ä¸ªæœºåœºï¼Œå› æ­¤ faa æ˜¯ä¸»é”®ã€‚\n\nairports\n#&gt; # A tibble: 1,458 Ã— 8\n#&gt;   faa   name                            lat   lon   alt    tz dst  \n#&gt;   &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A    \n#&gt; 2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A    \n#&gt; 3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A    \n#&gt; 4 06N   Randall Airport                41.4 -74.4   523    -5 A    \n#&gt; 5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A    \n#&gt; 6 0A9   Elizabethton Municipal Airpoâ€¦  36.4 -82.2  1593    -5 A    \n#&gt; # â„¹ 1,452 more rows\n#&gt; # â„¹ 1 more variable: tzone &lt;chr&gt;\n\n\n\nplanes records data about each plane. You can identify a plane by its tail number, making tailnum the primary key.planes è®°å½•äº†æ¯æ¶é£æœºçš„æ•°æ®ã€‚ä½ å¯ä»¥ç”¨å…¶å°¾å· (tail number) æ¥è¯†åˆ«ä¸€æ¶é£æœºï¼Œå› æ­¤ tailnum æ˜¯ä¸»é”®ã€‚\n\nplanes\n#&gt; # A tibble: 3,322 Ã— 9\n#&gt;   tailnum  year type              manufacturer    model     engines\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 N10156   2004 Fixed wing multiâ€¦ EMBRAER         EMB-145XR       2\n#&gt; 2 N102UW   1998 Fixed wing multiâ€¦ AIRBUS INDUSTRâ€¦ A320-214        2\n#&gt; 3 N103US   1999 Fixed wing multiâ€¦ AIRBUS INDUSTRâ€¦ A320-214        2\n#&gt; 4 N104UW   1999 Fixed wing multiâ€¦ AIRBUS INDUSTRâ€¦ A320-214        2\n#&gt; 5 N10575   2002 Fixed wing multiâ€¦ EMBRAER         EMB-145LR       2\n#&gt; 6 N105UW   1999 Fixed wing multiâ€¦ AIRBUS INDUSTRâ€¦ A320-214        2\n#&gt; # â„¹ 3,316 more rows\n#&gt; # â„¹ 3 more variables: seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\n\n\nweather records data about the weather at the origin airports. You can identify each observation by the combination of location and time, making origin and time_hour the compound primary key.weather è®°å½•äº†å§‹å‘æœºåœºçš„å¤©æ°”æ•°æ®ã€‚ä½ å¯ä»¥é€šè¿‡ä½ç½®å’Œæ—¶é—´çš„ç»„åˆæ¥è¯†åˆ«æ¯ä¸ªè§‚æµ‹å€¼ï¼Œå› æ­¤ origin å’Œ time_hour æ˜¯å¤åˆä¸»é”®ã€‚\n\nweather\n#&gt; # A tibble: 26,115 Ã— 15\n#&gt;   origin  year month   day  hour  temp  dewp humid wind_dir\n#&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 EWR     2013     1     1     1  39.0  26.1  59.4      270\n#&gt; 2 EWR     2013     1     1     2  39.0  27.0  61.6      250\n#&gt; 3 EWR     2013     1     1     3  39.0  28.0  64.4      240\n#&gt; 4 EWR     2013     1     1     4  39.9  28.0  62.2      250\n#&gt; 5 EWR     2013     1     1     5  39.0  28.0  64.4      260\n#&gt; 6 EWR     2013     1     1     6  37.9  28.0  67.2      240\n#&gt; # â„¹ 26,109 more rows\n#&gt; # â„¹ 6 more variables: wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, â€¦\n\n\n\nA foreign key is a variable (or set of variables) that corresponds to a primary key in another table.å¤–é”® (foreign key) æ˜¯ä¸€ä¸ªï¼ˆæˆ–ä¸€ç»„ï¼‰ä¸å¦ä¸€ä¸ªè¡¨ä¸­çš„ä¸»é”®ç›¸å¯¹åº”çš„å˜é‡ã€‚\nFor example:\nä¾‹å¦‚ï¼š\n\nflights$tailnum is a foreign key that corresponds to the primary key planes$tailnum.flights$tailnum æ˜¯ä¸€ä¸ªå¤–é”®ï¼Œå®ƒå¯¹åº”äºä¸»é”® planes$tailnumã€‚\nflights$carrier is a foreign key that corresponds to the primary key airlines$carrier.flights$carrier æ˜¯ä¸€ä¸ªå¤–é”®ï¼Œå®ƒå¯¹åº”äºä¸»é”® airlines$carrierã€‚\nflights$origin is a foreign key that corresponds to the primary key airports$faa.flights$origin æ˜¯ä¸€ä¸ªå¤–é”®ï¼Œå®ƒå¯¹åº”äºä¸»é”® airports$faaã€‚\nflights$dest is a foreign key that corresponds to the primary key airports$faa.flights$dest æ˜¯ä¸€ä¸ªå¤–é”®ï¼Œå®ƒå¯¹åº”äºä¸»é”® airports$faaã€‚\nflights$origin-flights$time_hour is a compound foreign key that corresponds to the compound primary key weather$origin-weather$time_hour.flights$origin-flights$time_hour æ˜¯ä¸€ä¸ªå¤åˆå¤–é”®ï¼Œå®ƒå¯¹åº”äºå¤åˆä¸»é”® weather$origin-weather$time_hourã€‚\n\nThese relationships are summarized visually in FigureÂ 19.1.\nè¿™äº›å…³ç³»åœ¨ FigureÂ 19.1 ä¸­è¿›è¡Œäº†å¯è§†åŒ–æ€»ç»“ã€‚\n\n\n\n\n\n\n\nFigureÂ 19.1: Connections between all five data frames in the nycflights13 package. Variables making up a primary key are colored grey, and are connected to their corresponding foreign keys with arrows.\n\n\n\n\nYouâ€™ll notice a nice feature in the design of these keys: the primary and foreign keys almost always have the same names, which, as youâ€™ll see shortly, will make your joining life much easier.\nä½ ä¼šæ³¨æ„åˆ°è¿™äº›é”®çš„è®¾è®¡ä¸­æœ‰ä¸€ä¸ªå¾ˆå¥½çš„ç‰¹æ€§ï¼šä¸»é”®å’Œå¤–é”®å‡ ä¹æ€»æ˜¯æœ‰ç›¸åŒçš„åç§°ï¼Œæ­£å¦‚ä½ å¾ˆå¿«å°±ä¼šçœ‹åˆ°çš„ï¼Œè¿™å°†ä½¿ä½ çš„è¿æ¥å·¥ä½œå˜å¾—å®¹æ˜“å¾—å¤šã€‚\nItâ€™s also worth noting the opposite relationship: almost every variable name used in multiple tables has the same meaning in each place.\nåŒæ ·å€¼å¾—æ³¨æ„çš„æ˜¯ç›¸åçš„å…³ç³»ï¼šå‡ ä¹æ¯ä¸ªåœ¨å¤šä¸ªè¡¨ä¸­ä½¿ç”¨çš„å˜é‡ååœ¨æ¯ä¸ªåœ°æ–¹éƒ½æœ‰ç›¸åŒçš„å«ä¹‰ã€‚\nThereâ€™s only one exception: year means year of departure in flights and year manufactured in planes.\nåªæœ‰ä¸€ä¸ªä¾‹å¤–ï¼šyear åœ¨ flights ä¸­è¡¨ç¤ºèµ·é£å¹´ä»½ï¼Œåœ¨ planes ä¸­è¡¨ç¤ºåˆ¶é€ å¹´ä»½ã€‚\nThis will become important when we start actually joining tables together.\nå½“æˆ‘ä»¬å¼€å§‹å®é™…è¿æ¥è¡¨æ—¶ï¼Œè¿™ä¸€ç‚¹å°†å˜å¾—å¾ˆé‡è¦ã€‚\n\n19.2.2 Checking primary keys\nNow that that weâ€™ve identified the primary keys in each table, itâ€™s good practice to verify that they do indeed uniquely identify each observation.\næ—¢ç„¶æˆ‘ä»¬å·²ç»ç¡®å®šäº†æ¯ä¸ªè¡¨ä¸­çš„ä¸»é”®ï¼Œé‚£ä¹ˆéªŒè¯å®ƒä»¬ç¡®å®å”¯ä¸€åœ°æ ‡è¯†äº†æ¯ä¸ªè§‚æµ‹å€¼æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚\nOne way to do that is to count() the primary keys and look for entries where n is greater than one.\nä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ count() è®¡ç®—ä¸»é”®ï¼Œå¹¶æŸ¥æ‰¾ n å¤§äº 1 çš„æ¡ç›®ã€‚\nThis reveals that planes and weather both look good:\nè¿™è¡¨æ˜ planes å’Œ weather éƒ½çœ‹èµ·æ¥ä¸é”™ï¼š\n\nplanes |&gt; \n  count(tailnum) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 Ã— 2\n#&gt; # â„¹ 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt;\n\nweather |&gt; \n  count(time_hour, origin) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 Ã— 3\n#&gt; # â„¹ 3 variables: time_hour &lt;dttm&gt;, origin &lt;chr&gt;, n &lt;int&gt;\n\nYou should also check for missing values in your primary keys â€” if a value is missing then it canâ€™t identify an observation!\nä½ è¿˜åº”è¯¥æ£€æŸ¥ä¸»é”®ä¸­çš„ç¼ºå¤±å€¼â€”â€”å¦‚æœä¸€ä¸ªå€¼æ˜¯ç¼ºå¤±çš„ï¼Œé‚£ä¹ˆå®ƒå°±æ— æ³•è¯†åˆ«ä¸€ä¸ªè§‚æµ‹å€¼ï¼\n\nplanes |&gt; \n  filter(is.na(tailnum))\n#&gt; # A tibble: 0 Ã— 9\n#&gt; # â„¹ 9 variables: tailnum &lt;chr&gt;, year &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;,\n#&gt; #   model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\nweather |&gt; \n  filter(is.na(time_hour) | is.na(origin))\n#&gt; # A tibble: 0 Ã— 15\n#&gt; # â„¹ 15 variables: origin &lt;chr&gt;, year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;,\n#&gt; #   hour &lt;int&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;, humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;, â€¦\n\n\n19.2.3 Surrogate keys\nSo far we havenâ€™t talked about the primary key for flights.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰è®¨è®º flights çš„ä¸»é”®ã€‚\nItâ€™s not super important here, because there are no data frames that use it as a foreign key, but itâ€™s still useful to consider because itâ€™s easier to work with observations if we have some way to describe them to others.\nåœ¨è¿™é‡Œå®ƒä¸æ˜¯ç‰¹åˆ«é‡è¦ï¼Œå› ä¸ºæ²¡æœ‰æ•°æ®æ¡†ä½¿ç”¨å®ƒä½œä¸ºå¤–é”®ï¼Œä½†å®ƒä»ç„¶å€¼å¾—è€ƒè™‘ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬æœ‰æŸç§æ–¹å¼å‘ä»–äººæè¿°è§‚æµ‹å€¼ï¼Œå¤„ç†å®ƒä»¬ä¼šæ›´å®¹æ˜“ã€‚\nAfter a little thinking and experimentation, we determined that there are three variables that together uniquely identify each flight:\nç»è¿‡ä¸€ç•ªæ€è€ƒå’Œå®éªŒï¼Œæˆ‘ä»¬ç¡®å®šæœ‰ä¸‰ä¸ªå˜é‡å¯ä»¥å…±åŒå”¯ä¸€åœ°è¯†åˆ«æ¯ä¸ªèˆªç­ï¼š\n\nflights |&gt; \n  count(time_hour, carrier, flight) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 Ã— 4\n#&gt; # â„¹ 4 variables: time_hour &lt;dttm&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, n &lt;int&gt;\n\nDoes the absence of duplicates automatically make time_hour-carrier-flight a primary key?\næ²¡æœ‰é‡å¤å€¼æ˜¯å¦ä¼šè‡ªåŠ¨ä½¿ time_hour-carrier-flight æˆä¸ºä¸»é”®ï¼Ÿ\nItâ€™s certainly a good start, but it doesnâ€™t guarantee it.\nè¿™å½“ç„¶æ˜¯ä¸€ä¸ªå¥½çš„å¼€å§‹ï¼Œä½†å¹¶ä¸èƒ½ä¿è¯ã€‚\nFor example, are altitude and latitude a good primary key for airports?\nä¾‹å¦‚ï¼Œé«˜åº¦å’Œçº¬åº¦æ˜¯ airports çš„å¥½ä¸»é”®å—ï¼Ÿ\n\nairports |&gt;\n  count(alt, lat) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;     alt   lat     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    13  40.6     2\n\nIdentifying an airport by its altitude and latitude is clearly a bad idea, and in general itâ€™s not possible to know from the data alone whether or not a combination of variables makes a good a primary key.\né€šè¿‡é«˜åº¦å’Œçº¬åº¦æ¥è¯†åˆ«ä¸€ä¸ªæœºåœºæ˜¾ç„¶æ˜¯ä¸€ä¸ªåä¸»æ„ï¼Œè€Œä¸”é€šå¸¸æ¥è¯´ï¼Œä»…ä»æ•°æ®æœ¬èº«æ— æ³•åˆ¤æ–­ä¸€ä¸ªå˜é‡ç»„åˆæ˜¯å¦èƒ½æ„æˆä¸€ä¸ªå¥½çš„ä¸»é”®ã€‚\nBut for flights, the combination of time_hour, carrier, and flight seems reasonable because it would be really confusing for an airline and its customers if there were multiple flights with the same flight number in the air at the same time.\nä½†å¯¹äºèˆªç­æ¥è¯´ï¼Œtime_hourã€carrier å’Œ flight çš„ç»„åˆä¼¼ä¹æ˜¯åˆç†çš„ï¼Œå› ä¸ºå¦‚æœåŒä¸€æ—¶é—´æœ‰å¤šæ¶ç›¸åŒèˆªç­å·çš„é£æœºåœ¨ç©ºä¸­ï¼Œå¯¹èˆªç©ºå…¬å¸åŠå…¶ä¹˜å®¢æ¥è¯´ä¼šéå¸¸æ··ä¹±ã€‚\nThat said, we might be better off introducing a simple numeric surrogate key using the row number:\nè¯è™½å¦‚æ­¤ï¼Œæˆ‘ä»¬æœ€å¥½è¿˜æ˜¯ä½¿ç”¨è¡Œå·å¼•å…¥ä¸€ä¸ªç®€å•çš„æ•°å­—ä»£ç†é”® (surrogate key)ï¼š\n\nflights2 &lt;- flights |&gt; \n  mutate(id = row_number(), .before = 1)\nflights2\n#&gt; # A tibble: 336,776 Ã— 20\n#&gt;      id  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1     1  2013     1     1      517            515         2      830\n#&gt; 2     2  2013     1     1      533            529         4      850\n#&gt; 3     3  2013     1     1      542            540         2      923\n#&gt; 4     4  2013     1     1      544            545        -1     1004\n#&gt; 5     5  2013     1     1      554            600        -6      812\n#&gt; 6     6  2013     1     1      554            558        -4      740\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, â€¦\n\nSurrogate keys can be particularly useful when communicating to other humans: itâ€™s much easier to tell someone to take a look at flight 2001 than to say look at UA430 which departed 9am 2013-01-03.\nä»£ç†é”®åœ¨ä¸äººäº¤æµæ—¶ç‰¹åˆ«æœ‰ç”¨ï¼šå‘Šè¯‰åˆ«äººæŸ¥çœ‹ 2001 å·èˆªç­æ¯”è¯´æŸ¥çœ‹ 2013 å¹´ 1 æœˆ 3 æ—¥ä¸Šåˆ 9 ç‚¹èµ·é£çš„ UA430 èˆªç­è¦å®¹æ˜“å¾—å¤šã€‚\n\n19.2.4 Exercises\n\nWe forgot to draw the relationship between weather and airports in FigureÂ 19.1. What is the relationship and how should it appear in the diagram?\nweather only contains information for the three origin airports in NYC. If it contained weather records for all airports in the USA, what additional connection would it make to flights?\nThe year, month, day, hour, and origin variables almost form a compound key for weather, but thereâ€™s one hour that has duplicate observations. Can you figure out whatâ€™s special about that hour?\nWe know that some days of the year are special and fewer people than usual fly on them (e.g., Christmas eve and Christmas day). How might you represent that data as a data frame? What would be the primary key? How would it connect to the existing data frames?\nDraw a diagram illustrating the connections between the Batting, People, and Salaries data frames in the Lahman package. Draw another diagram that shows the relationship between People, Managers, AwardsManagers. How would you characterize the relationship between the Batting, Pitching, and Fielding data frames?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-mutating-joins",
    "href": "joins.html#sec-mutating-joins",
    "title": "19Â  Joins",
    "section": "\n19.3 Basic joins",
    "text": "19.3 Basic joins\nNow that you understand how data frames are connected via keys, we can start using joins to better understand the flights dataset.\næ—¢ç„¶ä½ å·²ç»äº†è§£äº†æ•°æ®æ¡†æ˜¯å¦‚ä½•é€šè¿‡é”®è¿æ¥çš„ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹ä½¿ç”¨è¿æ¥æ¥æ›´å¥½åœ°ç†è§£ flights æ•°æ®é›†äº†ã€‚\ndplyr provides six join functions: left_join(), inner_join(), right_join(), full_join(), semi_join(), and anti_join(). They all have the same interface: they take a pair of data frames (x and y) and return a data frame.\ndplyr æä¾›äº†å…­ä¸ªè¿æ¥å‡½æ•°ï¼šleft_join()ã€inner_join()ã€right_join()ã€full_join()ã€semi_join() å’Œ anti_join()ã€‚å®ƒä»¬éƒ½å…·æœ‰ç›¸åŒçš„æ¥å£ï¼šæ¥æ”¶ä¸€å¯¹æ•°æ®æ¡† (x å’Œ y) å¹¶è¿”å›ä¸€ä¸ªæ•°æ®æ¡†ã€‚\nThe order of the rows and columns in the output is primarily determined by x.\nè¾“å‡ºä¸­è¡Œå’Œåˆ—çš„é¡ºåºä¸»è¦ç”± x å†³å®šã€‚\nIn this section, youâ€™ll learn how to use one mutating join, left_join(), and two filtering joins, semi_join() and anti_join().\nåœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ä¸€ä¸ªä¿®æ”¹è¿æ¥ (left_join()) å’Œä¸¤ä¸ªè¿‡æ»¤è¿æ¥ (semi_join() å’Œ anti_join())ã€‚\nIn the next section, youâ€™ll learn exactly how these functions work, and about the remaining inner_join(), right_join() and full_join().\nåœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œä½ å°†ç¡®åˆ‡åœ°å­¦ä¹ è¿™äº›å‡½æ•°çš„å·¥ä½œåŸç†ï¼Œä»¥åŠå‰©ä¸‹çš„ inner_join()ã€right_join() å’Œ full_join()ã€‚\n\n19.3.1 Mutating joins\nA mutating join allows you to combine variables from two data frames: it first matches observations by their keys, then copies across variables from one data frame to the other.ä¿®æ”¹è¿æ¥ (mutating join) å…è®¸ä½ åˆå¹¶æ¥è‡ªä¸¤ä¸ªæ•°æ®æ¡†çš„å˜é‡ï¼šå®ƒé¦–å…ˆé€šè¿‡å®ƒä»¬çš„é”®åŒ¹é…è§‚æµ‹å€¼ï¼Œç„¶åå°†å˜é‡ä»ä¸€ä¸ªæ•°æ®æ¡†å¤åˆ¶åˆ°å¦ä¸€ä¸ªã€‚\nLike mutate(), the join functions add variables to the right, so if your dataset has many variables, you wonâ€™t see the new ones.\nä¸ mutate() ç±»ä¼¼ï¼Œè¿æ¥å‡½æ•°ä¼šå°†å˜é‡æ·»åŠ åˆ°å³ä¾§ï¼Œæ‰€ä»¥å¦‚æœä½ çš„æ•°æ®é›†æœ‰å¾ˆå¤šå˜é‡ï¼Œä½ å°†çœ‹ä¸åˆ°æ–°æ·»åŠ çš„å˜é‡ã€‚\nFor these examples, weâ€™ll make it easier to see whatâ€™s going on by creating a narrower dataset with just six variables1:\nå¯¹äºè¿™äº›ä¾‹å­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåªåŒ…å«å…­ä¸ªå˜é‡çš„æ›´çª„çš„æ•°æ®é›†ï¼Œä»¥ä¾¿æ›´å®¹æ˜“åœ°çœ‹æ¸…æ¥šå‘ç”Ÿäº†ä»€ä¹ˆ1ï¼š\n\nflights2 &lt;- flights |&gt; \n  select(year, time_hour, origin, dest, tailnum, carrier)\nflights2\n#&gt; # A tibble: 336,776 Ã— 6\n#&gt;    year time_hour           origin dest  tailnum carrier\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA     \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA     \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA     \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL     \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA     \n#&gt; # â„¹ 336,770 more rows\n\nThere are four types of mutating join, but thereâ€™s one that youâ€™ll use almost all of the time: left_join().\næœ‰å››ç§ç±»å‹çš„ä¿®æ”¹è¿æ¥ï¼Œä½†æœ‰ä¸€ç§ä½ å‡ ä¹ä¼šä¸€ç›´ä½¿ç”¨ï¼šleft_join()ã€‚\nItâ€™s special because the output will always have the same rows as x, the data frame youâ€™re joining to2.\nå®ƒä¹‹æ‰€ä»¥ç‰¹æ®Šï¼Œæ˜¯å› ä¸ºè¾“å‡ºå°†å§‹ç»ˆä¸ä½ æ‰€è¿æ¥çš„æ•°æ®æ¡† x å…·æœ‰ç›¸åŒçš„è¡Œ2ã€‚\nThe primary use of left_join() is to add in additional metadata.left_join() çš„ä¸»è¦ç”¨é€”æ˜¯æ·»åŠ é¢å¤–çš„å…ƒæ•°æ® (metadata)ã€‚\nFor example, we can use left_join() to add the full airline name to the flights2 data:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ left_join() å°†å®Œæ•´çš„èˆªç©ºå…¬å¸åç§°æ·»åŠ åˆ° flights2 æ•°æ®ä¸­ï¼š\n\nflights2 |&gt;\n  left_join(airlines)\n#&gt; Joining with `by = join_by(carrier)`\n#&gt; # A tibble: 336,776 Ã— 7\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines Inâ€¦\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines Inâ€¦\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines Iâ€¦\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines Inâ€¦\n#&gt; # â„¹ 336,770 more rows\n\nOr we could find out the temperature and wind speed when each plane departed:\næˆ–è€…æˆ‘ä»¬å¯ä»¥æ‰¾å‡ºæ¯æ¶é£æœºèµ·é£æ—¶çš„æ¸©åº¦å’Œé£é€Ÿï¼š\n\nflights2 |&gt; \n  left_join(weather |&gt; select(origin, time_hour, temp, wind_speed))\n#&gt; Joining with `by = join_by(time_hour, origin)`\n#&gt; # A tibble: 336,776 Ã— 8\n#&gt;    year time_hour           origin dest  tailnum carrier  temp wind_speed\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA       39.0       12.7\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA       39.9       15.0\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA       39.0       15.0\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6       39.0       15.0\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL       39.9       16.1\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA       39.0       12.7\n#&gt; # â„¹ 336,770 more rows\n\nOr what size of plane was flying:\næˆ–è€…å½“æ—¶é£çš„æ˜¯ä»€ä¹ˆå°ºå¯¸çš„é£æœºï¼š\n\nflights2 |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 336,776 Ã— 9\n#&gt;    year time_hour           origin dest  tailnum carrier type                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Fixed wing multi enâ€¦\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      Fixed wing multi enâ€¦\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Fixed wing multi enâ€¦\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      Fixed wing multi enâ€¦\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Fixed wing multi enâ€¦\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Fixed wing multi enâ€¦\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 2 more variables: engines &lt;int&gt;, seats &lt;int&gt;\n\nWhen left_join() fails to find a match for a row in x, it fills in the new variables with missing values.\nå½“ left_join() æ— æ³•ä¸º x ä¸­çš„æŸä¸€è¡Œæ‰¾åˆ°åŒ¹é…é¡¹æ—¶ï¼Œå®ƒä¼šç”¨ç¼ºå¤±å€¼å¡«å……æ–°å˜é‡ã€‚\nFor example, thereâ€™s no information about the plane with tail number N3ALAA so the type, engines, and seats will be missing:\nä¾‹å¦‚ï¼Œæ²¡æœ‰å…³äºå°¾å·ä¸º N3ALAA çš„é£æœºçš„ä¿¡æ¯ï¼Œæ‰€ä»¥ typeã€engines å’Œ seats å°†ä¼šæ˜¯ç¼ºå¤±å€¼ï¼š\n\nflights2 |&gt; \n  filter(tailnum == \"N3ALAA\") |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 63 Ã— 9\n#&gt;    year time_hour           origin dest  tailnum carrier type  engines seats\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 2  2013 2013-01-02 18:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 3  2013 2013-01-03 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 4  2013 2013-01-07 19:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 5  2013 2013-01-08 17:00:00 JFK    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 6  2013 2013-01-16 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; # â„¹ 57 more rows\n\nWeâ€™ll come back to this problem a few times in the rest of the chapter.\næˆ‘ä»¬å°†åœ¨æœ¬ç« çš„å…¶ä½™éƒ¨åˆ†å‡ æ¬¡å›åˆ°è¿™ä¸ªé—®é¢˜ã€‚\n\n19.3.2 Specifying join keys\nBy default, left_join() will use all variables that appear in both data frames as the join key, the so called natural join.\né»˜è®¤æƒ…å†µä¸‹ï¼Œleft_join() ä¼šå°†ä¸¤ä¸ªæ•°æ®æ¡†ä¸­éƒ½å‡ºç°çš„æ‰€æœ‰å˜é‡ç”¨ä½œè¿æ¥é”®ï¼Œè¿™è¢«ç§°ä¸º è‡ªç„¶ (natural) è¿æ¥ã€‚\nThis is a useful heuristic, but it doesnâ€™t always work.\nè¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„å¯å‘å¼æ–¹æ³•ï¼Œä½†å¹¶ä¸æ€»æ˜¯æœ‰æ•ˆã€‚\nFor example, what happens if we try to join flights2 with the complete planes dataset?\nä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•å°† flights2 ä¸å®Œæ•´çš„ planes æ•°æ®é›†è¿æ¥ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\n\nflights2 |&gt; \n  left_join(planes)\n#&gt; Joining with `by = join_by(year, tailnum)`\n#&gt; # A tibble: 336,776 Ã— 13\n#&gt;    year time_hour           origin dest  tailnum carrier type  manufacturer\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 5 more variables: model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, â€¦\n\nWe get a lot of missing matches because our join is trying to use tailnum and year as a compound key.\næˆ‘ä»¬å¾—åˆ°äº†å¾ˆå¤šç¼ºå¤±çš„åŒ¹é…ï¼Œå› ä¸ºæˆ‘ä»¬çš„è¿æ¥è¯•å›¾ä½¿ç”¨ tailnum å’Œ year ä½œä¸ºå¤åˆé”®ã€‚\nBoth flights and planes have a year column but they mean different things: flights$year is the year the flight occurred and planes$year is the year the plane was built.flights å’Œ planes éƒ½æœ‰ä¸€ä¸ª year åˆ—ï¼Œä½†å®ƒä»¬çš„å«ä¹‰ä¸åŒï¼šflights$year æ˜¯èˆªç­å‘ç”Ÿçš„å¹´ä»½ï¼Œè€Œ planes$year æ˜¯é£æœºåˆ¶é€ çš„å¹´ä»½ã€‚\nWe only want to join on tailnum so we need to provide an explicit specification with join_by():\næˆ‘ä»¬åªæƒ³åœ¨ tailnum ä¸Šè¿›è¡Œè¿æ¥ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä½¿ç”¨ join_by() æä¾›ä¸€ä¸ªæ˜ç¡®çš„è§„èŒƒï¼š\n\nflights2 |&gt; \n  left_join(planes, join_by(tailnum))\n#&gt; # A tibble: 336,776 Ã— 14\n#&gt;   year.x time_hour           origin dest  tailnum carrier year.y\n#&gt;    &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999\n#&gt; 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998\n#&gt; 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990\n#&gt; 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012\n#&gt; 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991\n#&gt; 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 7 more variables: type &lt;chr&gt;, manufacturer &lt;chr&gt;, model &lt;chr&gt;, â€¦\n\nNote that the year variables are disambiguated in the output with a suffix (year.x and year.y), which tells you whether the variable came from the x or y argument.\nè¯·æ³¨æ„ï¼Œyear å˜é‡åœ¨è¾“å‡ºä¸­é€šè¿‡åç¼€ï¼ˆyear.x å’Œ year.yï¼‰æ¥æ¶ˆé™¤æ­§ä¹‰ï¼Œè¿™å‘Šè¯‰æ‚¨å˜é‡æ˜¯æ¥è‡ª x å‚æ•°è¿˜æ˜¯ y å‚æ•°ã€‚\nYou can override the default suffixes with the suffix argument.\næ‚¨å¯ä»¥ä½¿ç”¨ suffix å‚æ•°è¦†ç›–é»˜è®¤åç¼€ã€‚\njoin_by(tailnum) is short for join_by(tailnum == tailnum).join_by(tailnum) æ˜¯ join_by(tailnum == tailnum) çš„ç®€å†™ã€‚\nItâ€™s important to know about this fuller form for two reasons.\näº†è§£è¿™ç§æ›´å®Œæ•´çš„å½¢å¼å¾ˆé‡è¦ï¼ŒåŸå› æœ‰äºŒã€‚\nFirstly, it describes the relationship between the two tables: the keys must be equal.\né¦–å…ˆï¼Œå®ƒæè¿°äº†ä¸¤ä¸ªè¡¨ä¹‹é—´çš„å…³ç³»ï¼šé”®å¿…é¡»ç›¸ç­‰ã€‚\nThatâ€™s why this type of join is often called an equi join.\nè¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™ç§ç±»å‹çš„è¿æ¥é€šå¸¸è¢«ç§°ä¸º ç­‰å€¼è¿æ¥ (equi join)ã€‚\nYouâ€™ll learn about non-equi joins in Section 19.5.\nä½ å°†åœ¨ Section 19.5 ä¸­å­¦ä¹ éç­‰å€¼è¿æ¥ã€‚\nSecondly, itâ€™s how you specify different join keys in each table.\nå…¶æ¬¡ï¼Œè¿™æ˜¯ä½ åœ¨æ¯ä¸ªè¡¨ä¸­æŒ‡å®šä¸åŒè¿æ¥é”®çš„æ–¹å¼ã€‚\nFor example, there are two ways to join the flight2 and airports table: either by dest or origin:\nä¾‹å¦‚ï¼Œæœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥è¿æ¥ flight2 å’Œ airports è¡¨ï¼šé€šè¿‡ dest æˆ– originï¼š\n\nflights2 |&gt; \n  left_join(airports, join_by(dest == faa))\n#&gt; # A tibble: 336,776 Ã— 13\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      George Bush Intercoâ€¦\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      George Bush Intercoâ€¦\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Miami Intl          \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;                \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Hartsfield Jackson â€¦\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Chicago Ohare Intl  \n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, â€¦\n\nflights2 |&gt; \n  left_join(airports, join_by(origin == faa))\n#&gt; # A tibble: 336,776 Ã— 13\n#&gt;    year time_hour           origin dest  tailnum carrier name               \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;              \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Newark Liberty Intl\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      La Guardia         \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      John F Kennedy Intl\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      John F Kennedy Intl\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      La Guardia         \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Newark Liberty Intl\n#&gt; # â„¹ 336,770 more rows\n#&gt; # â„¹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, â€¦\n\nIn older code you might see a different way of specifying the join keys, using a character vector:\nåœ¨æ—§çš„ä»£ç ä¸­ï¼Œä½ å¯èƒ½ä¼šçœ‹åˆ°ä¸€ç§ä¸åŒçš„æŒ‡å®šè¿æ¥é”®çš„æ–¹å¼ï¼Œå³ä½¿ç”¨å­—ç¬¦å‘é‡ï¼š\n\nby = \"x\" corresponds to join_by(x).by = \"x\" å¯¹åº”äº join_by(x)ã€‚\nby = c(\"a\" = \"x\") corresponds to join_by(a == x). by = c(&quot;a&quot; = &quot;x&quot;) å¯¹åº”äº join_by(a == x)ã€‚\n\nNow that it exists, we prefer join_by() since it provides a clearer and more flexible specification.\næ—¢ç„¶å®ƒå·²ç»å­˜åœ¨ï¼Œæˆ‘ä»¬æ›´å–œæ¬¢ join_by()ï¼Œå› ä¸ºå®ƒæä¾›äº†æ›´æ¸…æ™°ã€æ›´çµæ´»çš„è§„èŒƒã€‚\ninner_join(), right_join(), full_join() have the same interface as left_join().inner_join()ã€right_join()ã€full_join() ä¸ left_join() å…·æœ‰ç›¸åŒçš„æ¥å£ã€‚\nThe difference is which rows they keep: left join keeps all the rows in x, the right join keeps all rows in y, the full join keeps all rows in either x or y, and the inner join only keeps rows that occur in both x and y.\nåŒºåˆ«åœ¨äºå®ƒä»¬ä¿ç•™å“ªäº›è¡Œï¼šå·¦è¿æ¥ä¿ç•™ x ä¸­çš„æ‰€æœ‰è¡Œï¼Œå³è¿æ¥ä¿ç•™ y ä¸­çš„æ‰€æœ‰è¡Œï¼Œå…¨è¿æ¥ä¿ç•™ x æˆ– y ä¸­çš„æ‰€æœ‰è¡Œï¼Œè€Œå†…è¿æ¥åªä¿ç•™åŒæ—¶å‡ºç°åœ¨ x å’Œ y ä¸­çš„è¡Œã€‚\nWeâ€™ll come back to these in more detail later.\næˆ‘ä»¬ç¨åä¼šæ›´è¯¦ç»†åœ°è®¨è®ºè¿™äº›ã€‚\n\n19.3.3 Filtering joins\nAs you might guess the primary action of a filtering join is to filter the rows.\nä½ å¯èƒ½å·²ç»çŒœåˆ°ï¼Œè¿‡æ»¤è¿æ¥ (filtering join) çš„ä¸»è¦ä½œç”¨æ˜¯è¿‡æ»¤è¡Œã€‚\nThere are two types: semi-joins and anti-joins.\næœ‰ä¸¤ç§ç±»å‹ï¼šåŠè¿æ¥ (semi-joins) å’Œåè¿æ¥ (anti-joins)ã€‚\nSemi-joins keep all rows in x that have a match in y.åŠè¿æ¥ (Semi-joins) ä¿ç•™ x ä¸­æ‰€æœ‰åœ¨ y ä¸­æœ‰åŒ¹é…çš„è¡Œã€‚\nFor example, we could use a semi-join to filter the airports dataset to show just the origin airports:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠè¿æ¥æ¥è¿‡æ»¤ airports æ•°æ®é›†ï¼Œåªæ˜¾ç¤ºå§‹å‘æœºåœºï¼š\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == origin))\n#&gt; # A tibble: 3 Ã— 8\n#&gt;   faa   name                  lat   lon   alt    tz dst   tzone           \n#&gt;   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n#&gt; 1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York\n#&gt; 2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n#&gt; 3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York\n\nOr just the destinations:\næˆ–è€…åªæ˜¾ç¤ºç›®çš„åœ°ï¼š\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == dest))\n#&gt; # A tibble: 101 Ã— 8\n#&gt;   faa   name                     lat    lon   alt    tz dst   tzone          \n#&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          \n#&gt; 1 ABQ   Albuquerque Internatiâ€¦  35.0 -107.   5355    -7 A     America/Denver \n#&gt; 2 ACK   Nantucket Mem           41.3  -70.1    48    -5 A     America/New_Yoâ€¦\n#&gt; 3 ALB   Albany Intl             42.7  -73.8   285    -5 A     America/New_Yoâ€¦\n#&gt; 4 ANC   Ted Stevens Anchorageâ€¦  61.2 -150.    152    -9 A     America/Anchorâ€¦\n#&gt; 5 ATL   Hartsfield Jackson Atâ€¦  33.6  -84.4  1026    -5 A     America/New_Yoâ€¦\n#&gt; 6 AUS   Austin Bergstrom Intl   30.2  -97.7   542    -6 A     America/Chicago\n#&gt; # â„¹ 95 more rows\n\nAnti-joins are the opposite: they return all rows in x that donâ€™t have a match in y.åè¿æ¥ (Anti-joins) åˆ™ç›¸åï¼šå®ƒä»¬è¿”å› x ä¸­æ‰€æœ‰åœ¨ y ä¸­æ²¡æœ‰åŒ¹é…çš„è¡Œã€‚\nTheyâ€™re useful for finding missing values that are implicit in the data, the topic of Section 18.3.\nå®ƒä»¬å¯¹äºæŸ¥æ‰¾æ•°æ®ä¸­ éšå¼ (implicit) çš„ç¼ºå¤±å€¼å¾ˆæœ‰ç”¨ï¼Œè¿™æ˜¯ Section 18.3 çš„ä¸»é¢˜ã€‚\nImplicitly missing values donâ€™t show up as NAs but instead only exist as an absence.\néšå¼ç¼ºå¤±å€¼ä¸ä¼šæ˜¾ç¤ºä¸º NAï¼Œè€Œæ˜¯ä»…ä½œä¸ºä¸€ç§ç¼ºå¸­è€Œå­˜åœ¨ã€‚\nFor example, we can find rows that are missing from airports by looking for flights that donâ€™t have a matching destination airport:\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æŸ¥æ‰¾æ²¡æœ‰åŒ¹é…ç›®çš„åœ°æœºåœºçš„èˆªç­æ¥æ‰¾åˆ° airports ä¸­ç¼ºå¤±çš„è¡Œï¼š\n\nflights2 |&gt; \n  anti_join(airports, join_by(dest == faa)) |&gt; \n  distinct(dest)\n#&gt; # A tibble: 4 Ã— 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\nOr we can find which tailnums are missing from planes:\næˆ–è€…æˆ‘ä»¬å¯ä»¥æ‰¾å‡º planes ä¸­ç¼ºå°‘å“ªäº› tailnumï¼š\n\nflights2 |&gt;\n  anti_join(planes, join_by(tailnum)) |&gt; \n  distinct(tailnum)\n#&gt; # A tibble: 722 Ã— 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # â„¹ 716 more rows\n\n\n19.3.4 Exercises\n\nFind the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns?\n\nImagine youâ€™ve found the top 10 most popular destinations using this code:\n\ntop_dest &lt;- flights2 |&gt;\n  count(dest, sort = TRUE) |&gt;\n  head(10)\n\nHow can you find all flights to those destinations?\n\nDoes every departing flight have corresponding weather data for that hour?\nWhat do the tail numbers that donâ€™t have a matching record in planes have in common? (Hint: one variable explains ~90% of the problems.)\nAdd a column to planes that lists every carrier that has flown that plane. You might expect that thereâ€™s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools youâ€™ve learned in previous chapters.\nAdd the latitude and the longitude of the origin and destination airport to flights. Is it easier to rename the columns before or after the join?\n\nCompute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. Hereâ€™s an easy way to draw a map of the United States:\n\nairports |&gt;\n  semi_join(flights, join_by(faa == dest)) |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n    borders(\"state\") +\n    geom_point() +\n    coord_quickmap()\n\nYou might want to use the size or color of the points to display the average delay for each airport.\n\nWhat happened on June 13 2013? Draw a map of the delays, and then use Google to cross-reference with the weather.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#how-do-joins-work",
    "href": "joins.html#how-do-joins-work",
    "title": "19Â  Joins",
    "section": "\n19.4 How do joins work?",
    "text": "19.4 How do joins work?\nNow that youâ€™ve used joins a few times itâ€™s time to learn more about how they work, focusing on how each row in x matches rows in y.\næ—¢ç„¶ä½ å·²ç»å¤šæ¬¡ä½¿ç”¨è¿æ¥ï¼Œç°åœ¨æ˜¯æ—¶å€™æ›´æ·±å…¥åœ°äº†è§£å®ƒä»¬çš„å·¥ä½œåŸç†äº†ï¼Œé‡ç‚¹æ˜¯ x ä¸­çš„æ¯ä¸€è¡Œå¦‚ä½•ä¸ y ä¸­çš„è¡ŒåŒ¹é…ã€‚\nWeâ€™ll begin by introducing a visual representation of joins, using the simple tibbles defined below and shown in FigureÂ 19.2.\næˆ‘ä»¬å°†ä»ä»‹ç»è¿æ¥çš„å¯è§†åŒ–è¡¨ç¤ºå¼€å§‹ï¼Œä½¿ç”¨ä¸‹é¢å®šä¹‰çš„ç®€å• tibbleï¼Œå¹¶åœ¨ FigureÂ 19.2 ä¸­å±•ç¤ºã€‚\nIn these examples weâ€™ll use a single key called key and a single value column (val_x and val_y), but the ideas all generalize to multiple keys and multiple values.\nåœ¨è¿™äº›ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåä¸º key çš„å•ä¸ªé”®å’Œä¸€ä¸ªå•ä¸ªå€¼åˆ—ï¼ˆval_x å’Œ val_yï¼‰ï¼Œä½†è¿™äº›æ€æƒ³éƒ½å¯ä»¥æ¨å¹¿åˆ°å¤šä¸ªé”®å’Œå¤šä¸ªå€¼ã€‚\n\nx &lt;- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     3, \"x3\"\n)\ny &lt;- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     4, \"y3\"\n)\n\n\n\n\n\n\n\n\nFigureÂ 19.2: Graphical representation of two simple tables. The colored key columns map background color to key value. The grey columns represent the â€œvalueâ€ columns that are carried along for the ride.\n\n\n\n\nFigureÂ 19.3 introduces the foundation for our visual representation.FigureÂ 19.3 ä»‹ç»äº†æˆ‘ä»¬å¯è§†åŒ–è¡¨ç¤ºçš„åŸºç¡€ã€‚\nIt shows all potential matches between x and y as the intersection between lines drawn from each row of x and each row of y.\nå®ƒå°† x å’Œ y ä¹‹é—´çš„æ‰€æœ‰æ½œåœ¨åŒ¹é…æ˜¾ç¤ºä¸ºä» x çš„æ¯ä¸€è¡Œå’Œ y çš„æ¯ä¸€è¡Œç”»å‡ºçš„çº¿çš„äº¤ç‚¹ã€‚\nThe rows and columns in the output are primarily determined by x, so the x table is horizontal and lines up with the output.\nè¾“å‡ºä¸­çš„è¡Œå’Œåˆ—ä¸»è¦ç”± x å†³å®šï¼Œæ‰€ä»¥ x è¡¨æ˜¯æ°´å¹³çš„ï¼Œå¹¶ä¸è¾“å‡ºå¯¹é½ã€‚\n\n\n\n\n\n\n\nFigureÂ 19.3: To understand how joins work, itâ€™s useful to think of every possible match. Here we show that with a grid of connecting lines.\n\n\n\n\nTo describe a specific type of join, we indicate matches with dots.\nä¸ºäº†æè¿°ç‰¹å®šç±»å‹çš„è¿æ¥ï¼Œæˆ‘ä»¬ç”¨ç‚¹æ¥è¡¨ç¤ºåŒ¹é…ã€‚\nThe matches determine the rows in the output, a new data frame that contains the key, the x values, and the y values.\nåŒ¹é…é¡¹å†³å®šäº†è¾“å‡ºä¸­çš„è¡Œï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«é”®ã€x å€¼å’Œ y å€¼çš„æ–°æ•°æ®æ¡†ã€‚\nFor example, FigureÂ 19.4 shows an inner join, where rows are retained if and only if the keys are equal.\nä¾‹å¦‚ï¼ŒFigureÂ 19.4 å±•ç¤ºäº†ä¸€ä¸ªå†…è¿æ¥ï¼Œå…¶ä¸­åªæœ‰å½“é”®ç›¸ç­‰æ—¶ï¼Œè¡Œæ‰ä¼šè¢«ä¿ç•™ã€‚\n\n\n\n\n\n\n\nFigureÂ 19.4: An inner join matches each row in x to the row in y that has the same value of key. Each match becomes a row in the output.\n\n\n\n\nWe can apply the same principles to explain the outer joins, which keep observations that appear in at least one of the data frames.\næˆ‘ä»¬å¯ä»¥åº”ç”¨ç›¸åŒçš„åŸåˆ™æ¥è§£é‡Š å¤–è¿æ¥ (outer joins)ï¼Œå®ƒä¿ç•™å‡ºç°åœ¨è‡³å°‘ä¸€ä¸ªæ•°æ®æ¡†ä¸­çš„è§‚æµ‹å€¼ã€‚\nThese joins work by adding an additional â€œvirtualâ€ observation to each data frame.\nè¿™äº›è¿æ¥é€šè¿‡å‘æ¯ä¸ªæ•°æ®æ¡†æ·»åŠ ä¸€ä¸ªé¢å¤–çš„â€œè™šæ‹Ÿâ€è§‚æµ‹å€¼æ¥å·¥ä½œã€‚\nThis observation has a key that matches if no other key matches, and values filled with NA.\nè¯¥è§‚æµ‹å€¼æœ‰ä¸€ä¸ªåœ¨æ²¡æœ‰å…¶ä»–é”®åŒ¹é…æ—¶èƒ½å¤ŸåŒ¹é…çš„é”®ï¼Œä»¥åŠå¡«å……äº† NA çš„å€¼ã€‚\nThere are three types of outer joins:\næœ‰ä¸‰ç§ç±»å‹çš„å¤–è¿æ¥ï¼š\n\nA left join keeps all observations in x, FigureÂ 19.5. Every row of x is preserved in the output because it can fall back to matching a row of NAs in y.\n\nå·¦è¿æ¥ (left join) ä¿ç•™ x ä¸­çš„æ‰€æœ‰è§‚æµ‹å€¼ï¼Œè§ FigureÂ 19.5ã€‚ x çš„æ¯ä¸€è¡Œéƒ½åœ¨è¾“å‡ºä¸­è¢«ä¿ç•™ï¼Œå› ä¸ºå®ƒå¯ä»¥å›é€€åˆ°åŒ¹é… y ä¸­ä¸€è¡Œ NA å€¼ã€‚\n\n\n\n\n\n\n\nFigureÂ 19.5: A visual representation of the left join where every row in x appears in the output.\n\n\n\n\n\nA right join keeps all observations in y, FigureÂ 19.6. Every row of y is preserved in the output because it can fall back to matching a row of NAs in x. The output still matches x as much as possible; any extra rows from y are added to the end.\n\nå³è¿æ¥ (right join) ä¿ç•™ y ä¸­çš„æ‰€æœ‰è§‚æµ‹å€¼ï¼Œè§ FigureÂ 19.6ã€‚ y çš„æ¯ä¸€è¡Œéƒ½åœ¨è¾“å‡ºä¸­è¢«ä¿ç•™ï¼Œå› ä¸ºå®ƒå¯ä»¥å›é€€åˆ°åŒ¹é… x ä¸­ä¸€è¡Œ NA å€¼ã€‚è¾“å‡ºä»ç„¶å°½å¯èƒ½å¤šåœ°ä¸ x åŒ¹é…ï¼›æ¥è‡ª y çš„ä»»ä½•å¤šä½™çš„è¡Œéƒ½è¢«æ·»åŠ åˆ°æœ«å°¾ã€‚\n\n\n\n\n\n\n\nFigureÂ 19.6: A visual representation of the right join where every row of y appears in the output.\n\n\n\n\n\nA full join keeps all observations that appear in x or y, FigureÂ 19.7. Every row of x and y is included in the output because both x and y have a fall back row of NAs. Again, the output starts with all rows from x, followed by the remaining unmatched y rows.\n\nå…¨è¿æ¥ (full join) ä¿ç•™æ‰€æœ‰å‡ºç°åœ¨ x æˆ– y ä¸­çš„è§‚æµ‹å€¼ï¼Œè§ FigureÂ 19.7ã€‚ x å’Œ y çš„æ¯ä¸€è¡Œéƒ½åŒ…å«åœ¨è¾“å‡ºä¸­ï¼Œå› ä¸º x å’Œ y éƒ½æœ‰ä¸€ä¸ªç”± NA å€¼æ„æˆçš„å¤‡ç”¨è¡Œã€‚åŒæ ·ï¼Œè¾“å‡ºä»¥ x çš„æ‰€æœ‰è¡Œå¼€å§‹ï¼Œç„¶åæ˜¯å‰©ä½™çš„æœªåŒ¹é…çš„ y è¡Œã€‚\n\n\n\n\n\n\n\nFigureÂ 19.7: A visual representation of the full join where every row in x and y appears in the output.\n\n\n\n\n\n\nAnother way to show how the types of outer join differ is with a Venn diagram, as in FigureÂ 19.8.\nå¦ä¸€ç§å±•ç¤ºå¤–è¿æ¥ç±»å‹å·®å¼‚çš„æ–¹æ³•æ˜¯ä½¿ç”¨éŸ¦æ©å›¾ (Venn diagram)ï¼Œå¦‚ FigureÂ 19.8 æ‰€ç¤ºã€‚\nHowever, this is not a great representation because while it might jog your memory about which rows are preserved, it fails to illustrate whatâ€™s happening with the columns.\nç„¶è€Œï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è¡¨ç¤ºæ–¹æ³•ï¼Œå› ä¸ºå®ƒè™½ç„¶å¯èƒ½å¸®åŠ©ä½ è®°èµ·å“ªäº›è¡Œè¢«ä¿ç•™äº†ï¼Œä½†å´æ— æ³•è¯´æ˜åˆ—å‘ç”Ÿäº†ä»€ä¹ˆã€‚\n\n\n\n\n\n\n\nFigureÂ 19.8: Venn diagrams showing the difference between inner, left, right, and full joins.\n\n\n\n\nThe joins shown here are the so-called equi joins, where rows match if the keys are equal.\nè¿™é‡Œå±•ç¤ºçš„è¿æ¥æ˜¯æ‰€è°“çš„ ç­‰å€¼ è¿æ¥ (equi joins)ï¼Œå…¶ä¸­å¦‚æœé”®ç›¸ç­‰ï¼Œåˆ™è¡ŒåŒ¹é…ã€‚\nEqui joins are the most common type of join, so weâ€™ll typically omit the equi prefix, and just say â€œinner joinâ€ rather than â€œequi inner joinâ€.\nç­‰å€¼è¿æ¥æ˜¯æœ€å¸¸è§çš„è¿æ¥ç±»å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬é€šå¸¸ä¼šçœç•¥â€œç­‰å€¼â€è¿™ä¸ªå‰ç¼€ï¼Œåªè¯´â€œå†…è¿æ¥â€è€Œä¸æ˜¯â€œç­‰å€¼å†…è¿æ¥â€ã€‚\nWeâ€™ll come back to non-equi joins in Section 19.5.\næˆ‘ä»¬å°†åœ¨ Section 19.5 å›é¡¾éç­‰å€¼è¿æ¥ã€‚\n\n19.4.1 Row matching\nSo far weâ€™ve explored what happens if a row in x matches zero or one row in y.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»æ¢è®¨äº†å¦‚æœ x ä¸­çš„ä¸€è¡Œä¸ y ä¸­çš„é›¶è¡Œæˆ–ä¸€è¡ŒåŒ¹é…æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚\nWhat happens if it matches more than one row?\nå¦‚æœå®ƒåŒ¹é…å¤šäºä¸€è¡Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\nTo understand whatâ€™s going on letâ€™s first narrow our focus to the inner_join() and then draw a picture, FigureÂ 19.9.\nä¸ºäº†ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆï¼Œè®©æˆ‘ä»¬é¦–å…ˆå°†æ³¨æ„åŠ›é›†ä¸­åœ¨ inner_join() ä¸Šï¼Œç„¶åç”»ä¸€å¹…å›¾ï¼Œå³ FigureÂ 19.9ã€‚\n\n\n\n\n\n\n\nFigureÂ 19.9: The three ways a row in x can match. x1 matches one row in y, x2 matches two rows in y, x3 matches zero rows in y. Note that while there are three rows in x and three rows in the output, there isnâ€™t a direct correspondence between the rows.\n\n\n\n\nThere are three possible outcomes for a row in x:x ä¸­çš„ä¸€è¡Œæœ‰ä¸‰ç§å¯èƒ½çš„ç»“æœï¼š\n\nIf it doesnâ€™t match anything, itâ€™s dropped.\nå¦‚æœå®ƒä¸åŒ¹é…ä»»ä½•ä¸œè¥¿ï¼Œå®ƒå°±ä¼šè¢«ä¸¢å¼ƒã€‚\nIf it matches 1 row in y, itâ€™s preserved.\nå¦‚æœå®ƒä¸ y ä¸­çš„ 1 è¡ŒåŒ¹é…ï¼Œå®ƒå°†è¢«ä¿ç•™ã€‚\nIf it matches more than 1 row in y, itâ€™s duplicated once for each match.\nå¦‚æœå®ƒä¸ y ä¸­çš„å¤šäº 1 è¡ŒåŒ¹é…ï¼Œå®ƒå°†ä¸ºæ¯ä¸ªåŒ¹é…å¤åˆ¶ä¸€æ¬¡ã€‚\n\nIn principle, this means that thereâ€™s no guaranteed correspondence between the rows in the output and the rows in x, but in practice, this rarely causes problems.\nåŸåˆ™ä¸Šï¼Œè¿™æ„å‘³ç€è¾“å‡ºä¸­çš„è¡Œä¸ x ä¸­çš„è¡Œä¹‹é—´æ²¡æœ‰ä¿è¯çš„å¯¹åº”å…³ç³»ï¼Œä½†åœ¨å®è·µä¸­ï¼Œè¿™å¾ˆå°‘ä¼šå¼•èµ·é—®é¢˜ã€‚\nThere is, however, one particularly dangerous case which can cause a combinatorial explosion of rows.\nç„¶è€Œï¼Œæœ‰ä¸€ç§ç‰¹åˆ«å±é™©çš„æƒ…å†µï¼Œå¯èƒ½ä¼šå¯¼è‡´è¡Œçš„ç»„åˆçˆ†ç‚¸ã€‚\nImagine joining the following two tables:\næƒ³è±¡ä¸€ä¸‹è¿æ¥ä»¥ä¸‹ä¸¤ä¸ªè¡¨ï¼š\n\ndf1 &lt;- tibble(key = c(1, 2, 2), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 &lt;- tibble(key = c(1, 2, 2), val_y = c(\"y1\", \"y2\", \"y3\"))\n\nWhile the first row in df1 only matches one row in df2, the second and third rows both match two rows.\nè™½ç„¶ df1 ä¸­çš„ç¬¬ä¸€è¡ŒåªåŒ¹é… df2 ä¸­çš„ä¸€è¡Œï¼Œä½†ç¬¬äºŒè¡Œå’Œç¬¬ä¸‰è¡Œéƒ½åŒ¹é…ä¸¤è¡Œã€‚\nThis is sometimes called a many-to-many join, and will cause dplyr to emit a warning:\nè¿™æœ‰æ—¶è¢«ç§°ä¸ºå¤šå¯¹å¤šè¿æ¥ï¼Œå¹¶ä¸”ä¼šå¯¼è‡´ dplyr å‘å‡ºè­¦å‘Šï¼š\n\ndf1 |&gt; \n  inner_join(df2, join_by(key))\n#&gt; Warning in inner_join(df1, df2, join_by(key)): Detected an unexpected many-to-many relationship between `x` and `y`.\n#&gt; â„¹ Row 2 of `x` matches multiple rows in `y`.\n#&gt; â„¹ Row 2 of `y` matches multiple rows in `x`.\n#&gt; â„¹ If a many-to-many relationship is expected, set `relationship =\n#&gt;   \"many-to-many\"` to silence this warning.\n#&gt; # A tibble: 5 Ã— 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     2 x2    y3   \n#&gt; 4     2 x3    y2   \n#&gt; 5     2 x3    y3\n\nIf you are doing this deliberately, you can set relationship = \"many-to-many\", as the warning suggests.\nå¦‚æœä½ æ˜¯æ•…æ„è¿™æ ·åšçš„ï¼Œå¯ä»¥åƒè­¦å‘Šå»ºè®®çš„é‚£æ ·è®¾ç½® relationship = \"many-to-many\"ã€‚\n\n19.4.2 Filtering joins\nThe number of matches also determines the behavior of the filtering joins.\nåŒ¹é…çš„æ•°é‡ä¹Ÿå†³å®šäº†è¿‡æ»¤è¿æ¥çš„è¡Œä¸ºã€‚\nThe semi-join keeps rows in x that have one or more matches in y, as in FigureÂ 19.10.\nåŠè¿æ¥ (semi-join) ä¿ç•™ x ä¸­åœ¨ y ä¸­æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªåŒ¹é…çš„è¡Œï¼Œå¦‚ FigureÂ 19.10 æ‰€ç¤ºã€‚\nThe anti-join keeps rows in x that match zero rows in y, as in FigureÂ 19.11.\nåè¿æ¥ (anti-join) ä¿ç•™ x ä¸­ä¸ y ä¸­é›¶è¡ŒåŒ¹é…çš„è¡Œï¼Œå¦‚ FigureÂ 19.11 æ‰€ç¤ºã€‚\nIn both cases, only the existence of a match is important; it doesnâ€™t matter how many times it matches.\nåœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œåªæœ‰åŒ¹é…çš„å­˜åœ¨æ‰é‡è¦ï¼›å®ƒåŒ¹é…å¤šå°‘æ¬¡å¹¶ä¸é‡è¦ã€‚\nThis means that filtering joins never duplicate rows like mutating joins do.\nè¿™æ„å‘³ç€è¿‡æ»¤è¿æ¥ä»ä¸åƒä¿®æ”¹è¿æ¥é‚£æ ·å¤åˆ¶è¡Œã€‚\n\n\n\n\n\n\n\nFigureÂ 19.10: In a semi-join it only matters that there is a match; otherwise values in y donâ€™t affect the output.\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 19.11: An anti-join is the inverse of a semi-join, dropping rows from x that have a match in y.",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-non-equi-joins",
    "href": "joins.html#sec-non-equi-joins",
    "title": "19Â  Joins",
    "section": "\n19.5 Non-equi joins",
    "text": "19.5 Non-equi joins\nSo far youâ€™ve only seen equi joins, joins where the rows match if the x key equals the y key.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ åªçœ‹åˆ°äº†ç­‰å€¼è¿æ¥ï¼Œå³å½“ x é”®ç­‰äº y é”®æ—¶è¡ŒåŒ¹é…çš„è¿æ¥ã€‚\nNow weâ€™re going to relax that restriction and discuss other ways of determining if a pair of rows match.\nç°åœ¨æˆ‘ä»¬å°†æ”¾å®½è¿™ä¸ªé™åˆ¶ï¼Œè®¨è®ºå…¶ä»–ç¡®å®šä¸€å¯¹è¡Œæ˜¯å¦åŒ¹é…çš„æ–¹æ³•ã€‚\nBut before we can do that, we need to revisit a simplification we made above.\nä½†åœ¨æˆ‘ä»¬è¿™æ ·åšä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°å®¡è§†æˆ‘ä»¬ä¸Šé¢åšçš„ä¸€ä¸ªç®€åŒ–ã€‚\nIn equi joins the x keys and y are always equal, so we only need to show one in the output.\nåœ¨ç­‰å€¼è¿æ¥ä¸­ï¼Œx é”®å’Œ y é”®æ€»æ˜¯ç›¸ç­‰çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€è¦åœ¨è¾“å‡ºä¸­æ˜¾ç¤ºä¸€ä¸ªã€‚\nWe can request that dplyr keep both keys with keep = TRUE, leading to the code below and the re-drawn inner_join() in FigureÂ 19.12.\næˆ‘ä»¬å¯ä»¥è¯·æ±‚ dplyr ä½¿ç”¨ keep = TRUE æ¥ä¿ç•™ä¸¤ä¸ªé”®ï¼Œä»è€Œå¾—åˆ°ä¸‹é¢çš„ä»£ç å’Œ FigureÂ 19.12 ä¸­é‡æ–°ç»˜åˆ¶çš„ inner_join()ã€‚\n\nx |&gt; inner_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 2 Ã— 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2\n\n\n\n\n\n\n\n\nFigureÂ 19.12: An inner join showing both x and y keys in the output.\n\n\n\n\nWhen we move away from equi joins weâ€™ll always show the keys, because the key values will often be different.\nå½“æˆ‘ä»¬ä¸å†ä½¿ç”¨ç­‰å€¼è¿æ¥æ—¶ï¼Œæˆ‘ä»¬å°†å§‹ç»ˆæ˜¾ç¤ºé”®ï¼Œå› ä¸ºé”®å€¼é€šå¸¸ä¼šä¸åŒã€‚\nFor example, instead of matching only when the x$key and y$key are equal, we could match whenever the x$key is greater than or equal to the y$key, leading to FigureÂ 19.13.\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä¸åªåœ¨ x$key å’Œ y$key ç›¸ç­‰æ—¶è¿›è¡ŒåŒ¹é…ï¼Œè€Œæ˜¯åœ¨ x$key å¤§äºæˆ–ç­‰äº y$key æ—¶è¿›è¡ŒåŒ¹é…ï¼Œè¿™å¯¼è‡´äº† FigureÂ 19.13ã€‚\ndplyrâ€™s join functions understand this distinction equi and non-equi joins so will always show both keys when you perform a non-equi join.\ndplyr çš„è¿æ¥å‡½æ•°ç†è§£ç­‰å€¼è¿æ¥å’Œéç­‰å€¼è¿æ¥ä¹‹é—´çš„åŒºåˆ«ï¼Œå› æ­¤å½“ä½ æ‰§è¡Œéç­‰å€¼è¿æ¥æ—¶ï¼Œå®ƒæ€»æ˜¯ä¼šæ˜¾ç¤ºä¸¤ä¸ªé”®ã€‚\n\n\n\n\n\n\n\nFigureÂ 19.13: A non-equi join where the x key must be greater than or equal to the y key. Many rows generate multiple matches.\n\n\n\n\nNon-equi join isnâ€™t a particularly useful term because it only tells you what the join is not, not what it is. dplyr helps by identifying four particularly useful types of non-equi join:\néç­‰å€¼è¿æ¥ (Non-equi join) å¹¶ä¸æ˜¯ä¸€ä¸ªç‰¹åˆ«æœ‰ç”¨çš„æœ¯è¯­ï¼Œå› ä¸ºå®ƒåªå‘Šè¯‰ä½ è¿æ¥ä¸æ˜¯ä»€ä¹ˆï¼Œè€Œä¸æ˜¯å®ƒæ˜¯ä»€ä¹ˆã€‚dplyr é€šè¿‡è¯†åˆ«å››ç§ç‰¹åˆ«æœ‰ç”¨çš„éç­‰å€¼è¿æ¥ç±»å‹æ¥æä¾›å¸®åŠ©ï¼š\n\nCross joins match every pair of rows.äº¤å‰è¿æ¥ (Cross joins) åŒ¹é…æ¯ä¸€å¯¹è¡Œã€‚\nInequality joins use &lt;, &lt;=, &gt;, and &gt;= instead of ==.ä¸ç­‰è¿æ¥ (Inequality joins) ä½¿ç”¨ &lt;ã€&lt;=ã€&gt; å’Œ &gt;= ä»£æ›¿ ==ã€‚\nRolling joins are similar to inequality joins but only find the closest match.æ»šåŠ¨è¿æ¥ (Rolling joins) ç±»ä¼¼äºä¸ç­‰è¿æ¥ï¼Œä½†åªæŸ¥æ‰¾æœ€æ¥è¿‘çš„åŒ¹é…ã€‚\nOverlap joins are a special type of inequality join designed to work with ranges.é‡å è¿æ¥ (Overlap joins) æ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„ä¸ç­‰è¿æ¥ï¼Œæ—¨åœ¨å¤„ç†èŒƒå›´ã€‚\n\nEach of these is described in more detail in the following sections.\nä»¥ä¸‹å„èŠ‚å°†æ›´è¯¦ç»†åœ°æè¿°è¿™äº›å†…å®¹ã€‚\n\n19.5.1 Cross joins\nA cross join matches everything, as in FigureÂ 19.14, generating the Cartesian product of rows.\näº¤å‰è¿æ¥åŒ¹é…æ‰€æœ‰å†…å®¹ï¼Œå¦‚ FigureÂ 19.14 æ‰€ç¤ºï¼Œç”Ÿæˆè¡Œçš„ç¬›å¡å°”ç§¯ (Cartesian product)ã€‚\nThis means the output will have nrow(x) * nrow(y) rows.\nè¿™æ„å‘³ç€è¾“å‡ºå°†æœ‰ nrow(x) * nrow(y) è¡Œã€‚\n\n\n\n\n\n\n\nFigureÂ 19.14: A cross join matches each row in x with every row in y.\n\n\n\n\nCross joins are useful when generating permutations.\näº¤å‰è¿æ¥åœ¨ç”Ÿæˆæ’åˆ—æ—¶å¾ˆæœ‰ç”¨ã€‚\nFor example, the code below generates every possible pair of names.\nä¾‹å¦‚ï¼Œä¸‹é¢çš„ä»£ç ç”Ÿæˆäº†æ‰€æœ‰å¯èƒ½çš„å§“åå¯¹ã€‚\nSince weâ€™re joining df to itself, this is sometimes called a self-join.\nç”±äºæˆ‘ä»¬å°† df ä¸å…¶è‡ªèº«è¿æ¥ï¼Œè¿™æœ‰æ—¶è¢«ç§°ä¸º è‡ªè¿æ¥ (self-join)ã€‚\nCross joins use a different join function because thereâ€™s no distinction between inner/left/right/full when youâ€™re matching every row.\näº¤å‰è¿æ¥ä½¿ç”¨ä¸åŒçš„è¿æ¥å‡½æ•°ï¼Œå› ä¸ºå½“ä½ åŒ¹é…æ¯ä¸€è¡Œæ—¶ï¼Œå†…/å·¦/å³/å…¨è¿æ¥ä¹‹é—´æ²¡æœ‰åŒºåˆ«ã€‚\n\ndf &lt;- tibble(name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\ndf |&gt; cross_join(df)\n#&gt; # A tibble: 16 Ã— 2\n#&gt;   name.x name.y\n#&gt;   &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 John   John  \n#&gt; 2 John   Simon \n#&gt; 3 John   Tracy \n#&gt; 4 John   Max   \n#&gt; 5 Simon  John  \n#&gt; 6 Simon  Simon \n#&gt; # â„¹ 10 more rows\n\n\n19.5.2 Inequality joins\nInequality joins use &lt;, &lt;=, &gt;=, or &gt; to restrict the set of possible matches, as in FigureÂ 19.13 and FigureÂ 19.15.\nä¸ç­‰è¿æ¥ä½¿ç”¨ &lt;ã€&lt;=ã€&gt;= æˆ– &gt; æ¥é™åˆ¶å¯èƒ½çš„åŒ¹é…é›†åˆï¼Œå¦‚ FigureÂ 19.13 å’Œ FigureÂ 19.15 æ‰€ç¤ºã€‚\n\n\n\n\n\n\n\nFigureÂ 19.15: An inequality join where x is joined to y on rows where the key of x is less than the key of y. This makes a triangular shape in the top-left corner.\n\n\n\n\nInequality joins are extremely general, so general that itâ€™s hard to come up with meaningful specific use cases.\nä¸ç­‰è¿æ¥éå¸¸é€šç”¨ï¼Œä»¥è‡³äºå¾ˆéš¾æƒ³å‡ºæœ‰æ„ä¹‰çš„ç‰¹å®šç”¨ä¾‹ã€‚\nOne small useful technique is to use them to restrict the cross join so that instead of generating all permutations, we generate all combinations:\nä¸€ä¸ªæœ‰ç”¨çš„å°æŠ€å·§æ˜¯ä½¿ç”¨å®ƒä»¬æ¥é™åˆ¶äº¤å‰è¿æ¥ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¸æ˜¯ç”Ÿæˆæ‰€æœ‰æ’åˆ—ï¼Œè€Œæ˜¯ç”Ÿæˆæ‰€æœ‰ç»„åˆï¼š\n\ndf &lt;- tibble(id = 1:4, name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\n\ndf |&gt; inner_join(df, join_by(id &lt; id))\n#&gt; # A tibble: 6 Ã— 4\n#&gt;    id.x name.x  id.y name.y\n#&gt;   &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; \n#&gt; 1     1 John       2 Simon \n#&gt; 2     1 John       3 Tracy \n#&gt; 3     1 John       4 Max   \n#&gt; 4     2 Simon      3 Tracy \n#&gt; 5     2 Simon      4 Max   \n#&gt; 6     3 Tracy      4 Max\n\n\n19.5.3 Rolling joins\nRolling joins are a special type of inequality join where instead of getting every row that satisfies the inequality, you get just the closest row, as in FigureÂ 19.16.\næ»šåŠ¨è¿æ¥æ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„ä¸ç­‰è¿æ¥ï¼Œåœ¨è¿™ç§è¿æ¥ä¸­ï¼Œä½ ä¸æ˜¯å¾—åˆ°æ»¡è¶³ä¸ç­‰å¼çš„æ¯ä¸€è¡Œï¼Œè€Œåªæ˜¯å¾—åˆ°æœ€æ¥è¿‘çš„é‚£ä¸€è¡Œï¼Œå¦‚ FigureÂ 19.16 æ‰€ç¤ºã€‚\nYou can turn any inequality join into a rolling join by adding closest().\nä½ å¯ä»¥é€šè¿‡æ·»åŠ  closest() å°†ä»»ä½•ä¸ç­‰è¿æ¥è½¬æ¢ä¸ºæ»šåŠ¨è¿æ¥ã€‚\nFor example join_by(closest(x &lt;= y)) matches the smallest y thatâ€™s greater than or equal to x, and join_by(closest(x &gt; y)) matches the biggest y thatâ€™s less than x.\nä¾‹å¦‚ï¼Œjoin_by(closest(x &lt;= y)) åŒ¹é…å¤§äºæˆ–ç­‰äº x çš„æœ€å° yï¼Œè€Œ join_by(closest(x &gt; y)) åŒ¹é…å°äº x çš„æœ€å¤§ yã€‚\n\n\n\n\n\n\n\nFigureÂ 19.16: A rolling join is similar to a greater-than-or-equal inequality join but only matches the first value.\n\n\n\n\nRolling joins are particularly useful when you have two tables of dates that donâ€™t perfectly line up and you want to find (e.g.) the closest date in table 1 that comes before (or after) some date in table 2.\nå½“ä½ æ‹¥æœ‰ä¸¤ä¸ªæ—¥æœŸä¸å®Œå…¨å¯¹é½çš„è¡¨æ ¼ï¼Œå¹¶ä¸”æƒ³è¦æŸ¥æ‰¾ï¼ˆä¾‹å¦‚ï¼‰è¡¨ 1 ä¸­åœ¨è¡¨ 2 ä¸­æŸä¸ªæ—¥æœŸä¹‹å‰ï¼ˆæˆ–ä¹‹åï¼‰çš„æœ€æ¥è¿‘æ—¥æœŸæ—¶ï¼Œæ»šåŠ¨è¿æ¥ç‰¹åˆ«æœ‰ç”¨ã€‚\nFor example, imagine that youâ€™re in charge of the party planning commission for your office.\nä¾‹å¦‚ï¼Œå‡è®¾ä½ è´Ÿè´£åŠå…¬å®¤çš„æ´¾å¯¹ç­–åˆ’å§”å‘˜ä¼šã€‚\nYour company is rather cheap so instead of having individual parties, you only have a party once each quarter.\nä½ çš„å…¬å¸ç›¸å½“å°æ°”ï¼Œæ‰€ä»¥ä½ ä»¬æ¯ä¸ªå­£åº¦åªä¸¾åŠä¸€æ¬¡æ´¾å¯¹ï¼Œè€Œä¸æ˜¯ä¸¾åŠä¸ªäººæ´¾å¯¹ã€‚\nThe rules for determining when a party will be held are a little complex: parties are always on a Monday, you skip the first week of January since a lot of people are on holiday, and the first Monday of Q3 2022 is July 4, so that has to be pushed back a week.\nå†³å®šæ´¾å¯¹ä½•æ—¶ä¸¾è¡Œçš„è§„åˆ™æœ‰ç‚¹å¤æ‚ï¼šæ´¾å¯¹æ€»æ˜¯åœ¨æ˜ŸæœŸä¸€ï¼Œä¸€æœˆä»½çš„ç¬¬ä¸€å‘¨ä¼šè·³è¿‡ï¼Œå› ä¸ºå¾ˆå¤šäººéƒ½åœ¨åº¦å‡ï¼Œè€Œ 2022 å¹´ç¬¬ä¸‰å­£åº¦çš„ç¬¬ä¸€ä¸ªæ˜ŸæœŸä¸€æ˜¯ 7 æœˆ 4 æ—¥ï¼Œæ‰€ä»¥å¿…é¡»æ¨è¿Ÿä¸€å‘¨ã€‚\nThat leads to the following party days:\nè¿™å¯¼è‡´äº†ä»¥ä¸‹æ´¾å¯¹æ—¥æœŸï¼š\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\"))\n)\n\nNow imagine that you have a table of employee birthdays:\nç°åœ¨æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æœ‰ä¸€å¼ å‘˜å·¥ç”Ÿæ—¥è¡¨ï¼š\n\nset.seed(123)\nemployees &lt;- tibble(\n  name = sample(babynames::babynames$name, 100),\n  birthday = ymd(\"2022-01-01\") + (sample(365, 100, replace = TRUE) - 1)\n)\nemployees\n#&gt; # A tibble: 100 Ã— 2\n#&gt;   name     birthday  \n#&gt;   &lt;chr&gt;    &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22\n#&gt; 2 Orean    2022-06-26\n#&gt; 3 Kirstyn  2022-02-11\n#&gt; 4 Amparo   2022-11-11\n#&gt; 5 Belen    2022-03-25\n#&gt; 6 Rayshaun 2022-01-11\n#&gt; # â„¹ 94 more rows\n\nAnd for each employee we want to find the last party date that comes before (or on) their birthday.\nå¯¹äºæ¯ä½å‘˜å·¥ï¼Œæˆ‘ä»¬éƒ½æƒ³æ‰¾åˆ°åœ¨ä»–ä»¬ç”Ÿæ—¥ä¹‹å‰ï¼ˆæˆ–å½“å¤©ï¼‰çš„æœ€åä¸€ä¸ªæ´¾å¯¹æ—¥æœŸã€‚\nWe can express that with a rolling join:\næˆ‘ä»¬å¯ä»¥ç”¨æ»šåŠ¨è¿æ¥æ¥è¡¨è¾¾ï¼š\n\nemployees |&gt; \n  left_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 100 Ã— 4\n#&gt;   name     birthday       q party     \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10\n#&gt; 2 Orean    2022-06-26     2 2022-04-04\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03\n#&gt; 5 Belen    2022-03-25     1 2022-01-10\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10\n#&gt; # â„¹ 94 more rows\n\nThere is, however, one problem with this approach: the folks with birthdays before January 10 donâ€™t get a party:\nç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼š1 æœˆ 10 æ—¥ä¹‹å‰ç”Ÿæ—¥çš„äººæ²¡æœ‰æ´¾å¯¹ï¼š\n\nemployees |&gt; \n  anti_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 2 Ã— 2\n#&gt;   name   birthday  \n#&gt;   &lt;chr&gt;  &lt;date&gt;    \n#&gt; 1 Maks   2022-01-07\n#&gt; 2 Nalani 2022-01-04\n\nTo resolve that issue weâ€™ll need to tackle the problem a different way, with overlap joins.\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ç”¨ä¸€ç§ä¸åŒçš„æ–¹å¼æ¥å¤„ç†ï¼Œå³ä½¿ç”¨é‡å è¿æ¥ã€‚\n\n19.5.4 Overlap joins\nOverlap joins provide three helpers that use inequality joins to make it easier to work with intervals:\né‡å è¿æ¥æä¾›äº†ä¸‰ä¸ªä½¿ç”¨ä¸ç­‰è¿æ¥çš„è¾…åŠ©å‡½æ•°ï¼Œä½¿å¤„ç†åŒºé—´å˜å¾—æ›´å®¹æ˜“ï¼š\n\nbetween(x, y_lower, y_upper) is short for x &gt;= y_lower, x &lt;= y_upper.between(x, y_lower, y_upper) æ˜¯ x &gt;= y_lower, x &lt;= y_upper çš„ç®€å†™ã€‚\nwithin(x_lower, x_upper, y_lower, y_upper) is short for x_lower &gt;= y_lower, x_upper &lt;= y_upper.within(x_lower, x_upper, y_lower, y_upper) æ˜¯ x_lower &gt;= y_lower, x_upper &lt;= y_upper çš„ç®€å†™ã€‚\noverlaps(x_lower, x_upper, y_lower, y_upper) is short for x_lower &lt;= y_upper, x_upper &gt;= y_lower.overlaps(x_lower, x_upper, y_lower, y_upper) æ˜¯ x_lower &lt;= y_upper, x_upper &gt;= y_lower çš„ç®€å†™ã€‚\n\nLetâ€™s continue the birthday example to see how you might use them.\nè®©æˆ‘ä»¬ç»§ç»­çœ‹ç”Ÿæ—¥çš„ä¾‹å­ï¼Œçœ‹çœ‹ä½ å¯èƒ½ä¼šå¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚\nThereâ€™s one problem with the strategy we used above: thereâ€™s no party preceding the birthdays Jan 1-9.\næˆ‘ä»¬ä¸Šé¢ä½¿ç”¨çš„ç­–ç•¥æœ‰ä¸€ä¸ªé—®é¢˜ï¼š1 æœˆ 1 æ—¥è‡³ 9 æ—¥ç”Ÿæ—¥ä¹‹å‰æ²¡æœ‰æ´¾å¯¹ã€‚\nSo it might be better to be explicit about the date ranges that each party spans, and make a special case for those early birthdays:\næ‰€ä»¥æœ€å¥½æ˜ç¡®æ¯ä¸ªæ´¾å¯¹æ¶µç›–çš„æ—¥æœŸèŒƒå›´ï¼Œå¹¶ä¸ºé‚£äº›æ—©æ—©è¿‡ç”Ÿæ—¥çš„äººåšä¸€ä¸ªç‰¹ä¾‹ï¼š\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-11\", \"2022-10-02\", \"2022-12-31\"))\n)\nparties\n#&gt; # A tibble: 4 Ã— 4\n#&gt;       q party      start      end       \n#&gt;   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2     2 2022-04-04 2022-04-04 2022-07-11\n#&gt; 3     3 2022-07-11 2022-07-11 2022-10-02\n#&gt; 4     4 2022-10-03 2022-10-03 2022-12-31\n\nHadley is hopelessly bad at data entry so he also wanted to check that the party periods donâ€™t overlap.\nHadley åœ¨æ•°æ®å½•å…¥æ–¹é¢éå¸¸ç³Ÿç³•ï¼Œæ‰€ä»¥ä»–è¿˜æƒ³æ£€æŸ¥ä¸€ä¸‹æ´¾å¯¹æ—¶æ®µæ˜¯å¦é‡å ã€‚\nOne way to do this is by using a self-join to check if any start-end interval overlap with another:\nä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨è‡ªè¿æ¥æ¥æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¼€å§‹-ç»“æŸåŒºé—´ä¸å¦ä¸€ä¸ªåŒºé—´é‡å ï¼š\n\nparties |&gt; \n  inner_join(parties, join_by(overlaps(start, end, start, end), q &lt; q)) |&gt; \n  select(start.x, end.x, start.y, end.y)\n#&gt; # A tibble: 1 Ã— 4\n#&gt;   start.x    end.x      start.y    end.y     \n#&gt;   &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 2022-04-04 2022-07-11 2022-07-11 2022-10-02\n\nOoops, there is an overlap, so letâ€™s fix that problem and continue:\nå“å‘€ï¼Œæœ‰é‡å ï¼Œæˆ‘ä»¬æ¥è§£å†³è¿™ä¸ªé—®é¢˜ç„¶åç»§ç»­ï¼š\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-10\", \"2022-10-02\", \"2022-12-31\"))\n)\n\nNow we can match each employee to their party.\nç°åœ¨æˆ‘ä»¬å¯ä»¥å°†æ¯ä½å‘˜å·¥ä¸ä»–ä»¬çš„æ´¾å¯¹åŒ¹é…èµ·æ¥ã€‚\nThis is a good place to use unmatched = \"error\" because we want to quickly find out if any employees didnâ€™t get assigned a party.\nè¿™é‡Œå¾ˆé€‚åˆä½¿ç”¨ unmatched = \"error\"ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³å¿«é€Ÿæ‰¾å‡ºæ˜¯å¦æœ‰ä»»ä½•å‘˜å·¥æ²¡æœ‰è¢«åˆ†é…åˆ°æ´¾å¯¹ã€‚\n\nemployees |&gt; \n  inner_join(parties, join_by(between(birthday, start, end)), unmatched = \"error\")\n#&gt; # A tibble: 100 Ã— 6\n#&gt;   name     birthday       q party      start      end       \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2 Orean    2022-06-26     2 2022-04-04 2022-04-04 2022-07-10\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03 2022-10-03 2022-12-31\n#&gt; 5 Belen    2022-03-25     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; # â„¹ 94 more rows\n\n\n19.5.5 Exercises\n\n\nCan you explain whatâ€™s happening with the keys in this equi join? Why are they different?\n\nx |&gt; full_join(y, join_by(key == key))\n#&gt; # A tibble: 4 Ã— 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt; \n#&gt; 4     4 &lt;NA&gt;  y3\n\nx |&gt; full_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 4 Ã— 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2   \n#&gt; 3     3 x3       NA &lt;NA&gt; \n#&gt; 4    NA &lt;NA&gt;      4 y3\n\n\nWhen finding if any party period overlapped with another party period we used q &lt; q in the join_by()? Why? What happens if you remove this inequality?",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#summary",
    "href": "joins.html#summary",
    "title": "19Â  Joins",
    "section": "\n19.6 Summary",
    "text": "19.6 Summary\nIn this chapter, youâ€™ve learned how to use mutating and filtering joins to combine data from a pair of data frames.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ä¿®æ”¹è¿æ¥å’Œè¿‡æ»¤è¿æ¥æ¥åˆå¹¶æ¥è‡ªä¸€å¯¹æ•°æ®æ¡†çš„æ•°æ®ã€‚\nAlong the way you learned how to identify keys, and the difference between primary and foreign keys.\nåœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä½ å­¦ä¼šäº†å¦‚ä½•è¯†åˆ«é”®ï¼Œä»¥åŠä¸»é”®å’Œå¤–é”®ä¹‹é—´çš„åŒºåˆ«ã€‚\nYou also understand how joins work and how to figure out how many rows the output will have.\nä½ è¿˜äº†è§£äº†è¿æ¥çš„å·¥ä½œåŸç†ä»¥åŠå¦‚ä½•ç¡®å®šè¾“å‡ºå°†æœ‰å¤šå°‘è¡Œã€‚\nFinally, youâ€™ve gained a glimpse into the power of non-equi joins and seen a few interesting use cases.\næœ€åï¼Œä½ å¯¹éç­‰å€¼è¿æ¥çš„å¼ºå¤§åŠŸèƒ½æœ‰äº†åˆæ­¥çš„äº†è§£ï¼Œå¹¶çœ‹åˆ°äº†ä¸€äº›æœ‰è¶£çš„ç”¨ä¾‹ã€‚\nThis chapter concludes the â€œTransformâ€ part of the book where the focus was on the tools you could use with individual columns and tibbles.\næœ¬ç« ç»“æŸäº†æœ¬ä¹¦çš„â€œè½¬æ¢â€éƒ¨åˆ†ï¼Œè¯¥éƒ¨åˆ†çš„é‡ç‚¹æ˜¯ä½ å¯ä»¥ç”¨äºå•ä¸ªåˆ—å’Œ tibble çš„å·¥å…·ã€‚\nYou learned about dplyr and base functions for working with logical vectors, numbers, and complete tables, stringr functions for working with strings, lubridate functions for working with date-times, and forcats functions for working with factors.\nä½ å­¦ä¹ äº†ç”¨äºå¤„ç†é€»è¾‘å‘é‡ã€æ•°å­—å’Œå®Œæ•´è¡¨æ ¼çš„ dplyr å’ŒåŸºç¡€å‡½æ•°ï¼Œç”¨äºå¤„ç†å­—ç¬¦ä¸²çš„ stringr å‡½æ•°ï¼Œç”¨äºå¤„ç†æ—¥æœŸæ—¶é—´çš„ lubridate å‡½æ•°ï¼Œä»¥åŠç”¨äºå¤„ç†å› å­çš„ forcats å‡½æ•°ã€‚\nIn the next part of the book, youâ€™ll learn more about getting various types of data into R in a tidy form.\nåœ¨æœ¬ä¹¦çš„ä¸‹ä¸€éƒ¨åˆ†ï¼Œä½ å°†å­¦ä¹ æ›´å¤šå…³äºå¦‚ä½•å°†å„ç§ç±»å‹çš„æ•°æ®ä»¥æ•´æ´çš„å½¢å¼å¯¼å…¥ R çš„çŸ¥è¯†ã€‚",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#footnotes",
    "href": "joins.html#footnotes",
    "title": "19Â  Joins",
    "section": "",
    "text": "Remember that in RStudio you can also use View() to avoid this problem.â†©ï¸\nThatâ€™s not 100% true, but youâ€™ll get a warning whenever it isnâ€™t.â†©ï¸",
    "crumbs": [
      "Transform",
      "<span class='chapter-number'>19</span>Â  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "import.html",
    "href": "import.html",
    "title": "Import",
    "section": "",
    "text": "In this part of the book, youâ€™ll learn how to import a wider range of data into R, as well as how to get it into a form useful for analysis. Sometimes this is just a matter of calling a function from the appropriate data import package. But in more complex cases it might require both tidying and transformation in order to get to the tidy rectangle that youâ€™d prefer to work with.\nåœ¨æœ¬ä¹¦çš„è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å°†æ›´å¹¿æ³›çš„æ•°æ®å¯¼å…¥ Rï¼Œä»¥åŠå¦‚ä½•å°†å…¶æ•´ç†æˆå¯ç”¨äºåˆ†æçš„å½¢å¼ã€‚æœ‰æ—¶ï¼Œè¿™åªæ˜¯è°ƒç”¨ç›¸åº”æ•°æ®å¯¼å…¥åŒ…ä¸­çš„ä¸€ä¸ªå‡½æ•°çš„é—®é¢˜ã€‚ä½†åœ¨æ›´å¤æ‚çš„æƒ…å†µä¸‹ï¼Œå¯èƒ½éœ€è¦è¿›è¡Œæ•´ç†å’Œè½¬æ¢ï¼Œæ‰èƒ½å¾—åˆ°ä½ æ›´å–œæ¬¢ä½¿ç”¨çš„æ•´æ´çŸ©å½¢æ•°æ®ã€‚\n\n\n\n\n\n\n\nFigureÂ 1: Data import is the beginning of the data science process; without data you canâ€™t do data science!\n\n\n\n\nIn this part of the book youâ€™ll learn how to access data stored in the following ways:\nåœ¨æœ¬ä¹¦çš„è¿™ä¸€éƒ¨åˆ†ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•è®¿é—®ä»¥ä¸‹åˆ—æ–¹å¼å­˜å‚¨çš„æ•°æ®ï¼š\n\nIn 20Â  Spreadsheets, youâ€™ll learn how to import data from Excel spreadsheets and Google Sheets.\nåœ¨ 20Â  Spreadsheets ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä» Excel ç”µå­è¡¨æ ¼å’Œ Google Sheets å¯¼å…¥æ•°æ®ã€‚\nIn 21Â  Databases, youâ€™ll learn about getting data out of a database and into R (and youâ€™ll also learn a little about how to get data out of R and into a database).\nåœ¨ 21Â  Databases ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å°†æ•°æ®ä»æ•°æ®åº“ä¸­å–å‡ºå¹¶å¯¼å…¥ R (ä½ è¿˜ä¼šå­¦åˆ°ä¸€ç‚¹å¦‚ä½•å°†æ•°æ®ä» R ä¸­å–å‡ºå¹¶å¯¼å…¥æ•°æ®åº“)ã€‚\nIn 22Â  Arrow, youâ€™ll learn about Arrow, a powerful tool for working with out-of-memory data, particularly when itâ€™s stored in the parquet format.\nåœ¨ 22Â  Arrow ä¸­ï¼Œä½ å°†å­¦ä¹  Arrowï¼Œè¿™æ˜¯ä¸€ä¸ªå¤„ç†å†…å­˜ä¸è¶³ (out-of-memory) æ•°æ®çš„å¼ºå¤§å·¥å…·ï¼Œå°¤å…¶æ˜¯å½“æ•°æ®ä»¥ parquet æ ¼å¼å­˜å‚¨æ—¶ã€‚\nIn 23Â  Hierarchical data, youâ€™ll learn how to work with hierarchical data, including the deeply nested lists produced by data stored in the JSON format.\nåœ¨ 23Â  Hierarchical data ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å¤„ç†åˆ†å±‚æ•°æ®ï¼ŒåŒ…æ‹¬ç”± JSON æ ¼å¼å­˜å‚¨çš„æ•°æ®äº§ç”Ÿçš„æ·±åº¦åµŒå¥—åˆ—è¡¨ã€‚\nIn 24Â  Web scraping, youâ€™ll learn web â€œscrapingâ€, the art and science of extracting data from web pages.\nåœ¨ 24Â  Web scraping ä¸­ï¼Œä½ å°†å­¦ä¹ ç½‘ç»œâ€œæŠ“å–â€ (scraping)ï¼Œå³ä»ç½‘é¡µä¸­æå–æ•°æ®çš„è‰ºæœ¯å’Œç§‘å­¦ã€‚\n\nThere are two important tidyverse packages that we donâ€™t discuss here: haven and xml2. If youâ€™re working with data from SPSS, Stata, and SAS files, check out the haven package, https://haven.tidyverse.org. If youâ€™re working with XML data, check out the xml2 package, https://xml2.r-lib.org. Otherwise, youâ€™ll need to do some research to figure which package youâ€™ll need to use; google is your friend here ğŸ˜ƒ.\næœ‰ä¸¤ä¸ªé‡è¦çš„ tidyverse åŒ…æˆ‘ä»¬åœ¨è¿™é‡Œä¸è®¨è®ºï¼šhaven å’Œ xml2ã€‚å¦‚æœä½ æ­£åœ¨å¤„ç†æ¥è‡ª SPSSã€Stata å’Œ SAS æ–‡ä»¶çš„æ•°æ®ï¼Œè¯·æŸ¥çœ‹ haven åŒ…ï¼Œhttps://haven.tidyverse.orgã€‚å¦‚æœä½ æ­£åœ¨å¤„ç† XML æ•°æ®ï¼Œè¯·æŸ¥çœ‹ xml2 åŒ…ï¼Œhttps://xml2.r-lib.orgã€‚å¦åˆ™ï¼Œä½ éœ€è¦åšä¸€äº›ç ”ç©¶æ¥æ‰¾å‡ºä½ éœ€è¦ä½¿ç”¨çš„åŒ…ï¼›è°·æ­Œæ˜¯ä½ çš„å¥½æœ‹å‹ ğŸ˜ƒã€‚",
    "crumbs": [
      "Import"
    ]
  },
  {
    "objectID": "spreadsheets.html",
    "href": "spreadsheets.html",
    "title": "20Â  Spreadsheets",
    "section": "",
    "text": "20.1 Introduction\nIn Chapter 7 you learned about importing data from plain text files like .csv and .tsv. Now itâ€™s time to learn how to get data out of a spreadsheet, either an Excel spreadsheet or a Google Sheet. This will build on much of what youâ€™ve learned in Chapter 7, but we will also discuss additional considerations and complexities when working with data from spreadsheets.\nåœ¨ Chapter 7 ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä» .csv å’Œ .tsv ç­‰çº¯æ–‡æœ¬æ–‡ä»¶å¯¼å…¥æ•°æ®ã€‚ç°åœ¨æ˜¯æ—¶å€™å­¦ä¹ å¦‚ä½•ä»ç”µå­è¡¨æ ¼ä¸­è·å–æ•°æ®äº†ï¼Œæ— è®ºæ˜¯ Excel ç”µå­è¡¨æ ¼è¿˜æ˜¯ Google Sheetã€‚æœ¬èŠ‚å°†å»ºç«‹åœ¨ä½ åœ¨ Chapter 7 ä¸­å­¦åˆ°çš„å¤§éƒ¨åˆ†çŸ¥è¯†ä¹‹ä¸Šï¼Œä½†æˆ‘ä»¬ä¹Ÿä¼šè®¨è®ºå¤„ç†ç”µå­è¡¨æ ¼æ•°æ®æ—¶çš„é¢å¤–è€ƒé‡å’Œå¤æ‚æ€§ã€‚\nIf you or your collaborators are using spreadsheets for organizing data, we strongly recommend reading the paper â€œData Organization in Spreadsheetsâ€ by Karl Broman and Kara Woo: https://doi.org/10.1080/00031305.2017.1375989. The best practices presented in this paper will save you much headache when you import data from a spreadsheet into R to analyze and visualize.\nå¦‚æœä½ æˆ–ä½ çš„åˆä½œè€…æ­£åœ¨ä½¿ç”¨ç”µå­è¡¨æ ¼æ¥ç»„ç»‡æ•°æ®ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®é˜…è¯» Karl Broman å’Œ Kara Woo çš„è®ºæ–‡ â€œData Organization in Spreadsheetsâ€ï¼šhttps://doi.org/10.1080/00031305.2017.1375989ã€‚å½“ä½ å°†æ•°æ®ä»ç”µå­è¡¨æ ¼å¯¼å…¥ R è¿›è¡Œåˆ†æå’Œå¯è§†åŒ–æ—¶ï¼Œæœ¬æ–‡æå‡ºçš„æœ€ä½³å®è·µå°†ä¸ºä½ çœå»å¾ˆå¤šéº»çƒ¦ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>20</span>Â  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#excel",
    "href": "spreadsheets.html#excel",
    "title": "20Â  Spreadsheets",
    "section": "\n20.2 Excel",
    "text": "20.2 Excel\nMicrosoft Excel is a widely used spreadsheet software program where data are organized in worksheets inside of spreadsheet files.\nMicrosoft Excel æ˜¯ä¸€æ¬¾å¹¿æ³›ä½¿ç”¨çš„ç”µå­è¡¨æ ¼è½¯ä»¶ç¨‹åºï¼Œæ•°æ®è¢«ç»„ç»‡åœ¨ç”µå­è¡¨æ ¼æ–‡ä»¶å†…çš„å·¥ä½œè¡¨ (worksheets) ä¸­ã€‚\n\n20.2.1 Prerequisites\nIn this section, youâ€™ll learn how to load data from Excel spreadsheets in R with the readxl package. This package is non-core tidyverse, so you need to load it explicitly, but it is installed automatically when you install the tidyverse package. Later, weâ€™ll also use the writexl package, which allows us to create Excel spreadsheets.\nåœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ readxl åŒ…åœ¨ R ä¸­åŠ è½½ Excel ç”µå­è¡¨æ ¼ä¸­çš„æ•°æ®ã€‚è¿™ä¸ªåŒ…ä¸æ˜¯ tidyverse çš„æ ¸å¿ƒåŒ…ï¼Œæ‰€ä»¥ä½ éœ€è¦æ˜¾å¼åŠ è½½å®ƒï¼Œä½†å®ƒä¼šåœ¨ä½ å®‰è£… tidyverse åŒ…æ—¶è‡ªåŠ¨å®‰è£…ã€‚ç¨åï¼Œæˆ‘ä»¬è¿˜å°†ä½¿ç”¨ writexl åŒ…ï¼Œå®ƒå…è®¸æˆ‘ä»¬åˆ›å»º Excel ç”µå­è¡¨æ ¼ã€‚\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(writexl)\n\n\n20.2.2 Getting started\nMost of readxlâ€™s functions allow you to load Excel spreadsheets into R:\nreadxl åŒ…çš„å¤§éƒ¨åˆ†å‡½æ•°éƒ½å¯ä»¥è®©ä½ å°† Excel ç”µå­è¡¨æ ¼åŠ è½½åˆ° R ä¸­ï¼š\n\nread_xls() reads Excel files with xls format.read_xls() è¯»å– xls æ ¼å¼çš„ Excel æ–‡ä»¶ã€‚\nread_xlsx() read Excel files with xlsx format.read_xlsx() è¯»å– xlsx æ ¼å¼çš„ Excel æ–‡ä»¶ã€‚\nread_excel() can read files with both xls and xlsx format. It guesses the file type based on the input.read_excel() å¯ä»¥è¯»å– xls å’Œ xlsx ä¸¤ç§æ ¼å¼çš„æ–‡ä»¶ã€‚å®ƒä¼šæ ¹æ®è¾“å…¥çŒœæµ‹æ–‡ä»¶ç±»å‹ã€‚\n\nThese functions all have similar syntax just like other functions we have previously introduced for reading other types of files, e.g., read_csv(), read_table(), etc. For the rest of the chapter we will focus on using read_excel().\nè¿™äº›å‡½æ•°éƒ½å…·æœ‰ç›¸ä¼¼çš„è¯­æ³•ï¼Œå°±åƒæˆ‘ä»¬ä¹‹å‰ä»‹ç»çš„ç”¨äºè¯»å–å…¶ä»–ç±»å‹æ–‡ä»¶çš„å‡½æ•°ä¸€æ ·ï¼Œä¾‹å¦‚ read_csv()ã€read_table() ç­‰ã€‚åœ¨æœ¬ç« çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä½¿ç”¨ read_excel()ã€‚\n\n20.2.3 Reading Excel spreadsheets\nFigureÂ 20.1 shows what the spreadsheet weâ€™re going to read into R looks like in Excel. This spreadsheet can be downloaded as an Excel file from https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w/.FigureÂ 20.1 å±•ç¤ºäº†æˆ‘ä»¬å³å°†è¯»å…¥ R çš„ç”µå­è¡¨æ ¼åœ¨ Excel ä¸­çš„æ ·å­ã€‚è¯¥ç”µå­è¡¨æ ¼å¯ä»¥ä» https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w/ ä¸‹è½½ä¸º Excel æ–‡ä»¶ã€‚\n\n\n\n\n\n\n\nFigureÂ 20.1: Spreadsheet called students.xlsx in Excel.\n\n\n\n\nThe first argument to read_excel() is the path to the file to read.read_excel() çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¦è¯»å–çš„æ–‡ä»¶çš„è·¯å¾„ã€‚\n\nstudents &lt;- read_excel(\"data/students.xlsx\")\n\nread_excel() will read the file in as a tibble.read_excel() ä¼šå°†æ–‡ä»¶è¯»å…¥ä¸ºä¸€ä¸ª tibbleã€‚\n\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nWe have six students in the data and five variables on each student. However there are a few things we might want to address in this dataset:\næ•°æ®ä¸­æœ‰å…­åå­¦ç”Ÿï¼Œæ¯åå­¦ç”Ÿæœ‰äº”ä¸ªå˜é‡ã€‚ç„¶è€Œï¼Œåœ¨è¿™ä¸ªæ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦è§£å†³ä¸€äº›é—®é¢˜ï¼š\n\n\nThe column names are all over the place. You can provide column names that follow a consistent format; we recommend snake_case using the col_names argument.\nåˆ—åäº”èŠ±å…«é—¨ã€‚ä½ å¯ä»¥æä¾›éµå¾ªä¸€è‡´æ ¼å¼çš„åˆ—åï¼›æˆ‘ä»¬æ¨èä½¿ç”¨ col_names å‚æ•°æ¥æŒ‡å®š snake_case æ ¼å¼çš„åˆ—åã€‚\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\")\n)\n#&gt; # A tibble: 7 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1 Student ID Full Name        favourite.food     mealPlan            AGE  \n#&gt; 2 1          Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 3 2          Barclay Lynn     French fries       Lunch only          5    \n#&gt; 4 3          Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 5 4          Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 6 5          Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 7 6          GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nUnfortunately, this didnâ€™t quite do the trick. We now have the variable names we want, but what was previously the header row now shows up as the first observation in the data. You can explicitly skip that row using the skip argument.\nä¸å¹¸çš„æ˜¯ï¼Œè¿™å¹¶æ²¡æœ‰å®Œå…¨è§£å†³é—®é¢˜ã€‚æˆ‘ä»¬ç°åœ¨æœ‰äº†æƒ³è¦çš„å˜é‡åï¼Œä½†ä¹‹å‰çš„æ ‡é¢˜è¡Œç°åœ¨ä½œä¸ºæ•°æ®ä¸­çš„ç¬¬ä¸€ä¸ªè§‚æµ‹å€¼å‡ºç°äº†ã€‚ä½ å¯ä»¥ä½¿ç”¨ skip å‚æ•°æ˜ç¡®è·³è¿‡é‚£ä¸€è¡Œã€‚\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1\n)\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\n\n\nIn the favourite_food column, one of the observations is N/A, which stands for â€œnot availableâ€ but itâ€™s currently not recognized as an NA (note the contrast between this N/A and the age of the fourth student in the list). You can specify which character strings should be recognized as NAs with the na argument. By default, only \"\" (empty string, or, in the case of reading from a spreadsheet, an empty cell or a cell with the formula =NA()) is recognized as an NA.\nåœ¨ favourite_food åˆ—ä¸­ï¼Œæœ‰ä¸€ä¸ªè§‚æµ‹å€¼æ˜¯ N/Aï¼Œå®ƒä»£è¡¨â€œä¸å¯ç”¨ (not available)â€ï¼Œä½†ç›®å‰æ²¡æœ‰è¢«è¯†åˆ«ä¸º NAï¼ˆæ³¨æ„è¿™ä¸ª N/A å’Œåˆ—è¡¨ä¸­ç¬¬å››ä¸ªå­¦ç”Ÿçš„å¹´é¾„ä¹‹é—´çš„å¯¹æ¯”ï¼‰ã€‚ä½ å¯ä»¥ä½¿ç”¨ na å‚æ•°æŒ‡å®šå“ªäº›å­—ç¬¦ä¸²åº”è¯¥è¢«è¯†åˆ«ä¸º NAã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œåªæœ‰ \"\"ï¼ˆç©ºå­—ç¬¦ä¸²ï¼Œæˆ–è€…åœ¨ä»ç”µå­è¡¨æ ¼è¯»å–æ—¶ï¼Œæ˜¯ä¸€ä¸ªç©ºå•å…ƒæ ¼æˆ–å¸¦æœ‰å…¬å¼ =NA() çš„å•å…ƒæ ¼ï¼‰è¢«è¯†åˆ«ä¸º NAã€‚\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\")\n)\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\n\n\nOne other remaining issue is that age is read in as a character variable, but it really should be numeric. Just like with read_csv() and friends for reading data from flat files, you can supply a col_types argument to read_excel() and specify the column types for the variables you read in. The syntax is a bit different, though. Your options are \"skip\", \"guess\", \"logical\", \"numeric\", \"date\", \"text\" or \"list\".\nå¦ä¸€ä¸ªé—ç•™é—®é¢˜æ˜¯ age è¢«è¯»ä½œå­—ç¬¦å˜é‡ï¼Œä½†å®ƒå®é™…ä¸Šåº”è¯¥æ˜¯æ•°å€¼å‹ã€‚å°±åƒä½¿ç”¨ read_csv() åŠå…¶ç³»åˆ—å‡½æ•°ä»å¹³é¢æ–‡ä»¶è¯»å–æ•°æ®ä¸€æ ·ï¼Œä½ å¯ä»¥ä¸º read_excel() æä¾›ä¸€ä¸ª col_types å‚æ•°ï¼Œå¹¶ä¸ºä½ è¯»å…¥çš„å˜é‡æŒ‡å®šåˆ—ç±»å‹ã€‚ä¸è¿‡ï¼Œè¯­æ³•æœ‰ç‚¹ä¸åŒã€‚ä½ çš„é€‰é¡¹æœ‰ \"skip\"ã€\"guess\"ã€\"logical\"ã€\"numeric\"ã€\"date\"ã€\"text\" æˆ– \"list\"ã€‚\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"numeric\")\n)\n#&gt; Warning: Expecting numeric in E6 / R6C5: got 'five'\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch    NA\n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only              6\n\nHowever, this didnâ€™t quite produce the desired result either. By specifying that age should be numeric, we have turned the one cell with the non-numeric entry (which had the value five) into an NA. In this case, we should read age in as \"text\" and then make the change once the data is loaded in R.\nç„¶è€Œï¼Œè¿™ä¹Ÿæ²¡æœ‰äº§ç”Ÿé¢„æœŸçš„ç»“æœã€‚é€šè¿‡æŒ‡å®š age åº”è¯¥æ˜¯æ•°å€¼å‹ï¼Œæˆ‘ä»¬å°†é‚£ä¸ªå¸¦æœ‰éæ•°å€¼æ¡ç›®ï¼ˆå…¶å€¼ä¸º fiveï¼‰çš„å•å…ƒæ ¼è½¬æ¢ä¸ºäº† NAã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥å°† age è¯»ä½œ \"text\"ï¼Œç„¶ååœ¨æ•°æ®åŠ è½½åˆ° R åå†è¿›è¡Œæ›´æ”¹ã€‚\n\nstudents &lt;- read_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"text\")\n)\n\nstudents &lt;- students |&gt;\n  mutate(\n    age = if_else(age == \"five\", \"5\", age),\n    age = parse_number(age)\n  )\n\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only              6\n\n\n\nIt took us multiple steps and trial-and-error to load the data in exactly the format we want, and this is not unexpected. Data science is an iterative process, and the process of iteration can be even more tedious when reading data in from spreadsheets compared to other plain text, rectangular data files because humans tend to input data into spreadsheets and use them not just for data storage but also for sharing and communication.\næˆ‘ä»¬é€šè¿‡å¤šä¸ªæ­¥éª¤å’Œåå¤è¯•é”™æ‰å°†æ•°æ®åŠ è½½æˆæˆ‘ä»¬æƒ³è¦çš„ç¡®åˆ‡æ ¼å¼ï¼Œè¿™å¹¶ä¸æ„å¤–ã€‚æ•°æ®ç§‘å­¦æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œä¸ä»å…¶ä»–çº¯æ–‡æœ¬ã€çŸ©å½¢æ•°æ®æ–‡ä»¶è¯»å–æ•°æ®ç›¸æ¯”ï¼Œä»ç”µå­è¡¨æ ¼ä¸­è¯»å–æ•°æ®çš„è¿­ä»£è¿‡ç¨‹å¯èƒ½æ›´åŠ ç¹çï¼Œå› ä¸ºäººä»¬å€¾å‘äºå°†æ•°æ®è¾“å…¥ç”µå­è¡¨æ ¼ï¼Œå¹¶ä¸ä»…ä»…å°†å…¶ç”¨äºæ•°æ®å­˜å‚¨ï¼Œè¿˜ç”¨äºå…±äº«å’Œäº¤æµã€‚\nThere is no way to know exactly what the data will look like until you load it and take a look at it. Well, there is one way, actually. You can open the file in Excel and take a peek. If youâ€™re going to do so, we recommend making a copy of the Excel file to open and browse interactively while leaving the original data file untouched and reading into R from the untouched file. This will ensure you donâ€™t accidentally overwrite anything in the spreadsheet while inspecting it. You should also not be afraid of doing what we did here: load the data, take a peek, make adjustments to your code, load it again, and repeat until youâ€™re happy with the result.\né™¤éä½ åŠ è½½å¹¶æŸ¥çœ‹æ•°æ®ï¼Œå¦åˆ™æ— æ³•ç¡®åˆ‡çŸ¥é“æ•°æ®ä¼šæ˜¯ä»€ä¹ˆæ ·å­ã€‚å—¯ï¼Œå®é™…ä¸Šï¼Œæœ‰ä¸€ç§æ–¹æ³•ã€‚ä½ å¯ä»¥åœ¨ Excel ä¸­æ‰“å¼€æ–‡ä»¶çœ‹ä¸€çœ‹ã€‚å¦‚æœä½ æ‰“ç®—è¿™æ ·åšï¼Œæˆ‘ä»¬å»ºè®®ä½ å¤åˆ¶ä¸€ä»½ Excel æ–‡ä»¶æ¥æ‰“å¼€å’Œäº¤äº’å¼æµè§ˆï¼ŒåŒæ—¶ä¿æŒåŸå§‹æ•°æ®æ–‡ä»¶ä¸å˜ï¼Œå¹¶ä»åŸå§‹æ–‡ä»¶è¯»å…¥ Rã€‚è¿™å°†ç¡®ä¿ä½ åœ¨æ£€æŸ¥ç”µå­è¡¨æ ¼æ—¶ä¸ä¼šæ„å¤–è¦†ç›–ä»»ä½•å†…å®¹ã€‚ä½ ä¹Ÿä¸åº”è¯¥å®³æ€•åƒæˆ‘ä»¬è¿™é‡Œæ‰€åšçš„é‚£æ ·ï¼šåŠ è½½æ•°æ®ï¼Œçœ‹ä¸€çœ‹ï¼Œè°ƒæ•´ä½ çš„ä»£ç ï¼Œå†æ¬¡åŠ è½½ï¼Œç„¶åé‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°ä½ å¯¹ç»“æœæ»¡æ„ä¸ºæ­¢ã€‚\n\n20.2.4 Reading worksheets\nAn important feature that distinguishes spreadsheets from flat files is the notion of multiple sheets, called worksheets. FigureÂ 20.2 shows an Excel spreadsheet with multiple worksheets. The data come from the palmerpenguins package, and you can download this spreadsheet as an Excel file from https://docs.google.com/spreadsheets/d/1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY/. Each worksheet contains information on penguins from a different island where data were collected.\nå°†ç”µå­è¡¨æ ¼ä¸å¹³é¢æ–‡ä»¶åŒºåˆ†å¼€æ¥çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯å¤šå¼ å·¥ä½œè¡¨ï¼ˆworksheetsï¼‰çš„æ¦‚å¿µã€‚FigureÂ 20.2 å±•ç¤ºäº†ä¸€ä¸ªåŒ…å«å¤šä¸ªå·¥ä½œè¡¨çš„ Excel ç”µå­è¡¨æ ¼ã€‚æ•°æ®æ¥è‡ª palmerpenguins åŒ…ï¼Œä½ å¯ä»¥ä» https://docs.google.com/spreadsheets/d/1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY/ ä¸‹è½½æ­¤ç”µå­è¡¨æ ¼çš„ Excel æ–‡ä»¶ã€‚æ¯ä¸ªå·¥ä½œè¡¨éƒ½åŒ…å«äº†æ¥è‡ªä¸åŒå²›å±¿çš„ä¼é¹…ä¿¡æ¯ï¼Œè¿™äº›æ•°æ®æ˜¯åœ¨è¿™äº›å²›å±¿ä¸Šæ”¶é›†çš„ã€‚\n\n\n\n\n\n\n\nFigureÂ 20.2: Spreadsheet called penguins.xlsx in Excel containing three worksheets.\n\n\n\n\nYou can read a single worksheet from a spreadsheet with the sheet argument in read_excel(). The default, which weâ€™ve been relying on up until now, is the first sheet.\nä½ å¯ä»¥ä½¿ç”¨ read_excel() ä¸­çš„ sheet å‚æ•°ä»ç”µå­è¡¨æ ¼ä¸­è¯»å–å•ä¸ªå·¥ä½œè¡¨ã€‚åˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬ä¸€ç›´ä¾èµ–çš„é»˜è®¤è®¾ç½®æ˜¯ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨ã€‚\n\nread_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\")\n#&gt; # A tibble: 52 Ã— 8\n#&gt;   species island    bill_length_mm     bill_depth_mm      flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;            \n#&gt; 1 Adelie  Torgersen 39.1               18.7               181              \n#&gt; 2 Adelie  Torgersen 39.5               17.399999999999999 186              \n#&gt; 3 Adelie  Torgersen 40.299999999999997 18                 195              \n#&gt; 4 Adelie  Torgersen NA                 NA                 NA               \n#&gt; 5 Adelie  Torgersen 36.700000000000003 19.3               193              \n#&gt; 6 Adelie  Torgersen 39.299999999999997 20.6               190              \n#&gt; # â„¹ 46 more rows\n#&gt; # â„¹ 3 more variables: body_mass_g &lt;chr&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nSome variables that appear to contain numerical data are read in as characters due to the character string \"NA\" not being recognized as a true NA.\nç”±äºå­—ç¬¦ä¸² \"NA\" æœªè¢«è¯†åˆ«ä¸ºçœŸæ­£çš„ NAï¼Œä¸€äº›çœ‹èµ·æ¥åŒ…å«æ•°å€¼æ•°æ®çš„å˜é‡è¢«è¯»å…¥ä¸ºå­—ç¬¦å‹ã€‚\n\npenguins_torgersen &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\", na = \"NA\")\n\npenguins_torgersen\n#&gt; # A tibble: 52 Ã— 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # â„¹ 46 more rows\n#&gt; # â„¹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nAlternatively, you can use excel_sheets() to get information on all worksheets in an Excel spreadsheet, and then read the one(s) youâ€™re interested in.\næˆ–è€…ï¼Œä½ å¯ä»¥ä½¿ç”¨ excel_sheets() è·å– Excel ç”µå­è¡¨æ ¼ä¸­æ‰€æœ‰å·¥ä½œè¡¨çš„ä¿¡æ¯ï¼Œç„¶åè¯»å–ä½ æ„Ÿå…´è¶£çš„ä¸€ä¸ªæˆ–å¤šä¸ªå·¥ä½œè¡¨ã€‚\n\nexcel_sheets(\"data/penguins.xlsx\")\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\nOnce you know the names of the worksheets, you can read them in individually with read_excel().\nä¸€æ—¦ä½ çŸ¥é“äº†å·¥ä½œè¡¨çš„åç§°ï¼Œå°±å¯ä»¥ä½¿ç”¨ read_excel() å•ç‹¬å°†å®ƒä»¬è¯»å…¥ã€‚\n\npenguins_biscoe &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Biscoe Island\", na = \"NA\")\npenguins_dream  &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Dream Island\", na = \"NA\")\n\nIn this case the full penguins dataset is spread across three worksheets in the spreadsheet. Each worksheet has the same number of columns but different numbers of rows.\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®Œæ•´çš„ä¼é¹…æ•°æ®é›†åˆ†å¸ƒåœ¨ç”µå­è¡¨æ ¼çš„ä¸‰ä¸ªå·¥ä½œè¡¨ä¸­ã€‚æ¯ä¸ªå·¥ä½œè¡¨çš„åˆ—æ•°ç›¸åŒï¼Œä½†è¡Œæ•°ä¸åŒã€‚\n\ndim(penguins_torgersen)\n#&gt; [1] 52  8\ndim(penguins_biscoe)\n#&gt; [1] 168   8\ndim(penguins_dream)\n#&gt; [1] 124   8\n\nWe can put them together with bind_rows().\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨ bind_rows() å°†å®ƒä»¬åˆå¹¶åœ¨ä¸€èµ·ã€‚\n\npenguins &lt;- bind_rows(penguins_torgersen, penguins_biscoe, penguins_dream)\npenguins\n#&gt; # A tibble: 344 Ã— 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # â„¹ 338 more rows\n#&gt; # â„¹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nIn Chapter 26 weâ€™ll talk about ways of doing this sort of task without repetitive code.\nåœ¨ Chapter 26 ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•åœ¨æ²¡æœ‰é‡å¤ä»£ç çš„æƒ…å†µä¸‹å®Œæˆè¿™ç±»ä»»åŠ¡ã€‚\n\n20.2.5 Reading part of a sheet\nSince many use Excel spreadsheets for presentation as well as for data storage, itâ€™s quite common to find cell entries in a spreadsheet that are not part of the data you want to read into R. FigureÂ 20.3 shows such a spreadsheet: in the middle of the sheet is what looks like a data frame but there is extraneous text in cells above and below the data.\nç”±äºè®¸å¤šäººä½¿ç”¨ Excel ç”µå­è¡¨æ ¼è¿›è¡Œæ¼”ç¤ºå’Œæ•°æ®å­˜å‚¨ï¼Œå› æ­¤åœ¨ç”µå­è¡¨æ ¼ä¸­å‘ç°ä¸å±äºæ‚¨æƒ³è¯»å…¥ R çš„æ•°æ®çš„å•å…ƒæ ¼æ¡ç›®æ˜¯å¾ˆå¸¸è§çš„ã€‚FigureÂ 20.3 å±•ç¤ºäº†è¿™æ ·ä¸€ä¸ªç”µå­è¡¨æ ¼ï¼šåœ¨å·¥ä½œè¡¨çš„ä¸­é—´çœ‹èµ·æ¥åƒä¸€ä¸ªæ•°æ®æ¡†ï¼Œä½†åœ¨æ•°æ®çš„ä¸Šæ–¹å’Œä¸‹æ–¹å•å…ƒæ ¼ä¸­æœ‰æ— å…³çš„æ–‡æœ¬ã€‚\n\n\n\n\n\n\n\nFigureÂ 20.3: Spreadsheet called deaths.xlsx in Excel.\n\n\n\n\nThis spreadsheet is one of the example spreadsheets provided in the readxl package. You can use the readxl_example() function to locate the spreadsheet on your system in the directory where the package is installed. This function returns the path to the spreadsheet, which you can use in read_excel() as usual.\nè¿™ä¸ªç”µå­è¡¨æ ¼æ˜¯ readxl åŒ…ä¸­æä¾›çš„ç¤ºä¾‹ç”µå­è¡¨æ ¼ä¹‹ä¸€ã€‚ä½ å¯ä»¥ä½¿ç”¨ readxl_example() å‡½æ•°åœ¨ä½ çš„ç³»ç»Ÿä¸Šå®šä½åˆ°åŒ…å®‰è£…ç›®å½•ä¸‹çš„è¿™ä¸ªç”µå­è¡¨æ ¼ã€‚è¯¥å‡½æ•°è¿”å›ç”µå­è¡¨æ ¼çš„è·¯å¾„ï¼Œä½ å¯ä»¥åƒå¾€å¸¸ä¸€æ ·åœ¨ read_excel() ä¸­ä½¿ç”¨å®ƒã€‚\n\ndeaths_path &lt;- readxl_example(\"deaths.xlsx\")\ndeaths &lt;- read_excel(deaths_path)\n#&gt; New names:\n#&gt; â€¢ `` -&gt; `...2`\n#&gt; â€¢ `` -&gt; `...3`\n#&gt; â€¢ `` -&gt; `...4`\n#&gt; â€¢ `` -&gt; `...5`\n#&gt; â€¢ `` -&gt; `...6`\ndeaths\n#&gt; # A tibble: 18 Ã— 6\n#&gt;   `Lots of people`    ...2       ...3  ...4     ...5          ...6           \n#&gt;   &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;          \n#&gt; 1 simply cannot resiâ€¦ &lt;NA&gt;       &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          some notes     \n#&gt; 2 at                  the        top   &lt;NA&gt;     of            their spreadshâ€¦\n#&gt; 3 or                  merging    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          cells          \n#&gt; 4 Name                Profession Age   Has kids Date of birth Date of death  \n#&gt; 5 David Bowie         musician   69    TRUE     17175         42379          \n#&gt; 6 Carrie Fisher       actor      60    TRUE     20749         42731          \n#&gt; # â„¹ 12 more rows\n\nThe top three rows and the bottom four rows are not part of the data frame. Itâ€™s possible to eliminate these extraneous rows using the skip and n_max arguments, but we recommend using cell ranges. In Excel, the top left cell is A1. As you move across columns to the right, the cell label moves down the alphabet, i.e. B1, C1, etc. And as you move down a column, the number in the cell label increases, i.e. A2, A3, etc.\næœ€ä¸Šé¢çš„ä¸‰è¡Œå’Œæœ€ä¸‹é¢çš„å››è¡Œä¸å±äºæ•°æ®æ¡†ã€‚å¯ä»¥ä½¿ç”¨ skip å’Œ n_max å‚æ•°æ¥æ¶ˆé™¤è¿™äº›å¤šä½™çš„è¡Œï¼Œä½†æˆ‘ä»¬å»ºè®®ä½¿ç”¨å•å…ƒæ ¼èŒƒå›´ã€‚åœ¨ Excel ä¸­ï¼Œå·¦ä¸Šè§’çš„å•å…ƒæ ¼æ˜¯ A1ã€‚å½“ä½ å‘å³ç§»åŠ¨åˆ—æ—¶ï¼Œå•å…ƒæ ¼æ ‡ç­¾ä¼šæŒ‰å­—æ¯è¡¨é¡ºåºç§»åŠ¨ï¼Œå³ B1ã€C1 ç­‰ã€‚å½“ä½ å‘ä¸‹ç§»åŠ¨ä¸€åˆ—æ—¶ï¼Œå•å…ƒæ ¼æ ‡ç­¾ä¸­çš„æ•°å­—ä¼šå¢åŠ ï¼Œå³ A2ã€A3 ç­‰ã€‚\nHere the data we want to read in starts in cell A5 and ends in cell F15. In spreadsheet notation, this is A5:F15, which we supply to the range argument:\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æƒ³è¦è¯»å…¥çš„æ•°æ®ä»å•å…ƒæ ¼ A5 å¼€å§‹ï¼Œåˆ°å•å…ƒæ ¼ F15 ç»“æŸã€‚åœ¨ç”µå­è¡¨æ ¼è¡¨ç¤ºæ³•ä¸­ï¼Œè¿™æ˜¯ A5:F15ï¼Œæˆ‘ä»¬å°†å…¶æä¾›ç»™ range å‚æ•°ï¼š\n\nread_excel(deaths_path, range = \"A5:F15\")\n#&gt; # A tibble: 10 Ã— 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # â„¹ 4 more rows\n#&gt; # â„¹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.2.6 Data types\nIn CSV files, all values are strings. This is not particularly true to the data, but it is simple: everything is a string.\nåœ¨ CSV æ–‡ä»¶ä¸­ï¼Œæ‰€æœ‰å€¼éƒ½æ˜¯å­—ç¬¦ä¸²ã€‚è¿™å¯¹äºæ•°æ®æ¥è¯´å¹¶éç‰¹åˆ«çœŸå®ï¼Œä½†å®ƒå¾ˆç®€å•ï¼šä¸€åˆ‡éƒ½æ˜¯å­—ç¬¦ä¸²ã€‚\nThe underlying data in Excel spreadsheets is more complex. A cell can be one of four things:\nExcel ç”µå­è¡¨æ ¼ä¸­çš„åº•å±‚æ•°æ®æ›´ä¸ºå¤æ‚ã€‚ä¸€ä¸ªå•å…ƒæ ¼å¯ä»¥æ˜¯ä»¥ä¸‹å››ç§ç±»å‹ä¹‹ä¸€ï¼š\n\nA boolean, like TRUE, FALSE, or NA.\nå¸ƒå°”å€¼ï¼Œå¦‚ TRUEã€FALSE æˆ– NAã€‚\nA number, like â€œ10â€ or â€œ10.5â€.\næ•°å­—ï¼Œå¦‚ â€œ10â€ æˆ– â€œ10.5â€ã€‚\nA datetime, which can also include time like â€œ11/1/21â€ or â€œ11/1/21 3:00 PMâ€.\næ—¥æœŸæ—¶é—´ï¼Œä¹Ÿå¯ä»¥åŒ…å«æ—¶é—´ï¼Œå¦‚ â€œ11/1/21â€ æˆ– â€œ11/1/21 3:00 PMâ€ã€‚\nA text string, like â€œtenâ€.\næ–‡æœ¬å­—ç¬¦ä¸²ï¼Œå¦‚ â€œtenâ€ã€‚\n\nWhen working with spreadsheet data, itâ€™s important to keep in mind that the underlying data can be very different than what you see in the cell. For example, Excel has no notion of an integer. All numbers are stored as floating points, but you can choose to display the data with a customizable number of decimal points. Similarly, dates are actually stored as numbers, specifically the number of seconds since January 1, 1970. You can customize how you display the date by applying formatting in Excel. Confusingly, itâ€™s also possible to have something that looks like a number but is actually a string (e.g., type '10 into a cell in Excel).\nåœ¨ä½¿ç”¨ç”µå­è¡¨æ ¼æ•°æ®æ—¶ï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œåº•å±‚æ•°æ®å¯èƒ½ä¸ä½ åœ¨å•å…ƒæ ¼ä¸­çœ‹åˆ°çš„å¤§ç›¸å¾„åº­ã€‚ä¾‹å¦‚ï¼ŒExcel æ²¡æœ‰æ•´æ•°çš„æ¦‚å¿µã€‚æ‰€æœ‰æ•°å­—éƒ½ä»¥æµ®ç‚¹æ•°å½¢å¼å­˜å‚¨ï¼Œä½†ä½ å¯ä»¥é€‰æ‹©ä»¥å¯è‡ªå®šä¹‰çš„å°æ•°ä½æ•°æ¥æ˜¾ç¤ºæ•°æ®ã€‚åŒæ ·ï¼Œæ—¥æœŸå®é™…ä¸Šæ˜¯ä½œä¸ºæ•°å­—å­˜å‚¨çš„ï¼Œå…·ä½“æ¥è¯´æ˜¯ä» 1970 å¹´ 1 æœˆ 1 æ—¥ä»¥æ¥çš„ç§’æ•°ã€‚ä½ å¯ä»¥é€šè¿‡åœ¨ Excel ä¸­åº”ç”¨æ ¼å¼æ¥è‡ªå®šä¹‰æ—¥æœŸçš„æ˜¾ç¤ºæ–¹å¼ã€‚ä»¤äººå›°æƒ‘çš„æ˜¯ï¼Œä¹Ÿå¯èƒ½å­˜åœ¨çœ‹èµ·æ¥åƒæ•°å­—ä½†å®é™…ä¸Šæ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µï¼ˆä¾‹å¦‚ï¼Œåœ¨ Excel å•å…ƒæ ¼ä¸­è¾“å…¥ '10ï¼‰ã€‚\nThese differences between how the underlying data are stored vs.Â how theyâ€™re displayed can cause surprises when the data are loaded into R. By default readxl will guess the data type in a given column. A recommended workflow is to let readxl guess the column types, confirm that youâ€™re happy with the guessed column types, and if not, go back and re-import specifying col_types as shown in Section 20.2.3.\nåº•å±‚æ•°æ®çš„å­˜å‚¨æ–¹å¼ä¸æ˜¾ç¤ºæ–¹å¼ä¹‹é—´çš„è¿™äº›å·®å¼‚ï¼Œåœ¨å°†æ•°æ®åŠ è½½åˆ° R æ—¶å¯èƒ½ä¼šå¸¦æ¥æ„å¤–ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œreadxl ä¼šçŒœæµ‹ç»™å®šåˆ—çš„æ•°æ®ç±»å‹ã€‚æ¨èçš„å·¥ä½œæµç¨‹æ˜¯è®© readxl çŒœæµ‹åˆ—ç±»å‹ï¼Œç¡®è®¤ä½ å¯¹çŒœæµ‹çš„åˆ—ç±»å‹æ»¡æ„ï¼Œå¦‚æœä¸æ»¡æ„ï¼Œåˆ™è¿”å›å¹¶é‡æ–°å¯¼å…¥ï¼Œå¹¶å¦‚ Section 20.2.3 æ‰€ç¤ºæŒ‡å®š col_typesã€‚\nAnother challenge is when you have a column in your Excel spreadsheet that has a mix of these types, e.g., some cells are numeric, others text, others dates. When importing the data into R readxl has to make some decisions. In these cases you can set the type for this column to \"list\", which will load the column as a list of length 1 vectors, where the type of each element of the vector is guessed.\nå¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯å½“ä½ çš„ Excel ç”µå­è¡¨æ ¼ä¸­çš„ä¸€åˆ—æ··åˆäº†è¿™äº›ç±»å‹æ—¶ï¼Œä¾‹å¦‚ï¼Œä¸€äº›å•å…ƒæ ¼æ˜¯æ•°å­—ï¼Œä¸€äº›æ˜¯æ–‡æœ¬ï¼Œè¿˜æœ‰ä¸€äº›æ˜¯æ—¥æœŸã€‚åœ¨å°†æ•°æ®å¯¼å…¥ R æ—¶ï¼Œreadxl å¿…é¡»åšå‡ºä¸€äº›å†³å®šã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å°†è¯¥åˆ—çš„ç±»å‹è®¾ç½®ä¸º \"list\"ï¼Œè¿™å°†æŠŠè¯¥åˆ—åŠ è½½ä¸ºä¸€ä¸ªé•¿åº¦ä¸º 1 çš„å‘é‡åˆ—è¡¨ï¼Œå…¶ä¸­å‘é‡çš„æ¯ä¸ªå…ƒç´ çš„ç±»å‹éƒ½æ˜¯è¢«çŒœæµ‹çš„ã€‚\n\n\n\n\n\n\nSometimes data is stored in more exotic ways, like the color of the cell background, or whether or not the text is bold. In such cases, you might find the tidyxl package useful. See https://nacnudus.github.io/spreadsheet-munging-strategies/ for more on strategies for working with non-tabular data from Excel.\næœ‰æ—¶æ•°æ®ä»¥æ›´å¥‡ç‰¹çš„æ–¹å¼å­˜å‚¨ï¼Œæ¯”å¦‚å•å…ƒæ ¼çš„èƒŒæ™¯é¢œè‰²ï¼Œæˆ–è€…æ–‡æœ¬æ˜¯å¦ä¸ºç²—ä½“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½ä¼šå‘ç° tidyxl åŒ…å¾ˆæœ‰ç”¨ã€‚æœ‰å…³å¤„ç†æ¥è‡ª Excel çš„éè¡¨æ ¼æ•°æ®çš„ç­–ç•¥ï¼Œè¯·å‚é˜… https://nacnudus.github.io/spreadsheet-munging-strategies/ã€‚\n\n\n\n\n20.2.7 Writing to Excel\nLetâ€™s create a small data frame that we can then write out. Note that item is a factor and quantity is an integer.\nè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå°çš„æ•°æ®æ¡†ï¼Œç„¶åå¯ä»¥å°†å…¶å†™å‡ºã€‚è¯·æ³¨æ„ï¼Œitem æ˜¯ä¸€ä¸ªå› å­ (factor)ï¼Œquantity æ˜¯ä¸€ä¸ªæ•´æ•° (integer)ã€‚\n\nbake_sale &lt;- tibble(\n  item     = factor(c(\"brownie\", \"cupcake\", \"cookie\")),\n  quantity = c(10, 5, 8)\n)\n\nbake_sale\n#&gt; # A tibble: 3 Ã— 2\n#&gt;   item    quantity\n#&gt;   &lt;fct&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\nYou can write data back to disk as an Excel file using the write_xlsx() function from the writexl package:\nä½ å¯ä»¥ä½¿ç”¨æ¥è‡ª writexl åŒ… çš„ write_xlsx() å‡½æ•°å°†æ•°æ®å†™å›ç£ç›˜ï¼Œä¿å­˜ä¸º Excel æ–‡ä»¶ï¼š\n\nwrite_xlsx(bake_sale, path = \"data/bake-sale.xlsx\")\n\nFigureÂ 20.4 shows what the data looks like in Excel. Note that column names are included and bolded. These can be turned off by setting col_names and format_headers arguments to FALSE.FigureÂ 20.4 å±•ç¤ºäº†æ•°æ®åœ¨ Excel ä¸­çš„æ ·å­ã€‚è¯·æ³¨æ„ï¼Œåˆ—åè¢«åŒ…å«å¹¶åŠ ç²—æ˜¾ç¤ºã€‚å¯ä»¥é€šè¿‡å°† col_names å’Œ format_headers å‚æ•°è®¾ç½®ä¸º FALSE æ¥å…³é—­è¿™äº›åŠŸèƒ½ã€‚\n\n\n\n\n\n\n\nFigureÂ 20.4: Spreadsheet called bake-sale.xlsx in Excel.\n\n\n\n\nJust like reading from a CSV, information on data type is lost when we read the data back in. This makes Excel files unreliable for caching interim results as well. For alternatives, see Section 7.5.\nå°±åƒä» CSV è¯»å–ä¸€æ ·ï¼Œå½“æˆ‘ä»¬å†æ¬¡è¯»å…¥æ•°æ®æ—¶ï¼Œå…³äºæ•°æ®ç±»å‹çš„ä¿¡æ¯ä¼šä¸¢å¤±ã€‚è¿™ä¹Ÿä½¿å¾— Excel æ–‡ä»¶ä¸é€‚åˆç”¨äºç¼“å­˜ä¸´æ—¶ç»“æœã€‚æœ‰å…³æ›¿ä»£æ–¹æ¡ˆï¼Œè¯·å‚è§ Section 7.5ã€‚\n\nread_excel(\"data/bake-sale.xlsx\")\n#&gt; # A tibble: 3 Ã— 2\n#&gt;   item    quantity\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\n\n20.2.8 Formatted output\nThe writexl package is a light-weight solution for writing a simple Excel spreadsheet, but if youâ€™re interested in additional features like writing to sheets within a spreadsheet and styling, you will want to use the openxlsx package. We wonâ€™t go into the details of using this package here, but we recommend reading https://ycphs.github.io/openxlsx/articles/Formatting.html for an extensive discussion on further formatting functionality for data written from R to Excel with openxlsx.\nwritexl åŒ…æ˜¯ä¸€ä¸ªç”¨äºç¼–å†™ç®€å• Excel ç”µå­è¡¨æ ¼çš„è½»é‡çº§è§£å†³æ–¹æ¡ˆï¼Œä½†å¦‚æœä½ å¯¹æ›´å¤šåŠŸèƒ½æ„Ÿå…´è¶£ï¼Œä¾‹å¦‚å†™å…¥ç”µå­è¡¨æ ¼ä¸­çš„å·¥ä½œè¡¨å’Œè®¾ç½®æ ·å¼ï¼Œä½ ä¼šæƒ³è¦ä½¿ç”¨ openxlsx åŒ…ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šè¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨è¿™ä¸ªåŒ…ï¼Œä½†æˆ‘ä»¬æ¨èé˜…è¯» https://ycphs.github.io/openxlsx/articles/Formatting.htmlï¼Œå…¶ä¸­å¹¿æ³›è®¨è®ºäº†ä½¿ç”¨ openxlsx å°†æ•°æ®ä» R å†™å…¥ Excel çš„è¿›ä¸€æ­¥æ ¼å¼åŒ–åŠŸèƒ½ã€‚\nNote that this package is not part of the tidyverse so the functions and workflows may feel unfamiliar. For example, function names are camelCase, multiple functions canâ€™t be composed in pipelines, and arguments are in a different order than they tend to be in the tidyverse. However, this is ok. As your R learning and usage expands outside of this book you will encounter lots of different styles used in various R packages that you might use to accomplish specific goals in R. A good way of familiarizing yourself with the coding style used in a new package is to run the examples provided in function documentation to get a feel for the syntax and the output formats as well as reading any vignettes that might come with the package.\nè¯·æ³¨æ„ï¼Œè¿™ä¸ªåŒ…ä¸æ˜¯ tidyverse çš„ä¸€éƒ¨åˆ†ï¼Œå› æ­¤å‡½æ•°å’Œå·¥ä½œæµç¨‹å¯èƒ½ä¼šè®©äººæ„Ÿåˆ°é™Œç”Ÿã€‚ä¾‹å¦‚ï¼Œå‡½æ•°åæ˜¯é©¼å³°å¼å‘½åæ³• (camelCase)ï¼Œå¤šä¸ªå‡½æ•°ä¸èƒ½åœ¨ç®¡é“ä¸­ç»„åˆä½¿ç”¨ï¼Œå¹¶ä¸”å‚æ•°çš„é¡ºåºä¹Ÿä¸ tidyverse ä¸­çš„é€šå¸¸é¡ºåºä¸åŒã€‚ç„¶è€Œï¼Œè¿™æ²¡å…³ç³»ã€‚éšç€ä½ çš„ R å­¦ä¹ å’Œä½¿ç”¨èŒƒå›´æ‰©å±•åˆ°æœ¬ä¹¦ä¹‹å¤–ï¼Œä½ ä¼šé‡åˆ°å„ç§ R åŒ…ä¸­ä½¿ç”¨çš„è®¸å¤šä¸åŒé£æ ¼ï¼Œä½ å¯èƒ½ä¼šç”¨å®ƒä»¬æ¥å®Œæˆ R ä¸­çš„ç‰¹å®šç›®æ ‡ã€‚ç†Ÿæ‚‰ä¸€ä¸ªæ–°åŒ…ä¸­ä½¿ç”¨çš„ç¼–ç é£æ ¼çš„ä¸€ä¸ªå¥½æ–¹æ³•æ˜¯è¿è¡Œå‡½æ•°æ–‡æ¡£ä¸­æä¾›çš„ç¤ºä¾‹ï¼Œä»¥æ„Ÿå—å…¶è¯­æ³•å’Œè¾“å‡ºæ ¼å¼ï¼Œå¹¶é˜…è¯»åŒ…å¯èƒ½é™„å¸¦çš„ä»»ä½• vignettesã€‚\n\n20.2.9 Exercises\n\n\nIn an Excel file, create the following dataset and save it as survey.xlsx. Alternatively, you can download it as an Excel file from here.\n\n\n\n\n\n\n\n\nThen, read it into R, with survey_id as a character variable and n_pets as a numerical variable.\n\n#&gt; # A tibble: 6 Ã— 2\n#&gt;   survey_id n_pets\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 1              0\n#&gt; 2 2              1\n#&gt; 3 3             NA\n#&gt; 4 4              2\n#&gt; 5 5              2\n#&gt; 6 6             NA\n\n\n\nIn another Excel file, create the following dataset and save it as roster.xlsx. Alternatively, you can download it as an Excel file from here.\n\n\n\n\n\n\n\n\nThen, read it into R. The resulting data frame should be called roster and should look like the following.\n\n#&gt; # A tibble: 12 Ã— 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12\n\n\n\nIn a new Excel file, create the following dataset and save it as sales.xlsx. Alternatively, you can download it as an Excel file from here.\n\n\n\n\n\n\n\n\na. Read sales.xlsx in and save as sales. The data frame should look like the following, with id and n as column names and with 9 rows.\n\n#&gt; # A tibble: 9 Ã— 2\n#&gt;   id      n    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 Brand 1 n    \n#&gt; 2 1234    8    \n#&gt; 3 8721    2    \n#&gt; 4 1822    3    \n#&gt; 5 Brand 2 n    \n#&gt; 6 3333    1    \n#&gt; 7 2156    3    \n#&gt; 8 3987    6    \n#&gt; 9 3216    5\n\nb. Modify sales further to get it into the following tidy format with three columns (brand, id, and n) and 7 rows of data. Note that id and n are numeric, brand is a character variable.\n\n#&gt; # A tibble: 7 Ã— 3\n#&gt;   brand      id     n\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Brand 1  1234     8\n#&gt; 2 Brand 1  8721     2\n#&gt; 3 Brand 1  1822     3\n#&gt; 4 Brand 2  3333     1\n#&gt; 5 Brand 2  2156     3\n#&gt; 6 Brand 2  3987     6\n#&gt; 7 Brand 2  3216     5\n\n\nRecreate the bake_sale data frame, write it out to an Excel file using the write.xlsx() function from the openxlsx package.\nIn Chapter 7 you learned about the janitor::clean_names() function to turn column names into snake case. Read the students.xlsx file that we introduced earlier in this section and use this function to â€œcleanâ€ the column names.\nWhat happens if you try to read in a file with .xlsx extension with read_xls()?",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>20</span>Â  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#google-sheets",
    "href": "spreadsheets.html#google-sheets",
    "title": "20Â  Spreadsheets",
    "section": "\n20.3 Google Sheets",
    "text": "20.3 Google Sheets\nGoogle Sheets is another widely used spreadsheet program. Itâ€™s free and web-based. Just like with Excel, in Google Sheets data are organized in worksheets (also called sheets) inside of spreadsheet files.\nGoogle Sheets æ˜¯å¦ä¸€æ¬¾å¹¿æ³›ä½¿ç”¨çš„ç”µå­è¡¨æ ¼ç¨‹åºã€‚å®ƒå…è´¹ä¸”åŸºäºç½‘ç»œã€‚å°±åƒ Excel ä¸€æ ·ï¼Œåœ¨ Google Sheets ä¸­ï¼Œæ•°æ®è¢«ç»„ç»‡åœ¨ç”µå­è¡¨æ ¼æ–‡ä»¶å†…éƒ¨çš„å·¥ä½œè¡¨ (worksheetsï¼Œä¹Ÿç§°ä¸º sheets) ä¸­ã€‚\n\n20.3.1 Prerequisites\nThis section will also focus on spreadsheets, but this time youâ€™ll be loading data from a Google Sheet with the googlesheets4 package. This package is non-core tidyverse as well, you need to load it explicitly.\næœ¬èŠ‚ä¹Ÿå°†é‡ç‚¹è®¨è®ºç”µå­è¡¨æ ¼ï¼Œä½†è¿™æ¬¡ä½ å°†ä½¿ç”¨ googlesheets4 åŒ…ä» Google Sheet åŠ è½½æ•°æ®ã€‚è¿™ä¸ªåŒ…åŒæ ·ä¸æ˜¯ tidyverse çš„æ ¸å¿ƒåŒ…ï¼Œä½ éœ€è¦æ˜¾å¼åœ°åŠ è½½å®ƒã€‚\n\nlibrary(googlesheets4)\nlibrary(tidyverse)\n\nA quick note about the name of the package: googlesheets4 uses v4 of the Sheets API v4 to provide an R interface to Google Sheets, hence the name.\nå…³äºåŒ…åçš„ä¸€ç‚¹è¯´æ˜ï¼šgooglesheets4 ä½¿ç”¨äº† Sheets API v4 çš„ç¬¬ 4 ç‰ˆæ¥æä¾› R ä¸ Google Sheets çš„æ¥å£ï¼Œå› æ­¤å¾—åã€‚\n\n20.3.2 Getting started\nThe main function of the googlesheets4 package is read_sheet(), which reads a Google Sheet from a URL or a file id. This function also goes by the name range_read().\ngooglesheets4 åŒ…çš„ä¸»è¦å‡½æ•°æ˜¯ read_sheet()ï¼Œå®ƒå¯ä»¥ä»ä¸€ä¸ª URL æˆ–æ–‡ä»¶ ID è¯»å– Google Sheetã€‚è¿™ä¸ªå‡½æ•°ä¹Ÿå« range_read()ã€‚\nYou can also create a brand new sheet with gs4_create() or write to an existing sheet with sheet_write() and friends.\nä½ ä¹Ÿå¯ä»¥ç”¨ gs4_create() åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„å·¥ä½œè¡¨ï¼Œæˆ–è€…ç”¨ sheet_write() åŠå…¶ç›¸å…³å‡½æ•°å‘ç°æœ‰çš„å·¥ä½œè¡¨å†™å…¥æ•°æ®ã€‚\nIn this section weâ€™ll work with the same datasets as the ones in the Excel section to highlight similarities and differences between workflows for reading data from Excel and Google Sheets. readxl and googlesheets4 packages are both designed to mimic the functionality of the readr package, which provides the read_csv() function youâ€™ve seen in Chapter 7. Therefore, many of the tasks can be accomplished with simply swapping out read_excel() for read_sheet(). However youâ€™ll also see that Excel and Google Sheets donâ€™t behave in exactly the same way, therefore other tasks may require further updates to the function calls.\nåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸ Excel éƒ¨åˆ†ç›¸åŒçš„æ•°æ®é›†ï¼Œä»¥çªæ˜¾ä» Excel å’Œ Google Sheets è¯»å–æ•°æ®çš„å·¥ä½œæµç¨‹ä¹‹é—´çš„å¼‚åŒã€‚readxl å’Œ googlesheets4 åŒ…éƒ½è¢«è®¾è®¡ä¸ºæ¨¡ä»¿ readr åŒ…çš„åŠŸèƒ½ï¼Œåè€…æä¾›äº†ä½ åœ¨ Chapter 7 ä¸­è§è¿‡çš„ read_csv() å‡½æ•°ã€‚å› æ­¤ï¼Œè®¸å¤šä»»åŠ¡åªéœ€å°† read_excel() æ›¿æ¢ä¸º read_sheet() å³å¯å®Œæˆã€‚ç„¶è€Œï¼Œä½ ä¹Ÿä¼šå‘ç° Excel å’Œ Google Sheets çš„è¡Œä¸ºä¸å®Œå…¨ç›¸åŒï¼Œå› æ­¤å…¶ä»–ä»»åŠ¡å¯èƒ½éœ€è¦å¯¹å‡½æ•°è°ƒç”¨è¿›è¡Œè¿›ä¸€æ­¥çš„æ›´æ–°ã€‚\n\n20.3.3 Reading Google Sheets\nFigureÂ 20.5 shows what the spreadsheet weâ€™re going to read into R looks like in Google Sheets. This is the same dataset as in FigureÂ 20.1, except itâ€™s stored in a Google Sheet instead of Excel.FigureÂ 20.5 å±•ç¤ºäº†æˆ‘ä»¬å°†è¦è¯»å…¥ R çš„ç”µå­è¡¨æ ¼åœ¨ Google Sheets ä¸­çš„æ ·å­ã€‚è¿™ä¸ FigureÂ 20.1 ä¸­çš„æ•°æ®é›†ç›¸åŒï¼Œåªæ˜¯å®ƒå­˜å‚¨åœ¨ Google Sheet ä¸­è€Œä¸æ˜¯ Excel ä¸­ã€‚\n\n\n\n\n\n\n\nFigureÂ 20.5: Google Sheet called students in a browser window.\n\n\n\n\nThe first argument to read_sheet() is the URL of the file to read, and it returns a tibble:https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w. These URLs are not pleasant to work with, so youâ€™ll often want to identify a sheet by its ID.read_sheet() çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¦è¯»å–çš„æ–‡ä»¶çš„ URLï¼Œå®ƒè¿”å›ä¸€ä¸ª tibbleï¼šhttps://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0wã€‚ è¿™äº› URL ä½¿ç”¨èµ·æ¥å¹¶ä¸æ–¹ä¾¿ï¼Œæ‰€ä»¥ä½ é€šå¸¸ä¼šå¸Œæœ›é€šè¿‡å…¶ ID æ¥è¯†åˆ«å·¥ä½œè¡¨ã€‚\n\ngs4_deauth()\n\n\nstudents_sheet_id &lt;- \"1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w\"\nstudents &lt;- read_sheet(students_sheet_id)\n#&gt; âœ” Reading from students.\n#&gt; âœ” Range Sheet1.\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE   \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;list&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          &lt;dbl&gt; \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          &lt;dbl&gt; \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch &lt;dbl&gt; \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NULL&gt;\n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch &lt;chr&gt; \n#&gt; 6            6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          &lt;dbl&gt;\n\nJust like we did with read_excel(), we can supply column names, NA strings, and column types to read_sheet().\nå°±åƒæˆ‘ä»¬å¯¹ read_excel() æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ä¸º read_sheet() æä¾›åˆ—åã€NA å­—ç¬¦ä¸²å’Œåˆ—ç±»å‹ã€‚\n\nstudents &lt;- read_sheet(\n  students_sheet_id,\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = \"dcccc\"\n)\n#&gt; âœ” Reading from students.\n#&gt; âœ” Range 2:10000000.\n\nstudents\n#&gt; # A tibble: 6 Ã— 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 GÃ¼venÃ§ Attila    Ice cream          Lunch only          6\n\nNote that we defined column types a bit differently here, using short codes. For example, â€œdccccâ€ stands for â€œdouble, character, character, character, characterâ€.\nè¯·æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œç”¨çŸ­ä»£ç å®šä¹‰åˆ—ç±»å‹çš„æ–¹å¼æœ‰äº›ä¸åŒã€‚ä¾‹å¦‚ï¼Œâ€œdccccâ€ ä»£è¡¨ â€œdouble, character, character, character, characterâ€ã€‚\nItâ€™s also possible to read individual sheets from Google Sheets as well. Letâ€™s read the â€œTorgersen Islandâ€ sheet from the penguins Google Sheet:\nä¹Ÿå¯ä»¥ä» Google Sheets è¯»å–å•ä¸ªå·¥ä½œè¡¨ã€‚è®©æˆ‘ä»¬ä» penguins Google Sheet ä¸­è¯»å–åä¸º â€œTorgersen Islandâ€ çš„å·¥ä½œè¡¨ï¼š\n\npenguins_sheet_id &lt;- \"1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY\"\nread_sheet(penguins_sheet_id, sheet = \"Torgersen Island\")\n#&gt; âœ” Reading from penguins.\n#&gt; âœ” Range ''Torgersen Island''.\n#&gt; # A tibble: 52 Ã— 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;list&gt;         &lt;list&gt;        &lt;list&gt;           \n#&gt; 1 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 2 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 3 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 4 Adelie  Torgersen &lt;chr [1]&gt;      &lt;chr [1]&gt;     &lt;chr [1]&gt;        \n#&gt; 5 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 6 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; # â„¹ 46 more rows\n#&gt; # â„¹ 3 more variables: body_mass_g &lt;list&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nYou can obtain a list of all sheets within a Google Sheet with sheet_names():\nä½ å¯ä»¥ä½¿ç”¨ sheet_names() è·å– Google Sheet ä¸­æ‰€æœ‰å·¥ä½œè¡¨çš„åˆ—è¡¨ï¼š\n\nsheet_names(penguins_sheet_id)\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\nFinally, just like with read_excel(), we can read in a portion of a Google Sheet by defining a range in read_sheet(). Note that weâ€™re also using the gs4_example() function below to locate an example Google Sheet that comes with the googlesheets4 package.\næœ€åï¼Œå°±åƒä½¿ç”¨ read_excel() ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨ read_sheet() ä¸­å®šä¹‰ä¸€ä¸ª range æ¥è¯»å– Google Sheet çš„ä¸€éƒ¨åˆ†ã€‚è¯·æ³¨æ„ï¼Œä¸‹é¢æˆ‘ä»¬è¿˜ä½¿ç”¨äº† gs4_example() å‡½æ•°æ¥å®šä½ä¸€ä¸ª googlesheets4 åŒ…è‡ªå¸¦çš„ç¤ºä¾‹ Google Sheetã€‚\n\ndeaths_url &lt;- gs4_example(\"deaths\")\ndeaths &lt;- read_sheet(deaths_url, range = \"A5:F15\")\n#&gt; âœ” Reading from deaths.\n#&gt; âœ” Range A5:F15.\ndeaths\n#&gt; # A tibble: 10 Ã— 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # â„¹ 4 more rows\n#&gt; # â„¹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.3.4 Writing to Google Sheets\nYou can write from R to Google Sheets with write_sheet(). The first argument is the data frame to write, and the second argument is the name (or other identifier) of the Google Sheet to write to:\nä½ å¯ä»¥ä½¿ç”¨ write_sheet() ä» R å†™å…¥æ•°æ®åˆ° Google Sheetsã€‚ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¦å†™å…¥çš„æ•°æ®æ¡†ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯è¦å†™å…¥çš„ Google Sheet çš„åç§°ï¼ˆæˆ–å…¶ä»–æ ‡è¯†ç¬¦ï¼‰ï¼š\n\nwrite_sheet(bake_sale, ss = \"bake-sale\")\n\nIf youâ€™d like to write your data to a specific (work)sheet inside a Google Sheet, you can specify that with the sheet argument as well.\nå¦‚æœä½ æƒ³å°†æ•°æ®å†™å…¥ Google Sheet ä¸­çš„ç‰¹å®šå·¥ä½œè¡¨ (worksheet)ï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡ sheet å‚æ•°æ¥æŒ‡å®šã€‚\n\nwrite_sheet(bake_sale, ss = \"bake-sale\", sheet = \"Sales\")\n\n\n20.3.5 Authentication\nWhile you can read from a public Google Sheet without authenticating with your Google account and with gs4_deauth(), reading a private sheet or writing to a sheet requires authentication so that googlesheets4 can view and manage your Google Sheets.\nè™½ç„¶ä½ å¯ä»¥ä½¿ç”¨ gs4_deauth() åœ¨ä¸é€šè¿‡ Google è´¦æˆ·è®¤è¯çš„æƒ…å†µä¸‹è¯»å–å…¬å¼€çš„ Google Sheetï¼Œä½†è¯»å–ç§æœ‰å·¥ä½œè¡¨æˆ–å‘å·¥ä½œè¡¨å†™å…¥æ•°æ®åˆ™éœ€è¦è®¤è¯ï¼Œä»¥ä¾¿ googlesheets4 å¯ä»¥æŸ¥çœ‹å’Œç®¡ç†ä½ çš„ Google Sheetsã€‚\nWhen you attempt to read in a sheet that requires authentication, googlesheets4 will direct you to a web browser with a prompt to sign in to your Google account and grant permission to operate on your behalf with Google Sheets. However, if you want to specify a specific Google account, authentication scope, etc. you can do so with gs4_auth(), e.g., gs4_auth(email = \"mine@example.com\"), which will force the use of a token associated with a specific email. For further authentication details, we recommend reading the documentation googlesheets4 auth vignette: https://googlesheets4.tidyverse.org/articles/auth.html.\nå½“ä½ å°è¯•è¯»å–éœ€è¦è®¤è¯çš„å·¥ä½œè¡¨æ—¶ï¼Œgooglesheets4 ä¼šå°†ä½ å¼•å¯¼è‡³ä¸€ä¸ªç½‘é¡µæµè§ˆå™¨ï¼Œæç¤ºä½ ç™»å½• Google è´¦æˆ·å¹¶æˆæƒå…¶ä»£è¡¨ä½ æ“ä½œ Google Sheetsã€‚ä½†æ˜¯ï¼Œå¦‚æœä½ æƒ³æŒ‡å®šä¸€ä¸ªç‰¹å®šçš„ Google è´¦æˆ·ã€è®¤è¯èŒƒå›´ç­‰ï¼Œä½ å¯ä»¥ä½¿ç”¨ gs4_auth() æ¥å®ç°ï¼Œä¾‹å¦‚ gs4_auth(email = \"mine@example.com\")ï¼Œè¿™å°†å¼ºåˆ¶ä½¿ç”¨ä¸ç‰¹å®šç”µå­é‚®ä»¶å…³è”çš„ä»¤ç‰Œã€‚æœ‰å…³æ›´å¤šè®¤è¯è¯¦æƒ…ï¼Œæˆ‘ä»¬å»ºè®®é˜…è¯» googlesheets4 è®¤è¯ vignette æ–‡æ¡£ï¼šhttps://googlesheets4.tidyverse.org/articles/auth.htmlã€‚\n\n20.3.6 Exercises\n\nRead the students dataset from earlier in the chapter from Excel and also from Google Sheets, with no additional arguments supplied to the read_excel() and read_sheet() functions. Are the resulting data frames in R exactly the same? If not, how are they different?\nRead the Google Sheet titled survey from https://pos.it/r4ds-survey, with survey_id as a character variable and n_pets as a numerical variable.\n\nRead the Google Sheet titled roster from https://pos.it/r4ds-roster. The resulting data frame should be called roster and should look like the following.\n\n#&gt; # A tibble: 12 Ã— 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>20</span>Â  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#summary",
    "href": "spreadsheets.html#summary",
    "title": "20Â  Spreadsheets",
    "section": "\n20.4 Summary",
    "text": "20.4 Summary\nMicrosoft Excel and Google Sheets are two of the most popular spreadsheet systems. Being able to interact with data stored in Excel and Google Sheets files directly from R is a superpower! In this chapter you learned how to read data into R from spreadsheets from Excel with read_excel() from the readxl package and from Google Sheets with read_sheet() from the googlesheets4 package. These functions work very similarly to each other and have similar arguments for specifying column names, NA strings, rows to skip on top of the file youâ€™re reading in, etc. Additionally, both functions make it possible to read a single sheet from a spreadsheet as well.\nMicrosoft Excel å’Œ Google Sheets æ˜¯ä¸¤ç§æœ€æµè¡Œçš„ç”µå­è¡¨æ ¼ç³»ç»Ÿã€‚èƒ½å¤Ÿç›´æ¥ä» R ä¸­ä¸å­˜å‚¨åœ¨ Excel å’Œ Google Sheets æ–‡ä»¶ä¸­çš„æ•°æ®è¿›è¡Œäº¤äº’æ˜¯ä¸€é¡¹è¶…èƒ½åŠ›ï¼åœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ readxl åŒ…ä¸­çš„ read_excel() å‡½æ•°ä» Excel ç”µå­è¡¨æ ¼ä¸­è¯»å–æ•°æ®åˆ° Rï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ googlesheets4 åŒ…ä¸­çš„ read_sheet() å‡½æ•°ä» Google Sheets ä¸­è¯»å–æ•°æ®ã€‚è¿™ä¸¤ä¸ªå‡½æ•°çš„å·¥ä½œæ–¹å¼éå¸¸ç›¸ä¼¼ï¼Œå¹¶ä¸”æœ‰ç±»ä¼¼çš„å‚æ•°ç”¨äºæŒ‡å®šåˆ—åã€NA å­—ç¬¦ä¸²ã€åœ¨è¯»å–æ–‡ä»¶é¡¶éƒ¨æ—¶è·³è¿‡çš„è¡Œæ•°ç­‰ã€‚æ­¤å¤–ï¼Œè¿™ä¸¤ä¸ªå‡½æ•°éƒ½æ”¯æŒä»ç”µå­è¡¨æ ¼ä¸­è¯»å–å•ä¸ªå·¥ä½œè¡¨ã€‚\nOn the other hand, writing to an Excel file requires a different package and function (writexl::write_xlsx()) while you can write to a Google Sheet with the googlesheets4 package, with write_sheet().\nå¦ä¸€æ–¹é¢ï¼Œå†™å…¥ Excel æ–‡ä»¶éœ€è¦ä½¿ç”¨ä¸åŒçš„åŒ…å’Œå‡½æ•° (writexl::write_xlsx())ï¼Œè€Œä½ å¯ä»¥ä½¿ç”¨ googlesheets4 åŒ…ä¸­çš„ write_sheet() å‡½æ•°æ¥å†™å…¥ Google Sheetã€‚\nIn the next chapter, youâ€™ll learn about a different data source and how to read data from that source into R: databases.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œä½ å°†å­¦ä¹ å¦ä¸€ç§ä¸åŒçš„æ•°æ®æºï¼Œä»¥åŠå¦‚ä½•å°†è¯¥æ¥æºçš„æ•°æ®è¯»å…¥ Rï¼šæ•°æ®åº“ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>20</span>Â  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "databases.html",
    "href": "databases.html",
    "title": "21Â  Databases",
    "section": "",
    "text": "21.1 Introduction\nA huge amount of data lives in databases, so itâ€™s essential that you know how to access it.\nå¤§é‡çš„æ•°æ®éƒ½å­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œå› æ­¤äº†è§£å¦‚ä½•è®¿é—®è¿™äº›æ•°æ®è‡³å…³é‡è¦ã€‚\nSometimes you can ask someone to download a snapshot into a .csv for you, but this gets painful quickly: every time you need to make a change youâ€™ll have to communicate with another human.\næœ‰æ—¶ï¼Œä½ å¯ä»¥è¯·åˆ«äººä¸ºä½ ä¸‹è½½ä¸€ä¸ªå¿«ç…§åˆ° .csv æ–‡ä»¶ä¸­ï¼Œä½†è¿™å¾ˆå¿«å°±ä¼šå˜å¾—ç—›è‹¦ï¼šæ¯æ¬¡ä½ éœ€è¦åšæ›´æ”¹æ—¶ï¼Œéƒ½å¿…é¡»ä¸å¦ä¸€ä¸ªäººæ²Ÿé€šã€‚\nYou want to be able to reach into the database directly to get the data you need, when you need it.\nä½ å¸Œæœ›èƒ½å¤Ÿç›´æ¥è®¿é—®æ•°æ®åº“ï¼Œåœ¨éœ€è¦çš„æ—¶å€™è·å–æ‰€éœ€çš„æ•°æ®ã€‚\nIn this chapter, youâ€™ll first learn the basics of the DBI package: how to use it to connect to a database and then retrieve data with a SQL1 query.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†é¦–å…ˆå­¦ä¹  DBI åŒ…çš„åŸºç¡€çŸ¥è¯†ï¼šå¦‚ä½•ä½¿ç”¨å®ƒè¿æ¥åˆ°æ•°æ®åº“ï¼Œç„¶åé€šè¿‡ SQL1 æŸ¥è¯¢æ¥æ£€ç´¢æ•°æ®ã€‚\nSQL, short for structured query language, is the lingua franca of databases, and is an important language for all data scientists to learn.SQL æ˜¯ç»“æ„åŒ–æŸ¥è¯¢è¯­è¨€ï¼ˆstructured query languageï¼‰çš„ç¼©å†™ï¼Œæ˜¯æ•°æ®åº“çš„é€šç”¨è¯­è¨€ï¼Œä¹Ÿæ˜¯æ‰€æœ‰æ•°æ®ç§‘å­¦å®¶éœ€è¦å­¦ä¹ çš„é‡è¦è¯­è¨€ã€‚\nThat said, weâ€™re not going to start with SQL, but instead weâ€™ll teach you dbplyr, which can translate your dplyr code to the SQL.\nå°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬ä¸ä¼šä» SQL å¼€å§‹ï¼Œè€Œæ˜¯ä¼šæ•™ä½  dbplyrï¼Œå®ƒå¯ä»¥å°†ä½ çš„ dplyr ä»£ç ç¿»è¯‘æˆ SQLã€‚\nWeâ€™ll use that as a way to teach you some of the most important features of SQL.\næˆ‘ä»¬å°†ä»¥æ­¤ä¸ºé€”å¾„ï¼Œæ•™ä½ ä¸€äº› SQL æœ€é‡è¦çš„ç‰¹æ€§ã€‚\nYou wonâ€™t become a SQL master by the end of the chapter, but you will be able to identify the most important components and understand what they do.\nåœ¨æœ¬ç« ç»“æŸæ—¶ï¼Œä½ ä¸ä¼šæˆä¸º SQL å¤§å¸ˆï¼Œä½†ä½ å°†èƒ½å¤Ÿè¯†åˆ«å‡ºæœ€é‡è¦çš„ç»„æˆéƒ¨åˆ†å¹¶ç†è§£å®ƒä»¬çš„ä½œç”¨ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#introduction",
    "href": "databases.html#introduction",
    "title": "21Â  Databases",
    "section": "",
    "text": "21.1.1 Prerequisites\nIn this chapter, weâ€™ll introduce DBI and dbplyr.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç» DBI å’Œ dbplyrã€‚\nDBI is a low-level interface that connects to databases and executes SQL; dbplyr is a high-level interface that translates your dplyr code to SQL queries then executes them with DBI.\nDBI æ˜¯ä¸€ä¸ªè¿æ¥æ•°æ®åº“å¹¶æ‰§è¡Œ SQL çš„åº•å±‚æ¥å£ï¼›dbplyr æ˜¯ä¸€ä¸ªé«˜å±‚æ¥å£ï¼Œå®ƒå°†ä½ çš„ dplyr ä»£ç ç¿»è¯‘æˆ SQL æŸ¥è¯¢ï¼Œç„¶åé€šè¿‡ DBI æ‰§è¡Œå®ƒä»¬ã€‚\n\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(tidyverse)",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#database-basics",
    "href": "databases.html#database-basics",
    "title": "21Â  Databases",
    "section": "\n21.2 Database basics",
    "text": "21.2 Database basics\nAt the simplest level, you can think about a database as a collection of data frames, called tables in database terminology.\nåœ¨æœ€ç®€å•çš„å±‚é¢ä¸Šï¼Œä½ å¯ä»¥æŠŠæ•°æ®åº“çœ‹ä½œæ˜¯æ•°æ®æ¡†çš„é›†åˆï¼Œåœ¨æ•°æ®åº“æœ¯è¯­ä¸­ç§°ä¸ºè¡¨ (tables)ã€‚\nLike a data frame, a database table is a collection of named columns, where every value in the column is the same type.\nä¸æ•°æ®æ¡†ä¸€æ ·ï¼Œæ•°æ®åº“è¡¨æ˜¯å‘½ååˆ—çš„é›†åˆï¼Œå…¶ä¸­æ¯åˆ—ä¸­çš„æ‰€æœ‰å€¼éƒ½å…·æœ‰ç›¸åŒçš„ç±»å‹ã€‚\nThere are three high level differences between data frames and database tables:\næ•°æ®æ¡†å’Œæ•°æ®åº“è¡¨ä¹‹é—´æœ‰ä¸‰ä¸ªé«˜çº§åˆ«çš„åŒºåˆ«ï¼š\n\nDatabase tables are stored on disk and can be arbitrarily large.\nData frames are stored in memory, and are fundamentally limited (although that limit is still plenty large for many problems).\næ•°æ®åº“è¡¨å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼Œå¯ä»¥ä»»æ„å¤§ã€‚\næ•°æ®æ¡†å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œå¹¶ä¸”æœ‰æ ¹æœ¬çš„å¤§å°é™åˆ¶ï¼ˆå°½ç®¡è¿™ä¸ªé™åˆ¶å¯¹äºè®¸å¤šé—®é¢˜æ¥è¯´ä»ç„¶è¶³å¤Ÿå¤§ï¼‰ã€‚\nDatabase tables almost always have indexes.\nMuch like the index of a book, a database index makes it possible to quickly find rows of interest without having to look at every single row.\nData frames and tibbles donâ€™t have indexes, but data.tables do, which is one of the reasons that theyâ€™re so fast.\næ•°æ®åº“è¡¨å‡ ä¹æ€»æ˜¯æœ‰ç´¢å¼•ã€‚\nå°±åƒä¹¦çš„ç´¢å¼•ä¸€æ ·ï¼Œæ•°æ®åº“ç´¢å¼•å¯ä»¥å¿«é€Ÿæ‰¾åˆ°æ„Ÿå…´è¶£çš„è¡Œï¼Œè€Œæ— éœ€æŸ¥çœ‹æ¯ä¸€è¡Œã€‚\næ•°æ®æ¡†å’Œ tibbles æ²¡æœ‰ç´¢å¼•ï¼Œä½† data.tables æœ‰ï¼Œè¿™ä¹Ÿæ˜¯å®ƒä»¬é€Ÿåº¦å¦‚æ­¤ä¹‹å¿«çš„åŸå› ä¹‹ä¸€ã€‚\nMost classical databases are optimized for rapidly collecting data, not analyzing existing data.\nThese databases are called row-oriented because the data is stored row-by-row, rather than column-by-column like R.\nMore recently, thereâ€™s been much development of column-oriented databases that make analyzing the existing data much faster.\nå¤§å¤šæ•°ä¼ ç»Ÿæ•°æ®åº“éƒ½ä¸ºå¿«é€Ÿæ”¶é›†æ•°æ®è€Œä¼˜åŒ–ï¼Œè€Œä¸æ˜¯ä¸ºåˆ†æç°æœ‰æ•°æ®è€Œä¼˜åŒ–ã€‚\nè¿™äº›æ•°æ®åº“è¢«ç§°ä¸ºè¡Œå¼å­˜å‚¨ (row-oriented)ï¼Œå› ä¸ºæ•°æ®æ˜¯æŒ‰è¡Œå­˜å‚¨çš„ï¼Œè€Œä¸æ˜¯åƒ R é‚£æ ·æŒ‰åˆ—å­˜å‚¨ã€‚\nè¿‘å¹´æ¥ï¼Œåˆ—å¼å­˜å‚¨ (column-oriented) æ•°æ®åº“å¾—åˆ°äº†é•¿è¶³å‘å±•ï¼Œå®ƒä»¬ä½¿åˆ†æç°æœ‰æ•°æ®å˜å¾—å¿«å¾—å¤šã€‚\n\nDatabases are run by database management systems (DBMSâ€™s for short), which come in three basic forms:\næ•°æ®åº“ç”±æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆç®€ç§° DBMSï¼‰è¿è¡Œï¼Œä¸»è¦æœ‰ä¸‰ç§åŸºæœ¬å½¢å¼ï¼š\n\nClient-server DBMSâ€™s run on a powerful central server, which you connect to from your computer (the client). They are great for sharing data with multiple people in an organization. Popular client-server DBMSâ€™s include PostgreSQL, MariaDB, SQL Server, and Oracle.å®¢æˆ·ç«¯-æœåŠ¡å™¨ (Client-server) æ¨¡å¼çš„ DBMS è¿è¡Œåœ¨ä¸€å°å¼ºå¤§çš„ä¸­å¤®æœåŠ¡å™¨ä¸Šï¼Œä½ ä»ä½ çš„è®¡ç®—æœºï¼ˆå®¢æˆ·ç«¯ï¼‰è¿æ¥åˆ°å®ƒã€‚å®ƒä»¬éå¸¸é€‚åˆåœ¨ç»„ç»‡å†…ä¸å¤šäººå…±äº«æ•°æ®ã€‚æµè¡Œçš„å®¢æˆ·ç«¯-æœåŠ¡å™¨ DBMS åŒ…æ‹¬ PostgreSQLã€MariaDBã€SQL Server å’Œ Oracleã€‚\nCloud DBMSâ€™s, like Snowflake, Amazonâ€™s RedShift, and Googleâ€™s BigQuery, are similar to client server DBMSâ€™s, but they run in the cloud. This means that they can easily handle extremely large datasets and can automatically provide more compute resources as needed.äº‘ (Cloud) DBMSï¼Œå¦‚ Snowflakeã€Amazon çš„ RedShift å’Œ Google çš„ BigQueryï¼Œä¸å®¢æˆ·ç«¯-æœåŠ¡å™¨ DBMS ç±»ä¼¼ï¼Œä½†å®ƒä»¬è¿è¡Œåœ¨äº‘ç«¯ã€‚è¿™æ„å‘³ç€å®ƒä»¬å¯ä»¥è½»æ¾å¤„ç†æå¤§çš„æ•°æ®é›†ï¼Œå¹¶å¯ä»¥æ ¹æ®éœ€è¦è‡ªåŠ¨æä¾›æ›´å¤šçš„è®¡ç®—èµ„æºã€‚\nIn-process DBMSâ€™s, like SQLite or duckdb, run entirely on your computer. Theyâ€™re great for working with large datasets where youâ€™re the primary user.è¿›ç¨‹å†… (In-process) DBMSï¼Œå¦‚ SQLite æˆ– duckdbï¼Œå®Œå…¨åœ¨ä½ çš„è®¡ç®—æœºä¸Šè¿è¡Œã€‚å½“ä½ ä½œä¸ºä¸»è¦ç”¨æˆ·å¤„ç†å¤§å‹æ•°æ®é›†æ—¶ï¼Œå®ƒä»¬æ˜¯å¾ˆå¥½çš„é€‰æ‹©ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#connecting-to-a-database",
    "href": "databases.html#connecting-to-a-database",
    "title": "21Â  Databases",
    "section": "\n21.3 Connecting to a database",
    "text": "21.3 Connecting to a database\nTo connect to the database from R, youâ€™ll use a pair of packages:\nè¦ä» R è¿æ¥åˆ°æ•°æ®åº“ï¼Œä½ éœ€è¦ä½¿ç”¨ä¸€å¯¹åŒ…ï¼š\n\nYouâ€™ll always use DBI (database interface) because it provides a set of generic functions that connect to the database, upload data, run SQL queries, etc.\nä½ å°†æ€»æ˜¯ä½¿ç”¨ DBIï¼ˆdatabase interfaceï¼Œæ•°æ®åº“æ¥å£ï¼‰ï¼Œå› ä¸ºå®ƒæä¾›äº†ä¸€ç»„é€šç”¨å‡½æ•°ï¼Œç”¨äºè¿æ¥æ•°æ®åº“ã€ä¸Šä¼ æ•°æ®ã€è¿è¡Œ SQL æŸ¥è¯¢ç­‰ã€‚\nYouâ€™ll also use a package tailored for the DBMS youâ€™re connecting to.\nThis package translates the generic DBI commands into the specifics needed for a given DBMS.\nThereâ€™s usually one package for each DBMS, e.g.\nRPostgres for PostgreSQL and RMariaDB for MySQL.\nä½ è¿˜éœ€è¦ä½¿ç”¨ä¸€ä¸ªä¸ºä½ æ‰€è¿æ¥çš„ DBMS å®šåˆ¶çš„åŒ…ã€‚\nè¿™ä¸ªåŒ…ä¼šå°†é€šç”¨çš„ DBI å‘½ä»¤ç¿»è¯‘æˆç‰¹å®š DBMS æ‰€éœ€çš„å…·ä½“æŒ‡ä»¤ã€‚\né€šå¸¸æ¯ä¸ª DBMS éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„åŒ…ï¼Œä¾‹å¦‚ï¼š\nç”¨äº PostgreSQL çš„ RPostgres å’Œç”¨äº MySQL çš„ RMariaDBã€‚\n\nIf you canâ€™t find a specific package for your DBMS, you can usually use the odbc package instead.\nå¦‚æœä½ æ‰¾ä¸åˆ°é€‚ç”¨äºä½ çš„ DBMS çš„ç‰¹å®šåŒ…ï¼Œä½ é€šå¸¸å¯ä»¥ä½¿ç”¨ odbc åŒ…ä½œä¸ºæ›¿ä»£ã€‚\nThis uses the ODBC protocol supported by many DBMS.\nå®ƒä½¿ç”¨äº†è®¸å¤š DBMS æ”¯æŒçš„ ODBC åè®®ã€‚\nodbc requires a little more setup because youâ€™ll also need to install an ODBC driver and tell the odbc package where to find it.\nodbc éœ€è¦å¤šä¸€äº›è®¾ç½®ï¼Œå› ä¸ºä½ è¿˜éœ€è¦å®‰è£…ä¸€ä¸ª ODBC é©±åŠ¨ç¨‹åºï¼Œå¹¶å‘Šè¯‰ odbc åŒ…åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°å®ƒã€‚\nConcretely, you create a database connection using DBI::dbConnect().\nå…·ä½“æ¥è¯´ï¼Œä½ ä½¿ç”¨ DBI::dbConnect() åˆ›å»ºä¸€ä¸ªæ•°æ®åº“è¿æ¥ã€‚\nThe first argument selects the DBMS2, then the second and subsequent arguments describe how to connect to it (i.e.Â where it lives and the credentials that you need to access it).\nç¬¬ä¸€ä¸ªå‚æ•°é€‰æ‹© DBMS2ï¼Œç„¶åç¬¬äºŒä¸ªåŠåç»­å‚æ•°æè¿°å¦‚ä½•è¿æ¥åˆ°å®ƒï¼ˆå³ï¼Œå®ƒåœ¨å“ªé‡Œä»¥åŠè®¿é—®å®ƒæ‰€éœ€çš„å‡­æ®ï¼‰ã€‚\nThe following code shows a couple of typical examples:\nä»¥ä¸‹ä»£ç å±•ç¤ºäº†å‡ ä¸ªå…¸å‹çš„ä¾‹å­ï¼š\n\ncon &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(), \n  username = \"foo\"\n)\ncon &lt;- DBI::dbConnect(\n  RPostgres::Postgres(), \n  hostname = \"databases.mycompany.com\", \n  port = 1234\n)\n\nThe precise details of the connection vary a lot from DBMS to DBMS so unfortunately we canâ€™t cover all the details here.\nè¿æ¥çš„å…·ä½“ç»†èŠ‚å›  DBMS è€Œå¼‚ï¼Œæ‰€ä»¥å¾ˆé—æ†¾æˆ‘ä»¬æ— æ³•åœ¨è¿™é‡Œæ¶µç›–æ‰€æœ‰ç»†èŠ‚ã€‚\nThis means youâ€™ll need to do a little research on your own.\nè¿™æ„å‘³ç€ä½ éœ€è¦è‡ªå·±åšä¸€äº›ç ”ç©¶ã€‚\nTypically you can ask the other data scientists in your team or talk to your DBA (database administrator).\né€šå¸¸ä½ å¯ä»¥è¯¢é—®å›¢é˜Ÿä¸­çš„å…¶ä»–æ•°æ®ç§‘å­¦å®¶æˆ–ä¸ä½ çš„ DBAï¼ˆæ•°æ®åº“ç®¡ç†å‘˜ï¼‰äº¤æµã€‚\nThe initial setup will often take a little fiddling (and maybe some googling) to get it right, but youâ€™ll generally only need to do it once.\nåˆå§‹è®¾ç½®é€šå¸¸éœ€è¦ä¸€äº›æ‘¸ç´¢ï¼ˆå¯èƒ½è¿˜éœ€è¦è°·æ­Œæœç´¢ï¼‰æ‰èƒ½æå®šï¼Œä½†ä½ é€šå¸¸åªéœ€è¦åšä¸€æ¬¡ã€‚\n\n21.3.1 In this book\nSetting up a client-server or cloud DBMS would be a pain for this book, so weâ€™ll instead use an in-process DBMS that lives entirely in an R package: duckdb.\nä¸ºæœ¬ä¹¦è®¾ç½®ä¸€ä¸ªå®¢æˆ·ç«¯-æœåŠ¡å™¨æˆ–äº‘ DBMS ä¼šå¾ˆéº»çƒ¦ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå®Œå…¨å­˜åœ¨äº R åŒ…ä¸­çš„è¿›ç¨‹å†… DBMSï¼šduckdbã€‚\nThanks to the magic of DBI, the only difference between using duckdb and any other DBMS is how youâ€™ll connect to the database.\nå¾—ç›Šäº DBI çš„é­”åŠ›ï¼Œä½¿ç”¨ duckdb å’Œä»»ä½•å…¶ä»– DBMS ä¹‹é—´çš„å”¯ä¸€åŒºåˆ«å°±æ˜¯ä½ å¦‚ä½•è¿æ¥åˆ°æ•°æ®åº“ã€‚\nThis makes it great to teach with because you can easily run this code as well as easily take what you learn and apply it elsewhere.\nè¿™ä½¿å¾—å®ƒéå¸¸é€‚åˆæ•™å­¦ï¼Œå› ä¸ºä½ å¯ä»¥è½»æ¾åœ°è¿è¡Œè¿™æ®µä»£ç ï¼Œä¹Ÿå¯ä»¥è½»æ¾åœ°å°†å­¦åˆ°çš„çŸ¥è¯†åº”ç”¨åˆ°å…¶ä»–åœ°æ–¹ã€‚\nConnecting to duckdb is particularly simple because the defaults create a temporary database that is deleted when you quit R.\nè¿æ¥åˆ° duckdb ç‰¹åˆ«ç®€å•ï¼Œå› ä¸ºé»˜è®¤è®¾ç½®ä¼šåˆ›å»ºä¸€ä¸ªä¸´æ—¶æ•°æ®åº“ï¼Œåœ¨ä½ é€€å‡º R æ—¶ä¼šè¢«åˆ é™¤ã€‚\nThatâ€™s great for learning because it guarantees that youâ€™ll start from a clean slate every time you restart R:\nè¿™å¯¹äºå­¦ä¹ æ¥è¯´éå¸¸æ£’ï¼Œå› ä¸ºå®ƒä¿è¯äº†ä½ æ¯æ¬¡é‡å¯ R æ—¶éƒ½èƒ½ä»ä¸€ä¸ªå¹²å‡€çš„çŠ¶æ€å¼€å§‹ï¼š\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\n\nduckdb is a high-performance database thatâ€™s designed very much for the needs of a data scientist.\nduckdb æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½æ•°æ®åº“ï¼Œå…¶è®¾è®¡éå¸¸è´´åˆæ•°æ®ç§‘å­¦å®¶çš„éœ€æ±‚ã€‚\nWe use it here because itâ€™s very easy to get started with, but itâ€™s also capable of handling gigabytes of data with great speed.\næˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨å®ƒï¼Œå› ä¸ºå®ƒéå¸¸å®¹æ˜“ä¸Šæ‰‹ï¼Œè€Œä¸”å®ƒè¿˜èƒ½ä»¥æå¿«çš„é€Ÿåº¦å¤„ç†æ•° GB çš„æ•°æ®ã€‚\nIf you want to use duckdb for a real data analysis project, youâ€™ll also need to supply the dbdir argument to make a persistent database and tell duckdb where to save it.\nå¦‚æœä½ æƒ³åœ¨ä¸€ä¸ªçœŸå®çš„æ•°æ®åˆ†æé¡¹ç›®ä¸­ä½¿ç”¨ duckdbï¼Œä½ è¿˜éœ€è¦æä¾› dbdir å‚æ•°æ¥åˆ›å»ºä¸€ä¸ªæŒä¹…åŒ–æ•°æ®åº“ï¼Œå¹¶å‘Šè¯‰ duckdb å°†å…¶ä¿å­˜åœ¨å“ªé‡Œã€‚\nAssuming youâ€™re using a project (Chapter 6), itâ€™s reasonable to store it in the duckdb directory of the current project:\nå‡è®¾ä½ æ­£åœ¨ä½¿ç”¨ä¸€ä¸ªé¡¹ç›® (Chapter 6)ï¼Œå°†å…¶å­˜å‚¨åœ¨å½“å‰é¡¹ç›®çš„ duckdb ç›®å½•ä¸­æ˜¯åˆç†çš„åšæ³•ï¼š\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), dbdir = \"duckdb\")\n\n\n21.3.2 Load some data\nSince this is a new database, we need to start by adding some data.\nç”±äºè¿™æ˜¯ä¸€ä¸ªæ–°æ•°æ®åº“ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæ·»åŠ ä¸€äº›æ•°æ®ã€‚\nHere weâ€™ll add mpg and diamonds datasets from ggplot2 using DBI::dbWriteTable().\nè¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨ DBI::dbWriteTable() æ·»åŠ æ¥è‡ª ggplot2 çš„ mpg å’Œ diamonds æ•°æ®é›†ã€‚\nThe simplest usage of dbWriteTable() needs three arguments: a database connection, the name of the table to create in the database, and a data frame of data.dbWriteTable() çš„æœ€ç®€å•ç”¨æ³•éœ€è¦ä¸‰ä¸ªå‚æ•°ï¼šä¸€ä¸ªæ•°æ®åº“è¿æ¥ã€è¦åœ¨æ•°æ®åº“ä¸­åˆ›å»ºçš„è¡¨çš„åç§°ï¼Œä»¥åŠä¸€ä¸ªæ•°æ®æ¡†ã€‚\n\ndbWriteTable(con, \"mpg\", ggplot2::mpg)\ndbWriteTable(con, \"diamonds\", ggplot2::diamonds)\n\nIf youâ€™re using duckdb in a real project, we highly recommend learning about duckdb_read_csv() and duckdb_register_arrow().\nå¦‚æœä½ åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨ duckdbï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ å­¦ä¹  duckdb_read_csv() å’Œ duckdb_register_arrow()ã€‚\nThese give you powerful and performant ways to quickly load data directly into duckdb, without having to first load it into R.\nå®ƒä»¬ä¸ºä½ æä¾›äº†å¼ºå¤§è€Œé«˜æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥å¿«é€Ÿå°†æ•°æ®ç›´æ¥åŠ è½½åˆ° duckdb ä¸­ï¼Œè€Œæ— éœ€å…ˆå°†å…¶åŠ è½½åˆ° R ä¸­ã€‚\nWeâ€™ll also show off a useful technique for loading multiple files into a database in Section 26.4.1.\næˆ‘ä»¬è¿˜å°†åœ¨ Section 26.4.1 ä¸­å±•ç¤ºä¸€ä¸ªå°†å¤šä¸ªæ–‡ä»¶åŠ è½½åˆ°æ•°æ®åº“ä¸­çš„å®ç”¨æŠ€å·§ã€‚\n\n21.3.3 DBI basics\nYou can check that the data is loaded correctly by using a couple of other DBI functions: dbListTables() lists all tables in the database3 and dbReadTable() retrieves the contents of a table.\nä½ å¯ä»¥é€šè¿‡ä½¿ç”¨å…¶ä»–å‡ ä¸ª DBI å‡½æ•°æ¥æ£€æŸ¥æ•°æ®æ˜¯å¦å·²æ­£ç¡®åŠ è½½ï¼šdbListTables() åˆ—å‡ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨3ï¼ŒdbReadTable() æ£€ç´¢è¡¨çš„å†…å®¹ã€‚\n\ndbListTables(con)\n#&gt; [1] \"diamonds\" \"mpg\"\n\ncon |&gt; \n  dbReadTable(\"diamonds\") |&gt; \n  as_tibble()\n#&gt; # A tibble: 53,940 Ã— 10\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # â„¹ 53,934 more rows\n\ndbReadTable() returns a data.frame so we use as_tibble() to convert it into a tibble so that it prints nicely.dbReadTable() è¿”å›ä¸€ä¸ª data.frameï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨ as_tibble() å°†å…¶è½¬æ¢ä¸º tibbleï¼Œä»¥ä¾¿æ›´å¥½åœ°æ‰“å°è¾“å‡ºã€‚\nIf you already know SQL, you can use dbGetQuery() to get the results of running a query on the database:\nå¦‚æœä½ å·²ç»äº†è§£ SQLï¼Œä½ å¯ä»¥ä½¿ç”¨ dbGetQuery() æ¥è·å–åœ¨æ•°æ®åº“ä¸Šè¿è¡ŒæŸ¥è¯¢çš„ç»“æœï¼š\n\nsql &lt;- \"\n  SELECT carat, cut, clarity, color, price \n  FROM diamonds \n  WHERE price &gt; 15000\n\"\nas_tibble(dbGetQuery(con, sql))\n#&gt; # A tibble: 1,655 Ã— 5\n#&gt;   carat cut       clarity color price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1  1.54 Premium   VS2     E     15002\n#&gt; 2  1.19 Ideal     VVS1    F     15005\n#&gt; 3  2.1  Premium   SI1     I     15007\n#&gt; 4  1.69 Ideal     SI1     D     15011\n#&gt; 5  1.5  Very Good VVS2    G     15013\n#&gt; 6  1.73 Very Good VS1     G     15014\n#&gt; # â„¹ 1,649 more rows\n\nIf youâ€™ve never seen SQL before, donâ€™t worry!\nå¦‚æœä½ ä»¥å‰æ²¡è§è¿‡ SQLï¼Œåˆ«æ‹…å¿ƒï¼\nYouâ€™ll learn more about it shortly.\nä½ å¾ˆå¿«å°±ä¼šå­¦åˆ°æ›´å¤šå…³äºå®ƒçš„çŸ¥è¯†ã€‚\nBut if you read it carefully, you might guess that it selects five columns of the diamonds dataset and all the rows where price is greater than 15,000.\nä½†æ˜¯å¦‚æœä½ ä»”ç»†é˜…è¯»å®ƒï¼Œä½ å¯èƒ½ä¼šçŒœåˆ°å®ƒä» diamonds æ•°æ®é›†ä¸­é€‰æ‹©äº†äº”åˆ—ï¼Œä»¥åŠæ‰€æœ‰ price å¤§äº 15,000 çš„è¡Œã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#dbplyr-basics",
    "href": "databases.html#dbplyr-basics",
    "title": "21Â  Databases",
    "section": "\n21.4 dbplyr basics",
    "text": "21.4 dbplyr basics\nNow that weâ€™ve connected to a database and loaded up some data, we can start to learn about dbplyr.\nç°åœ¨æˆ‘ä»¬å·²ç»è¿æ¥åˆ°æ•°æ®åº“å¹¶åŠ è½½äº†ä¸€äº›æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å­¦ä¹  dbplyr äº†ã€‚\ndbplyr is a dplyr backend, which means that you keep writing dplyr code but the backend executes it differently.\ndbplyr æ˜¯ä¸€ä¸ª dplyr åç«¯ (backend)ï¼Œè¿™æ„å‘³ç€ä½ ç»§ç»­ç¼–å†™ dplyr ä»£ç ï¼Œä½†åç«¯ä¼šä»¥ä¸åŒçš„æ–¹å¼æ‰§è¡Œå®ƒã€‚\nIn this, dbplyr translates to SQL; other backends include dtplyr which translates to data.table, and multidplyr which executes your code on multiple cores.\nåœ¨è¿™é‡Œï¼Œdbplyr å°†ä»£ç ç¿»è¯‘æˆ SQLï¼›å…¶ä»–åç«¯åŒ…æ‹¬å°†ä»£ç ç¿»è¯‘æˆ data.table çš„ dtplyrï¼Œä»¥åŠåœ¨å¤šä¸ªæ ¸å¿ƒä¸Šæ‰§è¡Œä»£ç çš„ multidplyrã€‚\nTo use dbplyr, you must first use tbl() to create an object that represents a database table:\nè¦ä½¿ç”¨ dbplyrï¼Œä½ å¿…é¡»é¦–å…ˆä½¿ç”¨ tbl() åˆ›å»ºä¸€ä¸ªä»£è¡¨æ•°æ®åº“è¡¨çš„å¯¹è±¡ï¼š\n\ndiamonds_db &lt;- tbl(con, \"diamonds\")\ndiamonds_db\n#&gt; # Source:   table&lt;diamonds&gt; [?? x 10]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # â„¹ more rows\n\n\n\n\n\n\n\nThere are two other common ways to interact with a database.\nä¸æ•°æ®åº“äº¤äº’è¿˜æœ‰å¦å¤–ä¸¤ç§å¸¸è§æ–¹å¼ã€‚\nFirst, many corporate databases are very large so you need some hierarchy to keep all the tables organized.\né¦–å…ˆï¼Œè®¸å¤šä¼ä¸šæ•°æ®åº“éå¸¸åºå¤§ï¼Œå› æ­¤ä½ éœ€è¦æŸç§å±‚çº§ç»“æ„æ¥ä¿æŒæ‰€æœ‰è¡¨çš„æœ‰åºæ€§ã€‚\nIn that case you might need to supply a schema, or a catalog and a schema, in order to pick the table youâ€™re interested in:\nåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½éœ€è¦æä¾›ä¸€ä¸ªæ¨¡å¼ (schema)ï¼Œæˆ–è€…ä¸€ä¸ªç›®å½• (catalog) å’Œä¸€ä¸ªæ¨¡å¼ï¼Œä»¥ä¾¿é€‰æ‹©ä½ æ„Ÿå…´è¶£çš„è¡¨ï¼š\n\ndiamonds_db &lt;- tbl(con, in_schema(\"sales\", \"diamonds\"))\ndiamonds_db &lt;- tbl(con, in_catalog(\"north_america\", \"sales\", \"diamonds\"))\n\nOther times you might want to use your own SQL query as a starting point:\nå…¶ä»–æ—¶å€™ï¼Œä½ å¯èƒ½æƒ³ç”¨è‡ªå·±çš„ SQL æŸ¥è¯¢ä½œä¸ºèµ·ç‚¹ï¼š\n\ndiamonds_db &lt;- tbl(con, sql(\"SELECT * FROM diamonds\"))\n\n\n\n\nThis object is lazy; when you use dplyr verbs on it, dplyr doesnâ€™t do any work: it just records the sequence of operations that you want to perform and only performs them when needed.\nè¿™ä¸ªå¯¹è±¡æ˜¯æƒ°æ€§ (lazy) çš„ï¼›å½“ä½ å¯¹å®ƒä½¿ç”¨ dplyr å‡½æ•°æ—¶ï¼Œdplyr å¹¶ä¸æ‰§è¡Œä»»ä½•å·¥ä½œï¼šå®ƒåªæ˜¯è®°å½•ä¸‹ä½ æƒ³è¦æ‰§è¡Œçš„æ“ä½œåºåˆ—ï¼Œå¹¶ä¸”åªåœ¨éœ€è¦æ—¶æ‰æ‰§è¡Œå®ƒä»¬ã€‚\nFor example, take the following pipeline:\nä¾‹å¦‚ï¼Œçœ‹ä¸‹é¢è¿™ä¸ªç®¡é“ï¼š\n\nbig_diamonds_db &lt;- diamonds_db |&gt; \n  filter(price &gt; 15000) |&gt; \n  select(carat:clarity, price)\n\nbig_diamonds_db\n#&gt; # Source:   SQL [?? x 5]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # â„¹ more rows\n\nYou can tell this object represents a database query because it prints the DBMS name at the top, and while it tells you the number of columns, it typically doesnâ€™t know the number of rows.\nä½ å¯ä»¥çœ‹å‡ºè¿™ä¸ªå¯¹è±¡ä»£è¡¨ä¸€ä¸ªæ•°æ®åº“æŸ¥è¯¢ï¼Œå› ä¸ºå®ƒåœ¨é¡¶éƒ¨æ‰“å°äº† DBMS çš„åç§°ï¼Œè€Œä¸”è™½ç„¶å®ƒå‘Šè¯‰äº†ä½ åˆ—æ•°ï¼Œä½†é€šå¸¸ä¸çŸ¥é“è¡Œæ•°ã€‚\nThis is because finding the total number of rows usually requires executing the complete query, something weâ€™re trying to avoid.\nè¿™æ˜¯å› ä¸ºæŸ¥æ‰¾æ€»è¡Œæ•°é€šå¸¸éœ€è¦æ‰§è¡Œå®Œæ•´çš„æŸ¥è¯¢ï¼Œè€Œè¿™æ­£æ˜¯æˆ‘ä»¬è¯•å›¾é¿å…çš„ã€‚\nYou can see the SQL code generated by the dplyr function show_query().\nä½ å¯ä»¥çœ‹åˆ°ç”± dplyr å‡½æ•° show_query() ç”Ÿæˆçš„ SQL ä»£ç ã€‚\nIf you know dplyr, this is a great way to learn SQL!\nå¦‚æœä½ äº†è§£ dplyrï¼Œè¿™æ˜¯å­¦ä¹  SQL çš„ä¸€ä¸ªå¥½æ–¹æ³•ï¼\nWrite some dplyr code, get dbplyr to translate it to SQL, and then try to figure out how the two languages match up.\nç¼–å†™ä¸€äº› dplyr ä»£ç ï¼Œè®© dbplyr å°†å…¶ç¿»è¯‘æˆ SQLï¼Œç„¶åè¯•ç€å¼„æ¸…æ¥šè¿™ä¸¤ç§è¯­è¨€æ˜¯å¦‚ä½•å¯¹åº”çš„ã€‚\n\nbig_diamonds_db |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT carat, cut, color, clarity, price\n#&gt; FROM diamonds\n#&gt; WHERE (price &gt; 15000.0)\n\nTo get all the data back into R, you call collect().\nè¦å°†æ‰€æœ‰æ•°æ®å–å› R ä¸­ï¼Œä½ å¯ä»¥è°ƒç”¨ collect()ã€‚\nBehind the scenes, this generates the SQL, calls dbGetQuery() to get the data, then turns the result into a tibble:\nåœ¨å¹•åï¼Œè¿™ä¼šç”Ÿæˆ SQLï¼Œè°ƒç”¨ dbGetQuery() è·å–æ•°æ®ï¼Œç„¶åå°†ç»“æœè½¬æ¢ä¸ºä¸€ä¸ª tibbleï¼š\n\nbig_diamonds &lt;- big_diamonds_db |&gt; \n  collect()\nbig_diamonds\n#&gt; # A tibble: 1,655 Ã— 5\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # â„¹ 1,649 more rows\n\nTypically, youâ€™ll use dbplyr to select the data you want from the database, performing basic filtering and aggregation using the translations described below.\né€šå¸¸ï¼Œä½ ä¼šä½¿ç”¨ dbplyr ä»æ•°æ®åº“ä¸­é€‰æ‹©ä½ æƒ³è¦çš„æ•°æ®ï¼Œä½¿ç”¨ä¸‹é¢æè¿°çš„è½¬æ¢æ–¹æ³•æ‰§è¡ŒåŸºæœ¬çš„ç­›é€‰å’Œèšåˆã€‚\nThen, once youâ€™re ready to analyse the data with functions that are unique to R, youâ€™ll collect() the data to get an in-memory tibble, and continue your work with pure R code.\nç„¶åï¼Œå½“ä½ å‡†å¤‡å¥½ä½¿ç”¨ R ç‰¹æœ‰çš„å‡½æ•°åˆ†ææ•°æ®æ—¶ï¼Œä½ ä¼š collect() æ•°æ®ä»¥è·å¾—ä¸€ä¸ªå†…å­˜ä¸­çš„ tibbleï¼Œå¹¶ç»§ç»­ç”¨çº¯ R ä»£ç è¿›è¡Œä½ çš„å·¥ä½œã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sql",
    "href": "databases.html#sql",
    "title": "21Â  Databases",
    "section": "\n21.5 SQL",
    "text": "21.5 SQL\nThe rest of the chapter will teach you a little SQL through the lens of dbplyr.\næœ¬ç« çš„å…¶ä½™éƒ¨åˆ†å°†é€šè¿‡ dbplyr çš„è§†è§’æ•™ä½ ä¸€äº› SQLã€‚\nItâ€™s a rather non-traditional introduction to SQL but we hope it will get you quickly up to speed with the basics.\nè¿™æ˜¯ä¸€ä¸ªç›¸å½“éä¼ ç»Ÿçš„ SQL å…¥é—¨ï¼Œä½†æˆ‘ä»¬å¸Œæœ›å®ƒèƒ½è®©ä½ å¿«é€ŸæŒæ¡åŸºç¡€çŸ¥è¯†ã€‚\nLuckily, if you understand dplyr youâ€™re in a great place to quickly pick up SQL because so many of the concepts are the same.\nå¹¸è¿çš„æ˜¯ï¼Œå¦‚æœä½ ç†è§£ dplyrï¼Œé‚£ä¹ˆä½ å¾ˆå¿«å°±èƒ½å­¦ä¼š SQLï¼Œå› ä¸ºå¾ˆå¤šæ¦‚å¿µæ˜¯ç›¸åŒçš„ã€‚\nWeâ€™ll explore the relationship between dplyr and SQL using a couple of old friends from the nycflights13 package: flights and planes.\næˆ‘ä»¬å°†ä½¿ç”¨ nycflights13 åŒ…ä¸­çš„ä¸¤ä¸ªè€æœ‹å‹ï¼šflights å’Œ planes æ¥æ¢ç´¢ dplyr å’Œ SQL ä¹‹é—´çš„å…³ç³»ã€‚\nThese datasets are easy to get into our learning database because dbplyr comes with a function that copies the tables from nycflights13 to our database:\nè¿™äº›æ•°æ®é›†å¾ˆå®¹æ˜“å¯¼å…¥åˆ°æˆ‘ä»¬çš„å­¦ä¹ æ•°æ®åº“ä¸­ï¼Œå› ä¸º dbplyr æä¾›äº†ä¸€ä¸ªå‡½æ•°ï¼Œå¯ä»¥å°† nycflights13 ä¸­çš„è¡¨å¤åˆ¶åˆ°æˆ‘ä»¬çš„æ•°æ®åº“ä¸­ï¼š\n\ndbplyr::copy_nycflights13(con)\n#&gt; Creating table: airlines\n#&gt; Creating table: airports\n#&gt; Creating table: flights\n#&gt; Creating table: planes\n#&gt; Creating table: weather\nflights &lt;- tbl(con, \"flights\")\nplanes &lt;- tbl(con, \"planes\")\n\n\n21.5.1 SQL basics\nThe top-level components of SQL are called statements.\nSQL çš„é¡¶å±‚ç»„ä»¶è¢«ç§°ä¸ºè¯­å¥ (statements)ã€‚\nCommon statements include CREATE for defining new tables, INSERT for adding data, and SELECT for retrieving data.\nå¸¸è§çš„è¯­å¥åŒ…æ‹¬ç”¨äºå®šä¹‰æ–°è¡¨çš„ CREATEã€ç”¨äºæ·»åŠ æ•°æ®çš„ INSERT ä»¥åŠç”¨äºæ£€ç´¢æ•°æ®çš„ SELECTã€‚\nWe will focus on SELECT statements, also called queries, because they are almost exclusively what youâ€™ll use as a data scientist.\næˆ‘ä»¬å°†ä¸“æ³¨äº SELECT è¯­å¥ï¼Œä¹Ÿç§°ä¸ºæŸ¥è¯¢ (queries)ï¼Œå› ä¸ºå®ƒä»¬å‡ ä¹æ˜¯ä½ ä½œä¸ºæ•°æ®ç§‘å­¦å®¶å”¯ä¸€ä¼šç”¨åˆ°çš„ã€‚\nA query is made up of clauses.\nä¸€ä¸ªæŸ¥è¯¢ç”±å­å¥ (clauses) ç»„æˆã€‚\nThere are five important clauses: SELECT, FROM, WHERE, ORDER BY, and GROUP BY. Every query must have the SELECT4 and FROM5 clauses and the simplest query is SELECT * FROM table, which selects all columns from the specified table . This is what dbplyr generates for an unadulterated table :\næœ‰äº”ä¸ªé‡è¦çš„å­å¥ï¼šSELECTã€FROMã€WHEREã€ORDER BY å’Œ GROUP BYã€‚æ¯ä¸ªæŸ¥è¯¢éƒ½å¿…é¡»æœ‰ SELECT4 å’Œ FROM5 å­å¥ï¼Œæœ€ç®€å•çš„æŸ¥è¯¢æ˜¯ SELECT * FROM tableï¼Œå®ƒä»æŒ‡å®šçš„è¡¨ä¸­é€‰æ‹©æ‰€æœ‰åˆ—ã€‚è¿™æ˜¯ dbplyr ä¸ºä¸€ä¸ªæœªç»å¤„ç†çš„è¡¨ç”Ÿæˆçš„ä»£ç ï¼š\n\nflights |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM flights\nplanes |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM planes\n\nWHERE and ORDER BY control which rows are included and how they are ordered:WHERE å’Œ ORDER BY æ§åˆ¶åŒ…å«å“ªäº›è¡Œä»¥åŠå®ƒä»¬çš„æ’åºæ–¹å¼ï¼š\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  arrange(dep_delay) |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH')\n#&gt; ORDER BY dep_delay\n\nGROUP BY converts the query to a summary, causing aggregation to happen:GROUP BY å°†æŸ¥è¯¢è½¬æ¢ä¸ºæ‘˜è¦ï¼Œä»è€Œè¿›è¡Œèšåˆæ“ä½œï¼š\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(dep_delay = mean(dep_delay, na.rm = TRUE)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT dest, AVG(dep_delay) AS dep_delay\n#&gt; FROM flights\n#&gt; GROUP BY dest\n\nThere are two important differences between dplyr verbs and SELECT clauses:\ndplyr å‡½æ•°å’Œ SELECT å­å¥ä¹‹é—´æœ‰ä¸¤ä¸ªé‡è¦åŒºåˆ«ï¼š\n\nIn SQL, case doesnâ€™t matter: you can write select, SELECT, or even SeLeCt. In this book weâ€™ll stick with the common convention of writing SQL keywords in uppercase to distinguish them from table or variables names.\nåœ¨ SQL ä¸­ï¼Œå¤§å°å†™ä¸é‡è¦ï¼šä½ å¯ä»¥å†™ selectã€SELECTï¼Œç”šè‡³ SeLeCtã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬å°†éµå¾ªé€šå¸¸çš„æƒ¯ä¾‹ï¼Œç”¨å¤§å†™å­—æ¯ä¹¦å†™ SQL å…³é”®å­—ï¼Œä»¥åŒºåˆ«äºè¡¨æˆ–å˜é‡åã€‚\nIn SQL, order matters: you must always write the clauses in the order SELECT, FROM, WHERE, GROUP BY, ORDER BY. Confusingly, this order doesnâ€™t match how the clauses are actually evaluated which is first FROM, then WHERE, GROUP BY, SELECT, and ORDER BY.\nåœ¨ SQL ä¸­ï¼Œé¡ºåºå¾ˆé‡è¦ï¼šä½ å¿…é¡»å§‹ç»ˆæŒ‰ SELECTã€FROMã€WHEREã€GROUP BYã€ORDER BY çš„é¡ºåºç¼–å†™å­å¥ã€‚ä»¤äººå›°æƒ‘çš„æ˜¯ï¼Œè¿™ä¸ªé¡ºåºä¸å­å¥çš„å®é™…æ±‚å€¼é¡ºåºä¸åŒ¹é…ï¼Œå®é™…é¡ºåºæ˜¯å…ˆ FROMï¼Œç„¶åæ˜¯ WHEREã€GROUP BYã€SELECT å’Œ ORDER BYã€‚\n\nThe following sections explore each clause in more detail.\nä»¥ä¸‹å„èŠ‚å°†æ›´è¯¦ç»†åœ°æ¢è®¨æ¯ä¸ªå­å¥ã€‚\n\n\n\n\n\n\nNote that while SQL is a standard, it is extremely complex and no database follows it exactly.\nè¯·æ³¨æ„ï¼Œè™½ç„¶ SQL æ˜¯ä¸€ä¸ªæ ‡å‡†ï¼Œä½†å®ƒæå…¶å¤æ‚ï¼Œæ²¡æœ‰å“ªä¸ªæ•°æ®åº“èƒ½å®Œå…¨éµå¾ªå®ƒã€‚\nWhile the main components that weâ€™ll focus on in this book are very similar between DBMSâ€™s, there are many minor variations.\nè™½ç„¶æœ¬ä¹¦ä¸­æˆ‘ä»¬å…³æ³¨çš„ä¸»è¦ç»„æˆéƒ¨åˆ†åœ¨ä¸åŒ DBMS ä¹‹é—´éå¸¸ç›¸ä¼¼ï¼Œä½†å­˜åœ¨è®¸å¤šç»†å¾®çš„å·®å¼‚ã€‚\nFortunately, dbplyr is designed to handle this problem and generates different translations for different databases.\nå¹¸è¿çš„æ˜¯ï¼Œdbplyr æ—¨åœ¨å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œå¹¶ä¸ºä¸åŒçš„æ•°æ®åº“ç”Ÿæˆä¸åŒçš„ç¿»è¯‘ã€‚\nItâ€™s not perfect, but itâ€™s continually improving, and if you hit a problem you can file an issue on GitHub to help us do better.\nå®ƒå¹¶ä¸å®Œç¾ï¼Œä½†å®ƒåœ¨ä¸æ–­æ”¹è¿›ï¼Œå¦‚æœä½ é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥åœ¨ GitHub ä¸Šæäº¤ä¸€ä¸ª issueï¼Œå¸®åŠ©æˆ‘ä»¬åšå¾—æ›´å¥½ã€‚\n\n\n\n\n21.5.2 SELECT\nThe SELECT clause is the workhorse of queries and performs the same job as select(), mutate(), rename(), relocate(), and, as youâ€™ll learn in the next section, summarize().SELECT å­å¥æ˜¯æŸ¥è¯¢çš„ä¸»åŠ›ï¼Œå®ƒæ‰§è¡Œä¸ select()ã€mutate()ã€rename()ã€relocate() ç›¸åŒçš„å·¥ä½œï¼Œå¹¶ä¸”ï¼Œæ­£å¦‚ä½ å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­å­¦åˆ°çš„ï¼Œè¿˜åŒ…æ‹¬ summarize()ã€‚\nselect(), rename(), and relocate() have very direct translations to SELECT as they just affect where a column appears (if at all) along with its name:select()ã€rename() å’Œ relocate() ä¸ SELECT æœ‰éå¸¸ç›´æ¥çš„è½¬æ¢å…³ç³»ï¼Œå› ä¸ºå®ƒä»¬åªå½±å“åˆ—å‡ºç°çš„ä½ç½®ï¼ˆå¦‚æœå‡ºç°çš„è¯ï¼‰åŠå…¶åç§°ï¼š\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\"\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  rename(year_built = year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\" AS year_built\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  relocate(manufacturer, model, .before = type) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, manufacturer, model, \"type\", \"year\"\n#&gt; FROM planes\n\nThis example also shows you how SQL does renaming.\nè¿™ä¸ªä¾‹å­ä¹Ÿå‘ä½ å±•ç¤ºäº† SQL å¦‚ä½•è¿›è¡Œé‡å‘½åã€‚\nIn SQL terminology renaming is called aliasing and is done with AS.\nåœ¨ SQL æœ¯è¯­ä¸­ï¼Œé‡å‘½åè¢«ç§°ä¸ºåˆ«å (aliasing)ï¼Œå¹¶ä½¿ç”¨ AS æ¥å®Œæˆã€‚\nNote that unlike mutate(), the old name is on the left and the new name is on the right.\nè¯·æ³¨æ„ï¼Œä¸ mutate() ä¸åŒï¼Œæ—§åç§°åœ¨å·¦è¾¹ï¼Œæ–°åç§°åœ¨å³è¾¹ã€‚\n\n\n\n\n\n\nIn the examples above note that \"year\" and \"type\" are wrapped in double quotes.\nåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œè¯·æ³¨æ„ \"year\" å’Œ \"type\" è¢«åŒå¼•å·åŒ…è£¹ç€ã€‚\nThatâ€™s because these are reserved words in duckdb, so dbplyr quotes them to avoid any potential confusion between column/table names and SQL operators.\nè¿™æ˜¯å› ä¸ºå®ƒä»¬åœ¨ duckdb ä¸­æ˜¯ä¿ç•™å­— (reserved words)ï¼Œæ‰€ä»¥ dbplyr ç»™å®ƒä»¬åŠ ä¸Šå¼•å·ï¼Œä»¥é¿å…åˆ—/è¡¨åä¸ SQL æ“ä½œç¬¦ä¹‹é—´å¯èƒ½äº§ç”Ÿçš„æ··æ·†ã€‚\nWhen working with other databases youâ€™re likely to see every variable name quoted because only a handful of client packages, like duckdb, know what all the reserved words are, so they quote everything to be safe.\nåœ¨ä½¿ç”¨å…¶ä»–æ•°æ®åº“æ—¶ï¼Œä½ å¾ˆå¯èƒ½ä¼šçœ‹åˆ°æ¯ä¸ªå˜é‡åéƒ½è¢«å¼•èµ·æ¥ï¼Œå› ä¸ºåªæœ‰å°‘æ•°å®¢æˆ·ç«¯åŒ…ï¼ˆå¦‚ duckdbï¼‰çŸ¥é“æ‰€æœ‰çš„ä¿ç•™å­—æ˜¯ä»€ä¹ˆï¼Œæ‰€ä»¥å®ƒä»¬ä¸ºäº†å®‰å…¨èµ·è§ä¼šå¼•ç”¨æ‰€æœ‰å†…å®¹ã€‚\nSELECT \"tailnum\", \"type\", \"manufacturer\", \"model\", \"year\"\nFROM \"planes\"\nSome other database systems use backticks instead of quotes:\nå…¶ä»–ä¸€äº›æ•°æ®åº“ç³»ç»Ÿä½¿ç”¨åå¼•å·è€Œä¸æ˜¯å¼•å·ï¼š\nSELECT `tailnum`, `type`, `manufacturer`, `model`, `year`\nFROM `planes`\n\n\n\nThe translations for mutate() are similarly straightforward: each variable becomes a new expression in SELECT:mutate() çš„è½¬æ¢åŒæ ·ç›´æ¥ï¼šæ¯ä¸ªå˜é‡éƒ½æˆä¸º SELECT ä¸­çš„ä¸€ä¸ªæ–°è¡¨è¾¾å¼ï¼š\n\nflights |&gt; \n  mutate(\n    speed = distance / (air_time / 60)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*, distance / (air_time / 60.0) AS speed\n#&gt; FROM flights\n\nWeâ€™ll come back to the translation of individual components (like /) in Section 21.6.\næˆ‘ä»¬å°†åœ¨ Section 21.6 ä¸­å›è¿‡å¤´æ¥è®¨è®ºå•ä¸ªç»„ä»¶ï¼ˆå¦‚ /ï¼‰çš„ç¿»è¯‘ã€‚\n\n21.5.3 FROM\nThe FROM clause defines the data source. Itâ€™s going to be rather uninteresting for a little while, because weâ€™re just using single tables. Youâ€™ll see more complex examples once we hit the join functions.FROM å­å¥å®šä¹‰äº†æ•°æ®æºã€‚åœ¨ä¸€æ®µæ—¶é—´å†…ï¼Œå®ƒä¼šæ˜¾å¾—ç›¸å½“æ— è¶£ï¼Œå› ä¸ºæˆ‘ä»¬åªä½¿ç”¨å•ä¸ªè¡¨ã€‚ä¸€æ—¦æˆ‘ä»¬æ¥è§¦åˆ°è¿æ¥å‡½æ•°ï¼Œä½ å°†ä¼šçœ‹åˆ°æ›´å¤æ‚çš„ä¾‹å­ã€‚\n\n21.5.4 GROUP BY\ngroup_by() is translated to the GROUP BY6 clause and summarize() is translated to the SELECT clause:group_by() è¢«ç¿»è¯‘ä¸º GROUP BY6 å­å¥ï¼Œè€Œ summarize() è¢«ç¿»è¯‘ä¸º SELECT å­å¥ï¼š\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(\n    n = n(),\n    avg_price = mean(price, na.rm = TRUE)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n, AVG(price) AS avg_price\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n\nWeâ€™ll come back to whatâ€™s happening with the translation of n() and mean() in Section 21.6.\næˆ‘ä»¬å°†åœ¨ Section 21.6 å›è¿‡å¤´æ¥è®¨è®º n() å’Œ mean() çš„ç¿»è¯‘å‘ç”Ÿäº†ä»€ä¹ˆã€‚\n\n21.5.5 WHERE\nfilter() is translated to the WHERE clause:filter() è¢«ç¿»è¯‘ä¸º WHERE å­å¥ï¼š\n\nflights |&gt; \n  filter(dest == \"IAH\" | dest == \"HOU\") |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH' OR dest = 'HOU')\n\nflights |&gt; \n  filter(arr_delay &gt; 0 & arr_delay &lt; 20) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (arr_delay &gt; 0.0 AND arr_delay &lt; 20.0)\n\nThere are a few important details to note here:\nè¿™é‡Œæœ‰å‡ ä¸ªé‡è¦çš„ç»†èŠ‚éœ€è¦æ³¨æ„ï¼š\n\n| becomes OR and & becomes AND.| å˜æˆ ORï¼Œ& å˜æˆ ANDã€‚\nSQL uses = for comparison, not ==. SQL doesnâ€™t have assignment, so thereâ€™s no potential for confusion there.\nSQL ä½¿ç”¨ = è¿›è¡Œæ¯”è¾ƒï¼Œè€Œä¸æ˜¯ ==ã€‚SQL æ²¡æœ‰èµ‹å€¼æ“ä½œï¼Œæ‰€ä»¥ä¸å­˜åœ¨æ··æ·†çš„å¯èƒ½ã€‚\nSQL uses only '' for strings, not \"\". In SQL, \"\" is used to identify variables, like Râ€™s ``.\nSQL åªç”¨ '' è¡¨ç¤ºå­—ç¬¦ä¸²ï¼Œè€Œä¸ç”¨ \"\"ã€‚åœ¨ SQL ä¸­ï¼Œ\"\" ç”¨äºæ ‡è¯†å˜é‡ï¼Œå°±åƒ R ä¸­çš„ `` ä¸€æ ·ã€‚\n\nAnother useful SQL operator is IN, which is very close to Râ€™s %in%:\nå¦ä¸€ä¸ªæœ‰ç”¨çš„ SQL è¿ç®—ç¬¦æ˜¯ INï¼Œå®ƒä¸ R çš„ %in% éå¸¸æ¥è¿‘ï¼š\n\nflights |&gt; \n  filter(dest %in% c(\"IAH\", \"HOU\")) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest IN ('IAH', 'HOU'))\n\nSQL uses NULL instead of NA. NULLs behave similarly to NAs. The main difference is that while theyâ€™re â€œinfectiousâ€ in comparisons and arithmetic, they are silently dropped when summarizing. dbplyr will remind you about this behavior the first time you hit it:\nSQL ä½¿ç”¨ NULL è€Œä¸æ˜¯ NAã€‚NULL çš„è¡Œä¸ºä¸ NA ç±»ä¼¼ã€‚ä¸»è¦åŒºåˆ«åœ¨äºï¼Œè™½ç„¶å®ƒä»¬åœ¨æ¯”è¾ƒå’Œç®—æœ¯è¿ç®—ä¸­å…·æœ‰â€œä¼ æŸ“æ€§â€ï¼Œä½†åœ¨æ±‡æ€»æ—¶ä¼šè¢«é™é»˜åœ°ä¸¢å¼ƒã€‚dbplyr åœ¨ä½ ç¬¬ä¸€æ¬¡é‡åˆ°è¿™ç§æƒ…å†µæ—¶ä¼šæé†’ä½ è¿™ä¸ªè¡Œä¸ºï¼š\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(delay = mean(arr_delay))\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;   dest  delay\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 MSY    6.49\n#&gt; 2 XNA    7.47\n#&gt; 3 ORF   10.9 \n#&gt; 4 ROC   11.6 \n#&gt; 5 ABQ    4.38\n#&gt; 6 LGA   NA   \n#&gt; # â„¹ more rows\n\nIf you want to learn more about how NULLs work, you might enjoy â€œThe Three-Valued Logic of SQLâ€ by Markus Winand.\nå¦‚æœä½ æƒ³æ›´å¤šåœ°äº†è§£ NULL çš„å·¥ä½œåŸç†ï¼Œä½ å¯èƒ½ä¼šå–œæ¬¢ Markus Winand çš„ã€ŠSQL çš„ä¸‰å€¼é€»è¾‘ã€‹ã€‚\nIn general, you can work with NULLs using the functions youâ€™d use for NAs in R:\né€šå¸¸ï¼Œä½ å¯ä»¥ä½¿ç”¨åœ¨ R ä¸­å¤„ç† NA çš„å‡½æ•°æ¥å¤„ç† NULLï¼š\n\nflights |&gt; \n  filter(!is.na(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (NOT((dep_delay IS NULL)))\n\nThis SQL query illustrates one of the drawbacks of dbplyr: while the SQL is correct, it isnâ€™t as simple as you might write by hand. In this case, you could drop the parentheses and use a special operator thatâ€™s easier to read:\nè¿™ä¸ª SQL æŸ¥è¯¢æ­ç¤ºäº† dbplyr çš„ä¸€ä¸ªç¼ºç‚¹ï¼šè™½ç„¶ SQL æ˜¯æ­£ç¡®çš„ï¼Œä½†å®ƒä¸åƒä½ æ‰‹å†™çš„é‚£æ ·ç®€æ´ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å»æ‰æ‹¬å·ï¼Œä½¿ç”¨ä¸€ä¸ªæ›´æ˜“è¯»çš„ç‰¹æ®Šè¿ç®—ç¬¦ï¼š\nWHERE \"dep_delay\" IS NOT NULL\nNote that if you filter() a variable that you created using a summarize, dbplyr will generate a HAVING clause, rather than a WHERE clause. This is a one of the idiosyncrasies of SQL: WHERE is evaluated before SELECT and GROUP BY, so SQL needs another clause thatâ€™s evaluated afterwards.\nè¯·æ³¨æ„ï¼Œå¦‚æœä½ å¯¹ä½¿ç”¨ summarize åˆ›å»ºçš„å˜é‡è¿›è¡Œ filter()ï¼Œdbplyr å°†ç”Ÿæˆ HAVING å­å¥ï¼Œè€Œä¸æ˜¯ WHERE å­å¥ã€‚è¿™æ˜¯ SQL çš„ä¸€ä¸ªç‰¹æ€§ï¼šWHERE åœ¨ SELECT å’Œ GROUP BY ä¹‹å‰è¢«è¯„ä¼°ï¼Œæ‰€ä»¥ SQL éœ€è¦å¦ä¸€ä¸ªåœ¨ä¹‹åè¯„ä¼°çš„å­å¥ã€‚\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(n = n()) |&gt; \n  filter(n &gt; 100) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n#&gt; HAVING (COUNT(*) &gt; 100.0)\n\n\n21.5.6 ORDER BY\nOrdering rows involves a straightforward translation from arrange() to the ORDER BY clause:\nå¯¹è¡Œè¿›è¡Œæ’åºï¼Œæ¶‰åŠä» arrange() åˆ° ORDER BY å­å¥çš„ç›´æ¥ç¿»è¯‘ï¼š\n\nflights |&gt; \n  arrange(year, month, day, desc(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; ORDER BY \"year\", \"month\", \"day\", dep_delay DESC\n\nNotice how desc() is translated to DESC: this is one of the many dplyr functions whose name was directly inspired by SQL.\næ³¨æ„ desc() æ˜¯å¦‚ä½•è¢«ç¿»è¯‘æˆ DESC çš„ï¼šè¿™æ˜¯ä¼—å¤šç›´æ¥å— SQL å¯å‘çš„ dplyr å‡½æ•°ä¹‹ä¸€ã€‚\n\n21.5.7 Subqueries\nSometimes itâ€™s not possible to translate a dplyr pipeline into a single SELECT statement and you need to use a subquery. A subquery is just a query used as a data source in the FROM clause, instead of the usual table.\næœ‰æ—¶ï¼Œæ— æ³•å°†ä¸€ä¸ª dplyr ç®¡é“ç¿»è¯‘æˆå•ä¸ª SELECT è¯­å¥ï¼Œè¿™æ—¶ä½ éœ€è¦ä½¿ç”¨å­æŸ¥è¯¢ã€‚å­æŸ¥è¯¢ (subquery) å°±æ˜¯ä¸€ä¸ªåœ¨ FROM å­å¥ä¸­ç”¨ä½œæ•°æ®æºçš„æŸ¥è¯¢ï¼Œè€Œä¸æ˜¯é€šå¸¸çš„è¡¨ã€‚\ndbplyr typically uses subqueries to work around limitations of SQL. For example, expressions in the SELECT clause canâ€™t refer to columns that were just created. That means that the following (silly) dplyr pipeline needs to happen in two steps: the first (inner) query computes year1 and then the second (outer) query can compute year2.\ndbplyr é€šå¸¸ä½¿ç”¨å­æŸ¥è¯¢æ¥è§„é¿ SQL çš„é™åˆ¶ã€‚ä¾‹å¦‚ï¼ŒSELECT å­å¥ä¸­çš„è¡¨è¾¾å¼ä¸èƒ½å¼•ç”¨åˆšåˆšåˆ›å»ºçš„åˆ—ã€‚è¿™æ„å‘³ç€ä¸‹é¢è¿™ä¸ªï¼ˆæœ‰ç‚¹å‚»çš„ï¼‰dplyr ç®¡é“éœ€è¦åˆ†ä¸¤æ­¥è¿›è¡Œï¼šç¬¬ä¸€æ­¥ï¼ˆå†…éƒ¨ï¼‰æŸ¥è¯¢è®¡ç®—å‡º year1ï¼Œç„¶åç¬¬äºŒæ­¥ï¼ˆå¤–éƒ¨ï¼‰æŸ¥è¯¢æ‰èƒ½è®¡ç®—å‡º year2ã€‚\n\nflights |&gt; \n  mutate(\n    year1 = year + 1,\n    year2 = year1 + 1\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*, year1 + 1.0 AS year2\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n\nYouâ€™ll also see this if you attempted to filter() a variable that you just created. Remember, even though WHERE is written after SELECT, itâ€™s evaluated before it, so we need a subquery in this (silly) example:\nå¦‚æœä½ è¯•å›¾å¯¹ä¸€ä¸ªåˆšåˆšåˆ›å»ºçš„å˜é‡è¿›è¡Œ filter()ï¼Œä½ ä¹Ÿä¼šçœ‹åˆ°è¿™ç§æƒ…å†µã€‚è®°ä½ï¼Œå°½ç®¡ WHERE å†™åœ¨ SELECT ä¹‹åï¼Œä½†å®ƒæ˜¯åœ¨ SELECT ä¹‹å‰è¢«è¯„ä¼°çš„ï¼Œæ‰€ä»¥åœ¨è¿™ä¸ªï¼ˆæœ‰ç‚¹å‚»çš„ï¼‰ä¾‹å­ä¸­æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå­æŸ¥è¯¢ï¼š\n\nflights |&gt; \n  mutate(year1 = year + 1) |&gt; \n  filter(year1 == 2014) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n#&gt; WHERE (year1 = 2014.0)\n\nSometimes dbplyr will create a subquery where itâ€™s not needed because it doesnâ€™t yet know how to optimize that translation. As dbplyr improves over time, these cases will get rarer but will probably never go away.\næœ‰æ—¶ dbplyr ä¼šåœ¨ä¸éœ€è¦çš„æƒ…å†µä¸‹åˆ›å»ºä¸€ä¸ªå­æŸ¥è¯¢ï¼Œå› ä¸ºå®ƒè¿˜ä¸çŸ¥é“å¦‚ä½•ä¼˜åŒ–è¯¥ç¿»è¯‘ã€‚éšç€ dbplyr çš„ä¸æ–­æ”¹è¿›ï¼Œè¿™äº›æƒ…å†µä¼šè¶Šæ¥è¶Šå°‘ï¼Œä½†å¯èƒ½æ°¸è¿œä¸ä¼šå®Œå…¨æ¶ˆå¤±ã€‚\n\n21.5.8 Joins\nIf youâ€™re familiar with dplyrâ€™s joins, SQL joins are very similar. Hereâ€™s a simple example:\nå¦‚æœä½ ç†Ÿæ‚‰ dplyr çš„è¿æ¥ (joins)ï¼ŒSQL çš„è¿æ¥éå¸¸ç›¸ä¼¼ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š\n\nflights |&gt; \n  left_join(planes |&gt; rename(year_built = year), join_by(tailnum)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   flights.*,\n#&gt;   planes.\"year\" AS year_built,\n#&gt;   \"type\",\n#&gt;   manufacturer,\n#&gt;   model,\n#&gt;   engines,\n#&gt;   seats,\n#&gt;   speed,\n#&gt;   engine\n#&gt; FROM flights\n#&gt; LEFT JOIN planes\n#&gt;   ON (flights.tailnum = planes.tailnum)\n\nThe main thing to notice here is the syntax: SQL joins use sub-clauses of the FROM clause to bring in additional tables, using ON to define how the tables are related.\nè¿™é‡Œä¸»è¦è¦æ³¨æ„çš„æ˜¯è¯­æ³•ï¼šSQL è¿æ¥ä½¿ç”¨ FROM å­å¥çš„å­å¥æ¥å¼•å…¥é¢å¤–çš„è¡¨ï¼Œå¹¶ä½¿ç”¨ ON æ¥å®šä¹‰è¡¨ä¹‹é—´çš„å…³ç³»ã€‚\ndplyrâ€™s names for these functions are so closely connected to SQL that you can easily guess the equivalent SQL for inner_join(), right_join(), and full_join():\ndplyr ä¸­è¿™äº›å‡½æ•°çš„åç§°ä¸ SQL ç´§å¯†ç›¸å…³ï¼Œå› æ­¤ä½ å¯ä»¥è½»æ¾çŒœå‡º inner_join()ã€right_join() å’Œ full_join() çš„ç­‰æ•ˆ SQLï¼š\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nINNER JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nRIGHT JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nFULL JOIN planes ON (flights.tailnum = planes.tailnum)\nYouâ€™re likely to need many joins when working with data from a database. Thatâ€™s because database tables are often stored in a highly normalized form, where each â€œfactâ€ is stored in a single place and to keep a complete dataset for analysis you need to navigate a complex network of tables connected by primary and foreign keys. If you hit this scenario, the dm package, by Tobias Schieferdecker, Kirill MÃ¼ller, and Darko Bergant, is a life saver. It can automatically determine the connections between tables using the constraints that DBAs often supply, visualize the connections so you can see whatâ€™s going on, and generate the joins you need to connect one table to another.\nå½“å¤„ç†æ•°æ®åº“ä¸­çš„æ•°æ®æ—¶ï¼Œä½ å¾ˆå¯èƒ½éœ€è¦è¿›è¡Œå¤šæ¬¡è¿æ¥ã€‚è¿™æ˜¯å› ä¸ºæ•°æ®åº“è¡¨é€šå¸¸ä»¥é«˜åº¦è§„èŒƒåŒ–çš„å½¢å¼å­˜å‚¨ï¼Œæ¯ä¸ªâ€œäº‹å®â€éƒ½å­˜å‚¨åœ¨å•ä¸€ä½ç½®ï¼Œä¸ºäº†è¿›è¡Œåˆ†æè€Œå¾—åˆ°ä¸€ä¸ªå®Œæ•´çš„æ•°æ®é›†ï¼Œä½ éœ€è¦åœ¨ä¸€ä¸ªç”±ä¸»é”®å’Œå¤–é”®è¿æ¥çš„å¤æ‚è¡¨ç½‘ç»œä¸­ç©¿æ¢­ã€‚å¦‚æœä½ é‡åˆ°è¿™ç§æƒ…å†µï¼Œç”± Tobias Schieferdeckerã€Kirill MÃ¼ller å’Œ Darko Bergant å¼€å‘çš„ dm åŒ… å°†æ˜¯ä½ çš„æ•‘æ˜Ÿã€‚å®ƒå¯ä»¥åˆ©ç”¨æ•°æ®åº“ç®¡ç†å‘˜ï¼ˆDBAï¼‰é€šå¸¸æä¾›çš„çº¦æŸè‡ªåŠ¨ç¡®å®šè¡¨ä¹‹é—´çš„è¿æ¥ï¼Œå°†è¿æ¥å¯è§†åŒ–ä»¥ä¾¿ä½ äº†è§£æƒ…å†µï¼Œå¹¶ç”Ÿæˆè¿æ¥ä¸€ä¸ªè¡¨åˆ°å¦ä¸€ä¸ªè¡¨æ‰€éœ€çš„è¿æ¥æ“ä½œã€‚\n\n21.5.9 Other verbs\ndbplyr also translates other verbs like distinct(), slice_*(), and intersect(), and a growing selection of tidyr functions like pivot_longer() and pivot_wider(). The easiest way to see the full set of whatâ€™s currently available is to visit the dbplyr website: https://dbplyr.tidyverse.org/reference/.\ndbplyr è¿˜å¯ä»¥ç¿»è¯‘å…¶ä»–åŠ¨è¯ï¼Œå¦‚ distinct()ã€slice_*() å’Œ intersect()ï¼Œä»¥åŠè¶Šæ¥è¶Šå¤šçš„ tidyr å‡½æ•°ï¼Œå¦‚ pivot_longer() å’Œ pivot_wider()ã€‚è¦æŸ¥çœ‹å½“å‰æ‰€æœ‰å¯ç”¨åŠŸèƒ½çš„å®Œæ•´åˆ—è¡¨ï¼Œæœ€ç®€å•çš„æ–¹æ³•æ˜¯è®¿é—® dbplyr ç½‘ç«™ï¼šhttps://dbplyr.tidyverse.org/reference/ã€‚\n\n21.5.10 Exercises\n\nWhat is distinct() translated to? How about head()?\n\nExplain what each of the following SQL queries do and try recreate them using dbplyr.\nSELECT \\* \nFROM flights\nWHERE dep_delay \\&lt; arr_delay\n\nSELECT \\*, distance / (air_time / 60) AS speed\nFROM flights",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-sql-expressions",
    "href": "databases.html#sec-sql-expressions",
    "title": "21Â  Databases",
    "section": "\n21.6 Function translations",
    "text": "21.6 Function translations\nSo far weâ€™ve focused on the big picture of how dplyr verbs are translated to the clauses of a query. Now weâ€™re going to zoom in a little and talk about the translation of the R functions that work with individual columns, e.g., what happens when you use mean(x) in a summarize()?\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨äº† dplyr åŠ¨è¯å¦‚ä½•è¢«ç¿»è¯‘æˆæŸ¥è¯¢å­å¥çš„å®è§‚å±‚é¢ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†ç¨å¾®æ·±å…¥ä¸€äº›ï¼Œè®¨è®ºå¤„ç†å•ä¸ªåˆ—çš„ R å‡½æ•°çš„ç¿»è¯‘ï¼Œä¾‹å¦‚ï¼Œå½“ä½ åœ¨ summarize() ä¸­ä½¿ç”¨ mean(x) æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\nTo help see whatâ€™s going on, weâ€™ll use a couple of little helper functions that run a summarize() or mutate() and show the generated SQL. That will make it a little easier to explore a few variations and see how summaries and transformations can differ.\nä¸ºäº†å¸®åŠ©ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å‡ ä¸ªå°è¾…åŠ©å‡½æ•°ï¼Œå®ƒä»¬ä¼šè¿è¡Œä¸€ä¸ª summarize() æˆ– mutate() å¹¶æ˜¾ç¤ºç”Ÿæˆçš„ SQLã€‚è¿™å°†ä½¿æˆ‘ä»¬æ›´å®¹æ˜“æ¢ç´¢ä¸€äº›å˜åŒ–ï¼Œå¹¶è§‚å¯Ÿæ±‡æ€»å’Œè½¬æ¢æœ‰ä½•ä¸åŒã€‚\n\nsummarize_query &lt;- function(df, ...) {\n  df |&gt; \n    summarize(...) |&gt; \n    show_query()\n}\nmutate_query &lt;- function(df, ...) {\n  df |&gt; \n    mutate(..., .keep = \"none\") |&gt; \n    show_query()\n}\n\nLetâ€™s dive in with some summaries! Looking at the code below youâ€™ll notice that some summary functions, like mean(), have a relatively simple translation while others, like median(), are much more complex. The complexity is typically higher for operations that are common in statistics but less common in databases.\nè®©æˆ‘ä»¬ä»ä¸€äº›æ±‡æ€»æ“ä½œå¼€å§‹å§ï¼çœ‹ä¸‹é¢çš„ä»£ç ï¼Œä½ ä¼šæ³¨æ„åˆ°ä¸€äº›æ±‡æ€»å‡½æ•°ï¼Œæ¯”å¦‚ mean()ï¼Œå…¶ç¿»è¯‘ç›¸å¯¹ç®€å•ï¼Œè€Œå¦ä¸€äº›ï¼Œæ¯”å¦‚ median()ï¼Œåˆ™è¦å¤æ‚å¾—å¤šã€‚å¯¹äºåœ¨ç»Ÿè®¡å­¦ä¸­å¸¸è§ä½†åœ¨æ•°æ®åº“ä¸­ä¸å¤ªå¸¸è§çš„æ“ä½œï¼Œå…¶å¤æ‚æ€§é€šå¸¸æ›´é«˜ã€‚\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  summarize_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n    median = median(arr_delay, na.rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by \"year\" and \"month\". You can override\n#&gt; using the `.groups` argument.\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) AS mean,\n#&gt;   MEDIAN(arr_delay) AS median\n#&gt; FROM flights\n#&gt; GROUP BY \"year\", \"month\", \"day\"\n\nThe translation of summary functions becomes more complicated when you use them inside a mutate() because they have to turn into so-called window functions. In SQL, you turn an ordinary aggregation function into a window function by adding OVER after it:\nå½“ä½ åœ¨ mutate() ä¸­ä½¿ç”¨æ±‡æ€»å‡½æ•°æ—¶ï¼Œå®ƒä»¬çš„ç¿»è¯‘ä¼šå˜å¾—æ›´åŠ å¤æ‚ï¼Œå› ä¸ºå®ƒä»¬å¿…é¡»è½¬æ¢æˆæ‰€è°“çš„çª—å£ (window) å‡½æ•°ã€‚åœ¨ SQL ä¸­ï¼Œä½ é€šè¿‡åœ¨æ™®é€šèšåˆå‡½æ•°åæ·»åŠ  OVER æ¥å°†å…¶è½¬æ¢ä¸ºçª—å£å‡½æ•°ï¼š\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  mutate_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) OVER (PARTITION BY \"year\", \"month\", \"day\") AS mean\n#&gt; FROM flights\n\nIn SQL, the GROUP BY clause is used exclusively for summaries so here you can see that the grouping has moved from the GROUP BY clause to OVER.\nåœ¨ SQL ä¸­ï¼ŒGROUP BY å­å¥ä¸“ç”¨äºæ±‡æ€»ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°åˆ†ç»„å·²ç»ä» GROUP BY å­å¥ç§»åˆ°äº† OVER ä¸­ã€‚\nWindow functions include all functions that look forward or backwards, like lead() and lag() which look at the â€œpreviousâ€ or â€œnextâ€ value respectively:\nçª—å£å‡½æ•°åŒ…æ‹¬æ‰€æœ‰å‘å‰æˆ–å‘åçœ‹çš„å‡½æ•°ï¼Œä¾‹å¦‚ lead() å’Œ lag()ï¼Œå®ƒä»¬åˆ†åˆ«æŸ¥çœ‹â€œå‰ä¸€ä¸ªâ€æˆ–â€œåä¸€ä¸ªâ€å€¼ï¼š\n\nflights |&gt; \n  group_by(dest) |&gt;  \n  arrange(time_hour) |&gt; \n  mutate_query(\n    lead = lead(arr_delay),\n    lag = lag(arr_delay)\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   dest,\n#&gt;   LEAD(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lead,\n#&gt;   LAG(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lag\n#&gt; FROM flights\n#&gt; ORDER BY time_hour\n\nHere itâ€™s important to arrange() the data, because SQL tables have no intrinsic order. In fact, if you donâ€™t use arrange() you might get the rows back in a different order every time! Notice for window functions, the ordering information is repeated: the ORDER BY clause of the main query doesnâ€™t automatically apply to window functions.\nåœ¨è¿™é‡Œï¼Œå¯¹æ•°æ®è¿›è¡Œ arrange() å¾ˆé‡è¦ï¼Œå› ä¸º SQL è¡¨æ²¡æœ‰å›ºæœ‰çš„é¡ºåºã€‚äº‹å®ä¸Šï¼Œå¦‚æœä½ ä¸ä½¿ç”¨ arrange()ï¼Œæ¯æ¬¡è¿”å›çš„è¡Œé¡ºåºå¯èƒ½éƒ½ä¸åŒï¼æ³¨æ„ï¼Œå¯¹äºçª—å£å‡½æ•°ï¼Œæ’åºä¿¡æ¯æ˜¯é‡å¤çš„ï¼šä¸»æŸ¥è¯¢çš„ ORDER BY å­å¥ä¸ä¼šè‡ªåŠ¨åº”ç”¨äºçª—å£å‡½æ•°ã€‚\nAnother important SQL function is CASE WHEN. Itâ€™s used as the translation of if_else() and case_when(), the dplyr function that it directly inspired. Here are a couple of simple examples:\nå¦ä¸€ä¸ªé‡è¦çš„ SQL å‡½æ•°æ˜¯ CASE WHENã€‚å®ƒè¢«ç”¨ä½œ if_else() å’Œ case_when() çš„ç¿»è¯‘ï¼Œè€Œåè€…æ­£æ˜¯ç›´æ¥å—å…¶å¯å‘çš„ dplyr å‡½æ•°ã€‚è¿™é‡Œæœ‰å‡ ä¸ªç®€å•çš„ä¾‹å­ï¼š\n\nflights |&gt; \n  mutate_query(\n    description = if_else(arr_delay &gt; 0, \"delayed\", \"on-time\")\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE WHEN (arr_delay &gt; 0.0) THEN 'delayed' WHEN NOT (arr_delay &gt; 0.0) THEN 'on-time' END AS description\n#&gt; FROM flights\nflights |&gt; \n  mutate_query(\n    description = \n      case_when(\n        arr_delay &lt; -5 ~ \"early\", \n        arr_delay &lt; 5 ~ \"on-time\",\n        arr_delay &gt;= 5 ~ \"late\"\n      )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt; -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt; 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt;= 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\nCASE WHEN is also used for some other functions that donâ€™t have a direct translation from R to SQL. A good example of this is cut():CASE WHEN ä¹Ÿç”¨äºä¸€äº›å…¶ä»–æ²¡æœ‰ä» R åˆ° SQL ç›´æ¥ç¿»è¯‘çš„å‡½æ•°ã€‚ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­æ˜¯ cut()ï¼š\n\nflights |&gt; \n  mutate_query(\n    description =  cut(\n      arr_delay, \n      breaks = c(-Inf, -5, 5, Inf), \n      labels = c(\"early\", \"on-time\", \"late\")\n    )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt;= -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt;= 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt; 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\ndbplyr also translates common string and date-time manipulation functions, which you can learn about in vignette(\"translation-function\", package = \"dbplyr\"). dbplyrâ€™s translations are certainly not perfect, and there are many R functions that arenâ€™t translated yet, but dbplyr does a surprisingly good job covering the functions that youâ€™ll use most of the time.\ndbplyr è¿˜å¯ä»¥ç¿»è¯‘å¸¸è§çš„å­—ç¬¦ä¸²å’Œæ—¥æœŸæ—¶é—´æ“ä½œå‡½æ•°ï¼Œä½ å¯ä»¥åœ¨ vignette(\"translation-function\", package = \"dbplyr\") ä¸­äº†è§£è¿™äº›å†…å®¹ã€‚dbplyr çš„ç¿»è¯‘å½“ç„¶ä¸æ˜¯å®Œç¾çš„ï¼Œè¿˜æœ‰å¾ˆå¤š R å‡½æ•°å°šæœªè¢«ç¿»è¯‘ï¼Œä½† dbplyr åœ¨è¦†ç›–ä½ å¤§éƒ¨åˆ†æ—¶é—´ä¼šç”¨åˆ°çš„å‡½æ•°æ–¹é¢åšå¾—ç›¸å½“ä¸é”™ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#summary",
    "href": "databases.html#summary",
    "title": "21Â  Databases",
    "section": "\n21.7 Summary",
    "text": "21.7 Summary\nIn this chapter you learned how to access data from databases. We focused on dbplyr, a dplyr â€œbackendâ€ that allows you to write the dplyr code youâ€™re familiar with, and have it be automatically translated to SQL. We used that translation to teach you a little SQL; itâ€™s important to learn some SQL because itâ€™s the most commonly used language for working with data and knowing some will make it easier for you to communicate with other data folks who donâ€™t use R.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä»æ•°æ®åº“è®¿é—®æ•°æ®ã€‚æˆ‘ä»¬é‡ç‚¹ä»‹ç»äº† dbplyrï¼Œè¿™æ˜¯ä¸€ä¸ª dplyr çš„â€œåç«¯â€ï¼Œå®ƒå…è®¸ä½ ç¼–å†™ä½ æ‰€ç†Ÿæ‚‰çš„ dplyr ä»£ç ï¼Œå¹¶å°†å…¶è‡ªåŠ¨ç¿»è¯‘æˆ SQLã€‚æˆ‘ä»¬åˆ©ç”¨è¿™ç§ç¿»è¯‘æ•™äº†ä½ ä¸€ç‚¹ SQLï¼›å­¦ä¹ ä¸€äº› SQL å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒæ˜¯æœ€å¸¸ç”¨çš„æ•°æ®å¤„ç†è¯­è¨€ï¼Œäº†è§£ä¸€äº› SQL å°†ä½¿ä½ æ›´å®¹æ˜“ä¸ä¸ä½¿ç”¨ R çš„å…¶ä»–æ•°æ®ä»ä¸šè€…äº¤æµã€‚\nIf youâ€™ve finished this chapter and would like to learn more about SQL, we have two recommendations:\nå¦‚æœä½ å·²ç»å®Œæˆäº†æœ¬ç« å¹¶æƒ³å­¦ä¹ æ›´å¤šå…³äº SQL çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªå»ºè®®ï¼š\n\nSQL for Data Scientists by RenÃ©e M. P. Teate is an introduction to SQL designed specifically for the needs of data scientists, and includes examples of the sort of highly interconnected data youâ€™re likely to encounter in real organizations.\nRenÃ©e M. P. Teate çš„ SQL for Data Scientists æ˜¯ä¸€æœ¬ä¸“ä¸ºæ•°æ®ç§‘å­¦å®¶çš„éœ€æ±‚è€Œè®¾è®¡çš„ SQL å…¥é—¨ä¹¦ç±ï¼Œå…¶ä¸­åŒ…å«äº†ä½ åœ¨çœŸå®ç»„ç»‡ä¸­å¯èƒ½é‡åˆ°çš„é‚£ç§é«˜åº¦äº’è”æ•°æ®çš„ç¤ºä¾‹ã€‚\nPractical SQL by Anthony DeBarros is written from the perspective of a data journalist (a data scientist specialized in telling compelling stories) and goes into more detail about getting your data into a database and running your own DBMS.\nAnthony DeBarros çš„ Practical SQL æ˜¯ä»æ•°æ®è®°è€…ï¼ˆä¸€ä½ä¸“é—¨è®²è¿°å¼•äººå…¥èƒœæ•…äº‹çš„æ•°æ®ç§‘å­¦å®¶ï¼‰çš„è§†è§’æ’°å†™çš„ï¼Œå®ƒæ›´è¯¦ç»†åœ°ä»‹ç»äº†å¦‚ä½•å°†æ•°æ®å¯¼å…¥æ•°æ®åº“ä»¥åŠå¦‚ä½•è¿è¡Œä½ è‡ªå·±çš„æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ (DBMS)ã€‚\n\nIn the next chapter, weâ€™ll learn about another dplyr backend for working with large data: arrow. Arrow is designed for working with large files on disk, and is a natural complement to databases.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦ä¸€ä¸ªç”¨äºå¤„ç†å¤§æ•°æ®çš„ dplyr åç«¯ï¼šarrowã€‚Arrow ä¸“ä¸ºå¤„ç†ç£ç›˜ä¸Šçš„å¤§æ–‡ä»¶è€Œè®¾è®¡ï¼Œæ˜¯æ•°æ®åº“çš„å¤©ç„¶è¡¥å……ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#footnotes",
    "href": "databases.html#footnotes",
    "title": "21Â  Databases",
    "section": "",
    "text": "SQL is either pronounced â€œsâ€-â€œqâ€-â€œlâ€ or â€œsequelâ€.â†©ï¸\nTypically, this is the only function youâ€™ll use from the client package, so we recommend using :: to pull out that one function, rather than loading the complete package with library().â†©ï¸\nAt least, all the tables that you have permission to see.â†©ï¸\nConfusingly, depending on the context, SELECT is either a statement or a clause.â†©ï¸\nOk, technically, only the SELECT is required, since you can write queries like SELECT 1+1 to perform basic calculations.â†©ï¸\nThis is no coincidence: the dplyr function name was inspired by the SQL clause.â†©ï¸",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>21</span>Â  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "arrow.html",
    "href": "arrow.html",
    "title": "22Â  Arrow",
    "section": "",
    "text": "22.1 Introduction\nCSV files are designed to be easily read by humans. Theyâ€™re a good interchange format because theyâ€™re very simple and they can be read by every tool under the sun. But CSV files arenâ€™t very efficient: you have to do quite a lot of work to read the data into R. In this chapter, youâ€™ll learn about a powerful alternative: the parquet format, an open standards-based format widely used by big data systems.\nCSV æ–‡ä»¶è¢«è®¾è®¡ä¸ºæ˜“äºäººç±»é˜…è¯»ã€‚å®ƒä»¬æ˜¯ä¸€ç§å¾ˆå¥½çš„äº¤æ¢æ ¼å¼ï¼Œå› ä¸ºå®ƒä»¬éå¸¸ç®€å•ï¼Œå¹¶ä¸”å‡ ä¹æ‰€æœ‰å·¥å…·éƒ½èƒ½è¯»å–ã€‚ä½†æ˜¯ CSV æ–‡ä»¶æ•ˆç‡ä¸é«˜ï¼šä½ éœ€è¦åšç›¸å½“å¤šçš„å·¥ä½œæ‰èƒ½å°†æ•°æ®è¯»å…¥ Rã€‚åœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸€ä¸ªå¼ºå¤§çš„æ›¿ä»£æ–¹æ¡ˆï¼šparquet æ ¼å¼ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¼€æ”¾æ ‡å‡†çš„æ ¼å¼ï¼Œè¢«å¤§æ•°æ®ç³»ç»Ÿå¹¿æ³›ä½¿ç”¨ã€‚\nWeâ€™ll pair parquet files with Apache Arrow, a multi-language toolbox designed for efficient analysis and transport of large datasets. Weâ€™ll use Apache Arrow via the arrow package, which provides a dplyr backend allowing you to analyze larger-than-memory datasets using familiar dplyr syntax. As an additional benefit, arrow is extremely fast: youâ€™ll see some examples later in the chapter.\næˆ‘ä»¬å°†æŠŠ parquet æ–‡ä»¶ä¸ Apache Arrow ç»“åˆä½¿ç”¨ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºé«˜æ•ˆåˆ†æå’Œä¼ è¾“å¤§å‹æ•°æ®é›†è€Œè®¾è®¡çš„å¤šè¯­è¨€å·¥å…·ç®±ã€‚æˆ‘ä»¬å°†é€šè¿‡ arrow åŒ… ä½¿ç”¨ Apache Arrowï¼Œå®ƒæä¾›äº†ä¸€ä¸ª dplyr åç«¯ï¼Œå…è®¸ä½ ä½¿ç”¨ç†Ÿæ‚‰çš„ dplyr è¯­æ³•åˆ†æå¤§äºå†…å­˜çš„æ•°æ®é›†ã€‚å¦å¤–ä¸€ä¸ªå¥½å¤„æ˜¯ï¼Œarrow éå¸¸å¿«ï¼šä½ å°†åœ¨æœ¬ç« åé¢çœ‹åˆ°ä¸€äº›ä¾‹å­ã€‚\nBoth arrow and dbplyr provide dplyr backends, so you might wonder when to use each. In many cases, the choice is made for you, as the data is already in a database or in parquet files, and youâ€™ll want to work with it as is. But if youâ€™re starting with your own data (perhaps CSV files), you can either load it into a database or convert it to parquet. In general, itâ€™s hard to know what will work best, so in the early stages of your analysis weâ€™d encourage you to try both and pick the one that works the best for you.\narrow å’Œ dbplyr éƒ½æä¾›äº† dplyr åç«¯ï¼Œæ‰€ä»¥ä½ å¯èƒ½ä¼šæƒ³çŸ¥é“ä½•æ—¶ä½¿ç”¨å“ªä¸€ä¸ªã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œé€‰æ‹©æ˜¯ç°æˆçš„ï¼Œå› ä¸ºæ•°æ®å·²ç»å­˜åœ¨äºæ•°æ®åº“æˆ– parquet æ–‡ä»¶ä¸­ï¼Œè€Œä½ å¸Œæœ›ç›´æ¥ä½¿ç”¨å®ƒã€‚ä½†å¦‚æœä½ æ˜¯ä»è‡ªå·±çš„æ•°æ®ï¼ˆæ¯”å¦‚ CSV æ–‡ä»¶ï¼‰å¼€å§‹ï¼Œä½ å¯ä»¥é€‰æ‹©å°†å…¶åŠ è½½åˆ°æ•°æ®åº“ä¸­æˆ–è½¬æ¢ä¸º parquet æ ¼å¼ã€‚æ€»çš„æ¥è¯´ï¼Œå¾ˆéš¾çŸ¥é“å“ªç§æ–¹æ³•æ•ˆæœæœ€å¥½ï¼Œå› æ­¤åœ¨ä½ åˆ†æçš„æ—©æœŸé˜¶æ®µï¼Œæˆ‘ä»¬é¼“åŠ±ä½ ä¸¤ç§æ–¹æ³•éƒ½è¯•è¯•ï¼Œç„¶åé€‰æ‹©æœ€é€‚åˆä½ çš„é‚£ä¸€ç§ã€‚\n(A big thanks to Danielle Navarro who contributed the initial version of this chapter.)\nï¼ˆéå¸¸æ„Ÿè°¢ Danielle Navarro è´¡çŒ®äº†æœ¬ç« çš„åˆç‰ˆã€‚ï¼‰",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>22</span>Â  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#introduction",
    "href": "arrow.html#introduction",
    "title": "22Â  Arrow",
    "section": "",
    "text": "22.1.1 Prerequisites\nIn this chapter, weâ€™ll continue to use the tidyverse, particularly dplyr, but weâ€™ll pair it with the arrow package which is designed specifically for working with large data.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­ä½¿ç”¨ tidyverseï¼Œç‰¹åˆ«æ˜¯ dplyrï¼Œä½†æˆ‘ä»¬ä¼šå°†å…¶ä¸ä¸“é—¨ä¸ºå¤„ç†å¤§æ•°æ®è€Œè®¾è®¡çš„ arrow åŒ…ç»“åˆä½¿ç”¨ã€‚\n\nlibrary(tidyverse)\nlibrary(arrow)\n\nLater in the chapter, weâ€™ll also see some connections between arrow and duckdb, so weâ€™ll also need dbplyr and duckdb.\nåœ¨æœ¬ç« çš„åé¢ï¼Œæˆ‘ä»¬è¿˜ä¼šçœ‹åˆ° arrow å’Œ duckdb ä¹‹é—´çš„ä¸€äº›è”ç³»ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿˜éœ€è¦ dbplyr å’Œ duckdbã€‚\n\nlibrary(dbplyr, warn.conflicts = FALSE)\nlibrary(duckdb)\n#&gt; Loading required package: DBI",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>22</span>Â  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#getting-the-data",
    "href": "arrow.html#getting-the-data",
    "title": "22Â  Arrow",
    "section": "\n22.2 Getting the data",
    "text": "22.2 Getting the data\nWe begin by getting a dataset worthy of these tools: a dataset of item checkouts from Seattle public libraries, available online at data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6. This dataset contains 41,389,465 rows that tell you how many times each book was checked out each month from April 2005 to October 2022.\næˆ‘ä»¬é¦–å…ˆè·å–ä¸€ä¸ªå€¼å¾—ä½¿ç”¨è¿™äº›å·¥å…·çš„æ•°æ®é›†ï¼šè¥¿é›…å›¾å…¬å…±å›¾ä¹¦é¦†çš„ç‰©å“å€Ÿé˜…æ•°æ®é›†ï¼Œå¯åœ¨çº¿è·å–ï¼šdata.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6ã€‚è¯¥æ•°æ®é›†åŒ…å« 41,389,465 è¡Œï¼Œè®°å½•äº†ä» 2005 å¹´ 4 æœˆåˆ° 2022 å¹´ 10 æœˆæœŸé—´ï¼Œæ¯æœ¬ä¹¦æ¯æœˆè¢«å€Ÿé˜…çš„æ¬¡æ•°ã€‚\nThe following code will get you a cached copy of the data. The data is a 9GB CSV file, so it will take some time to download. I highly recommend using curl::multi_download() to get very large files as itâ€™s built for exactly this purpose: it gives you a progress bar and it can resume the download if its interrupted.\nä»¥ä¸‹ä»£ç å°†ä¸ºä½ è·å–æ•°æ®çš„ç¼“å­˜å‰¯æœ¬ã€‚æ•°æ®æ˜¯ä¸€ä¸ª 9GB çš„ CSV æ–‡ä»¶ï¼Œå› æ­¤ä¸‹è½½éœ€è¦ä¸€äº›æ—¶é—´ã€‚æˆ‘å¼ºçƒˆæ¨èä½¿ç”¨ curl::multi_download() æ¥è·å–éå¸¸å¤§çš„æ–‡ä»¶ï¼Œå› ä¸ºå®ƒæ­£æ˜¯ä¸ºæ­¤ç›®çš„è€Œæ„å»ºçš„ï¼šå®ƒä¼šæä¾›ä¸€ä¸ªè¿›åº¦æ¡ï¼Œå¹¶ä¸”å¦‚æœä¸‹è½½ä¸­æ–­å¯ä»¥æ¢å¤ã€‚\n\ndir.create(\"data\", showWarnings = FALSE)\n\ncurl::multi_download(\n  \"https://r4ds.s3.us-west-2.amazonaws.com/seattle-library-checkouts.csv\",\n  \"data/seattle-library-checkouts.csv\",\n  resume = TRUE\n)",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>22</span>Â  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#opening-a-dataset",
    "href": "arrow.html#opening-a-dataset",
    "title": "22Â  Arrow",
    "section": "\n22.3 Opening a dataset",
    "text": "22.3 Opening a dataset\nLetâ€™s start by taking a look at the data. At 9 GB, this file is large enough that we probably donâ€™t want to load the whole thing into memory. A good rule of thumb is that you usually want at least twice as much memory as the size of the data, and many laptops top out at 16 GB. This means we want to avoid read_csv() and instead use the arrow::open_dataset():\næˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æ•°æ®ã€‚è¿™ä¸ª 9 GB çš„æ–‡ä»¶è¶³å¤Ÿå¤§ï¼Œæˆ‘ä»¬å¯èƒ½ä¸æƒ³æŠŠå®ƒå…¨éƒ¨åŠ è½½åˆ°å†…å­˜ä¸­ã€‚ä¸€ä¸ªå¥½çš„ç»éªŒæ³•åˆ™æ˜¯ï¼Œä½ é€šå¸¸éœ€è¦è‡³å°‘æ˜¯æ•°æ®å¤§å°ä¸¤å€çš„å†…å­˜ï¼Œè€Œè®¸å¤šç¬”è®°æœ¬ç”µè„‘çš„å†…å­˜ä¸Šé™æ˜¯ 16 GBã€‚è¿™æ„å‘³ç€æˆ‘ä»¬è¦é¿å…ä½¿ç”¨ read_csv()ï¼Œè€Œåº”ä½¿ç”¨ arrow::open_dataset()ï¼š\n\nseattle_csv &lt;- open_dataset(\n  sources = \"data/seattle-library-checkouts.csv\", \n  col_types = schema(ISBN = string()),\n  format = \"csv\"\n)\n\nWhat happens when this code is run? open_dataset() will scan a few thousand rows to figure out the structure of the dataset. The ISBN column contains blank values for the first 80,000 rows, so we have to specify the column type to help arrow work out the data structure. Once the data has been scanned by open_dataset(), it records what itâ€™s found and stops; it will only read further rows as you specifically request them. This metadata is what we see if we print seattle_csv:\nå½“è¿™æ®µä»£ç è¿è¡Œæ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿopen_dataset() ä¼šæ‰«æå‡ åƒè¡Œæ¥ç¡®å®šæ•°æ®é›†çš„ç»“æ„ã€‚ISBN åˆ—åœ¨å‰ 80,000 è¡Œä¸­åŒ…å«ç©ºå€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»æŒ‡å®šåˆ—ç±»å‹æ¥å¸®åŠ© arrow ç¡®å®šæ•°æ®ç»“æ„ã€‚ä¸€æ—¦ open_dataset() æ‰«æå®Œæ•°æ®ï¼Œå®ƒä¼šè®°å½•ä¸‹æ‰€å‘ç°çš„ä¿¡æ¯å¹¶åœæ­¢ï¼›å®ƒåªä¼šåœ¨ä½ æ˜ç¡®è¯·æ±‚æ—¶æ‰ä¼šè¯»å–æ›´å¤šçš„è¡Œã€‚è¿™ä¸ªå…ƒæ•°æ®å°±æ˜¯æˆ‘ä»¬æ‰“å° seattle_csv æ—¶çœ‹åˆ°çš„å†…å®¹ï¼š\n\nseattle_csv\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 12 columns\n#&gt; UsageClass: string\n#&gt; CheckoutType: string\n#&gt; MaterialType: string\n#&gt; CheckoutYear: int64\n#&gt; CheckoutMonth: int64\n#&gt; Checkouts: int64\n#&gt; Title: string\n#&gt; ISBN: string\n#&gt; Creator: string\n#&gt; Subjects: string\n#&gt; Publisher: string\n#&gt; PublicationYear: string\n\nThe first line in the output tells you that seattle_csv is stored locally on-disk as a single CSV file; it will only be loaded into memory as needed. The remainder of the output tells you the column type that arrow has imputed for each column.\nè¾“å‡ºçš„ç¬¬ä¸€è¡Œå‘Šè¯‰ä½  seattle_csv æ˜¯ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„ CSV æ–‡ä»¶å­˜å‚¨åœ¨æœ¬åœ°ç£ç›˜ä¸Šçš„ï¼›å®ƒåªä¼šåœ¨éœ€è¦æ—¶æ‰è¢«åŠ è½½åˆ°å†…å­˜ä¸­ã€‚è¾“å‡ºçš„å…¶ä½™éƒ¨åˆ†å‘Šè¯‰äº†ä½  arrow ä¸ºæ¯ä¸€åˆ—æ¨æ–­å‡ºçš„åˆ—ç±»å‹ã€‚\nWe can see whatâ€™s actually in with glimpse(). This reveals that there are ~41 million rows and 12 columns, and shows us a few values.\næˆ‘ä»¬å¯ä»¥ç”¨ glimpse() æ¥æŸ¥çœ‹å®é™…å†…å®¹ã€‚è¿™æ­ç¤ºäº†æ•°æ®å¤§çº¦æœ‰ 4100 ä¸‡è¡Œå’Œ 12 åˆ—ï¼Œå¹¶å‘æˆ‘ä»¬å±•ç¤ºäº†ä¸€äº›å€¼ã€‚\n\nseattle_csv |&gt; glimpse()\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 41,389,465 rows x 12 columns\n#&gt; $ UsageClass      &lt;string&gt; \"Physical\", \"Physical\", \"Digital\", \"Physical\", \"Phâ€¦\n#&gt; $ CheckoutType    &lt;string&gt; \"Horizon\", \"Horizon\", \"OverDrive\", \"Horizon\", \"Horâ€¦\n#&gt; $ MaterialType    &lt;string&gt; \"BOOK\", \"BOOK\", \"EBOOK\", \"BOOK\", \"SOUNDDISC\", \"BOOâ€¦\n#&gt; $ CheckoutYear     &lt;int64&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 20â€¦\n#&gt; $ CheckoutMonth    &lt;int64&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,â€¦\n#&gt; $ Checkouts        &lt;int64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 3, 2,â€¦\n#&gt; $ Title           &lt;string&gt; \"Super rich : a guide to having it all / Russell Sâ€¦\n#&gt; $ ISBN            &lt;string&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"â€¦\n#&gt; $ Creator         &lt;string&gt; \"Simmons, Russell\", \"Barclay, James, 1965-\", \"Tim â€¦\n#&gt; $ Subjects        &lt;string&gt; \"Self realization, Conduct of life, Attitude Psychâ€¦\n#&gt; $ Publisher       &lt;string&gt; \"Gotham Books,\", \"Pyr,\", \"Random House, Inc.\", \"Diâ€¦\n#&gt; $ PublicationYear &lt;string&gt; \"c2011.\", \"2010.\", \"2015\", \"2005.\", \"c2004.\", \"c20â€¦\n\nWe can start to use this dataset with dplyr verbs, using collect() to force arrow to perform the computation and return some data. For example, this code tells us the total number of checkouts per year:\næˆ‘ä»¬å¯ä»¥å¼€å§‹å¯¹è¿™ä¸ªæ•°æ®é›†ä½¿ç”¨ dplyr åŠ¨è¯ï¼Œå¹¶ä½¿ç”¨ collect() æ¥å¼ºåˆ¶ arrow æ‰§è¡Œè®¡ç®—å¹¶è¿”å›ä¸€äº›æ•°æ®ã€‚ä¾‹å¦‚ï¼Œè¿™æ®µä»£ç å‘Šè¯‰æˆ‘ä»¬æ¯å¹´çš„æ€»å€Ÿé˜…é‡ï¼š\n\nseattle_csv |&gt; \n  group_by(CheckoutYear) |&gt; \n  summarise(Checkouts = sum(Checkouts)) |&gt; \n  arrange(CheckoutYear) |&gt; \n  collect()\n#&gt; # A tibble: 18 Ã— 2\n#&gt;   CheckoutYear Checkouts\n#&gt;          &lt;int&gt;     &lt;int&gt;\n#&gt; 1         2005   3798685\n#&gt; 2         2006   6599318\n#&gt; 3         2007   7126627\n#&gt; 4         2008   8438486\n#&gt; 5         2009   9135167\n#&gt; 6         2010   8608966\n#&gt; # â„¹ 12 more rows\n\nThanks to arrow, this code will work regardless of how large the underlying dataset is. But itâ€™s currently rather slow: on Hadleyâ€™s computer, it took ~10s to run. Thatâ€™s not terrible given how much data we have, but we can make it much faster by switching to a better format.\nå¾—ç›Šäº arrowï¼Œæ— è®ºåº•å±‚æ•°æ®é›†æœ‰å¤šå¤§ï¼Œè¿™æ®µä»£ç éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚ä½†å®ƒç›®å‰ç›¸å½“æ…¢ï¼šåœ¨ Hadley çš„ç”µè„‘ä¸Šï¼Œè¿è¡Œå¤§çº¦éœ€è¦ 10 ç§’ã€‚è€ƒè™‘åˆ°æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®é‡ï¼Œè¿™ä¸ç®—å¤ªç³Ÿï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ‡æ¢åˆ°æ›´å¥½çš„æ ¼å¼æ¥è®©å®ƒå˜å¾—å¿«å¾—å¤šã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>22</span>Â  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#sec-parquet",
    "href": "arrow.html#sec-parquet",
    "title": "22Â  Arrow",
    "section": "\n22.4 The parquet format",
    "text": "22.4 The parquet format\nTo make this data easier to work with, letâ€™s switch to the parquet file format and split it up into multiple files. The following sections will first introduce you to parquet and partitioning, and then apply what we learned to the Seattle library data.\nä¸ºäº†è®©è¿™ä¸ªæ•°æ®æ›´å®¹æ˜“å¤„ç†ï¼Œè®©æˆ‘ä»¬åˆ‡æ¢åˆ° parquet æ–‡ä»¶æ ¼å¼ï¼Œå¹¶å°†å…¶åˆ†å‰²æˆå¤šä¸ªæ–‡ä»¶ã€‚æ¥ä¸‹æ¥çš„éƒ¨åˆ†å°†é¦–å…ˆå‘ä½ ä»‹ç» parquet å’Œåˆ†åŒº (partitioning)ï¼Œç„¶åå°†æˆ‘ä»¬å­¦åˆ°çš„çŸ¥è¯†åº”ç”¨åˆ°è¥¿é›…å›¾å›¾ä¹¦é¦†æ•°æ®ä¸Šã€‚\n\n22.4.1 Advantages of parquet\nLike CSV, parquet is used for rectangular data, but instead of being a text format that you can read with any file editor, itâ€™s a custom binary format designed specifically for the needs of big data. This means that:\nä¸ CSV ä¸€æ ·ï¼Œparquet ç”¨äºå¤„ç†çŸ©å½¢æ•°æ®ï¼Œä½†å®ƒä¸æ˜¯ä½ å¯ä»¥ç”¨ä»»ä½•æ–‡ä»¶ç¼–è¾‘å™¨è¯»å–çš„æ–‡æœ¬æ ¼å¼ï¼Œè€Œæ˜¯ä¸€ç§ä¸“ä¸ºå¤§æ•°æ®éœ€æ±‚è®¾è®¡çš„è‡ªå®šä¹‰äºŒè¿›åˆ¶æ ¼å¼ã€‚è¿™æ„å‘³ç€ï¼š\n\nParquet files are usually smaller than the equivalent CSV file. Parquet relies on efficient encodings to keep file size down, and supports file compression. This helps make parquet files fast because thereâ€™s less data to move from disk to memory.\nParquet æ–‡ä»¶é€šå¸¸æ¯”ç­‰æ•ˆçš„ CSV æ–‡ä»¶å°ã€‚Parquet ä¾èµ–äºé«˜æ•ˆç¼–ç æ¥å‡å°æ–‡ä»¶å¤§å°ï¼Œå¹¶æ”¯æŒæ–‡ä»¶å‹ç¼©ã€‚è¿™æœ‰åŠ©äºä½¿ parquet æ–‡ä»¶è¿è¡Œé€Ÿåº¦æ›´å¿«ï¼Œå› ä¸ºéœ€è¦ä»ç£ç›˜ç§»åŠ¨åˆ°å†…å­˜çš„æ•°æ®æ›´å°‘ã€‚\nParquet files have a rich type system. As we talked about in Section 7.3, a CSV file does not provide any information about column types. For example, a CSV reader has to guess whether \"08-10-2022\" should be parsed as a string or a date. In contrast, parquet files store data in a way that records the type along with the data.\nParquet æ–‡ä»¶æ‹¥æœ‰ä¸°å¯Œçš„ç±»å‹ç³»ç»Ÿã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ Section 7.3 ä¸­è®¨è®ºçš„ï¼ŒCSV æ–‡ä»¶ä¸æä¾›ä»»ä½•å…³äºåˆ—ç±»å‹çš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼ŒCSV è¯»å–å™¨å¿…é¡»çŒœæµ‹ \"08-10-2022\" åº”è¯¥è¢«è§£æä¸ºå­—ç¬¦ä¸²è¿˜æ˜¯æ—¥æœŸã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œparquet æ–‡ä»¶ä»¥ä¸€ç§å°†ç±»å‹ä¸æ•°æ®ä¸€åŒè®°å½•çš„æ–¹å¼å­˜å‚¨æ•°æ®ã€‚\nParquet files are â€œcolumn-orientedâ€. This means that theyâ€™re organized column-by-column, much like Râ€™s data frame. This typically leads to better performance for data analysis tasks compared to CSV files, which are organized row-by-row.\nParquet æ–‡ä»¶æ˜¯â€œåˆ—å¼å­˜å‚¨â€(column-oriented) çš„ã€‚è¿™æ„å‘³ç€å®ƒä»¬æ˜¯æŒ‰åˆ—ç»„ç»‡çš„ï¼Œå¾ˆåƒ R çš„æ•°æ®æ¡†ã€‚ä¸æŒ‰è¡Œç»„ç»‡çš„ CSV æ–‡ä»¶ç›¸æ¯”ï¼Œè¿™é€šå¸¸ä¼šä¸ºæ•°æ®åˆ†æä»»åŠ¡å¸¦æ¥æ›´å¥½çš„æ€§èƒ½ã€‚\nParquet files are â€œchunkedâ€, which makes it possible to work on different parts of the file at the same time, and, if youâ€™re lucky, to skip some chunks altogether.\nParquet æ–‡ä»¶æ˜¯â€œåˆ†å—çš„â€(chunked)ï¼Œè¿™ä½¿å¾—å¯ä»¥åŒæ—¶å¤„ç†æ–‡ä»¶çš„ä¸åŒéƒ¨åˆ†ï¼Œå¹¶ä¸”ï¼Œå¦‚æœå¹¸è¿çš„è¯ï¼Œå¯ä»¥å®Œå…¨è·³è¿‡æŸäº›å—ã€‚\n\nThereâ€™s one primary disadvantage to parquet files: they are no longer â€œhuman readableâ€, i.e.Â if you look at a parquet file using readr::read_file(), youâ€™ll just see a bunch of gibberish.\nparquet æ–‡ä»¶æœ‰ä¸€ä¸ªä¸»è¦ç¼ºç‚¹ï¼šå®ƒä»¬ä¸å†æ˜¯â€œäººç±»å¯è¯»çš„â€ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœä½ ç”¨ readr::read_file() æŸ¥çœ‹ä¸€ä¸ª parquet æ–‡ä»¶ï¼Œä½ åªä¼šçœ‹åˆ°ä¸€å †ä¹±ç ã€‚\n\n22.4.2 Partitioning\nAs datasets get larger and larger, storing all the data in a single file gets increasingly painful and itâ€™s often useful to split large datasets across many files. When this structuring is done intelligently, this strategy can lead to significant improvements in performance because many analyses will only require a subset of the files.\néšç€æ•°æ®é›†è¶Šæ¥è¶Šå¤§ï¼Œå°†æ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨å•ä¸ªæ–‡ä»¶ä¸­å˜å¾—è¶Šæ¥è¶Šç—›è‹¦ï¼Œå°†å¤§å‹æ•°æ®é›†åˆ†å‰²åˆ°å¤šä¸ªæ–‡ä»¶ä¸­é€šå¸¸å¾ˆæœ‰ç”¨ã€‚å½“è¿™ç§ç»“æ„åŒ–æ“ä½œåšå¾—å·§å¦™æ—¶ï¼Œè¯¥ç­–ç•¥å¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ï¼Œå› ä¸ºè®¸å¤šåˆ†æåªéœ€è¦æ–‡ä»¶çš„ä¸€ä¸ªå­é›†ã€‚\nThere are no hard and fast rules about how to partition your dataset: the results will depend on your data, access patterns, and the systems that read the data. Youâ€™re likely to need to do some experimentation before you find the ideal partitioning for your situation. As a rough guide, arrow suggests that you avoid files smaller than 20MB and larger than 2GB and avoid partitions that produce more than 10,000 files. You should also try to partition by variables that you filter by; as youâ€™ll see shortly, that allows arrow to skip a lot of work by reading only the relevant files.\nå…³äºå¦‚ä½•å¯¹æ•°æ®é›†è¿›è¡Œåˆ†åŒºï¼Œæ²¡æœ‰ç¡¬æ€§è§„å®šï¼šç»“æœå°†å–å†³äºä½ çš„æ•°æ®ã€è®¿é—®æ¨¡å¼ä»¥åŠè¯»å–æ•°æ®çš„ç³»ç»Ÿã€‚ä½ å¯èƒ½éœ€è¦è¿›è¡Œä¸€äº›å®éªŒæ‰èƒ½æ‰¾åˆ°é€‚åˆä½ æƒ…å†µçš„ç†æƒ³åˆ†åŒºæ–¹æ¡ˆã€‚ä½œä¸ºä¸€ä¸ªç²—ç•¥çš„æŒ‡å—ï¼Œarrow å»ºè®®ä½ é¿å…å°äº 20MB å’Œå¤§äº 2GB çš„æ–‡ä»¶ï¼Œå¹¶é¿å…äº§ç”Ÿè¶…è¿‡ 10,000 ä¸ªæ–‡ä»¶çš„åˆ†åŒºã€‚ä½ è¿˜åº”è¯¥å°è¯•æŒ‰ä½ è¿‡æ»¤æ—¶ä½¿ç”¨çš„å˜é‡è¿›è¡Œåˆ†åŒºï¼›æ­£å¦‚ä½ å¾ˆå¿«ä¼šçœ‹åˆ°çš„ï¼Œè¿™ä½¿å¾— arrow å¯ä»¥é€šè¿‡åªè¯»å–ç›¸å…³æ–‡ä»¶æ¥è·³è¿‡å¤§é‡å·¥ä½œã€‚\n\n22.4.3 Rewriting the Seattle library data\nLetâ€™s apply these ideas to the Seattle library data to see how they play out in practice. Weâ€™re going to partition by CheckoutYear, since itâ€™s likely some analyses will only want to look at recent data and partitioning by year yields 18 chunks of a reasonable size.\nè®©æˆ‘ä»¬å°†è¿™äº›æƒ³æ³•åº”ç”¨åˆ°è¥¿é›…å›¾å›¾ä¹¦é¦†æ•°æ®ä¸Šï¼Œçœ‹çœ‹å®ƒä»¬åœ¨å®è·µä¸­æ˜¯å¦‚ä½•å‘æŒ¥ä½œç”¨çš„ã€‚æˆ‘ä»¬å°†æŒ‰ CheckoutYear è¿›è¡Œåˆ†åŒºï¼Œå› ä¸ºå¾ˆå¯èƒ½ä¸€äº›åˆ†æåªæƒ³æŸ¥çœ‹æœ€è¿‘çš„æ•°æ®ï¼Œè€ŒæŒ‰å¹´ä»½åˆ†åŒºå¯ä»¥äº§ç”Ÿ 18 ä¸ªå¤§å°åˆé€‚çš„æ•°æ®å—ã€‚\nTo rewrite the data we define the partition using dplyr::group_by() and then save the partitions to a directory with arrow::write_dataset(). write_dataset() has two important arguments: a directory where weâ€™ll create the files and the format weâ€™ll use.\nä¸ºäº†é‡å†™æ•°æ®ï¼Œæˆ‘ä»¬ä½¿ç”¨ dplyr::group_by() å®šä¹‰åˆ†åŒºï¼Œç„¶åç”¨ arrow::write_dataset() å°†åˆ†åŒºä¿å­˜åˆ°ä¸€ä¸ªç›®å½•ä¸­ã€‚write_dataset() æœ‰ä¸¤ä¸ªé‡è¦çš„å‚æ•°ï¼šä¸€ä¸ªæ˜¯æˆ‘ä»¬å°†åœ¨å…¶ä¸­åˆ›å»ºæ–‡ä»¶çš„ç›®å½•ï¼Œå¦ä¸€ä¸ªæ˜¯æˆ‘ä»¬ä½¿ç”¨çš„æ ¼å¼ã€‚\n\npq_path &lt;- \"data/seattle-library-checkouts\"\n\n\nseattle_csv |&gt;\n  group_by(CheckoutYear) |&gt;\n  write_dataset(path = pq_path, format = \"parquet\")\n\nThis takes about a minute to run; as weâ€™ll see shortly this is an initial investment that pays off by making future operations much much faster.\nè¿™å¤§çº¦éœ€è¦ä¸€åˆ†é’Ÿæ¥è¿è¡Œï¼›æˆ‘ä»¬å¾ˆå¿«å°±ä¼šçœ‹åˆ°ï¼Œè¿™æ˜¯ä¸€é¡¹åˆå§‹æŠ•èµ„ï¼Œå®ƒä¼šé€šè¿‡ä½¿æœªæ¥çš„æ“ä½œå¿«å¾—å¤šè€Œå¾—åˆ°å›æŠ¥ã€‚\nLetâ€™s take a look at what we just produced:\nè®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬åˆšåˆšç”Ÿæˆäº†ä»€ä¹ˆï¼š\n\ntibble(\n  files = list.files(pq_path, recursive = TRUE),\n  size_MB = file.size(file.path(pq_path, files)) / 1024^2\n)\n#&gt; # A tibble: 18 Ã— 2\n#&gt;   files                            size_MB\n#&gt;   &lt;chr&gt;                              &lt;dbl&gt;\n#&gt; 1 CheckoutYear=2005/part-0.parquet    109.\n#&gt; 2 CheckoutYear=2006/part-0.parquet    164.\n#&gt; 3 CheckoutYear=2007/part-0.parquet    177.\n#&gt; 4 CheckoutYear=2008/part-0.parquet    194.\n#&gt; 5 CheckoutYear=2009/part-0.parquet    214.\n#&gt; 6 CheckoutYear=2010/part-0.parquet    222.\n#&gt; # â„¹ 12 more rows\n\nOur single 9GB CSV file has been rewritten into 18 parquet files. The file names use a â€œself-describingâ€ convention used by the Apache Hive project. Hive-style partitions name folders with a â€œkey=valueâ€ convention, so as you might guess, the CheckoutYear=2005 directory contains all the data where CheckoutYear is 2005. Each file is between 100 and 300 MB and the total size is now around 4 GB, a little over half the size of the original CSV file. This is as we expect since parquet is a much more efficient format.\næˆ‘ä»¬å•ä¸ª 9GB çš„ CSV æ–‡ä»¶å·²ç»è¢«é‡å†™ä¸º 18 ä¸ª parquet æ–‡ä»¶ã€‚æ–‡ä»¶åä½¿ç”¨äº† Apache Hive é¡¹ç›®ä½¿ç”¨çš„â€œè‡ªæè¿°â€çº¦å®šã€‚Hive é£æ ¼çš„åˆ†åŒºä½¿ç”¨â€œkey=valueâ€çš„çº¦å®šæ¥å‘½åæ–‡ä»¶å¤¹ï¼Œæ‰€ä»¥ä½ å¯èƒ½çŒœåˆ°ï¼ŒCheckoutYear=2005 ç›®å½•åŒ…å«äº†æ‰€æœ‰ CheckoutYear ä¸º 2005 çš„æ•°æ®ã€‚æ¯ä¸ªæ–‡ä»¶å¤§å°åœ¨ 100 åˆ° 300 MB ä¹‹é—´ï¼Œæ€»å¤§å°ç°åœ¨çº¦ä¸º 4 GBï¼Œç•¥å¤šäºåŸå§‹ CSV æ–‡ä»¶å¤§å°çš„ä¸€åŠã€‚è¿™æ­£å¦‚æˆ‘ä»¬æ‰€æ–™ï¼Œå› ä¸º parquet æ˜¯ä¸€ç§æ•ˆç‡é«˜å¾—å¤šçš„æ ¼å¼ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>22</span>Â  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#using-dplyr-with-arrow",
    "href": "arrow.html#using-dplyr-with-arrow",
    "title": "22Â  Arrow",
    "section": "\n22.5 Using dplyr with arrow",
    "text": "22.5 Using dplyr with arrow\nNow weâ€™ve created these parquet files, weâ€™ll need to read them in again. We use open_dataset() again, but this time we give it a directory:\nç°åœ¨æˆ‘ä»¬å·²ç»åˆ›å»ºäº†è¿™äº› parquet æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦å†æ¬¡å°†å®ƒä»¬è¯»å…¥ã€‚æˆ‘ä»¬å†æ¬¡ä½¿ç”¨ open_dataset()ï¼Œä½†è¿™æ¬¡æˆ‘ä»¬ç»™å®ƒä¸€ä¸ªç›®å½•ï¼š\n\nseattle_pq &lt;- open_dataset(pq_path)\n\nNow we can write our dplyr pipeline. For example, we could count the total number of books checked out in each month for the last five years:\nç°åœ¨æˆ‘ä»¬å¯ä»¥ç¼–å†™æˆ‘ä»¬çš„ dplyr ç®¡é“äº†ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—è¿‡å»äº”å¹´æ¯ä¸ªæœˆå€Ÿå‡ºçš„å›¾ä¹¦æ€»æ•°ï¼š\n\nquery &lt;- seattle_pq |&gt; \n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear, CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(CheckoutYear, CheckoutMonth)\n\nWriting dplyr code for arrow data is conceptually similar to dbplyr, Chapter 21: you write dplyr code, which is automatically transformed into a query that the Apache Arrow C++ library understands, which is then executed when you call collect(). If we print out the query object we can see a little information about what we expect Arrow to return when the execution takes place:\nä¸º arrow æ•°æ®ç¼–å†™ dplyr ä»£ç åœ¨æ¦‚å¿µä¸Šç±»ä¼¼äº dbplyrï¼ŒChapter 21ï¼šä½ ç¼–å†™ dplyr ä»£ç ï¼Œå®ƒä¼šè‡ªåŠ¨è½¬æ¢ä¸º Apache Arrow C++ åº“èƒ½ç†è§£çš„æŸ¥è¯¢ï¼Œç„¶ååœ¨ä½ è°ƒç”¨ collect() æ—¶æ‰§è¡Œã€‚å¦‚æœæˆ‘ä»¬æ‰“å°å‡º query å¯¹è±¡ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€äº›å…³äºæˆ‘ä»¬æœŸæœ› Arrow åœ¨æ‰§è¡Œæ—¶è¿”å›ä»€ä¹ˆçš„ä¿¡æ¯ï¼š\n\nquery\n#&gt; FileSystemDataset (query)\n#&gt; CheckoutYear: int32\n#&gt; CheckoutMonth: int64\n#&gt; TotalCheckouts: int64\n#&gt; \n#&gt; * Grouped by CheckoutYear\n#&gt; * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#&gt; See $.data for the source Arrow object\n\nAnd we can get the results by calling collect():\næˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨ collect() æ¥è·å–ç»“æœï¼š\n\nquery |&gt; collect()\n#&gt; # A tibble: 58 Ã— 3\n#&gt; # Groups:   CheckoutYear [5]\n#&gt;   CheckoutYear CheckoutMonth TotalCheckouts\n#&gt;          &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n#&gt; 1         2018             1         355101\n#&gt; 2         2018             2         309813\n#&gt; 3         2018             3         344487\n#&gt; 4         2018             4         330988\n#&gt; 5         2018             5         318049\n#&gt; 6         2018             6         341825\n#&gt; # â„¹ 52 more rows\n\nLike dbplyr, arrow only understands some R expressions, so you may not be able to write exactly the same code you usually would. However, the list of operations and functions supported is fairly extensive and continues to grow; find a complete list of currently supported functions in ?acero.\nä¸ dbplyr ç±»ä¼¼ï¼Œarrow åªç†è§£éƒ¨åˆ† R è¡¨è¾¾å¼ï¼Œæ‰€ä»¥ä½ å¯èƒ½æ— æ³•å®Œå…¨å†™å‡ºä½ é€šå¸¸ä¼šå†™çš„ä»£ç ã€‚ç„¶è€Œï¼Œæ”¯æŒçš„æ“ä½œå’Œå‡½æ•°åˆ—è¡¨ç›¸å½“å¹¿æ³›ï¼Œå¹¶ä¸”åœ¨ä¸æ–­å¢é•¿ï¼›å¯ä»¥åœ¨ ?acero ä¸­æ‰¾åˆ°å½“å‰æ”¯æŒçš„å‡½æ•°çš„å®Œæ•´åˆ—è¡¨ã€‚\n\n22.5.1 Performance\nLetâ€™s take a quick look at the performance impact of switching from CSV to parquet. First, letâ€™s time how long it takes to calculate the number of books checked out in each month of 2021, when the data is stored as a single large csv:\nè®©æˆ‘ä»¬å¿«é€Ÿçœ‹ä¸€ä¸‹ä» CSV åˆ‡æ¢åˆ° parquet å¯¹æ€§èƒ½çš„å½±å“ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ¥è®¡æ—¶è®¡ç®— 2021 å¹´æ¯ä¸ªæœˆå€Ÿé˜…çš„ä¹¦ç±æ•°é‡éœ€è¦å¤šé•¿æ—¶é—´ï¼Œæ­¤æ—¶æ•°æ®å­˜å‚¨ä¸ºä¸€ä¸ªå•ç‹¬çš„å¤§å‹ CSV æ–‡ä»¶ï¼š\n\nseattle_csv |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;   11.54    1.53   11.07\n\nNow letâ€™s use our new version of the dataset in which the Seattle library checkout data has been partitioned into 18 smaller parquet files:\nç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨æ–°ç‰ˆæœ¬çš„æ•°æ®é›†ï¼Œå…¶ä¸­è¥¿é›…å›¾å›¾ä¹¦é¦†çš„å€Ÿé˜…æ•°æ®å·²è¢«åˆ†åŒºä¸º 18 ä¸ªè¾ƒå°çš„ parquet æ–‡ä»¶ï¼š\n\nseattle_pq |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;    0.25    0.02    0.12\n\nThe ~100x speedup in performance is attributable to two factors: the multi-file partitioning, and the format of individual files:\næ€§èƒ½æå‡çº¦ 100 å€å¯å½’å› äºä¸¤ä¸ªå› ç´ ï¼šå¤šæ–‡ä»¶åˆ†åŒºå’Œå•ä¸ªæ–‡ä»¶çš„æ ¼å¼ï¼š\n\nPartitioning improves performance because this query uses CheckoutYear == 2021 to filter the data, and arrow is smart enough to recognize that it only needs to read 1 of the 18 parquet files.\nåˆ†åŒºæé«˜äº†æ€§èƒ½ï¼Œå› ä¸ºæ­¤æŸ¥è¯¢ä½¿ç”¨ CheckoutYear == 2021 æ¥è¿‡æ»¤æ•°æ®ï¼Œè€Œ arrow è¶³å¤Ÿæ™ºèƒ½ï¼Œèƒ½å¤Ÿè¯†åˆ«å‡ºå®ƒåªéœ€è¦è¯»å– 18 ä¸ª parquet æ–‡ä»¶ä¸­çš„ 1 ä¸ªã€‚\nThe parquet format improves performance by storing data in a binary format that can be read more directly into memory. The column-wise format and rich metadata means that arrow only needs to read the four columns actually used in the query (CheckoutYear, MaterialType, CheckoutMonth, and Checkouts).\nParquet æ ¼å¼é€šè¿‡ä»¥äºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨æ•°æ®æ¥æé«˜æ€§èƒ½ï¼Œè¿™ç§æ ¼å¼å¯ä»¥æ›´ç›´æ¥åœ°è¯»å…¥å†…å­˜ã€‚å…¶åˆ—å¼æ ¼å¼å’Œä¸°å¯Œçš„å…ƒæ•°æ®æ„å‘³ç€ arrow åªéœ€è¦è¯»å–æŸ¥è¯¢ä¸­å®é™…ä½¿ç”¨çš„å››åˆ—ï¼ˆCheckoutYearã€MaterialTypeã€CheckoutMonth å’Œ Checkoutsï¼‰ã€‚\n\nThis massive difference in performance is why it pays off to convert large CSVs to parquet!\nè¿™ç§å·¨å¤§çš„æ€§èƒ½å·®å¼‚å°±æ˜¯ä¸ºä»€ä¹ˆå°†å¤§å‹ CSV æ–‡ä»¶è½¬æ¢ä¸º parquet æ˜¯å€¼å¾—çš„ï¼\n\n22.5.2 Using duckdb with arrow\nThereâ€™s one last advantage of parquet and arrow â€” itâ€™s very easy to turn an arrow dataset into a DuckDB database (Chapter 21) by calling arrow::to_duckdb():\nparquet å’Œ arrow è¿˜æœ‰ä¸€ä¸ªæœ€åçš„ä¼˜åŠ¿â€”â€”é€šè¿‡è°ƒç”¨ arrow::to_duckdb()ï¼Œå¯ä»¥éå¸¸å®¹æ˜“åœ°å°†ä¸€ä¸ª arrow æ•°æ®é›†è½¬æ¢æˆä¸€ä¸ª DuckDB æ•°æ®åº“ (Chapter 21)ï¼š\n\nseattle_pq |&gt; \n  to_duckdb() |&gt;\n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutYear)) |&gt;\n  collect()\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # A tibble: 5 Ã— 2\n#&gt;   CheckoutYear TotalCheckouts\n#&gt;          &lt;int&gt;          &lt;dbl&gt;\n#&gt; 1         2022        2431502\n#&gt; 2         2021        2266438\n#&gt; 3         2020        1241999\n#&gt; 4         2019        3931688\n#&gt; 5         2018        3987569\n\nThe neat thing about to_duckdb() is that the transfer doesnâ€™t involve any memory copying, and speaks to the goals of the arrow ecosystem: enabling seamless transitions from one computing environment to another.to_duckdb() çš„å¦™å¤„åœ¨äºæ•°æ®ä¼ è¾“ä¸æ¶‰åŠä»»ä½•å†…å­˜å¤åˆ¶ï¼Œè¿™ä½“ç°äº† arrow ç”Ÿæ€ç³»ç»Ÿçš„ç›®æ ‡ï¼šå®ç°ä»ä¸€ä¸ªè®¡ç®—ç¯å¢ƒåˆ°å¦ä¸€ä¸ªè®¡ç®—ç¯å¢ƒçš„æ— ç¼è½¬æ¢ã€‚\n\n22.5.3 Exercises\n\nFigure out the most popular book each year.\nWhich author has the most books in the Seattle library system?\nHow has checkouts of books vs ebooks changed over the last 10 years?",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>22</span>Â  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#summary",
    "href": "arrow.html#summary",
    "title": "22Â  Arrow",
    "section": "\n22.6 Summary",
    "text": "22.6 Summary\nIn this chapter, youâ€™ve been given a taste of the arrow package, which provides a dplyr backend for working with large on-disk datasets. It can work with CSV files, and itâ€™s much much faster if you convert your data to parquet. Parquet is a binary data format thatâ€™s designed specifically for data analysis on modern computers. Far fewer tools can work with parquet files compared to CSV, but its partitioned, compressed, and columnar structure makes it much more efficient to analyze.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ åˆæ­¥äº†è§£äº† arrow åŒ…ï¼Œå®ƒä¸ºå¤„ç†å¤§å‹ç£ç›˜æ•°æ®é›†æä¾›äº†ä¸€ä¸ª dplyr åç«¯ã€‚å®ƒå¯ä»¥å¤„ç† CSV æ–‡ä»¶ï¼Œä½†å¦‚æœä½ å°†æ•°æ®è½¬æ¢ä¸º parquet æ ¼å¼ï¼Œé€Ÿåº¦ä¼šå¿«å¾—å¤šã€‚Parquet æ˜¯ä¸€ç§ä¸“ä¸ºåœ¨ç°ä»£è®¡ç®—æœºä¸Šè¿›è¡Œæ•°æ®åˆ†æè€Œè®¾è®¡çš„äºŒè¿›åˆ¶æ•°æ®æ ¼å¼ã€‚ä¸ CSV ç›¸æ¯”ï¼Œèƒ½å¤„ç† parquet æ–‡ä»¶çš„å·¥å…·è¦å°‘å¾—å¤šï¼Œä½†å…¶åˆ†åŒºã€å‹ç¼©å’Œåˆ—å¼ç»“æ„ä½¿å…¶åˆ†ææ•ˆç‡æ›´é«˜ã€‚\nNext up youâ€™ll learn about your first non-rectangular data source, which youâ€™ll handle using tools provided by the tidyr package. Weâ€™ll focus on data that comes from JSON files, but the general principles apply to tree-like data regardless of its source.\næ¥ä¸‹æ¥ï¼Œä½ å°†å­¦ä¹ ä½ çš„ç¬¬ä¸€ä¸ªéçŸ©å½¢æ•°æ®æºï¼Œä½ å°†ä½¿ç”¨ tidyr åŒ…æä¾›çš„å·¥å…·æ¥å¤„ç†å®ƒã€‚æˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨æ¥è‡ª JSON æ–‡ä»¶çš„æ•°æ®ï¼Œä½†é€šç”¨åŸåˆ™é€‚ç”¨äºä»»ä½•æ¥æºçš„æ ‘çŠ¶æ•°æ®ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>22</span>Â  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "rectangling.html",
    "href": "rectangling.html",
    "title": "23Â  Hierarchical data",
    "section": "",
    "text": "23.1 Introduction\nIn this chapter, youâ€™ll learn the art of data rectangling: taking data that is fundamentally hierarchical, or tree-like, and converting it into a rectangular data frame made up of rows and columns. This is important because hierarchical data is surprisingly common, especially when working with data that comes from the web.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ æ•°æ®çŸ©å½¢åŒ– (rectangling) çš„è‰ºæœ¯ï¼šå°†æœ¬è´¨ä¸Šæ˜¯åˆ†å±‚çš„æˆ–æ ‘çŠ¶çš„æ•°æ®ï¼Œè½¬æ¢ä¸ºç”±è¡Œå’Œåˆ—ç»„æˆçš„çŸ©å½¢æ•°æ®æ¡†ã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œå› ä¸ºåˆ†å±‚æ•°æ®å‡ºäººæ„æ–™åœ°å¸¸è§ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æ¥è‡ªç½‘ç»œçš„æ•°æ®æ—¶ã€‚\nTo learn about rectangling, youâ€™ll need to first learn about lists, the data structure that makes hierarchical data possible. Then youâ€™ll learn about two crucial tidyr functions: tidyr::unnest_longer() and tidyr::unnest_wider(). Weâ€™ll then show you a few case studies, applying these simple functions again and again to solve real problems. Weâ€™ll finish off by talking about JSON, the most frequent source of hierarchical datasets and a common format for data exchange on the web.\nè¦å­¦ä¹ çŸ©å½¢åŒ–ï¼Œä½ éœ€è¦å…ˆäº†è§£åˆ—è¡¨ï¼Œè¿™ç§æ•°æ®ç»“æ„ä½¿åˆ†å±‚æ•°æ®æˆä¸ºå¯èƒ½ã€‚ç„¶åä½ å°†å­¦ä¹ ä¸¤ä¸ªå…³é”®çš„ tidyr å‡½æ•°ï¼štidyr::unnest_longer() å’Œ tidyr::unnest_wider()ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€äº›æ¡ˆä¾‹ç ”ç©¶ï¼Œåå¤åº”ç”¨è¿™äº›ç®€å•çš„å‡½æ•°æ¥è§£å†³å®é™…é—®é¢˜ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è®¨è®º JSONï¼Œå®ƒæ˜¯åˆ†å±‚æ•°æ®é›†æœ€å¸¸è§çš„æ¥æºï¼Œä¹Ÿæ˜¯ç½‘ç»œä¸Šæ•°æ®äº¤æ¢çš„å¸¸ç”¨æ ¼å¼ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#introduction",
    "href": "rectangling.html#introduction",
    "title": "23Â  Hierarchical data",
    "section": "",
    "text": "23.1.1 Prerequisites\nIn this chapter, weâ€™ll use many functions from tidyr, a core member of the tidyverse. Weâ€™ll also use repurrrsive to provide some interesting datasets for rectangling practice, and weâ€™ll finish by using jsonlite to read JSON files into R lists.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è®¸å¤šæ¥è‡ª tidyr çš„å‡½æ•°ï¼Œå®ƒæ˜¯ tidyverse çš„æ ¸å¿ƒæˆå‘˜ã€‚æˆ‘ä»¬è¿˜å°†ä½¿ç”¨ repurrrsive åŒ…æ¥æä¾›ä¸€äº›æœ‰è¶£çš„æ•°æ®é›†ï¼Œç”¨äºçŸ©å½¢åŒ–ç»ƒä¹ ï¼Œæœ€åæˆ‘ä»¬å°†ä½¿ç”¨ jsonlite åŒ…å°† JSON æ–‡ä»¶è¯»å…¥ R åˆ—è¡¨ã€‚\n\nlibrary(tidyverse)\nlibrary(repurrrsive)\nlibrary(jsonlite)",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#lists",
    "href": "rectangling.html#lists",
    "title": "23Â  Hierarchical data",
    "section": "\n23.2 Lists",
    "text": "23.2 Lists\nSo far youâ€™ve worked with data frames that contain simple vectors like integers, numbers, characters, date-times, and factors. These vectors are simple because theyâ€™re homogeneous: every element is of the same data type. If you want to store elements of different types in the same vector, youâ€™ll need a list, which you create with list():\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ æ‰€ä½¿ç”¨çš„æ•°æ®æ¡†åŒ…å«çš„æ˜¯ç®€å•çš„å‘é‡ï¼Œå¦‚æ•´æ•°ã€æ•°å­—ã€å­—ç¬¦ã€æ—¥æœŸæ—¶é—´å’Œå› å­ã€‚è¿™äº›å‘é‡ä¹‹æ‰€ä»¥ç®€å•ï¼Œæ˜¯å› ä¸ºå®ƒä»¬æ˜¯åŒè´¨çš„ï¼šæ¯ä¸ªå…ƒç´ éƒ½å±äºç›¸åŒçš„æ•°æ®ç±»å‹ã€‚å¦‚æœä½ æƒ³åœ¨åŒä¸€ä¸ªå‘é‡ä¸­å­˜å‚¨ä¸åŒç±»å‹çš„å…ƒç´ ï¼Œä½ å°±éœ€è¦ä¸€ä¸ªåˆ—è¡¨ (list)ï¼Œä½ å¯ä»¥ç”¨ list() æ¥åˆ›å»ºå®ƒï¼š\n\nx1 &lt;- list(1:4, \"a\", TRUE)\nx1\n#&gt; [[1]]\n#&gt; [1] 1 2 3 4\n#&gt; \n#&gt; [[2]]\n#&gt; [1] \"a\"\n#&gt; \n#&gt; [[3]]\n#&gt; [1] TRUE\n\nItâ€™s often convenient to name the components, or children, of a list, which you can do in the same way as naming the columns of a tibble:\nä¸ºåˆ—è¡¨çš„ç»„ä»¶ï¼ˆæˆ–ç§°å­å…ƒç´  (children)ï¼‰å‘½åé€šå¸¸å¾ˆæ–¹ä¾¿ï¼Œä½ å¯ä»¥åƒå‘½å tibble çš„åˆ—ä¸€æ ·æ¥åšï¼š\n\nx2 &lt;- list(a = 1:2, b = 1:3, c = 1:4)\nx2\n#&gt; $a\n#&gt; [1] 1 2\n#&gt; \n#&gt; $b\n#&gt; [1] 1 2 3\n#&gt; \n#&gt; $c\n#&gt; [1] 1 2 3 4\n\nEven for these very simple lists, printing takes up quite a lot of space. A useful alternative is str(), which generates a compact display of the structure, de-emphasizing the contents:\nå³ä½¿æ˜¯è¿™äº›éå¸¸ç®€å•çš„åˆ—è¡¨ï¼Œæ‰“å°å‡ºæ¥ä¹Ÿä¼šå ç”¨ç›¸å½“å¤§çš„ç©ºé—´ã€‚ä¸€ä¸ªæœ‰ç”¨çš„æ›¿ä»£æ–¹æ³•æ˜¯ str()ï¼Œå®ƒä¼šç”Ÿæˆä¸€ä¸ªç´§å‡‘çš„ç»“æ„ (structure) æ˜¾ç¤ºï¼Œå¹¶æ·¡åŒ–å…¶å†…å®¹ï¼š\n\nstr(x1)\n#&gt; List of 3\n#&gt;  $ : int [1:4] 1 2 3 4\n#&gt;  $ : chr \"a\"\n#&gt;  $ : logi TRUE\nstr(x2)\n#&gt; List of 3\n#&gt;  $ a: int [1:2] 1 2\n#&gt;  $ b: int [1:3] 1 2 3\n#&gt;  $ c: int [1:4] 1 2 3 4\n\nAs you can see, str() displays each child of the list on its own line. It displays the name, if present, then an abbreviation of the type, then the first few values.\nå¦‚ä½ æ‰€è§ï¼Œstr() å°†åˆ—è¡¨çš„æ¯ä¸ªå­å…ƒç´ æ˜¾ç¤ºåœ¨å•ç‹¬çš„ä¸€è¡Œä¸Šã€‚å®ƒä¼šæ˜¾ç¤ºåç§°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œç„¶åæ˜¯ç±»å‹çš„ç¼©å†™ï¼Œæœ€åæ˜¯å‰å‡ ä¸ªå€¼ã€‚\n\n23.2.1 Hierarchy\nLists can contain any type of object, including other lists. This makes them suitable for representing hierarchical (tree-like) structures:\nåˆ—è¡¨å¯ä»¥åŒ…å«ä»»ä½•ç±»å‹çš„å¯¹è±¡ï¼ŒåŒ…æ‹¬å…¶ä»–åˆ—è¡¨ã€‚è¿™ä½¿å¾—å®ƒä»¬éå¸¸é€‚åˆè¡¨ç¤ºåˆ†å±‚ï¼ˆæ ‘çŠ¶ï¼‰ç»“æ„ï¼š\n\nx3 &lt;- list(list(1, 2), list(3, 4))\nstr(x3)\n#&gt; List of 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 1\n#&gt;   ..$ : num 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 3\n#&gt;   ..$ : num 4\n\nThis is notably different to c(), which generates a flat vector:\nè¿™ä¸ c() å‡½æ•°æ˜¾è‘—ä¸åŒï¼Œc() å‡½æ•°ä¼šç”Ÿæˆä¸€ä¸ªæ‰å¹³çš„å‘é‡ï¼š\n\nc(c(1, 2), c(3, 4))\n#&gt; [1] 1 2 3 4\n\nx4 &lt;- c(list(1, 2), list(3, 4))\nstr(x4)\n#&gt; List of 4\n#&gt;  $ : num 1\n#&gt;  $ : num 2\n#&gt;  $ : num 3\n#&gt;  $ : num 4\n\nAs lists get more complex, str() gets more useful, as it lets you see the hierarchy at a glance:\néšç€åˆ—è¡¨å˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œstr() çš„ç”¨å¤„ä¹Ÿè¶Šæ¥è¶Šå¤§ï¼Œå› ä¸ºå®ƒèƒ½è®©ä½ ä¸€ç›®äº†ç„¶åœ°çœ‹åˆ°å±‚çº§ç»“æ„ï¼š\n\nx5 &lt;- list(1, list(2, list(3, list(4, list(5)))))\nstr(x5)\n#&gt; List of 2\n#&gt;  $ : num 1\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 2\n#&gt;   ..$ :List of 2\n#&gt;   .. ..$ : num 3\n#&gt;   .. ..$ :List of 2\n#&gt;   .. .. ..$ : num 4\n#&gt;   .. .. ..$ :List of 1\n#&gt;   .. .. .. ..$ : num 5\n\nAs lists get even larger and more complex, str() eventually starts to fail, and youâ€™ll need to switch to View()1. FigureÂ 23.1 shows the result of calling View(x5). The viewer starts by showing just the top level of the list, but you can interactively expand any of the components to see more, as in FigureÂ 23.2. RStudio will also show you the code you need to access that element, as in FigureÂ 23.3. Weâ€™ll come back to how this code works in Section 27.3.\nå½“åˆ—è¡¨å˜å¾—æ›´å¤§ã€æ›´å¤æ‚æ—¶ï¼Œstr() æœ€ç»ˆä¼šå˜å¾—åŠ›ä¸ä»å¿ƒï¼Œè¿™æ—¶ä½ å°±éœ€è¦åˆ‡æ¢åˆ° View() 1ã€‚FigureÂ 23.1 å±•ç¤ºäº†è°ƒç”¨ View(x5) çš„ç»“æœã€‚æŸ¥çœ‹å™¨å¼€å§‹æ—¶åªæ˜¾ç¤ºåˆ—è¡¨çš„é¡¶å±‚ï¼Œä½†ä½ å¯ä»¥äº¤äº’å¼åœ°å±•å¼€ä»»ä½•ç»„ä»¶ä»¥æŸ¥çœ‹æ›´å¤šå†…å®¹ï¼Œå¦‚ FigureÂ 23.2 æ‰€ç¤ºã€‚RStudio è¿˜ä¼šå‘ä½ æ˜¾ç¤ºè®¿é—®è¯¥å…ƒç´ æ‰€éœ€ä»£ç ï¼Œå¦‚ FigureÂ 23.3 æ‰€ç¤ºã€‚æˆ‘ä»¬å°†åœ¨ Section 27.3 å›é¡¾è¿™æ®µä»£ç æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚\n\n\n\n\n\n\n\nFigureÂ 23.1: The RStudio view lets you interactively explore a complex list. The viewer opens showing only the top level of the list.\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 23.2: Clicking on the rightward facing triangle expands that component of the list so that you can also see its children.\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 23.3: You can repeat this operation as many times as needed to get to the data youâ€™re interested in. Note the bottom-left corner: if you click an element of the list, RStudio will give you the subsetting code needed to access it, in this case x5[[2]][[2]][[2]].\n\n\n\n\n\n23.2.2 List-columns\nLists can also live inside a tibble, where we call them list-columns. List-columns are useful because they allow you to place objects in a tibble that wouldnâ€™t usually belong in there. In particular, list-columns are used a lot in the tidymodels ecosystem, because they allow you to store things like model outputs or resamples in a data frame.\nåˆ—è¡¨ä¹Ÿå¯ä»¥å­˜åœ¨äº tibble ä¸­ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºåˆ—è¡¨åˆ— (list-columns)ã€‚åˆ—è¡¨åˆ—å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒä»¬å…è®¸ä½ å°†é€šå¸¸ä¸å±äº tibble çš„å¯¹è±¡æ”¾å…¥å…¶ä¸­ã€‚ç‰¹åˆ«åœ°ï¼Œåˆ—è¡¨åˆ—åœ¨ tidymodels ç”Ÿæ€ç³»ç»Ÿä¸­è¢«å¤§é‡ä½¿ç”¨ï¼Œå› ä¸ºå®ƒä»¬å…è®¸ä½ å°†æ¨¡å‹è¾“å‡ºæˆ–é‡é‡‡æ ·ç­‰å†…å®¹å­˜å‚¨åœ¨æ•°æ®æ¡†ä¸­ã€‚\nHereâ€™s a simple example of a list-column:\nä¸‹é¢æ˜¯åˆ—è¡¨åˆ—çš„ä¸€ä¸ªç®€å•ç¤ºä¾‹ï¼š\n\ndf &lt;- tibble(\n  x = 1:2, \n  y = c(\"a\", \"b\"),\n  z = list(list(1, 2), list(3, 4, 5))\n)\ndf\n#&gt; # A tibble: 2 Ã— 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n#&gt; 2     2 b     &lt;list [3]&gt;\n\nThereâ€™s nothing special about lists in a tibble; they behave like any other column:\ntibble ä¸­çš„åˆ—è¡¨æ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«ä¹‹å¤„ï¼›å®ƒä»¬çš„è¡Œä¸ºä¸ä»»ä½•å…¶ä»–åˆ—ä¸€æ ·ï¼š\n\ndf |&gt; \n  filter(x == 1)\n#&gt; # A tibble: 1 Ã— 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n\nComputing with list-columns is harder, but thatâ€™s because computing with lists is harder in general; weâ€™ll come back to that in Chapter 26. In this chapter, weâ€™ll focus on unnesting list-columns out into regular variables so you can use your existing tools on them.\nä½¿ç”¨åˆ—è¡¨åˆ—è¿›è¡Œè®¡ç®—æ›´åŠ å›°éš¾ï¼Œä½†è¿™æ˜¯å› ä¸ºé€šå¸¸æƒ…å†µä¸‹ä½¿ç”¨åˆ—è¡¨è¿›è¡Œè®¡ç®—å°±æ›´éš¾ï¼›æˆ‘ä»¬å°†åœ¨ Chapter 26 å›åˆ°è¿™ä¸ªé—®é¢˜ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºå°†åˆ—è¡¨åˆ—â€œå±•å¼€â€ (unnesting) ä¸ºå¸¸è§„å˜é‡ï¼Œä»¥ä¾¿ä½ å¯ä»¥ä½¿ç”¨ç°æœ‰çš„å·¥å…·æ¥å¤„ç†å®ƒä»¬ã€‚\nThe default print method just displays a rough summary of the contents. The list column could be arbitrarily complex, so thereâ€™s no good way to print it. If you want to see it, youâ€™ll need to pull out just the one list-column and apply one of the techniques that youâ€™ve learned above, like df |&gt; pull(z) |&gt; str() or df |&gt; pull(z) |&gt; View().\né»˜è®¤çš„æ‰“å°æ–¹æ³•åªæ˜¾ç¤ºäº†å†…å®¹çš„ç²—ç•¥æ‘˜è¦ã€‚åˆ—è¡¨åˆ—å¯èƒ½ä»»æ„å¤æ‚ï¼Œæ‰€ä»¥æ²¡æœ‰å¾ˆå¥½çš„æ–¹æ³•æ¥æ‰“å°å®ƒã€‚å¦‚æœä½ æƒ³æŸ¥çœ‹å®ƒï¼Œä½ éœ€è¦å•ç‹¬æŠ½å–å‡ºé‚£ä¸ªåˆ—è¡¨åˆ—ï¼Œå¹¶åº”ç”¨ä½ ä¸Šé¢å­¦åˆ°çš„æŠ€æœ¯ä¹‹ä¸€ï¼Œæ¯”å¦‚ df |&gt; pull(z) |&gt; str() æˆ– df |&gt; pull(z) |&gt; View()ã€‚\n\n\n\n\n\n\nBase R\n\n\n\nItâ€™s possible to put a list in a column of a data.frame, but itâ€™s a lot fiddlier because data.frame() treats a list as a list of columns:\nå¯ä»¥åœ¨ data.frame çš„ä¸€åˆ—ä¸­æ”¾å…¥ä¸€ä¸ªåˆ—è¡¨ï¼Œä½†è¿™è¦éº»çƒ¦å¾—å¤šï¼Œå› ä¸º data.frame() å°†åˆ—è¡¨è§†ä¸ºåˆ—çš„åˆ—è¡¨ï¼š\n\ndata.frame(x = list(1:3, 3:5))\n#&gt;   x.1.3 x.3.5\n#&gt; 1     1     3\n#&gt; 2     2     4\n#&gt; 3     3     5\n\nYou can force data.frame() to treat a list as a list of rows by wrapping it in list I(), but the result doesnâ€™t print particularly well:\nä½ å¯ä»¥é€šè¿‡å°†åˆ—è¡¨åŒ…è£…åœ¨ I() ä¸­æ¥å¼ºåˆ¶ data.frame() å°†å…¶è§†ä¸ºè¡Œçš„åˆ—è¡¨ï¼Œä½†ç»“æœæ‰“å°å¾—ä¸æ˜¯ç‰¹åˆ«å¥½ï¼š\n\ndata.frame(\n  x = I(list(1:2, 3:5)), \n  y = c(\"1, 2\", \"3, 4, 5\")\n)\n#&gt;         x       y\n#&gt; 1    1, 2    1, 2\n#&gt; 2 3, 4, 5 3, 4, 5\n\nItâ€™s easier to use list-columns with tibbles because tibble() treats lists like vectors and the print method has been designed with lists in mind.\nä½¿ç”¨ tibble æ¥å¤„ç†åˆ—è¡¨åˆ—æ›´å®¹æ˜“ï¼Œå› ä¸º tibble() å°†åˆ—è¡¨è§†ä¸ºå‘é‡ï¼Œå¹¶ä¸”å…¶æ‰“å°æ–¹æ³•æ˜¯ä¸ºåˆ—è¡¨è€Œä¸“é—¨è®¾è®¡çš„ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#unnesting",
    "href": "rectangling.html#unnesting",
    "title": "23Â  Hierarchical data",
    "section": "\n23.3 Unnesting",
    "text": "23.3 Unnesting\nNow that youâ€™ve learned the basics of lists and list-columns, letâ€™s explore how you can turn them back into regular rows and columns. Here weâ€™ll use very simple sample data so you can get the basic idea; in the next section weâ€™ll switch to real data.\næ—¢ç„¶ä½ å·²ç»äº†è§£äº†åˆ—è¡¨å’Œåˆ—è¡¨åˆ—çš„åŸºç¡€çŸ¥è¯†ï¼Œè®©æˆ‘ä»¬æ¥æ¢è®¨å¦‚ä½•å°†å®ƒä»¬è½¬æ¢å›å¸¸è§„çš„è¡Œå’Œåˆ—ã€‚è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨éå¸¸ç®€å•çš„ç¤ºä¾‹æ•°æ®ï¼Œä»¥ä¾¿ä½ æŒæ¡åŸºæœ¬æ¦‚å¿µï¼›åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è½¬å‘çœŸå®æ•°æ®ã€‚\nList-columns tend to come in two basic forms: named and unnamed. When the children are named, they tend to have the same names in every row. For example, in df1, every element of list-column y has two elements named a and b. Named list-columns naturally unnest into columns: each named element becomes a new named column.\nåˆ—è¡¨åˆ—é€šå¸¸æœ‰ä¸¤ç§åŸºæœ¬å½¢å¼ï¼šå‘½åçš„å’Œæœªå‘½åçš„ã€‚å½“å­å…ƒç´ æ˜¯å‘½åçš„ (named) æ—¶ï¼Œå®ƒä»¬åœ¨æ¯ä¸€è¡Œä¸­å¾€å¾€å…·æœ‰ç›¸åŒçš„åç§°ã€‚ä¾‹å¦‚ï¼Œåœ¨ df1 ä¸­ï¼Œåˆ—è¡¨åˆ— y çš„æ¯ä¸ªå…ƒç´ éƒ½æœ‰ä¸¤ä¸ªåä¸º a å’Œ b çš„å…ƒç´ ã€‚å‘½åçš„åˆ—è¡¨åˆ—å¾ˆè‡ªç„¶åœ°å¯ä»¥å±•å¼€ä¸ºåˆ—ï¼šæ¯ä¸ªå‘½åå…ƒç´ éƒ½ä¼šæˆä¸ºä¸€ä¸ªæ–°çš„å‘½ååˆ—ã€‚\n\ndf1 &lt;- tribble(\n  ~x, ~y,\n  1, list(a = 11, b = 12),\n  2, list(a = 21, b = 22),\n  3, list(a = 31, b = 32),\n)\n\nWhen the children are unnamed, the number of elements tends to vary from row-to-row. For example, in df2, the elements of list-column y are unnamed and vary in length from one to three. Unnamed list-columns naturally unnest into rows: youâ€™ll get one row for each child.\nå½“å­å…ƒç´ æ˜¯æœªå‘½åçš„ (unnamed) æ—¶ï¼Œå…ƒç´ çš„æ•°é‡å¾€å¾€å› è¡Œè€Œå¼‚ã€‚ä¾‹å¦‚ï¼Œåœ¨ df2 ä¸­ï¼Œåˆ—è¡¨åˆ— y çš„å…ƒç´ æ˜¯æœªå‘½åçš„ï¼Œå¹¶ä¸”é•¿åº¦ä»ä¸€åˆ°ä¸‰ä¸ç­‰ã€‚æœªå‘½åçš„åˆ—è¡¨åˆ—å¾ˆè‡ªç„¶åœ°å¯ä»¥å±•å¼€ä¸ºè¡Œï¼šæ¯ä¸ªå­å…ƒç´ éƒ½ä¼šç”Ÿæˆæ–°çš„ä¸€è¡Œã€‚\n\ndf2 &lt;- tribble(\n  ~x, ~y,\n  1, list(11, 12, 13),\n  2, list(21),\n  3, list(31, 32),\n)\n\ntidyr provides two functions for these two cases: unnest_wider() and unnest_longer(). The following sections explain how they work.\ntidyr ä¸ºè¿™ä¸¤ç§æƒ…å†µæä¾›äº†ä¸¤ä¸ªå‡½æ•°ï¼šunnest_wider() å’Œ unnest_longer()ã€‚ä»¥ä¸‹å„èŠ‚å°†è§£é‡Šå®ƒä»¬çš„å·¥ä½œåŸç†ã€‚\n\n23.3.1 unnest_wider()\n\nWhen each row has the same number of elements with the same names, like df1, itâ€™s natural to put each component into its own column with unnest_wider():\nå½“æ¯ä¸€è¡Œéƒ½æœ‰ç›¸åŒæ•°é‡ä¸”åç§°ç›¸åŒçš„å…ƒç´ æ—¶ï¼Œå°±åƒ df1 ä¸€æ ·ï¼Œå¾ˆè‡ªç„¶åœ°å¯ä»¥ä½¿ç”¨ unnest_wider() å°†æ¯ä¸ªç»„ä»¶æ”¾å…¥å„è‡ªçš„åˆ—ä¸­ï¼š\n\ndf1 |&gt; \n  unnest_wider(y)\n#&gt; # A tibble: 3 Ã— 3\n#&gt;       x     a     b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\nBy default, the names of the new columns come exclusively from the names of the list elements, but you can use the names_sep argument to request that they combine the column name and the element name. This is useful for disambiguating repeated names.\né»˜è®¤æƒ…å†µä¸‹ï¼Œæ–°åˆ—çš„åç§°å®Œå…¨æ¥è‡ªåˆ—è¡¨å…ƒç´ çš„åç§°ï¼Œä½†ä½ å¯ä»¥ä½¿ç”¨ names_sep å‚æ•°æ¥è¦æ±‚å®ƒä»¬åˆå¹¶åˆ—åå’Œå…ƒç´ åã€‚è¿™å¯¹äºæ¶ˆé™¤é‡å¤åç§°çš„æ­§ä¹‰å¾ˆæœ‰ç”¨ã€‚\n\ndf1 |&gt; \n  unnest_wider(y, names_sep = \"_\")\n#&gt; # A tibble: 3 Ã— 3\n#&gt;       x   y_a   y_b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\n\n23.3.2 unnest_longer()\n\nWhen each row contains an unnamed list, itâ€™s most natural to put each element into its own row with unnest_longer():\nå½“æ¯ä¸€è¡Œéƒ½åŒ…å«ä¸€ä¸ªæœªå‘½åçš„åˆ—è¡¨æ—¶ï¼Œæœ€è‡ªç„¶çš„åšæ³•æ˜¯ä½¿ç”¨ unnest_longer() å°†æ¯ä¸ªå…ƒç´ æ”¾å…¥å…¶è‡ªå·±çš„è¡Œä¸­ï¼š\n\ndf2 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 6 Ã— 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11\n#&gt; 2     1    12\n#&gt; 3     1    13\n#&gt; 4     2    21\n#&gt; 5     3    31\n#&gt; 6     3    32\n\nNote how x is duplicated for each element inside of y: we get one row of output for each element inside the list-column. But what happens if one of the elements is empty, as in the following example?\næ³¨æ„ x æ˜¯å¦‚ä½•ä¸º y å†…çš„æ¯ä¸ªå…ƒç´ å¤åˆ¶çš„ï¼šå¯¹äºåˆ—è¡¨åˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬éƒ½ä¼šå¾—åˆ°ä¸€è¡Œè¾“å‡ºã€‚ä½†æ˜¯ï¼Œå¦‚æœå…¶ä¸­ä¸€ä¸ªå…ƒç´ ä¸ºç©ºï¼Œå¦‚ä¸‹é¢çš„ä¾‹å­æ‰€ç¤ºï¼Œä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ\n\ndf6 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1, 2),\n  \"b\", list(3),\n  \"c\", list()\n)\ndf6 |&gt; unnest_longer(y)\n#&gt; # A tibble: 3 Ã— 2\n#&gt;   x         y\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 a         1\n#&gt; 2 a         2\n#&gt; 3 b         3\n\nWe get zero rows in the output, so the row effectively disappears. If you want to preserve that row, adding NA in y, set keep_empty = TRUE.\næˆ‘ä»¬åœ¨è¾“å‡ºä¸­å¾—åˆ°é›¶è¡Œï¼Œå› æ­¤è¯¥è¡Œå®é™…ä¸Šæ¶ˆå¤±äº†ã€‚å¦‚æœä½ æƒ³ä¿ç•™é‚£ä¸€è¡Œï¼Œå¹¶åœ¨ y ä¸­æ·»åŠ  NAï¼Œè¯·è®¾ç½® keep_empty = TRUEã€‚\n\n23.3.3 Inconsistent types\nWhat happens if you unnest a list-column that contains different types of vector? For example, take the following dataset where the list-column y contains two numbers, a character, and a logical, which canâ€™t normally be mixed in a single column.\nå¦‚æœä½ å±•å¼€ä¸€ä¸ªåŒ…å«ä¸åŒç±»å‹å‘é‡çš„åˆ—è¡¨åˆ—ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿä¾‹å¦‚ï¼Œçœ‹ä¸‹é¢è¿™ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åˆ—è¡¨åˆ— y åŒ…å«ä¸¤ä¸ªæ•°å­—ã€ä¸€ä¸ªå­—ç¬¦å’Œä¸€ä¸ªé€»è¾‘å€¼ï¼Œè¿™äº›é€šå¸¸ä¸èƒ½åœ¨å•ä¸ªåˆ—ä¸­æ··åˆã€‚\n\ndf4 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1),\n  \"b\", list(\"a\", TRUE, 5)\n)\n\nunnest_longer() always keeps the set of columns unchanged, while changing the number of rows. So what happens? How does unnest_longer() produce five rows while keeping everything in y?unnest_longer() æ€»æ˜¯ä¿æŒåˆ—é›†åˆä¸å˜ï¼ŒåŒæ—¶æ”¹å˜è¡Œçš„æ•°é‡ã€‚é‚£ä¹ˆä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿunnest_longer() æ˜¯å¦‚ä½•åœ¨ä¿æŒ y ä¸­æ‰€æœ‰å†…å®¹çš„åŒæ—¶ç”Ÿæˆäº”è¡Œçš„å‘¢ï¼Ÿ\n\ndf4 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 4 Ã— 2\n#&gt;   x     y        \n#&gt;   &lt;chr&gt; &lt;list&gt;   \n#&gt; 1 a     &lt;dbl [1]&gt;\n#&gt; 2 b     &lt;chr [1]&gt;\n#&gt; 3 b     &lt;lgl [1]&gt;\n#&gt; 4 b     &lt;dbl [1]&gt;\n\nAs you can see, the output contains a list-column, but every element of the list-column contains a single element. Because unnest_longer() canâ€™t find a common type of vector, it keeps the original types in a list-column. You might wonder if this breaks the commandment that every element of a column must be the same type. It doesnâ€™t: every element is a list, even though the contents are of different types.\næ­£å¦‚ä½ æ‰€è§ï¼Œè¾“å‡ºåŒ…å«ä¸€ä¸ªåˆ—è¡¨åˆ—ï¼Œä½†è¯¥åˆ—è¡¨åˆ—çš„æ¯ä¸ªå…ƒç´ éƒ½åªåŒ…å«ä¸€ä¸ªå•ä¸€å…ƒç´ ã€‚å› ä¸º unnest_longer() æ‰¾ä¸åˆ°ä¸€ä¸ªé€šç”¨çš„å‘é‡ç±»å‹ï¼Œæ‰€ä»¥å®ƒå°†åŸå§‹ç±»å‹ä¿ç•™åœ¨ä¸€ä¸ªåˆ—è¡¨åˆ—ä¸­ã€‚ä½ å¯èƒ½ä¼šå¥½å¥‡è¿™æ˜¯å¦è¿åäº†â€œåˆ—çš„æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯ç›¸åŒç±»å‹â€çš„è§„å®šã€‚ç­”æ¡ˆæ˜¯å¦å®šçš„ï¼šæ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå°½ç®¡å…¶å†…å®¹æ˜¯ä¸åŒç±»å‹çš„ã€‚\nDealing with inconsistent types is challenging and the details depend on the precise nature of the problem and your goals, but youâ€™ll most likely need tools from Chapter 26.\nå¤„ç†ä¸ä¸€è‡´çš„ç±»å‹æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå…·ä½“ç»†èŠ‚å–å†³äºé—®é¢˜çš„ç¡®åˆ‡æ€§è´¨å’Œä½ çš„ç›®æ ‡ï¼Œä½†ä½ å¾ˆå¯èƒ½éœ€è¦æ¥è‡ª Chapter 26 çš„å·¥å…·ã€‚\n\n23.3.4 Other functions\ntidyr has a few other useful rectangling functions that weâ€™re not going to cover in this book:\ntidyr è¿˜æœ‰ä¸€äº›å…¶ä»–æœ‰ç”¨çš„çŸ©å½¢åŒ–å‡½æ•°ï¼Œæˆ‘ä»¬åœ¨è¿™æœ¬ä¹¦ä¸­ä¸ä¼šæ¶‰åŠï¼š\n\nunnest_auto() automatically picks between unnest_longer() and unnest_wider() based on the structure of the list-column. Itâ€™s great for rapid exploration, but ultimately itâ€™s a bad idea because it doesnâ€™t force you to understand how your data is structured, and makes your code harder to understand.unnest_auto() ä¼šæ ¹æ®åˆ—è¡¨åˆ—çš„ç»“æ„è‡ªåŠ¨åœ¨ unnest_longer() å’Œ unnest_wider() ä¹‹é—´è¿›è¡Œé€‰æ‹©ã€‚å®ƒéå¸¸é€‚åˆå¿«é€Ÿæ¢ç´¢ï¼Œä½†æœ€ç»ˆæ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªåä¸»æ„ï¼Œå› ä¸ºå®ƒä¸ä¼šè¿«ä½¿ä½ å»ç†è§£ä½ çš„æ•°æ®ç»“æ„ï¼Œå¹¶ä½¿ä½ çš„ä»£ç æ›´éš¾ç†è§£ã€‚\nunnest() expands both rows and columns. Itâ€™s useful when you have a list-column that contains a 2d structure like a data frame, which you donâ€™t see in this book, but you might encounter if you use the tidymodels ecosystem.unnest() ä¼šåŒæ—¶æ‰©å±•è¡Œå’Œåˆ—ã€‚å½“ä½ çš„åˆ—è¡¨åˆ—åŒ…å«åƒæ•°æ®æ¡†è¿™æ ·çš„äºŒç»´ç»“æ„æ—¶ï¼Œå®ƒå¾ˆæœ‰ç”¨ï¼Œè¿™åœ¨æœ¬ä¹¦ä¸­ä½ ä¸ä¼šçœ‹åˆ°ï¼Œä½†å¦‚æœä½ ä½¿ç”¨ tidymodels ç”Ÿæ€ç³»ç»Ÿï¼Œä½ å¯èƒ½ä¼šé‡åˆ°ã€‚\n\nThese functions are good to know about as you might encounter them when reading other peopleâ€™s code or tackling rarer rectangling challenges yourself.\näº†è§£è¿™äº›å‡½æ•°æ˜¯å¾ˆæœ‰å¥½å¤„çš„ï¼Œå› ä¸ºåœ¨é˜…è¯»ä»–äººçš„ä»£ç æˆ–è‡ªå·±å¤„ç†æ›´ç½•è§çš„çŸ©å½¢åŒ–æŒ‘æˆ˜æ—¶ï¼Œä½ å¯èƒ½ä¼šé‡åˆ°å®ƒä»¬ã€‚\n\n23.3.5 Exercises\n\nWhat happens when you use unnest_wider() with unnamed list-columns like df2? What argument is now necessary? What happens to missing values?\nWhat happens when you use unnest_longer() with named list-columns like df1? What additional information do you get in the output? How can you suppress that extra detail?\n\nFrom time-to-time you encounter data frames with multiple list-columns with aligned values. For example, in the following data frame, the values of y and z are aligned (i.e.Â y and z will always have the same length within a row, and the first value of y corresponds to the first value of z). What happens if you apply two unnest_longer() calls to this data frame? How can you preserve the relationship between x and y? (Hint: carefully read the docs).\n\ndf4 &lt;- tribble(\n  ~x, ~y, ~z,\n  \"a\", list(\"y-a-1\", \"y-a-2\"), list(\"z-a-1\", \"z-a-2\"),\n  \"b\", list(\"y-b-1\", \"y-b-2\", \"y-b-3\"), list(\"z-b-1\", \"z-b-2\", \"z-b-3\")\n)",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#case-studies",
    "href": "rectangling.html#case-studies",
    "title": "23Â  Hierarchical data",
    "section": "\n23.4 Case studies",
    "text": "23.4 Case studies\nThe main difference between the simple examples we used above and real data is that real data typically contains multiple levels of nesting that require multiple calls to unnest_longer() and/or unnest_wider(). To show that in action, this section works through three real rectangling challenges using datasets from the repurrrsive package.\næˆ‘ä»¬ä¸Šé¢ä½¿ç”¨çš„ç®€å•ç¤ºä¾‹ä¸çœŸå®æ•°æ®ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼ŒçœŸå®æ•°æ®é€šå¸¸åŒ…å«å¤šä¸ªåµŒå¥—å±‚çº§ï¼Œéœ€è¦å¤šæ¬¡è°ƒç”¨ unnest_longer() å’Œ/æˆ– unnest_wider()ã€‚ä¸ºäº†å®é™…å±•ç¤ºè¿™ä¸€ç‚¹ï¼Œæœ¬èŠ‚å°†ä½¿ç”¨æ¥è‡ª repurrrsive åŒ…çš„æ•°æ®é›†ï¼Œé€šè¿‡ä¸‰ä¸ªçœŸå®çš„çŸ©å½¢åŒ–æŒ‘æˆ˜æ¥è¿›è¡Œè®²è§£ã€‚\n\n23.4.1 Very wide data\nWeâ€™ll start with gh_repos. This is a list that contains data about a collection of GitHub repositories retrieved using the GitHub API. Itâ€™s a very deeply nested list so itâ€™s difficult to show the structure in this book; we recommend exploring a little on your own with View(gh_repos) before we continue.\næˆ‘ä»¬ä» gh_repos å¼€å§‹ã€‚è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«é€šè¿‡ GitHub API æ£€ç´¢åˆ°çš„å…³äºä¸€ç»„ GitHub ä»“åº“çš„æ•°æ®ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æ·±å±‚åµŒå¥—çš„åˆ—è¡¨ï¼Œå› æ­¤å¾ˆéš¾åœ¨æœ¬ä¹¦ä¸­å±•ç¤ºå…¶ç»“æ„ï¼›æˆ‘ä»¬å»ºè®®åœ¨ç»§ç»­ä¹‹å‰ï¼Œä½ å¯ä»¥è‡ªå·±ç”¨ View(gh_repos) ç¨ä½œæ¢ç´¢ã€‚\ngh_repos is a list, but our tools work with list-columns, so weâ€™ll begin by putting it into a tibble. We call this column json for reasons weâ€™ll get to later.gh_repos æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œä½†æˆ‘ä»¬çš„å·¥å…·æ˜¯é’ˆå¯¹åˆ—è¡¨åˆ—å·¥ä½œçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬é¦–å…ˆè¦æŠŠå®ƒæ”¾è¿›ä¸€ä¸ª tibble ä¸­ã€‚æˆ‘ä»¬å°†è¿™ä¸€åˆ—å‘½åä¸º jsonï¼ŒåŸå› ç¨åä¼šè§£é‡Šã€‚\n\nrepos &lt;- tibble(json = gh_repos)\nrepos\n#&gt; # A tibble: 6 Ã— 1\n#&gt;   json       \n#&gt;   &lt;list&gt;     \n#&gt; 1 &lt;list [30]&gt;\n#&gt; 2 &lt;list [30]&gt;\n#&gt; 3 &lt;list [30]&gt;\n#&gt; 4 &lt;list [26]&gt;\n#&gt; 5 &lt;list [30]&gt;\n#&gt; 6 &lt;list [30]&gt;\n\nThis tibble contains 6 rows, one row for each child of gh_repos. Each row contains an unnamed list with either 26 or 30 rows. Since these are unnamed, weâ€™ll start with unnest_longer() to put each child in its own row:\nè¿™ä¸ª tibble åŒ…å« 6 è¡Œï¼Œgh_repos çš„æ¯ä¸ªå­å…ƒç´ å ä¸€è¡Œã€‚æ¯ä¸€è¡Œéƒ½åŒ…å«ä¸€ä¸ªæœªå‘½åçš„åˆ—è¡¨ï¼Œè¯¥åˆ—è¡¨æœ‰ 26 æˆ– 30 è¡Œã€‚ç”±äºè¿™äº›åˆ—è¡¨æ˜¯æœªå‘½åçš„ï¼Œæˆ‘ä»¬å…ˆä½¿ç”¨ unnest_longer() å°†æ¯ä¸ªå­å…ƒç´ æ”¾åˆ°å•ç‹¬çš„è¡Œä¸­ï¼š\n\nrepos |&gt; \n  unnest_longer(json)\n#&gt; # A tibble: 176 Ã— 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [68]&gt;\n#&gt; 2 &lt;named list [68]&gt;\n#&gt; 3 &lt;named list [68]&gt;\n#&gt; 4 &lt;named list [68]&gt;\n#&gt; 5 &lt;named list [68]&gt;\n#&gt; 6 &lt;named list [68]&gt;\n#&gt; # â„¹ 170 more rows\n\nAt first glance, it might seem like we havenâ€™t improved the situation: while we have more rows (176 instead of 6) each element of json is still a list. However, thereâ€™s an important difference: now each element is a named list so we can use unnest_wider() to put each element into its own column:\nä¹ä¸€çœ‹ï¼Œæƒ…å†µä¼¼ä¹å¹¶æ²¡æœ‰æ”¹å–„ï¼šè™½ç„¶æˆ‘ä»¬æœ‰äº†æ›´å¤šçš„è¡Œï¼ˆ176 è¡Œè€Œä¸æ˜¯ 6 è¡Œï¼‰ï¼Œä½† json çš„æ¯ä¸ªå…ƒç´ ä»ç„¶æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚ç„¶è€Œï¼Œæœ‰ä¸€ä¸ªé‡è¦çš„åŒºåˆ«ï¼šç°åœ¨æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå·²å‘½åçš„åˆ—è¡¨ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ unnest_wider() å°†æ¯ä¸ªå…ƒç´ æ”¾å…¥å…¶è‡ªå·±çš„åˆ—ä¸­ï¼š\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) \n#&gt; # A tibble: 176 Ã— 68\n#&gt;         id name        full_name         owner        private html_url       \n#&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;list&gt;       &lt;lgl&gt;   &lt;chr&gt;          \n#&gt; 1 61160198 after       gaborcsardi/after &lt;named list&gt; FALSE   https://githubâ€¦\n#&gt; 2 40500181 argufy      gaborcsardi/arguâ€¦ &lt;named list&gt; FALSE   https://githubâ€¦\n#&gt; 3 36442442 ask         gaborcsardi/ask   &lt;named list&gt; FALSE   https://githubâ€¦\n#&gt; 4 34924886 baseimports gaborcsardi/baseâ€¦ &lt;named list&gt; FALSE   https://githubâ€¦\n#&gt; 5 61620661 citest      gaborcsardi/citeâ€¦ &lt;named list&gt; FALSE   https://githubâ€¦\n#&gt; 6 33907457 clisymbols  gaborcsardi/clisâ€¦ &lt;named list&gt; FALSE   https://githubâ€¦\n#&gt; # â„¹ 170 more rows\n#&gt; # â„¹ 62 more variables: description &lt;chr&gt;, fork &lt;lgl&gt;, url &lt;chr&gt;, â€¦\n\nThis has worked but the result is a little overwhelming: there are so many columns that tibble doesnâ€™t even print all of them! We can see them all with names(); and here we look at the first 10:\nè¿™æ‹›å¥æ•ˆäº†ï¼Œä½†ç»“æœæœ‰ç‚¹è®©äººä¸çŸ¥æ‰€æªï¼šåˆ—å¤ªå¤šäº†ï¼Œä»¥è‡³äº tibble ç”šè‡³éƒ½æ— æ³•å…¨éƒ¨æ‰“å°å‡ºæ¥ï¼æˆ‘ä»¬å¯ä»¥ç”¨ names() æŸ¥çœ‹æ‰€æœ‰åˆ—ï¼›è¿™é‡Œæˆ‘ä»¬çœ‹ä¸€ä¸‹å‰ 10 ä¸ªï¼š\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  names() |&gt; \n  head(10)\n#&gt;  [1] \"id\"          \"name\"        \"full_name\"   \"owner\"       \"private\"    \n#&gt;  [6] \"html_url\"    \"description\" \"fork\"        \"url\"         \"forks_url\"\n\nLetâ€™s pull out a few that look interesting:\nè®©æˆ‘ä»¬æŒ‘å‡ºå‡ ä¸ªçœ‹èµ·æ¥æœ‰è¶£çš„åˆ—ï¼š\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description)\n#&gt; # A tibble: 176 Ã— 4\n#&gt;         id full_name               owner             description             \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;list&gt;            &lt;chr&gt;                   \n#&gt; 1 61160198 gaborcsardi/after       &lt;named list [17]&gt; Run Code in the Backgroâ€¦\n#&gt; 2 40500181 gaborcsardi/argufy      &lt;named list [17]&gt; Declarative function arâ€¦\n#&gt; 3 36442442 gaborcsardi/ask         &lt;named list [17]&gt; Friendly CLI interactioâ€¦\n#&gt; 4 34924886 gaborcsardi/baseimports &lt;named list [17]&gt; Do we get warnings for â€¦\n#&gt; 5 61620661 gaborcsardi/citest      &lt;named list [17]&gt; Test R package and repoâ€¦\n#&gt; 6 33907457 gaborcsardi/clisymbols  &lt;named list [17]&gt; Unicode symbols for CLIâ€¦\n#&gt; # â„¹ 170 more rows\n\nYou can use this to work back to understand how gh_repos was structured: each child was a GitHub user containing a list of up to 30 GitHub repositories that they created.\nä½ å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹åå‘æ¨å¯¼å‡º gh_repos çš„ç»“æ„ï¼šæ¯ä¸ªå­å…ƒç´ éƒ½æ˜¯ä¸€ä¸ª GitHub ç”¨æˆ·ï¼ŒåŒ…å«ä¸€ä¸ªç”±ä»–ä»¬åˆ›å»ºçš„å¤šè¾¾ 30 ä¸ª GitHub ä»“åº“çš„åˆ—è¡¨ã€‚\nowner is another list-column, and since it contains a named list, we can use unnest_wider() to get at the values:owner æ˜¯å¦ä¸€ä¸ªåˆ—è¡¨åˆ—ï¼Œç”±äºå®ƒåŒ…å«ä¸€ä¸ªå·²å‘½åçš„åˆ—è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ unnest_wider() æ¥è·å–å…¶å€¼ï¼š\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner)\n#&gt; Error in `unnest_wider()`:\n#&gt; ! Can't duplicate names between the affected columns and the original\n#&gt;   data.\n#&gt; âœ– These names are duplicated:\n#&gt;   â„¹ `id`, from `owner`.\n#&gt; â„¹ Use `names_sep` to disambiguate using the column name.\n#&gt; â„¹ Or use `names_repair` to specify a repair strategy.\n\nUh oh, this list column also contains an id column and we canâ€™t have two id columns in the same data frame. As suggested, lets use names_sep to resolve the problem:\nç³Ÿç³•ï¼Œè¿™ä¸ªåˆ—è¡¨åˆ—ä¹ŸåŒ…å«ä¸€ä¸ª id åˆ—ï¼Œè€Œæˆ‘ä»¬ä¸èƒ½åœ¨åŒä¸€ä¸ªæ•°æ®æ¡†ä¸­æœ‰ä¸¤ä¸ª id åˆ—ã€‚æ ¹æ®æç¤ºï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ names_sep æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner, names_sep = \"_\")\n#&gt; # A tibble: 176 Ã— 20\n#&gt;         id full_name               owner_login owner_id owner_avatar_url     \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;                \n#&gt; 1 61160198 gaborcsardi/after       gaborcsardi   660288 https://avatars.githâ€¦\n#&gt; 2 40500181 gaborcsardi/argufy      gaborcsardi   660288 https://avatars.githâ€¦\n#&gt; 3 36442442 gaborcsardi/ask         gaborcsardi   660288 https://avatars.githâ€¦\n#&gt; 4 34924886 gaborcsardi/baseimports gaborcsardi   660288 https://avatars.githâ€¦\n#&gt; 5 61620661 gaborcsardi/citest      gaborcsardi   660288 https://avatars.githâ€¦\n#&gt; 6 33907457 gaborcsardi/clisymbols  gaborcsardi   660288 https://avatars.githâ€¦\n#&gt; # â„¹ 170 more rows\n#&gt; # â„¹ 15 more variables: owner_gravatar_id &lt;chr&gt;, owner_url &lt;chr&gt;, â€¦\n\nThis gives another wide dataset, but you can get the sense that owner appears to contain a lot of additional data about the person who â€œownsâ€ the repository.\nè¿™ä¼šäº§ç”Ÿå¦ä¸€ä¸ªå®½æ•°æ®é›†ï¼Œä½†ä½ å¯ä»¥æ„Ÿè§‰åˆ° owner åˆ—ä¼¼ä¹åŒ…å«äº†å¤§é‡å…³äºä»“åº“â€œæ‰€æœ‰è€…â€(owner) çš„é™„åŠ æ•°æ®ã€‚\n\n23.4.2 Relational data\nNested data is sometimes used to represent data that weâ€™d usually spread across multiple data frames. For example, take got_chars which contains data about characters that appear in the Game of Thrones books and TV series. Like gh_repos itâ€™s a list, so we start by turning it into a list-column of a tibble:\nåµŒå¥—æ•°æ®æœ‰æ—¶ç”¨äºè¡¨ç¤ºæˆ‘ä»¬é€šå¸¸ä¼šåˆ†æ•£åœ¨å¤šä¸ªæ•°æ®æ¡†ä¸­çš„æ•°æ®ã€‚ä¾‹å¦‚ï¼Œgot_chars åŒ…å«äº†åœ¨ã€ŠæƒåŠ›çš„æ¸¸æˆã€‹ä¹¦ç±å’Œç”µè§†å‰§ä¸­å‡ºç°çš„è§’è‰²çš„æ•°æ®ã€‚å’Œ gh_repos ä¸€æ ·ï¼Œå®ƒæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ‰€ä»¥æˆ‘ä»¬é¦–å…ˆå°†å®ƒè½¬æ¢æˆä¸€ä¸ª tibble çš„åˆ—è¡¨åˆ—ï¼š\n\nchars &lt;- tibble(json = got_chars)\nchars\n#&gt; # A tibble: 30 Ã— 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [18]&gt;\n#&gt; 2 &lt;named list [18]&gt;\n#&gt; 3 &lt;named list [18]&gt;\n#&gt; 4 &lt;named list [18]&gt;\n#&gt; 5 &lt;named list [18]&gt;\n#&gt; 6 &lt;named list [18]&gt;\n#&gt; # â„¹ 24 more rows\n\nThe json column contains named elements, so weâ€™ll start by widening it:json åˆ—åŒ…å«å‘½åå…ƒç´ ï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆå°†å…¶åŠ å®½ï¼š\n\nchars |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 30 Ã— 18\n#&gt;   url                    id name            gender culture    born           \n#&gt;   &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          \n#&gt; 1 https://www.anapioâ€¦  1022 Theon Greyjoy   Male   \"Ironborn\" \"In 278 AC or â€¦\n#&gt; 2 https://www.anapioâ€¦  1052 Tyrion Lannistâ€¦ Male   \"\"         \"In 273 AC, atâ€¦\n#&gt; 3 https://www.anapioâ€¦  1074 Victarion Greyâ€¦ Male   \"Ironborn\" \"In 268 AC or â€¦\n#&gt; 4 https://www.anapioâ€¦  1109 Will            Male   \"\"         \"\"             \n#&gt; 5 https://www.anapioâ€¦  1166 Areo Hotah      Male   \"Norvoshi\" \"In 257 AC or â€¦\n#&gt; 6 https://www.anapioâ€¦  1267 Chett           Male   \"\"         \"At Hag's Mire\"\n#&gt; # â„¹ 24 more rows\n#&gt; # â„¹ 12 more variables: died &lt;chr&gt;, alive &lt;lgl&gt;, titles &lt;list&gt;, â€¦\n\nAnd selecting a few columns to make it easier to read:\nç„¶åé€‰æ‹©å‡ åˆ—ä»¥ä¾¿äºé˜…è¯»ï¼š\n\ncharacters &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, name, gender, culture, born, died, alive)\ncharacters\n#&gt; # A tibble: 30 Ã— 7\n#&gt;      id name              gender culture    born              died           \n#&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          \n#&gt; 1  1022 Theon Greyjoy     Male   \"Ironborn\" \"In 278 AC or 27â€¦ \"\"             \n#&gt; 2  1052 Tyrion Lannister  Male   \"\"         \"In 273 AC, at Câ€¦ \"\"             \n#&gt; 3  1074 Victarion Greyjoy Male   \"Ironborn\" \"In 268 AC or beâ€¦ \"\"             \n#&gt; 4  1109 Will              Male   \"\"         \"\"                \"In 297 AC, atâ€¦\n#&gt; 5  1166 Areo Hotah        Male   \"Norvoshi\" \"In 257 AC or beâ€¦ \"\"             \n#&gt; 6  1267 Chett             Male   \"\"         \"At Hag's Mire\"   \"In 299 AC, atâ€¦\n#&gt; # â„¹ 24 more rows\n#&gt; # â„¹ 1 more variable: alive &lt;lgl&gt;\n\nThis dataset contains also many list-columns:\nè¿™ä¸ªæ•°æ®é›†ä¹ŸåŒ…å«è®¸å¤šåˆ—è¡¨åˆ—ï¼š\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list))\n#&gt; # A tibble: 30 Ã— 8\n#&gt;      id titles    aliases    allegiances books     povBooks tvSeries playedBy\n#&gt;   &lt;int&gt; &lt;list&gt;    &lt;list&gt;     &lt;list&gt;      &lt;list&gt;    &lt;list&gt;   &lt;list&gt;   &lt;list&gt;  \n#&gt; 1  1022 &lt;chr [2]&gt; &lt;chr [4]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 2  1052 &lt;chr [2]&gt; &lt;chr [11]&gt; &lt;chr [1]&gt;   &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 3  1074 &lt;chr [2]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 4  1109 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [1]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 5  1166 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 6  1267 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; # â„¹ 24 more rows\n\nLetâ€™s explore the titles column. Itâ€™s an unnamed list-column, so weâ€™ll unnest it into rows:\næˆ‘ä»¬æ¥æ¢ç©¶ä¸€ä¸‹ titles åˆ—ã€‚å®ƒæ˜¯ä¸€ä¸ªæœªå‘½åçš„åˆ—è¡¨åˆ—ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å…¶å±•å¼€ä¸ºå¤šè¡Œï¼š\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles)\n#&gt; # A tibble: 59 Ã— 2\n#&gt;      id titles                                              \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # â„¹ 53 more rows\n\nYou might expect to see this data in its own table because it would be easy to join to the characters data as needed. Letâ€™s do that, which requires little cleaning: removing the rows containing empty strings and renaming titles to title since each row now only contains a single title.\nä½ å¯èƒ½æœŸæœ›åœ¨ä¸€ä¸ªç‹¬ç«‹çš„è¡¨ä¸­çœ‹åˆ°è¿™äº›æ•°æ®ï¼Œå› ä¸ºè¿™æ ·å¾ˆå®¹æ˜“æ ¹æ®éœ€è¦å°†å…¶è¿æ¥åˆ°è§’è‰²æ•°æ®ä¸Šã€‚æˆ‘ä»¬æ¥åŠ¨æ‰‹å®ç°ï¼Œè¿™éœ€è¦åšä¸€äº›æ¸…ç†ï¼šç§»é™¤åŒ…å«ç©ºå­—ç¬¦ä¸²çš„è¡Œï¼Œå¹¶å°† titles é‡å‘½åä¸º titleï¼Œå› ä¸ºç°åœ¨æ¯è¡ŒåªåŒ…å«ä¸€ä¸ªå¤´è¡”ã€‚\n\ntitles &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles) |&gt; \n  filter(titles != \"\") |&gt; \n  rename(title = titles)\ntitles\n#&gt; # A tibble: 52 Ã— 2\n#&gt;      id title                                               \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # â„¹ 46 more rows\n\nYou could imagine creating a table like this for each of the list-columns, then using joins to combine them with the character data as you need it.\nä½ å¯ä»¥æƒ³è±¡ä¸ºæ¯ä¸ªåˆ—è¡¨åˆ—åˆ›å»ºè¿™æ ·ä¸€ä¸ªè¡¨ï¼Œç„¶ååœ¨éœ€è¦æ—¶ä½¿ç”¨è¿æ¥æ“ä½œå°†å®ƒä»¬ä¸è§’è‰²æ•°æ®åˆå¹¶ã€‚\n\n23.4.3 Deeply nested\nWeâ€™ll finish off these case studies with a list-column thatâ€™s very deeply nested and requires repeated rounds of unnest_wider() and unnest_longer() to unravel: gmaps_cities. This is a two column tibble containing five city names and the results of using Googleâ€™s geocoding API to determine their location:\næˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªæ·±åº¦åµŒå¥—çš„åˆ—è¡¨åˆ—æ¥ç»“æŸè¿™äº›æ¡ˆä¾‹ç ”ç©¶ï¼Œå®ƒéœ€è¦åå¤è°ƒç”¨ unnest_wider() å’Œ unnest_longer() æ¥è§£å¼€ï¼šgmaps_citiesã€‚è¿™æ˜¯ä¸€ä¸ªä¸¤åˆ—çš„ tibbleï¼ŒåŒ…å«äº”ä¸ªåŸå¸‚åç§°ä»¥åŠä½¿ç”¨è°·æ­Œçš„åœ°ç†ç¼–ç  API æ¥ç¡®å®šå…¶ä½ç½®çš„ç»“æœï¼š\n\ngmaps_cities\n#&gt; # A tibble: 5 Ã— 2\n#&gt;   city       json            \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [2]&gt;\n#&gt; 2 Washington &lt;named list [2]&gt;\n#&gt; 3 New York   &lt;named list [2]&gt;\n#&gt; 4 Chicago    &lt;named list [2]&gt;\n#&gt; 5 Arlington  &lt;named list [2]&gt;\n\njson is a list-column with internal names, so we start with an unnest_wider():json æ˜¯ä¸€ä¸ªå¸¦æœ‰å†…éƒ¨åç§°çš„åˆ—è¡¨åˆ—ï¼Œæ‰€ä»¥æˆ‘ä»¬ä» unnest_wider() å¼€å§‹ï¼š\n\ngmaps_cities |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 5 Ã— 3\n#&gt;   city       results    status\n#&gt;   &lt;chr&gt;      &lt;list&gt;     &lt;chr&gt; \n#&gt; 1 Houston    &lt;list [1]&gt; OK    \n#&gt; 2 Washington &lt;list [2]&gt; OK    \n#&gt; 3 New York   &lt;list [1]&gt; OK    \n#&gt; 4 Chicago    &lt;list [1]&gt; OK    \n#&gt; 5 Arlington  &lt;list [2]&gt; OK\n\nThis gives us the status and the results. Weâ€™ll drop the status column since theyâ€™re all OK; in a real analysis, youâ€™d also want to capture all the rows where status != \"OK\" and figure out what went wrong. results is an unnamed list, with either one or two elements (weâ€™ll see why shortly) so weâ€™ll unnest it into rows:\nè¿™æ ·æˆ‘ä»¬å¾—åˆ°äº† status å’Œ resultsã€‚æˆ‘ä»¬å°†ä¸¢å¼ƒ status åˆ—ï¼Œå› ä¸ºå®ƒä»¬çš„å€¼éƒ½æ˜¯ OKï¼›åœ¨å®é™…åˆ†æä¸­ï¼Œä½ è¿˜éœ€è¦æ•è·æ‰€æœ‰ status != \"OK\" çš„è¡Œï¼Œå¹¶æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ã€‚results æ˜¯ä¸€ä¸ªæœªå‘½åçš„åˆ—è¡¨ï¼ŒåŒ…å«ä¸€ä¸ªæˆ–ä¸¤ä¸ªå…ƒç´ ï¼ˆæˆ‘ä»¬å¾ˆå¿«ä¼šçœ‹åˆ°åŸå› ï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å…¶å±•å¼€ä¸ºå¤šè¡Œï¼š\n\ngmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results)\n#&gt; # A tibble: 7 Ã— 2\n#&gt;   city       results         \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [5]&gt;\n#&gt; 2 Washington &lt;named list [5]&gt;\n#&gt; 3 Washington &lt;named list [5]&gt;\n#&gt; 4 New York   &lt;named list [5]&gt;\n#&gt; 5 Chicago    &lt;named list [5]&gt;\n#&gt; 6 Arlington  &lt;named list [5]&gt;\n#&gt; # â„¹ 1 more row\n\nNow results is a named list, so weâ€™ll use unnest_wider():\nç°åœ¨ results æ˜¯ä¸€ä¸ªå‘½ååˆ—è¡¨ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨ unnest_wider()ï¼š\n\nlocations &lt;- gmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\nlocations\n#&gt; # A tibble: 7 Ã— 6\n#&gt;   city       address_components formatted_address   geometry        \n#&gt;   &lt;chr&gt;      &lt;list&gt;             &lt;chr&gt;               &lt;list&gt;          \n#&gt; 1 Houston    &lt;list [4]&gt;         Houston, TX, USA    &lt;named list [4]&gt;\n#&gt; 2 Washington &lt;list [2]&gt;         Washington, USA     &lt;named list [4]&gt;\n#&gt; 3 Washington &lt;list [4]&gt;         Washington, DC, USA &lt;named list [4]&gt;\n#&gt; 4 New York   &lt;list [3]&gt;         New York, NY, USA   &lt;named list [4]&gt;\n#&gt; 5 Chicago    &lt;list [4]&gt;         Chicago, IL, USA    &lt;named list [4]&gt;\n#&gt; 6 Arlington  &lt;list [4]&gt;         Arlington, TX, USA  &lt;named list [4]&gt;\n#&gt; # â„¹ 1 more row\n#&gt; # â„¹ 2 more variables: place_id &lt;chr&gt;, types &lt;list&gt;\n\nNow we can see why two cities got two results: Washington matched both Washington state and Washington, DC, and Arlington matched Arlington, Virginia and Arlington, Texas.\nç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸ºä»€ä¹ˆæœ‰ä¸¤ä¸ªåŸå¸‚å¾—åˆ°äº†ä¸¤ä¸ªç»“æœï¼šåç››é¡¿ (Washington) åŒ¹é…äº†åç››é¡¿å·å’Œåç››é¡¿ç‰¹åŒºï¼Œè€Œé˜¿çµé¡¿ (Arlington) åŒ¹é…äº†å¼—å‰å°¼äºšå·çš„é˜¿çµé¡¿å’Œå¾·å…‹è¨æ–¯å·çš„é˜¿çµé¡¿ã€‚\nThere are a few different places we could go from here. We might want to determine the exact location of the match, which is stored in the geometry list-column:\nä»è¿™é‡Œå¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰å‡ ä¸ªä¸åŒçš„æ–¹å‘ã€‚æˆ‘ä»¬å¯èƒ½æƒ³ç¡®å®šåŒ¹é…çš„ç²¾ç¡®ä½ç½®ï¼Œå®ƒå­˜å‚¨åœ¨ geometry åˆ—è¡¨åˆ—ä¸­ï¼š\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry)\n#&gt; # A tibble: 7 Ã— 6\n#&gt;   city       formatted_address   bounds           location     location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;       &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; # â„¹ 1 more row\n#&gt; # â„¹ 1 more variable: viewport &lt;list&gt;\n\nThat gives us new bounds (a rectangular region) and location (a point). We can unnest location to see the latitude (lat) and longitude (lng):\nè¿™æ ·å°±å¾—åˆ°äº†æ–°çš„ boundsï¼ˆä¸€ä¸ªçŸ©å½¢åŒºåŸŸï¼‰å’Œ locationï¼ˆä¸€ä¸ªç‚¹ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥å±•å¼€ location æ¥æŸ¥çœ‹çº¬åº¦ (lat) å’Œç»åº¦ (lng)ï¼š\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  unnest_wider(location)\n#&gt; # A tibble: 7 Ã— 7\n#&gt;   city       formatted_address   bounds             lat    lng location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt;  29.8  -95.4 APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt;  47.8 -121.  APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt;  38.9  -77.0 APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt;  40.7  -74.0 APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt;  41.9  -87.6 APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt;  32.7  -97.1 APPROXIMATE  \n#&gt; # â„¹ 1 more row\n#&gt; # â„¹ 1 more variable: viewport &lt;list&gt;\n\nExtracting the bounds requires a few more steps:\næå–è¾¹ç•Œéœ€è¦æ›´å¤šå‡ ä¸ªæ­¥éª¤ï¼š\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  # focus on the variables of interest\n  select(!location:viewport) |&gt;\n  unnest_wider(bounds)\n#&gt; # A tibble: 7 Ã— 4\n#&gt;   city       formatted_address   northeast        southwest       \n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;          \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; # â„¹ 1 more row\n\nWe then rename southwest and northeast (the corners of the rectangle) so we can use names_sep to create short but evocative names:\nç„¶åæˆ‘ä»¬é‡å‘½å southwest å’Œ northeastï¼ˆçŸ©å½¢çš„è§’ç‚¹ï¼‰ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ names_sep æ¥åˆ›å»ºç®€çŸ­ä½†å¯Œæœ‰è¡¨ç°åŠ›çš„åç§°ï¼š\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  select(!location:viewport) |&gt;\n  unnest_wider(bounds) |&gt; \n  rename(ne = northeast, sw = southwest) |&gt; \n  unnest_wider(c(ne, sw), names_sep = \"_\") \n#&gt; # A tibble: 7 Ã— 6\n#&gt;   city       formatted_address   ne_lat ne_lng sw_lat sw_lng\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Houston    Houston, TX, USA      30.1  -95.0   29.5  -95.8\n#&gt; 2 Washington Washington, USA       49.0 -117.    45.5 -125. \n#&gt; 3 Washington Washington, DC, USA   39.0  -76.9   38.8  -77.1\n#&gt; 4 New York   New York, NY, USA     40.9  -73.7   40.5  -74.3\n#&gt; 5 Chicago    Chicago, IL, USA      42.0  -87.5   41.6  -87.9\n#&gt; 6 Arlington  Arlington, TX, USA    32.8  -97.0   32.6  -97.2\n#&gt; # â„¹ 1 more row\n\nNote how we unnest two columns simultaneously by supplying a vector of variable names to unnest_wider().\næ³¨æ„æˆ‘ä»¬æ˜¯å¦‚ä½•é€šè¿‡å‘ unnest_wider() æä¾›ä¸€ä¸ªå˜é‡åå‘é‡æ¥åŒæ—¶å±•å¼€ä¸¤åˆ—çš„ã€‚\nOnce youâ€™ve discovered the path to get to the components youâ€™re interested in, you can extract them directly using another tidyr function, hoist():\nä¸€æ—¦ä½ æ‰¾åˆ°äº†è·å–æ„Ÿå…´è¶£ç»„ä»¶çš„è·¯å¾„ï¼Œä½ å°±å¯ä»¥ä½¿ç”¨ tidyr çš„å¦ä¸€ä¸ªå‡½æ•° hoist() ç›´æ¥æå–å®ƒä»¬ï¼š\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  hoist(\n    geometry,\n    ne_lat = c(\"bounds\", \"northeast\", \"lat\"),\n    sw_lat = c(\"bounds\", \"southwest\", \"lat\"),\n    ne_lng = c(\"bounds\", \"northeast\", \"lng\"),\n    sw_lng = c(\"bounds\", \"southwest\", \"lng\"),\n  )\n\nIf these case studies have whetted your appetite for more real-life rectangling, you can see a few more examples in vignette(\"rectangling\", package = \"tidyr\").\nå¦‚æœè¿™äº›æ¡ˆä¾‹ç ”ç©¶æ¿€å‘äº†ä½ å¯¹æ›´å¤šç°å®ä¸–ç•Œä¸­æ•°æ®è§„æ•´åŒ–çš„å…´è¶£ï¼Œä½ å¯ä»¥åœ¨ vignette(\"rectangling\", package = \"tidyr\") ä¸­çœ‹åˆ°æ›´å¤šç¤ºä¾‹ã€‚\n\n23.4.4 Exercises\n\nRoughly estimate when gh_repos was created. Why can you only roughly estimate the date?\nThe owner column of gh_repo contains a lot of duplicated information because each owner can have many repos. Can you construct an owners data frame that contains one row for each owner? (Hint: does distinct() work with list-cols?)\nFollow the steps used for titles to create similar tables for the aliases, allegiances, books, and TV series for the Game of Thrones characters.\n\nExplain the following code line-by-line. Why is it interesting? Why does it work for got_chars but might not work in general?\n\ntibble(json = got_chars) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list)) |&gt; \n  pivot_longer(\n    where(is.list), \n    names_to = \"name\", \n    values_to = \"value\"\n  ) |&gt;  \n  unnest_longer(value)\n\n\nIn gmaps_cities, what does address_components contain? Why does the length vary between rows? Unnest it appropriately to figure it out. (Hint: types always appears to contain two elements. Does unnest_wider() make it easier to work with than unnest_longer()?) .",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#json",
    "href": "rectangling.html#json",
    "title": "23Â  Hierarchical data",
    "section": "\n23.5 JSON",
    "text": "23.5 JSON\nAll of the case studies in the previous section were sourced from wild-caught JSON. JSON is short for javascript object notation and is the way that most web APIs return data. Itâ€™s important to understand it because while JSON and Râ€™s data types are pretty similar, there isnâ€™t a perfect 1-to-1 mapping, so itâ€™s good to understand a bit about JSON if things go wrong.\nä¸Šä¸€èŠ‚ä¸­çš„æ‰€æœ‰æ¡ˆä¾‹ç ”ç©¶éƒ½æºäºä»ç½‘ç»œä¸Šè·å–çš„ JSON æ•°æ®ã€‚JSON æ˜¯ javascript object notationï¼ˆJavaScript å¯¹è±¡è¡¨ç¤ºæ³•ï¼‰çš„ç¼©å†™ï¼Œæ˜¯å¤§å¤šæ•° Web API è¿”å›æ•°æ®çš„æ–¹å¼ã€‚ç†è§£å®ƒå¾ˆé‡è¦ï¼Œå› ä¸ºè™½ç„¶ JSON å’Œ R çš„æ•°æ®ç±»å‹éå¸¸ç›¸ä¼¼ï¼Œä½†å®ƒä»¬ä¹‹é—´å¹¶éå®Œç¾çš„ 1 å¯¹ 1 æ˜ å°„ï¼Œæ‰€ä»¥å¦‚æœå‡ºç°é—®é¢˜ï¼Œå¯¹ JSON æœ‰æ‰€äº†è§£ä¼šå¾ˆæœ‰å¸®åŠ©ã€‚\n\n23.5.1 Data types\nJSON is a simple format designed to be easily read and written by machines, not humans. It has six key data types. Four of them are scalars:\nJSON æ˜¯ä¸€ç§ç®€å•çš„æ ¼å¼ï¼Œè®¾è®¡ç”¨äºæœºå™¨çš„è½»æ¾è¯»å†™ï¼Œè€Œéäººç±»ã€‚å®ƒæœ‰å…­ç§å…³é”®çš„æ•°æ®ç±»å‹ã€‚å…¶ä¸­å››ç§æ˜¯æ ‡é‡ï¼š\n\nThe simplest type is a null (null) which plays the same role as NA in R. It represents the absence of data.\næœ€ç®€å•çš„ç±»å‹æ˜¯ç©ºå€¼ï¼ˆnullï¼‰ï¼Œå®ƒæ‰®æ¼”ç€ä¸ R ä¸­ NA ç›¸åŒçš„è§’è‰²ã€‚å®ƒè¡¨ç¤ºæ•°æ®çš„ç¼ºå¤±ã€‚\nA string is much like a string in R, but must always use double quotes. å­—ç¬¦ä¸² (string) å¾ˆåƒ R ä¸­çš„å­—ç¬¦ä¸²ï¼Œä½†å¿…é¡»å§‹ç»ˆä½¿ç”¨åŒå¼•å·ã€‚\nA number is similar to Râ€™s numbers: they can use integer (e.g., 123), decimal (e.g., 123.45), or scientific (e.g., 1.23e3) notation. JSON doesnâ€™t support Inf, -Inf, or NaN.æ•°å­— (number) ç±»ä¼¼äº R ä¸­çš„æ•°å­—ï¼šå®ƒä»¬å¯ä»¥ä½¿ç”¨æ•´æ•°ï¼ˆä¾‹å¦‚ï¼Œ123ï¼‰ã€å°æ•°ï¼ˆä¾‹å¦‚ï¼Œ123.45ï¼‰æˆ–ç§‘å­¦ï¼ˆä¾‹å¦‚ï¼Œ1.23e3ï¼‰è®°æ•°æ³•ã€‚JSON ä¸æ”¯æŒ Infã€-Inf æˆ– NaNã€‚\nA boolean is similar to Râ€™s TRUE and FALSE, but uses lowercase true and false.å¸ƒå°”å€¼ (boolean) ç±»ä¼¼äº R çš„ TRUE å’Œ FALSEï¼Œä½†ä½¿ç”¨å°å†™çš„ true å’Œ falseã€‚\n\nJSONâ€™s strings, numbers, and booleans are pretty similar to Râ€™s character, numeric, and logical vectors. The main difference is that JSONâ€™s scalars can only represent a single value. To represent multiple values you need to use one of the two remaining types: arrays and objects.\nJSON çš„å­—ç¬¦ä¸²ã€æ•°å­—å’Œå¸ƒå°”å€¼ä¸ R çš„å­—ç¬¦ã€æ•°å€¼å’Œé€»è¾‘å‘é‡éå¸¸ç›¸ä¼¼ã€‚ä¸»è¦åŒºåˆ«åœ¨äº JSON çš„æ ‡é‡åªèƒ½è¡¨ç¤ºå•ä¸ªå€¼ã€‚è¦è¡¨ç¤ºå¤šä¸ªå€¼ï¼Œä½ éœ€è¦ä½¿ç”¨å‰©ä¸‹çš„ä¸¤ç§ç±»å‹ä¹‹ä¸€ï¼šæ•°ç»„å’Œå¯¹è±¡ã€‚\nBoth arrays and objects are similar to lists in R; the difference is whether or not theyâ€™re named. An array is like an unnamed list, and is written with []. For example [1, 2, 3] is an array containing 3 numbers, and [null, 1, \"string\", false] is an array that contains a null, a number, a string, and a boolean. An object is like a named list, and is written with {}. The names (keys in JSON terminology) are strings, so must be surrounded by quotes. For example, {\"x\": 1, \"y\": 2} is an object that maps x to 1 and y to 2.\næ•°ç»„å’Œå¯¹è±¡éƒ½ç±»ä¼¼äº R ä¸­çš„åˆ—è¡¨ï¼›åŒºåˆ«åœ¨äºå®ƒä»¬æ˜¯å¦æœ‰åç§°ã€‚ æ•°ç»„ (array) å°±åƒä¸€ä¸ªæœªå‘½åçš„åˆ—è¡¨ï¼Œç”¨ [] ä¹¦å†™ã€‚ä¾‹å¦‚ [1, 2, 3] æ˜¯ä¸€ä¸ªåŒ…å« 3 ä¸ªæ•°å­—çš„æ•°ç»„ï¼Œè€Œ [null, 1, \"string\", false] æ˜¯ä¸€ä¸ªåŒ…å«ç©ºå€¼ã€æ•°å­—ã€å­—ç¬¦ä¸²å’Œå¸ƒå°”å€¼çš„æ•°ç»„ã€‚ å¯¹è±¡ (object) å°±åƒä¸€ä¸ªå‘½ååˆ—è¡¨ï¼Œç”¨ {} ä¹¦å†™ã€‚åç§°ï¼ˆåœ¨ JSON æœ¯è¯­ä¸­ç§°ä¸ºé”® (keys)ï¼‰æ˜¯å­—ç¬¦ä¸²ï¼Œå› æ­¤å¿…é¡»ç”¨å¼•å·æ‹¬èµ·æ¥ã€‚ä¾‹å¦‚ï¼Œ{\"x\": 1, \"y\": 2} æ˜¯ä¸€ä¸ªå°† x æ˜ å°„åˆ° 1ï¼Œy æ˜ å°„åˆ° 2 çš„å¯¹è±¡ã€‚\nNote that JSON doesnâ€™t have any native way to represent dates or date-times, so theyâ€™re often stored as strings, and youâ€™ll need to use readr::parse_date() or readr::parse_datetime() to turn them into the correct data structure. Similarly, JSONâ€™s rules for representing floating point numbers in JSON are a little imprecise, so youâ€™ll also sometimes find numbers stored in strings. Apply readr::parse_double() as needed to get the correct variable type.\nè¯·æ³¨æ„ï¼ŒJSON æ²¡æœ‰ä»»ä½•åŸç”Ÿæ–¹å¼æ¥è¡¨ç¤ºæ—¥æœŸæˆ–æ—¥æœŸæ—¶é—´ï¼Œå› æ­¤å®ƒä»¬é€šå¸¸ä»¥å­—ç¬¦ä¸²å½¢å¼å­˜å‚¨ï¼Œä½ éœ€è¦ä½¿ç”¨ readr::parse_date() æˆ– readr::parse_datetime() å°†å®ƒä»¬è½¬æ¢ä¸ºæ­£ç¡®çš„æ•°æ®ç»“æ„ã€‚åŒæ ·ï¼ŒJSON è¡¨ç¤ºæµ®ç‚¹æ•°çš„è§„åˆ™æœ‰äº›ä¸ç²¾ç¡®ï¼Œæ‰€ä»¥ä½ æœ‰æ—¶ä¹Ÿä¼šå‘ç°æ•°å­—ä»¥å­—ç¬¦ä¸²å½¢å¼å­˜å‚¨ã€‚éœ€è¦æ—¶ï¼Œåº”ç”¨ readr::parse_double() ä»¥è·å–æ­£ç¡®çš„å˜é‡ç±»å‹ã€‚\n\n23.5.2 jsonlite\nTo convert JSON into R data structures, we recommend the jsonlite package, by Jeroen Ooms. Weâ€™ll use only two jsonlite functions: read_json() and parse_json(). In real life, youâ€™ll use read_json() to read a JSON file from disk. For example, the repurrsive package also provides the source for gh_user as a JSON file and you can read it with read_json():\nè¦å°† JSON è½¬æ¢ä¸º R æ•°æ®ç»“æ„ï¼Œæˆ‘ä»¬æ¨è Jeroen Ooms å¼€å‘çš„ jsonlite åŒ…ã€‚æˆ‘ä»¬å°†åªä½¿ç”¨ä¸¤ä¸ª jsonlite å‡½æ•°ï¼šread_json() å’Œ parse_json()ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä½ ä¼šä½¿ç”¨ read_json() ä»ç£ç›˜è¯»å– JSON æ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œrepurrsive åŒ…ä¹Ÿä»¥ JSON æ–‡ä»¶çš„å½¢å¼æä¾›äº† gh_user çš„æºæ•°æ®ï¼Œä½ å¯ä»¥ç”¨ read_json() è¯»å–å®ƒï¼š\n\n# A path to a json file inside the package:\ngh_users_json()\n#&gt; [1] \"C:/Users/14913/AppData/Local/R/win-library/4.5/repurrrsive/extdata/gh_users.json\"\n\n# Read it with read_json()\ngh_users2 &lt;- read_json(gh_users_json())\n\n# Check it's the same as the data we were using previously\nidentical(gh_users, gh_users2)\n#&gt; [1] TRUE\n\nIn this book, weâ€™ll also use parse_json(), since it takes a string containing JSON, which makes it good for generating simple examples. To get started, here are three simple JSON datasets, starting with a number, then putting a few numbers in an array, then putting that array in an object:\nåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿä¼šä½¿ç”¨ parse_json()ï¼Œå› ä¸ºå®ƒæ¥å—åŒ…å« JSON çš„å­—ç¬¦ä¸²ï¼Œè¿™ä½¿å¾—å®ƒå¾ˆé€‚åˆç”Ÿæˆç®€å•çš„ç¤ºä¾‹ã€‚ä½œä¸ºå¼€å§‹ï¼Œè¿™é‡Œæœ‰ä¸‰ä¸ªç®€å•çš„ JSON æ•°æ®é›†ï¼Œä»ä¸€ä¸ªæ•°å­—å¼€å§‹ï¼Œç„¶åå°†å‡ ä¸ªæ•°å­—æ”¾å…¥ä¸€ä¸ªæ•°ç»„ï¼Œå†å°†è¯¥æ•°ç»„æ”¾å…¥ä¸€ä¸ªå¯¹è±¡ä¸­ï¼š\n\nstr(parse_json('1'))\n#&gt;  int 1\nstr(parse_json('[1, 2, 3]'))\n#&gt; List of 3\n#&gt;  $ : int 1\n#&gt;  $ : int 2\n#&gt;  $ : int 3\nstr(parse_json('{\"x\": [1, 2, 3]}'))\n#&gt; List of 1\n#&gt;  $ x:List of 3\n#&gt;   ..$ : int 1\n#&gt;   ..$ : int 2\n#&gt;   ..$ : int 3\n\njsonlite has another important function called fromJSON(). We donâ€™t use it here because it performs automatic simplification (simplifyVector = TRUE). This often works well, particularly in simple cases, but we think youâ€™re better off doing the rectangling yourself so you know exactly whatâ€™s happening and can more easily handle the most complicated nested structures.\njsonlite è¿˜æœ‰å¦ä¸€ä¸ªé‡è¦çš„å‡½æ•°å«åš fromJSON()ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œä¸ä½¿ç”¨å®ƒï¼Œå› ä¸ºå®ƒä¼šæ‰§è¡Œè‡ªåŠ¨ç®€åŒ– (simplifyVector = TRUE)ã€‚è¿™åœ¨ç®€å•æƒ…å†µä¸‹é€šå¸¸æ•ˆæœå¾ˆå¥½ï¼Œä½†æˆ‘ä»¬è®¤ä¸ºæœ€å¥½è¿˜æ˜¯è‡ªå·±è¿›è¡Œæ•°æ®è§„æ•´åŒ–ï¼Œè¿™æ ·ä½ æ‰èƒ½ç¡®åˆ‡åœ°çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆï¼Œå¹¶èƒ½æ›´å®¹æ˜“åœ°å¤„ç†æœ€å¤æ‚çš„åµŒå¥—ç»“æ„ã€‚\n\n23.5.3 Starting the rectangling process\nIn most cases, JSON files contain a single top-level array, because theyâ€™re designed to provide data about multiple â€œthingsâ€, e.g., multiple pages, or multiple records, or multiple results. In this case, youâ€™ll start your rectangling with tibble(json) so that each element becomes a row:\nåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒJSON æ–‡ä»¶åŒ…å«ä¸€ä¸ªé¡¶å±‚æ•°ç»„ï¼Œå› ä¸ºå®ƒä»¬æ—¨åœ¨æä¾›å…³äºå¤šä¸ªâ€œäº‹ç‰©â€çš„æ•°æ®ï¼Œä¾‹å¦‚å¤šä¸ªé¡µé¢ã€å¤šä¸ªè®°å½•æˆ–å¤šä¸ªç»“æœã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å°†é€šè¿‡ tibble(json) å¼€å§‹ä½ çš„æ•°æ®è§„æ•´åŒ–è¿‡ç¨‹ï¼Œä½¿æ¯ä¸ªå…ƒç´ éƒ½æˆä¸ºä¸€è¡Œï¼š\n\njson &lt;- '[\n  {\"name\": \"John\", \"age\": 34},\n  {\"name\": \"Susan\", \"age\": 27}\n]'\ndf &lt;- tibble(json = parse_json(json))\ndf\n#&gt; # A tibble: 2 Ã— 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n#&gt; 2 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 2 Ã— 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\nIn rarer cases, the JSON file consists of a single top-level JSON object, representing one â€œthingâ€. In this case, youâ€™ll need to kick off the rectangling process by wrapping it in a list, before you put it in a tibble.\nåœ¨è¾ƒå°‘è§çš„æƒ…å†µä¸‹ï¼ŒJSON æ–‡ä»¶ç”±ä¸€ä¸ªé¡¶å±‚ JSON å¯¹è±¡ç»„æˆï¼Œä»£è¡¨ä¸€ä¸ªâ€œäº‹ç‰©â€ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨å°†å…¶æ”¾å…¥ tibble ä¹‹å‰ï¼Œä½ éœ€è¦é€šè¿‡å°†å…¶åŒ…è£…åœ¨åˆ—è¡¨ä¸­æ¥å¯åŠ¨æ•°æ®è§„æ•´åŒ–è¿‡ç¨‹ã€‚\n\njson &lt;- '{\n  \"status\": \"OK\", \n  \"results\": [\n    {\"name\": \"John\", \"age\": 34},\n    {\"name\": \"Susan\", \"age\": 27}\n ]\n}\n'\ndf &lt;- tibble(json = list(parse_json(json)))\ndf\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 Ã— 3\n#&gt;   status name    age\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 OK     John     34\n#&gt; 2 OK     Susan    27\n\nAlternatively, you can reach inside the parsed JSON and start with the bit that you actually care about:\næˆ–è€…ï¼Œä½ å¯ä»¥æ·±å…¥è§£æåçš„ JSON å†…éƒ¨ï¼Œä»ä½ çœŸæ­£å…³å¿ƒçš„éƒ¨åˆ†å¼€å§‹ï¼š\n\ndf &lt;- tibble(results = parse_json(json)$results)\ndf |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 Ã— 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\n\n23.5.4 Exercises\n\n\nRectangle the df_col and df_row below. They represent the two ways of encoding a data frame in JSON.\n\njson_col &lt;- parse_json('\n  {\n    \"x\": [\"a\", \"x\", \"z\"],\n    \"y\": [10, null, 3]\n  }\n')\njson_row &lt;- parse_json('\n  [\n    {\"x\": \"a\", \"y\": 10},\n    {\"x\": \"x\", \"y\": null},\n    {\"x\": \"z\", \"y\": 3}\n  ]\n')\n\ndf_col &lt;- tibble(json = list(json_col)) \ndf_row &lt;- tibble(json = json_row)",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#summary",
    "href": "rectangling.html#summary",
    "title": "23Â  Hierarchical data",
    "section": "\n23.6 Summary",
    "text": "23.6 Summary\nIn this chapter, you learned what lists are, how you can generate them from JSON files, and how to turn them into rectangular data frames. Surprisingly we only need two new functions: unnest_longer() to put list elements into rows and unnest_wider() to put list elements into columns. It doesnâ€™t matter how deeply nested the list-column is; all you need to do is repeatedly call these two functions.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†ä»€ä¹ˆæ˜¯åˆ—è¡¨ï¼Œå¦‚ä½•ä» JSON æ–‡ä»¶ç”Ÿæˆå®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•å°†å®ƒä»¬è½¬æ¢ä¸ºè§„æ•´çš„æ•°æ®æ¡†ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸¤ä¸ªæ–°å‡½æ•°ï¼šunnest_longer() ç”¨äºå°†åˆ—è¡¨å…ƒç´ æ”¾å…¥è¡Œï¼Œunnest_wider() ç”¨äºå°†åˆ—è¡¨å…ƒç´ æ”¾å…¥åˆ—ã€‚åˆ—è¡¨åˆ—çš„åµŒå¥—æ·±åº¦æ— å…³ç´§è¦ï¼›ä½ æ‰€éœ€è¦åšçš„å°±æ˜¯é‡å¤è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°ã€‚\nJSON is the most common data format returned by web APIs. What happens if the website doesnâ€™t have an API, but you can see data you want on the website? Thatâ€™s the topic of the next chapter: web scraping, extracting data from HTML webpages.\nJSON æ˜¯ Web API è¿”å›çš„æœ€å¸¸è§çš„æ•°æ®æ ¼å¼ã€‚å¦‚æœç½‘ç«™æ²¡æœ‰ APIï¼Œä½†ä½ å¯ä»¥åœ¨ç½‘ç«™ä¸Šçœ‹åˆ°ä½ æƒ³è¦çš„æ•°æ®ï¼Œé‚£è¯¥æ€ä¹ˆåŠï¼Ÿè¿™å°±æ˜¯ä¸‹ä¸€ç« çš„ä¸»é¢˜ï¼šç½‘é¡µæŠ“å–ï¼Œå³ä» HTML ç½‘é¡µä¸­æå–æ•°æ®ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#footnotes",
    "href": "rectangling.html#footnotes",
    "title": "23Â  Hierarchical data",
    "section": "",
    "text": "This is an RStudio feature.â†©ï¸",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>23</span>Â  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "webscraping.html",
    "href": "webscraping.html",
    "title": "24Â  Web scraping",
    "section": "",
    "text": "24.1 Introduction\nThis chapter introduces you to the basics of web scraping with rvest. Web scraping is a very useful tool for extracting data from web pages. Some websites will offer an API, a set of structured HTTP requests that return data as JSON, which you handle using the techniques from Chapter 23. Where possible, you should use the API1, because typically it will give you more reliable data. Unfortunately, however, programming with web APIs is out of scope for this book. Instead, we are teaching scraping, a technique that works whether or not a site provides an API.\næœ¬ç« å°†å‘æ‚¨ä»‹ç»ä½¿ç”¨ rvest è¿›è¡Œç½‘é¡µæŠ“å–çš„åŸºç¡€çŸ¥è¯†ã€‚ç½‘é¡µæŠ“å–ï¼ˆWeb scrapingï¼‰æ˜¯ä»ç½‘é¡µä¸­æå–æ•°æ®çš„éå¸¸æœ‰ç”¨çš„å·¥å…·ã€‚æœ‰äº›ç½‘ç«™ä¼šæä¾› APIï¼Œè¿™æ˜¯ä¸€ç»„ç»“æ„åŒ–çš„ HTTP è¯·æ±‚ï¼Œä»¥ JSON æ ¼å¼è¿”å›æ•°æ®ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ Chapter 23 ä¸­çš„æŠ€æœ¯æ¥å¤„ç†è¿™äº›æ•°æ®ã€‚åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨ API 1ï¼Œå› ä¸ºå®ƒé€šå¸¸ä¼šä¸ºæ‚¨æä¾›æ›´å¯é çš„æ•°æ®ã€‚ç„¶è€Œï¼Œä¸å¹¸çš„æ˜¯ï¼Œä½¿ç”¨ Web API è¿›è¡Œç¼–ç¨‹è¶…å‡ºäº†æœ¬ä¹¦çš„èŒƒå›´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ•™æˆçš„æ˜¯æŠ“å–æŠ€æœ¯ï¼Œæ— è®ºç½‘ç«™æ˜¯å¦æä¾› APIï¼Œè¿™ç§æŠ€æœ¯éƒ½é€‚ç”¨ã€‚\nIn this chapter, weâ€™ll first discuss the ethics and legalities of scraping before we dive into the basics of HTML. Youâ€™ll then learn the basics of CSS selectors to locate specific elements on the page, and how to use rvest functions to get data from text and attributes out of HTML and into R. Weâ€™ll then discuss some techniques to figure out what CSS selector you need for the page youâ€™re scraping, before finishing up with a couple of case studies, and a brief discussion of dynamic websites.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨æ·±å…¥æ¢è®¨ HTML åŸºç¡€çŸ¥è¯†ä¹‹å‰ï¼Œé¦–å…ˆè®¨è®ºæŠ“å–çš„é“å¾·å’Œæ³•å¾‹é—®é¢˜ã€‚ç„¶åï¼Œæ‚¨å°†å­¦ä¹  CSS é€‰æ‹©å™¨çš„åŸºç¡€çŸ¥è¯†ï¼Œä»¥åœ¨é¡µé¢ä¸Šå®šä½ç‰¹å®šå…ƒç´ ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ rvest å‡½æ•°ä» HTML çš„æ–‡æœ¬å’Œå±æ€§ä¸­æå–æ•°æ®å¹¶å¯¼å…¥ Rã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸€äº›æŠ€å·§ï¼Œä»¥ç¡®å®šæ‚¨éœ€è¦ä¸ºæ­£åœ¨æŠ“å–çš„é¡µé¢ä½¿ç”¨å“ªç§ CSS é€‰æ‹©å™¨ï¼Œæœ€åé€šè¿‡å‡ ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œå¹¶ç®€è¦è®¨è®ºåŠ¨æ€ç½‘ç«™ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#introduction",
    "href": "webscraping.html#introduction",
    "title": "24Â  Web scraping",
    "section": "",
    "text": "24.1.1 Prerequisites\nIn this chapter, weâ€™ll focus on tools provided by rvest. rvest is a member of the tidyverse, but is not a core member so youâ€™ll need to load it explicitly. Weâ€™ll also load the full tidyverse since weâ€™ll find it generally useful working with the data weâ€™ve scraped.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç» rvest æä¾›çš„å·¥å…·ã€‚rvest æ˜¯ tidyverse çš„æˆå‘˜ï¼Œä½†ä¸æ˜¯æ ¸å¿ƒæˆå‘˜ï¼Œå› æ­¤æ‚¨éœ€è¦æ˜¾å¼åŠ è½½å®ƒã€‚æˆ‘ä»¬è¿˜å°†åŠ è½½å®Œæ•´çš„ tidyverseï¼Œå› ä¸ºåœ¨å¤„ç†æˆ‘ä»¬æŠ“å–çš„æ•°æ®æ—¶ï¼Œå®ƒé€šå¸¸ä¼šå¾ˆæœ‰ç”¨ã€‚\n\nlibrary(tidyverse)\nlibrary(rvest)",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#scraping-ethics-and-legalities",
    "href": "webscraping.html#scraping-ethics-and-legalities",
    "title": "24Â  Web scraping",
    "section": "\n24.2 Scraping ethics and legalities",
    "text": "24.2 Scraping ethics and legalities\nBefore we get started discussing the code youâ€™ll need to perform web scraping, we need to talk about whether itâ€™s legal and ethical for you to do so. Overall, the situation is complicated with regards to both of these.\nåœ¨æˆ‘ä»¬å¼€å§‹è®¨è®ºæ‰§è¡Œç½‘é¡µæŠ“å–æ‰€éœ€çš„ä»£ç ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è°ˆè°ˆè¿™æ ·åšæ˜¯å¦åˆæ³•å’Œé“å¾·ã€‚æ€»çš„æ¥è¯´ï¼Œåœ¨è¿™ä¸¤ä¸ªæ–¹é¢ï¼Œæƒ…å†µéƒ½å¾ˆå¤æ‚ã€‚\nLegalities depend a lot on where you live. However, as a general principle, if the data is public, non-personal, and factual, youâ€™re likely to be ok2. These three factors are important because theyâ€™re connected to the siteâ€™s terms and conditions, personally identifiable information, and copyright, as weâ€™ll discuss below.\nåˆæ³•æ€§åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ‚¨å±…ä½çš„åœ°æ–¹ã€‚ç„¶è€Œï¼Œä½œä¸ºä¸€èˆ¬åŸåˆ™ï¼Œå¦‚æœæ•°æ®æ˜¯å…¬å¼€çš„ã€éä¸ªäººçš„å’Œäº‹å®æ€§çš„ï¼Œæ‚¨å¾ˆå¯èƒ½æ˜¯å¯ä»¥çš„2ã€‚è¿™ä¸‰ä¸ªå› ç´ å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒä»¬ä¸ç½‘ç«™çš„æœåŠ¡æ¡æ¬¾ã€ä¸ªäººèº«ä»½ä¿¡æ¯å’Œç‰ˆæƒæœ‰å…³ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹é¢è®¨è®ºã€‚\nIf the data isnâ€™t public, non-personal, or factual or youâ€™re scraping the data specifically to make money with it, youâ€™ll need to talk to a lawyer. In any case, you should be respectful of the resources of the server hosting the pages you are scraping. Most importantly, this means that if youâ€™re scraping many pages, you should make sure to wait a little between each request. One easy way to do so is to use the polite package by Dmytro Perepolkin. It will automatically pause between requests and cache the results so you never ask for the same page twice.\nå¦‚æœæ•°æ®ä¸æ˜¯å…¬å¼€çš„ã€éä¸ªäººçš„æˆ–äº‹å®æ€§çš„ï¼Œæˆ–è€…æ‚¨æŠ“å–æ•°æ®æ˜¯ä¸“é—¨ä¸ºäº†èµšé’±ï¼Œé‚£ä¹ˆæ‚¨éœ€è¦å’¨è¯¢å¾‹å¸ˆã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæ‚¨éƒ½åº”è¯¥å°Šé‡æ‰˜ç®¡æ‚¨æ­£åœ¨æŠ“å–çš„é¡µé¢çš„æœåŠ¡å™¨èµ„æºã€‚æœ€é‡è¦çš„æ˜¯ï¼Œè¿™æ„å‘³ç€å¦‚æœæ‚¨è¦æŠ“å–è®¸å¤šé¡µé¢ï¼Œæ‚¨åº”è¯¥ç¡®ä¿åœ¨æ¯ä¸ªè¯·æ±‚ä¹‹é—´ç¨ä½œç­‰å¾…ã€‚ä¸€ä¸ªç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ Dmytro Perepolkin çš„ polite åŒ…ã€‚å®ƒä¼šè‡ªåŠ¨åœ¨è¯·æ±‚ä¹‹é—´æš‚åœï¼Œå¹¶ç¼“å­˜ç»“æœï¼Œè¿™æ ·æ‚¨å°±æ°¸è¿œä¸ä¼šä¸¤æ¬¡è¯·æ±‚åŒä¸€ä¸ªé¡µé¢ã€‚\n\n24.2.1 Terms of service\nIf you look closely, youâ€™ll find many websites include a â€œterms and conditionsâ€ or â€œterms of serviceâ€ link somewhere on the page, and if you read that page closely youâ€™ll often discover that the site specifically prohibits web scraping. These pages tend to be a legal land grab where companies make very broad claims. Itâ€™s polite to respect these terms of service where possible, but take any claims with a grain of salt.\nå¦‚æœæ‚¨ä»”ç»†æŸ¥çœ‹ï¼Œæ‚¨ä¼šå‘ç°è®¸å¤šç½‘ç«™åœ¨é¡µé¢çš„æŸä¸ªåœ°æ–¹åŒ…å«â€œæ¡æ¬¾å’Œæ¡ä»¶â€æˆ–â€œæœåŠ¡æ¡æ¬¾â€çš„é“¾æ¥ï¼Œå¦‚æœæ‚¨ä»”ç»†é˜…è¯»è¯¥é¡µé¢ï¼Œæ‚¨é€šå¸¸ä¼šå‘ç°è¯¥ç½‘ç«™æ˜ç¡®ç¦æ­¢ç½‘é¡µæŠ“å–ã€‚è¿™äº›é¡µé¢å¾€å¾€æ˜¯å…¬å¸æå‡ºéå¸¸å®½æ³›ä¸»å¼ çš„æ³•å¾‹åœˆåœ°ã€‚åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ï¼Œå°Šé‡è¿™äº›æœåŠ¡æ¡æ¬¾æ˜¯ç¤¼è²Œçš„ï¼Œä½†å¯¹ä»»ä½•ä¸»å¼ éƒ½è¦æŒä¿ç•™æ€åº¦ã€‚\nUS courts have generally found that simply putting the terms of service in the footer of the website isnâ€™t sufficient for you to be bound by them, e.g., HiQ Labs v. LinkedIn. Generally, to be bound to the terms of service, you must have taken some explicit action like creating an account or checking a box. This is why whether or not the data is public is important; if you donâ€™t need an account to access them, it is unlikely that you are bound to the terms of service. Note, however, the situation is rather different in Europe where courts have found that terms of service are enforceable even if you donâ€™t explicitly agree to them.\nç¾å›½æ³•é™¢é€šå¸¸è®¤ä¸ºï¼Œä»…ä»…å°†æœåŠ¡æ¡æ¬¾æ”¾åœ¨ç½‘ç«™é¡µè„šå¹¶ä¸è¶³ä»¥ä½¿æ‚¨å—å…¶çº¦æŸï¼Œä¾‹å¦‚ HiQ Labs v. LinkedInã€‚é€šå¸¸ï¼Œè¦å—æœåŠ¡æ¡æ¬¾çš„çº¦æŸï¼Œæ‚¨å¿…é¡»é‡‡å–ä¸€äº›æ˜ç¡®çš„è¡ŒåŠ¨ï¼Œå¦‚åˆ›å»ºå¸æˆ·æˆ–å‹¾é€‰å¤é€‰æ¡†ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ•°æ®æ˜¯å¦å…¬å¼€å¾ˆé‡è¦çš„åŸå› ï¼›å¦‚æœæ‚¨ä¸éœ€è¦å¸æˆ·å³å¯è®¿é—®å®ƒä»¬ï¼Œé‚£ä¹ˆæ‚¨å°±ä¸å¤ªå¯èƒ½å—æœåŠ¡æ¡æ¬¾çš„çº¦æŸã€‚ä½†è¯·æ³¨æ„ï¼Œåœ¨æ¬§æ´²æƒ…å†µæœ‰æ‰€ä¸åŒï¼Œæ³•é™¢è®¤ä¸ºå³ä½¿æ‚¨æ²¡æœ‰æ˜ç¡®åŒæ„ï¼ŒæœåŠ¡æ¡æ¬¾ä¹Ÿæ˜¯å¯å¼ºåˆ¶æ‰§è¡Œçš„ã€‚\n\n24.2.2 Personally identifiable information\nEven if the data is public, you should be extremely careful about scraping personally identifiable information like names, email addresses, phone numbers, dates of birth, etc. Europe has particularly strict laws about the collection or storage of such data (GDPR), and regardless of where you live youâ€™re likely to be entering an ethical quagmire. For example, in 2016, a group of researchers scraped public profile information (e.g., usernames, age, gender, location, etc.) about 70,000 people on the dating site OkCupid and they publicly released these data without any attempts for anonymization. While the researchers felt that there was nothing wrong with this since the data were already public, this work was widely condemned due to ethics concerns around identifiability of users whose information was released in the dataset. If your work involves scraping personally identifiable information, we strongly recommend reading about the OkCupid study3 as well as similar studies with questionable research ethics involving the acquisition and release of personally identifiable information.\nå³ä½¿æ•°æ®æ˜¯å…¬å¼€çš„ï¼Œæ‚¨åœ¨æŠ“å–å§“åã€ç”µå­é‚®ä»¶åœ°å€ã€ç”µè¯å·ç ã€å‡ºç”Ÿæ—¥æœŸç­‰ä¸ªäººèº«ä»½ä¿¡æ¯æ—¶ä¹Ÿåº”æå…¶è°¨æ…ã€‚æ¬§æ´²å¯¹è¿™ç±»æ•°æ®çš„æ”¶é›†æˆ–å­˜å‚¨æœ‰ç‰¹åˆ«ä¸¥æ ¼çš„æ³•å¾‹ï¼ˆGDPRï¼‰ï¼Œæ— è®ºæ‚¨ä½åœ¨å“ªé‡Œï¼Œæ‚¨éƒ½å¯èƒ½é™·å…¥é“å¾·å›°å¢ƒã€‚ä¾‹å¦‚ï¼Œ2016å¹´ï¼Œä¸€ç¾¤ç ”ç©¶äººå‘˜ä»äº¤å‹ç½‘ç«™ OkCupid ä¸ŠæŠ“å–äº†çº¦ 70,000 äººçš„å…¬å¼€ä¸ªäººèµ„æ–™ä¿¡æ¯ï¼ˆå¦‚ç”¨æˆ·åã€å¹´é¾„ã€æ€§åˆ«ã€åœ°ç‚¹ç­‰ï¼‰ï¼Œå¹¶åœ¨æœªè¿›è¡Œä»»ä½•åŒ¿ååŒ–å¤„ç†çš„æƒ…å†µä¸‹å…¬å¼€å‘å¸ƒäº†è¿™äº›æ•°æ®ã€‚å°½ç®¡ç ”ç©¶äººå‘˜è®¤ä¸ºè¿™æ ·åšæ²¡æœ‰é”™ï¼Œå› ä¸ºæ•°æ®å·²ç»æ˜¯å…¬å¼€çš„ï¼Œä½†è¿™é¡¹å·¥ä½œå› æ¶‰åŠæ•°æ®é›†ä¸­ç”¨æˆ·ä¿¡æ¯çš„å¯è¯†åˆ«æ€§è€Œå—åˆ°å¹¿æ³›è°´è´£ã€‚å¦‚æœæ‚¨çš„å·¥ä½œæ¶‰åŠæŠ“å–ä¸ªäººèº«ä»½ä¿¡æ¯ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨é˜…è¯»å…³äº OkCupid ç ”ç©¶çš„èµ„æ–™3ï¼Œä»¥åŠæ¶‰åŠè·å–å’Œå‘å¸ƒä¸ªäººèº«ä»½ä¿¡æ¯å­˜åœ¨å¯ç–‘ç ”ç©¶ä¼¦ç†çš„ç±»ä¼¼ç ”ç©¶ã€‚\n\n24.2.3 Copyright\nFinally, you also need to worry about copyright law. Copyright law is complicated, but itâ€™s worth taking a look at the US law which describes exactly whatâ€™s protected: â€œ[â€¦] original works of authorship fixed in any tangible medium of expression, [â€¦]â€. It then goes on to describe specific categories that it applies like literary works, musical works, motion pictures and more. Notably absent from copyright protection are data. This means that as long as you limit your scraping to facts, copyright protection does not apply. (But note that Europe has a separate â€œsui generisâ€ right that protects databases.)\næœ€åï¼Œæ‚¨è¿˜éœ€è¦æ‹…å¿ƒç‰ˆæƒæ³•ã€‚ç‰ˆæƒæ³•å¾ˆå¤æ‚ï¼Œä½†å€¼å¾—ä¸€çœ‹çš„æ˜¯ç¾å›½æ³•å¾‹ï¼Œå®ƒç¡®åˆ‡åœ°æè¿°äº†å—ä¿æŠ¤çš„å†…å®¹ï¼šâ€œ[â€¦] å›ºå®šåœ¨ä»»ä½•æœ‰å½¢è¡¨è¾¾åª’ä»‹ä¸Šçš„åŸåˆ›ä½œè€…ä½œå“ [â€¦]â€ã€‚ç„¶åå®ƒç»§ç»­æè¿°äº†å…¶é€‚ç”¨çš„å…·ä½“ç±»åˆ«ï¼Œå¦‚æ–‡å­¦ä½œå“ã€éŸ³ä¹ä½œå“ã€ç”µå½±ç­‰ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ•°æ®ä¸åœ¨ç‰ˆæƒä¿æŠ¤ä¹‹åˆ—ã€‚è¿™æ„å‘³ç€ï¼Œåªè¦æ‚¨å°†æŠ“å–èŒƒå›´é™åˆ¶åœ¨äº‹å®ä¸Šï¼Œç‰ˆæƒä¿æŠ¤å°±ä¸é€‚ç”¨ã€‚ï¼ˆä½†è¯·æ³¨æ„ï¼Œæ¬§æ´²æœ‰ä¸€é¡¹å•ç‹¬çš„â€œæ•°æ®åº“æƒâ€ï¼ˆsui generisï¼‰æ¥ä¿æŠ¤æ•°æ®åº“ã€‚ï¼‰\nAs a brief example, in the US, lists of ingredients and instructions are not copyrightable, so copyright can not be used to protect a recipe. But if that list of recipes is accompanied by substantial novel literary content, that is copyrightable. This is why when youâ€™re looking for a recipe on the internet thereâ€™s always so much content beforehand.\nä¸¾ä¸ªç®€çŸ­çš„ä¾‹å­ï¼Œåœ¨ç¾å›½ï¼Œé…æ–™æ¸…å•å’Œè¯´æ˜æ˜¯ä¸å—ç‰ˆæƒä¿æŠ¤çš„ï¼Œå› æ­¤ç‰ˆæƒä¸èƒ½ç”¨æ¥ä¿æŠ¤é£Ÿè°±ã€‚ä½†å¦‚æœé‚£ä»½é£Ÿè°±æ¸…å•é™„æœ‰å¤§é‡æ–°é¢–çš„æ–‡å­¦å†…å®¹ï¼Œé‚£ä¹ˆè¿™äº›å†…å®¹å°±æ˜¯å—ç‰ˆæƒä¿æŠ¤çš„ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå½“æ‚¨åœ¨ç½‘ä¸ŠæŸ¥æ‰¾é£Ÿè°±æ—¶ï¼Œæ€»ä¼šå…ˆçœ‹åˆ°é‚£ä¹ˆå¤šå†…å®¹ã€‚\nIf you do need to scrape original content (like text or images), you may still be protected under the doctrine of fair use. Fair use is not a hard and fast rule, but weighs up a number of factors. Itâ€™s more likely to apply if you are collecting the data for research or non-commercial purposes and if you limit what you scrape to just what you need.\nå¦‚æœæ‚¨ç¡®å®éœ€è¦æŠ“å–åŸåˆ›å†…å®¹ï¼ˆå¦‚æ–‡æœ¬æˆ–å›¾åƒï¼‰ï¼Œæ‚¨å¯èƒ½ä»ç„¶å—åˆ°åˆç†ä½¿ç”¨åŸåˆ™çš„ä¿æŠ¤ã€‚åˆç†ä½¿ç”¨ä¸æ˜¯ä¸€æˆä¸å˜çš„è§„åˆ™ï¼Œè€Œæ˜¯æƒè¡¡å¤šç§å› ç´ çš„ç»“æœã€‚å¦‚æœæ‚¨æ˜¯ä¸ºç ”ç©¶æˆ–éå•†ä¸šç›®çš„æ”¶é›†æ•°æ®ï¼Œå¹¶ä¸”åªæŠ“å–æ‚¨éœ€è¦çš„å†…å®¹ï¼Œé‚£ä¹ˆå®ƒå°±æ›´æœ‰å¯èƒ½é€‚ç”¨ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#html-basics",
    "href": "webscraping.html#html-basics",
    "title": "24Â  Web scraping",
    "section": "\n24.3 HTML basics",
    "text": "24.3 HTML basics\nTo scrape webpages, you need to first understand a little bit about HTML, the language that describes web pages. HTML stands for HyperText Markup Language and looks something like this:\nè¦æŠ“å–ç½‘é¡µï¼Œæ‚¨é¦–å…ˆéœ€è¦äº†è§£ä¸€äº›å…³äº HTML çš„çŸ¥è¯†ï¼Œè¿™æ˜¯ä¸€ç§æè¿°ç½‘é¡µçš„è¯­è¨€ã€‚HTML æ˜¯è¶…æ–‡æœ¬æ ‡è®°è¯­è¨€ï¼ˆHyperText Markup Languageï¼‰çš„ç¼©å†™ï¼Œçœ‹èµ·æ¥åƒè¿™æ ·ï¼š\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Page title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='first'&gt;A heading&lt;/h1&gt;\n  &lt;p&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\nHTML has a hierarchical structure formed by elements which consist of a start tag (e.g., &lt;tag&gt;), optional attributes (id='first'), an end tag4 (like &lt;/tag&gt;), and contents (everything in between the start and end tag).\nHTML å…·æœ‰ç”±å…ƒç´ ï¼ˆelementsï¼‰æ„æˆçš„å±‚æ¬¡ç»“æ„ï¼Œå…ƒç´ ç”±å¼€å§‹æ ‡ç­¾ï¼ˆä¾‹å¦‚ &lt;tag&gt;ï¼‰ã€å¯é€‰çš„å±æ€§ï¼ˆattributesï¼‰ï¼ˆä¾‹å¦‚ id='first'ï¼‰ã€ç»“æŸæ ‡ç­¾4ï¼ˆä¾‹å¦‚ &lt;/tag&gt;ï¼‰å’Œå†…å®¹ï¼ˆcontentsï¼‰ï¼ˆå¼€å§‹å’Œç»“æŸæ ‡ç­¾ä¹‹é—´çš„æ‰€æœ‰å†…å®¹ï¼‰ç»„æˆã€‚\nSince &lt; and &gt; are used for start and end tags, you canâ€™t write them directly. Instead you have to use the HTML escapes &gt; (greater than) and &lt; (less than). And since those escapes use &, if you want a literal ampersand you have to escape it as &amp;. There are a wide range of possible HTML escapes but you donâ€™t need to worry about them too much because rvest automatically handles them for you.\nç”±äº &lt; å’Œ &gt; ç”¨äºå¼€å§‹å’Œç»“æŸæ ‡ç­¾ï¼Œå› æ­¤ä¸èƒ½ç›´æ¥ä¹¦å†™å®ƒä»¬ã€‚æ‚¨å¿…é¡»ä½¿ç”¨ HTML è½¬ä¹‰ç¬¦ï¼ˆescapesï¼‰ï¼Œå³ &gt;ï¼ˆå¤§äºï¼‰å’Œ &lt;ï¼ˆå°äºï¼‰ã€‚åˆå› ä¸ºè¿™äº›è½¬ä¹‰ç¬¦ä½¿ç”¨äº† &ï¼Œæ‰€ä»¥å¦‚æœæ‚¨æƒ³è¡¨ç¤ºä¸€ä¸ªå­—é¢æ„ä¹‰ä¸Šçš„ä¸å·ï¼ˆampersandï¼‰ï¼Œå°±å¿…é¡»å°†å…¶è½¬ä¹‰ä¸º &amp;ã€‚HTML æœ‰å¾ˆå¤šç§å¯èƒ½çš„è½¬ä¹‰ç¬¦ï¼Œä½†æ‚¨ä¸å¿…å¤ªè¿‡æ‹…å¿ƒï¼Œå› ä¸º rvest ä¼šè‡ªåŠ¨ä¸ºæ‚¨å¤„ç†ã€‚\nWeb scraping is possible because most pages that contain data that you want to scrape generally have a consistent structure.\nç½‘é¡µæŠ“å–ä¹‹æ‰€ä»¥å¯è¡Œï¼Œæ˜¯å› ä¸ºå¤§å¤šæ•°åŒ…å«æ‚¨æƒ³è¦æŠ“å–æ•°æ®åœ°ç½‘é¡µé€šå¸¸å…·æœ‰ä¸€è‡´çš„ç»“æ„ã€‚\n\n24.3.1 Elements\nThere are over 100 HTML elements. Some of the most important are:\nHTML å…ƒç´ è¶…è¿‡ 100 ç§ã€‚å…¶ä¸­ä¸€äº›æœ€é‡è¦çš„åŒ…æ‹¬ï¼š\n\nEvery HTML page must be in an &lt;html&gt; element, and it must have two children: &lt;head&gt;, which contains document metadata like the page title, and &lt;body&gt;, which contains the content you see in the browser.\næ¯ä¸ª HTML é¡µé¢éƒ½å¿…é¡»ä½äºä¸€ä¸ª &lt;html&gt; å…ƒç´ ä¸­ï¼Œå¹¶ä¸”å®ƒå¿…é¡»æœ‰ä¸¤ä¸ªå­å…ƒç´ ï¼š&lt;head&gt;ï¼ŒåŒ…å«æ–‡æ¡£å…ƒæ•°æ®ï¼Œå¦‚é¡µé¢æ ‡é¢˜ï¼›ä»¥åŠ &lt;body&gt;ï¼ŒåŒ…å«æ‚¨åœ¨æµè§ˆå™¨ä¸­çœ‹åˆ°çš„å†…å®¹ã€‚\nBlock tags like &lt;h1&gt; (heading 1), &lt;section&gt; (section), &lt;p&gt; (paragraph), and &lt;ol&gt; (ordered list) form the overall structure of the page.\nå—çº§æ ‡ç­¾ï¼Œå¦‚ &lt;h1&gt;ï¼ˆä¸€çº§æ ‡é¢˜ï¼‰ã€&lt;section&gt;ï¼ˆèŠ‚ï¼‰ã€&lt;p&gt;ï¼ˆæ®µè½ï¼‰å’Œ &lt;ol&gt;ï¼ˆæœ‰åºåˆ—è¡¨ï¼‰ï¼Œæ„æˆäº†é¡µé¢çš„æ•´ä½“ç»“æ„ã€‚\nInline tags like &lt;b&gt; (bold), &lt;i&gt; (italics), and &lt;a&gt; (link) format text inside block tags.\nå†…è”æ ‡ç­¾ï¼Œå¦‚ &lt;b&gt;ï¼ˆç²—ä½“ï¼‰ã€&lt;i&gt;ï¼ˆæ–œä½“ï¼‰å’Œ &lt;a&gt;ï¼ˆé“¾æ¥ï¼‰ï¼Œç”¨äºæ ¼å¼åŒ–å—çº§æ ‡ç­¾å†…çš„æ–‡æœ¬ã€‚\n\nIf you encounter a tag that youâ€™ve never seen before, you can find out what it does with a little googling. Another good place to start are the MDN Web Docs which describe just about every aspect of web programming.\nå¦‚æœæ‚¨é‡åˆ°ä¸€ä¸ªä»æœªè§è¿‡çš„æ ‡ç­¾ï¼Œå¯ä»¥é€šè¿‡ Google æœç´¢æ¥äº†è§£å®ƒçš„ä½œç”¨ã€‚å¦ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹æ˜¯ MDN Web Docsï¼Œå®ƒå‡ ä¹æè¿°äº†ç½‘é¡µç¼–ç¨‹çš„æ–¹æ–¹é¢é¢ã€‚\nMost elements can have content in between their start and end tags. This content can either be text or more elements. For example, the following HTML contains paragraph of text, with one word in bold.\nå¤§å¤šæ•°å…ƒç´ éƒ½å¯ä»¥åœ¨å…¶å¼€å§‹å’Œç»“æŸæ ‡ç­¾ä¹‹é—´åŒ…å«å†…å®¹ã€‚è¿™ä¸ªå†…å®¹å¯ä»¥æ˜¯æ–‡æœ¬ï¼Œä¹Ÿå¯ä»¥æ˜¯æ›´å¤šçš„å…ƒç´ ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„ HTML åŒ…å«ä¸€ä¸ªæ–‡æœ¬æ®µè½ï¼Œå…¶ä¸­ä¸€ä¸ªè¯æ˜¯ç²—ä½“ã€‚\n&lt;p&gt;\n  Hi! My &lt;b&gt;name&lt;/b&gt; is Hadley.\n&lt;/p&gt;\nThe children are the elements it contains, so the &lt;p&gt; element above has one child, the &lt;b&gt; element. The &lt;b&gt; element has no children, but it does have contents (the text â€œnameâ€).å­å…ƒç´ ï¼ˆchildrenï¼‰æ˜¯å®ƒæ‰€åŒ…å«çš„å…ƒç´ ï¼Œæ‰€ä»¥ä¸Šé¢ &lt;p&gt; å…ƒç´ æœ‰ä¸€ä¸ªå­å…ƒç´ ï¼Œå³ &lt;b&gt; å…ƒç´ ã€‚&lt;b&gt; å…ƒç´ æ²¡æœ‰å­å…ƒç´ ï¼Œä½†å®ƒæœ‰å†…å®¹ï¼ˆæ–‡æœ¬â€œnameâ€ï¼‰ã€‚\n\n24.3.2 Attributes\nTags can have named attributes which look like name1='value1' name2='value2'. Two of the most important attributes are id and class, which are used in conjunction with CSS (Cascading Style Sheets) to control the visual appearance of the page. These are often useful when scraping data off a page. Attributes are also used to record the destination of links (the href attribute of &lt;a&gt; elements) and the source of images (the src attribute of the &lt;img&gt; element).\næ ‡ç­¾å¯ä»¥æœ‰åä¸ºå±æ€§ï¼ˆattributesï¼‰çš„å‚æ•°ï¼Œå…¶å½¢å¼å¦‚ name1='value1' name2='value2'ã€‚å…¶ä¸­æœ€é‡è¦çš„ä¸¤ä¸ªå±æ€§æ˜¯ id å’Œ classï¼Œå®ƒä»¬ä¸ CSSï¼ˆå±‚å æ ·å¼è¡¨ï¼‰ç»“åˆä½¿ç”¨ï¼Œä»¥æ§åˆ¶é¡µé¢çš„è§†è§‰å¤–è§‚ã€‚åœ¨ä»é¡µé¢æŠ“å–æ•°æ®æ—¶ï¼Œè¿™äº›å±æ€§é€šå¸¸å¾ˆæœ‰ç”¨ã€‚å±æ€§è¿˜ç”¨äºè®°å½•é“¾æ¥çš„ç›®çš„åœ°ï¼ˆ&lt;a&gt; å…ƒç´ çš„ href å±æ€§ï¼‰å’Œå›¾åƒçš„æ¥æºï¼ˆ&lt;img&gt; å…ƒç´ çš„ src å±æ€§ï¼‰ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#extracting-data",
    "href": "webscraping.html#extracting-data",
    "title": "24Â  Web scraping",
    "section": "\n24.4 Extracting data",
    "text": "24.4 Extracting data\nTo get started scraping, youâ€™ll need the URL of the page you want to scrape, which you can usually copy from your web browser. Youâ€™ll then need to read the HTML for that page into R with read_html(). This returns an xml_document5 object which youâ€™ll then manipulate using rvest functions:\nè¦å¼€å§‹æŠ“å–ï¼Œæ‚¨éœ€è¦ç›®æ ‡é¡µé¢çš„ URLï¼Œé€šå¸¸å¯ä»¥ä»æ‚¨çš„ç½‘ç»œæµè§ˆå™¨ä¸­å¤åˆ¶ã€‚ç„¶åï¼Œæ‚¨éœ€è¦ä½¿ç”¨ read_html() å°†è¯¥é¡µé¢çš„ HTML è¯»å…¥ Rã€‚è¿™å°†è¿”å›ä¸€ä¸ª xml_document5 å¯¹è±¡ï¼Œæ‚¨å°†ä½¿ç”¨ rvest å‡½æ•°å¯¹å…¶è¿›è¡Œæ“ä½œï¼š\n\nhtml &lt;- read_html(\"http://rvest.tidyverse.org/\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html lang=\"en\"&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n    &lt;a href=\"#container\" class=\"visually-hidden-focusable\"&gt;Ski ...\n\nrvest also includes a function that lets you write HTML inline. Weâ€™ll use this a bunch in this chapter as we teach how the various rvest functions work with simple examples.\nrvest è¿˜åŒ…å«ä¸€ä¸ªå…è®¸æ‚¨å†…è”ç¼–å†™ HTML çš„å‡½æ•°ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†å¤§é‡ä½¿ç”¨å®ƒï¼Œé€šè¿‡ç®€å•çš„ä¾‹å­æ¥æ•™æˆå„ç§ rvest å‡½æ•°çš„å·¥ä½œæ–¹å¼ã€‚\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;This is a paragraph&lt;/p&gt;\n  &lt;ul&gt;\n    &lt;li&gt;This is a bulleted list&lt;/li&gt;\n  &lt;/ul&gt;\n\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n&lt;p&gt;This is a paragraph&lt;/p&gt;\\n  &lt;ul&gt;\\n&lt;li&gt;This is a bulleted lis ...\n\nNow that you have the HTML in R, itâ€™s time to extract the data of interest. Youâ€™ll first learn about the CSS selectors that allow you to identify the elements of interest and the rvest functions that you can use to extract data from them. Then weâ€™ll briefly cover HTML tables, which have some special tools.\nç°åœ¨æ‚¨å·²ç»åœ¨ R ä¸­è·å¾—äº† HTMLï¼Œæ˜¯æ—¶å€™æå–æ„Ÿå…´è¶£çš„æ•°æ®äº†ã€‚æ‚¨å°†é¦–å…ˆäº†è§£ CSS é€‰æ‹©å™¨ï¼Œå®ƒå…è®¸æ‚¨è¯†åˆ«æ„Ÿå…´è¶£çš„å…ƒç´ ï¼Œä»¥åŠå¯ä»¥ç”¨æ¥ä»ä¸­æå–æ•°æ®çš„ rvest å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬å°†ç®€è¦ä»‹ç» HTML è¡¨æ ¼ï¼Œå®ƒæœ‰ä¸€äº›ç‰¹æ®Šçš„å·¥å…·ã€‚\n\n24.4.1 Find elements\nCSS is short for cascading style sheets, and is a tool for defining the visual styling of HTML documents. CSS includes a miniature language for selecting elements on a page called CSS selectors. CSS selectors define patterns for locating HTML elements, and are useful for scraping because they provide a concise way of describing which elements you want to extract.\nCSS æ˜¯å±‚å æ ·å¼è¡¨ï¼ˆcascading style sheetsï¼‰çš„ç¼©å†™ï¼Œæ˜¯ç”¨äºå®šä¹‰ HTML æ–‡æ¡£è§†è§‰æ ·å¼çš„å·¥å…·ã€‚CSS åŒ…å«ä¸€ç§ç”¨äºåœ¨é¡µé¢ä¸Šé€‰æ‹©å…ƒç´ çš„å¾®å‹è¯­è¨€ï¼Œç§°ä¸º CSS é€‰æ‹©å™¨ï¼ˆCSS selectorsï¼‰ã€‚CSS é€‰æ‹©å™¨å®šä¹‰äº†å®šä½ HTML å…ƒç´ çš„æ¨¡å¼ï¼Œåœ¨æŠ“å–æ•°æ®æ—¶éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒä»¬æä¾›äº†ä¸€ç§ç®€æ´çš„æ–¹å¼æ¥æè¿°æ‚¨æƒ³è¦æå–çš„å…ƒç´ ã€‚\nWeâ€™ll come back to CSS selectors in more detail in Section 24.5, but luckily you can get a long way with just three:\næˆ‘ä»¬å°†åœ¨ Section 24.5 ä¸­æ›´è¯¦ç»†åœ°å›åˆ° CSS é€‰æ‹©å™¨ï¼Œä½†å¹¸è¿çš„æ˜¯ï¼Œä»…ç”¨ä»¥ä¸‹ä¸‰ä¸ªå°±å¯ä»¥èµ°å¾—å¾ˆè¿œï¼š\n\np selects all &lt;p&gt; elements.p é€‰æ‹©æ‰€æœ‰çš„ &lt;p&gt; å…ƒç´ ã€‚\n.title selects all elements with class â€œtitleâ€..title é€‰æ‹©æ‰€æœ‰ class ä¸º â€œtitleâ€ çš„å…ƒç´ ã€‚\n#title selects the element with the id attribute that equals â€œtitleâ€. Id attributes must be unique within a document, so this will only ever select a single element.#title é€‰æ‹© id å±æ€§ç­‰äº â€œtitleâ€ çš„å…ƒç´ ã€‚Id å±æ€§åœ¨æ–‡æ¡£ä¸­å¿…é¡»æ˜¯å”¯ä¸€çš„ï¼Œæ‰€ä»¥è¿™åªä¼šé€‰æ‹©ä¸€ä¸ªå…ƒç´ ã€‚\n\nLetâ€™s try out these selectors with a simple example:\nè®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥è¯•è¯•è¿™äº›é€‰æ‹©å™¨ï¼š\n\nhtml &lt;- minimal_html(\"\n  &lt;h1&gt;This is a heading&lt;/h1&gt;\n  &lt;p id='first'&gt;This is a paragraph&lt;/p&gt;\n  &lt;p class='important'&gt;This is an important paragraph&lt;/p&gt;\n\")\n\nUse html_elements() to find all elements that match the selector:\nä½¿ç”¨ html_elements() æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…é€‰æ‹©å™¨çš„å…ƒç´ ï¼š\n\nhtml |&gt; html_elements(\"p\")\n#&gt; {xml_nodeset (2)}\n#&gt; [1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n#&gt; [2] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\nhtml |&gt; html_elements(\".important\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\nhtml |&gt; html_elements(\"#first\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n\nAnother important function is html_element() which always returns the same number of outputs as inputs. If you apply it to a whole document itâ€™ll give you the first match:\nå¦ä¸€ä¸ªé‡è¦çš„å‡½æ•°æ˜¯ html_element()ï¼Œå®ƒæ€»æ˜¯è¿”å›ä¸è¾“å…¥ç›¸åŒæ•°é‡çš„è¾“å‡ºã€‚å¦‚æœå°†å…¶åº”ç”¨äºæ•´ä¸ªæ–‡æ¡£ï¼Œå®ƒå°†ç»™å‡ºç¬¬ä¸€ä¸ªåŒ¹é…é¡¹ï¼š\n\nhtml |&gt; html_element(\"p\")\n#&gt; {html_node}\n#&gt; &lt;p id=\"first\"&gt;\n\nThereâ€™s an important difference between html_element() and html_elements() when you use a selector that doesnâ€™t match any elements. html_elements() returns a vector of length 0, where html_element() returns a missing value. This will be important shortly.\nå½“æ‚¨ä½¿ç”¨ä¸€ä¸ªä¸åŒ¹é…ä»»ä½•å…ƒç´ çš„é€‰æ‹©å™¨æ—¶ï¼Œhtml_element() å’Œ html_elements() ä¹‹é—´æœ‰ä¸€ä¸ªé‡è¦çš„åŒºåˆ«ã€‚html_elements() è¿”å›ä¸€ä¸ªé•¿åº¦ä¸º 0 çš„å‘é‡ï¼Œè€Œ html_element() è¿”å›ä¸€ä¸ªç¼ºå¤±å€¼ã€‚è¿™ä¸€ç‚¹å¾ˆå¿«å°±ä¼šå˜å¾—å¾ˆé‡è¦ã€‚\n\nhtml |&gt; html_elements(\"b\")\n#&gt; {xml_nodeset (0)}\nhtml |&gt; html_element(\"b\")\n#&gt; {xml_missing}\n#&gt; &lt;NA&gt;\n\n\n24.4.2 Nesting selections\nIn most cases, youâ€™ll use html_elements() and html_element() together, typically using html_elements() to identify elements that will become observations then using html_element() to find elements that will become variables. Letâ€™s see this in action using a simple example. Here we have an unordered list (&lt;ul&gt;) where each list item (&lt;li&gt;) contains some information about four characters from StarWars:\nåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨ä¼šåŒæ—¶ä½¿ç”¨ html_elements() å’Œ html_element()ï¼Œé€šå¸¸ä½¿ç”¨ html_elements() æ¥è¯†åˆ«å°†æˆä¸ºè§‚æµ‹å€¼çš„å…ƒç´ ï¼Œç„¶åä½¿ç”¨ html_element() æ¥æŸ¥æ‰¾å°†æˆä¸ºå˜é‡çš„å…ƒç´ ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥çœ‹çœ‹å®ƒçš„å®é™…åº”ç”¨ã€‚è¿™é‡Œæˆ‘ä»¬æœ‰ä¸€ä¸ªæ— åºåˆ—è¡¨ï¼ˆ&lt;ul&gt;ï¼‰ï¼Œå…¶ä¸­æ¯ä¸ªåˆ—è¡¨é¡¹ï¼ˆ&lt;li&gt;ï¼‰éƒ½åŒ…å«æœ‰å…³ã€Šæ˜Ÿçƒå¤§æˆ˜ã€‹ä¸­å››ä¸ªè§’è‰²çš„ä¸€äº›ä¿¡æ¯ï¼š\n\nhtml &lt;- minimal_html(\"\n  &lt;ul&gt;\n    &lt;li&gt;&lt;b&gt;C-3PO&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;167 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R4-P17&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R2-D2&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;96 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;Yoda&lt;/b&gt; weighs &lt;span class='weight'&gt;66 kg&lt;/span&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n  \")\n\nWe can use html_elements() to make a vector where each element corresponds to a different character:\næˆ‘ä»¬å¯ä»¥ä½¿ç”¨ html_elements() åˆ›å»ºä¸€ä¸ªå‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªä¸åŒçš„è§’è‰²ï¼š\n\ncharacters &lt;- html |&gt; html_elements(\"li\")\ncharacters\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;li&gt;\\n&lt;b&gt;C-3PO&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class=\"weight\"&gt; ...\n#&gt; [2] &lt;li&gt;\\n&lt;b&gt;R4-P17&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt;\\n&lt;/li&gt;\n#&gt; [3] &lt;li&gt;\\n&lt;b&gt;R2-D2&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class=\"weight\"&gt; ...\n#&gt; [4] &lt;li&gt;\\n&lt;b&gt;Yoda&lt;/b&gt; weighs &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\\n&lt;/li&gt;\n\nTo extract the name of each character, we use html_element(), because when applied to the output of html_elements() itâ€™s guaranteed to return one response per element:\nè¦æå–æ¯ä¸ªè§’è‰²çš„åå­—ï¼Œæˆ‘ä»¬ä½¿ç”¨ html_element()ï¼Œå› ä¸ºå½“å®ƒåº”ç”¨äº html_elements() çš„è¾“å‡ºæ—¶ï¼Œå¯ä»¥ä¿è¯ä¸ºæ¯ä¸ªå…ƒç´ è¿”å›ä¸€ä¸ªå“åº”ï¼š\n\ncharacters |&gt; html_element(\"b\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;b&gt;C-3PO&lt;/b&gt;\n#&gt; [2] &lt;b&gt;R4-P17&lt;/b&gt;\n#&gt; [3] &lt;b&gt;R2-D2&lt;/b&gt;\n#&gt; [4] &lt;b&gt;Yoda&lt;/b&gt;\n\nThe distinction between html_element() and html_elements() isnâ€™t important for name, but it is important for weight. We want to get one weight for each character, even if thereâ€™s no weight &lt;span&gt;. Thatâ€™s what html_element() does:\nå¯¹äºåå­—æ¥è¯´ï¼Œhtml_element() å’Œ html_elements() ä¹‹é—´çš„åŒºåˆ«å¹¶ä¸é‡è¦ï¼Œä½†å¯¹äºä½“é‡æ¥è¯´ï¼Œè¿™ä¸ªåŒºåˆ«å¾ˆé‡è¦ã€‚æˆ‘ä»¬å¸Œæœ›ä¸ºæ¯ä¸ªè§’è‰²è·å–ä¸€ä¸ªä½“é‡ï¼Œå³ä½¿æ²¡æœ‰ä½“é‡ &lt;span&gt; æ ‡ç­¾ã€‚è¿™æ­£æ˜¯ html_element() æ‰€åšçš„ï¼š\n\ncharacters |&gt; html_element(\".weight\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;\n#&gt; [2] NA\n#&gt; [3] &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;\n#&gt; [4] &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\n\nhtml_elements() finds all weight &lt;span&gt;s that are children of characters. Thereâ€™s only three of these, so we lose the connection between names and weights:html_elements() ä¼šæ‰¾åˆ° characters çš„æ‰€æœ‰å­å…ƒç´ ä¸­çš„ä½“é‡ &lt;span&gt;ã€‚è¿™é‡Œåªæœ‰ä¸‰ä¸ªï¼Œæ‰€ä»¥æˆ‘ä»¬å¤±å»äº†åå­—å’Œä½“é‡ä¹‹é—´çš„è”ç³»ï¼š\n\ncharacters |&gt; html_elements(\".weight\")\n#&gt; {xml_nodeset (3)}\n#&gt; [1] &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;\n#&gt; [2] &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;\n#&gt; [3] &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\n\nNow that youâ€™ve selected the elements of interest, youâ€™ll need to extract the data, either from the text contents or some attributes.\næ—¢ç„¶æ‚¨å·²ç»é€‰æ‹©äº†æ„Ÿå…´è¶£çš„å…ƒç´ ï¼Œæ¥ä¸‹æ¥å°±éœ€è¦ä»æ–‡æœ¬å†…å®¹æˆ–æŸäº›å±æ€§ä¸­æå–æ•°æ®ã€‚\n\n24.4.3 Text and attributes\nhtml_text2()6 extracts the plain text contents of an HTML element:html_text2()6 æå– HTML å…ƒç´ çš„çº¯æ–‡æœ¬å†…å®¹ï¼š\n\ncharacters |&gt; \n  html_element(\"b\") |&gt; \n  html_text2()\n#&gt; [1] \"C-3PO\"  \"R4-P17\" \"R2-D2\"  \"Yoda\"\n\ncharacters |&gt; \n  html_element(\".weight\") |&gt; \n  html_text2()\n#&gt; [1] \"167 kg\" NA       \"96 kg\"  \"66 kg\"\n\nNote that any escapes will be automatically handled; youâ€™ll only ever see HTML escapes in the source HTML, not in the data returned by rvest.\nè¯·æ³¨æ„ï¼Œä»»ä½•è½¬ä¹‰å­—ç¬¦éƒ½ä¼šè¢«è‡ªåŠ¨å¤„ç†ï¼›ä½ åªä¼šåœ¨æº HTML ä¸­çœ‹åˆ° HTML è½¬ä¹‰å­—ç¬¦ï¼Œè€Œä¸ä¼šåœ¨ rvest è¿”å›çš„æ•°æ®ä¸­çœ‹åˆ°ã€‚\nhtml_attr() extracts data from attributes:html_attr() ä»å±æ€§ä¸­æå–æ•°æ®ï¼š\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Cat'&gt;cats&lt;/a&gt;&lt;/p&gt;\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Dog'&gt;dogs&lt;/a&gt;&lt;/p&gt;\n\")\n\nhtml |&gt; \n  html_elements(\"p\") |&gt; \n  html_element(\"a\") |&gt; \n  html_attr(\"href\")\n#&gt; [1] \"https://en.wikipedia.org/wiki/Cat\" \"https://en.wikipedia.org/wiki/Dog\"\n\nhtml_attr() always returns a string, so if youâ€™re extracting numbers or dates, youâ€™ll need to do some post-processing.html_attr() æ€»æ˜¯è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰€ä»¥å¦‚æœä½ è¦æå–æ•°å­—æˆ–æ—¥æœŸï¼Œå°±éœ€è¦è¿›è¡Œä¸€äº›åå¤„ç†ã€‚\n\n24.4.4 Tables\nIf youâ€™re lucky, your data will be already stored in an HTML table, and itâ€™ll be a matter of just reading it from that table. Itâ€™s usually straightforward to recognize a table in your browser: itâ€™ll have a rectangular structure of rows and columns, and you can copy and paste it into a tool like Excel.\nå¦‚æœä½ å¹¸è¿çš„è¯ï¼Œä½ çš„æ•°æ®å¯èƒ½å·²ç»å­˜å‚¨åœ¨ HTML è¡¨æ ¼ä¸­ï¼Œé‚£ä¹ˆé—®é¢˜å°±ç®€åŒ–ä¸ºä»è¯¥è¡¨æ ¼ä¸­è¯»å–æ•°æ®ã€‚åœ¨æµè§ˆå™¨ä¸­è¯†åˆ«è¡¨æ ¼é€šå¸¸å¾ˆç®€å•ï¼šå®ƒä¼šæœ‰ä¸€ä¸ªç”±è¡Œå’Œåˆ—ç»„æˆçš„çŸ©å½¢ç»“æ„ï¼Œä½ å¯ä»¥å°†å…¶å¤åˆ¶å¹¶ç²˜è´´åˆ°åƒ Excel è¿™æ ·çš„å·¥å…·ä¸­ã€‚\nHTML tables are built up from four main elements: &lt;table&gt;, &lt;tr&gt; (table row), &lt;th&gt; (table heading), and &lt;td&gt; (table data). Hereâ€™s a simple HTML table with two columns and three rows:\nHTML è¡¨æ ¼ç”±å››ä¸ªä¸»è¦å…ƒç´ æ„æˆï¼š&lt;table&gt;ã€&lt;tr&gt; (table rowï¼Œè¡¨æ ¼è¡Œ)ã€&lt;th&gt; (table headingï¼Œè¡¨å¤´) å’Œ &lt;td&gt; (table dataï¼Œè¡¨æ ¼æ•°æ®)ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªåŒ…å«ä¸¤åˆ—ä¸‰è¡Œçš„ç®€å• HTML è¡¨æ ¼ï¼š\n\nhtml &lt;- minimal_html(\"\n  &lt;table class='mytable'&gt;\n    &lt;tr&gt;&lt;th&gt;x&lt;/th&gt;    &lt;th&gt;y&lt;/th&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;1.5&lt;/td&gt; &lt;td&gt;2.7&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;4.9&lt;/td&gt; &lt;td&gt;1.3&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;7.2&lt;/td&gt; &lt;td&gt;8.1&lt;/td&gt;&lt;/tr&gt;\n  &lt;/table&gt;\n  \")\n\nrvest provides a function that knows how to read this sort of data: html_table(). It returns a list containing one tibble for each table found on the page. Use html_element() to identify the table you want to extract:\nrvest æä¾›äº†ä¸€ä¸ªçŸ¥é“å¦‚ä½•è¯»å–è¿™ç±»æ•°æ®çš„å‡½æ•°ï¼šhtml_table()ã€‚å®ƒè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«é¡µé¢ä¸Šæ‰¾åˆ°çš„æ¯ä¸ªè¡¨æ ¼å¯¹åº”çš„ä¸€ä¸ª tibbleã€‚ä½¿ç”¨ html_element() æ¥è¯†åˆ«ä½ æƒ³è¦æå–çš„è¡¨æ ¼ï¼š\n\nhtml |&gt; \n  html_element(\".mytable\") |&gt; \n  html_table()\n#&gt; # A tibble: 3 Ã— 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   1.5   2.7\n#&gt; 2   4.9   1.3\n#&gt; 3   7.2   8.1\n\nNote that x and y have automatically been converted to numbers. This automatic conversion doesnâ€™t always work, so in more complex scenarios you may want to turn it off with convert = FALSE and then do your own conversion.\næ³¨æ„ x å’Œ y å·²è¢«è‡ªåŠ¨è½¬æ¢ä¸ºæ•°å­—ã€‚è¿™ç§è‡ªåŠ¨è½¬æ¢å¹¶ä¸æ€»æ˜¯æœ‰æ•ˆï¼Œå› æ­¤åœ¨æ›´å¤æ‚çš„åœºæ™¯ä¸­ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨ convert = FALSE å°†å…¶å…³é—­ï¼Œç„¶åè‡ªå·±è¿›è¡Œè½¬æ¢ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#sec-css-selectors",
    "href": "webscraping.html#sec-css-selectors",
    "title": "24Â  Web scraping",
    "section": "\n24.5 Finding the right selectors",
    "text": "24.5 Finding the right selectors\nFiguring out the selector you need for your data is typically the hardest part of the problem. Youâ€™ll often need to do some experimenting to find a selector that is both specific (i.e.Â it doesnâ€™t select things you donâ€™t care about) and sensitive (i.e.Â it does select everything you care about). Lots of trial and error is a normal part of the process! There are two main tools that are available to help you with this process: SelectorGadget and your browserâ€™s developer tools.\næ‰¾å‡ºæ•°æ®æ‰€éœ€çš„é€‰æ‹©å™¨é€šå¸¸æ˜¯é—®é¢˜ä¸­æœ€å›°éš¾çš„éƒ¨åˆ†ã€‚ä½ é€šå¸¸éœ€è¦è¿›è¡Œä¸€äº›å®éªŒï¼Œä»¥æ‰¾åˆ°ä¸€ä¸ªæ—¢å…·ä½“ (specific)ï¼ˆå³å®ƒä¸ä¼šé€‰æ‹©ä½ ä¸åœ¨ä¹çš„ä¸œè¥¿ï¼‰åˆæ•æ„Ÿ (sensitive)ï¼ˆå³å®ƒç¡®å®é€‰æ‹©äº†ä½ å…³å¿ƒçš„æ‰€æœ‰ä¸œè¥¿ï¼‰çš„é€‰æ‹©å™¨ã€‚å¤§é‡çš„åå¤è¯•éªŒæ˜¯è¿™ä¸ªè¿‡ç¨‹çš„æ­£å¸¸éƒ¨åˆ†ï¼æœ‰ä¸¤ä¸ªä¸»è¦å·¥å…·å¯ä»¥å¸®åŠ©ä½ å®Œæˆè¿™ä¸ªè¿‡ç¨‹ï¼šSelectorGadget å’Œä½ æµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·ã€‚\nSelectorGadget is a javascript bookmarklet that automatically generates CSS selectors based on the positive and negative examples that you provide. It doesnâ€™t always work, but when it does, itâ€™s magic! You can learn how to install and use SelectorGadget either by reading https://rvest.tidyverse.org/articles/selectorgadget.html or watching Mineâ€™s video at https://www.youtube.com/watch?v=PetWV5g1Xsc.SelectorGadget æ˜¯ä¸€ä¸ª javascript ä¹¦ç­¾å·¥å…·ï¼Œå®ƒå¯ä»¥æ ¹æ®ä½ æä¾›çš„æ­£é¢å’Œè´Ÿé¢ç¤ºä¾‹è‡ªåŠ¨ç”Ÿæˆ CSS é€‰æ‹©å™¨ã€‚å®ƒå¹¶ä¸æ€»æ˜¯æœ‰æ•ˆï¼Œä½†ä¸€æ—¦æœ‰æ•ˆï¼Œæ•ˆæœå°±å¦‚åŒé­”æ³•ï¼ä½ å¯ä»¥é€šè¿‡é˜…è¯» https://rvest.tidyverse.org/articles/selectorgadget.html æˆ–è§‚çœ‹ Mine åœ¨ https://www.youtube.com/watch?v=PetWV5g1Xsc ä¸Šçš„è§†é¢‘æ¥å­¦ä¹ å¦‚ä½•å®‰è£…å’Œä½¿ç”¨ SelectorGadgetã€‚\nEvery modern browser comes with some toolkit for developers, but we recommend Chrome, even if it isnâ€™t your regular browser: its web developer tools are some of the best and theyâ€™re immediately available. Right click on an element on the page and click Inspect. This will open an expandable view of the complete HTML page, centered on the element that you just clicked. You can use this to explore the page and get a sense of what selectors might work. Pay particular attention to the class and id attributes, since these are often used to form the visual structure of the page, and hence make for good tools to extract the data that youâ€™re looking for.\næ¯ä¸ªç°ä»£æµè§ˆå™¨éƒ½å¸¦æœ‰ä¸€äº›é¢å‘å¼€å‘è€…çš„å·¥å…·åŒ…ï¼Œä½†æˆ‘ä»¬æ¨èä½¿ç”¨ Chromeï¼Œå³ä½¿å®ƒä¸æ˜¯ä½ çš„å¸¸ç”¨æµè§ˆå™¨ï¼šå®ƒçš„ Web å¼€å‘è€…å·¥å…·æ˜¯æœ€å¥½çš„ä¹‹ä¸€ï¼Œè€Œä¸”å¯ä»¥ç«‹å³ä½¿ç”¨ã€‚åœ¨é¡µé¢ä¸Šçš„ä¸€ä¸ªå…ƒç´ ä¸Šå³é”®å•å‡»ï¼Œç„¶åç‚¹å‡» Inspect (æ£€æŸ¥)ã€‚è¿™å°†æ‰“å¼€ä¸€ä¸ªå¯å±•å¼€çš„å®Œæ•´ HTML é¡µé¢è§†å›¾ï¼Œå¹¶ä»¥ä½ åˆšåˆšç‚¹å‡»çš„å…ƒç´ ä¸ºä¸­å¿ƒã€‚ä½ å¯ä»¥ç”¨å®ƒæ¥æ¢ç´¢é¡µé¢ï¼Œå¹¶äº†è§£å“ªäº›é€‰æ‹©å™¨å¯èƒ½æœ‰æ•ˆã€‚è¦ç‰¹åˆ«æ³¨æ„ class å’Œ id å±æ€§ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸ç”¨äºæ„æˆé¡µé¢çš„è§†è§‰ç»“æ„ï¼Œå› æ­¤æ˜¯æå–ä½ æ‰€å¯»æ‰¾æ•°æ®çš„å¥½å·¥å…·ã€‚\nInside the Elements view, you can also right click on an element and choose Copy as Selector to generate a selector that will uniquely identify the element of interest.\nåœ¨â€œå…ƒç´ â€(Elements) è§†å›¾ä¸­ï¼Œä½ è¿˜å¯ä»¥åœ¨ä¸€ä¸ªå…ƒç´ ä¸Šå³é”®å•å‡»å¹¶é€‰æ‹© Copy as Selector (å¤åˆ¶ä¸ºé€‰æ‹©å™¨)ï¼Œä»¥ç”Ÿæˆä¸€ä¸ªèƒ½å”¯ä¸€æ ‡è¯†ç›®æ ‡å…ƒç´ çš„é€‰æ‹©å™¨ã€‚\nIf either SelectorGadget or Chrome DevTools have generated a CSS selector that you donâ€™t understand, try Selectors Explained which translates CSS selectors into plain English. If you find yourself doing this a lot, you might want to learn more about CSS selectors generally. We recommend starting with the fun CSS dinner tutorial and then referring to the MDN web docs.\nå¦‚æœ SelectorGadget æˆ– Chrome å¼€å‘è€…å·¥å…·ç”Ÿæˆäº†ä½ çœ‹ä¸æ‡‚çš„ CSS é€‰æ‹©å™¨ï¼Œå¯ä»¥è¯•è¯• Selectors Explainedï¼Œå®ƒèƒ½å°† CSS é€‰æ‹©å™¨ç¿»è¯‘æˆé€šä¿—æ˜“æ‡‚çš„è‹±è¯­ã€‚å¦‚æœä½ å‘ç°è‡ªå·±ç»å¸¸è¿™æ ·åšï¼Œä½ å¯èƒ½éœ€è¦æ›´å…¨é¢åœ°å­¦ä¹  CSS é€‰æ‹©å™¨ã€‚æˆ‘ä»¬æ¨èä»æœ‰è¶£çš„ CSS dinner æ•™ç¨‹å¼€å§‹ï¼Œç„¶åå‚è€ƒ MDN web docsã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#putting-it-all-together",
    "href": "webscraping.html#putting-it-all-together",
    "title": "24Â  Web scraping",
    "section": "\n24.6 Putting it all together",
    "text": "24.6 Putting it all together\nLetâ€™s put this all together to scrape some websites. Thereâ€™s some risk that these examples may no longer work when you run them â€” thatâ€™s the fundamental challenge of web scraping; if the structure of the site changes, then youâ€™ll have to change your scraping code.\nè®©æˆ‘ä»¬æŠŠæ‰€æœ‰è¿™äº›æ•´åˆèµ·æ¥ï¼Œå»çˆ¬å–ä¸€äº›ç½‘ç«™ã€‚å½“ä½ è¿è¡Œè¿™äº›ç¤ºä¾‹æ—¶ï¼Œå®ƒä»¬å¯èƒ½ä¸å†æœ‰æ•ˆï¼Œè¿™å­˜åœ¨ä¸€å®šçš„é£é™©â€”â€”è¿™æ˜¯ç½‘ç»œçˆ¬å–çš„æ ¹æœ¬æŒ‘æˆ˜ï¼›å¦‚æœç½‘ç«™çš„ç»“æ„å‘ç”Ÿå˜åŒ–ï¼Œä½ å°±å¿…é¡»ä¿®æ”¹ä½ çš„çˆ¬å–ä»£ç ã€‚\n\n24.6.1 StarWars\nrvest includes a very simple example in vignette(\"starwars\"). This is a simple page with minimal HTML so itâ€™s a good place to start. Iâ€™d encourage you to navigate to that page now and use â€œInspect Elementâ€ to inspect one of the headings thatâ€™s the title of a Star Wars movie. Use the keyboard or mouse to explore the hierarchy of the HTML and see if you can get a sense of the shared structure used by each movie.\nrvest åœ¨ vignette(\"starwars\") ä¸­åŒ…å«äº†ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­ã€‚è¿™æ˜¯ä¸€ä¸ª HTML æç®€çš„ç®€å•é¡µé¢ï¼Œæ‰€ä»¥æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚æˆ‘é¼“åŠ±ä½ ç°åœ¨å°±å¯¼èˆªåˆ°é‚£ä¸ªé¡µé¢ï¼Œå¹¶ä½¿ç”¨â€œæ£€æŸ¥å…ƒç´ â€(Inspect Element) æ¥æ£€æŸ¥å…¶ä¸­ä¸€ä¸ªä½œä¸ºæ˜Ÿçƒå¤§æˆ˜ç”µå½±æ ‡é¢˜çš„æ ‡é¢˜ã€‚ä½¿ç”¨é”®ç›˜æˆ–é¼ æ ‡æ¥æ¢ç´¢ HTML çš„å±‚æ¬¡ç»“æ„ï¼Œçœ‹çœ‹ä½ æ˜¯å¦èƒ½äº†è§£æ¯éƒ¨ç”µå½±æ‰€ä½¿ç”¨çš„å…±äº«ç»“æ„ã€‚\nYou should be able to see that each movie has a shared structure that looks like this:\nä½ åº”è¯¥èƒ½å¤Ÿçœ‹åˆ°æ¯éƒ¨ç”µå½±éƒ½æœ‰ä¸€ä¸ªå…±äº«çš„ç»“æ„ï¼Œçœ‹èµ·æ¥åƒè¿™æ ·ï¼š\n&lt;section&gt;\n  &lt;h2 data-id=\"1\"&gt;The Phantom Menace&lt;/h2&gt;\n  &lt;p&gt;Released: 1999-05-19&lt;/p&gt;\n  &lt;p&gt;Director: &lt;span class=\"director\"&gt;George Lucas&lt;/span&gt;&lt;/p&gt;\n  \n  &lt;div class=\"crawl\"&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n  &lt;/div&gt;\n&lt;/section&gt;\nOur goal is to turn this data into a 7 row data frame with variables title, year, director, and intro. Weâ€™ll start by reading the HTML and extracting all the &lt;section&gt; elements:\næˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†è¿™äº›æ•°æ®è½¬æ¢æˆä¸€ä¸ªåŒ…å« titleã€yearã€director å’Œ intro å˜é‡çš„ 7 è¡Œæ•°æ®æ¡†ã€‚æˆ‘ä»¬å°†ä»è¯»å– HTML å¹¶æå–æ‰€æœ‰ &lt;section&gt; å…ƒç´ å¼€å§‹ï¼š\n\nurl &lt;- \"https://rvest.tidyverse.org/articles/starwars.html\"\nhtml &lt;- read_html(url)\n\nsection &lt;- html |&gt; html_elements(\"section\")\nsection\n#&gt; {xml_nodeset (7)}\n#&gt; [1] &lt;section&gt;&lt;h2 data-id=\"1\"&gt;\\nThe Phantom Menace\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [2] &lt;section&gt;&lt;h2 data-id=\"2\"&gt;\\nAttack of the Clones\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: ...\n#&gt; [3] &lt;section&gt;&lt;h2 data-id=\"3\"&gt;\\nRevenge of the Sith\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased:  ...\n#&gt; [4] &lt;section&gt;&lt;h2 data-id=\"4\"&gt;\\nA New Hope\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1977-05-2 ...\n#&gt; [5] &lt;section&gt;&lt;h2 data-id=\"5\"&gt;\\nThe Empire Strikes Back\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleas ...\n#&gt; [6] &lt;section&gt;&lt;h2 data-id=\"6\"&gt;\\nReturn of the Jedi\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [7] &lt;section&gt;&lt;h2 data-id=\"7\"&gt;\\nThe Force Awakens\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 20 ...\n\nThis retrieves seven elements matching the seven movies found on that page, suggesting that using section as a selector is good. Extracting the individual elements is straightforward since the data is always found in the text. Itâ€™s just a matter of finding the right selector:\nè¿™æ®µä»£ç æ£€ç´¢åˆ°ä¸ƒä¸ªå…ƒç´ ï¼Œä¸é¡µé¢ä¸Šæ‰¾åˆ°çš„ä¸ƒéƒ¨ç”µå½±ç›¸åŒ¹é…ï¼Œè¿™è¡¨æ˜ä½¿ç”¨ section ä½œä¸ºé€‰æ‹©å™¨æ˜¯å¾ˆå¥½çš„ã€‚æå–å•ä¸ªå…ƒç´ å¾ˆç®€å•ï¼Œå› ä¸ºæ•°æ®æ€»æ˜¯åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°ã€‚è¿™åªæ˜¯æ‰¾åˆ°æ­£ç¡®é€‰æ‹©å™¨çš„é—®é¢˜ï¼š\n\nsection |&gt; html_element(\"h2\") |&gt; html_text2()\n#&gt; [1] \"The Phantom Menace\"      \"Attack of the Clones\"   \n#&gt; [3] \"Revenge of the Sith\"     \"A New Hope\"             \n#&gt; [5] \"The Empire Strikes Back\" \"Return of the Jedi\"     \n#&gt; [7] \"The Force Awakens\"\n\nsection |&gt; html_element(\".director\") |&gt; html_text2()\n#&gt; [1] \"George Lucas\"     \"George Lucas\"     \"George Lucas\"    \n#&gt; [4] \"George Lucas\"     \"Irvin Kershner\"   \"Richard Marquand\"\n#&gt; [7] \"J. J. Abrams\"\n\nOnce weâ€™ve done that for each component, we can wrap all the results up into a tibble:\nä¸ºæ¯ä¸ªç»„ä»¶å®Œæˆæ­¤æ“ä½œåï¼Œæˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰ç»“æœåŒ…è£…åˆ°ä¸€ä¸ª tibble ä¸­ï¼š\n\ntibble(\n  title = section |&gt; \n    html_element(\"h2\") |&gt; \n    html_text2(),\n  released = section |&gt; \n    html_element(\"p\") |&gt; \n    html_text2() |&gt; \n    str_remove(\"Released: \") |&gt; \n    parse_date(),\n  director = section |&gt; \n    html_element(\".director\") |&gt; \n    html_text2(),\n  intro = section |&gt; \n    html_element(\".crawl\") |&gt; \n    html_text2()\n)\n#&gt; # A tibble: 7 Ã— 4\n#&gt;   title                   released   director         intro                  \n#&gt;   &lt;chr&gt;                   &lt;date&gt;     &lt;chr&gt;            &lt;chr&gt;                  \n#&gt; 1 The Phantom Menace      1999-05-19 George Lucas     \"Turmoil has engulfed â€¦\n#&gt; 2 Attack of the Clones    2002-05-16 George Lucas     \"There is unrest in thâ€¦\n#&gt; 3 Revenge of the Sith     2005-05-19 George Lucas     \"War! The Republic is â€¦\n#&gt; 4 A New Hope              1977-05-25 George Lucas     \"It is a period of civâ€¦\n#&gt; 5 The Empire Strikes Back 1980-05-17 Irvin Kershner   \"It is a dark time forâ€¦\n#&gt; 6 Return of the Jedi      1983-05-25 Richard Marquand \"Luke Skywalker has reâ€¦\n#&gt; # â„¹ 1 more row\n\nWe did a little more processing of released to get a variable that will be easy to use later in our analysis.\næˆ‘ä»¬å¯¹ released è¿›è¡Œäº†æ›´å¤šçš„å¤„ç†ï¼Œä»¥å¾—åˆ°ä¸€ä¸ªåœ¨åç»­åˆ†æä¸­æ›´æ˜“äºä½¿ç”¨çš„å˜é‡ã€‚\n\n24.6.2 IMDB top films\nFor our next task weâ€™ll tackle something a little trickier, extracting the top 250 movies from the internet movie database (IMDb). At the time we wrote this chapter, the page looked like FigureÂ 24.1.\nåœ¨æˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å°†å¤„ç†ä¸€ä¸ªç¨å¾®æ£˜æ‰‹çš„é—®é¢˜ï¼Œå³ä»äº’è”ç½‘ç”µå½±æ•°æ®åº“ (IMDb) ä¸­æå–æ’åå‰ 250 çš„ç”µå½±ã€‚åœ¨æˆ‘ä»¬æ’°å†™æœ¬ç« æ—¶ï¼Œè¯¥é¡µé¢çš„å¤–è§‚å¦‚ FigureÂ 24.1 æ‰€ç¤ºã€‚\n\n\n\n\n\n\n\nFigureÂ 24.1: Screenshot of the IMDb top movies web page taken on 2022-12-05.\n\n\n\n\nThis data has a clear tabular structure so itâ€™s worth starting with html_table():\nè¿™äº›æ•°æ®å…·æœ‰æ¸…æ™°çš„è¡¨æ ¼ç»“æ„ï¼Œå› æ­¤å€¼å¾—ä» html_table() å¼€å§‹ï¼š\n\nurl &lt;- \"https://web.archive.org/web/20220201012049/https://www.imdb.com/chart/top/\"\nhtml &lt;- read_html(url)\n\ntable &lt;- html |&gt; \n  html_element(\"table\") |&gt; \n  html_table()\ntable\n#&gt; # A tibble: 250 Ã— 5\n#&gt;   ``    `Rank & Title`                    `IMDb Rating` `Your Rating`   ``   \n#&gt;   &lt;lgl&gt; &lt;chr&gt;                                     &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt;\n#&gt; 1 NA    \"1.\\n      The Shawshank Redemptâ€¦           9.2 \"12345678910\\nâ€¦ NA   \n#&gt; 2 NA    \"2.\\n      The Godfather\\n      â€¦           9.1 \"12345678910\\nâ€¦ NA   \n#&gt; 3 NA    \"3.\\n      The Godfather: Part Iâ€¦           9   \"12345678910\\nâ€¦ NA   \n#&gt; 4 NA    \"4.\\n      The Dark Knight\\n    â€¦           9   \"12345678910\\nâ€¦ NA   \n#&gt; 5 NA    \"5.\\n      12 Angry Men\\n       â€¦           8.9 \"12345678910\\nâ€¦ NA   \n#&gt; 6 NA    \"6.\\n      Schindler's List\\n   â€¦           8.9 \"12345678910\\nâ€¦ NA   \n#&gt; # â„¹ 244 more rows\n\nThis includes a few empty columns, but overall does a good job of capturing the information from the table. However, we need to do some more processing to make it easier to use. First, weâ€™ll rename the columns to be easier to work with, and remove the extraneous whitespace in rank and title. We will do this with select() (instead of rename()) to do the renaming and selecting of just these two columns in one step. Then weâ€™ll remove the new lines and extra spaces, and then apply separate_wider_regex() (from Section 15.3.4) to pull out the title, year, and rank into their own variables.\nè¿™å…¶ä¸­åŒ…å«ä¸€äº›ç©ºåˆ—ï¼Œä½†æ€»ä½“ä¸Šå¾ˆå¥½åœ°æ•è·äº†è¡¨æ ¼ä¸­çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œæ›´å¤šçš„å¤„ç†ä»¥ä½¿å…¶æ›´æ˜“äºä½¿ç”¨ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†é‡å‘½ååˆ—åä»¥ä¾¿äºæ“ä½œï¼Œå¹¶ç§»é™¤æ’åå’Œæ ‡é¢˜ä¸­å¤šä½™çš„ç©ºç™½ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ select() (è€Œä¸æ˜¯ rename()) æ¥ä¸€æ­¥å®Œæˆé‡å‘½åå’Œä»…é€‰æ‹©è¿™ä¸¤åˆ—çš„æ“ä½œã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ç§»é™¤æ¢è¡Œç¬¦å’Œå¤šä½™çš„ç©ºæ ¼ï¼Œæ¥ç€åº”ç”¨ separate_wider_regex() (æ¥è‡ª Section 15.3.4) å°†æ ‡é¢˜ã€å¹´ä»½å’Œæ’åæå–åˆ°å„è‡ªçš„å˜é‡ä¸­ã€‚\n\nratings &lt;- table |&gt;\n  select(\n    rank_title_year = `Rank & Title`,\n    rating = `IMDb Rating`\n  ) |&gt; \n  mutate(\n    rank_title_year = str_replace_all(rank_title_year, \"\\n +\", \" \")\n  ) |&gt; \n  separate_wider_regex(\n    rank_title_year,\n    patterns = c(\n      rank = \"\\\\d+\", \"\\\\. \",\n      title = \".+\", \" +\\\\(\",\n      year = \"\\\\d+\", \"\\\\)\"\n    )\n  )\nratings\n#&gt; # A tibble: 250 Ã— 4\n#&gt;   rank  title                    year  rating\n#&gt;   &lt;chr&gt; &lt;chr&gt;                    &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 1     The Shawshank Redemption 1994     9.2\n#&gt; 2 2     The Godfather            1972     9.1\n#&gt; 3 3     The Godfather: Part II   1974     9  \n#&gt; 4 4     The Dark Knight          2008     9  \n#&gt; 5 5     12 Angry Men             1957     8.9\n#&gt; 6 6     Schindler's List         1993     8.9\n#&gt; # â„¹ 244 more rows\n\nEven in this case where most of the data comes from table cells, itâ€™s still worth looking at the raw HTML. If you do so, youâ€™ll discover that we can add a little extra data by using one of the attributes. This is one of the reasons itâ€™s worth spending a little time spelunking the source of the page; you might find extra data, or might find a parsing route thatâ€™s slightly easier.\nå³ä½¿åœ¨è¿™ç§å¤§éƒ¨åˆ†æ•°æ®æ¥è‡ªè¡¨æ ¼å•å…ƒæ ¼çš„æƒ…å†µä¸‹ï¼ŒæŸ¥çœ‹åŸå§‹ HTML ä»ç„¶æ˜¯å€¼å¾—çš„ã€‚å¦‚æœä½ è¿™æ ·åšï¼Œä½ ä¼šå‘ç°æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªå±æ€§æ¥æ·»åŠ ä¸€äº›é¢å¤–çš„æ•°æ®ã€‚è¿™å°±æ˜¯èŠ±ç‚¹æ—¶é—´ç ”ç©¶é¡µé¢æºä»£ç çš„åŸå› ä¹‹ä¸€ï¼›ä½ å¯èƒ½ä¼šå‘ç°é¢å¤–çš„æ•°æ®ï¼Œæˆ–è€…æ‰¾åˆ°ä¸€ä¸ªç¨å¾®å®¹æ˜“ä¸€äº›çš„è§£æè·¯å¾„ã€‚\n\nhtml |&gt; \n  html_elements(\"td strong\") |&gt; \n  head() |&gt; \n  html_attr(\"title\")\n#&gt; [1] \"9.2 based on 2,536,415 user ratings\"\n#&gt; [2] \"9.1 based on 1,745,675 user ratings\"\n#&gt; [3] \"9.0 based on 1,211,032 user ratings\"\n#&gt; [4] \"9.0 based on 2,486,931 user ratings\"\n#&gt; [5] \"8.9 based on 749,563 user ratings\"  \n#&gt; [6] \"8.9 based on 1,295,705 user ratings\"\n\nWe can combine this with the tabular data and again apply separate_wider_regex() to extract out the bit of data we care about:\næˆ‘ä»¬å¯ä»¥å°†å…¶ä¸è¡¨æ ¼æ•°æ®ç»“åˆèµ·æ¥ï¼Œå¹¶å†æ¬¡åº”ç”¨ separate_wider_regex() æ¥æå–æˆ‘ä»¬å…³å¿ƒçš„é‚£éƒ¨åˆ†æ•°æ®ï¼š\n\nratings |&gt;\n  mutate(\n    rating_n = html |&gt; html_elements(\"td strong\") |&gt; html_attr(\"title\")\n  ) |&gt; \n  separate_wider_regex(\n    rating_n,\n    patterns = c(\n      \"[0-9.]+ based on \",\n      number = \"[0-9,]+\",\n      \" user ratings\"\n    )\n  ) |&gt; \n  mutate(\n    number = parse_number(number)\n  )\n#&gt; # A tibble: 250 Ã— 5\n#&gt;   rank  title                    year  rating  number\n#&gt;   &lt;chr&gt; &lt;chr&gt;                    &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 1     The Shawshank Redemption 1994     9.2 2536415\n#&gt; 2 2     The Godfather            1972     9.1 1745675\n#&gt; 3 3     The Godfather: Part II   1974     9   1211032\n#&gt; 4 4     The Dark Knight          2008     9   2486931\n#&gt; 5 5     12 Angry Men             1957     8.9  749563\n#&gt; 6 6     Schindler's List         1993     8.9 1295705\n#&gt; # â„¹ 244 more rows",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#dynamic-sites",
    "href": "webscraping.html#dynamic-sites",
    "title": "24Â  Web scraping",
    "section": "\n24.7 Dynamic sites",
    "text": "24.7 Dynamic sites\nSo far we have focused on websites where html_elements() returns what you see in the browser and discussed how to parse what it returns and how to organize that information in tidy data frames. From time-to-time, however, youâ€™ll hit a site where html_elements() and friends donâ€™t return anything like what you see in the browser. In many cases, thatâ€™s because youâ€™re trying to scrape a website that dynamically generates the content of the page with javascript. This doesnâ€™t currently work with rvest, because rvest downloads the raw HTML and doesnâ€™t run any javascript.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´ä¸“æ³¨äºé‚£äº› html_elements() è¿”å›ä½ åœ¨æµè§ˆå™¨ä¸­çœ‹åˆ°çš„å†…å®¹çš„ç½‘ç«™ï¼Œå¹¶è®¨è®ºäº†å¦‚ä½•è§£æå…¶è¿”å›å†…å®¹ä»¥åŠå¦‚ä½•å°†è¿™äº›ä¿¡æ¯ç»„ç»‡æˆæ•´æ´çš„æ•°æ®æ¡†ã€‚ç„¶è€Œï¼Œä½ å¶å°”ä¼šé‡åˆ°ä¸€ä¸ªç½‘ç«™ï¼Œå…¶ä¸­ html_elements() åŠå…¶ç›¸å…³å‡½æ•°è¿”å›çš„å†…å®¹ä¸ä½ åœ¨æµè§ˆå™¨ä¸­çœ‹åˆ°çš„å®Œå…¨ä¸åŒã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œè¿™æ˜¯å› ä¸ºä½ è¯•å›¾çˆ¬å–ä¸€ä¸ªä½¿ç”¨ javascript åŠ¨æ€ç”Ÿæˆé¡µé¢å†…å®¹çš„ç½‘ç«™ã€‚è¿™ç›®å‰ä¸é€‚ç”¨äº rvestï¼Œå› ä¸º rvest ä¸‹è½½çš„æ˜¯åŸå§‹ HTMLï¼Œä¸è¿è¡Œä»»ä½• javascriptã€‚\nItâ€™s still possible to scrape these types of sites, but rvest needs to use a more expensive process: fully simulating the web browser including running all javascript. This functionality is not available at the time of writing, but itâ€™s something weâ€™re actively working on and might be available by the time you read this. It uses the chromote package which actually runs the Chrome browser in the background, and gives you additional tools to interact with the site, like a human typing text and clicking buttons. Check out the rvest website for more details.\nä»ç„¶å¯ä»¥çˆ¬å–è¿™ç±»ç½‘ç«™ï¼Œä½† rvest éœ€è¦ä½¿ç”¨ä¸€ä¸ªæ›´æ˜‚è´µçš„è¿‡ç¨‹ï¼šå®Œå…¨æ¨¡æ‹Ÿç½‘ç»œæµè§ˆå™¨ï¼ŒåŒ…æ‹¬è¿è¡Œæ‰€æœ‰ javascriptã€‚åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼Œæ­¤åŠŸèƒ½å°šä¸å¯ç”¨ï¼Œä½†è¿™æ˜¯æˆ‘ä»¬æ­£åœ¨ç§¯æå¼€å‘çš„åŠŸèƒ½ï¼Œå½“ä½ é˜…è¯»æœ¬æ–‡æ—¶å¯èƒ½å·²ç»å¯ç”¨ã€‚å®ƒä½¿ç”¨ chromote åŒ…ï¼Œè¯¥åŒ…å®é™…ä¸Šåœ¨åå°è¿è¡Œ Chrome æµè§ˆå™¨ï¼Œå¹¶ä¸ºä½ æä¾›ä¸ç½‘ç«™äº¤äº’çš„é¢å¤–å·¥å…·ï¼Œå°±åƒäººç±»è¾“å…¥æ–‡æœ¬å’Œç‚¹å‡»æŒ‰é’®ä¸€æ ·ã€‚è¯·æŸ¥çœ‹ rvest ç½‘ç«™ ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#summary",
    "href": "webscraping.html#summary",
    "title": "24Â  Web scraping",
    "section": "\n24.8 Summary",
    "text": "24.8 Summary\nIn this chapter, youâ€™ve learned about the why, the why not, and the how of scraping data from web pages. First, youâ€™ve learned about the basics of HTML and using CSS selectors to refer to specific elements, then youâ€™ve learned about using the rvest package to get data out of HTML into R. We then demonstrated web scraping with two case studies: a simpler scenario on scraping data on StarWars films from the rvest package website and a more complex scenario on scraping the top 250 films from IMDB.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†ä»ç½‘é¡µä¸Šçˆ¬å–æ•°æ®çš„åŸå› ã€ä¸åº”çˆ¬å–çš„æƒ…å†µä»¥åŠå¦‚ä½•çˆ¬å–ã€‚é¦–å…ˆï¼Œä½ å­¦ä¹ äº† HTML çš„åŸºç¡€çŸ¥è¯†å’Œä½¿ç”¨ CSS é€‰æ‹©å™¨æ¥å¼•ç”¨ç‰¹å®šå…ƒç´ ï¼Œç„¶åä½ å­¦ä¹ äº†ä½¿ç”¨ rvest åŒ…å°†æ•°æ®ä» HTML ä¸­æå–åˆ° R ä¸­ã€‚æ¥ç€ï¼Œæˆ‘ä»¬é€šè¿‡ä¸¤ä¸ªæ¡ˆä¾‹ç ”ç©¶æ¼”ç¤ºäº†ç½‘ç»œçˆ¬å–ï¼šä¸€ä¸ªæ˜¯åœ¨ rvest åŒ…ç½‘ç«™ä¸Šçˆ¬å–æ˜Ÿçƒå¤§æˆ˜ç”µå½±æ•°æ®çš„è¾ƒç®€å•åœºæ™¯ï¼Œå¦ä¸€ä¸ªæ˜¯åœ¨ IMDB ä¸Šçˆ¬å–æ’åå‰ 250 éƒ¨ç”µå½±çš„è¾ƒå¤æ‚åœºæ™¯ã€‚\nTechnical details of scraping data off the web can be complex, particularly when dealing with sites, however legal and ethical considerations can be even more complex. Itâ€™s important for you to educate yourself about both of these before setting out to scrape data.\nä»ç½‘ç»œä¸Šçˆ¬å–æ•°æ®çš„æŠ€æœ¯ç»†èŠ‚å¯èƒ½å¾ˆå¤æ‚ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ç½‘ç«™æ—¶ï¼Œç„¶è€Œæ³•å¾‹å’Œé“å¾·æ–¹é¢çš„è€ƒè™‘å¯èƒ½æ›´ä¸ºå¤æ‚ã€‚åœ¨å¼€å§‹çˆ¬å–æ•°æ®ä¹‹å‰ï¼Œå¯¹è¿™ä¸¤æ–¹é¢è¿›è¡Œè‡ªæˆ‘æ•™è‚²æ˜¯éå¸¸é‡è¦çš„ã€‚\nThis brings us to the end of the import part of the book where youâ€™ve learned techniques to get data from where it lives (spreadsheets, databases, JSON files, and web sites) into a tidy form in R. Now itâ€™s time to turn our sights to a new topic: making the most of R as a programming language.\nè¿™å°±ç»“æŸäº†æœ¬ä¹¦çš„å¯¼å…¥éƒ¨åˆ†ï¼Œä½ å·²ç»å­¦ä¹ äº†ä»æ•°æ®æ‰€åœ¨ä¹‹å¤„ï¼ˆç”µå­è¡¨æ ¼ã€æ•°æ®åº“ã€JSON æ–‡ä»¶å’Œç½‘ç«™ï¼‰è·å–æ•°æ®å¹¶å°†å…¶æ•´ç†æˆ R ä¸­æ•´æ´å½¢å¼çš„æŠ€æœ¯ã€‚ç°åœ¨æ˜¯æ—¶å€™å°†æˆ‘ä»¬çš„ç›®å…‰è½¬å‘ä¸€ä¸ªæ–°ä¸»é¢˜ï¼šå……åˆ†åˆ©ç”¨ R ä½œä¸ºä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "webscraping.html#footnotes",
    "href": "webscraping.html#footnotes",
    "title": "24Â  Web scraping",
    "section": "",
    "text": "And many popular APIs already have CRAN packages that wrap them, so start with a little research first!â†©ï¸\nObviously weâ€™re not lawyers, and this is not legal advice. Â  Â  But this is the best summary we can give having read a bunch about this topic.â†©ï¸\nOne example of an article on the OkCupid study was published by Wired, https://www.wired.com/2016/05/okcupid-study-reveals-perils-big-data-science.â†©ï¸\nA number of tags (including &lt;p&gt; and &lt;li&gt;) donâ€™t require end tags, but we think itâ€™s best to include them because it makes seeing the structure of the HTML a little easier.â†©ï¸\nThis class comes from the xml2 package. Â  Â  xml2 is a low-level package that rvest builds on top of.â†©ï¸\nrvest also provides html_text() but you should almost always use html_text2() since it does a better job of converting nested HTML to text.â†©ï¸",
    "crumbs": [
      "Import",
      "<span class='chapter-number'>24</span>Â  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "Program",
    "section": "",
    "text": "In this part of the book, youâ€™ll improve your programming skills. Programming is a cross-cutting skill needed for all data science work: you must use a computer to do data science; you cannot do it in your head, or with pencil and paper.\nåœ¨æœ¬ä¹¦çš„è¿™ä¸€éƒ¨åˆ†ï¼Œä½ å°†æå‡ä½ çš„ç¼–ç¨‹æŠ€èƒ½ã€‚ç¼–ç¨‹æ˜¯æ‰€æœ‰æ•°æ®ç§‘å­¦å·¥ä½œæ‰€éœ€çš„ä¸€é¡¹è´¯ç©¿æ€§æŠ€èƒ½ï¼šä½ å¿…é¡»ä½¿ç”¨è®¡ç®—æœºæ¥åšæ•°æ®ç§‘å­¦ï¼›ä½ æ— æ³•åœ¨å¤´è„‘ä¸­ï¼Œæˆ–ç”¨çº¸ç¬”å®Œæˆå®ƒã€‚\n\n\n\n\n\n\n\nFigureÂ 1: Programming is the water in which all the other components swim.\n\n\n\n\nProgramming produces code, and code is a tool of communication. Obviously code tells the computer what you want it to do. But it also communicates meaning to other humans. Thinking about code as a vehicle for communication is important because every project you do is fundamentally collaborative. Even if youâ€™re not working with other people, youâ€™ll definitely be working with future-you! Writing clear code is important so that others (like future-you) can understand why you tackled an analysis in the way you did. That means getting better at programming also involves getting better at communicating. Over time, you want your code to become not just easier to write, but easier for others to read.\nç¼–ç¨‹äº§ç”Ÿä»£ç ï¼Œè€Œä»£ç æ˜¯ä¸€ç§æ²Ÿé€šå·¥å…·ã€‚æ˜¾ç„¶ï¼Œä»£ç å‘Šè¯‰è®¡ç®—æœºä½ å¸Œæœ›å®ƒåšä»€ä¹ˆã€‚ä½†å®ƒä¹Ÿå‘å…¶ä»–äººç±»ä¼ è¾¾æ„ä¹‰ã€‚å°†ä»£ç è§†ä¸ºä¸€ç§æ²Ÿé€šåª’ä»‹éå¸¸é‡è¦ï¼Œå› ä¸ºä½ åšçš„æ¯ä¸ªé¡¹ç›®æœ¬è´¨ä¸Šéƒ½æ˜¯åä½œæ€§çš„ã€‚å³ä½¿ä½ æ²¡æœ‰å’Œåˆ«äººä¸€èµ·å·¥ä½œï¼Œä½ ä¹Ÿè‚¯å®šä¼šå’Œæœªæ¥çš„ä½ ä¸€èµ·å·¥ä½œï¼ç¼–å†™æ¸…æ™°çš„ä»£ç å¾ˆé‡è¦ï¼Œè¿™æ ·å…¶ä»–äººï¼ˆæ¯”å¦‚æœªæ¥çš„ä½ ï¼‰æ‰èƒ½ç†è§£ä½ ä¸ºä»€ä¹ˆç”¨é‚£ç§æ–¹å¼å¤„ç†åˆ†æã€‚è¿™æ„å‘³ç€ï¼Œæé«˜ç¼–ç¨‹èƒ½åŠ›ä¹ŸåŒ…æ‹¬æé«˜æ²Ÿé€šèƒ½åŠ›ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œä½ å¸Œæœ›ä½ çš„ä»£ç ä¸ä»…æ›´å®¹æ˜“ç¼–å†™ï¼Œä¹Ÿæ›´å®¹æ˜“ä¸ºä»–äººé˜…è¯»ã€‚\nIn the following three chapters, youâ€™ll learn skills to improve your programming skills:\nåœ¨æ¥ä¸‹æ¥çš„ä¸‰ç« ä¸­ï¼Œä½ å°†å­¦åˆ°æå‡ç¼–ç¨‹æŠ€èƒ½çš„æŠ€å·§ï¼š\n\nCopy-and-paste is a powerful tool, but you should avoid doing it more than twice. Repeating yourself in code is dangerous because it can easily lead to errors and inconsistencies. Instead, in 25Â  Functions, youâ€™ll learn how to write functions which let you extract out repeated tidyverse code so that it can be easily reused.\nå¤åˆ¶ç²˜è´´æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œä½†ä½ åº”è¯¥é¿å…é‡å¤ä½¿ç”¨å®ƒè¶…è¿‡ä¸¤æ¬¡ã€‚åœ¨ä»£ç ä¸­é‡å¤è‡ªå·±æ˜¯å±é™©çš„ï¼Œå› ä¸ºå®ƒå¾ˆå®¹æ˜“å¯¼è‡´é”™è¯¯å’Œä¸ä¸€è‡´ã€‚å› æ­¤ï¼Œåœ¨ 25Â  Functions ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ç¼–å†™å‡½æ•° (functions)ï¼Œè¿™èƒ½è®©ä½ æå–å‡ºé‡å¤çš„ tidyverse ä»£ç ï¼Œä»¥ä¾¿äºè½»æ¾é‡ç”¨ã€‚\nFunctions extract out repeated code, but you often need to repeat the same actions on different inputs. You need tools for iteration that let you do similar things again and again. These tools include for loops and functional programming, which youâ€™ll learn about in 26Â  Iteration.\nå‡½æ•°æå–äº†é‡å¤çš„ä»£ç ï¼Œä½†ä½ ç»å¸¸éœ€è¦å¯¹ä¸åŒçš„è¾“å…¥é‡å¤ç›¸åŒçš„æ“ä½œã€‚ä½ éœ€è¦è¿­ä»£ (iteration) å·¥å…·ï¼Œè®©ä½ èƒ½ä¸€éåˆä¸€éåœ°åšç±»ä¼¼çš„äº‹æƒ…ã€‚è¿™äº›å·¥å…·åŒ…æ‹¬ for å¾ªç¯å’Œå‡½æ•°å¼ç¼–ç¨‹ï¼Œä½ å°†åœ¨ 26Â  Iteration ä¸­å­¦ä¹ å®ƒä»¬ã€‚\nAs you read more code written by others, youâ€™ll see more code that doesnâ€™t use the tidyverse. In 27Â  A field guide to base R, youâ€™ll learn some of the most important base R functions that youâ€™ll see in the wild.\nå½“ä½ é˜…è¯»æ›´å¤šä»–äººç¼–å†™çš„ä»£ç æ—¶ï¼Œä½ ä¼šçœ‹åˆ°æ›´å¤šä¸ä½¿ç”¨ tidyverse çš„ä»£ç ã€‚åœ¨ 27Â  A field guide to base R ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸€äº›ä½ åœ¨å®é™…ä¸­ä¼šçœ‹åˆ°çš„æœ€é‡è¦çš„åŸºç¡€ R å‡½æ•°ã€‚\n\nThe goal of these chapters is to teach you the minimum about programming that you need for data science. Once you have mastered the material here, we strongly recommend that you continue to invest in your programming skills. Weâ€™ve written two books that you might find helpful. Hands on Programming with R, by Garrett Grolemund, is an introduction to R as a programming language and is a great place to start if R is your first programming language. Advanced R by Hadley Wickham dives into the details of R the programming language; itâ€™s a great place to start if you have existing programming experience and a great next step once youâ€™ve internalized the ideas in these chapters.\nè¿™äº›ç« èŠ‚çš„ç›®æ ‡æ˜¯æ•™ä¼šä½ æ•°æ®ç§‘å­¦æ‰€éœ€çš„æœ€ä½é™åº¦çš„ç¼–ç¨‹çŸ¥è¯†ã€‚ä¸€æ—¦ä½ æŒæ¡äº†è¿™é‡Œçš„å†…å®¹ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ ç»§ç»­æŠ•èµ„äºä½ çš„ç¼–ç¨‹æŠ€èƒ½ã€‚æˆ‘ä»¬å†™äº†ä¸¤æœ¬ä¹¦ï¼Œä½ å¯èƒ½ä¼šè§‰å¾—æœ‰å¸®åŠ©ã€‚Garrett Grolemund çš„ Hands on Programming with R æ˜¯ R ä½œä¸ºä¸€ç§ç¼–ç¨‹è¯­è¨€çš„å…¥é—¨ä»‹ç»ï¼Œå¦‚æœ R æ˜¯ä½ çš„ç¬¬ä¸€é—¨ç¼–ç¨‹è¯­è¨€ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚Hadley Wickham çš„ Advanced R æ·±å…¥æ¢è®¨äº† R ç¼–ç¨‹è¯­è¨€çš„ç»†èŠ‚ï¼›å¦‚æœä½ æœ‰ç°æˆçš„ç¼–ç¨‹ç»éªŒï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œä¹Ÿæ˜¯ä½ åœ¨å†…åŒ–äº†è¿™äº›ç« èŠ‚çš„æ€æƒ³åçš„ä¸€ä¸ªå¾ˆå¥½çš„ä¸‹ä¸€æ­¥ã€‚",
    "crumbs": [
      "Program"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "25Â  Functions",
    "section": "",
    "text": "25.1 Introduction\nOne of the best ways to improve your reach as a data scientist is to write functions. Functions allow you to automate common tasks in a more powerful and general way than copy-and-pasting. Writing a function has four big advantages over using copy-and-paste:\nä½œä¸ºä¸€åæ•°æ®ç§‘å­¦å®¶ï¼Œç¼–å†™å‡½æ•°æ˜¯æå‡èƒ½åŠ›æœ€å¥½çš„æ–¹æ³•ä¹‹ä¸€ã€‚å‡½æ•°å…è®¸ä½ ä»¥æ¯”å¤åˆ¶ç²˜è´´æ›´å¼ºå¤§ã€æ›´é€šç”¨çš„æ–¹å¼æ¥è‡ªåŠ¨åŒ–å¸¸è§ä»»åŠ¡ã€‚ä¸å¤åˆ¶ç²˜è´´ç›¸æ¯”ï¼Œç¼–å†™å‡½æ•°æœ‰å››å¤§ä¼˜åŠ¿ï¼š\nA good rule of thumb is to consider writing a function whenever youâ€™ve copied and pasted a block of code more than twice (i.e.Â you now have three copies of the same code). In this chapter, youâ€™ll learn about three useful types of functions:\nä¸€ä¸ªå¥½çš„ç»éªŒæ³•åˆ™æ˜¯ï¼Œå½“ä½ å¤åˆ¶ç²˜è´´ä¸€æ®µä»£ç è¶…è¿‡ä¸¤æ¬¡ï¼ˆå³ä½ ç°åœ¨æœ‰ä¸‰ä»½ç›¸åŒçš„ä»£ç ï¼‰æ—¶ï¼Œå°±åº”è¯¥è€ƒè™‘ç¼–å†™ä¸€ä¸ªå‡½æ•°ã€‚åœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸‰ç§æœ‰ç”¨çš„å‡½æ•°ç±»å‹ï¼š Vector functions take one or more vectors as input and return a vector as output.\nå‘é‡å‡½æ•° (Vector functions) å°†ä¸€ä¸ªæˆ–å¤šä¸ªå‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªå‘é‡ä½œä¸ºè¾“å‡ºã€‚\nEach of these sections includes many examples to help you generalize the patterns that you see. These examples wouldnâ€™t be possible without the help of folks of twitter, and we encourage you to follow the links in the comments to see the original inspirations. You might also want to read the original motivating tweets for general functions and plotting functions to see even more functions.\nè¿™äº›éƒ¨åˆ†ä¸­çš„æ¯ä¸€ä¸ªéƒ½åŒ…å«è®¸å¤šç¤ºä¾‹ï¼Œä»¥å¸®åŠ©ä½ å½’çº³æ‰€çœ‹åˆ°çš„æ¨¡å¼ã€‚æ²¡æœ‰ Twitter ä¸Šæœ‹å‹ä»¬çš„å¸®åŠ©ï¼Œè¿™äº›ç¤ºä¾‹æ˜¯ä¸å¯èƒ½å®Œæˆçš„ï¼Œæˆ‘ä»¬é¼“åŠ±ä½ ç‚¹å‡»è¯„è®ºä¸­çš„é“¾æ¥ï¼ŒæŸ¥çœ‹æœ€åˆçš„çµæ„Ÿæ¥æºã€‚ä½ å¯èƒ½è¿˜æƒ³é˜…è¯»å…³äº é€šç”¨å‡½æ•° å’Œ ç»˜å›¾å‡½æ•° çš„åŸå§‹æ¨æ–‡ï¼Œä»¥çœ‹åˆ°æ›´å¤šå‡½æ•°ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>25</span>Â  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#introduction",
    "href": "functions.html#introduction",
    "title": "25Â  Functions",
    "section": "",
    "text": "You can give a function an evocative name that makes your code easier to understand.\nä½ å¯ä»¥ç»™å‡½æ•°èµ·ä¸€ä¸ªèƒ½å”¤èµ·è®°å¿†çš„åç§°ï¼Œä½¿ä½ çš„ä»£ç æ›´å®¹æ˜“ç†è§£ã€‚\nAs requirements change, you only need to update code in one place, instead of many.\nå½“éœ€æ±‚å˜æ›´æ—¶ï¼Œä½ åªéœ€è¦åœ¨ä¸€ä¸ªåœ°æ–¹æ›´æ–°ä»£ç ï¼Œè€Œä¸æ˜¯å¤šä¸ªåœ°æ–¹ã€‚\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e.Â updating a variable name in one place, but not in another).\nä½ æ¶ˆé™¤äº†åœ¨å¤åˆ¶ç²˜è´´æ—¶çŠ¯ä¸‹å¶ç„¶é”™è¯¯çš„æœºä¼šï¼ˆä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªåœ°æ–¹æ›´æ–°äº†å˜é‡åï¼Œä½†åœ¨å¦ä¸€ä¸ªåœ°æ–¹æ²¡æœ‰æ›´æ–°ï¼‰ã€‚\nIt makes it easier to reuse work from project-to-project, increasing your productivity over time.\nè¿™ä½¿å¾—åœ¨é¡¹ç›®ä¹‹é—´é‡ç”¨å·¥ä½œå˜å¾—æ›´åŠ å®¹æ˜“ï¼Œä»è€Œéšç€æ—¶é—´çš„æ¨ç§»æé«˜ä½ çš„ç”Ÿäº§åŠ›ã€‚\n\n\n\nData frame functions take a data frame as input and return a data frame as output.\næ•°æ®æ¡†å‡½æ•° (Data frame functions) å°†ä¸€ä¸ªæ•°æ®æ¡†ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ•°æ®æ¡†ä½œä¸ºè¾“å‡ºã€‚\nPlot functions that take a data frame as input and return a plot as output.\nç»˜å›¾å‡½æ•° (Plot functions) å°†ä¸€ä¸ªæ•°æ®æ¡†ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªå›¾è¡¨ä½œä¸ºè¾“å‡ºã€‚\n\n\n\n25.1.1 Prerequisites\nWeâ€™ll wrap up a variety of functions from around the tidyverse. Weâ€™ll also use nycflights13 as a source of familiar data to use our functions with.\næˆ‘ä»¬å°†æ•´åˆ tidyverse ä¸­çš„å„ç§å‡½æ•°ã€‚æˆ‘ä»¬è¿˜å°†ä½¿ç”¨ nycflights13 ä½œä¸ºæˆ‘ä»¬ç†Ÿæ‚‰çš„ï¼Œç”¨äºå‡½æ•°å¤„ç†çš„æ•°æ®æºã€‚\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>25</span>Â  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#vector-functions",
    "href": "functions.html#vector-functions",
    "title": "25Â  Functions",
    "section": "\n25.2 Vector functions",
    "text": "25.2 Vector functions\nWeâ€™ll begin with vector functions: functions that take one or more vectors and return a vector result. For example, take a look at this code. What does it do?\næˆ‘ä»¬å°†ä»å‘é‡å‡½æ•°å¼€å§‹ï¼šå³æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªå‘é‡å¹¶è¿”å›ä¸€ä¸ªå‘é‡ç»“æœçš„å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œçœ‹çœ‹è¿™æ®µä»£ç ã€‚å®ƒæ˜¯åšä»€ä¹ˆçš„ï¼Ÿ\n\ndf &lt;- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |&gt; mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(a, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(b, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n#&gt; # A tibble: 5 Ã— 4\n#&gt;       a       b     c     d\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339  0.387  0.291 0    \n#&gt; 2 0.880 -0.613  0.611 0.557\n#&gt; 3 0     -0.0833 1     0.752\n#&gt; 4 0.795 -0.0822 0     1    \n#&gt; 5 1     -0.0952 0.580 0.394\n\nYou might be able to puzzle out that this rescales each column to have a range from 0 to 1. But did you spot the mistake? When Hadley wrote this code he made an error when copying-and-pasting and forgot to change an a to a b. Preventing this type of mistake is one very good reason to learn how to write functions.\nä½ æˆ–è®¸èƒ½çŒœåˆ°è¿™æ˜¯å°†æ¯ä¸€åˆ—é‡æ–°ç¼©æ”¾åˆ° 0 åˆ° 1 çš„èŒƒå›´ã€‚ä½†ä½ å‘ç°é”™è¯¯äº†å—ï¼ŸHadley åœ¨ç¼–å†™è¿™æ®µä»£ç æ—¶ï¼Œåœ¨å¤åˆ¶ç²˜è´´æ—¶çŠ¯äº†ä¸€ä¸ªé”™è¯¯ï¼Œå¿˜è®°å°†ä¸€ä¸ª a æ”¹æˆ bã€‚é¿å…è¿™ç±»é”™è¯¯æ˜¯å­¦ä¹ ç¼–å†™å‡½æ•°çš„ä¸€ä¸ªå¾ˆå¥½çš„ç†ç”±ã€‚\n\n25.2.1 Writing a function\nTo write a function you need to first analyse your repeated code to figure what parts are constant and what parts vary. If we take the code above and pull it outside of mutate(), itâ€™s a little easier to see the pattern because each repetition is now one line:\nè¦ç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œä½ é¦–å…ˆéœ€è¦åˆ†æä½ é‡å¤çš„ä»£ç ï¼Œæ‰¾å‡ºå“ªäº›éƒ¨åˆ†æ˜¯å¸¸é‡ï¼Œå“ªäº›éƒ¨åˆ†æ˜¯å˜é‡ã€‚å¦‚æœæˆ‘ä»¬æŠŠä¸Šé¢çš„ä»£ç ä» mutate() ä¸­æŠ½ç¦»å‡ºæ¥ï¼Œæ¨¡å¼ä¼šæ›´å®¹æ˜“çœ‹æ¸…ï¼Œå› ä¸ºç°åœ¨æ¯æ¬¡é‡å¤éƒ½åªæœ‰ä¸€è¡Œï¼š\n\n(a - min(a, na.rm = TRUE)) / (max(a, na.rm = TRUE) - min(a, na.rm = TRUE))\n(b - min(b, na.rm = TRUE)) / (max(b, na.rm = TRUE) - min(b, na.rm = TRUE))\n(c - min(c, na.rm = TRUE)) / (max(c, na.rm = TRUE) - min(c, na.rm = TRUE))\n(d - min(d, na.rm = TRUE)) / (max(d, na.rm = TRUE) - min(d, na.rm = TRUE))  \n\nTo make this a bit clearer we can replace the bit that varies with â–ˆ:\nä¸ºäº†æ›´æ¸…æ™°åœ°è¯´æ˜ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ â–ˆ æ›¿æ¢å˜åŒ–çš„éƒ¨åˆ†ï¼š\n\n(â–ˆ - min(â–ˆ, na.rm = TRUE)) / (max(â–ˆ, na.rm = TRUE) - min(â–ˆ, na.rm = TRUE))\n\nTo turn this into a function you need three things:\nè¦æŠŠè¿™ä¸ªå˜æˆä¸€ä¸ªå‡½æ•°ï¼Œä½ éœ€è¦ä¸‰æ ·ä¸œè¥¿ï¼š\n\nA name. Here weâ€™ll use rescale01 because this function rescales a vector to lie between 0 and 1.\nä¸€ä¸ªåç§°ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ rescale01ï¼Œå› ä¸ºè¿™ä¸ªå‡½æ•°å°†ä¸€ä¸ªå‘é‡é‡æ–°ç¼©æ”¾åˆ° 0 å’Œ 1 ä¹‹é—´ã€‚\nThe arguments. The arguments are things that vary across calls and our analysis above tells us that we have just one. Weâ€™ll call it x because this is the conventional name for a numeric vector.å‚æ•°ã€‚å‚æ•°æ˜¯æ¯æ¬¡è°ƒç”¨ä¸­å˜åŒ–çš„ä¸œè¥¿ï¼Œæˆ‘ä»¬ä¸Šé¢çš„åˆ†æå‘Šè¯‰æˆ‘ä»¬åªæœ‰ä¸€ä¸ªã€‚æˆ‘ä»¬ç§°å®ƒä¸º xï¼Œå› ä¸ºè¿™æ˜¯æ•°å€¼å‘é‡çš„å¸¸è§„åç§°ã€‚\nThe body. The body is the code thatâ€™s repeated across all the calls.å‡½æ•°ä½“ã€‚å‡½æ•°ä½“æ˜¯æ‰€æœ‰è°ƒç”¨ä¸­é‡å¤çš„ä»£ç ã€‚\n\nThen you create a function by following the template:\nç„¶åä½ æŒ‰ç…§ä»¥ä¸‹æ¨¡æ¿åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼š\n\nname &lt;- function(arguments) {\n  body\n}\n\nFor this case that leads to:\nå¯¹äºè¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š\n\nrescale01 &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nAt this point you might test with a few simple inputs to make sure youâ€™ve captured the logic correctly:\næ­¤æ—¶ï¼Œä½ å¯èƒ½ä¼šç”¨ä¸€äº›ç®€å•çš„è¾“å…¥æ¥æµ‹è¯•ï¼Œä»¥ç¡®ä¿ä½ å·²ç»æ­£ç¡®åœ°æ•è·äº†é€»è¾‘ï¼š\n\nrescale01(c(-10, 0, 10))\n#&gt; [1] 0.0 0.5 1.0\nrescale01(c(1, 2, 3, NA, 5))\n#&gt; [1] 0.00 0.25 0.50   NA 1.00\n\nThen you can rewrite the call to mutate() as:\nç„¶åä½ å¯ä»¥å°†å¯¹ mutate() çš„è°ƒç”¨é‡å†™ä¸ºï¼š\n\ndf |&gt; mutate(\n  a = rescale01(a),\n  b = rescale01(b),\n  c = rescale01(c),\n  d = rescale01(d),\n)\n#&gt; # A tibble: 5 Ã— 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339 1     0.291 0    \n#&gt; 2 0.880 0     0.611 0.557\n#&gt; 3 0     0.530 1     0.752\n#&gt; 4 0.795 0.531 0     1    \n#&gt; 5 1     0.518 0.580 0.394\n\n(In Chapter 26, youâ€™ll learn how to use across() to reduce the duplication even further so all you need is df |&gt; mutate(across(a:d, rescale01))).\nï¼ˆåœ¨ Chapter 26 ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ across() æ¥è¿›ä¸€æ­¥å‡å°‘é‡å¤ï¼Œè¿™æ ·ä½ åªéœ€è¦ df |&gt; mutate(across(a:d, rescale01))ï¼‰ã€‚\n\n25.2.2 Improving our function\nYou might notice that the rescale01() function does some unnecessary work â€” instead of computing min() twice and max() once we could instead compute both the minimum and maximum in one step with range():\nä½ å¯èƒ½ä¼šæ³¨æ„åˆ° rescale01() å‡½æ•°åšäº†ä¸€äº›ä¸å¿…è¦çš„å·¥ä½œâ€”â€”ä¸å…¶è®¡ç®—ä¸¤æ¬¡ min() å’Œä¸€æ¬¡ max()ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ range() ä¸€æ­¥è®¡ç®—å‡ºæœ€å°å€¼å’Œæœ€å¤§å€¼ï¼š\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nOr you might try this function on a vector that includes an infinite value:\næˆ–è€…ä½ å¯ä»¥åœ¨åŒ…å«æ— ç©·å¤§å€¼çš„å‘é‡ä¸Šå°è¯•è¿™ä¸ªå‡½æ•°ï¼š\n\nx &lt;- c(1:10, Inf)\nrescale01(x)\n#&gt;  [1]   0   0   0   0   0   0   0   0   0   0 NaN\n\nThat result is not particularly useful so we could ask range() to ignore infinite values:\nè¿™ä¸ªç»“æœä¸æ˜¯ç‰¹åˆ«æœ‰ç”¨ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®© range() å¿½ç•¥æ— ç©·å¤§å€¼ï¼š\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE, finite = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nrescale01(x)\n#&gt;  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n#&gt;  [8] 0.7777778 0.8888889 1.0000000       Inf\n\nThese changes illustrate an important benefit of functions: because weâ€™ve moved the repeated code into a function, we only need to make the change in one place.\nè¿™äº›æ”¹å˜è¯´æ˜äº†å‡½æ•°çš„ä¸€ä¸ªé‡è¦å¥½å¤„ï¼šå› ä¸ºæˆ‘ä»¬å·²ç»å°†é‡å¤çš„ä»£ç ç§»å…¥äº†ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨ä¸€ä¸ªåœ°æ–¹è¿›è¡Œä¿®æ”¹ã€‚\n\n25.2.3 Mutate functions\nNow that youâ€™ve got the basic idea of functions, letâ€™s take a look at a whole bunch of examples. Weâ€™ll start by looking at â€œmutateâ€ functions, i.e.Â functions that work well inside of mutate() and filter() because they return an output of the same length as the input.\næ—¢ç„¶ä½ å·²ç»æŒæ¡äº†å‡½æ•°çš„åŸºæœ¬æ¦‚å¿µï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€å¤§å †ä¾‹å­ã€‚æˆ‘ä»¬å°†ä»â€œmutateâ€å‡½æ•°å¼€å§‹ï¼Œå³é‚£äº›åœ¨ mutate() å’Œ filter() ä¸­å·¥ä½œå¾—å¾ˆå¥½çš„å‡½æ•°ï¼Œå› ä¸ºå®ƒä»¬è¿”å›çš„è¾“å‡ºä¸è¾“å…¥é•¿åº¦ç›¸åŒã€‚\nLetâ€™s start with a simple variation of rescale01(). Maybe you want to compute the Z-score, rescaling a vector to have a mean of zero and a standard deviation of one:\nè®©æˆ‘ä»¬ä» rescale01() çš„ä¸€ä¸ªç®€å•å˜ä½“å¼€å§‹ã€‚ä¹Ÿè®¸ä½ æƒ³è¦è®¡ç®— Z-scoreï¼Œå°†ä¸€ä¸ªå‘é‡é‡æ–°ç¼©æ”¾ï¼Œä½¿å…¶å‡å€¼ä¸ºé›¶ï¼Œæ ‡å‡†å·®ä¸ºä¸€ï¼š\n\nz_score &lt;- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\nOr maybe you want to wrap up a straightforward case_when() and give it a useful name. For example, this clamp() function ensures all values of a vector lie in between a minimum or a maximum:\næˆ–è€…ï¼Œä½ å¯èƒ½æƒ³åŒ…è£…ä¸€ä¸ªç®€å•çš„ case_when() å¹¶ç»™å®ƒä¸€ä¸ªæœ‰ç”¨çš„åå­—ã€‚ä¾‹å¦‚ï¼Œè¿™ä¸ª clamp() å‡½æ•°ç¡®ä¿å‘é‡çš„æ‰€æœ‰å€¼éƒ½ä»‹äºæœ€å°å€¼å’Œæœ€å¤§å€¼ä¹‹é—´ï¼š\n\nclamp &lt;- function(x, min, max) {\n  case_when(\n    x &lt; min ~ min,\n    x &gt; max ~ max,\n    .default = x\n  )\n}\n\nclamp(1:10, min = 3, max = 7)\n#&gt;  [1] 3 3 3 4 5 6 7 7 7 7\n\nOf course functions donâ€™t just need to work with numeric variables. You might want to do some repeated string manipulation. Maybe you need to make the first character upper case:\nå½“ç„¶ï¼Œå‡½æ•°ä¸åªé€‚ç”¨äºæ•°å€¼å˜é‡ã€‚ä½ å¯èƒ½æƒ³åšä¸€äº›é‡å¤çš„å­—ç¬¦ä¸²æ“ä½œã€‚ä¹Ÿè®¸ä½ éœ€è¦å°†ç¬¬ä¸€ä¸ªå­—ç¬¦å¤§å†™ï¼š\n\nfirst_upper &lt;- function(x) {\n  str_sub(x, 1, 1) &lt;- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nfirst_upper(\"hello\")\n#&gt; [1] \"Hello\"\n\nOr maybe you want to strip percent signs, commas, and dollar signs from a string before converting it into a number:\næˆ–è€…ï¼Œä½ å¯èƒ½æƒ³åœ¨å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å­—ä¹‹å‰ï¼Œå»é™¤å…¶ä¸­çš„ç™¾åˆ†å·ã€é€—å·å’Œç¾å…ƒç¬¦å·ï¼š\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nclean_number &lt;- function(x) {\n  is_pct &lt;- str_detect(x, \"%\")\n  num &lt;- x |&gt; \n    str_remove_all(\"%\") |&gt; \n    str_remove_all(\",\") |&gt; \n    str_remove_all(fixed(\"$\")) |&gt; \n    as.numeric()\n  if_else(is_pct, num / 100, num)\n}\n\nclean_number(\"$12,300\")\n#&gt; [1] 12300\nclean_number(\"45%\")\n#&gt; [1] 0.45\n\nSometimes your functions will be highly specialized for one data analysis step. For example, if you have a bunch of variables that record missing values as 997, 998, or 999, you might want to write a function to replace them with NA:\næœ‰æ—¶ä½ çš„å‡½æ•°ä¼šä¸ºä¸€ä¸ªæ•°æ®åˆ†ææ­¥éª¤é«˜åº¦ç‰¹åŒ–ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ä¸€å †å˜é‡å°†ç¼ºå¤±å€¼è®°å½•ä¸º 997ã€998 æˆ– 999ï¼Œä½ å¯èƒ½æƒ³å†™ä¸€ä¸ªå‡½æ•°å°†å®ƒä»¬æ›¿æ¢ä¸º NAï¼š\n\nfix_na &lt;- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\nWeâ€™ve focused on examples that take a single vector because we think theyâ€™re the most common. But thereâ€™s no reason that your function canâ€™t take multiple vector inputs.\næˆ‘ä»¬ä¸“æ³¨äºæ¥å—å•ä¸ªå‘é‡çš„ç¤ºä¾‹ï¼Œå› ä¸ºæˆ‘ä»¬è®¤ä¸ºå®ƒä»¬æœ€å¸¸è§ã€‚ä½†æ²¡æœ‰ç†ç”±ä½ çš„å‡½æ•°ä¸èƒ½æ¥å—å¤šä¸ªå‘é‡è¾“å…¥ã€‚\n\n25.2.4 Summary functions\nAnother important family of vector functions is summary functions, functions that return a single value for use in summarize(). Sometimes this can just be a matter of setting a default argument or two:\nå‘é‡å‡½æ•°çš„å¦ä¸€ä¸ªé‡è¦å®¶æ—æ˜¯æ‘˜è¦å‡½æ•°ï¼Œå³åœ¨ summarize() ä¸­ä½¿ç”¨å¹¶è¿”å›å•ä¸ªå€¼çš„å‡½æ•°ã€‚æœ‰æ—¶è¿™å¯èƒ½åªæ˜¯è®¾ç½®ä¸€ä¸ªæˆ–ä¸¤ä¸ªé»˜è®¤å‚æ•°çš„é—®é¢˜ï¼š\n\ncommas &lt;- function(x) {\n  str_flatten(x, collapse = \", \", last = \" and \")\n}\n\ncommas(c(\"cat\", \"dog\", \"pigeon\"))\n#&gt; [1] \"cat, dog and pigeon\"\n\nOr you might wrap up a simple computation, like for the coefficient of variation, which divides the standard deviation by the mean:\næˆ–è€…ä½ å¯èƒ½æƒ³åŒ…è£…ä¸€ä¸ªç®€å•çš„è®¡ç®—ï¼Œæ¯”å¦‚å˜å¼‚ç³»æ•°ï¼Œå®ƒæ˜¯æ ‡å‡†å·®é™¤ä»¥å‡å€¼ï¼š\n\ncv &lt;- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n#&gt; [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n#&gt; [1] 0.5652554\n\nOr maybe you just want to make a common pattern easier to remember by giving it a memorable name:\næˆ–è€…ï¼Œä½ å¯èƒ½åªæ˜¯æƒ³é€šè¿‡ç»™ä¸€ä¸ªå¸¸ç”¨æ¨¡å¼èµ·ä¸€ä¸ªå®¹æ˜“è®°ä½çš„åå­—ï¼Œæ¥è®©å®ƒæ›´å®¹æ˜“è¢«è®°ä½ï¼š\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nn_missing &lt;- function(x) {\n  sum(is.na(x))\n}\n\nYou can also write functions with multiple vector inputs. For example, maybe you want to compute the mean absolute percentage error to help you compare model predictions with actual values:\nä½ ä¹Ÿå¯ä»¥ç¼–å†™å…·æœ‰å¤šä¸ªå‘é‡è¾“å…¥çš„å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œä¹Ÿè®¸ä½ æƒ³è®¡ç®—å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (mean absolute percentage error) æ¥å¸®åŠ©ä½ æ¯”è¾ƒæ¨¡å‹é¢„æµ‹å€¼ä¸å®é™…å€¼ï¼š\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nmape &lt;- function(actual, predicted) {\n  sum(abs((actual - predicted) / actual)) / length(actual)\n}\n\n\n\n\n\n\n\nRStudio\n\n\n\nOnce you start writing functions, there are two RStudio shortcuts that are super useful:\nä¸€æ—¦ä½ å¼€å§‹ç¼–å†™å‡½æ•°ï¼Œæœ‰ä¸¤ä¸ª RStudio å¿«æ·é”®ä¼šéå¸¸æœ‰ç”¨ï¼š\n\nTo find the definition of a function that youâ€™ve written, place the cursor on the name of the function and press F2.\nè¦æŸ¥æ‰¾ä½ ç¼–å†™çš„å‡½æ•°çš„å®šä¹‰ï¼Œè¯·å°†å…‰æ ‡æ”¾åœ¨å‡½æ•°åç§°ä¸Šï¼Œç„¶åæŒ‰ F2ã€‚\nTo quickly jump to a function, press Ctrl + . to open the fuzzy file and function finder and type the first few letters of your function name. You can also navigate to files, Quarto sections, and more, making it a very handy navigation tool.\nè¦å¿«é€Ÿè·³è½¬åˆ°æŸä¸ªå‡½æ•°ï¼Œè¯·æŒ‰ Ctrl + . æ‰“å¼€æ¨¡ç³Šæ–‡ä»¶å’Œå‡½æ•°æŸ¥æ‰¾å™¨ï¼Œç„¶åè¾“å…¥å‡½æ•°åç§°çš„å‰å‡ ä¸ªå­—æ¯ã€‚ä½ è¿˜å¯ä»¥ç”¨å®ƒå¯¼èˆªåˆ°æ–‡ä»¶ã€Quarto ç« èŠ‚ç­‰ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„å¯¼èˆªå·¥å…·ã€‚\n\n\n\n\n25.2.5 Exercises\n\n\nPractice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need?\n\nmean(is.na(x))\nmean(is.na(y))\nmean(is.na(z))\n\nx / sum(x, na.rm = TRUE)\ny / sum(y, na.rm = TRUE)\nz / sum(z, na.rm = TRUE)\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n\nIn the second variant of rescale01(), infinite values are left unchanged. Can you rewrite rescale01() so that -Inf is mapped to 0, and Inf is mapped to 1?\nGiven a vector of birthdates, write a function to compute the age in years.\nWrite your own functions to compute the variance and skewness of a numeric vector. You can look up the definitions on Wikipedia or elsewhere.\nWrite both_na(), a summary function that takes two vectors of the same length and returns the number of positions that have an NA in both vectors.\n\nRead the documentation to figure out what the following functions do. Why are they useful even though they are so short?\n\nis_directory &lt;- function(x) {\n  file.info(x)$isdir\n}\nis_readable &lt;- function(x) {\n  file.access(x, 4) == 0\n}",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>25</span>Â  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#data-frame-functions",
    "href": "functions.html#data-frame-functions",
    "title": "25Â  Functions",
    "section": "\n25.3 Data frame functions",
    "text": "25.3 Data frame functions\nVector functions are useful for pulling out code thatâ€™s repeated within a dplyr verb. But youâ€™ll often also repeat the verbs themselves, particularly within a large pipeline. When you notice yourself copying and pasting multiple verbs multiple times, you might think about writing a data frame function. Data frame functions work like dplyr verbs: they take a data frame as the first argument, some extra arguments that say what to do with it, and return a data frame or a vector.\nå‘é‡å‡½æ•°å¯¹äºæå–åœ¨ dplyr åŠ¨è¯ä¸­é‡å¤å‡ºç°çš„ä»£ç å¾ˆæœ‰ç”¨ã€‚ä½†æ˜¯ï¼Œä½ ä¹Ÿç»å¸¸ä¼šé‡å¤ä½¿ç”¨åŠ¨è¯æœ¬èº«ï¼Œå°¤å…¶æ˜¯åœ¨å¤§å‹ç®¡é“ä¸­ã€‚å½“ä½ å‘ç°è‡ªå·±å¤šæ¬¡å¤åˆ¶å’Œç²˜è´´å¤šä¸ªåŠ¨è¯æ—¶ï¼Œä½ å¯èƒ½ä¼šè€ƒè™‘ç¼–å†™ä¸€ä¸ªæ•°æ®æ¡†å‡½æ•°ã€‚æ•°æ®æ¡†å‡½æ•°çš„å·¥ä½œæ–¹å¼ç±»ä¼¼äº dplyr åŠ¨è¯ï¼šå®ƒä»¬å°†æ•°æ®æ¡†ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°ï¼Œä»¥åŠä¸€äº›é¢å¤–çš„å‚æ•°æ¥è¯´æ˜å¦‚ä½•å¤„ç†å®ƒï¼Œå¹¶è¿”å›ä¸€ä¸ªæ•°æ®æ¡†æˆ–ä¸€ä¸ªå‘é‡ã€‚\nTo let you write a function that uses dplyr verbs, weâ€™ll first introduce you to the challenge of indirection and how you can overcome it with embracing, {{ }}. With this theory under your belt, weâ€™ll then show you a bunch of examples to illustrate what you might do with it.\nä¸ºäº†è®©ä½ èƒ½å¤Ÿç¼–å†™ä½¿ç”¨ dplyr åŠ¨è¯çš„å‡½æ•°ï¼Œæˆ‘ä»¬å°†é¦–å…ˆå‘ä½ ä»‹ç»é—´æ¥å¼•ç”¨ (indirection) çš„æŒ‘æˆ˜ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡æ‹¥æŠ± (embracing) {{ }} æ¥å…‹æœå®ƒã€‚æŒæ¡äº†è¿™ä¸€ç†è®ºåï¼Œæˆ‘ä»¬å°†å‘ä½ å±•ç¤ºä¸€ç³»åˆ—ç¤ºä¾‹ï¼Œä»¥è¯´æ˜ä½ å¯ä»¥ç”¨å®ƒåšä»€ä¹ˆã€‚\n\n25.3.1 Indirection and tidy evaluation\nWhen you start writing functions that use dplyr verbs you rapidly hit the problem of indirection. Letâ€™s illustrate the problem with a very simple function: grouped_mean(). The goal of this function is to compute the mean of mean_var grouped by group_var:\nå½“ä½ å¼€å§‹ç¼–å†™ä½¿ç”¨ dplyr åŠ¨è¯çš„å‡½æ•°æ—¶ï¼Œä½ ä¼šå¾ˆå¿«é‡åˆ°é—´æ¥å¼•ç”¨çš„é—®é¢˜ã€‚è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªéå¸¸ç®€å•çš„å‡½æ•° grouped_mean() æ¥è¯´æ˜è¿™ä¸ªé—®é¢˜ã€‚è¯¥å‡½æ•°çš„ç›®æ ‡æ˜¯è®¡ç®—æŒ‰ group_var åˆ†ç»„çš„ mean_var çš„å‡å€¼ï¼š\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by(group_var) |&gt; \n    summarize(mean(mean_var))\n}\n\nIf we try and use it, we get an error:\nå¦‚æœæˆ‘ä»¬å°è¯•ä½¿ç”¨å®ƒï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ªé”™è¯¯ï¼š\n\ndiamonds |&gt; grouped_mean(cut, carat)\n#&gt; Error in `group_by()`:\n#&gt; ! Must group by variables found in `.data`.\n#&gt; âœ– Column `group_var` is not found.\n\nTo make the problem a bit more clear, we can use a made up data frame:\nä¸ºäº†è®©é—®é¢˜æ›´æ¸…æ¥šä¸€äº›ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªè™šæ„çš„æ•°æ®æ¡†ï¼š\n\ndf &lt;- tibble(\n  mean_var = 1,\n  group_var = \"g\",\n  group = 1,\n  x = 10,\n  y = 100\n)\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\ndf |&gt; grouped_mean(group, y)\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\n\nRegardless of how we call grouped_mean() it always does df |&gt; group_by(group_var) |&gt; summarize(mean(mean_var)), instead of df |&gt; group_by(group) |&gt; summarize(mean(x)) or df |&gt; group_by(group) |&gt; summarize(mean(y)). This is a problem of indirection, and it arises because dplyr uses tidy evaluation to allow you to refer to the names of variables inside your data frame without any special treatment.\næ— è®ºæˆ‘ä»¬å¦‚ä½•è°ƒç”¨ grouped_mean()ï¼Œå®ƒæ€»æ˜¯æ‰§è¡Œ df |&gt; group_by(group_var) |&gt; summarize(mean(mean_var))ï¼Œè€Œä¸æ˜¯ df |&gt; group_by(group) |&gt; summarize(mean(x)) æˆ– df |&gt; group_by(group) |&gt; summarize(mean(y))ã€‚è¿™æ˜¯ä¸€ä¸ªé—´æ¥å¼•ç”¨çš„é—®é¢˜ï¼Œå®ƒçš„å‡ºç°æ˜¯å› ä¸º dplyr ä½¿ç”¨ æ•´æ´æ±‚å€¼ (tidy evaluation) æ¥å…è®¸ä½ å¼•ç”¨æ•°æ®æ¡†å†…çš„å˜é‡åè€Œæ— éœ€ä»»ä½•ç‰¹æ®Šå¤„ç†ã€‚\nTidy evaluation is great 95% of the time because it makes your data analyses very concise as you never have to say which data frame a variable comes from; itâ€™s obvious from the context. The downside of tidy evaluation comes when we want to wrap up repeated tidyverse code into a function. Here we need some way to tell group_by() and summarize() not to treat group_var and mean_var as the name of the variables, but instead look inside them for the variable we actually want to use.\næ•´æ´æ±‚å€¼åœ¨ 95% çš„æƒ…å†µä¸‹éƒ½å¾ˆå¥½ç”¨ï¼Œå› ä¸ºå®ƒè®©ä½ çš„æ•°æ®åˆ†æéå¸¸ç®€æ´ï¼Œä½ æ°¸è¿œä¸å¿…è¯´æ˜ä¸€ä¸ªå˜é‡æ¥è‡ªå“ªä¸ªæ•°æ®æ¡†ï¼›è¿™ä»ä¸Šä¸‹æ–‡ä¸­æ˜¯æ˜¾è€Œæ˜“è§çš„ã€‚æ•´æ´æ±‚å€¼çš„ç¼ºç‚¹åœ¨äºå½“æˆ‘ä»¬è¦å°†é‡å¤çš„ tidyverse ä»£ç å°è£…æˆå‡½æ•°æ—¶ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•å‘Šè¯‰ group_by() å’Œ summarize() ä¸è¦å°† group_var å’Œ mean_var è§†ä¸ºå˜é‡çš„åç§°ï¼Œè€Œæ˜¯æŸ¥çœ‹å®ƒä»¬å†…éƒ¨ä»¥æ‰¾åˆ°æˆ‘ä»¬å®é™…æƒ³è¦ä½¿ç”¨çš„å˜é‡ã€‚\nTidy evaluation includes a solution to this problem called embracing ğŸ¤—. Embracing a variable means to wrap it in braces so (e.g.) var becomes {{ var }}. Embracing a variable tells dplyr to use the value stored inside the argument, not the argument as the literal variable name. One way to remember whatâ€™s happening is to think of {{ }} as looking down a tunnel â€” {{ var }} will make a dplyr function look inside of var rather than looking for a variable called var.\næ•´æ´æ±‚å€¼åŒ…å«ä¸€ä¸ªè§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•ï¼Œç§°ä¸º æ‹¥æŠ± (embracing) ğŸ¤—ã€‚æ‹¥æŠ±ä¸€ä¸ªå˜é‡æ„å‘³ç€å°†å…¶ç”¨èŠ±æ‹¬å·æ‹¬èµ·æ¥ï¼Œä¾‹å¦‚ var å˜æˆ {{ var }}ã€‚æ‹¥æŠ±ä¸€ä¸ªå˜é‡ä¼šå‘Šè¯‰ dplyr ä½¿ç”¨å­˜å‚¨åœ¨å‚æ•°å†…çš„å€¼ï¼Œè€Œä¸æ˜¯å°†å‚æ•°æœ¬èº«ä½œä¸ºå­—é¢ä¸Šçš„å˜é‡åã€‚è®°ä½æ­£åœ¨å‘ç”Ÿä»€ä¹ˆçš„ä¸€ç§æ–¹æ³•æ˜¯ï¼Œå°† {{ }} æƒ³è±¡æˆåœ¨çœ‹ä¸€æ¡éš§é“ â€” {{ var }} ä¼šè®© dplyr å‡½æ•°æŸ¥çœ‹ var çš„å†…éƒ¨ï¼Œè€Œä¸æ˜¯å¯»æ‰¾ä¸€ä¸ªåä¸º var çš„å˜é‡ã€‚\nSo to make grouped_mean() work, we need to surround group_var and mean_var with {{ }}:\nå› æ­¤ï¼Œä¸ºäº†è®© grouped_mean() æ­£å¸¸å·¥ä½œï¼Œæˆ‘ä»¬éœ€è¦ç”¨ {{ }} å°† group_var å’Œ mean_var åŒ…å›´èµ·æ¥ï¼š\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by({{ group_var }}) |&gt; \n    summarize(mean({{ mean_var }}))\n}\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 Ã— 2\n#&gt;   group `mean(x)`\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1        10\n\nSuccess!\næˆåŠŸäº†ï¼\n\n25.3.2 When to embrace?\nSo the key challenge in writing data frame functions is figuring out which arguments need to be embraced. Fortunately, this is easy because you can look it up from the documentation ğŸ˜„. There are two terms to look for in the docs which correspond to the two most common sub-types of tidy evaluation:\nå› æ­¤ï¼Œç¼–å†™æ•°æ®æ¡†å‡½æ•°çš„å…³é”®æŒ‘æˆ˜æ˜¯å¼„æ¸…æ¥šå“ªäº›å‚æ•°éœ€è¦è¢«æ‹¥æŠ±ã€‚å¹¸è¿çš„æ˜¯ï¼Œè¿™å¾ˆå®¹æ˜“ï¼Œå› ä¸ºä½ å¯ä»¥ä»æ–‡æ¡£ä¸­æŸ¥åˆ° ğŸ˜„ã€‚åœ¨æ–‡æ¡£ä¸­éœ€è¦æ³¨æ„ä¸¤ä¸ªæœ¯è¯­ï¼Œå®ƒä»¬å¯¹åº”äºæ•´æ´æ±‚å€¼æœ€å¸¸è§çš„ä¸¤ç§å­ç±»å‹ï¼š\n\nData-masking: this is used in functions like arrange(), filter(), and summarize() that compute with variables.æ•°æ®å±è”½ (Data-masking)ï¼šè¿™ç”¨äºåƒ arrange()ã€filter() å’Œ summarize() è¿™æ ·éœ€è¦å¯¹å˜é‡è¿›è¡Œè®¡ç®—çš„å‡½æ•°ã€‚\nTidy-selection: this is used for functions like select(), relocate(), and rename() that select variables.æ•´æ´é€‰æ‹© (Tidy-selection)ï¼šè¿™ç”¨äºåƒ select()ã€relocate() å’Œ rename() è¿™æ ·éœ€è¦é€‰æ‹©å˜é‡çš„å‡½æ•°ã€‚\n\nYour intuition about which arguments use tidy evaluation should be good for many common functions â€” just think about whether you can compute (e.g., x + 1) or select (e.g., a:x).\nå¯¹äºè®¸å¤šå¸¸ç”¨å‡½æ•°ï¼Œä½ å…³äºå“ªäº›å‚æ•°ä½¿ç”¨æ•´æ´æ±‚å€¼çš„ç›´è§‰åº”è¯¥æ˜¯å‡†ç¡®çš„â€”â€”åªéœ€è€ƒè™‘ä½ æ˜¯åœ¨è¿›è¡Œè®¡ç®—ï¼ˆä¾‹å¦‚ x + 1ï¼‰è¿˜æ˜¯åœ¨è¿›è¡Œé€‰æ‹©ï¼ˆä¾‹å¦‚ a:xï¼‰ã€‚\nIn the following sections, weâ€™ll explore the sorts of handy functions you might write once you understand embracing.\nåœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œä¸€æ—¦ä½ ç†è§£äº†æ‹¥æŠ±æ“ä½œï¼Œæˆ‘ä»¬å°†ä¼šæ¢è®¨ä½ å¯ä»¥ç¼–å†™çš„å„ç§ä¾¿æ·å‡½æ•°ã€‚\n\n25.3.3 Common use cases\nIf you commonly perform the same set of summaries when doing initial data exploration, you might consider wrapping them up in a helper function:\nå¦‚æœä½ åœ¨è¿›è¡Œåˆæ­¥æ•°æ®æ¢ç´¢æ—¶ç»å¸¸æ‰§è¡ŒåŒä¸€ç»„æ±‡æ€»æ“ä½œï¼Œä½ å¯èƒ½ä¼šè€ƒè™‘å°†å®ƒä»¬å°è£…åˆ°ä¸€ä¸ªè¾…åŠ©å‡½æ•°ä¸­ï¼š\n\nsummary6 &lt;- function(data, var) {\n  data |&gt; summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    mean = mean({{ var }}, na.rm = TRUE),\n    median = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_miss = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamonds |&gt; summary6(carat)\n#&gt; # A tibble: 1 Ã— 6\n#&gt;     min  mean median   max     n n_miss\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1   0.2 0.798    0.7  5.01 53940      0\n\n(Whenever you wrap summarize() in a helper, we think itâ€™s good practice to set .groups = \"drop\" to both avoid the message and leave the data in an ungrouped state.)\nï¼ˆæ— è®ºä½•æ—¶å°† summarize() åŒ…è£…åœ¨è¾…åŠ©å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬éƒ½è®¤ä¸ºå°† .groups = \"drop\" è®¾ç½®ä¸ºå¥½ä¹ æƒ¯ï¼Œè¿™æ ·æ—¢å¯ä»¥é¿å…æ¶ˆæ¯æç¤ºï¼Œåˆèƒ½ä½¿æ•°æ®å¤„äºæœªåˆ†ç»„çŠ¶æ€ã€‚ï¼‰\nThe nice thing about this function is, because it wraps summarize(), you can use it on grouped data:\nè¿™ä¸ªå‡½æ•°çš„å¥½å¤„åœ¨äºï¼Œå› ä¸ºå®ƒåŒ…è£…äº† summarize()ï¼Œæ‰€ä»¥ä½ å¯ä»¥å¯¹åˆ†ç»„æ•°æ®ä½¿ç”¨å®ƒï¼š\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(carat)\n#&gt; # A tibble: 5 Ã— 7\n#&gt;   cut         min  mean median   max     n n_miss\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair       0.22 1.05    1     5.01  1610      0\n#&gt; 2 Good       0.23 0.849   0.82  3.01  4906      0\n#&gt; 3 Very Good  0.2  0.806   0.71  4    12082      0\n#&gt; 4 Premium    0.2  0.892   0.86  4.01 13791      0\n#&gt; 5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\nFurthermore, since the arguments to summarize are data-masking, so is the var argument to summary6(). That means you can also summarize computed variables:\næ­¤å¤–ï¼Œç”±äº summarize çš„å‚æ•°æ˜¯æ•°æ®å±è”½çš„ï¼Œsummary6() çš„ var å‚æ•°ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™æ„å‘³ç€ä½ ä¹Ÿå¯ä»¥å¯¹è®¡ç®—å¾—å‡ºçš„å˜é‡è¿›è¡Œæ±‡æ€»ï¼š\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(log10(carat))\n#&gt; # A tibble: 5 Ã— 7\n#&gt;   cut          min    mean  median   max     n n_miss\n#&gt;   &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair      -0.658 -0.0273  0      0.700  1610      0\n#&gt; 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n#&gt; 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n#&gt; 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n#&gt; 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\nTo summarize multiple variables, youâ€™ll need to wait until Section 26.2, where youâ€™ll learn how to use across().\nè¦æ±‡æ€»å¤šä¸ªå˜é‡ï¼Œä½ éœ€è¦ç­‰åˆ° Section 26.2 ç« èŠ‚ï¼Œå±Šæ—¶ä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ across()ã€‚\nAnother popular summarize() helper function is a version of count() that also computes proportions:\nå¦ä¸€ä¸ªæµè¡Œçš„ summarize() è¾…åŠ©å‡½æ•°æ˜¯ count() çš„ä¸€ä¸ªç‰ˆæœ¬ï¼Œå®ƒè¿˜èƒ½è®¡ç®—æ¯”ä¾‹ï¼š\n\n# https://twitter.com/Diabb6/status/1571635146658402309\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}\n\ndiamonds |&gt; count_prop(clarity)\n#&gt; # A tibble: 8 Ã— 3\n#&gt;   clarity     n   prop\n#&gt;   &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 I1        741 0.0137\n#&gt; 2 SI2      9194 0.170 \n#&gt; 3 SI1     13065 0.242 \n#&gt; 4 VS2     12258 0.227 \n#&gt; 5 VS1      8171 0.151 \n#&gt; 6 VVS2     5066 0.0939\n#&gt; # â„¹ 2 more rows\n\nThis function has three arguments: df, var, and sort, and only var needs to be embraced because itâ€™s passed to count() which uses data-masking for all variables. Note that we use a default value for sort so that if the user doesnâ€™t supply their own value it will default to FALSE.\nè¿™ä¸ªå‡½æ•°æœ‰ä¸‰ä¸ªå‚æ•°ï¼šdfã€var å’Œ sortï¼Œåªæœ‰ var éœ€è¦è¢«æ‹¥æŠ±ï¼Œå› ä¸ºå®ƒè¢«ä¼ é€’ç»™äº† count()ï¼Œè€Œ count() å¯¹æ‰€æœ‰å˜é‡éƒ½ä½¿ç”¨æ•°æ®å±è”½ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¸º sort ä½¿ç”¨äº†é»˜è®¤å€¼ï¼Œè¿™æ ·å¦‚æœç”¨æˆ·ä¸æä¾›è‡ªå·±çš„å€¼ï¼Œå®ƒå°†é»˜è®¤ä¸º FALSEã€‚\nOr maybe you want to find the sorted unique values of a variable for a subset of the data. Rather than supplying a variable and a value to do the filtering, weâ€™ll allow the user to supply a condition:\næˆ–è€…ï¼Œä½ å¯èƒ½æƒ³è¦ä¸ºæ•°æ®çš„å­é›†æŸ¥æ‰¾å˜é‡çš„å·²æ’åºå”¯ä¸€å€¼ã€‚ä¸å…¶æä¾›ä¸€ä¸ªå˜é‡å’Œä¸€ä¸ªå€¼æ¥è¿›è¡Œç­›é€‰ï¼Œä¸å¦‚è®©ç”¨æˆ·æä¾›ä¸€ä¸ªæ¡ä»¶ï¼š\n\nunique_where &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    distinct({{ var }}) |&gt; \n    arrange({{ var }})\n}\n\n# Find all the destinations in December\nflights |&gt; unique_where(month == 12, dest)\n#&gt; # A tibble: 96 Ã— 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 ABQ  \n#&gt; 2 ALB  \n#&gt; 3 ATL  \n#&gt; 4 AUS  \n#&gt; 5 AVL  \n#&gt; 6 BDL  \n#&gt; # â„¹ 90 more rows\n\nHere we embrace condition because itâ€™s passed to filter() and var because itâ€™s passed to distinct() and arrange().\nè¿™é‡Œæˆ‘ä»¬æ‹¥æŠ± condition æ˜¯å› ä¸ºå®ƒè¢«ä¼ é€’ç»™äº† filter()ï¼Œæ‹¥æŠ± var æ˜¯å› ä¸ºå®ƒè¢«ä¼ é€’ç»™äº† distinct() å’Œ arrange()ã€‚\nWeâ€™ve made all these examples to take a data frame as the first argument, but if youâ€™re working repeatedly with the same data, it can make sense to hardcode it. For example, the following function always works with the flights dataset and always selects time_hour, carrier, and flight since they form the compound primary key that allows you to identify a row.\næˆ‘ä»¬æ‰€æœ‰çš„ç¤ºä¾‹éƒ½å°†æ•°æ®æ¡†ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°ï¼Œä½†æ˜¯å¦‚æœä½ é‡å¤ä½¿ç”¨ç›¸åŒçš„æ•°æ®ï¼Œå°†å…¶ç¡¬ç¼–ç å¯èƒ½æ›´æœ‰æ„ä¹‰ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„å‡½æ•°æ€»æ˜¯å¤„ç† flights æ•°æ®é›†ï¼Œå¹¶ä¸”æ€»æ˜¯é€‰æ‹© time_hourã€carrier å’Œ flightï¼Œå› ä¸ºå®ƒä»¬æ„æˆäº†å¯ä»¥è¯†åˆ«ä¸€è¡Œçš„å¤åˆä¸»é”®ã€‚\n\nsubset_flights &lt;- function(rows, cols) {\n  flights |&gt; \n    filter({{ rows }}) |&gt; \n    select(time_hour, carrier, flight, {{ cols }})\n}\n\n\n25.3.4 Data-masking vs.Â tidy-selection\nSometimes you want to select variables inside a function that uses data-masking. For example, imagine you want to write a count_missing() that counts the number of missing observations in rows. You might try writing something like:\næœ‰æ—¶ä½ æƒ³åœ¨ä¸€ä¸ªä½¿ç”¨æ•°æ®å±è”½çš„å‡½æ•°å†…éƒ¨é€‰æ‹©å˜é‡ã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä½ æƒ³ç¼–å†™ä¸€ä¸ª count_missing() å‡½æ•°ï¼Œç”¨äºè®¡ç®—è¡Œä¸­ç¼ºå¤±è§‚æµ‹å€¼çš„æ•°é‡ã€‚ä½ å¯èƒ½ä¼šå°è¯•è¿™æ ·å†™ï¼š\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by({{ group_vars }}) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; Error in `group_by()`:\n#&gt; â„¹ In argument: `c(year, month, day)`.\n#&gt; Caused by error:\n#&gt; ! `c(year, month, day)` must be size 336776 or 1, not 1010328.\n\nThis doesnâ€™t work because group_by() uses data-masking, not tidy-selection. We can work around that problem by using the handy pick() function, which allows you to use tidy-selection inside data-masking functions:\nè¿™ä¸èµ·ä½œç”¨ï¼Œå› ä¸º group_by() ä½¿ç”¨çš„æ˜¯æ•°æ®å±è”½ (data-masking)ï¼Œè€Œä¸æ˜¯æ•´æ´é€‰æ‹© (tidy-selection)ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨æ–¹ä¾¿çš„ pick() å‡½æ•°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå®ƒå…è®¸ä½ åœ¨æ•°æ®å±è”½å‡½æ•°å†…éƒ¨ä½¿ç”¨æ•´æ´é€‰æ‹©ï¼š\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; # A tibble: 365 Ã— 4\n#&gt;    year month   day n_miss\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1  2013     1     1      4\n#&gt; 2  2013     1     2      8\n#&gt; 3  2013     1     3     10\n#&gt; 4  2013     1     4      6\n#&gt; 5  2013     1     5      3\n#&gt; 6  2013     1     6      1\n#&gt; # â„¹ 359 more rows\n\nAnother convenient use of pick() is to make a 2d table of counts. Here we count using all the variables in the rows and columns, then use pivot_wider() to rearrange the counts into a grid:pick() çš„å¦ä¸€ä¸ªä¾¿æ·ç”¨é€”æ˜¯åˆ¶ä½œä¸€ä¸ªäºŒç»´è®¡æ•°è¡¨ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ rows å’Œ columns ä¸­çš„æ‰€æœ‰å˜é‡è¿›è¡Œè®¡æ•°ï¼Œç„¶åä½¿ç”¨ pivot_wider() å°†è®¡æ•°é‡æ–°æ’åˆ—æˆä¸€ä¸ªç½‘æ ¼ï¼š\n\n# https://twitter.com/pollicipes/status/1571606508944719876\ncount_wide &lt;- function(data, rows, cols) {\n  data |&gt; \n    count(pick(c({{ rows }}, {{ cols }}))) |&gt; \n    pivot_wider(\n      names_from = {{ cols }}, \n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamonds |&gt; count_wide(c(clarity, color), cut)\n#&gt; # A tibble: 56 Ã— 7\n#&gt;   clarity color  Fair  Good `Very Good` Premium Ideal\n#&gt;   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 I1      D         4     8           5      12    13\n#&gt; 2 I1      E         9    23          22      30    18\n#&gt; 3 I1      F        35    19          13      34    42\n#&gt; 4 I1      G        53    19          16      46    16\n#&gt; 5 I1      H        52    14          12      46    38\n#&gt; 6 I1      I        34     9           8      24    17\n#&gt; # â„¹ 50 more rows\n\nWhile our examples have mostly focused on dplyr, tidy evaluation also underpins tidyr, and if you look at the pivot_wider() docs you can see that names_from uses tidy-selection.\nè™½ç„¶æˆ‘ä»¬çš„ç¤ºä¾‹ä¸»è¦é›†ä¸­åœ¨ dplyr ä¸Šï¼Œä½†æ•´æ´æ±‚å€¼ (tidy evaluation) ä¹Ÿæ˜¯ tidyr çš„åŸºç¡€ï¼Œå¦‚æœä½ æŸ¥çœ‹ pivot_wider() çš„æ–‡æ¡£ï¼Œä½ ä¼šå‘ç° names_from ä½¿ç”¨äº†æ•´æ´é€‰æ‹© (tidy-selection)ã€‚\n\n25.3.5 Exercises\n\n\nUsing the datasets from nycflights13, write a function that:\n\n\nFinds all flights that were cancelled (i.e.Â is.na(arr_time)) or delayed by more than an hour.\n\nflights |&gt; filter_severe()\n\n\n\nCounts the number of cancelled flights and the number of flights delayed by more than an hour.\n\nflights |&gt; group_by(dest) |&gt; summarize_severe()\n\n\n\nFinds all flights that were cancelled or delayed by more than a user supplied number of hours:\n\nflights |&gt; filter_severe(hours = 2)\n\n\n\nSummarizes the weather to compute the minimum, mean, and maximum, of a user supplied variable:\n\nweather |&gt; summarize_weather(temp)\n\n\n\nConverts the user supplied variable that uses clock time (e.g., dep_time, arr_time, etc.) into a decimal time (i.e.Â hours + (minutes / 60)).\n\nflights |&gt; standardize_time(sched_dep_time)\n\n\n\n\nFor each of the following functions list all arguments that use tidy evaluation and describe whether they use data-masking or tidy-selection: distinct(), count(), group_by(), rename_with(), slice_min(), slice_sample().\n\nGeneralize the following function so that you can supply any number of variables to count.\n\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>25</span>Â  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#plot-functions",
    "href": "functions.html#plot-functions",
    "title": "25Â  Functions",
    "section": "\n25.4 Plot functions",
    "text": "25.4 Plot functions\nInstead of returning a data frame, you might want to return a plot.\né™¤äº†è¿”å›ä¸€ä¸ªæ•°æ®æ¡†ï¼Œä½ å¯èƒ½è¿˜æƒ³è¿”å›ä¸€ä¸ªå›¾è¡¨ã€‚\nFortunately, you can use the same techniques with ggplot2, because aes() is a data-masking function.\nå¹¸è¿çš„æ˜¯ï¼Œä½ å¯ä»¥åœ¨ ggplot2 ä¸­ä½¿ç”¨ç›¸åŒçš„æŠ€æœ¯ï¼Œå› ä¸º aes() æ˜¯ä¸€ä¸ªæ•°æ®æ©ç  (data-masking) å‡½æ•°ã€‚\nFor example, imagine that youâ€™re making a lot of histograms:\nä¾‹å¦‚ï¼Œå‡è®¾ä½ æ­£åœ¨åˆ¶ä½œå¤§é‡çš„ç›´æ–¹å›¾ï¼š\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.05)\n\nWouldnâ€™t it be nice if you could wrap this up into a histogram function?\nå¦‚æœä½ èƒ½æŠŠè¿™äº›ä»£ç å°è£…æˆä¸€ä¸ªç›´æ–¹å›¾å‡½æ•°ï¼Œé‚£å²‚ä¸æ˜¯å¾ˆå¥½ï¼Ÿ\nThis is easy as pie once you know that aes() is a data-masking function and you need to embrace:\nä¸€æ—¦ä½ çŸ¥é“ aes() æ˜¯ä¸€ä¸ªæ•°æ®æ©ç å‡½æ•°å¹¶ä¸”éœ€è¦ä½¿ç”¨ embracing {{}}ï¼Œè¿™å°±å˜å¾—æ˜“å¦‚åæŒäº†ï¼š\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\nNote that histogram() returns a ggplot2 plot, meaning you can still add on additional components if you want.\nè¯·æ³¨æ„ï¼Œhistogram() è¿”å›çš„æ˜¯ä¸€ä¸ª ggplot2 å›¾è¡¨å¯¹è±¡ï¼Œè¿™æ„å‘³ç€ä½ ä»ç„¶å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ é¢å¤–çš„ç»„ä»¶ã€‚\nJust remember to switch from |&gt; to +:\nåªè¦è®°å¾—ä» |&gt; åˆ‡æ¢åˆ° + å³å¯ï¼š\n\ndiamonds |&gt; \n  histogram(carat, 0.1) +\n  labs(x = \"Size (in carats)\", y = \"Number of diamonds\")\n\n\n25.4.1 More variables\nItâ€™s straightforward to add more variables to the mix.\nåœ¨å‡½æ•°ä¸­æ·»åŠ æ›´å¤šå˜é‡æ˜¯ä»¶å¾ˆç®€å•çš„äº‹ã€‚\nFor example, maybe you want an easy way to eyeball whether or not a dataset is linear by overlaying a smooth line and a straight line:\nä¾‹å¦‚ï¼Œä½ å¯èƒ½æƒ³é€šè¿‡å åŠ ä¸€æ¡å¹³æ»‘æ›²çº¿å’Œä¸€æ¡ç›´çº¿æ¥å¿«é€Ÿç›®æµ‹ä¸€ä¸ªæ•°æ®é›†æ˜¯å¦å‘ˆçº¿æ€§å…³ç³»ï¼š\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nlinearity_check &lt;- function(df, x, y) {\n  df |&gt;\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\nstarwars |&gt; \n  filter(mass &lt; 1000) |&gt; \n  linearity_check(mass, height)\n\n\n\n\n\n\n\nOr maybe you want an alternative to colored scatterplots for very large datasets where overplotting is a problem:\næˆ–è€…ï¼Œå¯¹äºå› æ•°æ®ç‚¹è¿‡å¤šè€Œå­˜åœ¨è¿‡åº¦ç»˜åˆ¶ (overplotting) é—®é¢˜çš„å¤§å‹æ•°æ®é›†ï¼Œä½ å¯èƒ½æƒ³è¦ä¸€ç§æ›¿ä»£å½©è‰²æ•£ç‚¹å›¾çš„æ–¹æ³•ï¼š\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\nhex_plot &lt;- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |&gt; \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # make border same color as fill\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamonds |&gt; hex_plot(carat, price, depth)\n\n\n\n\n\n\n\n\n25.4.2 Combining with other tidyverse\nSome of the most useful helpers combine a dash of data manipulation with ggplot2.\nä¸€äº›æœ€æœ‰ç”¨çš„è¾…åŠ©å‡½æ•°ä¼šå°†å°‘é‡æ•°æ®å¤„ç†ä¸ ggplot2 ç»“åˆèµ·æ¥ã€‚\nFor example, if you might want to do a vertical bar chart where you automatically sort the bars in frequency order using fct_infreq().\nä¾‹å¦‚ï¼Œä½ å¯èƒ½æƒ³ç»˜åˆ¶ä¸€ä¸ªå‚ç›´æ¡å½¢å›¾ï¼Œå¹¶ä½¿ç”¨ fct_infreq() è‡ªåŠ¨æŒ‰é¢‘ç‡é¡ºåºå¯¹æ¡å½¢è¿›è¡Œæ’åºã€‚\nSince the bar chart is vertical, we also need to reverse the usual order to get the highest values at the top:\nç”±äºæ¡å½¢å›¾æ˜¯å‚ç›´çš„ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åè½¬é€šå¸¸çš„é¡ºåºï¼Œæ‰èƒ½è®©æœ€é«˜çš„å€¼æ˜¾ç¤ºåœ¨é¡¶éƒ¨ï¼š\n\nsorted_bars &lt;- function(df, var) {\n  df |&gt; \n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |&gt;\n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamonds |&gt; sorted_bars(clarity)\n\n\n\n\n\n\n\nWe have to use a new operator here, := (commonly referred to as the â€œwalrus operatorâ€), because we are generating the variable name based on user-supplied data.\næˆ‘ä»¬åœ¨è¿™é‡Œå¿…é¡»ä½¿ç”¨ä¸€ä¸ªæ–°çš„è¿ç®—ç¬¦ :=ï¼ˆé€šå¸¸è¢«ç§°ä¸ºâ€œæµ·è±¡è¿ç®—ç¬¦â€ï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„æ•°æ®æ¥ç”Ÿæˆå˜é‡åçš„ã€‚\nVariable names go on the left hand side of =, but Râ€™s syntax doesnâ€™t allow anything to the left of = except for a single literal name.\nå˜é‡åä½äº = çš„å·¦ä¾§ï¼Œä½† R çš„è¯­æ³•ä¸å…è®¸åœ¨ = å·¦ä¾§å‡ºç°é™¤å•ä¸ªå­—é¢åç§°ä¹‹å¤–çš„ä»»ä½•å†…å®¹ã€‚\nTo work around this problem, we use the special operator := which tidy evaluation treats in exactly the same way as =.\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç‰¹æ®Šçš„è¿ç®—ç¬¦ :=ï¼Œæ•´æ´æ±‚å€¼ (tidy evaluation) ä¼šå°†å…¶ä¸ = å®Œå…¨åŒç­‰å¯¹å¾…ã€‚\nOr maybe you want to make it easy to draw a bar plot just for a subset of the data:\nåˆæˆ–è€…ï¼Œä½ å¯èƒ½æƒ³è®©ç»˜åˆ¶æ•°æ®å­é›†çš„æ¡å½¢å›¾å˜å¾—æ›´å®¹æ˜“ï¼š\n\nconditional_bars &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamonds |&gt; conditional_bars(cut == \"Good\", clarity)\n\n\n\n\n\n\n\nYou can also get creative and display data summaries in other ways.\nä½ ä¹Ÿå¯ä»¥å‘æŒ¥åˆ›æ„ï¼Œç”¨å…¶ä»–æ–¹å¼æ¥å±•ç¤ºæ•°æ®æ‘˜è¦ã€‚\nYou can find a cool application at https://gist.github.com/GShotwell/b19ef520b6d56f61a830fabb3454965b; it uses the axis labels to display the highest value.\nä½ å¯ä»¥åœ¨ https://gist.github.com/GShotwell/b19ef520b6d56f61a830fabb3454965b æ‰¾åˆ°ä¸€ä¸ªå¾ˆé…·çš„åº”ç”¨ï¼›å®ƒä½¿ç”¨åæ ‡è½´æ ‡ç­¾æ¥æ˜¾ç¤ºæœ€é«˜å€¼ã€‚\nAs you learn more about ggplot2, the power of your functions will continue to increase.\néšç€ä½ å¯¹ ggplot2 çš„äº†è§£è¶Šæ¥è¶Šå¤šï¼Œä½ çš„å‡½æ•°çš„åŠŸèƒ½ä¹Ÿä¼šè¶Šæ¥è¶Šå¼ºå¤§ã€‚\nWeâ€™ll finish with a more complicated case: labelling the plots you create.\næœ€åï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªæ›´å¤æ‚çš„æƒ…å†µï¼šä¸ºä½ åˆ›å»ºçš„å›¾è¡¨æ·»åŠ æ ‡ç­¾ã€‚\n\n25.4.3 Labeling\nRemember the histogram function we showed you earlier?\nè¿˜è®°å¾—æˆ‘ä»¬å‰é¢å±•ç¤ºçš„ç›´æ–¹å›¾å‡½æ•°å—ï¼Ÿ\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\nWouldnâ€™t it be nice if we could label the output with the variable and the bin width that was used?\nå¦‚æœæˆ‘ä»¬èƒ½ç”¨æ‰€ä½¿ç”¨çš„å˜é‡å’Œç»„è· (bin width) æ¥æ ‡è®°è¾“å‡ºï¼Œé‚£å²‚ä¸æ˜¯å¾ˆå¥½ï¼Ÿ\nTo do so, weâ€™re going to have to go under the covers of tidy evaluation and use a function from the package we havenâ€™t talked about yet: rlang.\nè¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¿…é¡»æ·±å…¥äº†è§£æ•´æ´æ±‚å€¼ (tidy evaluation) çš„å†…éƒ¨æœºåˆ¶ï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªæˆ‘ä»¬å°šæœªè®¨è®ºè¿‡çš„åŒ…ä¸­çš„å‡½æ•°ï¼šrlangã€‚\nrlang is a low-level package thatâ€™s used by just about every other package in the tidyverse because it implements tidy evaluation (as well as many other useful tools).\nrlang æ˜¯ä¸€ä¸ªåº•å±‚åŒ…ï¼Œå‡ ä¹ tidyverse ä¸­çš„æ‰€æœ‰å…¶ä»–åŒ…éƒ½åœ¨ä½¿ç”¨å®ƒï¼Œå› ä¸ºå®ƒå®ç°äº†æ•´æ´æ±‚å€¼ (tidy evaluation)ï¼ˆä»¥åŠè®¸å¤šå…¶ä»–æœ‰ç”¨çš„å·¥å…·ï¼‰ã€‚\nTo solve the labeling problem we can use rlang::englue().\nä¸ºäº†è§£å†³æ·»åŠ æ ‡ç­¾çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ rlang::englue()ã€‚\nThis works similarly to str_glue(), so any value wrapped in { } will be inserted into the string.\nå®ƒçš„å·¥ä½œæ–¹å¼ç±»ä¼¼äº str_glue()ï¼Œå› æ­¤ä»»ä½•ç”¨ { } åŒ…è£…çš„å€¼éƒ½å°†è¢«æ’å…¥åˆ°å­—ç¬¦ä¸²ä¸­ã€‚\nBut it also understands {{ }}, which automatically inserts the appropriate variable name:\nä½†å®ƒè¿˜èƒ½ç†è§£ {{ }}ï¼Œè¯¥è¯­æ³•ä¼šè‡ªåŠ¨æ’å…¥ç›¸åº”çš„å˜é‡åï¼š\n\nhistogram &lt;- function(df, var, binwidth) {\n  label &lt;- rlang::englue(\"A histogram of {{var}} with binwidth {binwidth}\")\n  \n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = label)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\nYou can use the same approach in any other place where you want to supply a string in a ggplot2 plot.\nä½ å¯ä»¥åœ¨ä»»ä½•éœ€è¦åœ¨ ggplot2 å›¾è¡¨ä¸­æä¾›å­—ç¬¦ä¸²çš„åœ°æ–¹ä½¿ç”¨åŒæ ·çš„æ–¹æ³•ã€‚\n\n25.4.4 Exercises\nBuild up a rich plotting function by incrementally implementing each of the steps below:\n\nDraw a scatterplot given dataset and x and y variables.\nAdd a line of best fit (i.e.Â a linear model with no standard errors).\nAdd a title.",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>25</span>Â  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#style",
    "href": "functions.html#style",
    "title": "25Â  Functions",
    "section": "\n25.5 Style",
    "text": "25.5 Style\nR doesnâ€™t care what your function or arguments are called but the names make a big difference for humans.\nR å¹¶ä¸å…³å¿ƒä½ çš„å‡½æ•°æˆ–å‚æ•°å«ä»€ä¹ˆåå­—ï¼Œä½†è¿™äº›åå­—å¯¹äººç±»è¯»è€…æ¥è¯´å´è‡³å…³é‡è¦ã€‚\nIdeally, the name of your function will be short, but clearly evoke what the function does.\nç†æƒ³æƒ…å†µä¸‹ï¼Œå‡½æ•°ååº”è¯¥ç®€çŸ­ï¼Œä½†èƒ½æ¸…æ™°åœ°è¡¨è¾¾å‡½æ•°çš„åŠŸèƒ½ã€‚\nThatâ€™s hard!\nè¿™å¾ˆéš¾ï¼\nBut itâ€™s better to be clear than short, as RStudioâ€™s autocomplete makes it easy to type long names.\nä½†æ¸…æ™°æ¯”ç®€çŸ­æ›´é‡è¦ï¼Œå› ä¸º RStudio çš„è‡ªåŠ¨è¡¥å…¨åŠŸèƒ½å¯ä»¥è®©ä½ è½»æ¾è¾“å…¥é•¿åç§°ã€‚\nGenerally, function names should be verbs, and arguments should be nouns.\né€šå¸¸ï¼Œå‡½æ•°ååº”è¯¥æ˜¯åŠ¨è¯ï¼Œå‚æ•°åº”è¯¥æ˜¯åè¯ã€‚\nThere are some exceptions: nouns are ok if the function computes a very well known noun (i.e.Â mean() is better than compute_mean()), or accessing some property of an object (i.e.Â coef() is better than get_coefficients()).\nä¹Ÿæœ‰ä¸€äº›ä¾‹å¤–ï¼šå¦‚æœå‡½æ•°è®¡ç®—çš„æ˜¯ä¸€ä¸ªä¼—æ‰€å‘¨çŸ¥çš„åè¯ï¼ˆä¾‹å¦‚ mean() å°±æ¯” compute_mean() å¥½ï¼‰ï¼Œæˆ–è€…ç”¨äºè®¿é—®å¯¹è±¡çš„æŸä¸ªå±æ€§ï¼ˆä¾‹å¦‚ coef() å°±æ¯” get_coefficients() å¥½ï¼‰ï¼Œé‚£ä¹ˆä½¿ç”¨åè¯ä½œä¸ºå‡½æ•°åä¹Ÿæ˜¯å¯ä»¥çš„ã€‚\nUse your best judgement and donâ€™t be afraid to rename a function if you figure out a better name later.\nè¯·è¿ç”¨ä½ çš„æœ€ä½³åˆ¤æ–­åŠ›ï¼Œå¦‚æœä»¥åæƒ³åˆ°äº†æ›´å¥½çš„åå­—ï¼Œä¸è¦å®³æ€•é‡å‘½åå‡½æ•°ã€‚\n\n# Too short\nf()\n\n# Not a verb, or descriptive\nmy_awesome_function()\n\n# Long, but clear\nimpute_missing()\ncollapse_years()\n\nR also doesnâ€™t care about how you use white space in your functions but future readers will.\nR ä¹Ÿä¸å…³å¿ƒä½ åœ¨å‡½æ•°ä¸­å¦‚ä½•ä½¿ç”¨ç©ºç™½ï¼Œä½†æœªæ¥çš„è¯»è€…ä¼šåœ¨æ„ã€‚\nContinue to follow the rules from Chapter 4.\nè¯·ç»§ç»­éµå¾ª Chapter 4 ä¸­çš„è§„åˆ™ã€‚\nAdditionally, function() should always be followed by squiggly brackets ({}), and the contents should be indented by an additional two spaces.\næ­¤å¤–ï¼Œfunction() åé¢åº”å§‹ç»ˆç´§è·ŸèŠ±æ‹¬å· ({})ï¼Œå¹¶ä¸”å…¶ä¸­çš„å†…å®¹åº”é¢å¤–ç¼©è¿›ä¸¤ä¸ªç©ºæ ¼ã€‚\nThis makes it easier to see the hierarchy in your code by skimming the left-hand margin.\nè¿™æ ·ä¸€æ¥ï¼Œé€šè¿‡æµè§ˆä»£ç çš„å·¦è¾¹è·ï¼Œå°±å¯ä»¥æ›´å®¹æ˜“åœ°çœ‹æ¸…ä»£ç çš„å±‚çº§ç»“æ„ã€‚\n\n# Missing extra two spaces\ndensity &lt;- function(color, facets, binwidth = 0.1) {\ndiamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\n# Pipe indented incorrectly\ndensity &lt;- function(color, facets, binwidth = 0.1) {\n  diamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\nAs you can see we recommend putting extra spaces inside of {{ }}.\næ­£å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬å»ºè®®åœ¨ {{ }} å†…éƒ¨åŠ ä¸Šé¢å¤–çš„ç©ºæ ¼ã€‚\nThis makes it very obvious that something unusual is happening.\nè¿™ä½¿å¾—ä¸€äº›ä¸å¯»å¸¸çš„æ“ä½œå˜å¾—éå¸¸æ˜¾çœ¼ã€‚\n\n25.5.1 Exercises\n\n\nRead the source code for each of the following two functions, puzzle out what they do, and then brainstorm better names.\n\nf1 &lt;- function(string, prefix) {\n  str_sub(string, 1, str_length(prefix)) == prefix\n}\n\nf3 &lt;- function(x, y) {\n  rep(y, length.out = length(x))\n}\n\n\nTake a function that youâ€™ve written recently and spend 5 minutes brainstorming a better name for it and its arguments.\nMake a case for why norm_r(), norm_d() etc. would be better than rnorm(), dnorm(). Make a case for the opposite. How could you make the names even clearer?",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>25</span>Â  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#summary",
    "href": "functions.html#summary",
    "title": "25Â  Functions",
    "section": "\n25.6 Summary",
    "text": "25.6 Summary\nIn this chapter, you learned how to write functions for three useful scenarios: creating a vector, creating a data frame, or creating a plot.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•é’ˆå¯¹ä¸‰ç§æœ‰ç”¨çš„åœºæ™¯ç¼–å†™å‡½æ•°ï¼šåˆ›å»ºå‘é‡ã€åˆ›å»ºæ•°æ®æ¡†æˆ–åˆ›å»ºå›¾è¡¨ã€‚\nAlong the way you saw many examples, which hopefully started to get your creative juices flowing, and gave you some ideas for where functions might help your analysis code.\nåœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œä½ çœ‹åˆ°äº†è®¸å¤šç¤ºä¾‹ï¼Œå¸Œæœ›è¿™äº›ç¤ºä¾‹èƒ½æ¿€å‘ä½ çš„åˆ›é€ åŠ›ï¼Œå¹¶è®©ä½ å¯¹å‡½æ•°å¦‚ä½•å¸®åŠ©ä½ çš„åˆ†æä»£ç æœ‰äº†ä¸€äº›æƒ³æ³•ã€‚\nWe have only shown you the bare minimum to get started with functions and thereâ€™s much more to learn.\næˆ‘ä»¬åªå‘ä½ å±•ç¤ºäº†å‡½æ•°å…¥é—¨æ‰€éœ€çš„æœ€åŸºæœ¬çŸ¥è¯†ï¼Œè¿˜æœ‰æ›´å¤šå†…å®¹æœ‰å¾…å­¦ä¹ ã€‚\nA few places to learn more are:\nä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥æ·±å…¥å­¦ä¹ çš„åœ°æ–¹ï¼š\n\nTo learn more about programming with tidy evaluation, see useful recipes in programming with dplyr and programming with tidyr and learn more about the theory in What is data-masking and why do I need {{?.\nè¦äº†è§£æœ‰å…³ä½¿ç”¨æ•´æ´æ±‚å€¼ (tidy evaluation) ç¼–ç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… programming with dplyr å’Œ programming with tidyr ä¸­çš„å®ç”¨æ–¹æ³•ï¼Œå¹¶åœ¨ ä»€ä¹ˆæ˜¯æ•°æ®æ©ç  (data-masking) ä»¥åŠä¸ºä»€ä¹ˆæˆ‘éœ€è¦ {{? ä¸­å­¦ä¹ æ›´å¤šç›¸å…³ç†è®ºã€‚\nTo learn more about reducing duplication in your ggplot2 code, read the Programming with ggplot2 chapter of the ggplot2 book.\nè¦äº†è§£æœ‰å…³å‡å°‘ ggplot2 ä»£ç é‡å¤çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·é˜…è¯» ggplot2 ä¹¦ç±ä¸­çš„ ä½¿ç”¨ ggplot2 ç¼–ç¨‹ ä¸€ç« ã€‚\nFor more advice on function style, see the tidyverse style guide.\næœ‰å…³å‡½æ•°é£æ ¼çš„æ›´å¤šå»ºè®®ï¼Œè¯·å‚é˜… tidyverse é£æ ¼æŒ‡å—ã€‚\n\nIn the next chapter, weâ€™ll dive into iteration which gives you further tools for reducing code duplication.\nåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨è¿­ä»£ï¼Œå®ƒå°†ä¸ºä½ æä¾›æ›´å¤šå‡å°‘ä»£ç é‡å¤çš„å·¥å…·ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>25</span>Â  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "iteration.html",
    "href": "iteration.html",
    "title": "26Â  Iteration",
    "section": "",
    "text": "26.1 Introduction\nIn this chapter, youâ€™ll learn tools for iteration, repeatedly performing the same action on different objects.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å°†å­¦ä¹ è¿­ä»£çš„å·¥å…·ï¼Œå³å¯¹ä¸åŒçš„å¯¹è±¡é‡å¤æ‰§è¡Œç›¸åŒçš„æ“ä½œã€‚\nIteration in R generally tends to look rather different from other programming languages because so much of it is implicit and we get it for free.\nR ä¸­çš„è¿­ä»£é€šå¸¸çœ‹èµ·æ¥ä¸å…¶ä»–ç¼–ç¨‹è¯­è¨€å¤§ä¸ç›¸åŒï¼Œå› ä¸ºå…¶ä¸­å¾ˆå¤šæ˜¯éšå¼çš„ï¼Œæˆ‘ä»¬å¯ä»¥å…è´¹è·å¾—ã€‚\nFor example, if you want to double a numeric vector x in R, you can just write 2 * x.\nä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³åœ¨ R ä¸­å°†ä¸€ä¸ªæ•°å€¼å‘é‡ x çš„å€¼åŠ å€ï¼Œä½ åªéœ€å†™ 2 * xã€‚\nIn most other languages, youâ€™d need to explicitly double each element of x using some sort of for loop.\nåœ¨å¤§å¤šæ•°å…¶ä»–è¯­è¨€ä¸­ï¼Œä½ éœ€è¦ä½¿ç”¨æŸç§ for å¾ªç¯æ¥æ˜¾å¼åœ°å°† x çš„æ¯ä¸ªå…ƒç´ åŠ å€ã€‚\nThis book has already given you a small but powerful number of tools that perform the same action for multiple â€œthingsâ€:\næœ¬ä¹¦å·²ç»ä¸ºä½ æä¾›äº†ä¸€äº›å°è€Œå¼ºå¤§çš„å·¥å…·ï¼Œå¯ä»¥å¯¹å¤šä¸ªâ€œäº‹ç‰©â€æ‰§è¡Œç›¸åŒçš„æ“ä½œï¼š\nNow itâ€™s time to learn some more general tools, often called functional programming tools because they are built around functions that take other functions as inputs.\nç°åœ¨æ˜¯æ—¶å€™å­¦ä¹ ä¸€äº›æ›´é€šç”¨çš„å·¥å…·äº†ï¼Œè¿™äº›å·¥å…·é€šå¸¸è¢«ç§°ä¸ºå‡½æ•°å¼ç¼–ç¨‹ (functional programming) å·¥å…·ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å›´ç»•ç€æ¥å—å…¶ä»–å‡½æ•°ä½œä¸ºè¾“å…¥çš„å‡½æ•°æ„å»ºçš„ã€‚\nLearning functional programming can easily veer into the abstract, but in this chapter weâ€™ll keep things concrete by focusing on three common tasks: modifying multiple columns, reading multiple files, and saving multiple objects.\nå­¦ä¹ å‡½æ•°å¼ç¼–ç¨‹å¾ˆå®¹æ˜“å˜å¾—æŠ½è±¡ï¼Œä½†åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡å…³æ³¨ä¸‰ä¸ªå¸¸è§ä»»åŠ¡æ¥ä¿æŒå…·ä½“æ€§ï¼šä¿®æ”¹å¤šä¸ªåˆ—ã€è¯»å–å¤šä¸ªæ–‡ä»¶å’Œä¿å­˜å¤šä¸ªå¯¹è±¡ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>26</span>Â  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#introduction",
    "href": "iteration.html#introduction",
    "title": "26Â  Iteration",
    "section": "",
    "text": "facet_wrap() and facet_grid() draws a plot for each subset.facet_wrap() å’Œ facet_grid() ä¸ºæ¯ä¸ªå­é›†ç»˜åˆ¶ä¸€å¼ å›¾ã€‚\ngroup_by() plus summarize() computes summary statistics for each subset.group_by() åŠ ä¸Š summarize() ä¸ºæ¯ä¸ªå­é›†è®¡ç®—æ±‡æ€»ç»Ÿè®¡é‡ã€‚\nunnest_wider() and unnest_longer() create new rows and columns for each element of a list-column.unnest_wider() å’Œ unnest_longer() ä¸ºåˆ—è¡¨åˆ—çš„æ¯ä¸ªå…ƒç´ åˆ›å»ºæ–°çš„è¡Œå’Œåˆ—ã€‚\n\n\n\n\n26.1.1 Prerequisites\nIn this chapter, weâ€™ll focus on tools provided by dplyr and purrr, both core members of the tidyverse.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»ç”± dplyr å’Œ purrr æä¾›çš„å·¥å…·ï¼Œå®ƒä»¬éƒ½æ˜¯ tidyverse çš„æ ¸å¿ƒæˆå‘˜ã€‚\nYouâ€™ve seen dplyr before, but purrr is new.\nä½ ä¹‹å‰è§è¿‡ dplyrï¼Œä½† purrr æ˜¯æ–°çš„ã€‚\nWeâ€™re just going to use a couple of purrr functions in this chapter, but itâ€™s a great package to explore as you improve your programming skills.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬åªä¼šä½¿ç”¨å‡ ä¸ª purrr å‡½æ•°ï¼Œä½†éšç€ä½ ç¼–ç¨‹æŠ€èƒ½çš„æé«˜ï¼Œå®ƒæ˜¯ä¸€ä¸ªéå¸¸å€¼å¾—æ¢ç´¢çš„åŒ…ã€‚\n\nlibrary(tidyverse)",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>26</span>Â  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#sec-across",
    "href": "iteration.html#sec-across",
    "title": "26Â  Iteration",
    "section": "\n26.2 Modifying multiple columns",
    "text": "26.2 Modifying multiple columns\nImagine you have this simple tibble and you want to count the number of observations and compute the median of every column.\nå‡è®¾ä½ æœ‰è¿™ä¸ªç®€å•çš„ tibbleï¼Œå¹¶ä¸”ä½ æƒ³è¦è®¡ç®—è§‚æµ‹å€¼çš„æ•°é‡å¹¶è®¡ç®—æ¯ä¸€åˆ—çš„ä¸­ä½æ•°ã€‚\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nYou could do it with copy-and-paste:\nä½ å¯ä»¥é€šè¿‡å¤åˆ¶ç²˜è´´æ¥å®Œæˆï¼š\n\ndf |&gt; summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n#&gt; # A tibble: 1 Ã— 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nThat breaks our rule of thumb to never copy and paste more than twice, and you can imagine that this will get very tedious if you have tens or even hundreds of columns.\nè¿™è¿åäº†æˆ‘ä»¬â€œç»ä¸å¤åˆ¶ç²˜è´´è¶…è¿‡ä¸¤æ¬¡â€çš„ç»éªŒæ³•åˆ™ï¼Œè€Œä¸”ä½ å¯ä»¥æƒ³è±¡ï¼Œå¦‚æœä½ æœ‰å‡ åç”šè‡³å‡ ç™¾åˆ—ï¼Œè¿™å°†å˜å¾—éå¸¸ç¹çã€‚\nInstead, you can use across():\nç›¸åï¼Œä½ å¯ä»¥ä½¿ç”¨ across()ï¼š\n\ndf |&gt; summarize(\n  n = n(),\n  across(a:d, median),\n)\n#&gt; # A tibble: 1 Ã— 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nacross() has three particularly important arguments, which weâ€™ll discuss in detail in the following sections.across() æœ‰ä¸‰ä¸ªç‰¹åˆ«é‡è¦çš„å‚æ•°ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†è¯¦ç»†è®¨è®ºã€‚\nYouâ€™ll use the first two every time you use across(): the first argument, .cols, specifies which columns you want to iterate over, and the second argument, .fns, specifies what to do with each column.\næ¯æ¬¡ä½¿ç”¨ across() æ—¶ï¼Œä½ éƒ½ä¼šç”¨åˆ°å‰ä¸¤ä¸ªå‚æ•°ï¼šç¬¬ä¸€ä¸ªå‚æ•° .cols æŒ‡å®šäº†ä½ æƒ³è¦è¿­ä»£çš„åˆ—ï¼Œç¬¬äºŒä¸ªå‚æ•° .fns æŒ‡å®šäº†å¯¹æ¯ä¸€åˆ—åšä»€ä¹ˆã€‚\nYou can use the .names argument when you need additional control over the names of output columns, which is particularly important when you use across() with mutate().\nå½“ä½ éœ€è¦å¯¹è¾“å‡ºåˆ—çš„åç§°è¿›è¡Œé¢å¤–æ§åˆ¶æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ .names å‚æ•°ï¼Œè¿™åœ¨ä½¿ç”¨ across() å’Œ mutate() æ—¶å°¤å…¶é‡è¦ã€‚\nWeâ€™ll also discuss two important variations, if_any() and if_all(), which work with filter().\næˆ‘ä»¬è¿˜å°†è®¨è®ºä¸¤ä¸ªé‡è¦çš„å˜ä½“ï¼Œif_any() å’Œ if_all()ï¼Œå®ƒä»¬ä¸ filter() ä¸€èµ·ä½¿ç”¨ã€‚\n\n26.2.1 Selecting columns with .cols\n\nThe first argument to across(), .cols, selects the columns to transform.across() çš„ç¬¬ä¸€ä¸ªå‚æ•° .cols ç”¨äºé€‰æ‹©è¦è½¬æ¢çš„åˆ—ã€‚\nThis uses the same specifications as select(), Section 3.3.2, so you can use functions like starts_with() and ends_with() to select columns based on their name.\nå®ƒä½¿ç”¨ä¸ select() ç›¸åŒçš„è§„èŒƒï¼Œè§ Section 3.3.2ï¼Œæ‰€ä»¥ä½ å¯ä»¥ä½¿ç”¨åƒ starts_with() å’Œ ends_with() è¿™æ ·çš„å‡½æ•°æ¥æ ¹æ®åˆ—åé€‰æ‹©åˆ—ã€‚\nThere are two additional selection techniques that are particularly useful for across(): everything() and where().\nè¿˜æœ‰ä¸¤ç§é¢å¤–çš„é€‰æ‹©æŠ€æœ¯å¯¹ across() ç‰¹åˆ«æœ‰ç”¨ï¼ševerything() å’Œ where()ã€‚\neverything() is straightforward: it selects every (non-grouping) column:everything() å¾ˆç›´æ¥ï¼šå®ƒé€‰æ‹©æ¯ä¸€ä¸ªï¼ˆéåˆ†ç»„ï¼‰åˆ—ï¼š\n\ndf &lt;- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median))\n#&gt; # A tibble: 2 Ã— 5\n#&gt;     grp       a       b     c     d\n#&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1 -0.0935 -0.0163 0.363 0.364\n#&gt; 2     2  0.312  -0.0576 0.208 0.565\n\nNote grouping columns (grp here) are not included in across(), because theyâ€™re automatically preserved by summarize().\næ³¨æ„åˆ†ç»„åˆ—ï¼ˆæ­¤å¤„çš„ grpï¼‰ä¸åŒ…å«åœ¨ across() ä¸­ï¼Œå› ä¸ºå®ƒä»¬è¢« summarize() è‡ªåŠ¨ä¿ç•™äº†ã€‚\nwhere() allows you to select columns based on their type:where() å…è®¸ä½ æ ¹æ®åˆ—çš„ç±»å‹æ¥é€‰æ‹©åˆ—ï¼š\n\nwhere(is.numeric) selects all numeric columns.where(is.numeric) é€‰æ‹©æ‰€æœ‰æ•°å€¼å‹åˆ—ã€‚\nwhere(is.character) selects all string columns.where(is.character) é€‰æ‹©æ‰€æœ‰å­—ç¬¦å‹åˆ—ã€‚\nwhere(is.Date) selects all date columns.where(is.Date) é€‰æ‹©æ‰€æœ‰æ—¥æœŸå‹åˆ—ã€‚\nwhere(is.POSIXct) selects all date-time columns.where(is.POSIXct) é€‰æ‹©æ‰€æœ‰æ—¥æœŸæ—¶é—´å‹åˆ—ã€‚\nwhere(is.logical) selects all logical columns.where(is.logical) é€‰æ‹©æ‰€æœ‰é€»è¾‘å‹åˆ—ã€‚\n\nJust like other selectors, you can combine these with Boolean algebra.\nå°±åƒå…¶ä»–é€‰æ‹©å™¨ä¸€æ ·ï¼Œä½ å¯ä»¥å°†å®ƒä»¬ä¸å¸ƒå°”ä»£æ•°ç»“åˆä½¿ç”¨ã€‚\nFor example, !where(is.numeric) selects all non-numeric columns, and starts_with(\"a\") & where(is.logical) selects all logical columns whose name starts with â€œaâ€.\nä¾‹å¦‚ï¼Œ!where(is.numeric) é€‰æ‹©æ‰€æœ‰éæ•°å€¼å‹åˆ—ï¼Œè€Œ starts_with(\"a\") & where(is.logical) é€‰æ‹©æ‰€æœ‰åç§°ä»¥ â€œaâ€ å¼€å¤´çš„é€»è¾‘å‹åˆ—ã€‚\n\n26.2.2 Calling a single function\nThe second argument to across() defines how each column will be transformed.across() çš„ç¬¬äºŒä¸ªå‚æ•°å®šä¹‰äº†æ¯ä¸€åˆ—å°†å¦‚ä½•è¢«è½¬æ¢ã€‚\nIn simple cases, as above, this will be a single existing function.\nåœ¨ç®€å•çš„æƒ…å†µä¸‹ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªå•ä¸€çš„ç°æœ‰å‡½æ•°ã€‚\nThis is a pretty special feature of R: weâ€™re passing one function (median, mean, str_flatten, â€¦) to another function (across).\nè¿™æ˜¯ R çš„ä¸€ä¸ªç›¸å½“ç‰¹æ®Šçš„ç‰¹æ€§ï¼šæˆ‘ä»¬å°†ä¸€ä¸ªå‡½æ•°ï¼ˆmedianã€meanã€str_flatten ç­‰ï¼‰ä¼ é€’ç»™å¦ä¸€ä¸ªå‡½æ•° (across)ã€‚\nThis is one of the features that makes R a functional programming language.\nè¿™æ˜¯ä½¿ R æˆä¸ºä¸€é—¨å‡½æ•°å¼ç¼–ç¨‹è¯­è¨€çš„ç‰¹æ€§ä¹‹ä¸€ã€‚\nItâ€™s important to note that weâ€™re passing this function to across(), so across() can call it; weâ€™re not calling it ourselves.\né‡è¦çš„æ˜¯è¦æ³¨æ„ï¼Œæˆ‘ä»¬æ˜¯å°†è¿™ä¸ªå‡½æ•°ä¼ é€’ç»™ across()ï¼Œä»¥ä¾¿ across() å¯ä»¥è°ƒç”¨å®ƒï¼›æˆ‘ä»¬ä¸æ˜¯è‡ªå·±è°ƒç”¨å®ƒã€‚\nThat means the function name should never be followed by ().\nè¿™æ„å‘³ç€å‡½æ•°ååé¢ä¸åº”è¯¥è·Ÿ ()ã€‚\nIf you forget, youâ€™ll get an error:\nå¦‚æœä½ å¿˜äº†ï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ªé”™è¯¯ï¼š\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median()))\n#&gt; Error in `summarize()`:\n#&gt; â„¹ In argument: `across(everything(), median())`.\n#&gt; Caused by error in `median.default()`:\n#&gt; ! argument \"x\" is missing, with no default\n\nThis error arises because youâ€™re calling the function with no input, e.g.:\nè¿™ä¸ªé”™è¯¯çš„å‡ºç°æ˜¯å› ä¸ºä½ åœ¨æ²¡æœ‰è¾“å…¥çš„æƒ…å†µä¸‹è°ƒç”¨äº†å‡½æ•°ï¼Œä¾‹å¦‚ï¼š\n\nmedian()\n#&gt; Error in median.default(): argument \"x\" is missing, with no default\n\n\n26.2.3 Calling multiple functions\nIn more complex cases, you might want to supply additional arguments or perform multiple transformations.\nåœ¨æ›´å¤æ‚çš„æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½æƒ³è¦æä¾›é¢å¤–çš„å‚æ•°æˆ–æ‰§è¡Œå¤šä¸ªè½¬æ¢ã€‚\nLetâ€™s motivate this problem with a simple example: what happens if we have some missing values in our data?\nè®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥å¼•å‡ºè¿™ä¸ªé—®é¢˜ï¼šå¦‚æœæˆ‘ä»¬çš„æ•°æ®ä¸­æœ‰ä¸€äº›ç¼ºå¤±å€¼ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\nmedian() propagates those missing values, giving us a suboptimal output:median() ä¼šä¼ æ’­è¿™äº›ç¼ºå¤±å€¼ï¼Œå¯¼è‡´ä¸€ä¸ªæ¬¡ä¼˜çš„è¾“å‡ºï¼š\n\nrnorm_na &lt;- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss &lt;- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |&gt; \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n#&gt; # A tibble: 1 Ã— 5\n#&gt;       a     b     c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    NA    NA    NA  1.15     5\n\nIt would be nice if we could pass along na.rm = TRUE to median() to remove these missing values.\nå¦‚æœæˆ‘ä»¬èƒ½å°† na.rm = TRUE ä¼ é€’ç»™ median() æ¥ç§»é™¤è¿™äº›ç¼ºå¤±å€¼ï¼Œé‚£å°±å¤ªå¥½äº†ã€‚\nTo do so, instead of calling median() directly, we need to create a new function that calls median() with the desired arguments:\nè¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥è°ƒç”¨ median()ï¼Œè€Œæ˜¯éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°å‡½æ•°ï¼Œç”¨æ‰€éœ€çš„å‚æ•°æ¥è°ƒç”¨ median()ï¼š\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n#&gt; # A tibble: 1 Ã— 5\n#&gt;       a     b      c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 0.139 -1.11 -0.387  1.15     5\n\nThis is a little verbose, so R comes with a handy shortcut: for this sort of throw away, or anonymous[^6], function you can replace function with \\[^7]:\nè¿™æœ‰ç‚¹å†—é•¿ï¼Œæ‰€ä»¥ R æä¾›äº†ä¸€ä¸ªæ–¹ä¾¿çš„å¿«æ·æ–¹å¼ï¼šå¯¹äºè¿™ç§ä¸€æ¬¡æ€§ä½¿ç”¨çš„ï¼Œæˆ–è€…è¯´åŒ¿å (anonymous)6 çš„å‡½æ•°ï¼Œä½ å¯ä»¥ç”¨ \\ æ›¿æ¢ function7ï¼š\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\nIn either case, across() effectively expands to the following code:\nåœ¨ä»»ä½•ä¸€ç§æƒ…å†µä¸‹ï¼Œacross() å®é™…ä¸Šéƒ½ç­‰åŒäºå±•å¼€æˆä»¥ä¸‹ä»£ç ï¼š\n\ndf_miss |&gt; \n  summarize(\n    a = median(a, na.rm = TRUE),\n    b = median(b, na.rm = TRUE),\n    c = median(c, na.rm = TRUE),\n    d = median(d, na.rm = TRUE),\n    n = n()\n  )\n\nWhen we remove the missing values from the median(), it would be nice to know just how many values were removed.\nå½“æˆ‘ä»¬ä» median() ä¸­ç§»é™¤ç¼ºå¤±å€¼æ—¶ï¼Œå¦‚æœèƒ½çŸ¥é“ç§»é™¤äº†å¤šå°‘ä¸ªå€¼å°±æ›´å¥½äº†ã€‚\nWe can find that out by supplying two functions to across(): one to compute the median and the other to count the missing values.\næˆ‘ä»¬å¯ä»¥é€šè¿‡å‘ across() æä¾›ä¸¤ä¸ªå‡½æ•°æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼šä¸€ä¸ªç”¨äºè®¡ç®—ä¸­ä½æ•°ï¼Œå¦ä¸€ä¸ªç”¨äºè®¡ç®—ç¼ºå¤±å€¼çš„æ•°é‡ã€‚\nYou supply multiple functions by using a named list to .fns:\nä½ å¯ä»¥é€šè¿‡ä½¿ç”¨ä¸€ä¸ªå‘½åçš„åˆ—è¡¨ä½œä¸º .fns æ¥æä¾›å¤šä¸ªå‡½æ•°ï¼š\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n#&gt; # A tibble: 1 Ã— 9\n#&gt;   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # â„¹ 1 more variable: n &lt;int&gt;\n\nIf you look carefully, you might intuit that the columns are named using a glue specification (Section 14.3.2) like {.col}_{.fn} where .col is the name of the original column and .fn is the name of the function.\nå¦‚æœä½ ä»”ç»†è§‚å¯Ÿï¼Œä½ å¯èƒ½ä¼šç›´è§‰åœ°è®¤ä¸ºåˆ—æ˜¯æ ¹æ®ä¸€ä¸ªç±»ä¼¼ {.col}_{.fn} çš„ glue è§„èŒƒ (Section 14.3.2) æ¥å‘½åçš„ï¼Œå…¶ä¸­ .col æ˜¯åŸå§‹åˆ—çš„åç§°ï¼Œ.fn æ˜¯å‡½æ•°çš„åç§°ã€‚\nThatâ€™s not a coincidence!\né‚£ä¸æ˜¯å·§åˆï¼\nAs youâ€™ll learn in the next section, you can use the .names argument to supply your own glue spec.\næ­£å¦‚ä½ å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­å­¦åˆ°çš„ï¼Œä½ å¯ä»¥ä½¿ç”¨ .names å‚æ•°æ¥æä¾›ä½ è‡ªå·±çš„ glue è§„èŒƒã€‚\n\n26.2.4 Column names\nThe result of across() is named according to the specification provided in the .names argument.across() çš„ç»“æœæ˜¯æ ¹æ® .names å‚æ•°ä¸­æä¾›çš„è§„èŒƒæ¥å‘½åçš„ã€‚\nWe could specify our own if we wanted the name of the function to come first[^3]:\nå¦‚æœæˆ‘ä»¬å¸Œæœ›å‡½æ•°åæ’åœ¨å‰é¢ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå·±æŒ‡å®š[^3]ï¼š\n\ndf_miss |&gt; \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n#&gt; # A tibble: 1 Ã— 9\n#&gt;   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # â„¹ 1 more variable: n &lt;int&gt;\n\nThe .names argument is particularly important when you use across() with mutate().\nå½“æ‚¨å°† across() ä¸ mutate() ç»“åˆä½¿ç”¨æ—¶ï¼Œ.names å‚æ•°å°¤å…¶é‡è¦ã€‚\nBy default, the output of across() is given the same names as the inputs.\né»˜è®¤æƒ…å†µä¸‹ï¼Œacross() çš„è¾“å‡ºè¢«èµ‹äºˆä¸è¾“å…¥ç›¸åŒçš„åç§°ã€‚\nThis means that across() inside of mutate() will replace existing columns.\nè¿™æ„å‘³ç€ mutate() ä¸­çš„ across() å°†æ›¿æ¢ç°æœ‰çš„åˆ—ã€‚\nFor example, here we use coalesce() to replace NAs with 0:\nä¾‹å¦‚ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ coalesce() å°† NA æ›¿æ¢ä¸º 0ï¼š\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n#&gt; # A tibble: 5 Ã— 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25   0     1.60 \n#&gt; 2  0     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980  0     1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13 \n#&gt; 5  1.11   0     -0.387 0.704\n\nIf youâ€™d like to instead create new columns, you can use the .names argument to give the output new names:\nå¦‚æœä½ æƒ³åˆ›å»ºæ–°åˆ—ï¼Œå¯ä»¥ä½¿ç”¨ .names å‚æ•°ä¸ºè¾“å‡ºèµ‹äºˆæ–°åç§°ï¼š\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0), .names = \"{.col}_na_zero\")\n  )\n#&gt; # A tibble: 5 Ã— 8\n#&gt;        a      b      c     d a_na_zero b_na_zero c_na_zero d_na_zero\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60      0.434    -1.25      0         1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776     0        -1.43     -0.297     0.776\n#&gt; 3 -0.156 -0.980 NA     1.15     -0.156    -0.980     0         1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13     -2.61     -0.683    -0.785     2.13 \n#&gt; 5  1.11  NA     -0.387 0.704     1.11      0        -0.387     0.704\n\n\n26.2.5 Filtering\nacross() is a great match for summarize() and mutate() but itâ€™s more awkward to use with filter(), because you usually combine multiple conditions with either | or &.across() ä¸ summarize() å’Œ mutate() é…åˆå¾—å¾ˆå¥½ï¼Œä½†ä¸ filter() ä¸€èµ·ä½¿ç”¨æ—¶å°±æ¯”è¾ƒå°´å°¬ï¼Œå› ä¸ºä½ é€šå¸¸éœ€è¦ç”¨ | æˆ– & æ¥ç»„åˆå¤šä¸ªæ¡ä»¶ã€‚\nItâ€™s clear that across() can help to create multiple logical columns, but then what?\nå¾ˆæ˜æ˜¾ across() å¯ä»¥å¸®åŠ©åˆ›å»ºå¤šä¸ªé€»è¾‘åˆ—ï¼Œä½†ä¹‹åå‘¢ï¼Ÿ\nSo dplyr provides two variants of across() called if_any() and if_all():\nå› æ­¤ dplyr æä¾›äº† across() çš„ä¸¤ä¸ªå˜ä½“ï¼Œåä¸º if_any() å’Œ if_all()ï¼š\n\n# same as df_miss |&gt; filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\ndf_miss |&gt; filter(if_any(a:d, is.na))\n#&gt; # A tibble: 4 Ã— 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980 NA     1.15 \n#&gt; 4  1.11  NA     -0.387 0.704\n\n# same as df_miss |&gt; filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\ndf_miss |&gt; filter(if_all(a:d, is.na))\n#&gt; # A tibble: 0 Ã— 4\n#&gt; # â„¹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n\n26.2.6 across() in functions\nacross() is particularly useful to program with because it allows you to operate on multiple columns.across() åœ¨ç¼–ç¨‹ä¸­ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºå®ƒå…è®¸ä½ å¯¹å¤šä¸ªåˆ—è¿›è¡Œæ“ä½œã€‚\nFor example, Jacob Scott uses this little helper which wraps a bunch of lubridate functions to expand all date columns into year, month, and day columns:\nä¾‹å¦‚ï¼ŒJacob Scott ä½¿ç”¨è¿™ä¸ªå°è¾…åŠ©å‡½æ•°ï¼Œå®ƒå°è£…äº†ä¸€ç³»åˆ— lubridate å‡½æ•°ï¼Œå°†æ‰€æœ‰æ—¥æœŸåˆ—æ‰©å±•ä¸ºå¹´ã€æœˆã€æ—¥åˆ—ï¼š\n\nexpand_dates &lt;- function(df) {\n  df |&gt; \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date &lt;- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |&gt; \n  expand_dates()\n#&gt; # A tibble: 2 Ã— 5\n#&gt;   name  date       date_year date_month date_day\n#&gt;   &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 Amy   2009-08-03      2009          8        3\n#&gt; 2 Bob   2010-01-16      2010          1       16\n\nacross() also makes it easy to supply multiple columns in a single argument because the first argument uses tidy-select; you just need to remember to embrace that argument, as we discussed in Section 25.3.2.across() ä¹Ÿä½¿å¾—åœ¨å•ä¸ªå‚æ•°ä¸­æä¾›å¤šä¸ªåˆ—å˜å¾—å®¹æ˜“ï¼Œå› ä¸ºç¬¬ä¸€ä¸ªå‚æ•°ä½¿ç”¨äº†æ•´æ´é€‰æ‹©ï¼ˆtidy-selectï¼‰ï¼›ä½ åªéœ€è¦è®°ä½æ‹¥æŠ±ï¼ˆembraceï¼‰é‚£ä¸ªå‚æ•°ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ Section 25.3.2 ä¸­è®¨è®ºçš„é‚£æ ·ã€‚\nFor example, this function will compute the means of numeric columns by default.\nä¾‹å¦‚ï¼Œè¿™ä¸ªå‡½æ•°é»˜è®¤ä¼šè®¡ç®—æ•°å€¼åˆ—çš„å‡å€¼ã€‚\nBut by supplying the second argument you can choose to summarize just selected columns:\nä½†é€šè¿‡æä¾›ç¬¬äºŒä¸ªå‚æ•°ï¼Œä½ å¯ä»¥é€‰æ‹©åªå¯¹é€‰å®šçš„åˆ—è¿›è¡Œæ±‡æ€»ï¼š\n\nsummarize_means &lt;- function(df, summary_vars = where(is.numeric)) {\n  df |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means()\n#&gt; # A tibble: 5 Ã— 9\n#&gt;   cut       carat depth table price     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means(c(carat, x:z))\n#&gt; # A tibble: 5 Ã— 6\n#&gt;   cut       carat     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  5.51  5.52  3.40 21551\n\n\n26.2.7 Compare with pivot_longer()\n\nBefore we go on, itâ€™s worth pointing out an interesting connection between across() and pivot_longer() (Section 5.3). In many cases, you perform the same calculations by first pivoting the data and then performing the operations by group rather than by column. For example, take this multi-function summary:\nåœ¨æˆ‘ä»¬ç»§ç»­ä¹‹å‰ï¼Œæœ‰å¿…è¦æŒ‡å‡º across() å’Œ pivot_longer() (Section 5.3) ä¹‹é—´ä¸€ä¸ªæœ‰è¶£çš„è”ç³»ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œä½ å¯ä»¥é€šè¿‡å…ˆè½¬æ¢æ•°æ®ï¼Œç„¶åæŒ‰ç»„è€Œä¸æ˜¯æŒ‰åˆ—æ‰§è¡Œæ“ä½œæ¥å®Œæˆç›¸åŒçš„è®¡ç®—ã€‚ä¾‹å¦‚ï¼Œçœ‹è¿™ä¸ªå¤šå‡½æ•°æ‘˜è¦ï¼š\n\ndf |&gt; \n  summarize(across(a:d, list(median = median, mean = mean)))\n#&gt; # A tibble: 1 Ã— 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\nWe could compute the same values by pivoting longer and then summarizing:\næˆ‘ä»¬å¯ä»¥é€šè¿‡å…ˆåŠ é•¿æ•°æ®å†è¿›è¡Œæ±‡æ€»æ¥è®¡ç®—ç›¸åŒçš„å€¼ï¼š\n\nlong &lt;- df |&gt; \n  pivot_longer(a:d) |&gt; \n  group_by(name) |&gt; \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n#&gt; # A tibble: 4 Ã— 3\n#&gt;   name   median   mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 a      0.0380 0.205 \n#&gt; 2 b     -0.0163 0.0910\n#&gt; 3 c      0.260  0.0716\n#&gt; 4 d      0.540  0.508\n\nAnd if you wanted the same structure as across() you could pivot again:\nå¦‚æœä½ æƒ³è¦å’Œ across() ä¸€æ ·çš„ç»“æ„ï¼Œä½ å¯ä»¥å†æ¬¡è¿›è¡Œè½¬æ¢ï¼š\n\nlong |&gt; \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n#&gt; # A tibble: 1 Ã— 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\nThis is a useful technique to know about because sometimes youâ€™ll hit a problem thatâ€™s not currently possible to solve with across(): when you have groups of columns that you want to compute with simultaneously. For example, imagine that our data frame contains both values and weights and we want to compute a weighted mean:\nè¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰ç”¨çš„æŠ€å·§ï¼Œå› ä¸ºæœ‰æ—¶ä½ ä¼šé‡åˆ°ä¸€ä¸ªç›®å‰æ— æ³•ç”¨ across() è§£å†³çš„é—®é¢˜ï¼šå½“ä½ æœ‰å¤šç»„åˆ—éœ€è¦åŒæ—¶è¿›è¡Œè®¡ç®—æ—¶ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬çš„æ•°æ®æ¡†åŒæ—¶åŒ…å«å€¼å’Œæƒé‡ï¼Œæˆ‘ä»¬æƒ³è¦è®¡ç®—åŠ æƒå¹³å‡å€¼ï¼š\n\ndf_paired &lt;- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n\nThereâ€™s currently no way to do this with across()[^4], but itâ€™s relatively straightforward with pivot_longer():\nç›®å‰æ²¡æœ‰åŠæ³•ç”¨ across() åšåˆ°è¿™ä¸€ç‚¹4ï¼Œä½†ç”¨ pivot_longer() å°±ç›¸å¯¹ç›´æ¥äº†ï¼š\n\ndf_long &lt;- df_paired |&gt; \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n#&gt; # A tibble: 40 Ã— 3\n#&gt;   group    val   wts\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 a      0.715 0.518\n#&gt; 2 b     -0.709 0.691\n#&gt; 3 c      0.718 0.216\n#&gt; 4 d     -0.217 0.733\n#&gt; 5 a     -1.09  0.979\n#&gt; 6 b     -0.209 0.675\n#&gt; # â„¹ 34 more rows\n\ndf_long |&gt; \n  group_by(group) |&gt; \n  summarize(mean = weighted.mean(val, wts))\n#&gt; # A tibble: 4 Ã— 2\n#&gt;   group    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a      0.126 \n#&gt; 2 b     -0.0704\n#&gt; 3 c     -0.360 \n#&gt; 4 d     -0.248\n\nIf needed, you could pivot_wider() this back to the original form.\nå¦‚æœéœ€è¦ï¼Œä½ å¯ä»¥ç”¨ pivot_wider() å°†å…¶è½¬æ¢å›åŸå§‹å½¢å¼ã€‚\n\n26.2.8 Exercises\n\n\nPractice your across() skills by:\n\nComputing the number of unique values in each column of palmerpenguins::penguins.\nComputing the mean of every column in mtcars.\nGrouping diamonds by cut, clarity, and color then counting the number of observations and computing the mean of each numeric column.\n\n\nWhat happens if you use a list of functions in across(), but donâ€™t name them? How is the output named?\nAdjust expand_dates() to automatically remove the date columns after theyâ€™ve been expanded. Do you need to embrace any arguments?\n\nExplain what each step of the pipeline in this function does. What special feature of where() are we taking advantage of?\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\nnycflights13::flights |&gt; show_missing(c(year, month, day))",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>26</span>Â  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#reading-multiple-files",
    "href": "iteration.html#reading-multiple-files",
    "title": "26Â  Iteration",
    "section": "\n26.3 Reading multiple files",
    "text": "26.3 Reading multiple files\nIn the previous section, you learned how to use dplyr::across() to repeat a transformation on multiple columns. In this section, youâ€™ll learn how to use purrr::map() to do something to every file in a directory. Letâ€™s start with a little motivation: imagine you have a directory full of excel spreadsheets[^2] you want to read. You could do it with copy and paste:\nåœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ dplyr::across() å¯¹å¤šåˆ—é‡å¤è¿›è¡Œè½¬æ¢ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ purrr::map() å¯¹ç›®å½•ä¸­çš„æ¯ä¸ªæ–‡ä»¶æ‰§è¡Œæ“ä½œã€‚è®©æˆ‘ä»¬ä»ä¸€ä¸ªå°çš„åŠ¨æœºå¼€å§‹ï¼šæƒ³è±¡ä¸€ä¸‹ï¼Œä½ æœ‰ä¸€ä¸ªè£…æ»¡äº†ä½ æƒ³è¦è¯»å–çš„ Excel ç”µå­è¡¨æ ¼çš„ç›®å½•[^2]ã€‚ä½ å¯ä»¥é€šè¿‡å¤åˆ¶ç²˜è´´æ¥å®Œæˆï¼š\n\ndata2019 &lt;- readxl::read_excel(\"data/y2019.xlsx\")\ndata2020 &lt;- readxl::read_excel(\"data/y2020.xlsx\")\ndata2021 &lt;- readxl::read_excel(\"data/y2021.xlsx\")\ndata2022 &lt;- readxl::read_excel(\"data/y2022.xlsx\")\n\nAnd then use dplyr::bind_rows() to combine them all together:\nç„¶åä½¿ç”¨ dplyr::bind_rows() å°†å®ƒä»¬å…¨éƒ¨åˆå¹¶åœ¨ä¸€èµ·ï¼š\n\ndata &lt;- bind_rows(data2019, data2020, data2021, data2022)\n\nYou can imagine that this would get tedious quickly, especially if you had hundreds of files, not just four. The following sections show you how to automate this sort of task. There are three basic steps: use list.files() to list all the files in a directory, then use purrr::map() to read each of them into a list, then use purrr::list_rbind() to combine them into a single data frame. Weâ€™ll then discuss how you can handle situations of increasing heterogeneity, where you canâ€™t do exactly the same thing to every file.\nä½ å¯ä»¥æƒ³è±¡ï¼Œè¿™å¾ˆå¿«å°±ä¼šå˜å¾—ä¹å‘³ï¼Œç‰¹åˆ«æ˜¯å¦‚æœä½ æœ‰æ•°ç™¾ä¸ªæ–‡ä»¶ï¼Œè€Œä¸ä»…ä»…æ˜¯å››ä¸ªã€‚æ¥ä¸‹æ¥çš„éƒ¨åˆ†å°†å‘ä½ å±•ç¤ºå¦‚ä½•è‡ªåŠ¨åŒ–è¿™ç±»ä»»åŠ¡ã€‚æœ‰ä¸‰ä¸ªåŸºæœ¬æ­¥éª¤ï¼šä½¿ç”¨ list.files() åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨ purrr::map() å°†æ¯ä¸ªæ–‡ä»¶è¯»å…¥ä¸€ä¸ªåˆ—è¡¨ï¼Œå†ä½¿ç”¨ purrr::list_rbind() å°†å®ƒä»¬åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„æ•°æ®æ¡†ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•å¤„ç†å¼‚è´¨æ€§å¢åŠ çš„æƒ…å†µï¼Œå³ä½ ä¸èƒ½å¯¹æ¯ä¸ªæ–‡ä»¶éƒ½åšå®Œå…¨ç›¸åŒçš„äº‹æƒ…ã€‚\n\n26.3.1 Listing files in a directory\nAs the name suggests, list.files() lists the files in a directory. Youâ€™ll almost always use three arguments:\né¡¾åæ€ä¹‰ï¼Œlist.files() ä¼šåˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶ã€‚ä½ å‡ ä¹æ€»æ˜¯ä¼šä½¿ç”¨ä¸‰ä¸ªå‚æ•°ï¼š\n\nThe first argument, path, is the directory to look in.\nç¬¬ä¸€ä¸ªå‚æ•° path æ˜¯è¦æŸ¥æ‰¾çš„ç›®å½•ã€‚\npattern is a regular expression used to filter the file names. The most common pattern is something like [.]xlsx$ or [.]csv$ to find all files with a specified extension.pattern æ˜¯ä¸€ä¸ªç”¨äºç­›é€‰æ–‡ä»¶åçš„æ­£åˆ™è¡¨è¾¾å¼ã€‚æœ€å¸¸è§çš„æ¨¡å¼æ˜¯åƒ [.]xlsx$ æˆ– [.]csv$ è¿™æ ·çš„ï¼Œç”¨æ¥æŸ¥æ‰¾æ‰€æœ‰å…·æœ‰æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶ã€‚\nfull.names determines whether or not the directory name should be included in the output.\nYou almost always want this to be TRUE.full.names å†³å®šäº†ç›®å½•åæ˜¯å¦åº”åŒ…å«åœ¨è¾“å‡ºä¸­ã€‚ä½ å‡ ä¹æ€»æ˜¯å¸Œæœ›è¿™ä¸ªå€¼ä¸º TRUEã€‚\n\nTo make our motivating example concrete, this book contains a folder with 12 excel spreadsheets containing data from the gapminder package. Each file contains one yearâ€™s worth of data for 142 countries. We can list them all with the appropriate call to list.files():\nä¸ºäº†è®©æˆ‘ä»¬çš„æ¿€åŠ±ç¤ºä¾‹æ›´å…·ä½“ï¼Œæœ¬ä¹¦åŒ…å«ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œé‡Œé¢æœ‰ 12 ä¸ª Excel ç”µå­è¡¨æ ¼ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ª gapminder åŒ…çš„æ•°æ®ã€‚æ¯ä¸ªæ–‡ä»¶åŒ…å« 142 ä¸ªå›½å®¶ä¸€å¹´çš„æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¯¹ list.files() çš„é€‚å½“è°ƒç”¨æ¥åˆ—å‡ºæ‰€æœ‰è¿™äº›æ–‡ä»¶ï¼š\n\npaths &lt;- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\npaths\n#&gt;  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#&gt;  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#&gt;  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#&gt;  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#&gt;  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#&gt; [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n\n26.3.2 Lists\nNow that we have these 12 paths, we could call read_excel() 12 times to get 12 data frames:\nç°åœ¨æˆ‘ä»¬æœ‰äº†è¿™ 12 ä¸ªè·¯å¾„ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨ read_excel() 12 æ¬¡æ¥è·å– 12 ä¸ªæ•°æ®æ¡†ï¼š\n\ngapminder_1952 &lt;- readxl::read_excel(\"data/gapminder/1952.xlsx\")\ngapminder_1957 &lt;- readxl::read_excel(\"data/gapminder/1957.xlsx\")\ngapminder_1962 &lt;- readxl::read_excel(\"data/gapminder/1962.xlsx\")\n  ...,\ngapminder_2007 &lt;- readxl::read_excel(\"data/gapminder/2007.xlsx\")\n\nBut putting each sheet into its own variable is going to make it hard to work with them a few steps down the road. Instead, theyâ€™ll be easier to work with if we put them into a single object. A list is the perfect tool for this job:\nä½†æ˜¯ï¼Œå°†æ¯ä¸ªå·¥ä½œè¡¨æ”¾å…¥å…¶è‡ªå·±çš„å˜é‡ä¸­ï¼Œä¼šåœ¨åç»­æ­¥éª¤ä¸­éš¾ä»¥å¤„ç†ã€‚ç›¸åï¼Œå¦‚æœæˆ‘ä»¬å°†å®ƒä»¬æ”¾å…¥ä¸€ä¸ªå•ä¸€çš„å¯¹è±¡ä¸­ï¼Œå¤„ç†èµ·æ¥ä¼šæ›´å®¹æ˜“ã€‚åˆ—è¡¨ (list) æ˜¯å®Œæˆè¿™é¡¹å·¥ä½œçš„å®Œç¾å·¥å…·ï¼š\n\nfiles &lt;- list(\n  readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nNow that you have these data frames in a list, how do you get one out? You can use files[[i]] to extract the i&lt;sup&gt;th&lt;/sup&gt; element:\nç°åœ¨ä½ å·²ç»å°†è¿™äº›æ•°æ®æ¡†æ”¾åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­äº†ï¼Œä½ è¯¥å¦‚ä½•å–å‡ºä¸€ä¸ªå‘¢ï¼Ÿä½ å¯ä»¥ä½¿ç”¨ files[[i]] æ¥æå–ç¬¬ i&lt;sup&gt;th&lt;/sup&gt; ä¸ªå…ƒç´ ï¼š\n\nfiles[[3]]\n#&gt; # A tibble: 142 Ã— 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # â„¹ 136 more rows\n\nWeâ€™ll come back to [[ in more detail in Section 27.3.\næˆ‘ä»¬å°†åœ¨ Section 27.3 ä¸­æ›´è¯¦ç»†åœ°å›è¿‡å¤´æ¥è®¨è®º [[ã€‚\n\n26.3.3 purrr::map() and list_rbind()\n\nThe code to collect those data frames in a list â€œby handâ€ is basically just as tedious to type as code that reads the files one-by-one. Happily, we can use purrr::map() to make even better use of our paths vector. map() is similar toacross(), but instead of doing something to each column in a data frame, it does something to each element of a vector.map(x, f) is shorthand for:\nâ€œæ‰‹åŠ¨â€æ”¶é›†é‚£äº›æ•°æ®æ¡†åˆ°åˆ—è¡¨ä¸­çš„ä»£ç ï¼ŒåŸºæœ¬ä¸Šå’Œé€ä¸ªè¯»å–æ–‡ä»¶çš„ä»£ç ä¸€æ ·ä¹å‘³ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ purrr::map() æ¥æ›´å¥½åœ°åˆ©ç”¨æˆ‘ä»¬çš„ paths å‘é‡ã€‚map() ç±»ä¼¼äº across()ï¼Œä½†å®ƒä¸æ˜¯å¯¹æ•°æ®æ¡†çš„æ¯ä¸€åˆ—æ‰§è¡Œæ“ä½œï¼Œè€Œæ˜¯å¯¹å‘é‡çš„æ¯ä¸ªå…ƒç´ æ‰§è¡Œæ“ä½œã€‚map(x, f) æ˜¯ä»¥ä¸‹ä»£ç çš„ç®€å†™ï¼š\n\nlist(\n  f(x[[1]]),\n  f(x[[2]]),\n  ...,\n  f(x[[n]])\n)\n\nSo we can use map() to get a list of 12 data frames:\næ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ map() æ¥å¾—åˆ°ä¸€ä¸ªåŒ…å« 12 ä¸ªæ•°æ®æ¡†çš„åˆ—è¡¨ï¼š\n\nfiles &lt;- map(paths, readxl::read_excel)\nlength(files)\n#&gt; [1] 12\n\nfiles[[1]]\n#&gt; # A tibble: 142 Ã— 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # â„¹ 136 more rows\n\n(This is another data structure that doesnâ€™t display particularly compactly with str() so you might want to load it into RStudio and inspect it with View()).\nï¼ˆè¿™æ˜¯å¦ä¸€ä¸ªç”¨ str() æ˜¾ç¤ºä¸å¤Ÿç´§å‡‘çš„æ•°æ®ç»“æ„ï¼Œæ‰€ä»¥ä½ å¯èƒ½æƒ³å°†å®ƒåŠ è½½åˆ° RStudio ä¸­å¹¶ç”¨ View() æ¥æ£€æŸ¥å®ƒï¼‰ã€‚\nNow we can use purrr::list_rbind() to combine that list of data frames into a single data frame:\nç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ purrr::list_rbind() å°†é‚£ä¸ªæ•°æ®æ¡†åˆ—è¡¨åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„æ•°æ®æ¡†ï¼š\n\nlist_rbind(files)\n#&gt; # A tibble: 1,704 Ã— 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # â„¹ 1,698 more rows\n\nOr we could do both steps at once in a pipeline:\næˆ–è€…æˆ‘ä»¬å¯ä»¥åœ¨ä¸€ä¸ªç®¡é“ä¸­ä¸€æ¬¡æ€§å®Œæˆè¿™ä¸¤ä¸ªæ­¥éª¤ï¼š\n\npaths |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind()\n\nWhat if we want to pass in extra arguments to read_excel()? We use the same technique that we used with across(). For example, itâ€™s often useful to peek at the first few rows of the data with n_max = 1:\nå¦‚æœæˆ‘ä»¬æƒ³ç»™ read_excel() ä¼ é€’é¢å¤–çš„å‚æ•°æ€ä¹ˆåŠï¼Ÿæˆ‘ä»¬ä½¿ç”¨ä¸ across() ç›¸åŒçš„æŠ€æœ¯ã€‚ä¾‹å¦‚ï¼Œç”¨ n_max = 1 æ¥æŸ¥çœ‹æ•°æ®çš„å‰å‡ è¡Œé€šå¸¸å¾ˆæœ‰ç”¨ï¼š\n\npaths |&gt; \n  map(\\(path) readxl::read_excel(path, n_max = 1)) |&gt; \n  list_rbind()\n#&gt; # A tibble: 12 Ã— 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Afghanistan Asia         30.3  9240934      821.\n#&gt; 3 Afghanistan Asia         32.0 10267083      853.\n#&gt; 4 Afghanistan Asia         34.0 11537966      836.\n#&gt; 5 Afghanistan Asia         36.1 13079460      740.\n#&gt; 6 Afghanistan Asia         38.4 14880372      786.\n#&gt; # â„¹ 6 more rows\n\nThis makes it clear that something is missing: thereâ€™s no year column because that value is recorded in the path, not in the individual files. Weâ€™ll tackle that problem next.\nè¿™æ¸…æ¥šåœ°è¡¨æ˜æœ‰äº›ä¸œè¥¿ä¸¢å¤±äº†ï¼šæ²¡æœ‰ year åˆ—ï¼Œå› ä¸ºè¯¥å€¼è®°å½•åœ¨è·¯å¾„ä¸­ï¼Œè€Œä¸æ˜¯åœ¨å•ä¸ªæ–‡ä»¶ä¸­ã€‚æˆ‘ä»¬æ¥ä¸‹æ¥å°†è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\n\n26.3.4 Data in the path\nSometimes the name of the file is data itself. In this example, the file name contains the year, which is not otherwise recorded in the individual files. To get that column into the final data frame, we need to do two things:\næœ‰æ—¶æ–‡ä»¶åæœ¬èº«å°±æ˜¯æ•°æ®ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ–‡ä»¶ååŒ…å«äº†å¹´ä»½ï¼Œè€Œè¿™ä¸ªä¿¡æ¯åœ¨å•ä¸ªæ–‡ä»¶ä¸­å¹¶æ²¡æœ‰è®°å½•ã€‚ä¸ºäº†å°†è¿™ä¸€åˆ—åŠ å…¥åˆ°æœ€ç»ˆçš„æ•°æ®æ¡†ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åšä¸¤ä»¶äº‹ï¼š\nFirst, we name the vector of paths. The easiest way to do this is with the set_names() function, which can take a function. Here we use basename() to extract just the file name from the full path:\né¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºè·¯å¾„å‘é‡å‘½åã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ set_names() å‡½æ•°ï¼Œå®ƒå¯ä»¥æ¥å—ä¸€ä¸ªå‡½æ•°ä½œä¸ºå‚æ•°ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ basename() ä»å®Œæ•´è·¯å¾„ä¸­æå–æ–‡ä»¶åï¼š\n\npaths |&gt; set_names(basename) \n#&gt;                  1952.xlsx                  1957.xlsx \n#&gt; \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n#&gt;                  1962.xlsx                  1967.xlsx \n#&gt; \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n#&gt;                  1972.xlsx                  1977.xlsx \n#&gt; \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n#&gt;                  1982.xlsx                  1987.xlsx \n#&gt; \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n#&gt;                  1992.xlsx                  1997.xlsx \n#&gt; \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n#&gt;                  2002.xlsx                  2007.xlsx \n#&gt; \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\nThose names are automatically carried along by all the map functions, so the list of data frames will have those same names:\nè¿™äº›åç§°ä¼šè‡ªåŠ¨è¢«æ‰€æœ‰ map å‡½æ•°æ²¿ç”¨ï¼Œæ‰€ä»¥æ•°æ®æ¡†åˆ—è¡¨ä¹Ÿä¼šæœ‰ç›¸åŒçš„åç§°ï¼š\n\nfiles &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel)\n\nThat makes this call to map() shorthand for:\nè¿™ä½¿å¾—å¯¹ map() çš„è°ƒç”¨æˆä¸ºä»¥ä¸‹ä»£ç çš„ç®€å†™ï¼š\n\nfiles &lt;- list(\n  \"1952.xlsx\" = readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  \"1957.xlsx\" = readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  \"1962.xlsx\" = readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  \"2007.xlsx\" = readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nYou can also use [[ to extract elements by name:\nä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ [[ æŒ‰åç§°æå–å…ƒç´ ï¼š\n\nfiles[[\"1962.xlsx\"]]\n#&gt; # A tibble: 142 Ã— 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # â„¹ 136 more rows\n\nThen we use the names_to argument to list_rbind() to tell it to save the names into a new column called year then use readr::parse_number() to extract the number from the string.\nç„¶åæˆ‘ä»¬ä½¿ç”¨ list_rbind() çš„ names_to å‚æ•°ï¼Œå‘Šè¯‰å®ƒå°†åç§°ä¿å­˜åˆ°ä¸€ä¸ªåä¸º year çš„æ–°åˆ—ä¸­ï¼Œç„¶åä½¿ç”¨ readr::parse_number() ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—ã€‚\n\npaths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n#&gt; # A tibble: 1,704 Ã— 6\n#&gt;    year country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  1952 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2  1952 Albania     Europe       55.2  1282697     1601.\n#&gt; 3  1952 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4  1952 Angola      Africa       30.0  4232095     3521.\n#&gt; 5  1952 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6  1952 Australia   Oceania      69.1  8691212    10040.\n#&gt; # â„¹ 1,698 more rows\n\nIn more complicated cases, there might be other variables stored in the directory name, or maybe the file name contains multiple bits of data. In that case, use set_names() (without any arguments) to record the full path, and then use tidyr::separate_wider_delim() and friends to turn them into useful columns.\nåœ¨æ›´å¤æ‚çš„æƒ…å†µä¸‹ï¼Œç›®å½•åä¸­å¯èƒ½å­˜å‚¨äº†å…¶ä»–å˜é‡ï¼Œæˆ–è€…æ–‡ä»¶åå¯èƒ½åŒ…å«å¤šä¸ªæ•°æ®ç‰‡æ®µã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½¿ç”¨ set_names()ï¼ˆä¸å¸¦ä»»ä½•å‚æ•°ï¼‰æ¥è®°å½•å®Œæ•´è·¯å¾„ï¼Œç„¶åä½¿ç”¨ tidyr::separate_wider_delim() åŠå…¶ç›¸å…³å‡½æ•°å°†å®ƒä»¬è½¬æ¢æˆæœ‰ç”¨çš„åˆ—ã€‚\n\npaths |&gt; \n  set_names() |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |&gt; \n  separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n#&gt; # A tibble: 1,704 Ã— 8\n#&gt;   dir       file  ext   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n#&gt; 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n#&gt; 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n#&gt; # â„¹ 1,698 more rows\n\n\n26.3.5 Save your work\nNow that youâ€™ve done all this hard work to get to a nice tidy data frame, itâ€™s a great time to save your work:\næ—¢ç„¶ä½ å·²ç»è´¹äº†è¿™ä¹ˆå¤šåŠŸå¤«å¾—åˆ°äº†ä¸€ä¸ªæ•´æ´çš„æ•°æ®æ¡†ï¼Œç°åœ¨æ˜¯ä¿å­˜ä½ å·¥ä½œæˆæœçš„å¥½æ—¶æœºï¼š\n\ngapminder &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n\nwrite_csv(gapminder, \"gapminder.csv\")\n\nNow when you come back to this problem in the future, you can read in a single csv file. For large and richer datasets, using parquet might be a better choice than .csv, as discussed in Section 22.4.\nç°åœ¨ï¼Œå½“ä½ å°†æ¥å†æ¬¡å¤„ç†è¿™ä¸ªé—®é¢˜æ—¶ï¼Œä½ å¯ä»¥ç›´æ¥è¯»å–ä¸€ä¸ª CSV æ–‡ä»¶ã€‚å¯¹äºå¤§å‹ä¸”æ›´ä¸°å¯Œçš„æ•°æ®é›†ï¼Œä½¿ç”¨ Parquet å¯èƒ½æ˜¯æ¯” .csv æ›´å¥½çš„é€‰æ‹©ï¼Œæ­£å¦‚åœ¨ Section 22.4 ä¸­è®¨è®ºçš„é‚£æ ·ã€‚\nIf youâ€™re working in a project, we suggest calling the file that does this sort of data prep work something like 0-cleanup.R. The 0 in the file name suggests that this should be run before anything else.\nå¦‚æœä½ åœ¨ä¸€ä¸ªé¡¹ç›®ä¸­å·¥ä½œï¼Œæˆ‘ä»¬å»ºè®®å°†æ‰§è¡Œæ­¤ç±»æ•°æ®å‡†å¤‡å·¥ä½œçš„æ–‡ä»¶å‘½åä¸º 0-cleanup.R ä¹‹ç±»çš„åç§°ã€‚æ–‡ä»¶åä¸­çš„ 0 æš—ç¤ºè¿™ä¸ªæ–‡ä»¶åº”è¯¥åœ¨å…¶ä»–ä»»ä½•æ–‡ä»¶ä¹‹å‰è¿è¡Œã€‚\nIf your input data files change over time, you might consider learning a tool like targets to set up your data cleaning code to automatically re-run whenever one of the input files is modified.\nå¦‚æœä½ çš„è¾“å…¥æ•°æ®æ–‡ä»¶éšæ—¶é—´å˜åŒ–ï¼Œä½ å¯èƒ½éœ€è¦è€ƒè™‘å­¦ä¹ ä¸€ä¸ªåƒ targets è¿™æ ·çš„å·¥å…·ï¼Œæ¥è®¾ç½®ä½ çš„æ•°æ®æ¸…ç†ä»£ç ï¼Œä»¥ä¾¿åœ¨ä»»ä½•è¾“å…¥æ–‡ä»¶è¢«ä¿®æ”¹æ—¶è‡ªåŠ¨é‡æ–°è¿è¡Œã€‚\n\n26.3.6 Many simple iterations\nHere weâ€™ve just loaded the data directly from disk, and were lucky enough to get a tidy dataset. In most cases, youâ€™ll need to do some additional tidying, and you have two basic options: you can do one round of iteration with a complex function, or do multiple rounds of iteration with simple functions. In our experience most folks reach first for one complex iteration, but youâ€™re often better by doing multiple simple iterations.\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åªæ˜¯ç›´æ¥ä»ç£ç›˜åŠ è½½äº†æ•°æ®ï¼Œå¹¶ä¸”å¹¸è¿åœ°å¾—åˆ°äº†ä¸€ä¸ªæ•´æ´çš„æ•°æ®é›†ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ éœ€è¦è¿›è¡Œä¸€äº›é¢å¤–çš„æ•´ç†ï¼Œä½ æœ‰ä¸¤ä¸ªåŸºæœ¬é€‰æ‹©ï¼šä½ å¯ä»¥ç”¨ä¸€ä¸ªå¤æ‚çš„å‡½æ•°è¿›è¡Œä¸€è½®è¿­ä»£ï¼Œæˆ–è€…ç”¨ç®€å•çš„å‡½æ•°è¿›è¡Œå¤šè½®è¿­ä»£ã€‚æ ¹æ®æˆ‘ä»¬çš„ç»éªŒï¼Œå¤§å¤šæ•°äººé¦–å…ˆä¼šé€‰æ‹©è¿›è¡Œä¸€æ¬¡å¤æ‚çš„è¿­ä»£ï¼Œä½†é€šå¸¸é€šè¿‡è¿›è¡Œå¤šæ¬¡ç®€å•çš„è¿­ä»£ä¼šæ›´å¥½ã€‚\nFor example, imagine that you want to read in a bunch of files, filter out missing values, pivot, and then combine. One way to approach the problem is to write a function that takes a file and does all those steps then call map() once:\nä¾‹å¦‚ï¼Œæƒ³è±¡ä¸€ä¸‹ä½ æƒ³è¯»å…¥ä¸€å †æ–‡ä»¶ï¼Œè¿‡æ»¤æ‰ç¼ºå¤±å€¼ï¼Œè¿›è¡Œæ•°æ®é€è§†ï¼Œç„¶ååˆå¹¶ã€‚ä¸€ç§è§£å†³é—®é¢˜çš„æ–¹æ³•æ˜¯ç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸€ä¸ªæ–‡ä»¶å¹¶æ‰§è¡Œæ‰€æœ‰è¿™äº›æ­¥éª¤ï¼Œç„¶åè°ƒç”¨ map() ä¸€æ¬¡ï¼š\n\nprocess_file &lt;- function(path) {\n  df &lt;- read_csv(path)\n  \n  df |&gt; \n    filter(!is.na(id)) |&gt; \n    mutate(id = tolower(id)) |&gt; \n    pivot_longer(jan:dec, names_to = \"month\")\n}\n\npaths |&gt; \n  map(process_file) |&gt; \n  list_rbind()\n\nAlternatively, you could perform each step of process_file() to every file:\næˆ–è€…ï¼Œä½ å¯ä»¥å¯¹æ¯ä¸ªæ–‡ä»¶æ‰§è¡Œ process_file() çš„æ¯ä¸€æ­¥ï¼š\n\npaths |&gt; \n  map(read_csv) |&gt; \n  map(\\(df) df |&gt; filter(!is.na(id))) |&gt; \n  map(\\(df) df |&gt; mutate(id = tolower(id))) |&gt; \n  map(\\(df) df |&gt; pivot_longer(jan:dec, names_to = \"month\")) |&gt; \n  list_rbind()\n\nWe recommend this approach because it stops you getting fixated on getting the first file right before moving on to the rest. By considering all of the data when doing tidying and cleaning, youâ€™re more likely to think holistically and end up with a higher quality result.\næˆ‘ä»¬æ¨èè¿™ç§æ–¹æ³•ï¼Œå› ä¸ºå®ƒèƒ½é˜²æ­¢ä½ åœ¨å¤„ç†å…¶ä»–æ–‡ä»¶ä¹‹å‰ï¼Œè¿‡åˆ†æ‰§ç€äºæŠŠç¬¬ä¸€ä¸ªæ–‡ä»¶å¤„ç†å¥½ã€‚åœ¨è¿›è¡Œæ•°æ®æ•´ç†å’Œæ¸…æ´—æ—¶ï¼Œé€šè¿‡è€ƒè™‘æ‰€æœ‰æ•°æ®ï¼Œä½ æ›´æœ‰å¯èƒ½è¿›è¡Œæ•´ä½“æ€è€ƒï¼Œå¹¶æœ€ç»ˆå¾—åˆ°æ›´é«˜è´¨é‡çš„ç»“æœã€‚\nIn this particular example, thereâ€™s another optimization you could make, by binding all the data frames together earlier. Then you can rely on regular dplyr behavior:\nåœ¨è¿™ä¸ªç‰¹å®šçš„ä¾‹å­ä¸­ï¼Œä½ è¿˜å¯ä»¥è¿›è¡Œå¦ä¸€ä¸ªä¼˜åŒ–ï¼Œå³æ›´æ—©åœ°å°†æ‰€æœ‰æ•°æ®æ¡†ç»‘å®šåœ¨ä¸€èµ·ã€‚ç„¶åä½ å°±å¯ä»¥ä¾èµ–å¸¸è§„çš„ dplyr è¡Œä¸ºï¼š\n\npaths |&gt; \n  map(read_csv) |&gt; \n  list_rbind() |&gt; \n  filter(!is.na(id)) |&gt; \n  mutate(id = tolower(id)) |&gt; \n  pivot_longer(jan:dec, names_to = \"month\")\n\n\n26.3.7 Heterogeneous data\nUnfortunately, sometimes itâ€™s not possible to go from map() straight to list_rbind() because the data frames are so heterogeneous that list_rbind() either fails or yields a data frame thatâ€™s not very useful. In that case, itâ€™s still useful to start by loading all of the files:\nä¸å¹¸çš„æ˜¯ï¼Œæœ‰æ—¶æ— æ³•ç›´æ¥ä» map() è½¬åˆ° list_rbind()ï¼Œå› ä¸ºæ•°æ®æ¡†çš„å¼‚æ„æ€§å¤ªå¼ºï¼Œå¯¼è‡´ list_rbind() è¦ä¹ˆå¤±è´¥ï¼Œè¦ä¹ˆäº§ç”Ÿä¸€ä¸ªä¸å¤ªæœ‰ç”¨çš„æ•°æ®æ¡†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»åŠ è½½æ‰€æœ‰æ–‡ä»¶å¼€å§‹ä»ç„¶æ˜¯å¾ˆæœ‰ç”¨çš„ï¼š\n\nfiles &lt;- paths |&gt; \n  map(readxl::read_excel) \n\nThen a very useful strategy is to capture the structure of the data frames so that you can explore it using your data science skills. One way to do so is with this handy df_types function[^1] that returns a tibble with one row for each column:\nç„¶åï¼Œä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ç­–ç•¥æ˜¯æ•è·æ•°æ®æ¡†çš„ç»“æ„ï¼Œä»¥ä¾¿ä½ å¯ä»¥è¿ç”¨æ•°æ®ç§‘å­¦æŠ€èƒ½å¯¹å…¶è¿›è¡Œæ¢ç´¢ã€‚ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨è¿™ä¸ªæ–¹ä¾¿çš„ df_types å‡½æ•°[^1]ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ª tibbleï¼Œæ¯è¡Œå¯¹åº”ä¸€åˆ—ï¼š\n\ndf_types &lt;- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder)\n#&gt; # A tibble: 6 Ã— 3\n#&gt;   col_name  col_type  n_miss\n#&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 year      double         0\n#&gt; 2 country   character      0\n#&gt; 3 continent character      0\n#&gt; 4 lifeExp   double         0\n#&gt; 5 pop       double         0\n#&gt; 6 gdpPercap double         0\n\nYou can then apply this function to all of the files, and maybe do some pivoting to make it easier to see where the differences are. For example, this makes it easy to verify that the gapminder spreadsheets that weâ€™ve been working with are all quite homogeneous:\nç„¶åï¼Œä½ å¯ä»¥å°†æ­¤å‡½æ•°åº”ç”¨äºæ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶å¯èƒ½è¿›è¡Œä¸€äº›é€è§†æ“ä½œï¼Œä»¥ä¾¿æ›´å®¹æ˜“åœ°æŸ¥çœ‹å·®å¼‚æ‰€åœ¨ã€‚ä¾‹å¦‚ï¼Œè¿™å¯ä»¥è½»æ¾éªŒè¯æˆ‘ä»¬ä¸€ç›´åœ¨ä½¿ç”¨çš„ gapminder ç”µå­è¡¨æ ¼éƒ½éå¸¸åŒè´¨ï¼š\n\nfiles |&gt; \n  map(df_types) |&gt; \n  list_rbind(names_to = \"file_name\") |&gt; \n  select(-n_miss) |&gt; \n  pivot_wider(names_from = col_name, values_from = col_type)\n#&gt; # A tibble: 12 Ã— 6\n#&gt;   file_name country   continent lifeExp pop    gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1 1952.xlsx character character double  double double   \n#&gt; 2 1957.xlsx character character double  double double   \n#&gt; 3 1962.xlsx character character double  double double   \n#&gt; 4 1967.xlsx character character double  double double   \n#&gt; 5 1972.xlsx character character double  double double   \n#&gt; 6 1977.xlsx character character double  double double   \n#&gt; # â„¹ 6 more rows\n\nIf the files have heterogeneous formats, you might need to do more processing before you can successfully merge them. Unfortunately, weâ€™re now going to leave you to figure that out on your own, but you might want to read about map_if() and map_at(). map_if() allows you to selectively modify elements of a list based on their values; map_at() allows you to selectively modify elements based on their names.\nå¦‚æœæ–‡ä»¶å…·æœ‰å¼‚æ„æ ¼å¼ï¼Œä½ å¯èƒ½éœ€è¦è¿›è¡Œæ›´å¤šå¤„ç†æ‰èƒ½æˆåŠŸåˆå¹¶å®ƒä»¬ã€‚ä¸å¹¸çš„æ˜¯ï¼Œç°åœ¨æˆ‘ä»¬å°†è®©ä½ è‡ªå·±å»è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†ä½ å¯èƒ½æƒ³äº†è§£ä¸€ä¸‹ map_if() å’Œ map_at()ã€‚map_if() å…è®¸ä½ æ ¹æ®åˆ—è¡¨å…ƒç´ çš„å€¼é€‰æ‹©æ€§åœ°ä¿®æ”¹å®ƒä»¬ï¼›map_at() å…è®¸ä½ æ ¹æ®åˆ—è¡¨å…ƒç´ çš„åç§°é€‰æ‹©æ€§åœ°ä¿®æ”¹å®ƒä»¬ã€‚\n\n26.3.8 Handling failures\nSometimes the structure of your data might be sufficiently wild that you canâ€™t even read all the files with a single command. And then youâ€™ll encounter one of the downsides of map(): it succeeds or fails as a whole. map() will either successfully read all of the files in a directory or fail with an error, reading zero files. This is annoying: why does one failure prevent you from accessing all the other successes?\næœ‰æ—¶ï¼Œä½ çš„æ•°æ®ç»“æ„å¯èƒ½éå¸¸æ··ä¹±ï¼Œä»¥è‡³äºä½ ç”šè‡³æ— æ³•ç”¨ä¸€ä¸ªå‘½ä»¤è¯»å–æ‰€æœ‰æ–‡ä»¶ã€‚ç„¶åä½ ä¼šé‡åˆ° map() çš„ä¸€ä¸ªç¼ºç‚¹ï¼šå®ƒè¦ä¹ˆæ•´ä½“æˆåŠŸï¼Œè¦ä¹ˆæ•´ä½“å¤±è´¥ã€‚map() è¦ä¹ˆæˆåŠŸè¯»å–ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œè¦ä¹ˆå› é”™è¯¯è€Œå¤±è´¥ï¼Œè¯»å–é›¶ä¸ªæ–‡ä»¶ã€‚è¿™å¾ˆçƒ¦äººï¼šä¸ºä»€ä¹ˆä¸€ä¸ªå¤±è´¥ä¼šé˜»æ­¢ä½ è®¿é—®æ‰€æœ‰å…¶ä»–æˆåŠŸçš„ç»“æœï¼Ÿ\nLuckily, purrr comes with a helper to tackle this problem: possibly(). possibly() is whatâ€™s known as a function operator: it takes a function and returns a function with modified behavior. In particular, possibly() changes a function from erroring to returning a value that you specify:\nå¹¸è¿çš„æ˜¯ï¼Œpurrr æä¾›äº†ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼špossibly()ã€‚possibly() è¢«ç§°ä¸ºå‡½æ•°æ“ä½œç¬¦ï¼šå®ƒæ¥å—ä¸€ä¸ªå‡½æ•°å¹¶è¿”å›ä¸€ä¸ªè¡Œä¸ºè¢«ä¿®æ”¹äº†çš„å‡½æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œpossibly() å°†ä¸€ä¸ªä¼šå‡ºé”™çš„å‡½æ•°æ›´æ”¹ä¸ºè¿”å›ä½ æŒ‡å®šçš„å€¼ï¼š\n\nfiles &lt;- paths |&gt; \n  map(possibly(\\(path) readxl::read_excel(path), NULL))\n\ndata &lt;- files |&gt; list_rbind()\n\nThis works particularly well here because list_rbind(), like many tidyverse functions, automatically ignores NULLs.\nè¿™åœ¨è¿™é‡Œç‰¹åˆ«æœ‰æ•ˆï¼Œå› ä¸º list_rbind() å’Œè®¸å¤š tidyverse å‡½æ•°ä¸€æ ·ï¼Œä¼šè‡ªåŠ¨å¿½ç•¥ NULL å€¼ã€‚\nNow you have all the data that can be read easily, and itâ€™s time to tackle the hard part of figuring out why some files failed to load and what to do about it. Start by getting the paths that failed:\nç°åœ¨ä½ å·²ç»æœ‰äº†æ‰€æœ‰å¯ä»¥è½»æ¾è¯»å–çš„æ•°æ®ï¼Œæ˜¯æ—¶å€™è§£å†³å›°éš¾çš„éƒ¨åˆ†äº†ï¼šå¼„æ¸…æ¥šä¸ºä»€ä¹ˆæœ‰äº›æ–‡ä»¶åŠ è½½å¤±è´¥ä»¥åŠå¦‚ä½•å¤„ç†ã€‚é¦–å…ˆè·å–å¤±è´¥çš„è·¯å¾„ï¼š\n\nfailed &lt;- map_vec(files, is.null)\npaths[failed]\n#&gt; character(0)\n\nThen call the import function again for each failure and figure out what went wrong.\nç„¶åå¯¹æ¯ä¸ªå¤±è´¥çš„æ–‡ä»¶å†æ¬¡è°ƒç”¨å¯¼å…¥å‡½æ•°ï¼Œæ‰¾å‡ºé—®é¢˜æ‰€åœ¨ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>26</span>Â  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#saving-multiple-outputs",
    "href": "iteration.html#saving-multiple-outputs",
    "title": "26Â  Iteration",
    "section": "\n26.4 Saving multiple outputs",
    "text": "26.4 Saving multiple outputs\nIn the last section, you learned about map(), which is useful for reading multiple files into a single object. In this section, weâ€™ll now explore sort of the opposite problem: how can you take one or more R objects and save it to one or more files? Weâ€™ll explore this challenge using three examples:\nåœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œä½ å­¦ä¹ äº† map()ï¼Œå®ƒå¯¹äºå°†å¤šä¸ªæ–‡ä»¶è¯»å…¥å•ä¸ªå¯¹è±¡å¾ˆæœ‰ç”¨ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸€ä¸ªç›¸åçš„é—®é¢˜ï¼šå¦‚ä½•å°†ä¸€ä¸ªæˆ–å¤šä¸ª R å¯¹è±¡ä¿å­˜åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ä¸­ï¼Ÿæˆ‘ä»¬å°†é€šè¿‡ä¸‰ä¸ªä¾‹å­æ¥æ¢è®¨è¿™ä¸ªæŒ‘æˆ˜ï¼š\n\nSaving multiple data frames into one database.\nå°†å¤šä¸ªæ•°æ®æ¡†ä¿å­˜åˆ°ä¸€ä¸ªæ•°æ®åº“ä¸­ã€‚\nSaving multiple data frames into multiple .csv files.\nå°†å¤šä¸ªæ•°æ®æ¡†ä¿å­˜åˆ°å¤šä¸ª .csv æ–‡ä»¶ä¸­ã€‚\nSaving multiple plots to multiple .png files.\nå°†å¤šä¸ªå›¾ä¿å­˜åˆ°å¤šä¸ª .png æ–‡ä»¶ä¸­ã€‚\n\n\n26.4.1 Writing to a database\nSometimes when working with many files at once, itâ€™s not possible to fit all your data into memory at once, and you canâ€™t do map(files, read_csv). One approach to deal with this problem is to load your data into a database so you can access just the bits you need with dbplyr.\næœ‰æ—¶ï¼Œå½“ä¸€æ¬¡å¤„ç†å¤šä¸ªæ–‡ä»¶æ—¶ï¼Œä¸å¯èƒ½å°†æ‰€æœ‰æ•°æ®ä¸€æ¬¡æ€§è£…å…¥å†…å­˜ï¼Œä¹Ÿå°±æ— æ³•æ‰§è¡Œ map(files, read_csv)ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯å°†æ•°æ®åŠ è½½åˆ°æ•°æ®åº“ä¸­ï¼Œè¿™æ ·ä½ å°±å¯ä»¥ä½¿ç”¨ dbplyr åªè®¿é—®ä½ éœ€è¦çš„éƒ¨åˆ†ã€‚\nIf youâ€™re lucky, the database package youâ€™re using will provide a handy function that takes a vector of paths and loads them all into the database. This is the case with duckdbâ€™s duckdb_read_csv():\nå¦‚æœå¹¸è¿çš„è¯ï¼Œä½ ä½¿ç”¨çš„æ•°æ®åº“åŒ…ä¼šæä¾›ä¸€ä¸ªæ–¹ä¾¿çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸€ä¸ªè·¯å¾„å‘é‡å¹¶å°†å®ƒä»¬å…¨éƒ¨åŠ è½½åˆ°æ•°æ®åº“ä¸­ã€‚duckdb çš„ duckdb_read_csv() å°±æ˜¯è¿™ç§æƒ…å†µï¼š\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nduckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\nThis would work well here, but we donâ€™t have csv files, instead we have excel spreadsheets. So weâ€™re going to have to do it â€œby handâ€. Learning to do it by hand will also help you when you have a bunch of csvs and the database that youâ€™re working with doesnâ€™t have one function that will load them all in.\nè¿™åœ¨è¿™é‡Œä¼šå¾ˆæœ‰æ•ˆï¼Œä½†æˆ‘ä»¬æ²¡æœ‰ csv æ–‡ä»¶ï¼Œè€Œæ˜¯ excel ç”µå­è¡¨æ ¼ã€‚æ‰€ä»¥æˆ‘ä»¬å¿…é¡»â€œæ‰‹åŠ¨â€æ¥åšã€‚å½“ä½ æœ‰ä¸€å † csv æ–‡ä»¶ï¼Œè€Œä½ æ­£åœ¨ä½¿ç”¨çš„æ•°æ®åº“æ²¡æœ‰ä¸€ä¸ªèƒ½å°†å®ƒä»¬å…¨éƒ¨åŠ è½½çš„å‡½æ•°æ—¶ï¼Œå­¦ä¼šæ‰‹åŠ¨æ“ä½œä¹Ÿä¼šå¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚\nWe need to start by creating a table that we will fill in with data. The easiest way to do this is by creating a template, a dummy data frame that contains all the columns we want, but only a sampling of the data. For the gapminder data, we can make that template by reading a single file and adding the year to it:\næˆ‘ä»¬éœ€è¦ä»åˆ›å»ºä¸€ä¸ªæˆ‘ä»¬å°†ç”¨æ•°æ®å¡«å……çš„è¡¨å¼€å§‹ã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯åˆ›å»ºä¸€ä¸ªæ¨¡æ¿ï¼Œä¸€ä¸ªåŒ…å«æˆ‘ä»¬æƒ³è¦çš„æ‰€æœ‰åˆ—ä½†åªæœ‰å°‘é‡ç¤ºä¾‹æ•°æ®çš„è™šæ‹Ÿæ•°æ®æ¡†ã€‚å¯¹äº gapminder æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯»å–å•ä¸ªæ–‡ä»¶å¹¶å‘å…¶æ·»åŠ å¹´ä»½æ¥åˆ¶ä½œè¯¥æ¨¡æ¿ï¼š\n\ntemplate &lt;- readxl::read_excel(paths[[1]])\ntemplate$year &lt;- 1952\ntemplate\n#&gt; # A tibble: 142 Ã— 6\n#&gt;   country     continent lifeExp      pop gdpPercap  year\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.  1952\n#&gt; 2 Albania     Europe       55.2  1282697     1601.  1952\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.  1952\n#&gt; 4 Angola      Africa       30.0  4232095     3521.  1952\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.  1952\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.  1952\n#&gt; # â„¹ 136 more rows\n\nNow we can connect to the database, and use DBI::dbCreateTable() to turn our template into a database table:\nç°åœ¨æˆ‘ä»¬å¯ä»¥è¿æ¥åˆ°æ•°æ®åº“ï¼Œå¹¶ä½¿ç”¨ DBI::dbCreateTable() å°†æˆ‘ä»¬çš„æ¨¡æ¿è½¬æ¢æˆä¸€ä¸ªæ•°æ®åº“è¡¨ï¼š\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nDBI::dbCreateTable(con, \"gapminder\", template)\n\ndbCreateTable() doesnâ€™t use the data in template, just the variable names and types. So if we inspect the gapminder table now youâ€™ll see that itâ€™s empty but it has the variables we need with the types we expect:dbCreateTable() ä¸ä¼šä½¿ç”¨ template ä¸­çš„æ•°æ®ï¼Œåªä½¿ç”¨å˜é‡åå’Œç±»å‹ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬ç°åœ¨æ£€æŸ¥ gapminder è¡¨ï¼Œä½ ä¼šçœ‹åˆ°å®ƒæ˜¯ç©ºçš„ï¼Œä½†å®ƒæ‹¥æœ‰æˆ‘ä»¬éœ€è¦çš„å˜é‡å’Œæˆ‘ä»¬æœŸæœ›çš„ç±»å‹ï¼š\n\ncon |&gt; tbl(\"gapminder\")\n#&gt; # Source:   table&lt;gapminder&gt; [?? x 6]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt; # â„¹ 6 variables: country &lt;chr&gt;, continent &lt;chr&gt;, lifeExp &lt;dbl&gt;, pop &lt;dbl&gt;,\n#&gt; #   gdpPercap &lt;dbl&gt;, year &lt;dbl&gt;\n\nNext, we need a function that takes a single file path, reads it into R, and adds the result to the gapminder table. We can do that by combining read_excel() with DBI::dbAppendTable():\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒæ¥å—å•ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œå°†å…¶è¯»å…¥ Rï¼Œå¹¶å°†ç»“æœæ·»åŠ åˆ° gapminder è¡¨ä¸­ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç»“åˆ read_excel() å’Œ DBI::dbAppendTable() æ¥å®ç°ï¼š\n\nappend_file &lt;- function(path) {\n  df &lt;- readxl::read_excel(path)\n  df$year &lt;- parse_number(basename(path))\n  \n  DBI::dbAppendTable(con, \"gapminder\", df)\n}\n\nNow we need to call append_file() once for each element of paths. Thatâ€™s certainly possible with map():\nç°åœ¨æˆ‘ä»¬éœ€è¦å¯¹ paths çš„æ¯ä¸ªå…ƒç´ è°ƒç”¨ä¸€æ¬¡ append_file()ã€‚è¿™å½“ç„¶å¯ä»¥ç”¨ map() å®ç°ï¼š\n\npaths |&gt; map(append_file)\n\nBut we donâ€™t care about the output of append_file(), so instead of map() itâ€™s slightly nicer to use walk(). walk() does exactly the same thing as map() but throws the output away:\nä½†æˆ‘ä»¬ä¸å…³å¿ƒ append_file() çš„è¾“å‡ºï¼Œæ‰€ä»¥ä½¿ç”¨ walk() ä¼šæ¯” map() æ›´ç®€æ´ä¸€äº›ã€‚walk() çš„ä½œç”¨ä¸ map() å®Œå…¨ç›¸åŒï¼Œä½†ä¼šä¸¢å¼ƒè¾“å‡ºï¼š\n\npaths |&gt; walk(append_file)\n\nNow we can see if we have all the data in our table:\nç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹çœ‹æˆ‘ä»¬çš„è¡¨ä¸­æ˜¯å¦åŒ…å«äº†æ‰€æœ‰æ•°æ®ï¼š\n\ncon |&gt; \n  tbl(\"gapminder\") |&gt; \n  count(year)\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB v1.3.1 [14913@Windows 10 x64:R 4.5.1/:memory:]\n#&gt;    year     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1967   142\n#&gt; 2  1972   142\n#&gt; 3  1992   142\n#&gt; 4  1997   142\n#&gt; 5  2002   142\n#&gt; 6  1987   142\n#&gt; # â„¹ more rows\n\n\n26.4.2 Writing csv files\nThe same basic principle applies if we want to write multiple csv files, one for each group. Letâ€™s imagine that we want to take the ggplot2::diamonds data and save one csv file for each clarity. First we need to make those individual datasets. There are many ways you could do that, but thereâ€™s one way we particularly like: group_nest().\nå¦‚æœæˆ‘ä»¬æƒ³ä¸ºæ¯ä¸ªç»„åˆ«å†™å…¥å¤šä¸ª csv æ–‡ä»¶ï¼ŒåŒæ ·çš„åŸºæœ¬åŸåˆ™ä¹Ÿé€‚ç”¨ã€‚å‡è®¾æˆ‘ä»¬æƒ³è¦è·å– ggplot2::diamonds æ•°æ®ï¼Œå¹¶ä¸ºæ¯ä¸ª clarity ä¿å­˜ä¸€ä¸ª csv æ–‡ä»¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºè¿™äº›ç‹¬ç«‹çš„æ•°æ®é›†ã€‚æœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†æˆ‘ä»¬ç‰¹åˆ«å–œæ¬¢ä¸€ç§æ–¹æ³•ï¼šgroup_nest()ã€‚\n\nby_clarity &lt;- diamonds |&gt; \n  group_nest(clarity)\n\nby_clarity\n#&gt; # A tibble: 8 Ã— 2\n#&gt;   clarity               data\n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n#&gt; 1 I1               [741 Ã— 9]\n#&gt; 2 SI2            [9,194 Ã— 9]\n#&gt; 3 SI1           [13,065 Ã— 9]\n#&gt; 4 VS2           [12,258 Ã— 9]\n#&gt; 5 VS1            [8,171 Ã— 9]\n#&gt; 6 VVS2           [5,066 Ã— 9]\n#&gt; # â„¹ 2 more rows\n\nThis gives us a new tibble with eight rows and two columns. clarity is our grouping variable and data is a list-column containing one tibble for each unique value of clarity:\nè¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ªæœ‰å…«è¡Œä¸¤åˆ—çš„æ–° tibbleã€‚clarity æ˜¯æˆ‘ä»¬çš„åˆ†ç»„å˜é‡ï¼Œdata æ˜¯ä¸€ä¸ªåˆ—è¡¨åˆ— (list-column)ï¼Œå…¶ä¸­åŒ…å«å¯¹åº” clarity æ¯ä¸ªå”¯ä¸€å€¼çš„ä¸€ä¸ª tibbleï¼š\n\nby_clarity$data[[1]]\n#&gt; # A tibble: 741 Ã— 9\n#&gt;   carat cut       color depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#&gt; 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#&gt; 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#&gt; 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#&gt; 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#&gt; 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#&gt; # â„¹ 735 more rows\n\nWhile weâ€™re here, letâ€™s create a column that gives the name of output file, using mutate() and str_glue():\nè¶æ­¤æœºä¼šï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ mutate() å’Œ str_glue() åˆ›å»ºä¸€ä¸ªåŒ…å«è¾“å‡ºæ–‡ä»¶åçš„åˆ—ï¼š\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n#&gt; # A tibble: 8 Ã— 3\n#&gt;   clarity               data path             \n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n#&gt; 1 I1               [741 Ã— 9] diamonds-I1.csv  \n#&gt; 2 SI2            [9,194 Ã— 9] diamonds-SI2.csv \n#&gt; 3 SI1           [13,065 Ã— 9] diamonds-SI1.csv \n#&gt; 4 VS2           [12,258 Ã— 9] diamonds-VS2.csv \n#&gt; 5 VS1            [8,171 Ã— 9] diamonds-VS1.csv \n#&gt; 6 VVS2           [5,066 Ã— 9] diamonds-VVS2.csv\n#&gt; # â„¹ 2 more rows\n\nSo if we were going to save these data frames by hand, we might write something like:\nå› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æ‰“ç®—æ‰‹åŠ¨ä¿å­˜è¿™äº›æ•°æ®æ¡†ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå†™å‡ºç±»ä¼¼è¿™æ ·çš„ä»£ç ï¼š\n\nwrite_csv(by_clarity$data[[1]], by_clarity$path[[1]])\nwrite_csv(by_clarity$data[[2]], by_clarity$path[[2]])\nwrite_csv(by_clarity$data[[3]], by_clarity$path[[3]])\n...\nwrite_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])\n\nThis is a little different to our previous uses of map() because there are two arguments that are changing, not just one. That means we need a new function: map2(), which varies both the first and second arguments. And because we again donâ€™t care about the output, we want walk2() rather than map2(). That gives us:\nè¿™ä¸æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨ map() çš„æƒ…å†µç•¥æœ‰ä¸åŒï¼Œå› ä¸ºæœ‰ä¸¤ä¸ªå‚æ•°åœ¨å˜åŒ–ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªã€‚è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ–°çš„å‡½æ•°ï¼šmap2()ï¼Œå®ƒå¯ä»¥åŒæ—¶æ”¹å˜ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªå‚æ•°ã€‚è€Œä¸”å› ä¸ºæˆ‘ä»¬åŒæ ·ä¸å…³å¿ƒè¾“å‡ºï¼Œæ‰€ä»¥æˆ‘ä»¬æƒ³è¦ç”¨ walk2() è€Œä¸æ˜¯ map2()ã€‚è¿™æ ·æˆ‘ä»¬å¾—åˆ°ï¼š\n\nwalk2(by_clarity$data, by_clarity$path, write_csv)\n\n\n26.4.3 Saving plots\nWe can take the same basic approach to create many plots. Letâ€™s first make a function that draws the plot we want:\næˆ‘ä»¬å¯ä»¥é‡‡å–åŒæ ·çš„åŸºæœ¬æ–¹æ³•æ¥åˆ›å»ºå¤šä¸ªå›¾ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥ç»˜åˆ¶æˆ‘ä»¬æƒ³è¦çš„å›¾ï¼š\n\ncarat_histogram &lt;- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\n\n\n\nNow we can use map() to create a list of many plots[^5] and their eventual file paths:\nç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ map() æ¥åˆ›å»ºè®¸å¤šå›¾çš„åˆ—è¡¨5åŠå…¶æœ€ç»ˆçš„æ–‡ä»¶è·¯å¾„ï¼š\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\nThen use walk2() with ggsave() to save each plot:\nç„¶åä½¿ç”¨ walk2() å’Œ ggsave() æ¥ä¿å­˜æ¯ä¸ªå›¾ï¼š\n\nwalk2(\n  by_clarity$path,\n  by_clarity$plot,\n  \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n)\n\nThis is shorthand for:\nè¿™æ˜¯ä»¥ä¸‹ä»£ç çš„ç®€å†™ï¼š\n\nggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)\nggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)\nggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)\n...\nggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>26</span>Â  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#summary",
    "href": "iteration.html#summary",
    "title": "26Â  Iteration",
    "section": "\n26.5 Summary",
    "text": "26.5 Summary\nIn this chapter, youâ€™ve seen how to use explicit iteration to solve three problems that come up frequently when doing data science: manipulating multiple columns, reading multiple files, and saving multiple outputs. But in general, iteration is a super power: if you know the right iteration technique, you can easily go from fixing one problem to fixing all the problems. Once youâ€™ve mastered the techniques in this chapter, we highly recommend learning more by reading the Functionals chapter of Advanced R and consulting the purrr website.\nåœ¨æœ¬ç« ä¸­ï¼Œä½ å·²ç»å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨æ˜¾å¼è¿­ä»£æ¥è§£å†³æ•°æ®ç§‘å­¦ä¸­ç»å¸¸å‡ºç°çš„ä¸‰ä¸ªé—®é¢˜ï¼šæ“ä½œå¤šä¸ªåˆ—ã€è¯»å–å¤šä¸ªæ–‡ä»¶ä»¥åŠä¿å­˜å¤šä¸ªè¾“å‡ºã€‚ä½†æ€»çš„æ¥è¯´ï¼Œè¿­ä»£æ˜¯ä¸€é¡¹è¶…èƒ½åŠ›ï¼šå¦‚æœä½ æŒæ¡äº†æ­£ç¡®çš„è¿­ä»£æŠ€å·§ï¼Œä½ å°±å¯ä»¥è½»æ¾åœ°ä»è§£å†³ä¸€ä¸ªé—®é¢˜æ‰©å±•åˆ°è§£å†³æ‰€æœ‰é—®é¢˜ã€‚ä¸€æ—¦ä½ æŒæ¡äº†æœ¬ç« çš„æŠ€å·§ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ é€šè¿‡é˜…è¯» Advanced R çš„ å‡½æ•°å¼ç¼–ç¨‹ (Functionals) ç« èŠ‚ å’ŒæŸ¥é˜… purrr ç½‘ç«™ æ¥å­¦ä¹ æ›´å¤šå†…å®¹ã€‚\nIf you know much about iteration in other languages, you might be surprised that we didnâ€™t discuss the for loop. Thatâ€™s because Râ€™s orientation towards data analysis changes how we iterate: in most cases you can rely on an existing idiom to do something to each columns or each group. And when you canâ€™t, you can often use a functional programming tool like map() that does something to each element of a list. However, you will see for loops in wild-caught code, so youâ€™ll learn about them in the next chapter where weâ€™ll discuss some important base R tools.\nå¦‚æœä½ å¯¹å…¶ä»–è¯­è¨€ä¸­çš„è¿­ä»£å¾ˆäº†è§£ï¼Œä½ å¯èƒ½ä¼šæƒŠè®¶äºæˆ‘ä»¬æ²¡æœ‰è®¨è®º for å¾ªç¯ã€‚è¿™æ˜¯å› ä¸º R é¢å‘æ•°æ®åˆ†æçš„ç‰¹æ€§æ”¹å˜äº†æˆ‘ä»¬è¿­ä»£çš„æ–¹å¼ï¼šåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥ä¾èµ–ç°æœ‰çš„æƒ¯ç”¨æ³•æ¥å¯¹æ¯ä¸€åˆ—æˆ–æ¯ä¸€ç»„æ‰§è¡Œæ“ä½œã€‚å½“ä½ æ— æ³•è¿™æ ·åšæ—¶ï¼Œä½ é€šå¸¸å¯ä»¥ä½¿ç”¨åƒ map() è¿™æ ·çš„å‡½æ•°å¼ç¼–ç¨‹å·¥å…·ï¼Œå®ƒä¼šå¯¹åˆ—è¡¨çš„æ¯ä¸ªå…ƒç´ æ‰§è¡ŒæŸäº›æ“ä½œã€‚ç„¶è€Œï¼Œä½ ä¼šåœ¨å®é™…ä»£ç ä¸­çœ‹åˆ° for å¾ªç¯ï¼Œæ‰€ä»¥ä½ å°†åœ¨ä¸‹ä¸€ç« ä¸­å­¦ä¹ å®ƒä»¬ï¼Œå±Šæ—¶æˆ‘ä»¬å°†è®¨è®ºä¸€äº›é‡è¦çš„ R åŸºç¡€å·¥å…·ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>26</span>Â  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "base-R.html",
    "href": "base-R.html",
    "title": "27Â  A field guide to base R",
    "section": "",
    "text": "27.1 Introduction\nTo finish off the programming section, weâ€™re going to give you a quick tour of the most important base R functions that we donâ€™t otherwise discuss in the book.\nä¸ºäº†ç»“æŸç¼–ç¨‹éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å¸¦ä½ å¿«é€Ÿæµè§ˆä¸€ä¸‹æœ¬ä¹¦ä¸­æœªæ›¾è®¨è®ºè¿‡çš„æœ€é‡è¦çš„åŸºç¡€ R å‡½æ•°ã€‚\nThese tools are particularly useful as you do more programming and will help you read code youâ€™ll encounter in the wild.\nå½“ä½ è¿›è¡Œæ›´å¤šç¼–ç¨‹æ—¶ï¼Œè¿™äº›å·¥å…·ç‰¹åˆ«æœ‰ç”¨ï¼Œå®ƒä»¬å°†å¸®åŠ©ä½ é˜…è¯»åœ¨å®é™…ä¸­é‡åˆ°çš„ä»£ç ã€‚\nThis is a good place to remind you that the tidyverse is not the only way to solve data science problems.\nè¿™é‡Œæ­£å¥½å¯ä»¥æé†’ä½ ï¼Œtidyverse å¹¶ä¸æ˜¯è§£å†³æ•°æ®ç§‘å­¦é—®é¢˜çš„å”¯ä¸€æ–¹æ³•ã€‚\nWe teach the tidyverse in this book because tidyverse packages share a common design philosophy, increasing the consistency across functions, and making each new function or package a little easier to learn and use.\næˆ‘ä»¬åœ¨æœ¬ä¹¦ä¸­æ•™æˆ tidyverseï¼Œå› ä¸º tidyverse çš„åŒ…å…±äº«ä¸€ä¸ªå…±åŒçš„è®¾è®¡ç†å¿µï¼Œå¢åŠ äº†å‡½æ•°ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œä½¿å¾—å­¦ä¹ å’Œä½¿ç”¨æ¯ä¸ªæ–°å‡½æ•°æˆ–åŒ…éƒ½å˜å¾—æ›´å®¹æ˜“ä¸€äº›ã€‚\nItâ€™s not possible to use the tidyverse without using base R, so weâ€™ve actually already taught you a lot of base R functions: from library() to load packages, to sum() and mean() for numeric summaries, to the factor, date, and POSIXct data types, and of course all the basic operators like +, -, /, *, |, &, and !.\nä¸ä½¿ç”¨åŸºç¡€ R æ˜¯ä¸å¯èƒ½ä½¿ç”¨ tidyverse çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šå·²ç»æ•™äº†ä½ å¾ˆå¤šåŸºç¡€ R å‡½æ•°ï¼šä»åŠ è½½åŒ…çš„ library()ï¼Œåˆ°ç”¨äºæ•°å€¼æ‘˜è¦çš„ sum() å’Œ mean()ï¼Œå†åˆ°å› å­ã€æ—¥æœŸå’Œ POSIXct æ•°æ®ç±»å‹ï¼Œå½“ç„¶è¿˜æœ‰æ‰€æœ‰åŸºæœ¬è¿ç®—ç¬¦ï¼Œå¦‚ +ã€-ã€/ã€*ã€|ã€& å’Œ !ã€‚\nWhat we havenâ€™t focused on so far is base R workflows, so we will highlight a few of those in this chapter.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰é‡ç‚¹å…³æ³¨åŸºç¡€ R çš„å·¥ä½œæµç¨‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†åœ¨æœ¬ç« ä¸­é‡ç‚¹ä»‹ç»å…¶ä¸­çš„ä¸€äº›ã€‚\nAfter you read this book, youâ€™ll learn other approaches to the same problems using base R, data.table, and other packages.\nè¯»å®Œè¿™æœ¬ä¹¦åï¼Œä½ å°†å­¦ä¹ åˆ°ä½¿ç”¨åŸºç¡€ Rã€data.table å’Œå…¶ä»–åŒ…æ¥è§£å†³åŒæ ·é—®é¢˜çš„å…¶ä»–æ–¹æ³•ã€‚\nYouâ€™ll undoubtedly encounter these other approaches when you start reading R code written by others, particularly if youâ€™re using StackOverflow.\nå½“ä½ å¼€å§‹é˜…è¯»ä»–äººç¼–å†™çš„ R ä»£ç æ—¶ï¼Œæ¯«æ— ç–‘é—®ä½ ä¼šé‡åˆ°è¿™äº›å…¶ä»–æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨ StackOverflow æ—¶ã€‚\nItâ€™s 100% okay to write code that uses a mix of approaches, and donâ€™t let anyone tell you otherwise!\nç¼–å†™æ··åˆä½¿ç”¨å¤šç§æ–¹æ³•çš„ä»£ç æ˜¯ 100% å¯ä»¥çš„ï¼Œä¸è¦è®©ä»»ä½•äººå‘Šè¯‰ä½ åˆ«çš„ï¼\nIn this chapter, weâ€™ll focus on four big topics: subsetting with [, subsetting with [[ and $, the apply family of functions, and for loops.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨å››ä¸ªå¤§ä¸»é¢˜ï¼šä½¿ç”¨ [ è¿›è¡Œå­é›†æå–ï¼Œä½¿ç”¨ [[ å’Œ $ è¿›è¡Œå­é›†æå–ï¼Œapply å‡½æ•°æ—ï¼Œä»¥åŠ for å¾ªç¯ã€‚\nTo finish off, weâ€™ll briefly discuss two essential plotting functions.\næœ€åï¼Œæˆ‘ä»¬å°†ç®€è¦è®¨è®ºä¸¤ä¸ªåŸºæœ¬çš„ç»˜å›¾å‡½æ•°ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#introduction",
    "href": "base-R.html#introduction",
    "title": "27Â  A field guide to base R",
    "section": "",
    "text": "27.1.1 Prerequisites\nThis package focuses on base R so doesnâ€™t have any real prerequisites, but weâ€™ll load the tidyverse in order to explain some of the differences.\nè¿™ä¸ªåŒ…ä¸“æ³¨äºåŸºç¡€ Rï¼Œæ‰€ä»¥æ²¡æœ‰çœŸæ­£çš„å…ˆå†³æ¡ä»¶ï¼Œä½†æˆ‘ä»¬ä¼šåŠ è½½ tidyverse ä»¥ä¾¿è§£é‡Šä¸€äº›å·®å¼‚ã€‚\n\nlibrary(tidyverse)",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-many",
    "href": "base-R.html#sec-subset-many",
    "title": "27Â  A field guide to base R",
    "section": "\n27.2 Selecting multiple elements with [\n",
    "text": "27.2 Selecting multiple elements with [\n\n[ is used to extract sub-components from vectors and data frames, and is called like x[i] or x[i, j].[ ç”¨äºä»å‘é‡å’Œæ•°æ®æ¡†ä¸­æå–å­ç»„ä»¶ï¼Œè°ƒç”¨æ–¹å¼å¦‚ x[i] æˆ– x[i, j]ã€‚\nIn this section, weâ€™ll introduce you to the power of [, first showing you how you can use it with vectors, then how the same principles extend in a straightforward way to two-dimensional (2d) structures like data frames.\nåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å‘ä½ ä»‹ç» [ çš„å¼ºå¤§åŠŸèƒ½ï¼Œé¦–å…ˆå±•ç¤ºå¦‚ä½•å°†å…¶ç”¨äºå‘é‡ï¼Œç„¶åå±•ç¤ºç›¸åŒçš„åŸåˆ™å¦‚ä½•ç›´æ¥æ‰©å±•åˆ°äºŒç»´ï¼ˆ2Dï¼‰ç»“æ„ï¼Œå¦‚æ•°æ®æ¡†ã€‚\nWeâ€™ll then help you cement that knowledge by showing how various dplyr verbs are special cases of [.\nç„¶åï¼Œæˆ‘ä»¬å°†é€šè¿‡å±•ç¤ºå„ç§ dplyr åŠ¨è¯å¦‚ä½•æ˜¯ [ çš„ç‰¹ä¾‹æ¥å¸®åŠ©ä½ å·©å›ºè¿™äº›çŸ¥è¯†ã€‚\n\n27.2.1 Subsetting vectors\nThere are five main types of things that you can subset a vector with, i.e., that can be the i in x[i]:\nä½ å¯ä»¥ç”¨äº”ç§ä¸»è¦ç±»å‹çš„ä¸œè¥¿æ¥å¯¹å‘é‡è¿›è¡Œå­é›†æå–ï¼Œå³ x[i] ä¸­çš„ i å¯ä»¥æ˜¯ï¼š\n\n\nA vector of positive integers.ä¸€ä¸ªæ­£æ•´æ•°å‘é‡ã€‚\nSubsetting with positive integers keeps the elements at those positions:\nç”¨æ­£æ•´æ•°è¿›è¡Œå­é›†æå–ä¼šä¿ç•™é‚£äº›ä½ç½®ä¸Šçš„å…ƒç´ ï¼š\n\nx &lt;- c(\"one\", \"two\", \"three\", \"four\", \"five\")\nx[c(3, 2, 5)]\n#&gt; [1] \"three\" \"two\"   \"five\"\n\nBy repeating a position, you can actually make a longer output than input, making the term â€œsubsettingâ€ a bit of a misnomer.\né€šè¿‡é‡å¤ä¸€ä¸ªä½ç½®ï¼Œä½ å®é™…ä¸Šå¯ä»¥ä½¿è¾“å‡ºæ¯”è¾“å…¥æ›´é•¿ï¼Œè¿™ä½¿å¾—â€œå­é›†æå–â€è¿™ä¸ªæœ¯è¯­æœ‰ç‚¹ç”¨è¯ä¸å½“ã€‚\n\nx[c(1, 1, 5, 5, 5, 2)]\n#&gt; [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\"\n\n\n\nA vector of negative integers.ä¸€ä¸ªè´Ÿæ•´æ•°å‘é‡ã€‚\nNegative values drop the elements at the specified positions:\nè´Ÿå€¼ä¼šåˆ é™¤æŒ‡å®šä½ç½®çš„å…ƒç´ ï¼š\n\nx[c(-1, -3, -5)]\n#&gt; [1] \"two\"  \"four\"\n\n\n\nA logical vector.ä¸€ä¸ªé€»è¾‘å‘é‡ã€‚\nSubsetting with a logical vector keeps all values corresponding to a TRUE value.\nç”¨é€»è¾‘å‘é‡è¿›è¡Œå­é›†æå–ä¼šä¿ç•™æ‰€æœ‰å¯¹åº” TRUE å€¼çš„å€¼ã€‚\nThis is most often useful in conjunction with the comparison functions.\nè¿™åœ¨ä¸æ¯”è¾ƒå‡½æ•°ç»“åˆä½¿ç”¨æ—¶æœ€æœ‰ç”¨ã€‚\n\nx &lt;- c(10, 3, NA, 5, 8, 1, NA)\n\n# All non-missing values of x\nx[!is.na(x)]\n#&gt; [1] 10  3  5  8  1\n\n# All even (or missing!) values of x\nx[x %% 2 == 0]\n#&gt; [1] 10 NA  8 NA\n\nUnlike filter(), NA indices will be included in the output as NAs.\nä¸ filter() ä¸åŒï¼ŒNA ç´¢å¼•å°†ä½œä¸º NA åŒ…å«åœ¨è¾“å‡ºä¸­ã€‚\n\n\nA character vector.ä¸€ä¸ªå­—ç¬¦å‘é‡ã€‚\nIf you have a named vector, you can subset it with a character vector:\nå¦‚æœä½ æœ‰ä¸€ä¸ªå‘½åçš„å‘é‡ï¼Œä½ å¯ä»¥ç”¨ä¸€ä¸ªå­—ç¬¦å‘é‡æ¥å¯¹å®ƒè¿›è¡Œå­é›†æå–ï¼š\n\nx &lt;- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n#&gt; xyz def \n#&gt;   5   2\n\nAs with subsetting with positive integers, you can use a character vector to duplicate individual entries.\nä¸ä½¿ç”¨æ­£æ•´æ•°è¿›è¡Œå­é›†æå–ä¸€æ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨å­—ç¬¦å‘é‡æ¥å¤åˆ¶å•ä¸ªæ¡ç›®ã€‚\n\nNothing.ä»€ä¹ˆéƒ½ä¸æä¾›ã€‚\nThe final type of subsetting is nothing, x[], which returns the complete x.\næœ€åä¸€ç§å­é›†æå–æ˜¯ä»€ä¹ˆéƒ½ä¸æä¾›ï¼Œå³ x[]ï¼Œå®ƒè¿”å›å®Œæ•´çš„ xã€‚\n\nThis is not useful for subsetting vectors, but as weâ€™ll see shortly, it is useful when subsetting 2d structures like tibbles.\nè¿™å¯¹äºå‘é‡çš„å­é›†æå–æ²¡æœ‰ç”¨ï¼Œä½†æ­£å¦‚æˆ‘ä»¬ç¨åå°†çœ‹åˆ°çš„ï¼Œå®ƒåœ¨å¯¹åƒ tibble è¿™æ ·çš„äºŒç»´ç»“æ„è¿›è¡Œå­é›†æå–æ—¶å¾ˆæœ‰ç”¨ã€‚\n\n27.2.2 Subsetting data frames\nThere are quite a few different ways1 that you can use [ with a data frame, but the most important way is to select rows and columns independently with df[rows, cols]. Here rows and cols are vectors as described above.\nä½ å¯ä»¥ç”¨å¤šç§ä¸åŒçš„æ–¹å¼1 å¯¹æ•°æ®æ¡†ä½¿ç”¨ [ï¼Œä½†æœ€é‡è¦çš„æ–¹å¼æ˜¯ä½¿ç”¨ df[rows, cols] ç‹¬ç«‹åœ°é€‰æ‹©è¡Œå’Œåˆ—ã€‚è¿™é‡Œçš„ rows å’Œ cols æ˜¯å¦‚ä¸Šæ‰€è¿°çš„å‘é‡ã€‚\nFor example, df[rows, ] and df[, cols] select just rows or just columns, using the empty subset to preserve the other dimension.\nä¾‹å¦‚ï¼Œdf[rows, ] å’Œ df[, cols] åªé€‰æ‹©è¡Œæˆ–åˆ—ï¼Œä½¿ç”¨ç©ºçš„å­é›†æ¥ä¿ç•™å¦ä¸€ç»´åº¦ã€‚\nHere are a couple of examples:\nè¿™é‡Œæœ‰å‡ ä¸ªä¾‹å­ï¼š\n\ndf &lt;- tibble(\n  x = 1:3, \n  y = c(\"a\", \"e\", \"f\"), \n  z = runif(3)\n)\n\n# Select first row and second column\ndf[1, 2]\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   y    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a\n\n# Select all rows and columns x and y\ndf[, c(\"x\" , \"y\")]\n#&gt; # A tibble: 3 Ã— 2\n#&gt;       x y    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 a    \n#&gt; 2     2 e    \n#&gt; 3     3 f\n\n# Select rows where `x` is greater than 1 and all columns\ndf[df$x &gt; 1, ]\n#&gt; # A tibble: 2 Ã— 3\n#&gt;       x y         z\n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2 e     0.834\n#&gt; 2     3 f     0.601\n\nWeâ€™ll come back to $ shortly, but you should be able to guess what df$x does from the context: it extracts the x variable from df.\næˆ‘ä»¬ç¨åä¼šå›åˆ° $ï¼Œä½†ä½ åº”è¯¥èƒ½ä»ä¸Šä¸‹æ–‡ä¸­çŒœå‡º df$x çš„ä½œç”¨ï¼šå®ƒä» df ä¸­æå– x å˜é‡ã€‚\nWe need to use it here because [ doesnâ€™t use tidy evaluation, so you need to be explicit about the source of the x variable.\næˆ‘ä»¬åœ¨è¿™é‡Œéœ€è¦ä½¿ç”¨å®ƒï¼Œå› ä¸º [ ä¸ä½¿ç”¨æ•´æ´è¯„ä¼° (tidy evaluation)ï¼Œæ‰€ä»¥ä½ éœ€è¦æ˜ç¡® x å˜é‡çš„æ¥æºã€‚\nThereâ€™s an important difference between tibbles and data frames when it comes to [.\nåœ¨ [ çš„ä½¿ç”¨ä¸Šï¼Œtibble å’Œæ•°æ®æ¡†ä¹‹é—´æœ‰ä¸€ä¸ªé‡è¦çš„åŒºåˆ«ã€‚\nIn this book, weâ€™ve mainly used tibbles, which are data frames, but they tweak some behaviors to make your life a little easier.\nåœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦ä½¿ç”¨ tibbleï¼Œå®ƒæ˜¯æ•°æ®æ¡†ï¼Œä½†å®ƒä»¬è°ƒæ•´äº†ä¸€äº›è¡Œä¸ºï¼Œè®©ä½ çš„ç”Ÿæ´»æ›´è½»æ¾ä¸€äº›ã€‚\nIn most places, you can use â€œtibbleâ€ and â€œdata frameâ€ interchangeably, so when we want to draw particular attention to Râ€™s built-in data frame, weâ€™ll write data.frame.\nåœ¨å¤§å¤šæ•°åœ°æ–¹ï¼Œä½ å¯ä»¥äº’æ¢ä½¿ç”¨ â€œtibbleâ€ å’Œ â€œdata frameâ€ï¼Œæ‰€ä»¥å½“æˆ‘ä»¬æƒ³ç‰¹åˆ«æŒ‡å‡º R çš„å†…ç½®æ•°æ®æ¡†æ—¶ï¼Œæˆ‘ä»¬ä¼šå†™ data.frameã€‚\nIf df is a data.frame, then df[, cols] will return a vector if col selects a single column and a data frame if it selects more than one column.\nå¦‚æœ df æ˜¯ä¸€ä¸ª data.frameï¼Œé‚£ä¹ˆå¦‚æœ col é€‰æ‹©å•ä¸ªåˆ—ï¼Œdf[, cols] å°†è¿”å›ä¸€ä¸ªå‘é‡ï¼›å¦‚æœé€‰æ‹©å¤šä¸ªåˆ—ï¼Œåˆ™è¿”å›ä¸€ä¸ªæ•°æ®æ¡†ã€‚\nIf df is a tibble, then [ will always return a tibble.\nå¦‚æœ df æ˜¯ä¸€ä¸ª tibbleï¼Œé‚£ä¹ˆ [ å°†æ€»æ˜¯è¿”å›ä¸€ä¸ª tibbleã€‚\n\ndf1 &lt;- data.frame(x = 1:3)\ndf1[, \"x\"]\n#&gt; [1] 1 2 3\n\ndf2 &lt;- tibble(x = 1:3)\ndf2[, \"x\"]\n#&gt; # A tibble: 3 Ã— 1\n#&gt;       x\n#&gt;   &lt;int&gt;\n#&gt; 1     1\n#&gt; 2     2\n#&gt; 3     3\n\nOne way to avoid this ambiguity with data.frames is to explicitly specify drop = FALSE:\nè¦é¿å… data.frame çš„è¿™ç§ä¸ç¡®å®šæ€§ï¼Œä¸€ç§æ–¹æ³•æ˜¯æ˜ç¡®æŒ‡å®š drop = FALSEï¼š\n\ndf1[, \"x\" , drop = FALSE]\n#&gt;   x\n#&gt; 1 1\n#&gt; 2 2\n#&gt; 3 3\n\n\n27.2.3 dplyr equivalents\nSeveral dplyr verbs are special cases of [:\næœ‰å‡ ä¸ª dplyr åŠ¨è¯æ˜¯ [ çš„ç‰¹ä¾‹ï¼š\n\n\nfilter() is equivalent to subsetting the rows with a logical vector, taking care to exclude missing values:filter() ç­‰åŒäºä½¿ç”¨é€»è¾‘å‘é‡å¯¹è¡Œè¿›è¡Œå­é›†æå–ï¼Œå¹¶æ³¨æ„æ’é™¤ç¼ºå¤±å€¼ï¼š\n\ndf &lt;- tibble(\n  x = c(2, 3, 1, 1, NA), \n  y = letters[1:5], \n  z = runif(5)\n)\ndf |&gt; filter(x &gt; 1)\n\n# same as\ndf[!is.na(df$x) & df$x &gt; 1, ]\n\nAnother common technique in the wild is to use which() for its side-effect of dropping missing values: df[which(df$x &gt; 1), ].\nåœ¨å®è·µä¸­ï¼Œå¦ä¸€ç§å¸¸è§çš„æŠ€å·§æ˜¯ä½¿ç”¨ which()ï¼Œåˆ©ç”¨å…¶å¯ä»¥ä¸¢å¼ƒç¼ºå¤±å€¼çš„å‰¯ä½œç”¨ï¼šdf[which(df$x &gt; 1), ]ã€‚\n\n\narrange() is equivalent to subsetting the rows with an integer vector, usually created with order():arrange() ç­‰åŒäºä½¿ç”¨ä¸€ä¸ªæ•´æ•°å‘é‡å¯¹è¡Œè¿›è¡Œå­é›†æå–ï¼Œè¿™ä¸ªå‘é‡é€šå¸¸ç”± order() åˆ›å»ºï¼š\n\ndf |&gt; arrange(x, y)\n\n# same as\ndf[order(df$x, df$y), ]\n\nYou can use order(decreasing = TRUE) to sort all columns in descending order or -rank(col) to sort columns in decreasing order individually.\nä½ å¯ä»¥ä½¿ç”¨ order(decreasing = TRUE) æŒ‰é™åºå¯¹æ‰€æœ‰åˆ—è¿›è¡Œæ’åºï¼Œæˆ–è€…ä½¿ç”¨ -rank(col) å•ç‹¬æŒ‰é™åºå¯¹åˆ—è¿›è¡Œæ’åºã€‚\n\nBoth select() and relocate() are similar to subsetting the columns with a character vector:select() å’Œ relocate() éƒ½ç±»ä¼¼äºä½¿ç”¨å­—ç¬¦å‘é‡å¯¹åˆ—è¿›è¡Œå­é›†æå–ï¼š\n\n\ndf |&gt; select(x, z)\n\n# same as\ndf[, c(\"x\", \"z\")]\n\n\n\nBase R also provides a function that combines the features of filter() and select()2 called subset():\nåŸºç¡€ R è¿˜æä¾›äº†ä¸€ä¸ªåä¸º subset() çš„å‡½æ•°ï¼Œå®ƒç»“åˆäº† filter() å’Œ select() çš„åŠŸèƒ½2ï¼š\n\ndf |&gt; \n  filter(x &gt; 1) |&gt; \n  select(y, z)\n#&gt; # A tibble: 2 Ã— 2\n#&gt;   y           z\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a     0.157  \n#&gt; 2 b     0.00740\n\n\n# same as\ndf |&gt; subset(x &gt; 1, c(y, z))\n\nThis function was the inspiration for much of dplyrâ€™s syntax.\nè¿™ä¸ªå‡½æ•°æ˜¯ dplyr è®¸å¤šè¯­æ³•çš„çµæ„Ÿæ¥æºã€‚\n\n27.2.4 Exercises\n\n\nCreate functions that take a vector as input and return:\n\nThe elements at even-numbered positions.\nEvery element except the last value.\nOnly even values (and no missing values).\n\n\nWhy is x[-which(x &gt; 0)] not the same as x[x &lt;= 0]? Read the documentation for which() and do some experiments to figure it out.",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-one",
    "href": "base-R.html#sec-subset-one",
    "title": "27Â  A field guide to base R",
    "section": "\n27.3 Selecting a single element with $ and [[\n",
    "text": "27.3 Selecting a single element with $ and [[\n\n[, which selects many elements, is paired with [[ and $, which extract a single element.\nç”¨äºé€‰æ‹©å¤šä¸ªå…ƒç´ çš„ [ ä¸ç”¨äºæå–å•ä¸ªå…ƒç´ çš„ [[ å’Œ $ é…å¯¹ä½¿ç”¨ã€‚\nIn this section, weâ€™ll show you how to use [[ and $ to pull columns out of data frames, discuss a couple more differences between data.frames and tibbles, and emphasize some important differences between [ and [[ when used with lists.\nåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨ [[ å’Œ $ ä»æ•°æ®æ¡†ä¸­æå–åˆ—ï¼Œè®¨è®º data.frame å’Œ tibble ä¹‹é—´çš„æ›´å¤šå·®å¼‚ï¼Œå¹¶å¼ºè°ƒåœ¨ä¸åˆ—è¡¨ä¸€èµ·ä½¿ç”¨æ—¶ [ å’Œ [[ ä¹‹é—´çš„ä¸€äº›é‡è¦åŒºåˆ«ã€‚\n\n27.3.1 Data frames\n[[ and $ can be used to extract columns out of a data frame.[[ å’Œ $ å¯ä»¥ç”¨æ¥ä»æ•°æ®æ¡†ä¸­æå–åˆ—ã€‚\n[[ can access by position or by name, and $ is specialized for access by name:[[ å¯ä»¥é€šè¿‡ä½ç½®æˆ–åç§°è®¿é—®ï¼Œè€Œ $ åˆ™ä¸“é—¨ç”¨äºé€šè¿‡åç§°è®¿é—®ï¼š\n\ntb &lt;- tibble(\n  x = 1:4,\n  y = c(10, 4, 1, 21)\n)\n\n# by position\ntb[[1]]\n#&gt; [1] 1 2 3 4\n\n# by name\ntb[[\"x\"]]\n#&gt; [1] 1 2 3 4\ntb$x\n#&gt; [1] 1 2 3 4\n\nThey can also be used to create new columns, the base R equivalent of mutate():\nå®ƒä»¬ä¹Ÿå¯ä»¥ç”¨æ¥åˆ›å»ºæ–°åˆ—ï¼Œè¿™ç›¸å½“äºåŸºç¡€ R ä¸­çš„ mutate()ï¼š\n\ntb$z &lt;- tb$x + tb$y\ntb\n#&gt; # A tibble: 4 Ã— 3\n#&gt;       x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    10    11\n#&gt; 2     2     4     6\n#&gt; 3     3     1     4\n#&gt; 4     4    21    25\n\nThere are several other base R approaches to creating new columns including with transform(), with(), and within().\nè¿˜æœ‰å…¶ä»–å‡ ç§åŸºç¡€ R çš„æ–¹æ³•å¯ä»¥åˆ›å»ºæ–°åˆ—ï¼ŒåŒ…æ‹¬ä½¿ç”¨ transform()ã€with() å’Œ within()ã€‚\nHadley collected a few examples at https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf.\nHadley åœ¨ https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf æ”¶é›†äº†ä¸€äº›ä¾‹å­ã€‚\nUsing $ directly is convenient when performing quick summaries.\nåœ¨è¿›è¡Œå¿«é€Ÿæ‘˜è¦æ—¶ï¼Œç›´æ¥ä½¿ç”¨ $ å¾ˆæ–¹ä¾¿ã€‚\nFor example, if you just want to find the size of the biggest diamond or the possible values of cut, thereâ€™s no need to use summarize():\nä¾‹å¦‚ï¼Œå¦‚æœä½ åªæƒ³æ‰¾åˆ°æœ€å¤§é’»çŸ³çš„å°ºå¯¸æˆ– cut çš„å¯èƒ½å€¼ï¼Œå°±ä¸éœ€è¦ä½¿ç”¨ summarize()ï¼š\n\nmax(diamonds$carat)\n#&gt; [1] 5.01\n\nlevels(diamonds$cut)\n#&gt; [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\ndplyr also provides an equivalent to [[/$ that we didnâ€™t mention in Chapter 3: pull().\ndplyr ä¹Ÿæä¾›äº†ä¸€ä¸ªç­‰ä»·äº [[/$ çš„å‡½æ•°ï¼Œæˆ‘ä»¬åœ¨ Chapter 3 ä¸­æ²¡æœ‰æåˆ°ï¼špull()ã€‚\npull() takes either a variable name or variable position and returns just that column.pull() æ¥å—å˜é‡åæˆ–å˜é‡ä½ç½®ï¼Œå¹¶åªè¿”å›é‚£ä¸€åˆ—ã€‚\nThat means we could rewrite the above code to use the pipe:\nè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é‡å†™ä¸Šé¢çš„ä»£ç æ¥ä½¿ç”¨ç®¡é“ï¼š\n\ndiamonds |&gt; pull(carat) |&gt; max()\n#&gt; [1] 5.01\n\ndiamonds |&gt; pull(cut) |&gt; levels()\n#&gt; [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\n\n27.3.2 Tibbles\nThere are a couple of important differences between tibbles and base data.frames when it comes to $. Data frames match the prefix of any variable names (so-called partial matching) and donâ€™t complain if a column doesnâ€™t exist:\nåœ¨ä½¿ç”¨ $ æ—¶ï¼Œtibble å’ŒåŸºç¡€ data.frame ä¹‹é—´æœ‰å‡ ä¸ªé‡è¦çš„åŒºåˆ«ã€‚æ•°æ®æ¡†ä¼šåŒ¹é…ä»»ä½•å˜é‡åçš„å‰ç¼€ï¼ˆæ‰€è°“çš„éƒ¨åˆ†åŒ¹é… (partial matching)ï¼‰ï¼Œå¹¶ä¸”å¦‚æœåˆ—ä¸å­˜åœ¨ä¹Ÿä¸ä¼šæŠ¥é”™ï¼š\n\ndf &lt;- data.frame(x1 = 1)\ndf$x\n#&gt; [1] 1\ndf$z\n#&gt; NULL\n\nTibbles are more strict: they only ever match variable names exactly and they will generate a warning if the column you are trying to access doesnâ€™t exist:\nTibble æ›´ä¸ºä¸¥æ ¼ï¼šå®ƒä»¬åªç²¾ç¡®åŒ¹é…å˜é‡åï¼Œå¹¶ä¸”å¦‚æœä½ å°è¯•è®¿é—®çš„åˆ—ä¸å­˜åœ¨ï¼Œå®ƒä»¬ä¼šç”Ÿæˆä¸€ä¸ªè­¦å‘Šï¼š\n\ntb &lt;- tibble(x1 = 1)\n\ntb$x\n#&gt; Warning: Unknown or uninitialised column: `x`.\n#&gt; NULL\ntb$z\n#&gt; Warning: Unknown or uninitialised column: `z`.\n#&gt; NULL\n\nFor this reason we sometimes joke that tibbles are lazy and surly: they do less and complain more.\nå› æ­¤ï¼Œæˆ‘ä»¬æœ‰æ—¶å¼€ç©ç¬‘è¯´ tibble æ—¢æ‡’æƒ°åˆæš´èºï¼šå®ƒä»¬åšå¾—æ›´å°‘ï¼ŒæŠ±æ€¨å¾—æ›´å¤šã€‚\n\n27.3.3 Lists\n[[ and $ are also really important for working with lists, and itâ€™s important to understand how they differ from [. Letâ€™s illustrate the differences with a list named l:[[ å’Œ $ åœ¨å¤„ç†åˆ—è¡¨æ—¶ä¹Ÿéå¸¸é‡è¦ï¼Œç†è§£å®ƒä»¬ä¸ [ çš„åŒºåˆ«è‡³å…³é‡è¦ã€‚è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªåä¸º l çš„åˆ—è¡¨æ¥è¯´æ˜è¿™äº›å·®å¼‚ï¼š\n\nl &lt;- list(\n  a = 1:3, \n  b = \"a string\", \n  c = pi, \n  d = list(-1, -5)\n)\n\n\n\n[ extracts a sub-list. It doesnâ€™t matter how many elements you extract, the result will always be a list.[ æå–ä¸€ä¸ªå­åˆ—è¡¨ã€‚æ— è®ºä½ æå–å¤šå°‘ä¸ªå…ƒç´ ï¼Œç»“æœæ€»æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚\n\nstr(l[1:2])\n#&gt; List of 2\n#&gt;  $ a: int [1:3] 1 2 3\n#&gt;  $ b: chr \"a string\"\n\nstr(l[1])\n#&gt; List of 1\n#&gt;  $ a: int [1:3] 1 2 3\n\nstr(l[4])\n#&gt; List of 1\n#&gt;  $ d:List of 2\n#&gt;   ..$ : num -1\n#&gt;   ..$ : num -5\n\nLike with vectors, you can subset with a logical, integer, or character vector.\nä¸å‘é‡ä¸€æ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨é€»è¾‘å‹ã€æ•´å‹æˆ–å­—ç¬¦å‹å‘é‡è¿›è¡Œå­é›†æå–ã€‚\n\n\n[[ and $ extract a single component from a list. They remove a level of hierarchy from the list.[[ å’Œ $ ä»åˆ—è¡¨ä¸­æå–å•ä¸ªç»„ä»¶ã€‚å®ƒä»¬ä¼šä»åˆ—è¡¨ä¸­ç§»é™¤ä¸€ä¸ªå±‚çº§ã€‚\n\nstr(l[[1]])\n#&gt;  int [1:3] 1 2 3\n\nstr(l[[4]])\n#&gt; List of 2\n#&gt;  $ : num -1\n#&gt;  $ : num -5\n\nstr(l$a)\n#&gt;  int [1:3] 1 2 3\n\n\n\nThe difference between [ and [[ is particularly important for lists because [[ drills down into the list while [ returns a new, smaller list. To help you remember the difference, take a look at the unusual pepper shaker shown in FigureÂ 27.1. If this pepper shaker is your list pepper, then, pepper[1] is a pepper shaker containing a single pepper packet. pepper[2] would look the same, but would contain the second packet. pepper[1:2] would be a pepper shaker containing two pepper packets. pepper[[1]] would extract the pepper packet itself.[ å’Œ [[ ä¹‹é—´çš„åŒºåˆ«å¯¹äºåˆ—è¡¨å°¤å…¶é‡è¦ï¼Œå› ä¸º [[ ä¼šæ·±å…¥åˆ°åˆ—è¡¨ä¸­ï¼Œè€Œ [ è¿”å›ä¸€ä¸ªæ–°çš„ã€æ›´å°çš„åˆ—è¡¨ã€‚ä¸ºäº†å¸®åŠ©ä½ è®°ä½è¿™ä¸ªåŒºåˆ«ï¼Œè¯·çœ‹ FigureÂ 27.1 ä¸­å±•ç¤ºçš„é‚£ä¸ªä¸å¯»å¸¸çš„èƒ¡æ¤’ç“¶ã€‚å¦‚æœè¿™ä¸ªèƒ¡æ¤’ç“¶æ˜¯ä½ çš„åˆ—è¡¨ pepperï¼Œé‚£ä¹ˆ pepper[1] å°±æ˜¯ä¸€ä¸ªåŒ…å«å•ä¸ªèƒ¡æ¤’åŒ…çš„èƒ¡æ¤’ç“¶ã€‚pepper[2] çœ‹èµ·æ¥ä¸€æ ·ï¼Œä½†ä¼šåŒ…å«ç¬¬äºŒä¸ªåŒ…ã€‚pepper[1:2] å°†æ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªèƒ¡æ¤’åŒ…çš„èƒ¡æ¤’ç“¶ã€‚è€Œ pepper[[1]] åˆ™ä¼šæå–å‡ºèƒ¡æ¤’åŒ…æœ¬èº«ã€‚\n\n\n\n\n\n\n\nFigureÂ 27.1: (Left) A pepper shaker that Hadley once found in his hotel room. (Middle) pepper[1]. (Right) pepper[[1]]\n\n\n\n\nThis same principle applies when you use 1d [ with a data frame: df[\"x\"] returns a one-column data frame and df[[\"x\"]] returns a vector.\nå½“ä½ å¯¹æ•°æ®æ¡†ä½¿ç”¨ä¸€ç»´ [ æ—¶ï¼ŒåŒæ ·çš„åŸåˆ™ä¹Ÿé€‚ç”¨ï¼šdf[\"x\"] è¿”å›ä¸€ä¸ªå•åˆ—æ•°æ®æ¡†ï¼Œè€Œ df[[\"x\"]] è¿”å›ä¸€ä¸ªå‘é‡ã€‚\n\n27.3.4 Exercises\n\nWhat happens when you use [[ with a positive integer thatâ€™s bigger than the length of the vector? What happens when you subset with a name that doesnâ€™t exist?\nWhat would pepper[[1]][1] be? What about pepper[[1]][[1]]?",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#apply-family",
    "href": "base-R.html#apply-family",
    "title": "27Â  A field guide to base R",
    "section": "\n27.4 Apply family",
    "text": "27.4 Apply family\nIn Chapter 26, you learned tidyverse techniques for iteration like dplyr::across() and the map family of functions. In this section, youâ€™ll learn about their base equivalents, the apply family. In this context apply and map are synonyms because another way of saying â€œmap a function over each element of a vectorâ€ is â€œapply a function over each element of a vectorâ€. Here weâ€™ll give you a quick overview of this family so you can recognize them in the wild.\nåœ¨ Chapter 26 ä¸­ï¼Œä½ å­¦ä¹ äº† tidyverse çš„è¿­ä»£æŠ€æœ¯ï¼Œå¦‚ dplyr::across() å’Œ map ç³»åˆ—å‡½æ•°ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å®ƒä»¬åœ¨åŸºç¡€ R ä¸­çš„ç­‰ä»·ç‰©ï¼Œå³ apply å®¶æ—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œapply å’Œ map æ˜¯åŒä¹‰è¯ï¼Œå› ä¸ºâ€œå°†å‡½æ•°æ˜ å°„åˆ°å‘é‡çš„æ¯ä¸ªå…ƒç´ ä¸Šâ€çš„å¦ä¸€ç§è¯´æ³•æ˜¯â€œå°†å‡½æ•°åº”ç”¨äºå‘é‡çš„æ¯ä¸ªå…ƒç´ ä¸Šâ€ã€‚è¿™é‡Œæˆ‘ä»¬å°†å¿«é€Ÿä»‹ç»è¿™ä¸ªå®¶æ—ï¼Œä»¥ä¾¿ä½ åœ¨å®é™…ä¸­èƒ½è®¤å‡ºå®ƒä»¬ã€‚\nThe most important member of this family is lapply(), which is very similar to purrr::map()3. In fact, because we havenâ€™t used any of map()â€™s more advanced features, you can replace every map() call in Chapter 26 with lapply().\nè¿™ä¸ªå®¶æ—ä¸­æœ€é‡è¦çš„æˆå‘˜æ˜¯ lapply()ï¼Œå®ƒä¸ purrr::map() éå¸¸ç›¸ä¼¼3ã€‚äº‹å®ä¸Šï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ map() çš„ä»»ä½•æ›´é«˜çº§çš„åŠŸèƒ½ï¼Œä½ å¯ä»¥ç”¨ lapply() æ›¿æ¢ Chapter 26 ä¸­çš„æ¯ä¸€ä¸ª map() è°ƒç”¨ã€‚\nThereâ€™s no exact base R equivalent to across() but you can get close by using [ with lapply(). This works because under the hood, data frames are lists of columns, so calling lapply() on a data frame applies the function to each column.\nåŸºç¡€ R ä¸­æ²¡æœ‰ä¸ across() å®Œå…¨ç­‰ä»·çš„å‡½æ•°ï¼Œä½†ä½ å¯ä»¥é€šè¿‡å°† [ ä¸ lapply() ç»“åˆä½¿ç”¨æ¥æ¥è¿‘å®ƒçš„åŠŸèƒ½ã€‚è¿™æ ·åšæ˜¯å¯è¡Œçš„ï¼Œå› ä¸ºåœ¨åº•å±‚ï¼Œæ•°æ®æ¡†æ˜¯åˆ—çš„åˆ—è¡¨ï¼Œæ‰€ä»¥å¯¹æ•°æ®æ¡†è°ƒç”¨ lapply() ä¼šå°†å‡½æ•°åº”ç”¨äºæ¯ä¸€åˆ—ã€‚\n\ndf &lt;- tibble(a = 1, b = 2, c = \"a\", d = \"b\", e = 4)\n\n# First find numeric columns\nnum_cols &lt;- sapply(df, is.numeric)\nnum_cols\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\n# Then transform each column with lapply() then replace the original values\ndf[, num_cols] &lt;- lapply(df[, num_cols, drop = FALSE], \\(x) x * 2)\ndf\n#&gt; # A tibble: 1 Ã— 5\n#&gt;       a     b c     d         e\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2     4 a     b         8\n\nThe code above uses a new function, sapply(). Itâ€™s similar to lapply() but it always tries to simplify the result, hence the s in its name, here producing a logical vector instead of a list. We donâ€™t recommend using it for programming, because the simplification can fail and give you an unexpected type, but itâ€™s usually fine for interactive use. purrr has a similar function called map_vec() that we didnâ€™t mention in Chapter 26.\nä¸Šé¢çš„ä»£ç ä½¿ç”¨äº†ä¸€ä¸ªæ–°å‡½æ•° sapply()ã€‚å®ƒä¸ lapply() ç›¸ä¼¼ï¼Œä½†å®ƒæ€»æ˜¯å°è¯•ç®€åŒ–ç»“æœï¼Œå› æ­¤å…¶åç§°ä¸­å¸¦æœ‰ sï¼Œè¿™é‡Œå®ƒäº§ç”Ÿä¸€ä¸ªé€»è¾‘å‘é‡è€Œä¸æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚æˆ‘ä»¬ä¸å»ºè®®åœ¨ç¼–ç¨‹ä¸­ä½¿ç”¨å®ƒï¼Œå› ä¸ºç®€åŒ–å¯èƒ½ä¼šå¤±è´¥å¹¶ç»™ä½ ä¸€ä¸ªæ„æƒ³ä¸åˆ°çš„ç±»å‹ï¼Œä½†å¯¹äºäº¤äº’å¼ä½¿ç”¨æ¥è¯´é€šå¸¸æ²¡é—®é¢˜ã€‚purrr æœ‰ä¸€ä¸ªç±»ä¼¼çš„å‡½æ•°å«åš map_vec()ï¼Œæˆ‘ä»¬åœ¨ Chapter 26 ä¸­æ²¡æœ‰æåˆ°ã€‚\nBase R provides a stricter version of sapply() called vapply(), short for vector apply. It takes an additional argument that specifies the expected type, ensuring that simplification occurs the same way regardless of the input. For example, we could replace the sapply() call above with this vapply() where we specify that we expect is.numeric() to return a logical vector of length 1:\nåŸºç¡€ R æä¾›äº†ä¸€ä¸ªæ›´ä¸¥æ ¼çš„ sapply() ç‰ˆæœ¬ï¼Œåä¸º vapply()ï¼Œæ˜¯ vector apply çš„ç¼©å†™ã€‚å®ƒæ¥å—ä¸€ä¸ªé¢å¤–çš„å‚æ•°æ¥æŒ‡å®šé¢„æœŸçš„ç±»å‹ï¼Œç¡®ä¿æ— è®ºè¾“å…¥å¦‚ä½•ï¼Œç®€åŒ–éƒ½ä»¥ç›¸åŒçš„æ–¹å¼å‘ç”Ÿã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ª vapply() æ›¿æ¢ä¸Šé¢çš„ sapply() è°ƒç”¨ï¼Œæˆ‘ä»¬åœ¨å…¶ä¸­æŒ‡å®šæˆ‘ä»¬æœŸæœ› is.numeric() è¿”å›ä¸€ä¸ªé•¿åº¦ä¸º 1 çš„é€»è¾‘å‘é‡ï¼š\n\nvapply(df, is.numeric, logical(1))\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\nThe distinction between sapply() and vapply() is really important when theyâ€™re inside a function (because it makes a big difference to the functionâ€™s robustness to unusual inputs), but it doesnâ€™t usually matter in data analysis.sapply() å’Œ vapply() ä¹‹é—´çš„åŒºåˆ«åœ¨å®ƒä»¬ä½äºå‡½æ•°å†…éƒ¨æ—¶éå¸¸é‡è¦ï¼ˆå› ä¸ºå®ƒå¯¹å‡½æ•°å¯¹å¼‚å¸¸è¾“å…¥çš„é²æ£’æ€§æœ‰å¾ˆå¤§å½±å“ï¼‰ï¼Œä½†åœ¨æ•°æ®åˆ†æä¸­é€šå¸¸æ— å…³ç´§è¦ã€‚\nAnother important member of the apply family is tapply() which computes a single grouped summary:\napply å®¶æ—çš„å¦ä¸€ä¸ªé‡è¦æˆå‘˜æ˜¯ tapply()ï¼Œå®ƒè®¡ç®—å•ä¸ªåˆ†ç»„æ‘˜è¦ï¼š\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize(price = mean(price))\n#&gt; # A tibble: 5 Ã— 2\n#&gt;   cut       price\n#&gt;   &lt;ord&gt;     &lt;dbl&gt;\n#&gt; 1 Fair      4359.\n#&gt; 2 Good      3929.\n#&gt; 3 Very Good 3982.\n#&gt; 4 Premium   4584.\n#&gt; 5 Ideal     3458.\n\ntapply(diamonds$price, diamonds$cut, mean)\n#&gt;      Fair      Good Very Good   Premium     Ideal \n#&gt;  4358.758  3928.864  3981.760  4584.258  3457.542\n\nUnfortunately tapply() returns its results in a named vector which requires some gymnastics if you want to collect multiple summaries and grouping variables into a data frame (itâ€™s certainly possible to not do this and just work with free floating vectors, but in our experience that just delays the work). If you want to see how you might use tapply() or other base techniques to perform other grouped summaries, Hadley has collected a few techniques in a gist.\nä¸å¹¸çš„æ˜¯ï¼Œtapply() ä»¥å‘½åå‘é‡çš„å½¢å¼è¿”å›å…¶ç»“æœï¼Œå¦‚æœä½ æƒ³å°†å¤šä¸ªæ‘˜è¦å’Œåˆ†ç»„å˜é‡æ”¶é›†åˆ°ä¸€ä¸ªæ•°æ®æ¡†ä¸­ï¼Œå°±éœ€è¦ä¸€äº›æŠ€å·§ï¼ˆå½“ç„¶å¯ä»¥ä¸è¿™æ ·åšï¼Œåªä½¿ç”¨è‡ªç”±æµ®åŠ¨çš„å‘é‡ï¼Œä½†æ ¹æ®æˆ‘ä»¬çš„ç»éªŒï¼Œè¿™åªæ˜¯æ¨è¿Ÿäº†å·¥ä½œï¼‰ã€‚å¦‚æœä½ æƒ³çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ tapply() æˆ–å…¶ä»–åŸºç¡€æŠ€æœ¯æ¥æ‰§è¡Œå…¶ä»–åˆ†ç»„æ‘˜è¦ï¼ŒHadley åœ¨ ä¸€ä¸ª gist ä¸­æ”¶é›†äº†ä¸€äº›æŠ€å·§ã€‚\nThe final member of the apply family is the titular apply(), which works with matrices and arrays. In particular, watch out for apply(df, 2, something), which is a slow and potentially dangerous way of doing lapply(df, something). This rarely comes up in data science because we usually work with data frames and not matrices.\napply å®¶æ—çš„æœ€åä¸€ä¸ªæˆå‘˜æ˜¯åŒåçš„ apply()ï¼Œå®ƒç”¨äºå¤„ç†çŸ©é˜µå’Œæ•°ç»„ã€‚ç‰¹åˆ«è¦æ³¨æ„ apply(df, 2, something)ï¼Œè¿™æ˜¯ä¸€ç§ç¼“æ…¢ä¸”å¯èƒ½å±é™©çš„æ–¹å¼æ¥æ‰§è¡Œ lapply(df, something)ã€‚è¿™åœ¨æ•°æ®ç§‘å­¦ä¸­å¾ˆå°‘å‡ºç°ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸å¤„ç†æ•°æ®æ¡†è€Œä¸æ˜¯çŸ©é˜µã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#for-loops",
    "href": "base-R.html#for-loops",
    "title": "27Â  A field guide to base R",
    "section": "\n27.5 for loops",
    "text": "27.5 for loops\nfor loops are the fundamental building block of iteration that both the apply and map families use under the hood. for loops are powerful and general tools that are important to learn as you become a more experienced R programmer. The basic structure of a for loop looks like this:for å¾ªç¯æ˜¯è¿­ä»£çš„åŸºæœ¬æ„å»ºå—ï¼Œapply å’Œ map å®¶æ—åœ¨åº•å±‚éƒ½ä½¿ç”¨äº†å®ƒã€‚for å¾ªç¯æ˜¯å¼ºå¤§è€Œé€šç”¨çš„å·¥å…·ï¼Œéšç€ä½ æˆä¸ºä¸€åæ›´æœ‰ç»éªŒçš„ R ç¨‹åºå‘˜ï¼Œå­¦ä¹ å®ƒä»¬éå¸¸é‡è¦ã€‚for å¾ªç¯çš„åŸºæœ¬ç»“æ„å¦‚ä¸‹ï¼š\n\nfor (element in vector) {\n  # do something with element\n}\n\nThe most straightforward use of for loops is to achieve the same effect as walk(): call some function with a side-effect on each element of a list. For example, in Section 26.4.1 instead of using walk():for å¾ªç¯æœ€ç›´æ¥çš„ç”¨é€”æ˜¯å®ç°ä¸ walk() ç›¸åŒçš„æ•ˆæœï¼šå¯¹åˆ—è¡¨çš„æ¯ä¸ªå…ƒç´ è°ƒç”¨æŸä¸ªå…·æœ‰å‰¯ä½œç”¨çš„å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œåœ¨ Section 26.4.1 ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ä½¿ç”¨ walk()ï¼š\n\npaths |&gt; walk(append_file)\n\nWe could have used a for loop:\nè€Œæ˜¯ä½¿ç”¨ for å¾ªç¯ï¼š\n\nfor (path in paths) {\n  append_file(path)\n}\n\nThings get a little trickier if you want to save the output of the for loop, for example reading all of the excel files in a directory like we did in Chapter 26:\nå¦‚æœä½ æƒ³ä¿å­˜ for å¾ªç¯çš„è¾“å‡ºï¼Œäº‹æƒ…ä¼šå˜å¾—ç¨å¾®å¤æ‚ä¸€äº›ï¼Œä¾‹å¦‚ï¼Œåƒæˆ‘ä»¬åœ¨ Chapter 26 ä¸­æ‰€åšçš„é‚£æ ·ï¼Œè¯»å–ç›®å½•ä¸­æ‰€æœ‰çš„ excel æ–‡ä»¶ï¼š\n\npaths &lt;- dir(\"data/gapminder\", pattern = \"\\\\.xlsx$\", full.names = TRUE)\nfiles &lt;- map(paths, readxl::read_excel)\n\nThere are a few different techniques that you can use, but we recommend being explicit about what the output is going to look like upfront. In this case, weâ€™re going to want a list the same length as paths, which we can create with vector():\nä½ å¯ä»¥ä½¿ç”¨å‡ ç§ä¸åŒçš„æŠ€æœ¯ï¼Œä½†æˆ‘ä»¬å»ºè®®é¢„å…ˆæ˜ç¡®è¾“å‡ºçš„æ ·å­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸ paths é•¿åº¦ç›¸åŒçš„åˆ—è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ vector() åˆ›å»ºå®ƒï¼š\n\nfiles &lt;- vector(\"list\", length(paths))\n\nThen instead of iterating over the elements of paths, weâ€™ll iterate over their indices, using seq_along() to generate one index for each element of paths:\nç„¶åï¼Œæˆ‘ä»¬ä¸éå† paths çš„å…ƒç´ ï¼Œè€Œæ˜¯éå†å®ƒä»¬çš„ç´¢å¼•ï¼Œä½¿ç”¨ seq_along() ä¸º paths çš„æ¯ä¸ªå…ƒç´ ç”Ÿæˆä¸€ä¸ªç´¢å¼•ï¼š\n\nseq_along(paths)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12\n\nUsing the indices is important because it allows us to link to each position in the input with the corresponding position in the output:\nä½¿ç”¨ç´¢å¼•å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒå…è®¸æˆ‘ä»¬å°†è¾“å…¥ä¸­çš„æ¯ä¸ªä½ç½®ä¸è¾“å‡ºä¸­ç›¸åº”çš„ä½ç½®é“¾æ¥èµ·æ¥ï¼š\n\nfor (i in seq_along(paths)) {\n  files[[i]] &lt;- readxl::read_excel(paths[[i]])\n}\n\nTo combine the list of tibbles into a single tibble you can use do.call() + rbind():\nè¦å°† tibble åˆ—è¡¨åˆå¹¶ä¸ºå•ä¸ª tibbleï¼Œä½ å¯ä»¥ä½¿ç”¨ do.call() + rbind()ï¼š\n\ndo.call(rbind, files)\n#&gt; # A tibble: 1,704 Ã— 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # â„¹ 1,698 more rows\n\nRather than making a list and saving the results as we go, a simpler approach is to build up the data frame piece-by-piece:\nä¸å…¶åˆ›å»ºä¸€ä¸ªåˆ—è¡¨å¹¶éšæ—¶ä¿å­˜ç»“æœï¼Œä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ³•æ˜¯é€ä¸ªæ„å»ºæ•°æ®æ¡†ï¼š\n\nout &lt;- NULL\nfor (path in paths) {\n  out &lt;- rbind(out, readxl::read_excel(path))\n}\n\nWe recommend avoiding this pattern because it can become very slow when the vector is very long. This is the source of the persistent canard that for loops are slow: theyâ€™re not, but iteratively growing a vector is.\næˆ‘ä»¬å»ºè®®é¿å…è¿™ç§æ¨¡å¼ï¼Œå› ä¸ºå½“å‘é‡éå¸¸é•¿æ—¶ï¼Œå®ƒä¼šå˜å¾—éå¸¸æ…¢ã€‚è¿™å°±æ˜¯ for å¾ªç¯å¾ˆæ…¢è¿™ä¸ªè°£è¨€çš„æ¥æºï¼šå®ƒä»¬æœ¬èº«ä¸æ…¢ï¼Œä½†è¿­ä»£åœ°å¢é•¿ä¸€ä¸ªå‘é‡æ˜¯æ…¢çš„ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#plots",
    "href": "base-R.html#plots",
    "title": "27Â  A field guide to base R",
    "section": "\n27.6 Plots",
    "text": "27.6 Plots\nMany R users who donâ€™t otherwise use the tidyverse prefer ggplot2 for plotting due to helpful features like sensible defaults, automatic legends, and a modern look. However, base R plotting functions can still be useful because theyâ€™re so concise â€” it takes very little typing to do a basic exploratory plot.\nè®¸å¤šä¸ä½¿ç”¨ tidyverse çš„ R ç”¨æˆ·ä¹Ÿå–œæ¬¢ç”¨ ggplot2 æ¥ç»˜å›¾ï¼Œå› ä¸ºå®ƒæœ‰è®¸å¤šæœ‰ç”¨çš„åŠŸèƒ½ï¼Œæ¯”å¦‚åˆç†çš„é»˜è®¤è®¾ç½®ã€è‡ªåŠ¨å›¾ä¾‹å’Œç°ä»£çš„å¤–è§‚ã€‚ç„¶è€Œï¼ŒåŸºç¡€ R çš„ç»˜å›¾å‡½æ•°ä»ç„¶å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒä»¬éå¸¸ç®€æ´â€”â€”åšä¸€ä¸ªåŸºæœ¬çš„æ¢ç´¢æ€§å›¾è¡¨åªéœ€è¦å¾ˆå°‘çš„è¾“å…¥ã€‚\nThere are two main types of base plot youâ€™ll see in the wild: scatterplots and histograms, produced with plot() and hist() respectively. Hereâ€™s a quick example from the diamonds dataset:\nä½ åœ¨å®è·µä¸­ä¼šçœ‹åˆ°ä¸¤ç§ä¸»è¦çš„åŸºç¡€å›¾ç±»å‹ï¼šæ•£ç‚¹å›¾å’Œç›´æ–¹å›¾ï¼Œåˆ†åˆ«ç”¨ plot() å’Œ hist() ç”Ÿæˆã€‚è¿™é‡Œæœ‰ä¸€ä¸ªæ¥è‡ª diamonds æ•°æ®é›†çš„å¿«é€Ÿç¤ºä¾‹ï¼š\n# Left\nhist(diamonds$carat)\n\n# Right\nplot(diamonds$carat, diamonds$price)\n\n\n\n\n\n\n\n\n\n\nNote that base plotting functions work with vectors, so you need to pull columns out of the data frame using $ or some other technique.\nè¯·æ³¨æ„ï¼ŒåŸºç¡€ç»˜å›¾å‡½æ•°æ˜¯ä½œç”¨äºå‘é‡çš„ï¼Œæ‰€ä»¥ä½ éœ€è¦ä½¿ç”¨ $ æˆ–å…¶ä»–æŠ€æœ¯ä»æ•°æ®æ¡†ä¸­æå–åˆ—ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#summary",
    "href": "base-R.html#summary",
    "title": "27Â  A field guide to base R",
    "section": "\n27.7 Summary",
    "text": "27.7 Summary\nIn this chapter, weâ€™ve shown you a selection of base R functions useful for subsetting and iteration. Compared to approaches discussed elsewhere in the book, these functions tend to have more of a â€œvectorâ€ flavor than a â€œdata frameâ€ flavor because base R functions tend to take individual vectors, rather than a data frame and some column specification. This often makes life easier for programming and so becomes more important as you write more functions and begin to write your own packages.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å‘ä½ å±•ç¤ºäº†ä¸€äº›ç”¨äºå­é›†å’Œè¿­ä»£çš„åŸºç¡€ R å‡½æ•°ã€‚ä¸æœ¬ä¹¦å…¶ä»–åœ°æ–¹è®¨è®ºçš„æ–¹æ³•ç›¸æ¯”ï¼Œè¿™äº›å‡½æ•°æ›´å…·â€œå‘é‡â€é£æ ¼è€Œéâ€œæ•°æ®æ¡†â€é£æ ¼ï¼Œå› ä¸ºåŸºç¡€ R å‡½æ•°å€¾å‘äºæ¥å—å•ä¸ªå‘é‡ï¼Œè€Œä¸æ˜¯æ•°æ®æ¡†å’Œä¸€äº›åˆ—è§„èŒƒã€‚è¿™é€šå¸¸ä½¿ç¼–ç¨‹ç”Ÿæ´»æ›´è½»æ¾ï¼Œå› æ­¤åœ¨ä½ ç¼–å†™æ›´å¤šå‡½æ•°å¹¶å¼€å§‹ç¼–å†™è‡ªå·±çš„åŒ…æ—¶å˜å¾—æ›´åŠ é‡è¦ã€‚\nThis chapter concludes the programming section of the book. Youâ€™ve made a solid start on your journey to becoming not just a data scientist who uses R, but a data scientist who can program in R. We hope these chapters have sparked your interest in programming and that youâ€™re looking forward to learning more outside of this book.\næœ¬ç« ç»“æŸäº†æœ¬ä¹¦çš„ç¼–ç¨‹éƒ¨åˆ†ã€‚ä½ å·²ç»åœ¨æˆä¸ºä¸€åä¸ä»…ä½¿ç”¨ R çš„æ•°æ®ç§‘å­¦å®¶ï¼Œè€Œä¸”æ˜¯èƒ½å¤Ÿç”¨ R ç¼–ç¨‹ çš„æ•°æ®ç§‘å­¦å®¶çš„é“è·¯ä¸Šè¿ˆå‡ºäº†åšå®çš„ä¸€æ­¥ã€‚æˆ‘ä»¬å¸Œæœ›è¿™äº›ç« èŠ‚èƒ½æ¿€å‘ä½ å¯¹ç¼–ç¨‹çš„å…´è¶£ï¼Œå¹¶æœŸå¾…ä½ åœ¨æœ¬ä¹¦ä¹‹å¤–å­¦ä¹ æ›´å¤šå†…å®¹ã€‚",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "base-R.html#footnotes",
    "href": "base-R.html#footnotes",
    "title": "27Â  A field guide to base R",
    "section": "",
    "text": "Read https://adv-r.hadley.nz/subsetting.html#subset-multiple to see how you can also subset a data frame like it is a 1d object and how you can subset it with a matrix.â†©ï¸\nBut it doesnâ€™t handle grouped data frames differently and it doesnâ€™t support selection helper functions like starts_with().â†©ï¸\nIt just lacks convenient features like progress bars and reporting which element caused the problem if thereâ€™s an error.â†©ï¸",
    "crumbs": [
      "Program",
      "<span class='chapter-number'>27</span>Â  <span class='chapter-title'>A field guide to base R</span>"
    ]
  },
  {
    "objectID": "communicate.html",
    "href": "communicate.html",
    "title": "Communicate",
    "section": "",
    "text": "So far, youâ€™ve learned the tools to get your data into R, tidy it into a form convenient for analysis, and then understand your data through transformation, and visualization.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»å­¦ä¹ äº†å°†æ•°æ®å¯¼å…¥ Rã€å°†å…¶æ•´ç†æˆä¾¿äºåˆ†æçš„å½¢å¼ï¼Œç„¶åé€šè¿‡è½¬æ¢å’Œå¯è§†åŒ–æ¥ç†è§£æ•°æ®çš„å·¥å…·ã€‚\nHowever, it doesnâ€™t matter how great your analysis is unless you can explain it to others: you need to communicate your results.\nç„¶è€Œï¼Œæ— è®ºä½ çš„åˆ†ææœ‰å¤šå‡ºè‰²ï¼Œé™¤éä½ èƒ½å‘ä»–äººè§£é‡Šæ¸…æ¥šï¼Œå¦åˆ™éƒ½æ¯«æ— æ„ä¹‰ï¼šä½ éœ€è¦æ²Ÿé€šä½ çš„ç»“æœã€‚\n\n\n\n\n\n\n\nFigureÂ 1: Communication is the final part of the data science process; if you canâ€™t communicate your results to other humans, it doesnâ€™t matter how great your analysis is.\n\n\n\n\nCommunication is the theme of the following two chapters:\næ²Ÿé€šæ˜¯æ¥ä¸‹æ¥ä¸¤ç« çš„ä¸»é¢˜ï¼š\n\nIn 28Â  Quarto, you will learn about Quarto, a tool for integrating prose, code, and results.\nYou can use Quarto for analyst-to-analyst communication as well as analyst-to-decision-maker communication.\nThanks to the power of Quarto formats, you can even use the same document for both purposes.\nåœ¨ 28Â  Quarto ä¸­ï¼Œä½ å°†å­¦ä¹  Quartoï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ•´åˆæ–‡å­—ã€ä»£ç å’Œç»“æœçš„å·¥å…·ã€‚\nä½ å¯ä»¥ä½¿ç”¨ Quarto è¿›è¡Œåˆ†æå¸ˆä¸åˆ†æå¸ˆä¹‹é—´çš„æ²Ÿé€šï¼Œä»¥åŠåˆ†æå¸ˆä¸å†³ç­–è€…ä¹‹é—´çš„æ²Ÿé€šã€‚\nå¾—ç›Šäº Quarto æ ¼å¼çš„å¼ºå¤§åŠŸèƒ½ï¼Œä½ ç”šè‡³å¯ä»¥ä¸ºè¿™ä¸¤ç§ç›®çš„ä½¿ç”¨åŒä¸€ä»½æ–‡æ¡£ã€‚\nIn 29Â  Quarto formats, youâ€™ll learn a little about the many other varieties of outputs you can produce using Quarto, including dashboards, websites, and books.\nåœ¨ 29Â  Quarto formats ä¸­ï¼Œä½ å°†å­¦ä¹ ä¸€äº›å…³äºä½¿ç”¨ Quarto å¯ä»¥ç”Ÿæˆçš„è®¸å¤šå…¶ä»–ç±»å‹çš„è¾“å‡ºï¼ŒåŒ…æ‹¬ä»ªè¡¨æ¿ã€ç½‘ç«™å’Œä¹¦ç±ã€‚\n\nThese chapters focus mostly on the technical mechanics of communication, not the really hard problems of communicating your thoughts to other humans.\nè¿™äº›ç« èŠ‚ä¸»è¦å…³æ³¨æ²Ÿé€šçš„æŠ€æœ¯å±‚é¢ï¼Œè€Œä¸æ˜¯å°†ä½ çš„æƒ³æ³•ä¼ è¾¾ç»™å…¶ä»–äººçš„çœŸæ­£éš¾é¢˜ã€‚\nHowever, there are lot of other great books about communication, which weâ€™ll point you to at the end of each chapter.\nä¸è¿‡ï¼Œå…³äºæ²Ÿé€šè¿˜æœ‰å¾ˆå¤šå…¶ä»–ä¼˜ç§€çš„ä¹¦ç±ï¼Œæˆ‘ä»¬ä¼šåœ¨æ¯ç« æœ«å°¾å‘ä½ æ¨èã€‚",
    "crumbs": [
      "Communicate"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "28Â  Quarto",
    "section": "",
    "text": "28.1 Introduction\nQuarto provides a unified authoring framework for data science, combining your code, its results, and your prose. Quarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto ä¸ºæ•°æ®ç§‘å­¦æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„åˆ›ä½œæ¡†æ¶ï¼Œå®ƒç»“åˆäº†ä½ çš„ä»£ç ã€ä»£ç çš„è¿è¡Œç»“æœä»¥åŠä½ çš„æ–‡å­—è¯´æ˜ã€‚Quarto æ–‡æ¡£æ˜¯å®Œå…¨å¯å¤ç°çš„ï¼Œå¹¶æ”¯æŒæ•°åç§è¾“å‡ºæ ¼å¼ï¼Œå¦‚ PDFã€Word æ–‡ä»¶ã€æ¼”ç¤ºæ–‡ç¨¿ç­‰ã€‚\nQuarto files are designed to be used in three ways:\nQuarto æ–‡ä»¶è®¾è®¡ç”¨äºä»¥ä¸‹ä¸‰ç§æ–¹å¼ï¼š\nQuarto is a command line interface tool, not an R package. This means that help is, by-and-large, not available through ?. Instead, as you work through this chapter, and use Quarto in the future, you should refer to the Quarto documentation.\nQuarto æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œç•Œé¢å·¥å…·ï¼Œè€Œä¸æ˜¯ä¸€ä¸ª R åŒ…ã€‚è¿™æ„å‘³ç€ï¼Œæ€»çš„æ¥è¯´ï¼Œä½ æ— æ³•é€šè¿‡ ? æ¥è·å–å¸®åŠ©ã€‚ç›¸åï¼Œåœ¨å­¦ä¹ æœ¬ç« å’Œå°†æ¥ä½¿ç”¨ Quarto æ—¶ï¼Œä½ åº”è¯¥å‚è€ƒ Quarto å®˜æ–¹æ–‡æ¡£ã€‚\nIf youâ€™re an R Markdown user, you might be thinking â€œQuarto sounds a lot like R Markdownâ€. Youâ€™re not wrong! Quarto unifies the functionality of many packages from the R Markdown ecosystem (rmarkdown, bookdown, distill, xaringan, etc.) into a single consistent system as well as extends it with native support for multiple programming languages like Python and Julia in addition to R. In a way, Quarto reflects everything that was learned from expanding and supporting the R Markdown ecosystem over a decade.\nå¦‚æœä½ æ˜¯ R Markdown ç”¨æˆ·ï¼Œä½ å¯èƒ½ä¼šæƒ³â€œQuarto å¬èµ·æ¥å¾ˆåƒ R Markdownâ€ã€‚ä½ æ²¡è¯´é”™ï¼Quarto å°† R Markdown ç”Ÿæ€ç³»ç»Ÿä¸­çš„è®¸å¤šåŒ…ï¼ˆrmarkdownã€bookdownã€distillã€xaringan ç­‰ï¼‰çš„åŠŸèƒ½ç»Ÿä¸€åˆ°ä¸€ä¸ªå•ä¸€ã€ä¸€è‡´çš„ç³»ç»Ÿä¸­ï¼Œå¹¶é€šè¿‡å¯¹ R ä¹‹å¤–çš„å¤šç§ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚ Python å’Œ Juliaï¼‰çš„åŸç”Ÿæ”¯æŒæ¥æ‰©å±•å®ƒã€‚åœ¨æŸç§ç¨‹åº¦ä¸Šï¼ŒQuarto åæ˜ äº†åå¤šå¹´æ¥åœ¨æ‰©å±•å’Œæ”¯æŒ R Markdown ç”Ÿæ€ç³»ç»Ÿè¿‡ç¨‹ä¸­å­¦åˆ°çš„ä¸€åˆ‡ã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#introduction",
    "href": "quarto.html#introduction",
    "title": "28Â  Quarto",
    "section": "",
    "text": "For communicating to decision-makers, who want to focus on the conclusions, not the code behind the analysis.\nç”¨äºä¸å†³ç­–è€…æ²Ÿé€šï¼Œä»–ä»¬å¸Œæœ›ä¸“æ³¨äºç»“è®ºï¼Œè€Œä¸æ˜¯åˆ†æèƒŒåçš„ä»£ç ã€‚\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e.Â the code).\nç”¨äºä¸å…¶ä»–æ•°æ®ç§‘å­¦å®¶ï¼ˆåŒ…æ‹¬æœªæ¥çš„ä½ ï¼ï¼‰åˆä½œï¼Œä»–ä»¬å¯¹ä½ çš„ç»“è®ºä»¥åŠä½ å¦‚ä½•å¾—å‡ºè¿™äº›ç»“è®ºï¼ˆå³ä»£ç ï¼‰éƒ½æ„Ÿå…´è¶£ã€‚\nAs an environment in which to do data science, as a modern-day lab notebook where you can capture not only what you did, but also what you were thinking.\nä½œä¸ºä¸€ä¸ªä»äº‹æ•°æ®ç§‘å­¦çš„ç¯å¢ƒï¼Œå°±åƒä¸€ä¸ªç°ä»£åŒ–çš„å®éªŒå®¤ç¬”è®°æœ¬ï¼Œä½ ä¸ä»…å¯ä»¥è®°å½•ä½ åšäº†ä»€ä¹ˆï¼Œè¿˜å¯ä»¥è®°å½•ä½ çš„æƒ³æ³•ã€‚\n\n\n\n\n28.1.1 Prerequisites\nYou need the Quarto command line interface (Quarto CLI), but you donâ€™t need to explicitly install it or load it, as RStudio automatically does both when needed.\nä½ éœ€è¦ Quarto å‘½ä»¤è¡Œç•Œé¢ (Quarto CLI)ï¼Œä½†ä½ ä¸éœ€è¦æ˜¾å¼åœ°å®‰è£…æˆ–åŠ è½½å®ƒï¼Œå› ä¸º RStudio ä¼šåœ¨éœ€è¦æ—¶è‡ªåŠ¨å®Œæˆè¿™ä¸¤é¡¹å·¥ä½œã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#quarto-basics",
    "href": "quarto.html#quarto-basics",
    "title": "28Â  Quarto",
    "section": "\n28.2 Quarto basics",
    "text": "28.2 Quarto basics\nThis is a Quarto file â€“ a plain text file that has the extension .qmd:\nè¿™æ˜¯ä¸€ä¸ª Quarto æ–‡ä»¶â€”â€”ä¸€ä¸ªæ‰©å±•åä¸º .qmd çš„çº¯æ–‡æœ¬æ–‡ä»¶ï¼š\n\n---\ntitle: \"Diamond sizes\"\ndate: 2022-09-12\nformat: html\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt;= 2.5)\n```\n\nWe have data about `r nrow(diamonds)` diamonds.\nOnly `r nrow(diamonds) - nrow(smaller)` are larger than 2.5 carats.\nThe distribution of the remainder is shown below:\n\n```{r}\n#| label: plot-smaller-diamonds\n#| echo: false\n\nsmaller |&gt; \n  ggplot(aes(x = carat)) + \n  geom_freqpoly(binwidth = 0.01)\n```\n\nIt contains three important types of content:\nå®ƒåŒ…å«ä¸‰ç§é‡è¦çš„å†…å®¹ç±»å‹ï¼š\n\nAn (optional) YAML header surrounded by ---s.\nä¸€ä¸ªï¼ˆå¯é€‰çš„ï¼‰ç”± --- åŒ…å›´çš„ YAML å¤´ã€‚\nChunks of R code surrounded by ```.\nç”± ``` åŒ…å›´çš„ R ä»£ç å—ã€‚\nText mixed with simple text formatting like # heading and _italics_.\næ··åˆäº†ç®€å•æ–‡æœ¬æ ¼å¼çš„æ–‡æœ¬ï¼Œå¦‚ # æ ‡é¢˜ å’Œ _æ–œä½“_ã€‚\n\nFigureÂ 28.1 shows a .qmd document in RStudio with notebook interface where code and output are interleaved. You can run each code chunk by clicking the Run icon (it looks like a play button at the top of the chunk), or by pressing Cmd/Ctrl + Shift + Enter. RStudio executes the code and displays the results inline with the code.FigureÂ 28.1 å±•ç¤ºäº† RStudio ä¸­ä¸€ä¸ªé‡‡ç”¨ç¬”è®°æœ¬ç•Œé¢çš„ .qmd æ–‡æ¡£ï¼Œå…¶ä¸­ä»£ç å’Œè¾“å‡ºäº¤é”™æ˜¾ç¤ºã€‚ä½ å¯ä»¥é€šè¿‡ç‚¹å‡»è¿è¡Œå›¾æ ‡ï¼ˆå®ƒçœ‹èµ·æ¥åƒä»£ç å—é¡¶éƒ¨çš„æ’­æ”¾æŒ‰é’®ï¼‰ï¼Œæˆ–æŒ‰ Cmd/Ctrl + Shift + Enter æ¥è¿è¡Œæ¯ä¸ªä»£ç å—ã€‚RStudio ä¼šæ‰§è¡Œä»£ç å¹¶å°†ç»“æœå†…è”æ˜¾ç¤ºåœ¨ä»£ç æ—è¾¹ã€‚\n\n\n\n\n\n\n\nFigureÂ 28.1: A Quarto document in RStudio. Code and output interleaved in the document, with the plot output appearing right underneath the code.\n\n\n\n\nIf you donâ€™t like seeing your plots and output in your document and would rather make use of RStudioâ€™s Console and Plot panes, you can click on the gear icon next to â€œRenderâ€ and switch to â€œChunk Output in Consoleâ€, as shown in FigureÂ 28.2.\nå¦‚æœä½ ä¸å–œæ¬¢åœ¨æ–‡æ¡£ä¸­çœ‹åˆ°ä½ çš„ç»˜å›¾å’Œè¾“å‡ºï¼Œè€Œæ›´æ„¿æ„ä½¿ç”¨ RStudio çš„æ§åˆ¶å° (Console) å’Œç»˜å›¾ (Plot) çª—æ ¼ï¼Œä½ å¯ä»¥ç‚¹å‡»â€œRenderâ€æ—è¾¹çš„é½¿è½®å›¾æ ‡ï¼Œå¹¶åˆ‡æ¢åˆ°â€œChunk Output in Consoleâ€ï¼Œå¦‚ FigureÂ 28.2 æ‰€ç¤ºã€‚\n\n\n\n\n\n\n\nFigureÂ 28.2: A Quarto document in RStudio with the plot output in the Plots pane.\n\n\n\n\nTo produce a complete report containing all text, code, and results, click â€œRenderâ€ or press Cmd/Ctrl + Shift + K. You can also do this programmatically with quarto::quarto_render(\"diamond-sizes.qmd\"). This will display the report in the viewer pane as shown in FigureÂ 28.3 and create an HTML file.\nè¦ç”Ÿæˆä¸€ä¸ªåŒ…å«æ‰€æœ‰æ–‡æœ¬ã€ä»£ç å’Œç»“æœçš„å®Œæ•´æŠ¥å‘Šï¼Œè¯·ç‚¹å‡»â€œRenderâ€æˆ–æŒ‰ Cmd/Ctrl + Shift + Kã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡ç¼–ç¨‹æ–¹å¼ä½¿ç”¨ quarto::quarto_render(\"diamond-sizes.qmd\") æ¥å®ç°ã€‚è¿™å°†åœ¨æŸ¥çœ‹å™¨çª—æ ¼ä¸­æ˜¾ç¤ºæŠ¥å‘Šï¼Œå¦‚ FigureÂ 28.3 æ‰€ç¤ºï¼Œå¹¶åˆ›å»ºä¸€ä¸ª HTML æ–‡ä»¶ã€‚\n\n\n\n\n\n\n\nFigureÂ 28.3: A Quarto document in RStudio with the rendered document in the Viewer pane.\n\n\n\n\nWhen you render the document, Quarto sends the .qmd file to knitr, https://yihui.org/knitr/, which executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated by knitr is then processed by pandoc, https://pandoc.org, which is responsible for creating the finished file. This process is shown in FigureÂ 28.4. The advantage of this two step workflow is that you can create a very wide range of output formats, as youâ€™ll learn about in Chapter 29.\nå½“ä½ æ¸²æŸ“æ–‡æ¡£æ—¶ï¼ŒQuarto ä¼šå°† .qmd æ–‡ä»¶å‘é€ç»™ knitr (https://yihui.org/knitr/)ï¼Œå®ƒä¼šæ‰§è¡Œæ‰€æœ‰ä»£ç å—å¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„ Markdown (.md) æ–‡æ¡£ï¼Œå…¶ä¸­åŒ…å«ä»£ç åŠå…¶è¾“å‡ºã€‚ç„¶åï¼Œç”± knitr ç”Ÿæˆçš„ Markdown æ–‡ä»¶ä¼šè¢« pandoc (https://pandoc.org) å¤„ç†ï¼Œpandoc è´Ÿè´£åˆ›å»ºæœ€ç»ˆæ–‡ä»¶ã€‚è¿™ä¸ªè¿‡ç¨‹å¦‚ FigureÂ 28.4 æ‰€ç¤ºã€‚è¿™ç§ä¸¤æ­¥å·¥ä½œæµçš„ä¼˜ç‚¹æ˜¯ä½ å¯ä»¥åˆ›å»ºéå¸¸å¹¿æ³›çš„è¾“å‡ºæ ¼å¼ï¼Œä½ å°†åœ¨ Chapter 29 ä¸­å­¦åˆ°ç›¸å…³å†…å®¹ã€‚\n\n\n\n\n\n\n\nFigureÂ 28.4: Diagram of Quarto workflow from qmd, to knitr, to md, to pandoc, to output in PDF, MS Word, or HTML formats.\n\n\n\n\nTo get started with your own .qmd file, select File &gt; New File &gt; Quarto Documentâ€¦ in the menu bar. RStudio will launch a wizard that you can use to pre-populate your file with useful content that reminds you how the key features of Quarto work.\nè¦å¼€å§‹åˆ›å»ºä½ è‡ªå·±çš„ .qmd æ–‡ä»¶ï¼Œè¯·åœ¨èœå•æ ä¸­é€‰æ‹© File &gt; New File &gt; Quarto Documentâ€¦ã€‚RStudio å°†å¯åŠ¨ä¸€ä¸ªå‘å¯¼ï¼Œä½ å¯ä»¥ç”¨å®ƒæ¥é¢„å¡«å……æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æœ‰ç”¨çš„å†…å®¹ï¼Œæé†’ä½  Quarto çš„å…³é”®åŠŸèƒ½æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚\nThe following sections dive into the three components of a Quarto document in more details: the markdown text, the code chunks, and the YAML header.\nä»¥ä¸‹å„èŠ‚å°†æ›´è¯¦ç»†åœ°æ¢è®¨ Quarto æ–‡æ¡£çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ï¼šMarkdown æ–‡æœ¬ã€ä»£ç å—å’Œ YAML å¤´ã€‚\n\n28.2.1 Exercises\n\nCreate a new Quarto document using File &gt; New File &gt; Quarto Document. Read the instructions. Practice running the chunks individually. Then render the document by clicking the appropriate button and then by using the appropriate keyboard short cut. Verify that you can modify the code, re-run it, and see modified output.\nCreate one new Quarto document for each of the three built-in formats: HTML, PDF and Word. Render each of the three documents. How do the outputs differ? How do the inputs differ? (You may need to install LaTeX in order to build the PDF output â€” RStudio will prompt you if this is necessary.)",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#visual-editor",
    "href": "quarto.html#visual-editor",
    "title": "28Â  Quarto",
    "section": "\n28.3 Visual editor",
    "text": "28.3 Visual editor\nThe Visual editor in RStudio provides a WYSIWYM interface for authoring Quarto documents. Under the hood, prose in Quarto documents (.qmd files) is written in Markdown, a lightweight set of conventions for formatting plain text files. In fact, Quarto uses Pandoc markdown (a slightly extended version of Markdown that Quarto understands), including tables, citations, cross-references, footnotes, divs/spans, definition lists, attributes, raw HTML/TeX, and more as well as support for executing code cells and viewing their output inline. While Markdown is designed to be easy to read and write, as you will see in Section 28.4, it still requires learning new syntax. Therefore, if youâ€™re new to computational documents like .qmd files but have experience using tools like Google Docs or MS Word, the easiest way to get started with Quarto in RStudio is the visual editor.\nRStudio ä¸­çš„å¯è§†åŒ–ç¼–è¾‘å™¨ä¸ºåˆ›ä½œ Quarto æ–‡æ¡£æä¾›äº†ä¸€ä¸ª WYSIWYM (æ‰€è§å³æ‰€æ„) ç•Œé¢ã€‚å®é™…ä¸Šï¼ŒQuarto æ–‡æ¡£ï¼ˆ.qmd æ–‡ä»¶ï¼‰ä¸­çš„æ–‡å­—æ˜¯ä½¿ç”¨ Markdown ç¼–å†™çš„ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ ¼å¼åŒ–çº¯æ–‡æœ¬æ–‡ä»¶çš„è½»é‡çº§çº¦å®šã€‚äº‹å®ä¸Šï¼ŒQuarto ä½¿ç”¨çš„æ˜¯ Pandoc markdownï¼ˆQuarto èƒ½ç†è§£çš„ Markdown çš„ä¸€ä¸ªç•¥å¾®æ‰©å±•çš„ç‰ˆæœ¬ï¼‰ï¼Œå®ƒåŒ…æ‹¬è¡¨æ ¼ã€å¼•æ–‡ã€äº¤å‰å¼•ç”¨ã€è„šæ³¨ã€divs/spansã€å®šä¹‰åˆ—è¡¨ã€å±æ€§ã€åŸå§‹ HTML/TeX ç­‰ç­‰ï¼Œå¹¶ä¸”æ”¯æŒæ‰§è¡Œä»£ç å•å…ƒæ ¼å¹¶å†…è”æŸ¥çœ‹å…¶è¾“å‡ºã€‚è™½ç„¶ Markdown è¢«è®¾è®¡å¾—æ˜“äºè¯»å†™ï¼Œæ­£å¦‚ä½ å°†åœ¨ Section 28.4 ä¸­çœ‹åˆ°çš„ï¼Œå®ƒä»ç„¶éœ€è¦å­¦ä¹ æ–°çš„è¯­æ³•ã€‚å› æ­¤ï¼Œå¦‚æœä½ æ˜¯åˆæ¬¡æ¥è§¦åƒ .qmd æ–‡ä»¶è¿™æ ·çš„è®¡ç®—æ–‡æ¡£ï¼Œä½†æœ‰ä½¿ç”¨ Google Docs æˆ– MS Word ç­‰å·¥å…·çš„ç»éªŒï¼Œé‚£ä¹ˆåœ¨ RStudio ä¸­å¼€å§‹ä½¿ç”¨ Quarto çš„æœ€ç®€å•æ–¹æ³•å°±æ˜¯å¯è§†åŒ–ç¼–è¾‘å™¨ã€‚\nIn the visual editor you can either use the buttons on the menu bar to insert images, tables, cross-references, etc. or you can use the catch-all &lt;kbd&gt;âŒ˜&lt;/kbd&gt; + &lt;kbd&gt;/&lt;/kbd&gt; or &lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;/&lt;/kbd&gt; shortcut to insert just about anything. If you are at the beginning of a line (as shown in FigureÂ 28.5), you can also enter just &lt;kbd&gt;/&lt;/kbd&gt; to invoke the shortcut.\nåœ¨å¯è§†åŒ–ç¼–è¾‘å™¨ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨èœå•æ ä¸Šçš„æŒ‰é’®æ¥æ’å…¥å›¾åƒã€è¡¨æ ¼ã€äº¤å‰å¼•ç”¨ç­‰ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ä¸‡èƒ½å¿«æ·é”® &lt;kbd&gt;âŒ˜&lt;/kbd&gt; + &lt;kbd&gt;/&lt;/kbd&gt; æˆ– &lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;/&lt;/kbd&gt; æ¥æ’å…¥å‡ ä¹ä»»ä½•ä¸œè¥¿ã€‚å¦‚æœä½ ä½äºä¸€è¡Œçš„å¼€å¤´ï¼ˆå¦‚ FigureÂ 28.5 æ‰€ç¤ºï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥åªè¾“å…¥ &lt;kbd&gt;/&lt;/kbd&gt; æ¥è°ƒç”¨è¯¥å¿«æ·æ–¹å¼ã€‚\n\n\n\n\n\n\n\nFigureÂ 28.5: Quarto visual editor.\n\n\n\n\nInserting images and customizing how they are displayed is also facilitated with the visual editor. You can either paste an image from your clipboard directly into the visual editor (and RStudio will place a copy of that image in the project directory and link to it) or you can use the visual editorâ€™s Insert &gt; Figure / Image menu to browse to the image you want to insert or paste itâ€™s URL. In addition, using the same menu you can resize the image as well as add a caption, alternative text, and a link.\nå¯è§†åŒ–ç¼–è¾‘å™¨ä¹Ÿæ–¹ä¾¿äº†æ’å…¥å›¾åƒå’Œè‡ªå®šä¹‰å…¶æ˜¾ç¤ºæ–¹å¼ã€‚ä½ å¯ä»¥ç›´æ¥å°†å‰ªè´´æ¿ä¸­çš„å›¾åƒç²˜è´´åˆ°å¯è§†åŒ–ç¼–è¾‘å™¨ä¸­ï¼ˆRStudio ä¼šå°†è¯¥å›¾åƒçš„å‰¯æœ¬æ”¾ç½®åœ¨é¡¹ç›®ç›®å½•ä¸­å¹¶é“¾æ¥åˆ°å®ƒï¼‰ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¯è§†åŒ–ç¼–è¾‘å™¨çš„ Insert &gt; Figure / Image èœå•æ¥æµè§ˆè¦æ’å…¥çš„å›¾åƒæˆ–ç²˜è´´å…¶ URLã€‚æ­¤å¤–ï¼Œä½¿ç”¨åŒä¸€èœå•ï¼Œä½ è¿˜å¯ä»¥è°ƒæ•´å›¾åƒå¤§å°ï¼Œä»¥åŠæ·»åŠ æ ‡é¢˜ã€æ›¿ä»£æ–‡æœ¬å’Œé“¾æ¥ã€‚\nThe visual editor has many more features that we havenâ€™t enumerated here that you might find useful as you gain experience authoring with it.\nå¯è§†åŒ–ç¼–è¾‘å™¨è¿˜æœ‰è®¸å¤šæˆ‘ä»¬åœ¨æ­¤æœªåˆ—ä¸¾çš„åŠŸèƒ½ï¼Œéšç€ä½ åˆ›ä½œç»éªŒçš„å¢åŠ ï¼Œä½ å¯èƒ½ä¼šå‘ç°å®ƒä»¬å¾ˆæœ‰ç”¨ã€‚\nMost importantly, while the visual editor displays your content with formatting, under the hood, it saves your content in plain Markdown and you can switch back and forth between the visual and source editors to view and edit your content using either tool.\næœ€é‡è¦çš„æ˜¯ï¼Œè™½ç„¶å¯è§†åŒ–ç¼–è¾‘å™¨ä¼šå¸¦æ ¼å¼åœ°æ˜¾ç¤ºä½ çš„å†…å®¹ï¼Œä½†å®é™…ä¸Šå®ƒä»¥çº¯ Markdown æ ¼å¼ä¿å­˜ä½ çš„å†…å®¹ï¼Œä½ å¯ä»¥åœ¨å¯è§†åŒ–ç¼–è¾‘å™¨å’Œæºä»£ç ç¼–è¾‘å™¨ä¹‹é—´æ¥å›åˆ‡æ¢ï¼Œä½¿ç”¨ä»»ä¸€å·¥å…·æŸ¥çœ‹å’Œç¼–è¾‘ä½ çš„å†…å®¹ã€‚\n\n28.3.1 Exercises\n\nRe-create the document in FigureÂ 28.5 using the visual editor.\nUsing the visual editor, insert a code chunk using the Insert menu and then the insert anything tool.\nUsing the visual editor, figure out how to:\n\nAdd a footnote.\nAdd a horizontal rule.\nAdd a block quote.\n\n\nIn the visual editor, go to Insert &gt; Citation and insert a citation to the paper titled Welcome to the Tidyverse using its DOI (digital object identifier), which is 10.21105/joss.01686. Render the document and observe how the reference shows up in the document. What change do you observe in the YAML of your document?",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-source-editor",
    "href": "quarto.html#sec-source-editor",
    "title": "28Â  Quarto",
    "section": "\n28.4 Source editor",
    "text": "28.4 Source editor\nYou can also edit Quarto documents using the Source editor in RStudio, without the assist of the Visual editor. While the Visual editor will feel familiar to those with experience writing in tools like Google docs, the Source editor will feel familiar to those with experience writing R scripts or R Markdown documents. The Source editor can also be useful for debugging any Quarto syntax errors since itâ€™s often easier to catch these in plain text.\nä½ ä¹Ÿå¯ä»¥åœ¨ RStudio ä¸­ä½¿ç”¨æºä»£ç ç¼–è¾‘å™¨æ¥ç¼–è¾‘ Quarto æ–‡æ¡£ï¼Œè€Œæ— éœ€å¯è§†åŒ–ç¼–è¾‘å™¨çš„è¾…åŠ©ã€‚å¯¹äºæœ‰ä½¿ç”¨ Google Docs ç­‰å·¥å…·å†™ä½œç»éªŒçš„äººæ¥è¯´ï¼Œå¯è§†åŒ–ç¼–è¾‘å™¨ä¼šæ„Ÿè§‰å¾ˆç†Ÿæ‚‰ï¼›è€Œå¯¹äºæœ‰ç¼–å†™ R è„šæœ¬æˆ– R Markdown æ–‡æ¡£ç»éªŒçš„äººæ¥è¯´ï¼Œæºä»£ç ç¼–è¾‘å™¨ä¼šæ„Ÿè§‰å¾ˆç†Ÿæ‚‰ã€‚æºä»£ç ç¼–è¾‘å™¨å¯¹äºè°ƒè¯•ä»»ä½• Quarto è¯­æ³•é”™è¯¯ä¹Ÿå¾ˆæœ‰ç”¨ï¼Œå› ä¸ºåœ¨çº¯æ–‡æœ¬ä¸­é€šå¸¸æ›´å®¹æ˜“å‘ç°è¿™äº›é”™è¯¯ã€‚\nThe guide below shows how to use Pandocâ€™s Markdown for authoring Quarto documents in the source editor.\nä¸‹é¢çš„æŒ‡å—å±•ç¤ºäº†å¦‚ä½•åœ¨æºä»£ç ç¼–è¾‘å™¨ä¸­ä½¿ç”¨ Pandocâ€™s Markdown æ¥åˆ›ä½œ Quarto æ–‡æ¡£ã€‚\n\n## Text formatting\n\n*italic* **bold** ~~strikeout~~ `code`\n\nsuperscript^2^ subscript~2~\n\n[underline]{.underline} [small caps]{.smallcaps}\n\n## Headings\n\n# 1st Level Header\n\n## 2nd Level Header\n\n### 3rd Level Header\n\n## Lists\n\n-   Bulleted list item 1\n\n-   Item 2\n\n    -   Item 2a\n\n    -   Item 2b\n\n1.  Numbered list item 1\n\n2.  Item 2.\n    The numbers are incremented automatically in the output.\n\n## Links and images\n\n&lt;http://example.com&gt;\n\n[linked phrase](http://example.com)\n\n![optional caption text](quarto.png){fig-alt=\"Quarto logo and the word quarto spelled in small case letters\"}\n\n## Tables\n\n| First Header | Second Header |\n|--------------|---------------|\n| Content Cell | Content Cell  |\n| Content Cell | Content Cell  |\n\nThe best way to learn these is simply to try them out. It will take a few days, but soon they will become second nature, and you wonâ€™t need to think about them. If you forget, you can get to a handy reference sheet with Help &gt; Markdown Quick Reference.\nå­¦ä¹ è¿™äº›çš„æœ€å¥½æ–¹æ³•å°±æ˜¯äº²è‡ªå°è¯•ã€‚è¿™å¯èƒ½éœ€è¦å‡ å¤©æ—¶é—´ï¼Œä½†å¾ˆå¿«å®ƒä»¬å°±ä¼šæˆä¸ºä½ çš„ç¬¬äºŒå¤©æ€§ï¼Œä½ å°†ä¸å†éœ€è¦åˆ»æ„å»æƒ³å®ƒä»¬ã€‚å¦‚æœä½ å¿˜è®°äº†ï¼Œå¯ä»¥é€šè¿‡ Help &gt; Markdown Quick Reference æ‰“å¼€ä¸€ä¸ªæ–¹ä¾¿çš„å‚è€ƒè¡¨ã€‚\n\n28.4.1 Exercises\n\nPractice what youâ€™ve learned by creating a brief CV. The title should be your name, and you should include headings for (at least) education or employment. Each of the sections should include a bulleted list of jobs/degrees. Highlight the year in bold.\n\nUsing the source editor and the Markdown quick reference, figure out how to:\n\nAdd a footnote.\nAdd a horizontal rule.\nAdd a block quote.\n\n\nCopy and paste the contents of diamond-sizes.qmd from https://github.com/hadley/r4ds/tree/main/quarto in to a local R Quarto document. Check that you can run it, then add text after the frequency polygon that describes its most striking features.\nCreate a document in a Google doc or MS Word (or locate a document you have created previously) with some content in it such as headings, hyperlinks, formatted text, etc. Copy the contents of this document and paste it into a Quarto document in the visual editor. Then, switch over to the source editor and inspect the source code.",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#code-chunks",
    "href": "quarto.html#code-chunks",
    "title": "28Â  Quarto",
    "section": "\n28.5 Code chunks",
    "text": "28.5 Code chunks\nTo run code inside a Quarto document, you need to insert a chunk. There are three ways to do so:\nè¦åœ¨ Quarto æ–‡æ¡£ä¸­è¿è¡Œä»£ç ï¼Œä½ éœ€è¦æ’å…¥ä¸€ä¸ªä»£ç å—ã€‚æœ‰ä¸‰ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼š\n\nThe keyboard shortcut Cmd + Option + I / Ctrl + Alt + I.\né”®ç›˜å¿«æ·é”® Cmd + Option + I / Ctrl + Alt + Iã€‚\nThe â€œInsertâ€ button icon in the editor toolbar.\nç¼–è¾‘å™¨å·¥å…·æ ä¸­çš„â€œInsertâ€æŒ‰é’®å›¾æ ‡ã€‚\nBy manually typing the chunk delimiters ```{r} and ```.\næ‰‹åŠ¨è¾“å…¥ä»£ç å—çš„åˆ†éš”ç¬¦ ```{r} å’Œ ```ã€‚\n\nWeâ€™d recommend you learn the keyboard shortcut. It will save you a lot of time in the long run!\næˆ‘ä»¬å»ºè®®ä½ å­¦ä¹ è¿™ä¸ªé”®ç›˜å¿«æ·é”®ã€‚ä»é•¿è¿œæ¥çœ‹ï¼Œå®ƒä¼šä¸ºä½ èŠ‚çœå¤§é‡æ—¶é—´ï¼\nYou can continue to run the code using the keyboard shortcut that by now (we hope!) you know and love: Cmd/Ctrl + Enter. However, chunks get a new keyboard shortcut: Cmd/Ctrl + Shift + Enter, which runs all the code in the chunk. Think of a chunk like a function. A chunk should be relatively self-contained, and focused around a single task.\nä½ å¯ä»¥ç»§ç»­ä½¿ç”¨ä½ ç°åœ¨ï¼ˆæˆ‘ä»¬å¸Œæœ›ï¼ï¼‰å·²ç»ç†ŸçŸ¥å¹¶å–œçˆ±çš„é”®ç›˜å¿«æ·é”®æ¥è¿è¡Œä»£ç ï¼šCmd/Ctrl + Enterã€‚ç„¶è€Œï¼Œä»£ç å—æœ‰äº†ä¸€ä¸ªæ–°çš„é”®ç›˜å¿«æ·é”®ï¼šCmd/Ctrl + Shift + Enterï¼Œå®ƒä¼šè¿è¡Œä»£ç å—ä¸­çš„æ‰€æœ‰ä»£ç ã€‚å¯ä»¥æŠŠä»£ç å—æƒ³è±¡æˆä¸€ä¸ªå‡½æ•°ã€‚ä¸€ä¸ªä»£ç å—åº”è¯¥æ˜¯ç›¸å¯¹ç‹¬ç«‹çš„ï¼Œå¹¶ä¸“æ³¨äºä¸€ä¸ªå•ä¸€çš„ä»»åŠ¡ã€‚\nThe following sections describe the chunk header which consists of ```{r}, followed by an optional chunk label and various other chunk options, each on their own line, marked by #|.\nä»¥ä¸‹å„èŠ‚æè¿°äº†ä»£ç å—çš„å¤´éƒ¨ï¼Œå®ƒç”± ```{r} ç»„æˆï¼Œåé¢è·Ÿç€ä¸€ä¸ªå¯é€‰çš„ä»£ç å—æ ‡ç­¾å’Œå„ç§å…¶ä»–çš„ä»£ç å—é€‰é¡¹ï¼Œæ¯ä¸ªé€‰é¡¹éƒ½ç‹¬å ä¸€è¡Œï¼Œå¹¶ä»¥ #| æ ‡è®°ã€‚\n\n28.5.1 Chunk label\nChunks can be given an optional label, e.g.\nä»£ç å—å¯ä»¥è¢«èµ‹äºˆä¸€ä¸ªå¯é€‰çš„æ ‡ç­¾ï¼Œä¾‹å¦‚ï¼š\n\n```{r}\n#| label: simple-addition\n1 + 1\n```\n#&gt; [1] 2\n\nThis has three advantages:\nè¿™æœ‰ä¸‰ä¸ªä¼˜ç‚¹ï¼š\n\n\nYou can more easily navigate to specific chunks using the drop-down code navigator in the bottom-left of the script editor:\nä½ å¯ä»¥ä½¿ç”¨è„šæœ¬ç¼–è¾‘å™¨å·¦ä¸‹è§’çš„ä¸‹æ‹‰ä»£ç å¯¼èˆªå™¨æ›´è½»æ¾åœ°å¯¼èˆªåˆ°ç‰¹å®šçš„ä»£ç å—ï¼š\n{r}     #| echo: false     #| out-width: \"30%\"     #| fig-alt: |     #|   Snippet of RStudio IDE showing only the drop-down code navigator      #|   which shows three chunks. Chunk 1 is setup. Chunk 2 is cars and      #|   it is in a section called Quarto. Chunk 3 is pressure and it is in      #|   a section called Including plots.     knitr::include_graphics(\"screenshots/quarto-chunk-nav.png\")\n\nGraphics produced by the chunks will have useful names that make them easier to use elsewhere. More on that in Section 28.6.\nä»£ç å—ç”Ÿæˆçš„å›¾å½¢å°†å…·æœ‰æœ‰ç”¨çš„åç§°ï¼Œä½¿å®ƒä»¬æ›´æ˜“äºåœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨ã€‚æ›´å¤šç›¸å…³å†…å®¹è¯·å‚è§ Section 28.6ã€‚\nYou can set up networks of cached chunks to avoid re-performing expensive computations on every run. More on that in Section 28.8.\nä½ å¯ä»¥è®¾ç½®ç¼“å­˜ä»£ç å—ç½‘ç»œï¼Œä»¥é¿å…åœ¨æ¯æ¬¡è¿è¡Œæ—¶é‡æ–°æ‰§è¡Œè€—æ—¶çš„è®¡ç®—ã€‚æ›´å¤šç›¸å…³å†…å®¹è¯·å‚è§ Section 28.8ã€‚\n\nYour chunk labels should be short but evocative and should not contain spaces. We recommend using dashes (-) to separate words (instead of underscores, _) and avoiding other special characters in chunk labels.\nä½ çš„ä»£ç å—æ ‡ç­¾åº”è¯¥ç®€çŸ­ä½†å…·æœ‰æè¿°æ€§ï¼Œå¹¶ä¸”ä¸åº”åŒ…å«ç©ºæ ¼ã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨ç ´æŠ˜å· (-) æ¥åˆ†éš”å•è¯ï¼ˆè€Œä¸æ˜¯ä¸‹åˆ’çº¿ _ï¼‰ï¼Œå¹¶é¿å…åœ¨ä»£ç å—æ ‡ç­¾ä¸­ä½¿ç”¨å…¶ä»–ç‰¹æ®Šå­—ç¬¦ã€‚\nYou are generally free to label your chunk however you like, but there is one chunk name that imbues special behavior: setup. When youâ€™re in a notebook mode, the chunk named setup will be run automatically once, before any other code is run.\nä½ é€šå¸¸å¯ä»¥éšæ„å‘½åä½ çš„ä»£ç å—ï¼Œä½†æœ‰ä¸€ä¸ªä»£ç å—åç§°å…·æœ‰ç‰¹æ®Šçš„è¡Œä¸ºï¼šsetupã€‚å½“ä½ åœ¨ç¬”è®°æœ¬æ¨¡å¼ä¸‹æ—¶ï¼Œåä¸º setup çš„ä»£ç å—ä¼šåœ¨è¿è¡Œä»»ä½•å…¶ä»–ä»£ç ä¹‹å‰è‡ªåŠ¨è¿è¡Œä¸€æ¬¡ã€‚\nAdditionally, chunk labels cannot be duplicated. Each chunk label must be unique.\næ­¤å¤–ï¼Œä»£ç å—æ ‡ç­¾ä¸èƒ½é‡å¤ã€‚æ¯ä¸ªä»£ç å—æ ‡ç­¾å¿…é¡»æ˜¯å”¯ä¸€çš„ã€‚\n\n28.5.2 Chunk options\nChunk output can be customized with options, fields supplied to chunk header. Knitr provides almost 60 options that you can use to customize your code chunks. Here weâ€™ll cover the most important chunk options that youâ€™ll use frequently. You can see the full list at https://yihui.org/knitr/options.\nä»£ç å—çš„è¾“å‡ºå¯ä»¥é€šè¿‡é€‰é¡¹ï¼ˆæä¾›ç»™ä»£ç å—å¤´éƒ¨çš„å­—æ®µï¼‰è¿›è¡Œè‡ªå®šä¹‰ã€‚Knitr æä¾›äº†è¿‘ 60 ä¸ªé€‰é¡¹ï¼Œä½ å¯ä»¥ç”¨æ¥è‡ªå®šä¹‰ä½ çš„ä»£ç å—ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä»‹ç»ä½ å°†é¢‘ç¹ä½¿ç”¨çš„æœ€é‡è¦çš„ä»£ç å—é€‰é¡¹ã€‚ä½ å¯ä»¥åœ¨ https://yihui.org/knitr/options æŸ¥çœ‹å®Œæ•´åˆ—è¡¨ã€‚\nThe most important set of options controls if your code block is executed and what results are inserted in the finished report:\næœ€é‡è¦çš„ä¸€ç»„é€‰é¡¹æ§åˆ¶ç€ä½ çš„ä»£ç å—æ˜¯å¦è¢«æ‰§è¡Œï¼Œä»¥åŠå“ªäº›ç»“æœè¢«æ’å…¥åˆ°æœ€ç»ˆçš„æŠ¥å‘Šä¸­ï¼š\n\neval: false prevents code from being evaluated.eval: false å¯é˜²æ­¢ä»£ç è¢«æ‰§è¡Œã€‚\n(And obviously if the code is not run, no results will be generated).\nï¼ˆå¾ˆæ˜æ˜¾ï¼Œå¦‚æœä»£ç æ²¡æœ‰è¿è¡Œï¼Œå°±ä¸ä¼šç”Ÿæˆä»»ä½•ç»“æœï¼‰ã€‚\nThis is useful for displaying example code, or for disabling a large block of code without commenting each line.\nè¿™å¯¹äºæ˜¾ç¤ºç¤ºä¾‹ä»£ç ï¼Œæˆ–åœ¨ä¸é€è¡Œæ³¨é‡Šçš„æƒ…å†µä¸‹ç¦ç”¨å¤§æ®µä»£ç éå¸¸æœ‰ç”¨ã€‚\ninclude: false runs the code, but doesnâ€™t show the code or results in the final document.include: false ä¼šè¿è¡Œä»£ç ï¼Œä½†ä¸ä¼šåœ¨æœ€ç»ˆæ–‡æ¡£ä¸­æ˜¾ç¤ºä»£ç æˆ–ç»“æœã€‚\nUse this for setup code that you donâ€™t want cluttering your report.\nå¯å°†æ­¤é€‰é¡¹ç”¨äºä½ ä¸æƒ³è®©æŠ¥å‘Šæ˜¾å¾—æ‚ä¹±çš„è®¾ç½®ä»£ç ã€‚\necho: false prevents code, but not the results, from appearing in the finished file.echo: false å¯ä»¥é˜²æ­¢ä»£ç ï¼ˆä½†ä¸ä¼šé˜»æ­¢ç»“æœï¼‰å‡ºç°åœ¨æœ€ç»ˆæ–‡ä»¶ä¸­ã€‚\nUse this when writing reports aimed at people who donâ€™t want to see the underlying R code.\nå½“ç¼–å†™é¢å‘ä¸æƒ³çœ‹åˆ°åº•å±‚ R ä»£ç çš„è¯»è€…çš„æŠ¥å‘Šæ—¶ï¼Œè¯·ä½¿ç”¨æ­¤é€‰é¡¹ã€‚\nmessage: false or warning: false prevents messages or warnings from appearing in the finished file.message: false æˆ– warning: false å¯ä»¥é˜²æ­¢æ¶ˆæ¯æˆ–è­¦å‘Šå‡ºç°åœ¨æœ€ç»ˆæ–‡ä»¶ä¸­ã€‚\nresults: hide hides printed output; fig-show: hide hides plots.results: hide éšè—æ‰“å°è¾“å‡ºï¼›fig-show: hide éšè—ç»˜å›¾ã€‚\nerror: true causes the render to continue even if code returns an error.error: true ä¼šä½¿æ¸²æŸ“åœ¨ä»£ç è¿”å›é”™è¯¯æ—¶ä¹Ÿèƒ½ç»§ç»­è¿›è¡Œã€‚\nThis is rarely something youâ€™ll want to include in the final version of your report, but can be very useful if you need to debug exactly what is going on inside your .qmd.\nä½ å¾ˆå°‘ä¼šå¸Œæœ›åœ¨æŠ¥å‘Šçš„æœ€ç»ˆç‰ˆæœ¬ä¸­åŒ…å«æ­¤é€‰é¡¹ï¼Œä½†å½“éœ€è¦å‡†ç¡®è°ƒè¯• .qmd æ–‡ä»¶å†…éƒ¨æƒ…å†µæ—¶ï¼Œå®ƒä¼šéå¸¸æœ‰ç”¨ã€‚\nItâ€™s also useful if youâ€™re teaching R and want to deliberately include an error.\nå¦‚æœä½ åœ¨æ•™æˆ R è¯­è¨€å¹¶å¸Œæœ›æ•…æ„å¼•å…¥ä¸€ä¸ªé”™è¯¯ï¼Œè¿™ä¸ªé€‰é¡¹ä¹Ÿå¾ˆæœ‰ç”¨ã€‚\nThe default, error: false causes rendering to fail if there is a single error in the document.\né»˜è®¤å€¼ error: false ä¼šåœ¨æ–‡æ¡£ä¸­å‡ºç°å•ä¸ªé”™è¯¯æ—¶å¯¼è‡´æ¸²æŸ“å¤±è´¥ã€‚\n\nEach of these chunk options get added to the header of the chunk, following #|, e.g., in the following chunk the result is not printed since eval is set to false.\nè¿™äº›ä»£ç å—é€‰é¡¹ä¸­çš„æ¯ä¸€ä¸ªéƒ½ä¼šè¢«æ·»åŠ åˆ°ä»£ç å—çš„å¤´éƒ¨ï¼Œè·Ÿåœ¨ #| åé¢ï¼Œä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„ä»£ç å—ä¸­ï¼Œç»“æœä¸ä¼šè¢«æ‰“å°å‡ºæ¥ï¼Œå› ä¸º eval è¢«è®¾ç½®ä¸ºäº† falseã€‚\n\n```{r}\n#| label: simple-multiplication\n#| eval: false\n2 * 2\n```\n\nThe following table summarizes which types of output each option suppresses:\nä¸‹è¡¨æ€»ç»“äº†æ¯ä¸ªé€‰é¡¹æŠ‘åˆ¶çš„è¾“å‡ºç±»å‹ï¼š\n\n\n\n\n\n\n\n\n\n\n\nOption\nRun code\nShow code\nOutput\nPlots\nMessages\nWarnings\n\n\n\neval: false\nX\n\nX\nX\nX\nX\n\n\ninclude: false\n\nX\nX\nX\nX\nX\n\n\necho: false\n\nX\n\n\n\n\n\n\nresults: hide\n\n\nX\n\n\n\n\n\nfig-show: hide\n\n\n\nX\n\n\n\n\nmessage: false\n\n\n\n\nX\n\n\n\nwarning: false\n\n\n\n\n\nX\n\n\n\n28.5.3 Global options\nAs you work more with knitr, you will discover that some of the default chunk options donâ€™t fit your needs and you want to change them.\néšç€ä½ æ›´å¤šåœ°ä½¿ç”¨ knitrï¼Œä½ ä¼šå‘ç°ä¸€äº›é»˜è®¤çš„ä»£ç å—é€‰é¡¹ä¸ç¬¦åˆä½ çš„éœ€æ±‚ï¼Œä½ ä¼šæƒ³è¦æ›´æ”¹å®ƒä»¬ã€‚\nYou can do this by adding the preferred options in the document YAML, under execute. For example, if you are preparing a report for an audience who does not need to see your code but only your results and narrative, you might set echo: false at the document level. That will hide the code by default, so only showing the chunks you deliberately choose to show (with echo: true). You might consider setting message: false and warning: false, but that would make it harder to debug problems because you wouldnâ€™t see any messages in the final document.\nä½ å¯ä»¥åœ¨æ–‡æ¡£çš„ YAML ä¸­ï¼Œexecute é¡¹ä¸‹æ·»åŠ åå¥½çš„é€‰é¡¹æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æ­£åœ¨ä¸ºä¸€ç¾¤ä¸éœ€è¦çœ‹ä½ çš„ä»£ç ï¼Œåªå…³å¿ƒç»“æœå’Œå™è¿°çš„è¯»è€…å‡†å¤‡æŠ¥å‘Šï¼Œä½ å¯ä»¥åœ¨æ–‡æ¡£çº§åˆ«è®¾ç½® echo: falseã€‚è¿™æ ·ä¼šé»˜è®¤éšè—ä»£ç ï¼Œåªæ˜¾ç¤ºä½ ç‰¹æ„é€‰æ‹©æ˜¾ç¤ºçš„ä»£ç å—ï¼ˆé€šè¿‡ echo: trueï¼‰ã€‚ä½ å¯èƒ½ä¼šè€ƒè™‘è®¾ç½® message: false å’Œ warning: falseï¼Œä½†è¿™ä¼šä½¿è°ƒè¯•é—®é¢˜å˜å¾—æ›´åŠ å›°éš¾ï¼Œå› ä¸ºä½ åœ¨æœ€ç»ˆçš„æ–‡æ¡£ä¸­çœ‹ä¸åˆ°ä»»ä½•æ¶ˆæ¯ã€‚\ntitle: \"My report\"\nexecute:\n  echo: false\nSince Quarto is designed to be multi-lingual (works with R as well as other languages like Python, Julia, etc.), all of the knitr options are not available at the document execution level since some of them only work with knitr and not other engines Quarto uses for running code in other languages (e.g., Jupyter). You can, however, still set these as global options for your document under the knitr field, under opts_chunk. For example, when writing books and tutorials we set:\nç”±äº Quarto è¢«è®¾è®¡ä¸ºå¤šè¯­è¨€çš„ï¼ˆæ—¢æ”¯æŒ Rï¼Œä¹Ÿæ”¯æŒ Pythonã€Julia ç­‰å…¶ä»–è¯­è¨€ï¼‰ï¼Œå› æ­¤å¹¶éæ‰€æœ‰çš„ knitr é€‰é¡¹éƒ½åœ¨æ–‡æ¡£æ‰§è¡Œçº§åˆ«å¯ç”¨ï¼Œå› ä¸ºå…¶ä¸­ä¸€äº›é€‰é¡¹åªé€‚ç”¨äº knitrï¼Œè€Œä¸é€‚ç”¨äº Quarto ç”¨äºè¿è¡Œå…¶ä»–è¯­è¨€ä»£ç ï¼ˆä¾‹å¦‚ï¼ŒJupyterï¼‰çš„å…¶ä»–å¼•æ“ã€‚ä¸è¿‡ï¼Œä½ ä»ç„¶å¯ä»¥åœ¨ knitr å­—æ®µä¸‹çš„ opts_chunk ä¸­å°†å®ƒä»¬è®¾ç½®ä¸ºæ–‡æ¡£çš„å…¨å±€é€‰é¡¹ã€‚ä¾‹å¦‚ï¼Œåœ¨ç¼–å†™ä¹¦ç±å’Œæ•™ç¨‹æ—¶ï¼Œæˆ‘ä»¬ä¼šè¿™æ ·è®¾ç½®ï¼š\ntitle: \"Tutorial\"\nknitr:\n  opts_chunk:\n    comment: \"#&gt;\"\n    collapse: true\nThis uses our preferred comment formatting and ensures that the code and output are kept closely entwined.\nè¿™ä¼šä½¿ç”¨æˆ‘ä»¬åå¥½çš„æ³¨é‡Šæ ¼å¼ï¼Œå¹¶ç¡®ä¿ä»£ç å’Œè¾“å‡ºç´§å¯†åœ°ç»“åˆåœ¨ä¸€èµ·ã€‚\n\n28.5.4 Inline code\nThere is one other way to embed R code into a Quarto document: directly into the text, with: `r `. This can be very useful if you mention properties of your data in the text. For example, the example document used at the start of the chapter had:\nè¿˜æœ‰ä¸€ç§å°† R ä»£ç åµŒå…¥ Quarto æ–‡æ¡£çš„æ–¹å¼ï¼šç›´æ¥åµŒå…¥æ–‡æœ¬ä¸­ï¼Œä½¿ç”¨ï¼š`r `ã€‚å¦‚æœä½ åœ¨æ–‡æœ¬ä¸­æåˆ°æ•°æ®çš„å±æ€§ï¼Œè¿™ä¼šéå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œæœ¬ç« å¼€å¤´ä½¿ç”¨çš„ç¤ºä¾‹æ–‡æ¡£ä¸­æœ‰ï¼š\n\nWe have data about `r nrow(diamonds)` diamonds. Only `r nrow(diamonds) - nrow(smaller)` are larger than 2.5 carats. The distribution of the remainder is shown below:\n\nWhen the report is rendered, the results of these computations are inserted into the text:\nå½“æŠ¥å‘Šè¢«æ¸²æŸ“æ—¶ï¼Œè¿™äº›è®¡ç®—çš„ç»“æœä¼šè¢«æ’å…¥åˆ°æ–‡æœ¬ä¸­ï¼š\n\nWe have data about 53940 diamonds. Only 126 are larger than 2.5 carats. The distribution of the remainder is shown below:\n\nWhen inserting numbers into text, format() is your friend. It allows you to set the number of digits so you donâ€™t print to a ridiculous degree of precision, and a big.mark to make numbers easier to read. You might combine these into a helper function:\nå½“åœ¨æ–‡æœ¬ä¸­æ’å…¥æ•°å­—æ—¶ï¼Œformat() æ˜¯ä½ çš„å¥½å¸®æ‰‹ã€‚å®ƒå…è®¸ä½ è®¾ç½® digits çš„æ•°é‡ï¼Œè¿™æ ·ä½ å°±ä¸ä¼šæ‰“å°å‡ºç²¾åº¦é«˜åˆ°ç¦»è°±çš„æ•°å­—ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨ big.mark ä½¿æ•°å­—æ›´æ˜“äºé˜…è¯»ã€‚ä½ å¯ä»¥å°†è¿™äº›ç»„åˆæˆä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼š\n\ncomma &lt;- function(x) format(x, digits = 2, big.mark = \",\")\ncomma(3452345)\n#&gt; [1] \"3,452,345\"\ncomma(.12358124331)\n#&gt; [1] \"0.12\"\n\n\n28.5.5 Exercises\n\nAdd a section that explores how diamond sizes vary by cut, color, and clarity. Assume youâ€™re writing a report for someone who doesnâ€™t know R, and instead of setting echo: false on each chunk, set a global option.\nDownload diamond-sizes.qmd from https://github.com/hadley/r4ds/tree/main/quarto. Add a section that describes the largest 20 diamonds, including a table that displays their most important attributes.\nModify diamonds-sizes.qmd to use label_comma() to produce nicely formatted output. Also include the percentage of diamonds that are larger than 2.5 carats.",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-figures",
    "href": "quarto.html#sec-figures",
    "title": "28Â  Quarto",
    "section": "\n28.6 Figures",
    "text": "28.6 Figures\nThe figures in a Quarto document can be embedded (e.g., a PNG or JPEG file) or generated as a result of a code chunk.\nQuarto æ–‡æ¡£ä¸­çš„å›¾å½¢å¯ä»¥æ˜¯åµŒå…¥å¼çš„ï¼ˆä¾‹å¦‚ï¼ŒPNG æˆ– JPEG æ–‡ä»¶ï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯ç”±ä»£ç å—ç”Ÿæˆçš„ç»“æœã€‚\nTo embed an image from an external file, you can use the Insert menu in the Visual Editor in RStudio and select Figure / Image. This will pop open a menu where you can browse to the image you want to insert as well as add alternative text or caption to it and adjust its size. In the visual editor you can also simply paste an image from your clipboard into your document and RStudio will place a copy of that image in your project folder.\nè¦ä»å¤–éƒ¨æ–‡ä»¶åµŒå…¥å›¾åƒï¼Œä½ å¯ä»¥åœ¨ RStudio çš„å¯è§†åŒ–ç¼–è¾‘å™¨ä¸­ä½¿ç”¨æ’å…¥èœå•ï¼Œå¹¶é€‰æ‹©å›¾å½¢ / å›¾åƒã€‚è¿™å°†å¼¹å‡ºä¸€ä¸ªèœå•ï¼Œä½ å¯ä»¥åœ¨å…¶ä¸­æµè§ˆè¦æ’å…¥çš„å›¾åƒï¼Œå¹¶ä¸ºå…¶æ·»åŠ æ›¿ä»£æ–‡æœ¬æˆ–æ ‡é¢˜ï¼Œä»¥åŠè°ƒæ•´å…¶å¤§å°ã€‚åœ¨å¯è§†åŒ–ç¼–è¾‘å™¨ä¸­ï¼Œä½ ä¹Ÿå¯ä»¥ç®€å•åœ°å°†å‰ªè´´æ¿ä¸­çš„å›¾åƒç²˜è´´åˆ°æ–‡æ¡£ä¸­ï¼ŒRStudio ä¼šå°†è¯¥å›¾åƒçš„å‰¯æœ¬æ”¾ç½®åœ¨ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹ä¸­ã€‚\nIf you include a code chunk that generates a figure (e.g., includes a ggplot() call), the resulting figure will be automatically included in your Quarto document.\nå¦‚æœä½ åŒ…å«ä¸€ä¸ªç”Ÿæˆå›¾å½¢çš„ä»£ç å—ï¼ˆä¾‹å¦‚ï¼ŒåŒ…å«ä¸€ä¸ª ggplot() è°ƒç”¨ï¼‰ï¼Œç”Ÿæˆçš„å›¾å½¢å°†è‡ªåŠ¨åŒ…å«åœ¨ä½ çš„ Quarto æ–‡æ¡£ä¸­ã€‚\n\n28.6.1 Figure sizing\nThe biggest challenge of graphics in Quarto is getting your figures the right size and shape. There are five main options that control figure sizing: fig-width, fig-height, fig-asp, out-width and out-height. Image sizing is challenging because there are two sizes (the size of the figure created by R and the size at which it is inserted in the output document), and multiple ways of specifying the size (i.e.Â height, width, and aspect ratio: pick two of three).\nåœ¨ Quarto ä¸­ï¼Œå›¾å½¢é¢ä¸´çš„æœ€å¤§æŒ‘æˆ˜æ˜¯è·å¾—åˆé€‚çš„å°ºå¯¸å’Œå½¢çŠ¶ã€‚æœ‰äº”ä¸ªä¸»è¦é€‰é¡¹å¯ä»¥æ§åˆ¶å›¾å½¢å¤§å°ï¼šfig-widthã€fig-heightã€fig-aspã€out-width å’Œ out-heightã€‚å›¾åƒå°ºå¯¸è°ƒæ•´ä¹‹æ‰€ä»¥å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œæ˜¯å› ä¸ºå­˜åœ¨ä¸¤ç§å°ºå¯¸ï¼ˆR åˆ›å»ºçš„å›¾å½¢å°ºå¯¸å’Œæ’å…¥åˆ°è¾“å‡ºæ–‡æ¡£ä¸­çš„å°ºå¯¸ï¼‰ï¼Œå¹¶ä¸”æœ‰å¤šç§æŒ‡å®šå°ºå¯¸çš„æ–¹å¼ï¼ˆå³é«˜åº¦ã€å®½åº¦å’Œçºµæ¨ªæ¯”ï¼šä¸‰è€…é€‰å…¶äºŒï¼‰ã€‚\nWe recommend three of the five options:\næˆ‘ä»¬æ¨èäº”ä¸ªé€‰é¡¹ä¸­çš„ä¸‰ä¸ªï¼š\n\nPlots tend to be more aesthetically pleasing if they have consistent width.\nTo enforce this, set fig-width: 6 (6â€) and fig-asp: 0.618 (the golden ratio) in the defaults.\nThen in individual chunks, only adjust fig-asp.\nå¦‚æœå›¾çš„å®½åº¦ä¸€è‡´ï¼Œå®ƒä»¬å¾€å¾€åœ¨ç¾å­¦ä¸Šæ›´ä»¤äººæ„‰æ‚¦ã€‚\nä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œå¯ä»¥åœ¨é»˜è®¤è®¾ç½®ä¸­è®¾å®š fig-width: 6ï¼ˆ6è‹±å¯¸ï¼‰å’Œ fig-asp: 0.618ï¼ˆé»„é‡‘æ¯”ä¾‹ï¼‰ã€‚\nç„¶ååœ¨å•ä¸ªä»£ç å—ä¸­ï¼Œåªè°ƒæ•´ fig-aspã€‚\nControl the output size with out-width and set it to a percentage of the body width of the output document.\nWe suggest to out-width: \"70%\" and fig-align: center.\nThat gives plots room to breathe, without taking up too much space.\nä½¿ç”¨ out-width æ§åˆ¶è¾“å‡ºå°ºå¯¸ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºè¾“å‡ºæ–‡æ¡£æ­£æ–‡å®½åº¦çš„ç™¾åˆ†æ¯”ã€‚\næˆ‘ä»¬å»ºè®®è®¾ç½®ä¸º out-width: \"70%\" å’Œ fig-align: centerã€‚\nè¿™ç»™å›¾è¡¨ç•™å‡ºäº†å‘¼å¸çš„ç©ºé—´ï¼Œè€Œä¸ä¼šå ç”¨å¤ªå¤šç©ºé—´ã€‚\nTo put multiple plots in a single row, set the layout-ncol to 2 for two plots, 3 for three plots, etc.\nThis effectively sets out-width to â€œ50%â€ for each of your plots if layout-ncol is 2, â€œ33%â€ if layout-ncol is 3, etc.\nDepending on what youâ€™re trying to illustrate (e.g., show data or show plot variations), you might also tweak fig-width, as discussed below.\nè¦å°†å¤šä¸ªå›¾æ”¾åœ¨ä¸€è¡Œä¸­ï¼Œå¯ä»¥å°† layout-ncol è®¾ç½®ä¸º 2ï¼ˆè¡¨ç¤ºä¸¤ä¸ªå›¾ï¼‰ã€3ï¼ˆè¡¨ç¤ºä¸‰ä¸ªå›¾ï¼‰ç­‰ã€‚\nå¦‚æœ layout-ncol æ˜¯ 2ï¼Œè¿™å®é™…ä¸Šä¼šå°†æ¯ä¸ªå›¾çš„ out-width è®¾ç½®ä¸º â€œ50%â€ï¼›å¦‚æœ layout-ncol æ˜¯ 3ï¼Œåˆ™è®¾ç½®ä¸º â€œ33%â€ï¼Œä»¥æ­¤ç±»æ¨ã€‚\næ ¹æ®ä½ è¯•å›¾è¯´æ˜çš„å†…å®¹ï¼ˆä¾‹å¦‚ï¼Œæ˜¾ç¤ºæ•°æ®æˆ–æ˜¾ç¤ºå›¾çš„å˜åŒ–ï¼‰ï¼Œä½ å¯èƒ½è¿˜éœ€è¦è°ƒæ•´ fig-widthï¼Œå¦‚ä¸‹æ–‡æ‰€è¿°ã€‚\n\nIf you find that youâ€™re having to squint to read the text in your plot, you need to tweak fig-width. If fig-width is larger than the size the figure is rendered in the final doc, the text will be too small; if fig-width is smaller, the text will be too big. Youâ€™ll often need to do a little experimentation to figure out the right ratio between the fig-width and the eventual width in your document. To illustrate the principle, the following three plots have fig-width of 4, 6, and 8 respectively:\nå¦‚æœä½ å‘ç°è‡ªå·±éœ€è¦çœ¯ç€çœ¼ç›æ‰èƒ½çœ‹æ¸…å›¾ä¸­çš„æ–‡å­—ï¼Œé‚£ä¹ˆä½ éœ€è¦è°ƒæ•´ fig-widthã€‚å¦‚æœ fig-width å¤§äºæœ€ç»ˆæ–‡æ¡£ä¸­æ¸²æŸ“çš„å›¾å½¢å°ºå¯¸ï¼Œæ–‡å­—ä¼šå¤ªå°ï¼›å¦‚æœ fig-width æ›´å°ï¼Œæ–‡å­—ä¼šå¤ªå¤§ã€‚ä½ é€šå¸¸éœ€è¦åšä¸€äº›å®éªŒæ¥æ‰¾å‡º fig-width å’Œæ–‡æ¡£ä¸­æœ€ç»ˆå®½åº¦ä¹‹é—´çš„æ­£ç¡®æ¯”ä¾‹ã€‚ä¸ºäº†è¯´æ˜è¿™ä¸ªåŸç†ï¼Œä¸‹é¢ä¸‰ä¸ªå›¾çš„ fig-width åˆ†åˆ«ä¸º 4ã€6 å’Œ 8ï¼š\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you want to make sure the font size is consistent across all your figures, whenever you set out-width, youâ€™ll also need to adjust fig-width to maintain the same ratio with your default out-width. For example, if your default fig-width is 6 and out-width is â€œ70%â€, when you set out-width: \"50%\" youâ€™ll need to set fig-width to 4.3 (6 * 0.5 / 0.7).\nå¦‚æœä½ æƒ³ç¡®ä¿æ‰€æœ‰å›¾å½¢çš„å­—ä½“å¤§å°ä¿æŒä¸€è‡´ï¼Œé‚£ä¹ˆæ¯å½“ä½ è®¾ç½® out-width æ—¶ï¼Œä½ ä¹Ÿéœ€è¦è°ƒæ•´ fig-width ä»¥ä¿æŒä¸é»˜è®¤ out-width ç›¸åŒçš„æ¯”ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ çš„é»˜è®¤ fig-width æ˜¯ 6ï¼Œout-width æ˜¯ â€œ70%â€ï¼Œé‚£ä¹ˆå½“ä½ å°† out-width è®¾ç½®ä¸º â€œ50%â€ æ—¶ï¼Œä½ éœ€è¦å°† fig-width è®¾ç½®ä¸º 4.3 (6 * 0.5 / 0.7)ã€‚\nFigure sizing and scaling is an art and science and getting things right can require an iterative trial-and-error approach. You can learn more about figure sizing in the taking control of plot scaling blog post.\nå›¾å½¢çš„å°ºå¯¸å’Œç¼©æ”¾æ˜¯ä¸€é—¨è‰ºæœ¯å’Œç§‘å­¦ï¼Œè¦åšåˆ°æ°åˆ°å¥½å¤„å¯èƒ½éœ€è¦åå¤è¯•éªŒã€‚ä½ å¯ä»¥åœ¨ ã€ŠæŒæ§ç»˜å›¾ç¼©æ”¾ã€‹è¿™ç¯‡åšæ–‡ ä¸­äº†è§£æ›´å¤šå…³äºå›¾å½¢å°ºå¯¸è°ƒæ•´çš„çŸ¥è¯†ã€‚\n\n28.6.2 Other important options\nWhen mingling code and text, like in this book, you can set fig-show: hold so that plots are shown after the code. This has the pleasant side effect of forcing you to break up large blocks of code with their explanations.\nå½“åƒæœ¬ä¹¦è¿™æ ·å°†ä»£ç å’Œæ–‡æœ¬æ··åˆåœ¨ä¸€èµ·æ—¶ï¼Œä½ å¯ä»¥è®¾ç½® fig-show: holdï¼Œè¿™æ ·å›¾è¡¨å°±ä¼šåœ¨ä»£ç ä¹‹åæ˜¾ç¤ºã€‚è¿™æ ·åšæœ‰ä¸€ä¸ªä»¤äººæ„‰å¿«çš„å¥½å¤„ï¼Œå°±æ˜¯è¿«ä½¿ä½ ç”¨è§£é‡Šæ¥æ‰“æ–­å¤§æ®µçš„ä»£ç ã€‚\nTo add a caption to the plot, use fig-cap. In Quarto this will change the figure from inline to â€œfloatingâ€.\nè¦ä¸ºå›¾è¡¨æ·»åŠ æ ‡é¢˜ï¼Œè¯·ä½¿ç”¨ fig-capã€‚åœ¨ Quarto ä¸­ï¼Œè¿™ä¼šå°†å›¾å½¢ä»å†…è”ï¼ˆinlineï¼‰æ›´æ”¹ä¸ºâ€œæµ®åŠ¨â€ï¼ˆfloatingï¼‰ã€‚\nIf youâ€™re producing PDF output, the default graphics type is PDF. This is a good default because PDFs are high quality vector graphics. However, they can produce very large and slow plots if you are displaying thousands of points. In that case, set fig-format: \"png\" to force the use of PNGs. They are slightly lower quality, but will be much more compact.\nå¦‚æœä½ è¦ç”Ÿæˆ PDF è¾“å‡ºï¼Œé»˜è®¤çš„å›¾å½¢ç±»å‹æ˜¯ PDFã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é»˜è®¤è®¾ç½®ï¼Œå› ä¸º PDF æ˜¯é«˜è´¨é‡çš„çŸ¢é‡å›¾å½¢ã€‚ä½†æ˜¯ï¼Œå¦‚æœä½ è¦æ˜¾ç¤ºæ•°åƒä¸ªç‚¹ï¼Œå®ƒä»¬å¯èƒ½ä¼šç”Ÿæˆéå¸¸å¤§ä¸”åŠ è½½ç¼“æ…¢çš„å›¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥è®¾ç½® fig-format: \"png\" æ¥å¼ºåˆ¶ä½¿ç”¨ PNGã€‚å®ƒä»¬çš„è´¨é‡ç¨ä½ï¼Œä½†ä¼šæ›´åŠ ç´§å‡‘ã€‚\nItâ€™s a good idea to name code chunks that produce figures, even if you donâ€™t routinely label other chunks. The chunk label is used to generate the file name of the graphic on disk, so naming your chunks makes it much easier to pick out plots and reuse in other circumstances (e.g., if you want to quickly drop a single plot into an email).\nä¸ºç”Ÿæˆå›¾å½¢çš„ä»£ç å—å‘½åæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå³ä½¿ä½ å¹¶ä¸å¸¸è§„åœ°ä¸ºå…¶ä»–ä»£ç å—æ·»åŠ æ ‡ç­¾ã€‚ä»£ç å—æ ‡ç­¾ç”¨äºç”Ÿæˆç£ç›˜ä¸Šå›¾å½¢æ–‡ä»¶çš„åç§°ï¼Œå› æ­¤ä¸ºä»£ç å—å‘½åå¯ä»¥è®©ä½ æ›´å®¹æ˜“åœ°æŒ‘é€‰å‡ºå›¾è¡¨å¹¶åœ¨å…¶ä»–æƒ…å†µä¸‹é‡ç”¨ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³å¿«é€Ÿå°†å•ä¸ªå›¾è¡¨æ”¾å…¥ç”µå­é‚®ä»¶ä¸­ï¼‰ã€‚\n\n28.6.3 Exercises\n\nOpen diamond-sizes.qmd in the visual editor, find an image of a diamond, copy it, and paste it into the document. Double click on the image and add a caption. Resize the image and render your document. Observe how the image is saved in your current working directory.\nEdit the label of the code chunk in diamond-sizes.qmd that generates a plot to start with the prefix fig- and add a caption to the figure with the chunk option fig-cap. Then, edit the text above the code chunk to add a cross-reference to the figure with Insert &gt; Cross Reference.\nChange the size of the figure with the following chunk options, one at a time, render your document, and describe how the figure changes.\n\nfig-width: 10\nfig-height: 3\nout-width: \"100%\"\nout-width: \"20%\"",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#tables",
    "href": "quarto.html#tables",
    "title": "28Â  Quarto",
    "section": "\n28.7 Tables",
    "text": "28.7 Tables\nSimilar to figures, you can include two types of tables in a Quarto document. They can be markdown tables that you create directly in your Quarto document (using the Insert Table menu) or they can be tables generated as a result of a code chunk. In this section we will focus on the latter, tables generated via computation.\nä¸å›¾å½¢ç±»ä¼¼ï¼Œä½ å¯ä»¥åœ¨ Quarto æ–‡æ¡£ä¸­åŒ…å«ä¸¤ç§ç±»å‹çš„è¡¨æ ¼ã€‚å®ƒä»¬å¯ä»¥æ˜¯ä½ ç›´æ¥åœ¨ Quarto æ–‡æ¡£ä¸­åˆ›å»ºçš„ markdown è¡¨æ ¼ï¼ˆä½¿ç”¨â€œæ’å…¥è¡¨æ ¼â€èœå•ï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯ç”±ä»£ç å—ç”Ÿæˆçš„ç»“æœã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨åè€…ï¼Œå³é€šè¿‡è®¡ç®—ç”Ÿæˆçš„è¡¨æ ¼ã€‚\nBy default, Quarto prints data frames and matrices as youâ€™d see them in the console:\né»˜è®¤æƒ…å†µä¸‹ï¼ŒQuarto ä¼šåƒä½ åœ¨æ§åˆ¶å°ä¸­çœ‹åˆ°çš„é‚£æ ·æ‰“å°æ•°æ®æ¡†å’ŒçŸ©é˜µï¼š\n\nmtcars[1:5, ]\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\nIf you prefer that data be displayed with additional formatting you can use the knitr::kable() function. The code below generates TableÂ 28.1.\nå¦‚æœä½ å¸Œæœ›æ•°æ®ä»¥é™„åŠ æ ¼å¼æ˜¾ç¤ºï¼Œå¯ä»¥ä½¿ç”¨ knitr::kable() å‡½æ•°ã€‚ä¸‹é¢çš„ä»£ç ç”Ÿæˆäº† TableÂ 28.1ã€‚\n\nknitr::kable(mtcars[1:5, ], )\n\n\nTableÂ 28.1: A knitr kable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\n\n\nRead the documentation for ?knitr::kable to see the other ways in which you can customize the table. For even deeper customization, consider the gt, huxtable, reactable, kableExtra, xtable, stargazer, pander, tables, and ascii packages. Each provides a set of tools for returning formatted tables from R code.\né˜…è¯» ?knitr::kable çš„æ–‡æ¡£ï¼Œäº†è§£è‡ªå®šä¹‰è¡¨æ ¼çš„å…¶ä»–æ–¹æ³•ã€‚å¦‚æœéœ€è¦æ›´æ·±åº¦çš„å®šåˆ¶ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ gtã€huxtableã€reactableã€kableExtraã€xtableã€stargazerã€panderã€tables å’Œ ascii ç­‰åŒ…ã€‚æ¯ä¸ªåŒ…éƒ½æä¾›äº†ä¸€å¥—ç”¨äºä» R ä»£ç è¿”å›æ ¼å¼åŒ–è¡¨æ ¼çš„å·¥å…·ã€‚\n\n28.7.1 Exercises\n\nOpen diamond-sizes.qmd in the visual editor, insert a code chunk, and add a table with knitr::kable() that shows the first 5 rows of the diamonds data frame.\nDisplay the same table with gt::gt() instead.\nAdd a chunk label that starts with the prefix tbl- and add a caption to the table with the chunk option tbl-cap. Then, edit the text above the code chunk to add a cross-reference to the table with Insert &gt; Cross Reference.",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-caching",
    "href": "quarto.html#sec-caching",
    "title": "28Â  Quarto",
    "section": "\n28.8 Caching",
    "text": "28.8 Caching\nNormally, each render of a document starts from a completely clean slate.\né€šå¸¸ï¼Œæ¯æ¬¡æ¸²æŸ“æ–‡æ¡£éƒ½æ˜¯ä»ä¸€ä¸ªå®Œå…¨å¹²å‡€çš„çŠ¶æ€å¼€å§‹çš„ã€‚\nThis is great for reproducibility, because it ensures that youâ€™ve captured every important computation in code.\nè¿™å¯¹äºå¯å¤ç°æ€§æ¥è¯´éå¸¸å¥½ï¼Œå› ä¸ºå®ƒç¡®ä¿äº†ä½ å·²ç»åœ¨ä»£ç ä¸­æ•è·äº†æ¯ä¸€ä¸ªé‡è¦çš„è®¡ç®—ã€‚\nHowever, it can be painful if you have some computations that take a long time.\nç„¶è€Œï¼Œå¦‚æœä½ æœ‰ä¸€äº›éœ€è¦å¾ˆé•¿æ—¶é—´æ‰èƒ½å®Œæˆçš„è®¡ç®—ï¼Œè¿™å¯èƒ½ä¼šå¾ˆç—›è‹¦ã€‚\nThe solution is cache: true.\nè§£å†³æ–¹æ¡ˆæ˜¯ cache: trueã€‚\nYou can enable the Knitr cache at the document level for caching the results of all computations in a document using standard YAML options:\nä½ å¯ä»¥ä½¿ç”¨æ ‡å‡†çš„ YAML é€‰é¡¹ï¼Œåœ¨æ–‡æ¡£çº§åˆ«å¯ç”¨ Knitr ç¼“å­˜ï¼Œæ¥ç¼“å­˜æ–‡æ¡£ä¸­æ‰€æœ‰è®¡ç®—çš„ç»“æœï¼š\n---\ntitle: \"My Document\"\nexecute: \n  cache: true\n---\nYou can also enable caching at the chunk level for caching the results of computation in a specific chunk:\nä½ ä¹Ÿå¯ä»¥åœ¨ä»£ç å—çº§åˆ«å¯ç”¨ç¼“å­˜ï¼Œæ¥ç¼“å­˜ç‰¹å®šä»£ç å—ä¸­çš„è®¡ç®—ç»“æœï¼š\n\n```{r}\n#| cache: true\n# code for lengthy computation...\n```\n\nWhen set, this will save the output of the chunk to a specially named file on disk.\nè®¾ç½®åï¼Œè¿™å°†æŠŠä»£ç å—çš„è¾“å‡ºä¿å­˜åˆ°ç£ç›˜ä¸Šçš„ä¸€ä¸ªç‰¹æ®Šå‘½åçš„æ–‡ä»¶ä¸­ã€‚\nOn subsequent runs, knitr will check to see if the code has changed, and if it hasnâ€™t, it will reuse the cached results.\nåœ¨åç»­è¿è¡Œä¸­ï¼Œknitr å°†æ£€æŸ¥ä»£ç æ˜¯å¦å·²æ›´æ”¹ï¼Œå¦‚æœæœªæ›´æ”¹ï¼Œå®ƒå°†é‡ç”¨ç¼“å­˜çš„ç»“æœã€‚\nThe caching system must be used with care, because by default it is based on the code only, not its dependencies.\nç¼“å­˜ç³»ç»Ÿå¿…é¡»è°¨æ…ä½¿ç”¨ï¼Œå› ä¸ºé»˜è®¤æƒ…å†µä¸‹å®ƒåªåŸºäºä»£ç æœ¬èº«ï¼Œè€Œä¸åŸºäºå…¶ä¾èµ–é¡¹ã€‚\nFor example, here the processed_data chunk depends on the raw-data chunk:\nä¾‹å¦‚ï¼Œè¿™é‡Œçš„ processed_data ä»£ç å—ä¾èµ–äº raw-data ä»£ç å—ï¼š\n``` {{r}}\n#| label: raw-data\n#| cache: true\nrawdata &lt;- readr::read_csv(\"a_very_large_file.csv\")\n```\n``` {{r}}\n#| label: processed_data\n#| cache: true\nprocessed_data &lt;- rawdata |&gt; \n  filter(!is.na(import_var)) |&gt; \n  mutate(new_variable = complicated_transformation(x, y, z))\n```\nCaching the processed_data chunk means that it will get re-run if the dplyr pipeline is changed, but it wonâ€™t get rerun if the read_csv() call changes.\nç¼“å­˜ processed_data ä»£ç å—æ„å‘³ç€å¦‚æœ dplyr ç®¡é“å‘ç”Ÿæ›´æ”¹ï¼Œå®ƒå°†é‡æ–°è¿è¡Œï¼Œä½†å¦‚æœ read_csv() è°ƒç”¨å‘ç”Ÿæ›´æ”¹ï¼Œå®ƒå°†ä¸ä¼šé‡æ–°è¿è¡Œã€‚\nYou can avoid that problem with the dependson chunk option:\nä½ å¯ä»¥ä½¿ç”¨ dependson ä»£ç å—é€‰é¡¹æ¥é¿å…è¿™ä¸ªé—®é¢˜ï¼š\n``` {{r}}\n#| label: processed-data\n#| cache: true\n#| dependson: \"raw-data\"\nprocessed_data &lt;- rawdata |&gt; \n  filter(!is.na(import_var)) |&gt; \n  mutate(new_variable = complicated_transformation(x, y, z))\n```\ndependson should contain a character vector of every chunk that the cached chunk depends on.dependson åº”è¯¥åŒ…å«ä¸€ä¸ªå­—ç¬¦å‘é‡ï¼Œå…¶ä¸­åŒ…å«è¢«ç¼“å­˜çš„ä»£ç å—æ‰€ä¾èµ–çš„æ¯ä¸€ä¸ªä»£ç å—ã€‚\nKnitr will update the results for the cached chunk whenever it detects that one of its dependencies have changed.\næ¯å½“ Knitr æ£€æµ‹åˆ°å…¶æŸä¸ªä¾èµ–é¡¹å·²æ›´æ”¹æ—¶ï¼Œå®ƒå°†æ›´æ–°ç¼“å­˜ä»£ç å—çš„ç»“æœã€‚\nNote that the chunks wonâ€™t update if a_very_large_file.csv changes, because knitr caching only tracks changes within the .qmd file.\nè¯·æ³¨æ„ï¼Œå¦‚æœ a_very_large_file.csv å‘ç”Ÿæ›´æ”¹ï¼Œä»£ç å—ä¸ä¼šæ›´æ–°ï¼Œå› ä¸º knitr ç¼“å­˜åªè·Ÿè¸ª .qmd æ–‡ä»¶å†…éƒ¨çš„æ›´æ”¹ã€‚\nIf you want to also track changes to that file you can use the cache.extra option.\nå¦‚æœä½ è¿˜æƒ³è·Ÿè¸ªè¯¥æ–‡ä»¶çš„æ›´æ”¹ï¼Œå¯ä»¥ä½¿ç”¨ cache.extra é€‰é¡¹ã€‚\nThis is an arbitrary R expression that will invalidate the cache whenever it changes.\nè¿™æ˜¯ä¸€ä¸ªä»»æ„çš„ R è¡¨è¾¾å¼ï¼Œæ¯å½“å®ƒå‘ç”Ÿæ›´æ”¹æ—¶ï¼Œéƒ½ä¼šä½¿ç¼“å­˜å¤±æ•ˆã€‚\nA good function to use is file.mtime(): it returns when it was last modified.\nä¸€ä¸ªå¾ˆå¥½ç”¨çš„å‡½æ•°æ˜¯ file.mtime()ï¼šå®ƒè¿”å›æ–‡ä»¶çš„æœ€åä¿®æ”¹æ—¶é—´ã€‚\nThen you can write:\nç„¶åä½ å¯ä»¥è¿™æ ·å†™ï¼š\n``` {{r}}\n#| label: raw-data\n#| cache: true\n#| cache.extra: !expr file.mtime(\"a_very_large_file.csv\")\nrawdata &lt;- readr::read_csv(\"a_very_large_file.csv\")\n```\nWeâ€™ve followed the advice of David Robinson to name these chunks: each chunk is named after the primary object that it creates.\næˆ‘ä»¬éµå¾ªäº† David Robinson çš„å»ºè®®æ¥å‘½åè¿™äº›ä»£ç å—ï¼šæ¯ä¸ªä»£ç å—éƒ½ä»¥å®ƒåˆ›å»ºçš„ä¸»è¦å¯¹è±¡å‘½åã€‚\nThis makes it easier to understand the dependson specification.\nè¿™ä½¿å¾—ç†è§£ dependson çš„è§„èŒƒå˜å¾—æ›´åŠ å®¹æ˜“ã€‚\nAs your caching strategies get progressively more complicated, itâ€™s a good idea to regularly clear out all your caches with knitr::clean_cache().\néšç€ä½ çš„ç¼“å­˜ç­–ç•¥å˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œå®šæœŸä½¿ç”¨ knitr::clean_cache() æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ˜¯ä¸ªå¥½ä¸»æ„ã€‚\n\n28.8.1 Exercises\n\nSet up a network of chunks where d depends on c and b, and both b and c depend on a. Have each chunk print lubridate::now(), set cache: true, then verify your understanding of caching.",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#troubleshooting",
    "href": "quarto.html#troubleshooting",
    "title": "28Â  Quarto",
    "section": "\n28.9 Troubleshooting",
    "text": "28.9 Troubleshooting\nTroubleshooting Quarto documents can be challenging because you are no longer in an interactive R environment, and you will need to learn some new tricks.\nå¯¹ Quarto æ–‡æ¡£è¿›è¡Œæ•…éšœæ’é™¤å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºä½ ä¸å†å¤„äºäº¤äº’å¼ R ç¯å¢ƒä¸­ï¼Œéœ€è¦å­¦ä¹ ä¸€äº›æ–°æŠ€å·§ã€‚\nAdditionally, the error could be due to issues with the Quarto document itself or due to the R code in the Quarto document.\næ­¤å¤–ï¼Œé”™è¯¯å¯èƒ½æ˜¯ç”±äº Quarto æ–‡æ¡£æœ¬èº«çš„é—®é¢˜ï¼Œä¹Ÿå¯èƒ½æ˜¯ç”±äº Quarto æ–‡æ¡£ä¸­çš„ R ä»£ç é—®é¢˜ã€‚\nOne common error in documents with code chunks is duplicated chunk labels, which are especially pervasive if your workflow involves copying and pasting code chunks.\nå¸¦æœ‰ä»£ç å—çš„æ–‡æ¡£ä¸­ä¸€ä¸ªå¸¸è§çš„é”™è¯¯æ˜¯é‡å¤çš„ä»£ç å—æ ‡ç­¾ï¼Œå¦‚æœä½ çš„å·¥ä½œæµç¨‹æ¶‰åŠå¤åˆ¶å’Œç²˜è´´ä»£ç å—ï¼Œè¿™ä¸ªé—®é¢˜å°¤å…¶æ™®éã€‚\nTo address this issue, all you need to do is to change one of your duplicated labels.\nè¦è§£å†³æ­¤é—®é¢˜ï¼Œä½ åªéœ€æ›´æ”¹å…¶ä¸­ä¸€ä¸ªé‡å¤çš„æ ‡ç­¾å³å¯ã€‚\nIf the errors are due to the R code in the document, the first thing you should always try is to recreate the problem in an interactive session.\nå¦‚æœé”™è¯¯æ˜¯ç”±äºæ–‡æ¡£ä¸­çš„ R ä»£ç å¼•èµ·çš„ï¼Œä½ é¦–å…ˆåº”è¯¥å°è¯•åœ¨äº¤äº’å¼ä¼šè¯ä¸­é‡ç°é—®é¢˜ã€‚\nRestart R, then â€œRun all chunksâ€, either from the Code menu, under Run region or with the keyboard shortcut Ctrl + Alt + R.\né‡å¯ Rï¼Œç„¶åâ€œè¿è¡Œæ‰€æœ‰ä»£ç å—â€ï¼Œå¯ä»¥ä»â€œä»£ç â€èœå•çš„â€œè¿è¡ŒåŒºåŸŸâ€ä¸‹é€‰æ‹©ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨é”®ç›˜å¿«æ·é”® Ctrl + Alt + Rã€‚\nIf youâ€™re lucky, that will recreate the problem, and you can figure out whatâ€™s going on interactively.\nå¦‚æœå¹¸è¿çš„è¯ï¼Œè¿™å°†é‡ç°é—®é¢˜ï¼Œä½ å°±å¯ä»¥åœ¨äº¤äº’å¼ç¯å¢ƒä¸­æ‰¾å‡ºé—®é¢˜æ‰€åœ¨ã€‚\nIf that doesnâ€™t help, there must be something different between your interactive environment and the Quarto environment.\nå¦‚æœè¿™æ²¡æœ‰å¸®åŠ©ï¼Œé‚£ä¹ˆä½ çš„äº¤äº’å¼ç¯å¢ƒå’Œ Quarto ç¯å¢ƒä¹‹é—´è‚¯å®šå­˜åœ¨å·®å¼‚ã€‚\nYouâ€™re going to need to systematically explore the options.\nä½ å°†éœ€è¦ç³»ç»Ÿåœ°æ¢ç´¢å„ç§å¯èƒ½æ€§ã€‚\nThe most common difference is the working directory: the working directory of a Quarto is the directory in which it lives.\næœ€å¸¸è§çš„åŒºåˆ«æ˜¯å·¥ä½œç›®å½•ï¼šQuarto çš„å·¥ä½œç›®å½•æ˜¯å®ƒæ‰€åœ¨çš„ç›®å½•ã€‚\nCheck the working directory is what you expect by including getwd() in a chunk.\né€šè¿‡åœ¨ä»£ç å—ä¸­åŒ…å« getwd() æ¥æ£€æŸ¥å·¥ä½œç›®å½•æ˜¯å¦ç¬¦åˆä½ çš„é¢„æœŸã€‚\nNext, brainstorm all the things that might cause the bug.\næ¥ä¸‹æ¥ï¼Œé›†æ€å¹¿ç›Šï¼Œæƒ³å‡ºæ‰€æœ‰å¯èƒ½å¯¼è‡´é”™è¯¯çš„äº‹æƒ…ã€‚\nYouâ€™ll need to systematically check that theyâ€™re the same in your R session and your Quarto session.\nä½ éœ€è¦ç³»ç»Ÿåœ°æ£€æŸ¥å®ƒä»¬åœ¨ä½ çš„ R ä¼šè¯å’Œ Quarto ä¼šè¯ä¸­æ˜¯å¦ç›¸åŒã€‚\nThe easiest way to do that is to set error: true on the chunk causing the problem, then use print() and str() to check that settings are as you expect.\næœ€ç®€å•çš„æ–¹æ³•æ˜¯åœ¨å¯¼è‡´é—®é¢˜çš„ä»£ç å—ä¸Šè®¾ç½® error: trueï¼Œç„¶åä½¿ç”¨ print() å’Œ str() æ¥æ£€æŸ¥è®¾ç½®æ˜¯å¦å¦‚ä½ æ‰€æ–™ã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#yaml-header",
    "href": "quarto.html#yaml-header",
    "title": "28Â  Quarto",
    "section": "\n28.10 YAML header",
    "text": "28.10 YAML header\nYou can control many other â€œwhole documentâ€ settings by tweaking the parameters of the YAML header.\nä½ å¯ä»¥é€šè¿‡è°ƒæ•´ YAML å¤´éƒ¨çš„å‚æ•°æ¥æ§åˆ¶è®¸å¤šå…¶ä»–çš„â€œæ•´ä¸ªæ–‡æ¡£â€è®¾ç½®ã€‚\nYou might wonder what YAML stands for: itâ€™s â€œYAML Ainâ€™t Markup Languageâ€, which is designed for representing hierarchical data in a way thatâ€™s easy for humans to read and write.\nä½ å¯èƒ½æƒ³çŸ¥é“ YAML ä»£è¡¨ä»€ä¹ˆï¼šå®ƒæ˜¯ â€œYAML Ainâ€™t Markup Languageâ€ï¼ˆYAML ä¸æ˜¯æ ‡è®°è¯­è¨€ï¼‰ï¼Œæ—¨åœ¨ä»¥ä¸€ç§æ˜“äºäººç±»è¯»å†™çš„æ–¹å¼è¡¨ç¤ºåˆ†å±‚æ•°æ®ã€‚\nQuarto uses it to control many details of the output.\nQuarto ä½¿ç”¨å®ƒæ¥æ§åˆ¶è¾“å‡ºçš„è®¸å¤šç»†èŠ‚ã€‚\nHere weâ€™ll discuss three: self-contained documents, document parameters, and bibliographies.\nè¿™é‡Œæˆ‘ä»¬å°†è®¨è®ºä¸‰ä¸ªï¼šè‡ªåŒ…å«æ–‡æ¡£ã€æ–‡æ¡£å‚æ•°å’Œå‚è€ƒæ–‡çŒ®ã€‚\n\n28.10.1 Self-contained\nHTML documents typically have a number of external dependencies (e.g., images, CSS style sheets, JavaScript, etc.) and, by default, Quarto places these dependencies in a _files folder in the same directory as your .qmd file.\nHTML æ–‡æ¡£é€šå¸¸æœ‰è®¸å¤šå¤–éƒ¨ä¾èµ–é¡¹ï¼ˆä¾‹å¦‚ï¼Œå›¾åƒã€CSS æ ·å¼è¡¨ã€JavaScript ç­‰ï¼‰ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼ŒQuarto å°†è¿™äº›ä¾èµ–é¡¹æ”¾åœ¨ä¸ä½ çš„ .qmd æ–‡ä»¶ç›¸åŒç›®å½•ä¸‹çš„ä¸€ä¸ª _files æ–‡ä»¶å¤¹ä¸­ã€‚\nIf you publish the HTML file on a hosting platform (e.g., QuartoPub, https://quartopub.com/), the dependencies in this directory are published with your document and hence are available in the published report.\nå¦‚æœä½ åœ¨æ‰˜ç®¡å¹³å°ï¼ˆä¾‹å¦‚ï¼ŒQuartoPub, https://quartopub.com/ï¼‰ä¸Šå‘å¸ƒ HTML æ–‡ä»¶ï¼Œæ­¤ç›®å½•ä¸­çš„ä¾èµ–é¡¹å°†ä¸ä½ çš„æ–‡æ¡£ä¸€èµ·å‘å¸ƒï¼Œå› æ­¤åœ¨å‘å¸ƒçš„æŠ¥å‘Šä¸­å¯ç”¨ã€‚\nHowever, if you want to email the report to a colleague, you might prefer to have a single, self-contained, HTML document that embeds all of its dependencies.\nç„¶è€Œï¼Œå¦‚æœä½ æƒ³é€šè¿‡ç”µå­é‚®ä»¶å°†æŠ¥å‘Šå‘é€ç»™åŒäº‹ï¼Œä½ å¯èƒ½æ›´å–œæ¬¢ä¸€ä¸ªå•ä¸€çš„ã€è‡ªåŒ…å«çš„ã€åµŒå…¥äº†æ‰€æœ‰ä¾èµ–é¡¹çš„ HTML æ–‡æ¡£ã€‚\nYou can do this by specifying the embed-resources option:\nä½ å¯ä»¥é€šè¿‡æŒ‡å®š embed-resources é€‰é¡¹æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼š\nformat:\n  html:\n    embed-resources: true\nThe resulting file will be self-contained, such that it will need no external files and no internet access to be displayed properly by a browser.\nç”Ÿæˆçš„æ–‡ä»¶å°†æ˜¯è‡ªåŒ…å«çš„ï¼Œå› æ­¤å®ƒä¸éœ€è¦ä»»ä½•å¤–éƒ¨æ–‡ä»¶ï¼Œä¹Ÿä¸éœ€è¦äº’è”ç½‘è¿æ¥å³å¯è¢«æµè§ˆå™¨æ­£å¸¸æ˜¾ç¤ºã€‚\n\n28.10.2 Parameters\nQuarto documents can include one or more parameters whose values can be set when you render the report.\nQuarto æ–‡æ¡£å¯ä»¥åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå‚æ•°ï¼Œå…¶å€¼å¯ä»¥åœ¨ä½ æ¸²æŸ“æŠ¥å‘Šæ—¶è®¾ç½®ã€‚\nParameters are useful when you want to re-render the same report with distinct values for various key inputs.\nå½“ä½ å¸Œæœ›ä½¿ç”¨ä¸åŒçš„å…³é”®è¾“å…¥å€¼é‡æ–°æ¸²æŸ“åŒä¸€ä»½æŠ¥å‘Šæ—¶ï¼Œå‚æ•°éå¸¸æœ‰ç”¨ã€‚\nFor example, you might be producing sales reports per branch, exam results by student, or demographic summaries by country.\nä¾‹å¦‚ï¼Œä½ å¯èƒ½æ­£åœ¨æŒ‰åˆ†å…¬å¸ç”Ÿæˆé”€å”®æŠ¥å‘Šã€æŒ‰å­¦ç”Ÿç”Ÿæˆè€ƒè¯•æˆç»©æˆ–æŒ‰å›½å®¶ç”Ÿæˆäººå£æ‘˜è¦ã€‚\nTo declare one or more parameters, use the params field.\nè¦å£°æ˜ä¸€ä¸ªæˆ–å¤šä¸ªå‚æ•°ï¼Œè¯·ä½¿ç”¨ params å­—æ®µã€‚\nThis example uses a my_class parameter to determine which class of cars to display:\næ­¤ç¤ºä¾‹ä½¿ç”¨ my_class å‚æ•°æ¥ç¡®å®šè¦æ˜¾ç¤ºçš„æ±½è½¦ç±»åˆ«ï¼š\n\n---\nformat: html\nparams:\n  my_class: \"suv\"\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nclass &lt;- mpg |&gt; filter(class == params$my_class)\n```\n\n# Fuel economy for `r params$my_class`s\n\n```{r}\n#| message: false\n\nggplot(class, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n```\n\nAs you can see, parameters are available within the code chunks as a read-only list named params.\nå¦‚ä½ æ‰€è§ï¼Œå‚æ•°åœ¨ä»£ç å—ä¸­ä»¥åä¸º params çš„åªè¯»åˆ—è¡¨å½¢å¼æä¾›ã€‚\nYou can write atomic vectors directly into the YAML header.\nä½ å¯ä»¥å°†åŸå­å‘é‡ç›´æ¥å†™å…¥ YAML å¤´éƒ¨ã€‚\nYou can also run arbitrary R expressions by prefacing the parameter value with !expr.\nä½ è¿˜å¯ä»¥é€šè¿‡åœ¨å‚æ•°å€¼å‰åŠ ä¸Š !expr æ¥è¿è¡Œä»»æ„çš„ R è¡¨è¾¾å¼ã€‚\nThis is a good way to specify date/time parameters.\nè¿™æ˜¯æŒ‡å®šæ—¥æœŸ/æ—¶é—´å‚æ•°çš„å¥½æ–¹æ³•ã€‚\nparams:\n  start: !expr lubridate::ymd(\"2015-01-01\")\n  snapshot: !expr lubridate::ymd_hms(\"2015-01-01 12:30:00\")\n\n28.10.3 Bibliographies and Citations\nQuarto can automatically generate citations and a bibliography in a number of styles.\nQuarto å¯ä»¥è‡ªåŠ¨ç”Ÿæˆå¤šç§æ ·å¼çš„å¼•æ–‡å’Œå‚è€ƒæ–‡çŒ®ã€‚\nThe most straightforward way of adding citations and bibliographies to a Quarto document is using the visual editor in RStudio.\nå‘ Quarto æ–‡æ¡£æ·»åŠ å¼•æ–‡å’Œå‚è€ƒæ–‡çŒ®æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯ä½¿ç”¨ RStudio ä¸­çš„å¯è§†åŒ–ç¼–è¾‘å™¨ã€‚\nTo add a citation using the visual editor, go to Insert &gt; Citation.\nè¦ä½¿ç”¨å¯è§†åŒ–ç¼–è¾‘å™¨æ·»åŠ å¼•æ–‡ï¼Œè¯·è½¬åˆ°æ’å…¥ &gt; å¼•æ–‡ (Insert &gt; Citation)ã€‚\nCitations can be inserted from a variety of sources:\nå¼•æ–‡å¯ä»¥ä»å¤šç§æ¥æºæ’å…¥ï¼š\n\nDOI (Document Object Identifier) references.DOIï¼ˆæ–‡æ¡£å¯¹è±¡æ ‡è¯†ç¬¦ï¼‰å¼•ç”¨ã€‚\nZotero personal or group libraries.Zotero ä¸ªäººæˆ–å°ç»„æ–‡çŒ®åº“ã€‚\nSearches of Crossref, DataCite, or PubMed.\næœç´¢ Crossrefã€DataCite æˆ– PubMedã€‚\nYour document bibliography (a .bib file in the directory of your document)\nä½ çš„æ–‡æ¡£å‚è€ƒæ–‡çŒ®ï¼ˆæ–‡æ¡£ç›®å½•ä¸­çš„ä¸€ä¸ª .bib æ–‡ä»¶ï¼‰ã€‚\n\nUnder the hood, the visual mode uses the standard Pandoc markdown representation for citations (e.g., [@citation]).\nåœ¨åº•å±‚ï¼Œå¯è§†åŒ–æ¨¡å¼ä½¿ç”¨æ ‡å‡†çš„ Pandoc markdown è¡¨ç¤ºæ³•æ¥è¡¨ç¤ºå¼•æ–‡ï¼ˆä¾‹å¦‚ï¼Œ[@citation]ï¼‰ã€‚\nIf you add a citation using one of the first three methods, the visual editor will automatically create a bibliography.bib file for you and add the reference to it.\nå¦‚æœä½ ä½¿ç”¨å‰ä¸‰ç§æ–¹æ³•ä¹‹ä¸€æ·»åŠ å¼•æ–‡ï¼Œå¯è§†åŒ–ç¼–è¾‘å™¨å°†è‡ªåŠ¨ä¸ºä½ åˆ›å»ºä¸€ä¸ª bibliography.bib æ–‡ä»¶å¹¶å°†å¼•ç”¨æ·»åŠ åˆ°å…¶ä¸­ã€‚\nIt will also add a bibliography field to the document YAML.\nå®ƒè¿˜ä¼šåœ¨æ–‡æ¡£çš„ YAML ä¸­æ·»åŠ ä¸€ä¸ª bibliography å­—æ®µã€‚\nAs you add more references, this file will get populated with their citations.\néšç€ä½ æ·»åŠ æ›´å¤šå¼•ç”¨ï¼Œè¯¥æ–‡ä»¶å°†å¡«å……å®ƒä»¬çš„å¼•æ–‡ä¿¡æ¯ã€‚\nYou can also directly edit this file using many common bibliography formats including BibLaTeX, BibTeX, EndNote, Medline.\nä½ è¿˜å¯ä»¥ä½¿ç”¨è®¸å¤šå¸¸è§çš„å‚è€ƒæ–‡çŒ®æ ¼å¼ç›´æ¥ç¼–è¾‘æ­¤æ–‡ä»¶ï¼ŒåŒ…æ‹¬ BibLaTeXã€BibTeXã€EndNoteã€Medlineã€‚\nTo create a citation within your .qmd file in the source editor, use a key composed of â€˜@â€™ + the citation identifier from the bibliography file.\nè¦åœ¨æºç¼–è¾‘å™¨ä¸­åœ¨ä½ çš„ .qmd æ–‡ä»¶å†…åˆ›å»ºå¼•æ–‡ï¼Œè¯·ä½¿ç”¨ç”±â€œ@â€+ å‚è€ƒæ–‡çŒ®æ–‡ä»¶ä¸­çš„å¼•æ–‡æ ‡è¯†ç¬¦ç»„æˆçš„é”®ã€‚\nThen place the citation in square brackets.\nç„¶åå°†å¼•æ–‡æ”¾åœ¨æ–¹æ‹¬å·ä¸­ã€‚\nHere are some examples:\nè¿™é‡Œæœ‰ä¸€äº›ä¾‹å­ï¼š\nSeparate multiple citations with a `;`: Blah blah [@smith04; @doe99].\n\nYou can add arbitrary comments inside the square brackets: \nBlah blah [see @doe99, pp. 33-35; also @smith04, ch. 1].\n\nRemove the square brackets to create an in-text citation: @smith04 \nsays blah, or @smith04 [p. 33] says blah.\n\nAdd a `-` before the citation to suppress the author's name: \nSmith says blah [-@smith04].\nWhen Quarto renders your file, it will build and append a bibliography to the end of your document.\nå½“ Quarto æ¸²æŸ“ä½ çš„æ–‡ä»¶æ—¶ï¼Œå®ƒå°†æ„å»ºä¸€ä¸ªå‚è€ƒæ–‡çŒ®åˆ—è¡¨å¹¶é™„åŠ åˆ°ä½ çš„æ–‡æ¡£æœ«å°¾ã€‚\nThe bibliography will contain each of the cited references from your bibliography file, but it will not contain a section heading.\nå‚è€ƒæ–‡çŒ®åˆ—è¡¨å°†åŒ…å«ä½ çš„å‚è€ƒæ–‡çŒ®æ–‡ä»¶ä¸­çš„æ¯ä¸€ä¸ªè¢«å¼•ç”¨çš„æ–‡çŒ®ï¼Œä½†å®ƒä¸ä¼šåŒ…å«ç« èŠ‚æ ‡é¢˜ã€‚\nAs a result it is common practice to end your file with a section header for the bibliography, such as # References or # Bibliography.\nå› æ­¤ï¼Œé€šå¸¸çš„åšæ³•æ˜¯åœ¨æ–‡ä»¶æœ«å°¾ä¸ºå‚è€ƒæ–‡çŒ®æ·»åŠ ä¸€ä¸ªç« èŠ‚æ ‡é¢˜ï¼Œä¾‹å¦‚ # References æˆ– # Bibliographyã€‚\nYou can change the style of your citations and bibliography by referencing a CSL (citation style language) file in the csl field:\nä½ å¯ä»¥é€šè¿‡åœ¨ csl å­—æ®µä¸­å¼•ç”¨ä¸€ä¸ª CSLï¼ˆå¼•æ–‡æ ·å¼è¯­è¨€ï¼‰æ–‡ä»¶æ¥æ›´æ”¹ä½ çš„å¼•æ–‡å’Œå‚è€ƒæ–‡çŒ®çš„æ ·å¼ï¼š\nbibliography: rmarkdown.bib\ncsl: apa.csl\nAs with the bibliography field, your csl file should contain a path to the file.\nä¸å‚è€ƒæ–‡çŒ®å­—æ®µä¸€æ ·ï¼Œä½ çš„ csl æ–‡ä»¶åº”åŒ…å«æ–‡ä»¶çš„è·¯å¾„ã€‚\nHere we assume that the csl file is in the same directory as the .qmd file.\nè¿™é‡Œæˆ‘ä»¬å‡è®¾ csl æ–‡ä»¶ä¸ .qmd æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸­ã€‚\nA good place to find CSL style files for common bibliography styles is https://github.com/citation-style-language/styles.\nä¸€ä¸ªå¯»æ‰¾å¸¸è§å‚è€ƒæ–‡çŒ®æ ·å¼ CSL æ ·å¼æ–‡ä»¶çš„å¥½åœ°æ–¹æ˜¯ https://github.com/citation-style-language/stylesã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#workflow",
    "href": "quarto.html#workflow",
    "title": "28Â  Quarto",
    "section": "\n28.11 Workflow",
    "text": "28.11 Workflow\nEarlier, we discussed a basic workflow for capturing your R code where you work interactively in the console, then capture what works in the script editor.\nä¹‹å‰ï¼Œæˆ‘ä»¬è®¨è®ºäº†æ•è· R ä»£ç çš„åŸºæœ¬å·¥ä½œæµç¨‹ï¼Œå³åœ¨æ§åˆ¶å°ä¸­è¿›è¡Œäº¤äº’å¼å·¥ä½œï¼Œç„¶ååœ¨è„šæœ¬ç¼–è¾‘å™¨ä¸­æ•è·æœ‰æ•ˆçš„å†…å®¹ã€‚\nQuarto brings together the console and the script editor, blurring the lines between interactive exploration and long-term code capture.\nQuarto å°†æ§åˆ¶å°å’Œè„šæœ¬ç¼–è¾‘å™¨ç»“åˆåœ¨ä¸€èµ·ï¼Œæ¨¡ç³Šäº†äº¤äº’å¼æ¢ç´¢å’Œé•¿æœŸä»£ç æ•è·ä¹‹é—´çš„ç•Œé™ã€‚\nYou can rapidly iterate within a chunk, editing and re-executing with Cmd/Ctrl + Shift + Enter.\nä½ å¯ä»¥åœ¨ä¸€ä¸ªä»£ç å—å†…å¿«é€Ÿè¿­ä»£ï¼Œä½¿ç”¨ Cmd/Ctrl + Shift + Enter è¿›è¡Œç¼–è¾‘å’Œé‡æ–°æ‰§è¡Œã€‚\nWhen youâ€™re happy, you move on and start a new chunk.\nå½“ä½ æ»¡æ„æ—¶ï¼Œå°±å¯ä»¥ç»§ç»­å‰è¿›å¹¶å¼€å§‹ä¸€ä¸ªæ–°çš„ä»£ç å—ã€‚\nQuarto is also important because it so tightly integrates prose and code.\nQuarto ä¹Ÿå¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒå°†æ•£æ–‡å’Œä»£ç å¦‚æ­¤ç´§å¯†åœ°ç»“åˆåœ¨ä¸€èµ·ã€‚\nThis makes it a great analysis notebook because it lets you develop code and record your thoughts.\nè¿™ä½¿å®ƒæˆä¸ºä¸€ä¸ªå‡ºè‰²çš„åˆ†æç¬”è®°ï¼Œå› ä¸ºå®ƒèƒ½è®©ä½ åœ¨å¼€å‘ä»£ç çš„åŒæ—¶è®°å½•ä½ çš„æƒ³æ³•ã€‚\nAn analysis notebook shares many of the same goals as a classic lab notebook in the physical sciences.\nåˆ†æç¬”è®°ä¸ç‰©ç†ç§‘å­¦ä¸­çš„ç»å…¸å®éªŒç¬”è®°æœ‰è®¸å¤šç›¸åŒçš„ç›®æ ‡ã€‚\nIt:\nå®ƒï¼š\n\nRecords what you did and why you did it. Regardless of how great your memory is, if you donâ€™t record what you do, there will come a time when you have forgotten important details. Write them down so you donâ€™t forget!\nè®°å½•ä½ åšäº†ä»€ä¹ˆä»¥åŠä¸ºä»€ä¹ˆè¿™æ ·åšã€‚ æ— è®ºä½ çš„è®°å¿†åŠ›æœ‰å¤šå¥½ï¼Œå¦‚æœä½ ä¸è®°å½•ä½ æ‰€åšçš„äº‹æƒ…ï¼Œæ€»æœ‰ä¸€å¤©ä½ ä¼šå¿˜è®°é‡è¦çš„ç»†èŠ‚ã€‚ æŠŠå®ƒä»¬å†™ä¸‹æ¥ï¼Œè¿™æ ·ä½ å°±ä¸ä¼šå¿˜è®°äº†ï¼\nSupports rigorous thinking. You are more likely to come up with a strong analysis if you record your thoughts as you go, and continue to reflect on them. This also saves you time when you eventually write up your analysis to share with others.\næ”¯æŒä¸¥è°¨çš„æ€è€ƒã€‚ å¦‚æœä½ è¾¹åšè¾¹è®°å½•ä½ çš„æƒ³æ³•ï¼Œå¹¶ä¸æ–­åæ€ï¼Œä½ å°±æ›´æœ‰å¯èƒ½å¾—å‡ºä¸€ä¸ªæœ‰åŠ›çš„åˆ†æã€‚ è¿™ä¹Ÿèƒ½åœ¨ä½ æœ€ç»ˆæ’°å†™åˆ†æä¸ä»–äººåˆ†äº«æ—¶èŠ‚çœæ—¶é—´ã€‚\nHelps others understand your work. It is rare to do data analysis by yourself, and youâ€™ll often be working as part of a team. A lab notebook helps you share not only what youâ€™ve done, but why you did it with your colleagues or lab mates.\nå¸®åŠ©ä»–äººç†è§£ä½ çš„å·¥ä½œã€‚ ä½ å¾ˆå°‘ä¼šç‹¬è‡ªè¿›è¡Œæ•°æ®åˆ†æï¼Œé€šå¸¸ä½ ä¼šä½œä¸ºå›¢é˜Ÿçš„ä¸€å‘˜å·¥ä½œã€‚ å®éªŒç¬”è®°å¯ä»¥å¸®åŠ©ä½ ä¸ä»…åˆ†äº«ä½ åšäº†ä»€ä¹ˆï¼Œè¿˜èƒ½ä¸ä½ çš„åŒäº‹æˆ–å®éªŒå®¤ä¼™ä¼´åˆ†äº«ä½ ä¸ºä»€ä¹ˆè¿™ä¹ˆåšã€‚\n\nMuch of the good advice about using lab notebooks effectively can also be translated to analysis notebooks.\nè®¸å¤šå…³äºæœ‰æ•ˆä½¿ç”¨å®éªŒç¬”è®°çš„å¥½å»ºè®®ä¹Ÿå¯ä»¥è½¬åŒ–ä¸ºåˆ†æç¬”è®°ã€‚\nWeâ€™ve drawn on our own experiences and Colin Purringtonâ€™s advice on lab notebooks (https://colinpurrington.com/tips/lab-notebooks) to come up with the following tips:\næˆ‘ä»¬å€Ÿé‰´äº†è‡ªå·±çš„ç»éªŒå’Œ Colin Purrington å…³äºå®éªŒç¬”è®°çš„å»ºè®® (https://colinpurrington.com/tips/lab-notebooks)ï¼Œæå‡ºäº†ä»¥ä¸‹æŠ€å·§ï¼š\n\nEnsure each notebook has a descriptive title, an evocative file name, and a first paragraph that briefly describes the aims of the analysis.\nç¡®ä¿æ¯ä¸ªç¬”è®°éƒ½æœ‰ä¸€ä¸ªæè¿°æ€§çš„æ ‡é¢˜ã€ä¸€ä¸ªå¼•äººéæƒ³çš„æ–‡ä»¶åï¼Œä»¥åŠä¸€ä¸ªç®€è¦æè¿°åˆ†æç›®æ ‡çš„ç¬¬ä¸€æ®µã€‚\n\nUse the YAML header date field to record the date you started working on the notebook:\nä½¿ç”¨ YAML å¤´éƒ¨çš„æ—¥æœŸå­—æ®µæ¥è®°å½•ä½ å¼€å§‹ä½¿ç”¨ç¬”è®°çš„æ—¥æœŸï¼š\nyaml     date: 2016-08-23\nUse ISO8601 YYYY-MM-DD format so thatâ€™s there no ambiguity. Use it even if you donâ€™t normally write dates that way!\nä½¿ç”¨ ISO8601 YYYY-MM-DD æ ¼å¼ï¼Œè¿™æ ·å°±ä¸ä¼šæœ‰ä»»ä½•æ­§ä¹‰ã€‚ å³ä½¿ä½ é€šå¸¸ä¸é‚£æ ·å†™æ—¥æœŸï¼Œä¹Ÿè¦ä½¿ç”¨å®ƒï¼\n\nIf you spend a lot of time on an analysis idea and it turns out to be a dead end, donâ€™t delete it! Write up a brief note about why it failed and leave it in the notebook. That will help you avoid going down the same dead end when you come back to the analysis in the future.\nå¦‚æœä½ åœ¨ä¸€ä¸ªåˆ†ææƒ³æ³•ä¸ŠèŠ±äº†å¾ˆå¤šæ—¶é—´ï¼Œç»“æœå´å‘ç°æ˜¯æ¡æ­»èƒ¡åŒï¼Œä¸è¦åˆ é™¤å®ƒï¼ å†™ä¸€ä¸ªç®€çŸ­çš„ç¬”è®°ï¼Œè¯´æ˜å®ƒä¸ºä»€ä¹ˆå¤±è´¥ï¼Œå¹¶æŠŠå®ƒç•™åœ¨ç¬”è®°æœ¬é‡Œã€‚ è¿™å°†å¸®åŠ©ä½ åœ¨å°†æ¥å›åˆ°è¿™ä¸ªåˆ†ææ—¶ï¼Œé¿å…é‡è¹ˆè¦†è¾™ã€‚\nGenerally, youâ€™re better off doing data entry outside of R. But if you do need to record a small snippet of data, clearly lay it out using tibble::tribble().\né€šå¸¸æƒ…å†µä¸‹ï¼Œä½ æœ€å¥½åœ¨ R ä¹‹å¤–è¿›è¡Œæ•°æ®å½•å…¥ã€‚ ä½†æ˜¯ï¼Œå¦‚æœä½ ç¡®å®éœ€è¦è®°å½•ä¸€å°æ®µæ•°æ®ï¼Œè¯·ä½¿ç”¨ tibble::tribble() æ¸…æ™°åœ°å°†å…¶å¸ƒå±€ã€‚\nIf you discover an error in a data file, never modify it directly, but instead write code to correct the value. Explain why you made the fix.\nå¦‚æœä½ åœ¨æ•°æ®æ–‡ä»¶ä¸­å‘ç°é”™è¯¯ï¼Œåˆ‡å‹¿ç›´æ¥ä¿®æ”¹å®ƒï¼Œè€Œåº”ç¼–å†™ä»£ç æ¥ä¿®æ­£è¯¥å€¼ã€‚ è§£é‡Šä½ ä¸ºä»€ä¹ˆè¿›è¡Œä¿®å¤ã€‚\nBefore you finish for the day, make sure you can render the notebook. If youâ€™re using caching, make sure to clear the caches. That will let you fix any problems while the code is still fresh in your mind.\nåœ¨ä¸€å¤©ç»“æŸä¹‹å‰ï¼Œç¡®ä¿ä½ å¯ä»¥æ¸²æŸ“ç¬”è®°ã€‚ å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ç¼“å­˜ï¼Œè¯·ç¡®ä¿æ¸…é™¤ç¼“å­˜ã€‚ è¿™å°†è®©ä½ åœ¨ä»£ç è¿˜è®°å¿†çŠ¹æ–°çš„æ—¶å€™è§£å†³ä»»ä½•é—®é¢˜ã€‚\nIf you want your code to be reproducible in the long-run (i.e.Â so you can come back to run it next month or next year), youâ€™ll need to track the versions of the packages that your code uses. A rigorous approach is to use renv, https://rstudio.github.io/renv/index.html, which stores packages in your project directory. A quick and dirty hack is to include a chunk that runs sessionInfo() â€” that wonâ€™t let you easily recreate your packages as they are today, but at least youâ€™ll know what they were.\nå¦‚æœä½ å¸Œæœ›ä½ çš„ä»£ç åœ¨é•¿æœŸå†…æ˜¯å¯å¤ç°çš„ï¼ˆå³ï¼Œä¸‹ä¸ªæœˆæˆ–æ˜å¹´ä½ å›æ¥è¿˜èƒ½è¿è¡Œå®ƒï¼‰ï¼Œä½ éœ€è¦è·Ÿè¸ªä½ çš„ä»£ç ä½¿ç”¨çš„åŒ…çš„ç‰ˆæœ¬ã€‚ ä¸€ç§ä¸¥è°¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨ renv (https://rstudio.github.io/renv/index.html)ï¼Œå®ƒå°†åŒ…å­˜å‚¨åœ¨ä½ çš„é¡¹ç›®ç›®å½•ä¸­ã€‚ ä¸€ä¸ªå¿«é€Ÿè€Œç®€ä¾¿çš„æ–¹æ³•æ˜¯åŒ…å«ä¸€ä¸ªè¿è¡Œ sessionInfo() çš„ä»£ç å—â€”â€”è¿™ä¸èƒ½è®©ä½ è½»æ¾åœ°é‡ç°ä»Šå¤©çš„åŒ…ï¼Œä½†è‡³å°‘ä½ ä¼šçŸ¥é“å®ƒä»¬æ›¾ç»æ˜¯ä»€ä¹ˆç‰ˆæœ¬ã€‚\nYou are going to create many, many, many analysis notebooks over the course of your career. How are you going to organize them so you can find them again in the future? We recommend storing them in individual projects, and coming up with a good naming scheme.\nåœ¨ä½ çš„èŒä¸šç”Ÿæ¶¯ä¸­ï¼Œä½ å°†ä¼šåˆ›å»ºéå¸¸éå¸¸å¤šçš„åˆ†æç¬”è®°ã€‚ ä½ å°†å¦‚ä½•ç»„ç»‡å®ƒä»¬ä»¥ä¾¿å°†æ¥èƒ½å†æ¬¡æ‰¾åˆ°å®ƒä»¬ï¼Ÿ æˆ‘ä»¬å»ºè®®å°†å®ƒä»¬å­˜å‚¨åœ¨å„è‡ªçš„é¡¹ç›®ä¸­ï¼Œå¹¶åˆ¶å®šä¸€ä¸ªå¥½çš„å‘½åæ–¹æ¡ˆã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#summary",
    "href": "quarto.html#summary",
    "title": "28Â  Quarto",
    "section": "\n28.12 Summary",
    "text": "28.12 Summary\nIn this chapter we introduced you to Quarto for authoring and publishing reproducible computational documents that include your code and your prose in one place.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å‘ä½ ä»‹ç»äº† Quartoï¼Œç”¨äºåˆ›ä½œå’Œå‘å¸ƒå¯å¤ç°çš„è®¡ç®—æ–‡æ¡£ï¼Œå®ƒå°†ä½ çš„ä»£ç å’Œæ–‡å­—å†…å®¹é›†äºä¸€å¤„ã€‚\nYouâ€™ve learned about writing Quarto documents in RStudio with the visual or the source editor, how code chunks work and how to customize options for them, how to include figures and tables in your Quarto documents, and options for caching for computations.\nä½ å·²ç»å­¦ä¹ äº†å¦‚ä½•åœ¨ RStudio ä¸­ä½¿ç”¨å¯è§†åŒ–æˆ–æºä»£ç ç¼–è¾‘å™¨ç¼–å†™ Quarto æ–‡æ¡£ï¼Œä»£ç å—å¦‚ä½•å·¥ä½œä»¥åŠå¦‚ä½•ä¸ºå…¶è‡ªå®šä¹‰é€‰é¡¹ï¼Œå¦‚ä½•åœ¨ä½ çš„ Quarto æ–‡æ¡£ä¸­åŒ…å«å›¾å½¢å’Œè¡¨æ ¼ï¼Œä»¥åŠç”¨äºè®¡ç®—çš„ç¼“å­˜é€‰é¡¹ã€‚\nAdditionally, youâ€™ve learned about adjusting YAML header options for creating self-contained or parametrized documents as well as including citations and bibliography.\næ­¤å¤–ï¼Œä½ è¿˜å­¦ä¹ äº†è°ƒæ•´ YAML å¤´éƒ¨é€‰é¡¹ä»¥åˆ›å»ºè‡ªåŒ…å«æˆ–å‚æ•°åŒ–æ–‡æ¡£ï¼Œä»¥åŠåŒ…å«å¼•æ–‡å’Œå‚è€ƒæ–‡çŒ®ã€‚\nWe have also given you some troubleshooting and workflow tips.\næˆ‘ä»¬è¿˜ä¸ºä½ æä¾›äº†ä¸€äº›æ•…éšœæ’é™¤å’Œå·¥ä½œæµç¨‹çš„æç¤ºã€‚\nWhile this introduction should be sufficient to get you started with Quarto, there is still a lot more to learn.\nè™½ç„¶è¿™ä¸ªä»‹ç»è¶³ä»¥è®©ä½ å¼€å§‹ä½¿ç”¨ Quartoï¼Œä½†ä»æœ‰è®¸å¤šä¸œè¥¿éœ€è¦å­¦ä¹ ã€‚\nQuarto is still relatively young, and is still growing rapidly.\nQuarto è¿˜ç›¸å¯¹å¹´è½»ï¼Œå¹¶ä¸”ä»åœ¨å¿«é€Ÿå‘å±•ã€‚\nThe best place to stay on top of innovations is the official Quarto website: https://quarto.org.\näº†è§£æœ€æ–°åˆ›æ–°çš„æœ€ä½³åœ°ç‚¹æ˜¯ Quarto å®˜æ–¹ç½‘ç«™ï¼šhttps://quarto.orgã€‚\nThere are two important topics that we havenâ€™t covered here: collaboration and the details of accurately communicating your ideas to other humans.\næˆ‘ä»¬åœ¨è¿™é‡Œæ²¡æœ‰æ¶‰åŠä¸¤ä¸ªé‡è¦çš„ä¸»é¢˜ï¼šåä½œä»¥åŠå¦‚ä½•å‡†ç¡®åœ°å‘ä»–äººä¼ è¾¾ä½ çš„æƒ³æ³•çš„ç»†èŠ‚ã€‚\nCollaboration is a vital part of modern data science, and you can make your life much easier by using version control tools, like Git and GitHub.\nåä½œæ˜¯ç°ä»£æ•°æ®ç§‘å­¦è‡³å…³é‡è¦çš„ä¸€éƒ¨åˆ†ï¼Œé€šè¿‡ä½¿ç”¨åƒ Git å’Œ GitHub è¿™æ ·çš„ç‰ˆæœ¬æ§åˆ¶å·¥å…·ï¼Œä½ å¯ä»¥è®©ä½ çš„ç”Ÿæ´»è½»æ¾å¾—å¤šã€‚\nWe recommend â€œHappy Git with Râ€, a user friendly introduction to Git and GitHub from R users, by Jenny Bryan.\næˆ‘ä»¬æ¨è Jenny Bryan ç¼–å†™çš„ã€ŠHappy Git with Rã€‹ï¼Œè¿™æ˜¯ä¸€æœ¬ç”± R ç”¨æˆ·ç¼–å†™çš„å¯¹ Git å’Œ GitHub ç”¨æˆ·å‹å¥½çš„å…¥é—¨ä¹¦ã€‚\nThe book is freely available online: https://happygitwithr.com.\nè¿™æœ¬ä¹¦å¯ä»¥åœ¨çº¿å…è´¹è·å–ï¼šhttps://happygitwithr.comã€‚\nWe have also not touched on what you should actually write in order to clearly communicate the results of your analysis.\næˆ‘ä»¬ä¹Ÿæ²¡æœ‰æ¶‰åŠä½ åº”è¯¥å®é™…å†™äº›ä»€ä¹ˆï¼Œä»¥ä¾¿æ¸…æ™°åœ°ä¼ è¾¾ä½ çš„åˆ†æç»“æœã€‚\nTo improve your writing, we highly recommend reading either Style: Lessons in Clarity and Grace by Joseph M. Williams & Joseph Bizup, or The Sense of Structure: Writing from the Readerâ€™s Perspective by George Gopen.\nä¸ºäº†æé«˜ä½ çš„å†™ä½œæ°´å¹³ï¼Œæˆ‘ä»¬å¼ºçƒˆæ¨èé˜…è¯» Joseph M. Williams å’Œ Joseph Bizup åˆè‘—çš„ã€Šé£æ ¼ï¼šæ¸…æ™°ä¸ä¼˜é›…çš„è¯¾ç¨‹ã€‹(Style: Lessons in Clarity and Grace)ï¼Œæˆ–è€… George Gopen çš„ã€Šç»“æ„æ„Ÿï¼šä»è¯»è€…çš„è§’åº¦å†™ä½œã€‹(The Sense of Structure: Writing from the Readerâ€™s Perspective)ã€‚\nBoth books will help you understand the structure of sentences and paragraphs, and give you the tools to make your writing more clear.\nè¿™ä¸¤æœ¬ä¹¦éƒ½å°†å¸®åŠ©ä½ ç†è§£å¥å­å’Œæ®µè½çš„ç»“æ„ï¼Œå¹¶ä¸ºä½ æä¾›ä½¿ä½ çš„å†™ä½œæ›´æ¸…æ™°çš„å·¥å…·ã€‚\n(These books are rather expensive if purchased new, but theyâ€™re used by many English classes so there are plenty of cheap second-hand copies).\nï¼ˆè¿™äº›ä¹¦å¦‚æœä¹°æ–°çš„ä¼šç›¸å½“æ˜‚è´µï¼Œä½†å¾ˆå¤šè‹±è¯­è¯¾éƒ½ä½¿ç”¨å®ƒä»¬ï¼Œæ‰€ä»¥æœ‰å¾ˆå¤šä¾¿å®œçš„äºŒæ‰‹ä¹¦ï¼‰ã€‚\nGeorge Gopen also has a number of short articles on writing at https://www.georgegopen.com/litigation-articles.html.\nGeorge Gopen è¿˜åœ¨ https://www.georgegopen.com/litigation-articles.html ä¸Šå‘è¡¨äº†è®¸å¤šå…³äºå†™ä½œçš„çŸ­æ–‡ã€‚\nThey are aimed at lawyers, but almost everything applies to data scientists too.\nå®ƒä»¬æ˜¯é’ˆå¯¹å¾‹å¸ˆçš„ï¼Œä½†å‡ ä¹æ‰€æœ‰å†…å®¹ä¹ŸåŒæ ·é€‚ç”¨äºæ•°æ®ç§‘å­¦å®¶ã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>28</span>Â  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html",
    "href": "quarto-formats.html",
    "title": "29Â  Quarto formats",
    "section": "",
    "text": "29.1 Introduction\nSo far, youâ€™ve seen Quarto used to produce HTML documents.\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»çœ‹åˆ°äº†å¦‚ä½•ä½¿ç”¨ Quarto æ¥ç”Ÿæˆ HTML æ–‡æ¡£ã€‚\nThis chapter gives a brief overview of some of the many other types of output you can produce with Quarto.\næœ¬ç« å°†ç®€è¦æ¦‚è¿°ä½ å¯ä»¥ä½¿ç”¨ Quarto åˆ¶ä½œçš„è®¸å¤šå…¶ä»–ç±»å‹çš„è¾“å‡ºã€‚\nThere are two ways to set the output of a document:\næœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥è®¾ç½®æ–‡æ¡£çš„è¾“å‡ºï¼š",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#introduction",
    "href": "quarto-formats.html#introduction",
    "title": "29Â  Quarto formats",
    "section": "",
    "text": "Permanently, by modifying the YAML header:\næ°¸ä¹…æ€§åœ°ï¼Œé€šè¿‡ä¿®æ”¹ YAML æ ‡é¢˜ï¼š\nyaml     title: \"Diamond sizes\"     format: html\n\n\nTransiently, by calling quarto::quarto_render() by hand:\nä¸´æ—¶æ€§åœ°ï¼Œé€šè¿‡æ‰‹åŠ¨è°ƒç”¨ quarto::quarto_render()ï¼š\n{r}     #| eval: false     quarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"docx\")\nThis is useful if you want to programmatically produce multiple types of output since the output_format argument can also take a list of values.\nå¦‚æœä½ æƒ³ä»¥ç¼–ç¨‹æ–¹å¼ç”Ÿæˆå¤šç§ç±»å‹çš„è¾“å‡ºï¼Œè¿™ä¼šå¾ˆæœ‰ç”¨ï¼Œå› ä¸º output_format å‚æ•°ä¹Ÿå¯ä»¥æ¥å—ä¸€ä¸ªå€¼åˆ—è¡¨ã€‚\n{r}     #| eval: false     quarto::quarto_render(\"diamond-sizes.qmd\", output_format = c(\"docx\", \"pdf\"))",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#output-options",
    "href": "quarto-formats.html#output-options",
    "title": "29Â  Quarto formats",
    "section": "\n29.2 Output options",
    "text": "29.2 Output options\nQuarto offers a wide range of output formats.\nQuarto æä¾›äº†å¤šç§è¾“å‡ºæ ¼å¼ã€‚\nYou can find the complete list at https://quarto.org/docs/output-formats/all-formats.html.\nä½ å¯ä»¥åœ¨ https://quarto.org/docs/output-formats/all-formats.html æŸ¥çœ‹å®Œæ•´åˆ—è¡¨ã€‚\nMany formats share some output options (e.g., toc: true for including a table of contents), but others have options that are format specific (e.g., code-fold: true collapses code chunks into a &lt;details&gt; tag for HTML output so the user can display it on demand, itâ€™s not applicable in a PDF or Word document).\nè®¸å¤šæ ¼å¼å…±äº«ä¸€äº›è¾“å‡ºé€‰é¡¹ï¼ˆä¾‹å¦‚ï¼Œç”¨äºåŒ…å«ç›®å½•çš„ toc: trueï¼‰ï¼Œä½†å…¶ä»–æ ¼å¼åˆ™æœ‰å…¶ç‰¹å®šçš„é€‰é¡¹ï¼ˆä¾‹å¦‚ï¼Œcode-fold: true ä¼šå°†ä»£ç å—æŠ˜å æˆä¸€ä¸ª HTML è¾“å‡ºçš„ &lt;details&gt; æ ‡ç­¾ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥æŒ‰éœ€æ˜¾ç¤ºï¼Œè¿™åœ¨ PDF æˆ– Word æ–‡æ¡£ä¸­ä¸é€‚ç”¨ï¼‰ã€‚\nTo override the default options, you need to use an expanded format field.\nè¦è¦†ç›–é»˜è®¤é€‰é¡¹ï¼Œä½ éœ€è¦ä½¿ç”¨ä¸€ä¸ªæ‰©å±•çš„ format å­—æ®µã€‚\nFor example, if you wanted to render an html with a floating table of contents, youâ€™d use:\nä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³æ¸²æŸ“ä¸€ä¸ªå¸¦æœ‰æµ®åŠ¨ç›®å½•çš„ htmlï¼Œä½ å¯ä»¥è¿™æ ·å†™ï¼š\nformat:\n  html:\n    toc: true\n    toc_float: true\nYou can even render to multiple outputs by supplying a list of formats:\nä½ ç”šè‡³å¯ä»¥é€šè¿‡æä¾›ä¸€ä¸ªæ ¼å¼åˆ—è¡¨æ¥æ¸²æŸ“æˆå¤šç§è¾“å‡ºï¼š\nformat:\n  html:\n    toc: true\n    toc_float: true\n  pdf: default\n  docx: default\nNote the special syntax (pdf: default) if you donâ€™t want to override any default options.\næ³¨æ„ï¼Œå¦‚æœä½ ä¸æƒ³è¦†ç›–ä»»ä½•é»˜è®¤é€‰é¡¹ï¼Œå¯ä»¥ä½¿ç”¨ç‰¹æ®Šè¯­æ³• (pdf: default)ã€‚\nTo render to all formats specified in the YAML of a document, you can use output_format = \"all\".\nè¦æ¸²æŸ“åˆ°æ–‡æ¡£ YAML ä¸­æŒ‡å®šçš„æ‰€æœ‰æ ¼å¼ï¼Œä½ å¯ä»¥ä½¿ç”¨ output_format = \"all\"ã€‚\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"all\")",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#documents",
    "href": "quarto-formats.html#documents",
    "title": "29Â  Quarto formats",
    "section": "\n29.3 Documents",
    "text": "29.3 Documents\nThe previous chapter focused on the default html output.\nä¸Šä¸€ç« é‡ç‚¹ä»‹ç»äº†é»˜è®¤çš„ html è¾“å‡ºã€‚\nThere are several basic variations on that theme, generating different types of documents.\nåœ¨è¿™ä¸ªä¸»é¢˜ä¸Šæœ‰å‡ ç§åŸºæœ¬çš„å˜åŒ–ï¼Œå¯ä»¥ç”Ÿæˆä¸åŒç±»å‹çš„æ–‡æ¡£ã€‚\nFor example:\nä¾‹å¦‚ï¼š\n\npdf makes a PDF with LaTeX (an open-source document layout system), which youâ€™ll need to install. RStudio will prompt you if you donâ€™t already have it.pdf ä½¿ç”¨ LaTeXï¼ˆä¸€ä¸ªå¼€æºçš„æ–‡æ¡£æ’ç‰ˆç³»ç»Ÿï¼‰æ¥åˆ›å»º PDFï¼Œä½ éœ€è¦å®‰è£…å®ƒã€‚å¦‚æœä½ å°šæœªå®‰è£…ï¼ŒRStudio ä¼šæç¤ºä½ ã€‚\ndocx for Microsoft Word (.docx) documents.docx ç”¨äºç”Ÿæˆ Microsoft Word (.docx) æ–‡æ¡£ã€‚\nodt for OpenDocument Text (.odt) documents.odt ç”¨äºç”Ÿæˆ OpenDocument æ–‡æœ¬ (.odt) æ–‡æ¡£ã€‚\nrtf for Rich Text Format (.rtf) documents.rtf ç”¨äºç”Ÿæˆå¯Œæ–‡æœ¬æ ¼å¼ (.rtf) æ–‡æ¡£ã€‚\ngfm for a GitHub Flavored Markdown (.md) document.gfm ç”¨äºç”Ÿæˆ GitHub Flavored Markdown (.md) æ–‡æ¡£ã€‚\nipynb for Jupyter Notebooks (.ipynb).ipynb ç”¨äºç”Ÿæˆ Jupyter Notebooks (.ipynb)ã€‚\n\nRemember, when generating a document to share with decision-makers, you can turn off the default display of code by setting global options in the document YAML:\nè¯·è®°ä½ï¼Œåœ¨ç”Ÿæˆä¸å†³ç­–è€…å…±äº«çš„æ–‡æ¡£æ—¶ï¼Œä½ å¯ä»¥é€šè¿‡åœ¨æ–‡æ¡£ YAML ä¸­è®¾ç½®å…¨å±€é€‰é¡¹æ¥å…³é—­ä»£ç çš„é»˜è®¤æ˜¾ç¤ºï¼š\nexecute:\n  echo: false\nFor html documents another option is to make the code chunks hidden by default, but visible with a click:\nå¯¹äº html æ–‡æ¡£ï¼Œå¦ä¸€ä¸ªé€‰æ‹©æ˜¯è®©ä»£ç å—é»˜è®¤éšè—ï¼Œä½†å¯ä»¥é€šè¿‡ç‚¹å‡»æ¥æ˜¾ç¤ºï¼š\nformat:\n  html:\n    code: true",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#presentations",
    "href": "quarto-formats.html#presentations",
    "title": "29Â  Quarto formats",
    "section": "\n29.4 Presentations",
    "text": "29.4 Presentations\nYou can also use Quarto to produce presentations.\nä½ è¿˜å¯ä»¥ä½¿ç”¨ Quarto æ¥åˆ¶ä½œæ¼”ç¤ºæ–‡ç¨¿ã€‚\nYou get less visual control than with a tool like Keynote or PowerPoint, but automatically inserting the results of your R code into a presentation can save a huge amount of time.\nä¸ Keynote æˆ– PowerPoint è¿™æ ·çš„å·¥å…·ç›¸æ¯”ï¼Œä½ çš„è§†è§‰æ§åˆ¶åŠ›è¾ƒå¼±ï¼Œä½†å°† R ä»£ç çš„ç»“æœè‡ªåŠ¨æ’å…¥æ¼”ç¤ºæ–‡ç¨¿å¯ä»¥èŠ‚çœå¤§é‡æ—¶é—´ã€‚\nPresentations work by dividing your content into slides, with a new slide beginning at each second (##) level header.\næ¼”ç¤ºæ–‡ç¨¿çš„å·¥ä½œæ–¹å¼æ˜¯å°†ä½ çš„å†…å®¹åˆ†æˆå¹»ç¯ç‰‡ï¼Œæ¯ä¸€å¼ æ–°çš„å¹»ç¯ç‰‡éƒ½ä»¥äºŒçº§ (##) æ ‡é¢˜å¼€å§‹ã€‚\nAdditionally, first (#) level headers indicate the beginning of a new section with a section title slide that is, by default, centered in the middle.\næ­¤å¤–ï¼Œä¸€çº§ (#) æ ‡é¢˜è¡¨ç¤ºæ–°ç« èŠ‚çš„å¼€å§‹ï¼Œå…¶æ ‡é¢˜å¹»ç¯ç‰‡é»˜è®¤å±…ä¸­ã€‚\nQuarto supports a variety of presentation formats, including:\nQuarto æ”¯æŒå¤šç§æ¼”ç¤ºæ–‡ç¨¿æ ¼å¼ï¼ŒåŒ…æ‹¬ï¼š\n\nrevealjs - HTML presentation with revealjsrevealjs - ä½¿ç”¨ revealjs çš„ HTML æ¼”ç¤ºæ–‡ç¨¿\npptx - PowerPoint presentationpptx - PowerPoint æ¼”ç¤ºæ–‡ç¨¿\nbeamer - PDF presentation with LaTeX Beamer.beamer - ä½¿ç”¨ LaTeX Beamer çš„ PDF æ¼”ç¤ºæ–‡ç¨¿\n\nYou can read more about creating presentations with Quarto at https://quarto.org/docs/presentations.\nä½ å¯ä»¥åœ¨ https://quarto.org/docs/presentations é˜…è¯»æ›´å¤šå…³äºä½¿ç”¨ Quarto åˆ›å»ºæ¼”ç¤ºæ–‡ç¨¿çš„ä¿¡æ¯ã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#interactivity",
    "href": "quarto-formats.html#interactivity",
    "title": "29Â  Quarto formats",
    "section": "\n29.5 Interactivity",
    "text": "29.5 Interactivity\nJust like any HTML document, HTML documents created with Quarto can contain interactive components as well.\nå°±åƒä»»ä½• HTML æ–‡æ¡£ä¸€æ ·ï¼Œä½¿ç”¨ Quarto åˆ›å»ºçš„ HTML æ–‡æ¡£ä¹Ÿå¯ä»¥åŒ…å«äº¤äº’å¼ç»„ä»¶ã€‚\nHere we introduce two options for including interactivity in your Quarto documents: htmlwidgets and Shiny.\nè¿™é‡Œæˆ‘ä»¬ä»‹ç»åœ¨ä½ çš„ Quarto æ–‡æ¡£ä¸­åŠ å…¥äº¤äº’æ€§çš„ä¸¤ç§é€‰æ‹©ï¼šhtmlwidgets å’Œ Shinyã€‚\n\n29.5.1 htmlwidgets\nHTML is an interactive format, and you can take advantage of that interactivity with htmlwidgets, R functions that produce interactive HTML visualizations.\nHTML æ˜¯ä¸€ç§äº¤äº’å¼æ ¼å¼ï¼Œä½ å¯ä»¥åˆ©ç”¨ htmlwidgetsï¼ˆç”Ÿæˆäº¤äº’å¼ HTML å¯è§†åŒ–çš„ R å‡½æ•°ï¼‰æ¥åˆ©ç”¨è¿™ç§äº¤äº’æ€§ã€‚\nFor example, take the leaflet map below.\nä¾‹å¦‚ï¼Œçœ‹çœ‹ä¸‹é¢çš„ leaflet åœ°å›¾ã€‚\nIf youâ€™re viewing this page on the web, you can drag the map around, zoom in and out, etc.\nå¦‚æœä½ æ­£åœ¨ç½‘é¡µä¸ŠæŸ¥çœ‹æ­¤é¡µé¢ï¼Œä½ å¯ä»¥æ‹–åŠ¨åœ°å›¾ï¼Œæ”¾å¤§å’Œç¼©å°ç­‰ã€‚\nYou obviously canâ€™t do that in a book, so Quarto automatically inserts a static screenshot for you.\nåœ¨ä¹¦ä¸­ä½ æ˜¾ç„¶ä¸èƒ½è¿™æ ·åšï¼Œæ‰€ä»¥ Quarto ä¼šè‡ªåŠ¨ä¸ºä½ æ’å…¥ä¸€ä¸ªé™æ€æˆªå›¾ã€‚\n\nlibrary(leaflet)\nleaflet() |&gt;\n  setView(174.764, -36.877, zoom = 16) |&gt; \n  addTiles() |&gt;\n  addMarkers(174.764, -36.877, popup = \"Maungawhau\") \n\n\n\n\n\nThe great thing about htmlwidgets is that you donâ€™t need to know anything about HTML or JavaScript to use them.\nhtmlwidgets çš„ä¼˜ç‚¹åœ¨äºï¼Œä½ æ— éœ€äº†è§£ä»»ä½• HTML æˆ– JavaScript çŸ¥è¯†å°±å¯ä»¥ä½¿ç”¨å®ƒä»¬ã€‚\nAll the details are wrapped inside the package, so you donâ€™t need to worry about it.\næ‰€æœ‰çš„ç»†èŠ‚éƒ½è¢«å°è£…åœ¨åŒ…é‡Œï¼Œæ‰€ä»¥ä½ ä¸éœ€è¦æ‹…å¿ƒã€‚\nThere are many packages that provide htmlwidgets, including:\næœ‰è®¸å¤šæä¾› htmlwidgets çš„åŒ…ï¼ŒåŒ…æ‹¬ï¼š\n\ndygraphs for interactive time series visualizations.dygraphs ç”¨äºäº¤äº’å¼æ—¶é—´åºåˆ—å¯è§†åŒ–ã€‚\nDT for interactive tables.DT ç”¨äºäº¤äº’å¼è¡¨æ ¼ã€‚\nthreejs for interactive 3d plots.threejs ç”¨äºäº¤äº’å¼ 3D å›¾ã€‚\nDiagrammeR for diagrams (like flow charts and simple node-link diagrams).DiagrammeR ç”¨äºå›¾è¡¨ï¼ˆå¦‚æµç¨‹å›¾å’Œç®€å•çš„èŠ‚ç‚¹é“¾æ¥å›¾ï¼‰ã€‚\n\nTo learn more about htmlwidgets and see a complete list of packages that provide them visit https://www.htmlwidgets.org.\nè¦äº†è§£æ›´å¤šå…³äº htmlwidgets çš„ä¿¡æ¯å¹¶æŸ¥çœ‹æä¾›å®ƒä»¬çš„åŒ…çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·è®¿é—® https://www.htmlwidgets.orgã€‚\n\n29.5.2 Shiny\nhtmlwidgets provide client-side interactivity â€” all the interactivity happens in the browser, independently of R.\nhtmlwidgets æä¾›å®¢æˆ·ç«¯ (client-side) äº¤äº’æ€§â€”â€”æ‰€æœ‰çš„äº¤äº’éƒ½å‘ç”Ÿåœ¨æµè§ˆå™¨ä¸­ï¼Œä¸ R æ— å…³ã€‚\nOn the one hand, thatâ€™s great because you can distribute the HTML file without any connection to R.\nä¸€æ–¹é¢ï¼Œè¿™å¾ˆå¥½ï¼Œå› ä¸ºä½ å¯ä»¥åˆ†å‘ HTML æ–‡ä»¶è€Œæ— éœ€ä»»ä½•ä¸ R çš„è¿æ¥ã€‚\nHowever, that fundamentally limits what you can do to things that have been implemented in HTML and JavaScript.\nç„¶è€Œï¼Œè¿™ä»æ ¹æœ¬ä¸Šé™åˆ¶äº†ä½ åªèƒ½åšé‚£äº›å·²ç»åœ¨ HTML å’Œ JavaScript ä¸­å®ç°çš„äº‹æƒ…ã€‚\nAn alternative approach is to use shiny, a package that allows you to create interactivity using R code, not JavaScript.\nå¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ shinyï¼Œè¿™æ˜¯ä¸€ä¸ªå…è®¸ä½ ä½¿ç”¨ R ä»£ç è€Œä¸æ˜¯ JavaScript æ¥åˆ›å»ºäº¤äº’æ€§çš„åŒ…ã€‚\nTo call Shiny code from a Quarto document, add server: shiny to the YAML header:\nè¦ä» Quarto æ–‡æ¡£ä¸­è°ƒç”¨ Shiny ä»£ç ï¼Œè¯·åœ¨ YAML å¤´éƒ¨æ·»åŠ  server: shinyï¼š\ntitle: \"Shiny Web App\"\nformat: html\nserver: shiny\nThen you can use the â€œinputâ€ functions to add interactive components to the document:\nç„¶åä½ å¯ä»¥ä½¿ç”¨â€œè¾“å…¥â€å‡½æ•°å‘æ–‡æ¡£æ·»åŠ äº¤äº’å¼ç»„ä»¶ï¼š\n\nlibrary(shiny)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\n\n\n\n\n\n\n\n\n\nAnd you also need a code chunk with chunk option context: server which contains the code that needs to run in a Shiny server.\nä½ è¿˜éœ€è¦ä¸€ä¸ªå¸¦æœ‰ context: server å—é€‰é¡¹çš„ä»£ç å—ï¼Œå…¶ä¸­åŒ…å«éœ€è¦åœ¨ Shiny æœåŠ¡å™¨ä¸­è¿è¡Œçš„ä»£ç ã€‚\nYou can then refer to the values with input$name and input$age, and the code that uses them will be automatically re-run whenever they change.\nç„¶åä½ å¯ä»¥ç”¨ input$name å’Œ input$age æ¥å¼•ç”¨è¿™äº›å€¼ï¼Œä½¿ç”¨å®ƒä»¬çš„ä»£ç ä¼šåœ¨å®ƒä»¬æ”¹å˜æ—¶è‡ªåŠ¨é‡æ–°è¿è¡Œã€‚\nWe canâ€™t show you a live shiny app here because shiny interactions occur on the server-side.\næˆ‘ä»¬æ— æ³•åœ¨è¿™é‡Œå‘ä½ å±•ç¤ºä¸€ä¸ªå®æ—¶çš„ Shiny åº”ç”¨ï¼Œå› ä¸º Shiny çš„äº¤äº’å‘ç”Ÿåœ¨æœåŠ¡å™¨ç«¯ (server-side)ã€‚\nThis means that you can write interactive apps without knowing JavaScript, but you need a server to run them on.\nè¿™æ„å‘³ç€ä½ å¯ä»¥ç¼–å†™äº¤äº’å¼åº”ç”¨è€Œæ— éœ€äº†è§£ JavaScriptï¼Œä½†ä½ éœ€è¦ä¸€ä¸ªæœåŠ¡å™¨æ¥è¿è¡Œå®ƒä»¬ã€‚\nThis introduces a logistical issue: Shiny apps need a Shiny server to be run online.\nè¿™å°±å¸¦æ¥äº†ä¸€ä¸ªåå‹¤é—®é¢˜ï¼šShiny åº”ç”¨éœ€è¦ä¸€ä¸ª Shiny æœåŠ¡å™¨æ‰èƒ½åœ¨çº¿è¿è¡Œã€‚\nWhen you run Shiny apps on your own computer, Shiny automatically sets up a Shiny server for you, but you need a public-facing Shiny server if you want to publish this sort of interactivity online.\nå½“ä½ åœ¨è‡ªå·±çš„è®¡ç®—æœºä¸Šè¿è¡Œ Shiny åº”ç”¨æ—¶ï¼ŒShiny ä¼šè‡ªåŠ¨ä¸ºä½ è®¾ç½®ä¸€ä¸ª Shiny æœåŠ¡å™¨ï¼Œä½†å¦‚æœä½ æƒ³åœ¨çº¿å‘å¸ƒè¿™ç§äº¤äº’æ€§ï¼Œä½ éœ€è¦ä¸€ä¸ªé¢å‘å…¬ä¼—çš„ Shiny æœåŠ¡å™¨ã€‚\nThatâ€™s the fundamental trade-off of shiny: you can do anything in a shiny document that you can do in R, but it requires someone to be running R.\nè¿™æ˜¯ Shiny çš„æ ¹æœ¬æƒè¡¡ï¼šä½ å¯ä»¥åœ¨ Shiny æ–‡æ¡£ä¸­åšä»»ä½•ä½ åœ¨ R ä¸­èƒ½åšçš„äº‹æƒ…ï¼Œä½†è¿™éœ€è¦æœ‰äººåœ¨è¿è¡Œ Rã€‚\nFor learning more about Shiny, we recommend reading Mastering Shiny by Hadley Wickham, https://mastering-shiny.org.\nè¦äº†è§£æ›´å¤šå…³äº Shiny çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬æ¨èé˜…è¯» Hadley Wickham çš„ã€Šç²¾é€š Shinyã€‹(Mastering Shiny)ï¼Œç½‘å€ï¼šhttps://mastering-shiny.orgã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#websites-and-books",
    "href": "quarto-formats.html#websites-and-books",
    "title": "29Â  Quarto formats",
    "section": "\n29.6 Websites and books",
    "text": "29.6 Websites and books\nWith a bit of additional infrastructure, you can use Quarto to generate a complete website or book:\né€šè¿‡ä¸€äº›é¢å¤–çš„åŸºç¡€è®¾æ–½ï¼Œä½ å¯ä»¥ä½¿ç”¨ Quarto ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ç½‘ç«™æˆ–ä¹¦ç±ï¼š\n\nPut your .qmd files in a single directory. index.qmd will become the home page.\nå°†ä½ çš„ .qmd æ–‡ä»¶æ”¾åœ¨ä¸€ä¸ªå•ç‹¬çš„ç›®å½•ä¸­ã€‚index.qmd å°†æˆä¸ºä¸»é¡µã€‚\n\nAdd a YAML file named _quarto.yml that provides the navigation for the site. In this file, set the project type to either book or website, e.g.:\næ·»åŠ ä¸€ä¸ªåä¸º _quarto.yml çš„ YAML æ–‡ä»¶ï¼Œä¸ºç½‘ç«™æä¾›å¯¼èˆªã€‚åœ¨è¿™ä¸ªæ–‡ä»¶ä¸­ï¼Œå°† project ç±»å‹è®¾ç½®ä¸º book æˆ– websiteï¼Œä¾‹å¦‚ï¼š\nyaml     project:       type: book\n\n\nFor example, the following _quarto.yml file creates a website from three source files: index.qmd (the home page), viridis-colors.qmd, and terrain-colors.qmd.\nä¾‹å¦‚ï¼Œä¸‹é¢çš„ _quarto.yml æ–‡ä»¶ä»ä¸‰ä¸ªæºæ–‡ä»¶åˆ›å»ºäº†ä¸€ä¸ªç½‘ç«™ï¼šindex.qmdï¼ˆä¸»é¡µï¼‰ã€viridis-colors.qmd å’Œ terrain-colors.qmdã€‚\n\nproject:\n  type: website\n\nwebsite:\n  title: \"A website on color scales\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: viridis-colors.qmd\n        text: Viridis colors\n      - href: terrain-colors.qmd\n        text: Terrain colors\n\nThe _quarto.yml file you need for a book is very similarly structured.\nä½ ä¸ºä¹¦ç±æ‰€éœ€çš„ _quarto.yml æ–‡ä»¶ç»“æ„éå¸¸ç›¸ä¼¼ã€‚\nThe following example shows how you can create a book with four chapters that renders to three different outputs (html, pdf, and epub). Once again, the source files are .qmd files.\nä¸‹é¢çš„ä¾‹å­å±•ç¤ºäº†å¦‚ä½•åˆ›å»ºä¸€æœ¬æœ‰å››ç« çš„ä¹¦ï¼Œå¹¶æ¸²æŸ“æˆä¸‰ç§ä¸åŒçš„è¾“å‡º (htmlã€pdf å’Œ epub)ã€‚æºæ–‡ä»¶åŒæ ·æ˜¯ .qmd æ–‡ä»¶ã€‚\n\nproject:\n  type: book\n\nbook:\n  title: \"A book on color scales\"\n  author: \"Jane Coloriste\"\n  chapters:\n    - index.qmd\n    - intro.qmd\n    - viridis-colors.qmd\n    - terrain-colors.qmd\n\nformat:\n  html:\n    theme: cosmo\n  pdf: default\n  epub: default\n\nWe recommend that you use an RStudio project for your websites and books.\næˆ‘ä»¬å»ºè®®ä½ ä¸ºä½ çš„ç½‘ç«™å’Œä¹¦ç±ä½¿ç”¨ RStudio é¡¹ç›®ã€‚\nBased on the _quarto.yml file, RStudio will recognize the type of project youâ€™re working on, and add a Build tab to the IDE that you can use to render and preview your websites and books.\næ ¹æ® _quarto.yml æ–‡ä»¶ï¼ŒRStudio ä¼šè¯†åˆ«ä½ æ­£åœ¨å¤„ç†çš„é¡¹ç›®ç±»å‹ï¼Œå¹¶åœ¨ IDE ä¸­æ·»åŠ ä¸€ä¸ª Build é€‰é¡¹å¡ï¼Œä½ å¯ä»¥ç”¨å®ƒæ¥æ¸²æŸ“å’Œé¢„è§ˆä½ çš„ç½‘ç«™å’Œä¹¦ç±ã€‚\nBoth websites and books can also be rendered using quarto::quarto_render().\nç½‘ç«™å’Œä¹¦ç±ä¹Ÿå¯ä»¥ä½¿ç”¨ quarto::quarto_render() è¿›è¡Œæ¸²æŸ“ã€‚\nRead more at https://quarto.org/docs/websites about Quarto websites and https://quarto.org/docs/books about books.\nåœ¨ https://quarto.org/docs/websites é˜…è¯»æ›´å¤šå…³äº Quarto ç½‘ç«™çš„ä¿¡æ¯ï¼Œåœ¨ https://quarto.org/docs/books é˜…è¯»æ›´å¤šå…³äºä¹¦ç±çš„ä¿¡æ¯ã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#other-formats",
    "href": "quarto-formats.html#other-formats",
    "title": "29Â  Quarto formats",
    "section": "\n29.7 Other formats",
    "text": "29.7 Other formats\nQuarto offers even more output formats:\nQuarto æä¾›äº†æ›´å¤šçš„è¾“å‡ºæ ¼å¼ï¼š\n\nYou can write journal articles using Quarto Journal Templates: https://quarto.org/docs/journals/templates.html.\nä½ å¯ä»¥ä½¿ç”¨ Quarto æœŸåˆŠæ¨¡æ¿æ’°å†™æœŸåˆŠæ–‡ç« ï¼šhttps://quarto.org/docs/journals/templates.htmlã€‚\nYou can output Quarto documents to Jupyter Notebooks with format: ipynb: https://quarto.org/docs/reference/formats/ipynb.html.\nä½ å¯ä»¥ä½¿ç”¨ format: ipynb å°† Quarto æ–‡æ¡£è¾“å‡ºåˆ° Jupyter Notebooksï¼šhttps://quarto.org/docs/reference/formats/ipynb.htmlã€‚\n\nSee https://quarto.org/docs/output-formats/all-formats.html for a list of even more formats.\nè¯·å‚é˜… https://quarto.org/docs/output-formats/all-formats.html è·å–æ›´å¤šæ ¼å¼çš„åˆ—è¡¨ã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#summary",
    "href": "quarto-formats.html#summary",
    "title": "29Â  Quarto formats",
    "section": "\n29.8 Summary",
    "text": "29.8 Summary\nIn this chapter we presented you a variety of options for communicating your results with Quarto, from static and interactive documents to presentations to websites and books.\nåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å‘ä½ ä»‹ç»äº†ä½¿ç”¨ Quarto äº¤æµæˆæœçš„å¤šç§é€‰æ‹©ï¼Œä»é™æ€å’Œäº¤äº’å¼æ–‡æ¡£åˆ°æ¼”ç¤ºæ–‡ç¨¿ï¼Œå†åˆ°ç½‘ç«™å’Œä¹¦ç±ã€‚\nTo learn more about effective communication in these different formats, we recommend the following resources:\nè¦äº†è§£æ›´å¤šå…³äºåœ¨è¿™äº›ä¸åŒæ ¼å¼ä¸­è¿›è¡Œæœ‰æ•ˆæ²Ÿé€šçš„çŸ¥è¯†ï¼Œæˆ‘ä»¬æ¨èä»¥ä¸‹èµ„æºï¼š\n\nTo improve your presentation skills, try Presentation Patterns by Neal Ford, Matthew McCollough, and Nathaniel Schutta. It provides a set of effective patterns (both low- and high-level) that you can apply to improve your presentations.\nä¸ºäº†æé«˜ä½ çš„æ¼”è®²æŠ€å·§ï¼Œå¯ä»¥è¯•è¯• Neal Fordã€Matthew McCollough å’Œ Nathaniel Schutta åˆè‘—çš„ Presentation Patternsã€‚å®ƒæä¾›äº†ä¸€å¥—è¡Œä¹‹æœ‰æ•ˆçš„æ¨¡å¼ï¼ˆåŒ…æ‹¬ä½å±‚æ¬¡å’Œé«˜å±‚æ¬¡ï¼‰ï¼Œä½ å¯ä»¥åº”ç”¨è¿™äº›æ¨¡å¼æ¥æ”¹è¿›ä½ çš„æ¼”è®²ã€‚\nIf you give academic talks, you might like the Leek group guide to giving talks.\nå¦‚æœä½ åšå­¦æœ¯æŠ¥å‘Šï¼Œä½ å¯èƒ½ä¼šå–œæ¬¢ Leek group guide to giving talksã€‚\nWe havenâ€™t taken it ourselves, but weâ€™ve heard good things about Matt McGarrityâ€™s online course on public speaking: https://www.coursera.org/learn/public-speaking.\næˆ‘ä»¬è‡ªå·±æ²¡æœ‰ä¸Šè¿‡ï¼Œä½†æˆ‘ä»¬å¬è¯´è¿‡ Matt McGarrity çš„åœ¨çº¿å…¬å¼€æ¼”è®²è¯¾ç¨‹çš„å¥½è¯„ï¼šhttps://www.coursera.org/learn/public-speakingã€‚\nIf you are creating many dashboards, make sure to read Stephen Fewâ€™s Information Dashboard Design: The Effective Visual Communication of Data. It will help you create dashboards that are truly useful, not just pretty to look at.\nå¦‚æœä½ æ­£åœ¨åˆ›å»ºè®¸å¤šä»ªè¡¨ç›˜ï¼Œè¯·åŠ¡å¿…é˜…è¯» Stephen Few çš„ Information Dashboard Design: The Effective Visual Communication of Dataã€‚å®ƒå°†å¸®åŠ©ä½ åˆ›å»ºçœŸæ­£æœ‰ç”¨è€Œä¸ä»…ä»…æ˜¯å¥½çœ‹çš„ä»ªè¡¨ç›˜ã€‚\nEffectively communicating your ideas often benefits from some knowledge of graphic design. Robin Williamsâ€™ The Non-Designerâ€™s Design Book is a great place to start.\næœ‰æ•ˆåœ°ä¼ è¾¾ä½ çš„æƒ³æ³•é€šå¸¸ä¼šå—ç›Šäºä¸€äº›å›¾å½¢è®¾è®¡çŸ¥è¯†ã€‚Robin Williams çš„ The Non-Designerâ€™s Design Book æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚",
    "crumbs": [
      "Communicate",
      "<span class='chapter-number'>29</span>Â  <span class='chapter-title'>Quarto formats</span>"
    ]
  }
]